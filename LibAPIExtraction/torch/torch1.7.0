
----------------------------------------/home/zhang/Packages/torch/torch1.7.0/serialization.py----------------------------------------
A:torch.serialization.path->tempfile.mkdtemp()
A:torch.serialization.start->f.tell()
A:torch.serialization.byte->f.read(1)
A:torch.serialization.version_strs->_import_dotted_name(storage_type.__module__).__version__.split('.')
A:torch.serialization.module_version->tuple((type(req_field)(version_strs[idx]) for (idx, req_field) in enumerate(req_version_tuple)))
A:torch.serialization.device->validate_cuda_device(location)
A:torch.serialization.device_count->torch.cuda.device_count()
A:torch.serialization.storage_type->normalize_storage_type(type(obj))
A:torch.serialization.location->map_location.get(location, location)
A:torch.serialization.result->pickle_module.Unpickler(data_file, **pickle_load_args).load()
A:torch.serialization.module->_import_dotted_name(storage_type.__module__)
A:torch.serialization.(source_lines, _, source_file)->get_source_lines_and_file(obj)
A:torch.serialization.source->''.join(source_lines)
A:torch.serialization.obj->data_type(size)
A:torch.serialization.obj_key->str(obj._cdata)
A:torch.serialization.sys_info->dict(protocol_version=PROTOCOL_VERSION, little_endian=sys.byteorder == 'little', type_sizes=dict(short=SHORT_SIZE, int=INT_SIZE, long=LONG_SIZE))
A:torch.serialization.pickler->pickle_module.Pickler(data_buf, protocol=pickle_protocol)
A:torch.serialization.serialized_storage_keys->sorted(serialized_storages.keys())
A:torch.serialization.data_buf->io.BytesIO()
A:torch.serialization.data_value->io.BytesIO().getvalue()
A:torch.serialization.buf->io.BytesIO()
A:torch.serialization.buf_value->io.BytesIO().getvalue()
A:torch.serialization.orig_position->opened_file.tell()
A:torch.serialization.restore_location->_get_restore_location(map_location)
A:torch.serialization.current_source->''.join(get_source_lines_and_file(container_type)[0])
A:torch.serialization.diff->difflib.unified_diff(current_source.split('\n'), original_source.split('\n'), source_file, source_file, lineterm='')
A:torch.serialization.lines->'\n'.join(diff)
A:torch.serialization.file_size->f.seek(0, 2)
A:torch.serialization.num_storages->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.args->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.storage_views->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.num_tensors->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.tensor_type->storage_to_tensor_type(storage)
A:torch.serialization.(ndim,)->struct.unpack('<i', f.read(4))
A:torch.serialization.size->struct.unpack(f'<{ndim}q', f.read(8 * ndim))
A:torch.serialization.stride->struct.unpack(f'<{ndim}q', f.read(8 * ndim))
A:torch.serialization.(storage_offset,)->struct.unpack('<q', f.read(8))
A:torch.serialization.tensor->tensor_type().set_(storage, storage_offset, size, stride)
A:torch.serialization.pickle_file->tar.extractfile('pickle')
A:torch.serialization.unpickler->pickle_module.Unpickler(data_file, **pickle_load_args)
A:torch.serialization.typename->_maybe_decode_ascii(saved_id[0])
A:torch.serialization.deserialized_objects[root_key]->restore_location(obj, location)
A:torch.serialization.f_should_read_directly->_should_read_directly(f)
A:torch.serialization.magic_number->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.protocol_version->pickle_module.load(f, **pickle_load_args)
A:torch.serialization._sys_info->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.deserialized_storage_keys->pickle_module.load(f, **pickle_load_args)
A:torch.serialization.offset->f.tell()
A:torch.serialization.storage->zip_file.get_storage_from_record(name, size, dtype).storage()
A:torch.serialization.loaded_storages[key]->restore_location(storage, location)
A:torch.serialization.data_file->io.BytesIO(zip_file.get_record(pickle_file))
torch.load(f,map_location=None,pickle_module=pickle,**pickle_load_args)
torch.save(obj,f:Union[str,os.PathLike,BinaryIO],pickle_module=pickle,pickle_protocol=DEFAULT_PROTOCOL,_use_new_zipfile_serialization=True)->None
torch.serialization.SourceChangeWarning(Warning)
torch.serialization._check_dill_version(pickle_module)->None
torch.serialization._check_seekable(f)->bool
torch.serialization._cpu_deserialize(obj,location)
torch.serialization._cpu_tag(obj)
torch.serialization._cuda_deserialize(obj,location)
torch.serialization._cuda_tag(obj)
torch.serialization._get_layout(name)
torch.serialization._get_restore_location(map_location)
torch.serialization._is_compressed_file(f)->bool
torch.serialization._is_path(name_or_buffer)
torch.serialization._is_torchscript_zip(zip_file)
torch.serialization._is_zipfile(f)->bool
torch.serialization._legacy_load(f,map_location,pickle_module,**pickle_load_args)
torch.serialization._legacy_save(obj,f,pickle_module,pickle_protocol)->None
torch.serialization._load(zip_file,map_location,pickle_module,pickle_file='data.pkl',**pickle_load_args)
torch.serialization._maybe_decode_ascii(bytes_str:Union[bytes,str])->str
torch.serialization._open_buffer_reader(self,buffer)
torch.serialization._open_buffer_reader.__init__(self,buffer)
torch.serialization._open_buffer_writer(_opener)
torch.serialization._open_buffer_writer.__exit__(self,*args)
torch.serialization._open_file(self,name,mode)
torch.serialization._open_file.__exit__(self,*args)
torch.serialization._open_file.__init__(self,name,mode)
torch.serialization._open_file_like(name_or_buffer,mode)
torch.serialization._open_zipfile_reader(self,name_or_buffer)
torch.serialization._open_zipfile_reader.__init__(self,name_or_buffer)
torch.serialization._open_zipfile_writer(name_or_buffer)
torch.serialization._open_zipfile_writer_buffer(self,buffer)
torch.serialization._open_zipfile_writer_buffer.__exit__(self,*args)->None
torch.serialization._open_zipfile_writer_buffer.__init__(self,buffer)
torch.serialization._open_zipfile_writer_file(self,name)
torch.serialization._open_zipfile_writer_file.__exit__(self,*args)->None
torch.serialization._open_zipfile_writer_file.__init__(self,name)
torch.serialization._opener(self,file_like)
torch.serialization._opener.__enter__(self)
torch.serialization._opener.__exit__(self,*args)
torch.serialization._opener.__init__(self,file_like)
torch.serialization._save(obj,zip_file,pickle_module,pickle_protocol)
torch.serialization._should_read_directly(f)
torch.serialization.check_module_version_greater_or_equal(module,req_version_tuple,error_if_malformed=True)
torch.serialization.default_restore_location(storage,location)
torch.serialization.load(f,map_location=None,pickle_module=pickle,**pickle_load_args)
torch.serialization.location_tag(storage:Storage)
torch.serialization.mkdtemp()
torch.serialization.normalize_storage_type(storage_type)
torch.serialization.register_package(priority,tagger,deserializer)
torch.serialization.save(obj,f:Union[str,os.PathLike,BinaryIO],pickle_module=pickle,pickle_protocol=DEFAULT_PROTOCOL,_use_new_zipfile_serialization=True)->None
torch.serialization.storage_to_tensor_type(storage)
torch.serialization.validate_cuda_device(location)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_utils.py----------------------------------------
A:torch._utils.non_blocking->_get_async_or_non_blocking('cuda', non_blocking, kwargs)
A:torch._utils.dtype->_import_dotted_name(dtype)
A:torch._utils.new_module_name->_import_dotted_name(dtype).__module__.replace('.sparse', '')
A:torch._utils.new_values->torch._values(self).type(new_values_type_name, non_blocking)
A:torch._utils.new_indices->torch._indices(self).type(new_indices_type_name, non_blocking)
A:torch._utils.device->torch.device(device)
A:torch._utils.new_type->getattr(torch.cuda, self.__class__.__name__)
A:torch._utils.indices->torch._indices(tensor)
A:torch._utils.values->torch._values(tensor)
A:torch._utils.argument->list(kwargs.keys()).pop()
A:torch._utils.t->torch._empty_per_channel_affine_quantized(size, scales=scales, zero_points=zero_points, axis=axis, dtype=storage.dtype).type()
A:torch._utils.tensor->torch._empty_per_channel_affine_quantized(size, scales=scales, zero_points=zero_points, axis=axis, dtype=storage.dtype)
A:torch._utils.result->torch._sparse_coo_tensor_unsafe(indices, values, size)
A:torch._utils.scales->torch.tensor(scales, dtype=torch.float)
A:torch._utils.zero_points->torch.tensor(zero_points, dtype=torch.float)
A:torch._utils.param->torch.nn.Parameter(data, requires_grad)
A:torch._utils.components->name.split('.')
A:torch._utils.obj->getattr(obj, component)
A:torch._utils.it->iter(iterable)
A:torch._utils.total->fn(total, element)
A:torch._utils.flat->torch.cat([t.contiguous().view(-1) for t in tensors], dim=0)
A:torch._utils.flat_indices->_flatten_dense_tensors([torch._indices(t) for t in tensors])
A:torch._utils.flat_values->_flatten_dense_tensors([torch._values(t) for t in tensors])
A:torch._utils.numel->torch._empty_per_channel_affine_quantized(size, scales=scales, zero_points=zero_points, axis=axis, dtype=storage.dtype).numel()
A:torch._utils.type_dict->defaultdict(list)
A:torch._utils.buf_dict->defaultdict(lambda : [[], 0])
A:torch._utils.fun.__annotations__->dict(kwargs)
A:torch._utils.exc_info->sys.exc_info()
A:torch._utils.self.exc_msg->''.join(traceback.format_exception(*exc_info))
A:torch._utils.msg->KeyErrorMessage(msg)
A:torch._utils.device_type->_get_available_device_type()
A:torch._utils.device_idx->_get_current_device_index()
torch._import_dotted_name(name)
torch._utils.ExceptionWrapper(self,exc_info=None,where='inbackground')
torch._utils.ExceptionWrapper.__init__(self,exc_info=None,where='inbackground')
torch._utils.ExceptionWrapper.reraise(self)
torch._utils.KeyErrorMessage(str)
torch._utils.KeyErrorMessage.__repr__(self)
torch._utils._accumulate(iterable,fn=lambdax,y:x+y)
torch._utils._cuda(self,device=None,non_blocking=False,**kwargs)
torch._utils._flatten_dense_tensors(tensors)
torch._utils._flatten_sparse_tensors(tensors)
torch._utils._get_all_device_indices()
torch._utils._get_async_or_non_blocking(function_name,non_blocking,kwargs)
torch._utils._get_available_device_type()
torch._utils._get_current_device_index()
torch._utils._get_device_attr(get_member)
torch._utils._get_device_index(device,optional=False,allow_cpu=False)->int
torch._utils._get_devices_properties(device_ids)
torch._utils._import_dotted_name(name)
torch._utils._rebuild_parameter(data,requires_grad,backward_hooks)
torch._utils._rebuild_qtensor(storage,storage_offset,size,stride,quantizer_params,requires_grad,backward_hooks)
torch._utils._rebuild_sparse_tensor(layout,data)
torch._utils._rebuild_tensor(storage,storage_offset,size,stride)
torch._utils._rebuild_tensor_v2(storage,storage_offset,size,stride,requires_grad,backward_hooks)
torch._utils._rebuild_xla_tensor(data,dtype,device,requires_grad)
torch._utils._reorder_tensors_as(tensors,ordered_tensors)
torch._utils._take_tensors(tensors,size_limit)
torch._utils._type(self,dtype=None,non_blocking=False,**kwargs)
torch._utils._unflatten_dense_tensors(flat,tensors)
torch._utils._unflatten_sparse_tensors(flat,tensors)
torch._utils._validate_loaded_sparse_tensors()
torch._utils.annotate(ret,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/storage.py----------------------------------------
A:torch.storage.memo->memo.setdefault('torch', {}).setdefault('torch', {})
A:torch.storage.new_storage->self.clone()
A:torch.storage.b->io.BytesIO()
A:torch.storage.allocator->torch.cuda._host_allocator()
torch._StorageBase(object)
torch._StorageBase.__copy__(self)
torch._StorageBase.__deepcopy__(self,memo)
torch._StorageBase.__iter__(self)
torch._StorageBase.__reduce__(self)
torch._StorageBase.__repr__(self)
torch._StorageBase.__sizeof__(self)
torch._StorageBase.__str__(self)
torch._StorageBase._new_shared(cls,size)
torch._StorageBase.bfloat16(self)
torch._StorageBase.bool(self)
torch._StorageBase.byte(self)
torch._StorageBase.char(self)
torch._StorageBase.clone(self)
torch._StorageBase.complex_double(self)
torch._StorageBase.complex_float(self)
torch._StorageBase.cpu(self)
torch._StorageBase.double(self)
torch._StorageBase.float(self)
torch._StorageBase.half(self)
torch._StorageBase.int(self)
torch._StorageBase.long(self)
torch._StorageBase.pin_memory(self)
torch._StorageBase.share_memory_(self)
torch._StorageBase.short(self)
torch._StorageBase.tolist(self)
torch.storage._StorageBase(object)
torch.storage._StorageBase.__copy__(self)
torch.storage._StorageBase.__deepcopy__(self,memo)
torch.storage._StorageBase.__iter__(self)
torch.storage._StorageBase.__reduce__(self)
torch.storage._StorageBase.__repr__(self)
torch.storage._StorageBase.__sizeof__(self)
torch.storage._StorageBase.__str__(self)
torch.storage._StorageBase._new_shared(cls,size)
torch.storage._StorageBase.bfloat16(self)
torch.storage._StorageBase.bool(self)
torch.storage._StorageBase.byte(self)
torch.storage._StorageBase.char(self)
torch.storage._StorageBase.clone(self)
torch.storage._StorageBase.complex_double(self)
torch.storage._StorageBase.complex_float(self)
torch.storage._StorageBase.cpu(self)
torch.storage._StorageBase.double(self)
torch.storage._StorageBase.float(self)
torch.storage._StorageBase.half(self)
torch.storage._StorageBase.int(self)
torch.storage._StorageBase.long(self)
torch.storage._StorageBase.pin_memory(self)
torch.storage._StorageBase.share_memory_(self)
torch.storage._StorageBase.short(self)
torch.storage._StorageBase.tolist(self)
torch.storage._load_from_bytes(b)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/types.py----------------------------------------
torch.types.Storage(object)
torch.types.Storage.__deepcopy__(self,memo)->'Storage'
torch.types.Storage._new_shared(self,int)->'Storage'
torch.types.Storage._write_file(self,f:Any,is_real_file:_bool,save_size:_bool)->None
torch.types.Storage.element_size(self)->int
torch.types.Storage.is_shared(self)->bool
torch.types.Storage.share_memory_(self)->'Storage'
torch.types.Storage.size(self)->int


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/__config__.py----------------------------------------
torch.__config__.parallel_info()
torch.__config__.show()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_ops.py----------------------------------------
A:torch._ops.old_flags->sys.getdlopenflags()
A:torch._ops.qualified_op_name->'{}::{}'.format(self.name, op_name)
A:torch._ops.op->torch._C._jit_get_operation(qualified_op_name)
A:torch._ops.__file__->os.path.join(os.path.dirname(__file__), '_ops.py')
A:torch._ops.self.loaded_libraries->set()
A:torch._ops.namespace->_OpNamespace(name)
A:torch._ops.path->torch._utils_internal.resolve_library_path(path)
A:torch._ops.ops->_Ops()
torch._ops._OpNamespace(self,name)
torch._ops._OpNamespace.__getattr__(self,op_name)
torch._ops._OpNamespace.__init__(self,name)
torch._ops._Ops(self)
torch._ops._Ops.__getattr__(self,name)
torch._ops._Ops.__init__(self)
torch._ops._Ops.load_library(self,path)
torch._ops.dl_open_guard()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_namedtensor_internals.py----------------------------------------
A:torch._namedtensor_internals.namedshape->namedshape.items().items()
A:torch._namedtensor_internals.globbed_names->expand_single_ellipsis(ellipsis_idx, len(names) - ellipsis_idx - 1, tensor_names)
A:torch._namedtensor_internals.ellipsis_idx->single_ellipsis_index(names, fn_name)
A:torch._namedtensor_internals.dim_map->build_dim_map(tensor)
A:torch._namedtensor_internals.has_rename_pairs->bool(rename_map)
torch._namedtensor_internals.build_dim_map(tensor)
torch._namedtensor_internals.check_serializing_named_tensor(tensor)
torch._namedtensor_internals.expand_single_ellipsis(numel_pre_glob,numel_post_glob,names)
torch._namedtensor_internals.is_ellipsis(item)
torch._namedtensor_internals.namer_api_name(inplace)
torch._namedtensor_internals.replace_ellipsis_by_position(ellipsis_idx,names,tensor_names)
torch._namedtensor_internals.resolve_ellipsis(names,tensor_names,fn_name)
torch._namedtensor_internals.single_ellipsis_index(names,fn_name)
torch._namedtensor_internals.unzip_namedshape(namedshape)
torch._namedtensor_internals.update_names(tensor,names,rename_map,inplace)
torch._namedtensor_internals.update_names_with_list(tensor,names,inplace)
torch._namedtensor_internals.update_names_with_mapping(tensor,rename_map,inplace)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_linalg_utils.py----------------------------------------
A:torch._linalg_utils.ndim->len(A.shape)
A:torch._linalg_utils.(Q, _)->torch.qr(A, some=True)
A:torch._linalg_utils.Q->torch.orgqr(*torch.geqrf(A))
A:torch._linalg_utils.(E, Z)->torch.symeig(A, eigenvectors, True)
A:torch._linalg_utils.E->torch.flip(E, dims=(-1,))
A:torch._linalg_utils.Z->torch.flip(Z, dims=(-1,))
torch._linalg_utils.basis(A)
torch._linalg_utils.bform(X,A,Y)
torch._linalg_utils.conjugate(A)
torch._linalg_utils.get_floating_dtype(A)
torch._linalg_utils.is_sparse(A)
torch._linalg_utils.matmul(A,B)
torch._linalg_utils.qform(A,S)
torch._linalg_utils.symeig(A,largest=False,eigenvectors=True)
torch._linalg_utils.transjugate(A)
torch._linalg_utils.transpose(A)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/overrides.py----------------------------------------
A:torch.overrides.ignored->get_ignored_functions()
A:torch.overrides.func->getattr(namespace, func_name)
A:torch.overrides.arg_type->type(arg)
A:torch.overrides.index->len(overloaded_args)
A:torch.overrides.overloaded_args->_get_overloaded_args(relevant_args)
A:torch.overrides.types->tuple(map(type, overloaded_args))
A:torch.overrides.result->overloaded_arg.__torch_function__(public_api, types, args, kwargs)
A:torch.overrides.func_name->'{}.{}'.format(public_api.__module__, public_api.__name__)
A:torch.overrides.overridable_funcs->get_overridable_functions()
A:torch.overrides.methods->set(overridable_funcs[torch.Tensor])
torch.handle_torch_function(public_api:Callable,relevant_args:Iterable[Any],*args,**kwargs)->Any
torch.has_torch_function(relevant_args:Iterable[Any])->bool
torch.overrides._get_overloaded_args(relevant_args:Iterable[Any])->List[Any]
torch.overrides.get_ignored_functions()->Set[Callable]
torch.overrides.get_overridable_functions()->Dict[Any, List[Callable]]
torch.overrides.get_tensor_methods()->Set[Callable]
torch.overrides.get_testing_overrides()->Dict[Callable, Callable]
torch.overrides.handle_torch_function(public_api:Callable,relevant_args:Iterable[Any],*args,**kwargs)->Any
torch.overrides.has_torch_function(relevant_args:Iterable[Any])->bool
torch.overrides.is_tensor_like(inp)
torch.overrides.is_tensor_method_or_property(func:Callable)->bool


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_lobpcg.py----------------------------------------
A:torch._lobpcg.Ut->self._get_svqb(U, False, tau_replace).transpose(-2, -1).contiguous()
A:torch._lobpcg.res->_symeig_backward_complete_eigenspace(D_grad, U_grad, A, D, U)
A:torch._lobpcg.poly_coeffs_shape->list(roots.shape)
A:torch._lobpcg.poly_coeffs->roots.new_zeros(poly_coeffs_shape)
A:torch._lobpcg.out->poly_coeffs_new.narrow(-1, poly_order - i, i + 1)
A:torch._lobpcg.zero_power->x.new_ones(1).expand(x.shape)
A:torch._lobpcg.gen->torch.Generator(A.device)
A:torch._lobpcg.U_ortho->proj_U_ortho.matmul(torch.randn((*A.shape[:-1], A.size(-1) - D.size(-1)), dtype=A.dtype, device=A.device, generator=gen))
A:torch._lobpcg.U_ortho_t->proj_U_ortho.matmul(torch.randn((*A.shape[:-1], A.size(-1) - D.size(-1)), dtype=A.dtype, device=A.device, generator=gen)).transpose(-2, -1).contiguous()
A:torch._lobpcg.chr_poly_D->_polynomial_coefficients_given_roots(D)
A:torch._lobpcg.series_acc->A.matmul(U_grad_projected).new_zeros(U_grad_projected.shape)
A:torch._lobpcg.poly_D->_vector_polynomial_value(chr_poly_D[..., k:], D)
A:torch._lobpcg.U_grad_projected->A.matmul(U_grad_projected)
A:torch._lobpcg.chr_poly_D_at_A->_matrix_polynomial_value(chr_poly_D, A)
A:torch._lobpcg.chr_poly_D_at_A_to_U_ortho->torch.matmul(U_ortho_t, torch.matmul(chr_poly_D_at_A, U_ortho))
A:torch._lobpcg.chr_poly_D_at_A_to_U_ortho_L->torch.cholesky(chr_poly_D_at_A_to_U_ortho_sign * chr_poly_D_at_A_to_U_ortho)
A:torch._lobpcg.(D, U)->_lobpcg(A, k, B, X, n, iK, niter, tol, largest, method, tracker, ortho_iparams, ortho_fparams, ortho_bparams)
A:torch._lobpcg.A_grad->_symeig_backward(D_grad, U_grad, A, D, U, largest)
A:torch._lobpcg.dtype->_utils.get_floating_dtype(A)
A:torch._lobpcg.iparams['ortho_i_max']->iparams.get('ortho_i_max', 3)
A:torch._lobpcg.iparams['ortho_j_max']->iparams.get('ortho_j_max', 3)
A:torch._lobpcg.fparams['ortho_tol']->fparams.get('ortho_tol', tol)
A:torch._lobpcg.fparams['ortho_tol_drop']->fparams.get('ortho_tol_drop', tol)
A:torch._lobpcg.fparams['ortho_tol_replace']->fparams.get('ortho_tol_replace', tol)
A:torch._lobpcg.bparams['ortho_use_drop']->bparams.get('ortho_use_drop', False)
A:torch._lobpcg.N->int(torch.prod(torch.tensor(A.shape[:-2])))
A:torch._lobpcg.bA->A.reshape((N,) + A.shape[-2:])
A:torch._lobpcg.bE->torch.empty((N, k), dtype=dtype, device=device)
A:torch._lobpcg.bXret->torch.empty((N, m, k), dtype=dtype, device=device)
A:torch._lobpcg.worker->LOBPCG(A, B, X, iK, iparams, fparams, bparams, method, tracker)
A:torch._lobpcg.self.E->torch.zeros((n,), dtype=X.dtype, device=X.device)
A:torch._lobpcg.self.R->torch.zeros((m, n), dtype=X.dtype, device=X.device)
A:torch._lobpcg.self.S->torch.zeros((m, 3 * n), dtype=X.dtype, device=X.device)
A:torch._lobpcg.X_norm->float(torch.norm(self.X))
A:torch._lobpcg.Ri->self._get_rayleigh_ritz_transform(self.X)
A:torch._lobpcg.M->_utils.qform(_utils.qform(self.A, self.X), Ri)
A:torch._lobpcg.(E, Z)->_utils.symeig(DUBUD, eigenvectors=True)
A:torch._lobpcg.self.X[:]->mm(self.X, mm(Ri, Z))
A:torch._lobpcg.nc->self.update_converged_count()
A:torch._lobpcg.W->self._get_ortho(self.R[:, nc:], self.S[:, :n + np])
A:torch._lobpcg.(E_, Z)->_utils.symeig(_utils.qform(self.A, S_), largest)
A:torch._lobpcg.self.X[:, nc:]->mm(S_, Z[:, :n - nc])
A:torch._lobpcg.P->mm(S_, mm(Z[:, n - nc:], _utils.basis(_utils.transpose(Z[:n - nc, n - nc:]))))
A:torch._lobpcg.self.X->mm(self.X, mm(Ri, Z))
A:torch._lobpcg.SBS->_utils.qform(B, S)
A:torch._lobpcg.d_col->(d ** (-0.5)).reshape(d.shape[0], 1)
A:torch._lobpcg.R->torch.cholesky(SBS * d_row * d_col, upper=True)
A:torch._lobpcg.Rinv->torch.inverse(R)
A:torch._lobpcg.UBU->mm(_utils.transpose(U), BU)
A:torch._lobpcg.d->mm(_utils.transpose(U), BU).diagonal(0, -2, -1)
A:torch._lobpcg.nz->torch.where(abs(d) != 0.0)
A:torch._lobpcg.keep->torch.where(E > t)
A:torch._lobpcg.BV_norm->torch.norm(mm_B(self.B, V))
A:torch._lobpcg.BU->mm_B(self.B, U)
A:torch._lobpcg.VBU->mm(_utils.transpose(V), BU)
A:torch._lobpcg.U->self._get_svqb(U, False, tau_replace)
A:torch._lobpcg.U_norm->torch.norm(U)
A:torch._lobpcg.BU_norm->torch.norm(BU)
A:torch._lobpcg.R_norm->torch.norm(R)
A:torch._lobpcg.vkey->'ortho_VBU_rerr[{}]'.format(i)
A:torch._lobpcg.VBU_norm->torch.norm(VBU)
torch._lobpcg.LOBPCG(self,A,B,X,iK,iparams,fparams,bparams,method,tracker)
torch._lobpcg.LOBPCG.__init__(self,A,B,X,iK,iparams,fparams,bparams,method,tracker)
torch._lobpcg.LOBPCG.__str__(self)
torch._lobpcg.LOBPCG._get_ortho(self,U,V)
torch._lobpcg.LOBPCG._get_rayleigh_ritz_transform(self,S)
torch._lobpcg.LOBPCG._get_svqb(self,U,drop,tau)
torch._lobpcg.LOBPCG._update_basic(self)
torch._lobpcg.LOBPCG._update_ortho(self)
torch._lobpcg.LOBPCG.call_tracker(self)
torch._lobpcg.LOBPCG.run(self)
torch._lobpcg.LOBPCG.stop_iteration(self)
torch._lobpcg.LOBPCG.update(self)
torch._lobpcg.LOBPCG.update_converged_count(self)
torch._lobpcg.LOBPCG.update_residual(self)
torch._lobpcg.LOBPCGAutogradFunction(torch.autograd.Function)
torch._lobpcg.LOBPCGAutogradFunction.backward(ctx,D_grad,U_grad)
torch._lobpcg.LOBPCGAutogradFunction.forward(ctx,A:Tensor,k:Optional[int]=None,B:Optional[Tensor]=None,X:Optional[Tensor]=None,n:Optional[int]=None,iK:Optional[Tensor]=None,niter:Optional[int]=None,tol:Optional[float]=None,largest:Optional[bool]=None,method:Optional[str]=None,tracker:Optional[None]=None,ortho_iparams:Optional[Dict[str,int]]=None,ortho_fparams:Optional[Dict[str,float]]=None,ortho_bparams:Optional[Dict[str,bool]]=None)->Tuple[Tensor, Tensor]
torch._lobpcg.LOBPCG_call_tracker(self)
torch._lobpcg._lobpcg(A:Tensor,k:Optional[int]=None,B:Optional[Tensor]=None,X:Optional[Tensor]=None,n:Optional[int]=None,iK:Optional[Tensor]=None,niter:Optional[int]=None,tol:Optional[float]=None,largest:Optional[bool]=None,method:Optional[str]=None,tracker:Optional[None]=None,ortho_iparams:Optional[Dict[str,int]]=None,ortho_fparams:Optional[Dict[str,float]]=None,ortho_bparams:Optional[Dict[str,bool]]=None)->Tuple[Tensor, Tensor]
torch._lobpcg._matrix_polynomial_value(poly,x,zero_power=None)
torch._lobpcg._polynomial_coefficients_given_roots(roots)
torch._lobpcg._polynomial_value(poly,x,zero_power,transition)
torch._lobpcg._symeig_backward(D_grad,U_grad,A,D,U,largest)
torch._lobpcg._symeig_backward_complete_eigenspace(D_grad,U_grad,A,D,U)
torch._lobpcg._symeig_backward_partial_eigenspace(D_grad,U_grad,A,D,U,largest)
torch._lobpcg._vector_polynomial_value(poly,x,zero_power=None)
torch._lobpcg.lobpcg(A:Tensor,k:Optional[int]=None,B:Optional[Tensor]=None,X:Optional[Tensor]=None,n:Optional[int]=None,iK:Optional[Tensor]=None,niter:Optional[int]=None,tol:Optional[float]=None,largest:Optional[bool]=None,method:Optional[str]=None,tracker:Optional[None]=None,ortho_iparams:Optional[Dict[str,int]]=None,ortho_fparams:Optional[Dict[str,float]]=None,ortho_bparams:Optional[Dict[str,bool]]=None)->Tuple[Tensor, Tensor]
torch.lobpcg(A:Tensor,k:Optional[int]=None,B:Optional[Tensor]=None,X:Optional[Tensor]=None,n:Optional[int]=None,iK:Optional[Tensor]=None,niter:Optional[int]=None,tol:Optional[float]=None,largest:Optional[bool]=None,method:Optional[str]=None,tracker:Optional[None]=None,ortho_iparams:Optional[Dict[str,int]]=None,ortho_fparams:Optional[Dict[str,float]]=None,ortho_bparams:Optional[Dict[str,bool]]=None)->Tuple[Tensor, Tensor]


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_six.py----------------------------------------
A:torch._six.t->type(obj)
torch._six.bind_method(fn,obj,obj_type)
torch._six.get_function_from_type(cls,name)
torch._six.istuple(obj)->bool
torch._six.with_metaclass(meta:type,*bases)->type


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_torch_docs.py----------------------------------------
A:torch._torch_docs.regx->re.compile('\\n\\s{4}(?!\\s)')
A:torch._torch_docs.common_args->parse_kwargs('\n    input (Tensor): the input tensor.\n    generator (:class:`torch.Generator`, optional): a pseudorandom number generator for sampling\n    out (Tensor, optional): the output tensor.\n    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n        returned tensor. Default: ``torch.preserve_format``.\n')
A:torch._torch_docs.reduceops_common_args->merge_dicts(common_args, parse_kwargs('\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n        If specified, the input tensor is casted to :attr:`dtype` before the operation\n        is performed. This is useful for preventing data type overflows. Default: None.\n    keepdim (bool): whether the output tensor has :attr:`dim` retained or not.\n'))
A:torch._torch_docs.multi_dim_common->merge_dicts(reduceops_common_args, parse_kwargs('\n    dim (int or tuple of ints): the dimension or dimensions to reduce.\n'), {'keepdim_details': '\nIf :attr:`keepdim` is ``True``, the output tensor is of the same size\nas :attr:`input` except in the dimension(s) :attr:`dim` where it is of size 1.\nOtherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in the\noutput tensor having 1 (or ``len(dim)``) fewer dimension(s).\n'})
A:torch._torch_docs.single_dim_common->merge_dicts(reduceops_common_args, parse_kwargs('\n    dim (int): the dimension to reduce.\n'), {'keepdim_details': 'If :attr:`keepdim` is ``True``, the output tensor is of the same size\nas :attr:`input` except in the dimension :attr:`dim` where it is of size 1.\nOtherwise, :attr:`dim` is squeezed (see :func:`torch.squeeze`), resulting in\nthe output tensor having 1 fewer dimension than :attr:`input`.'})
A:torch._torch_docs.factory_common_args->merge_dicts(common_args, parse_kwargs('\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n        Default: if ``None``, uses a global default (see :func:`torch.set_default_tensor_type`).\n    layout (:class:`torch.layout`, optional): the desired layout of returned Tensor.\n        Default: ``torch.strided``.\n    device (:class:`torch.device`, optional): the desired device of returned tensor.\n        Default: if ``None``, uses the current device for the default tensor type\n        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n        for CPU tensor types and the current CUDA device for CUDA tensor types.\n    requires_grad (bool, optional): If autograd should record operations on the\n        returned tensor. Default: ``False``.\n    pin_memory (bool, optional): If set, returned tensor would be allocated in\n        the pinned memory. Works only for CPU tensors. Default: ``False``.\n    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n        returned Tensor. Default: ``torch.contiguous_format``.\n'))
A:torch._torch_docs.factory_like_common_args->parse_kwargs('\n    input (Tensor): the size of :attr:`input` will determine size of the output tensor.\n    layout (:class:`torch.layout`, optional): the desired layout of returned tensor.\n        Default: if ``None``, defaults to the layout of :attr:`input`.\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned Tensor.\n        Default: if ``None``, defaults to the dtype of :attr:`input`.\n    device (:class:`torch.device`, optional): the desired device of returned tensor.\n        Default: if ``None``, defaults to the device of :attr:`input`.\n    requires_grad (bool, optional): If autograd should record operations on the\n        returned tensor. Default: ``False``.\n    pin_memory (bool, optional): If set, returned tensor would be allocated in\n        the pinned memory. Works only for CPU tensors. Default: ``False``.\n    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n        returned Tensor. Default: ``torch.preserve_format``.\n')
A:torch._torch_docs.factory_data_common_args->parse_kwargs('\n    data (array_like): Initial data for the tensor. Can be a list, tuple,\n        NumPy ``ndarray``, scalar, and other types.\n    dtype (:class:`torch.dtype`, optional): the desired data type of returned tensor.\n        Default: if ``None``, infers data type from :attr:`data`.\n    device (:class:`torch.device`, optional): the desired device of returned tensor.\n        Default: if ``None``, uses the current device for the default tensor type\n        (see :func:`torch.set_default_tensor_type`). :attr:`device` will be the CPU\n        for CPU tensor types and the current CUDA device for CUDA tensor types.\n    requires_grad (bool, optional): If autograd should record operations on the\n        returned tensor. Default: ``False``.\n    pin_memory (bool, optional): If set, returned tensor would be allocated in\n        the pinned memory. Works only for CPU tensors. Default: ``False``.\n')
torch._torch_docs.merge_dicts(*dicts)
torch._torch_docs.parse_kwargs(desc)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/functional.py----------------------------------------
A:torch.functional.empty_list->torch.jit.annotate(List[int], [])
A:torch.functional.result_temp->torch.jit.annotate(List[List[int]], [])
A:torch.functional.k->min(m, n)
A:torch.functional.U->U.narrow(-2, 0, k).narrow(-2, 0, k)
A:torch.functional.L->L.narrow(-1, 0, k).narrow(-1, 0, k)
A:torch.functional.indices->_indices_product(shape[:-2])
A:torch.functional.p_idx->_index_tensor_with_indices_list(P, idx)
A:torch.functional.P->P.index_select(1, torch.as_tensor(final_order, device=LU_pivots.device)).index_select(1, torch.as_tensor(final_order, device=LU_pivots.device))
A:torch.functional.signal_dim->input.view(input.shape[-signal_dim:]).dim()
A:torch.functional.pad->int(n_fft // 2)
A:torch.functional.input->input.view(input.shape[-signal_dim:]).view(input.shape[-signal_dim:])
A:torch.functional.(output, inverse_indices, counts)->torch._VF.unique_consecutive(input, return_inverse=return_inverse, return_counts=return_counts, dim=dim)
A:torch.functional.(output, _, counts)->_unique_consecutive_impl(input, return_inverse, return_counts, dim)
A:torch.functional.(output, _, _)->_unique_consecutive_impl(input, return_inverse, return_counts, dim)
A:torch.functional.(output, inverse_indices, _)->_unique_consecutive_impl(input, return_inverse, return_counts, dim)
A:torch.functional._return_inverse_false->boolean_dispatch(arg_name='return_counts', arg_index=3, default=False, if_true=_return_counts, if_false=_return_output, module_name=__name__, func_name='unique')
A:torch.functional._return_inverse_true->boolean_dispatch(arg_name='return_counts', arg_index=3, default=False, if_true=_unique_impl, if_false=_return_inverse, module_name=__name__, func_name='unique')
A:torch.functional.unique->boolean_dispatch(arg_name='return_inverse', arg_index=2, default=False, if_true=_return_inverse_true, if_false=_return_inverse_false, module_name=__name__, func_name='unique')
A:torch.functional._consecutive_return_inverse_false->boolean_dispatch(arg_name='return_counts', arg_index=1, default=False, if_true=_consecutive_return_counts, if_false=_consecutive_return_output, module_name=__name__, func_name='unique_consecutive')
A:torch.functional._consecutive_return_inverse_true->boolean_dispatch(arg_name='return_counts', arg_index=1, default=False, if_true=_unique_consecutive_impl, if_false=_consecutive_return_inverse, module_name=__name__, func_name='unique_consecutive')
A:torch.functional.unique_consecutive->boolean_dispatch(arg_name='return_inverse', arg_index=2, default=False, if_true=_consecutive_return_inverse_true, if_false=_consecutive_return_inverse_false, module_name=__name__, func_name='unique_consecutive')
A:torch.functional.dims->dims.item().item()
A:torch.functional.dims_a->list(range(-dims, 0))
A:torch.functional.dims_b->list(range(dims))
A:torch.functional.ndim->input.view(input.shape[-signal_dim:]).view(input.shape[-signal_dim:]).dim()
A:torch.functional.result->_lu_impl(A, pivot, get_infos, out)
A:torch.functional.lu->boolean_dispatch(arg_name='get_infos', arg_index=2, default=False, if_true=_lu_with_infos, if_false=_lu_no_infos, module_name=__name__, func_name='lu')
torch._check_list_size(out_len:int,get_infos:bool,out:_ListOrSeq)->None
torch._consecutive_return_counts(input,return_inverse=False,return_counts=False,dim=None)
torch._consecutive_return_inverse(input,return_inverse=False,return_counts=False,dim=None)
torch._consecutive_return_output(input,return_inverse=False,return_counts=False,dim=None)
torch._index_tensor_with_indices_list(tensor,indices)
torch._indices_product(indices:_Indices)->List[List[int]]
torch._lu_impl(A,pivot=True,get_infos=False,out=None)
torch._lu_no_infos(A,pivot=True,get_infos=False,out=None)
torch._lu_with_infos(A,pivot=True,get_infos=False,out=None)
torch._meshgrid(*tensors)
torch._return_counts(input,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch._return_inverse(input,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch._return_output(input,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch._unique_consecutive_impl(input:Tensor,return_inverse:bool=False,return_counts:bool=False,dim:Optional[int]=None)->_unique_impl_out
torch._unique_impl(input:Tensor,sorted:bool=True,return_inverse:bool=False,return_counts:bool=False,dim:Optional[int]=None)->_unique_impl_out
torch.align_tensors(*tensors)
torch.atleast_1d(*tensors)
torch.atleast_2d(*tensors)
torch.atleast_3d(*tensors)
torch.block_diag(*tensors)
torch.broadcast_tensors(*tensors)
torch.cartesian_prod(*tensors)
torch.cdist(x1,x2,p=2.0,compute_mode='use_mm_for_euclid_dist_if_necessary')
torch.chain_matmul(*matrices)
torch.einsum(equation,*operands)
torch.functional._check_list_size(out_len:int,get_infos:bool,out:_ListOrSeq)->None
torch.functional._consecutive_return_counts(input,return_inverse=False,return_counts=False,dim=None)
torch.functional._consecutive_return_inverse(input,return_inverse=False,return_counts=False,dim=None)
torch.functional._consecutive_return_output(input,return_inverse=False,return_counts=False,dim=None)
torch.functional._index_tensor_with_indices_list(tensor,indices)
torch.functional._indices_product(indices:_Indices)->List[List[int]]
torch.functional._lu_impl(A,pivot=True,get_infos=False,out=None)
torch.functional._lu_no_infos(A,pivot=True,get_infos=False,out=None)
torch.functional._lu_with_infos(A,pivot=True,get_infos=False,out=None)
torch.functional._meshgrid(*tensors)
torch.functional._return_counts(input,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch.functional._return_inverse(input,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch.functional._return_output(input,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch.functional._unique_consecutive_impl(input:Tensor,return_inverse:bool=False,return_counts:bool=False,dim:Optional[int]=None)->_unique_impl_out
torch.functional._unique_impl(input:Tensor,sorted:bool=True,return_inverse:bool=False,return_counts:bool=False,dim:Optional[int]=None)->_unique_impl_out
torch.functional.align_tensors(*tensors)
torch.functional.atleast_1d(*tensors)
torch.functional.atleast_2d(*tensors)
torch.functional.atleast_3d(*tensors)
torch.functional.block_diag(*tensors)
torch.functional.broadcast_tensors(*tensors)
torch.functional.cartesian_prod(*tensors)
torch.functional.cdist(x1,x2,p=2.0,compute_mode='use_mm_for_euclid_dist_if_necessary')
torch.functional.chain_matmul(*matrices)
torch.functional.einsum(equation,*operands)
torch.functional.istft(input:Tensor,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:Optional[Tensor]=None,center:bool=True,normalized:bool=False,onesided:Optional[bool]=None,length:Optional[int]=None,return_complex:bool=False)->Tensor
torch.functional.lu_unpack(LU_data,LU_pivots,unpack_data=True,unpack_pivots=True)
torch.functional.norm(input,p='fro',dim=None,keepdim=False,out=None,dtype=None)
torch.functional.split(tensor,split_size_or_sections,dim=0)
torch.functional.stft(input:Tensor,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:Optional[Tensor]=None,center:bool=True,pad_mode:str='reflect',normalized:bool=False,onesided:Optional[bool]=None,return_complex:Optional[bool]=None)->Tensor
torch.functional.tensordot(a,b,dims=2)
torch.istft(input:Tensor,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:Optional[Tensor]=None,center:bool=True,normalized:bool=False,onesided:Optional[bool]=None,length:Optional[int]=None,return_complex:bool=False)->Tensor
torch.lu_unpack(LU_data,LU_pivots,unpack_data=True,unpack_pivots=True)
torch.norm(input,p='fro',dim=None,keepdim=False,out=None,dtype=None)
torch.split(tensor,split_size_or_sections,dim=0)
torch.stft(input:Tensor,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:Optional[Tensor]=None,center:bool=True,pad_mode:str='reflect',normalized:bool=False,onesided:Optional[bool]=None,return_complex:Optional[bool]=None)->Tensor
torch.tensordot(a,b,dims=2)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_vmap_internals.py----------------------------------------
A:torch._vmap_internals.in_dims_as_tuple->_as_tuple(in_dims, len(args), lambda : f'vmap({_get_name(func)}, in_dims={in_dims}, ...)(<inputs>): expected one `in_dim` per input (got {len(args)} inputs) of {_get_name(func)}')
A:torch._vmap_internals.batch_size->_validate_and_get_batch_size(in_dims_as_tuple, args)
A:torch._vmap_internals.batched_inputs->tuple((arg if in_dim is None else torch._add_batch_dim(arg, in_dim, vmap_level) for (in_dim, arg) in zip(in_dims_as_tuple, args)))
A:torch._vmap_internals.num_outputs->_num_outputs(batched_outputs)
A:torch._vmap_internals.out_dims_as_tuple->_as_tuple(out_dims, num_outputs, lambda : f'vmap({_get_name(func)}, ..., out_dims={out_dims}): `out_dims` must have one dim per output (got {num_outputs} outputs) of {_get_name(func)}.')
A:torch._vmap_internals.fn_name->repr(func)
A:torch._vmap_internals.vmap_level->torch._C._vmapmode_increment_nesting()
A:torch._vmap_internals.(batched_inputs, batch_size)->_create_batched_inputs(in_dims, args, vmap_level, func)
A:torch._vmap_internals.batched_outputs->func(*batched_inputs)
torch._vmap_internals._as_tuple(value:Any,num_elements:int,error_message_lambda:Callable[[],str])->Tuple
torch._vmap_internals._check_args_can_be_mapped_with_in_dims(in_dims_as_tuple:Tuple[Optional[int],...],args:Tuple,func:Callable,in_dims:in_dims_t)->None
torch._vmap_internals._check_out_dims_is_int_or_int_tuple(out_dims:out_dims_t,func:Callable)->None
torch._vmap_internals._create_batched_inputs(in_dims:in_dims_t,args:Tuple,vmap_level:int,func:Callable)->Tuple[Tuple, int]
torch._vmap_internals._get_name(func:Callable)
torch._vmap_internals._num_outputs(batched_outputs:Union[Tensor,Tuple[Tensor,...]])->int
torch._vmap_internals._unwrap_batched(batched_outputs:Union[Tensor,Tuple[Tensor,...]],out_dims:out_dims_t,vmap_level:int,batch_size:int,func:Callable)->Tuple
torch._vmap_internals._validate_and_get_batch_size(in_dims_as_tuple:Tuple[Optional[int],...],args:Tuple)->int
torch._vmap_internals._validate_outputs(outputs:Any,func:Callable)->None
torch._vmap_internals.vmap(func:Callable,in_dims:in_dims_t=0,out_dims:out_dims_t=0)->Callable


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_lowrank.py----------------------------------------
A:torch._lowrank.dtype->_utils.get_floating_dtype(A)
A:torch._lowrank.R->torch.randn(n, q, dtype=dtype, device=A.device)
A:torch._lowrank.A_H->_utils.transjugate(A)
A:torch._lowrank.(Q, _)->(matmul(A, Q) - matmul(M, Q)).qr()
A:torch._lowrank.M_H->_utils.transjugate(M)
A:torch._lowrank.M_t->_utils.transpose(M)
A:torch._lowrank.A_t->_utils.transpose(A)
A:torch._lowrank.Q->get_approximate_basis(A, q, niter=niter, M=M)
A:torch._lowrank.Q_c->_utils.conjugate(Q)
A:torch._lowrank.B_t->matmul(A, Q_c)
A:torch._lowrank.(U, S, V)->torch.svd(_utils.transpose(B))
A:torch._lowrank.V->get_approximate_basis(A, q, niter=niter, M=M).matmul(V)
A:torch._lowrank.B->matmul(A_t, Q_c)
A:torch._lowrank.U->get_approximate_basis(A, q, niter=niter, M=M).matmul(U)
A:torch._lowrank.q->min(6, m, n)
A:torch._lowrank.indices->torch.zeros(2, len(column_indices), dtype=column_indices.dtype, device=column_indices.device)
A:torch._lowrank.C_t->torch.sparse_coo_tensor(indices, c.values(), (n, 1), dtype=dtype, device=A.device)
A:torch._lowrank.ones_m1_t->torch.ones(A.shape[:-2] + (1, m), dtype=dtype, device=A.device)
A:torch._lowrank.M->_utils.transpose(torch.sparse.mm(C_t, ones_m1_t))
A:torch._lowrank.C->A.mean(dim=(-2,), keepdim=True)
torch._lowrank._svd_lowrank(A,q=6,niter=2,M=None)
torch._lowrank.get_approximate_basis(A,q,niter=2,M=None)
torch._lowrank.pca_lowrank(A,q=None,center=True,niter=2)
torch._lowrank.svd_lowrank(A,q=6,niter=2,M=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_utils_internal.py----------------------------------------
A:torch._utils_internal.torch_parent->os.path.dirname(os.path.dirname(__file__))
A:torch._utils_internal.filename->inspect.getsourcefile(obj)
A:torch._utils_internal.(sourcelines, file_lineno)->inspect.getsourcelines(obj)
torch._utils_internal.get_file_path(*path_components)
torch._utils_internal.get_file_path_2(*path_components)
torch._utils_internal.get_source_lines_and_file(obj,error_msg=None)
torch._utils_internal.get_writable_path(path)
torch._utils_internal.prepare_multiprocessing_environment(path)
torch._utils_internal.resolve_library_path(path)
torch.get_file_path(*path_components)
torch.get_file_path_2(*path_components)
torch.prepare_multiprocessing_environment(path)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/version.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_storage_docs.py----------------------------------------
A:torch._storage_docs.cls->getattr(torch._C, cls_name)
torch._storage_docs.add_docstr_all(method,docstr)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/__future__.py----------------------------------------
torch.__future__.get_overwrite_module_params_on_conversion()
torch.__future__.set_overwrite_module_params_on_conversion(value)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_appdirs.py----------------------------------------
A:torch._appdirs.__version_info__->tuple((int(segment) for segment in __version__.split('.')))
A:torch._appdirs.path->os.path.join(path, version)
A:torch._appdirs.appname->os.path.join(appname, version)
A:torch._appdirs.key->winreg.OpenKey(_winreg.HKEY_CURRENT_USER, 'Software\\Microsoft\\Windows\\CurrentVersion\\Explorer\\Shell Folders')
A:torch._appdirs.(dir, type)->winreg.QueryValueEx(key, shell_folder_name)
A:torch._appdirs.dir->com.sun.jna.Native.toString(buf.tostring()).rstrip('\x00')
A:torch._appdirs.buf->array.zeros('c', buf_size)
A:torch._appdirs.buf2->ctypes.create_unicode_buffer(1024)
A:torch._appdirs.dirs->AppDirs(appname, appauthor=False)
torch._appdirs.AppDirs(self,appname=None,appauthor=None,version=None,roaming=False,multipath=False)
torch._appdirs.AppDirs.__init__(self,appname=None,appauthor=None,version=None,roaming=False,multipath=False)
torch._appdirs.AppDirs.site_config_dir(self)
torch._appdirs.AppDirs.site_data_dir(self)
torch._appdirs.AppDirs.user_cache_dir(self)
torch._appdirs.AppDirs.user_config_dir(self)
torch._appdirs.AppDirs.user_data_dir(self)
torch._appdirs.AppDirs.user_log_dir(self)
torch._appdirs.AppDirs.user_state_dir(self)
torch._appdirs._get_win_folder_from_registry(csidl_name)
torch._appdirs._get_win_folder_with_ctypes(csidl_name)
torch._appdirs._get_win_folder_with_jna(csidl_name)
torch._appdirs._get_win_folder_with_pywin32(csidl_name)
torch._appdirs.site_config_dir(appname=None,appauthor=None,version=None,multipath=False)
torch._appdirs.site_data_dir(appname=None,appauthor=None,version=None,multipath=False)
torch._appdirs.user_cache_dir(appname=None,appauthor=None,version=None,opinion=True)
torch._appdirs.user_config_dir(appname=None,appauthor=None,version=None,roaming=False)
torch._appdirs.user_data_dir(appname=None,appauthor=None,version=None,roaming=False)
torch._appdirs.user_log_dir(appname=None,appauthor=None,version=None,opinion=True)
torch._appdirs.user_state_dir(appname=None,appauthor=None,version=None,roaming=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quasirandom.py----------------------------------------
A:torch.quasirandom.cpu->torch.device('cpu')
A:torch.quasirandom.self.sobolstate->torch.zeros(dimension, self.MAXBIT, device=cpu, dtype=torch.long)
A:torch.quasirandom.g->torch.Generator()
A:torch.quasirandom.shift_ints->torch.randint(2, (self.dimension, self.MAXBIT), device=cpu, generator=g)
A:torch.quasirandom.self.shift->torch.zeros(self.dimension, device=cpu, dtype=torch.long)
A:torch.quasirandom.ltm->torch.randint(2, ltm_dims, device=cpu, generator=g).tril()
A:torch.quasirandom.self.quasi->self.shift.clone(memory_format=torch.contiguous_format)
A:torch.quasirandom.(result, self.quasi)->torch._sobol_engine_draw(self.quasi, n, self.sobolstate, self.dimension, self.num_generated, dtype=dtype)
torch.quasirandom.SobolEngine(self,dimension,scramble=False,seed=None)
torch.quasirandom.SobolEngine.__init__(self,dimension,scramble=False,seed=None)
torch.quasirandom.SobolEngine.__repr__(self)
torch.quasirandom.SobolEngine.draw(self,n=1,out=None,dtype=torch.float32)
torch.quasirandom.SobolEngine.fast_forward(self,n)
torch.quasirandom.SobolEngine.reset(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/random.py----------------------------------------
A:torch.random.seed->torch._C.default_generator.seed()
A:torch.random.num_devices->torch.cuda.device_count()
A:torch.random.devices->list(devices)
A:torch.random.cpu_rng_state->torch.get_rng_state()
torch.get_rng_state()->torch.Tensor
torch.initial_seed()->int
torch.manual_seed(seed)->torch._C.Generator
torch.random.fork_rng(devices=None,enabled=True,_caller='fork_rng',_devices_kw='devices')
torch.random.get_rng_state()->torch.Tensor
torch.random.initial_seed()->int
torch.random.manual_seed(seed)->torch._C.Generator
torch.random.seed()->int
torch.random.set_rng_state(new_state)->None
torch.seed()->int
torch.set_rng_state(new_state)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/__init__.py----------------------------------------
A:torch.__init__.pfiles_path->os.getenv('ProgramFiles', 'C:\\Program Files')
A:torch.__init__.py_dll_path->os.path.join(sys.exec_prefix, 'Library', 'bin')
A:torch.__init__.th_dll_path->os.path.join(os.path.dirname(__file__), 'lib')
A:torch.__init__.base_py_dll_path->os.path.join(sys.base_exec_prefix, 'Library', 'bin')
A:torch.__init__.dll_paths->list(filter(os.path.exists, [th_dll_path, py_dll_path, base_py_dll_path]))
A:torch.__init__.nvtoolsext_dll_path->os.path.join(os.getenv('NVTOOLSEXT_PATH', os.path.join(pfiles_path, 'NVIDIA Corporation', 'NvToolsExt')), 'bin', 'x64')
A:torch.__init__.cuda_version_1->version.cuda.replace('.', '_')
A:torch.__init__.default_path->os.path.join(pfiles_path, 'NVIDIA GPU Computing Toolkit', 'CUDA', 'v' + cuda_version)
A:torch.__init__.cuda_path->os.path.join(os.getenv(cuda_path_var, default_path), 'bin')
A:torch.__init__.kernel32->ctypes.WinDLL('kernel32.dll', use_last_error=True)
A:torch.__init__.with_load_library_flags->hasattr(kernel32, 'AddDllDirectory')
A:torch.__init__.prev_error_mode->ctypes.WinDLL('kernel32.dll', use_last_error=True).SetErrorMode(1)
A:torch.__init__.res->ctypes.WinDLL('kernel32.dll', use_last_error=True).LoadLibraryW(dll)
A:torch.__init__.err->ctypes.WinError(ctypes.get_last_error())
A:torch.__init__.dlls->glob.glob(os.path.join(th_dll_path, '*.dll'))
A:torch.__init__.last_error->ctypes.get_last_error()
A:torch.__init__.os.environ['PATH']->';'.join(dll_paths + [os.environ['PATH']])
A:torch.__init__.here->os.path.abspath(__file__)
A:torch.__init__.lib_path->os.path.join(os.path.dirname(here), 'lib', lib_name)
A:torch.__init__.old_flags->sys.getdlopenflags()
A:torch.__init__.t->_import_dotted_name(t)
A:torch.__init__.path->get_file_path('torch', 'bin', 'torch_shm_manager')
A:torch.__init__.globals()[name]->getattr(_C._VariableFunctions, name)
torch.__init__.Assert(condition,message)
torch.__init__.BFloat16Storage(_C.BFloat16StorageBase,_StorageBase)
torch.__init__.BoolStorage(_C.BoolStorageBase,_StorageBase)
torch.__init__.ByteStorage(_C.ByteStorageBase,_StorageBase)
torch.__init__.CharStorage(_C.CharStorageBase,_StorageBase)
torch.__init__.ComplexDoubleStorage(_C.ComplexDoubleStorageBase,_StorageBase)
torch.__init__.ComplexFloatStorage(_C.ComplexFloatStorageBase,_StorageBase)
torch.__init__.DoubleStorage(_C.DoubleStorageBase,_StorageBase)
torch.__init__.FloatStorage(_C.FloatStorageBase,_StorageBase)
torch.__init__.HalfStorage(_C.HalfStorageBase,_StorageBase)
torch.__init__.IntStorage(_C.IntStorageBase,_StorageBase)
torch.__init__.LongStorage(_C.LongStorageBase,_StorageBase)
torch.__init__.QInt32Storage(_C.QInt32StorageBase,_StorageBase)
torch.__init__.QInt8Storage(_C.QInt8StorageBase,_StorageBase)
torch.__init__.QUInt8Storage(_C.QUInt8StorageBase,_StorageBase)
torch.__init__.ShortStorage(_C.ShortStorageBase,_StorageBase)
torch.__init__._load_global_deps()
torch.__init__.compiled_with_cxx11_abi()
torch.__init__.is_deterministic()
torch.__init__.is_storage(obj)
torch.__init__.is_tensor(obj)
torch.__init__.manager_path()
torch.__init__.set_default_dtype(d)
torch.__init__.set_default_tensor_type(t)
torch.__init__.set_deterministic(d)
torch.__init__.typename(o)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_tensor_docs.py----------------------------------------
A:torch._tensor_docs.common_args->parse_kwargs('\n    memory_format (:class:`torch.memory_format`, optional): the desired memory format of\n        returned Tensor. Default: ``torch.preserve_format``.\n')
A:torch._tensor_docs.new_common_args->parse_kwargs('\n    size (int...): a list, tuple, or :class:`torch.Size` of integers defining the\n        shape of the output tensor.\n    dtype (:class:`torch.dtype`, optional): the desired type of returned tensor.\n        Default: if None, same :class:`torch.dtype` as this tensor.\n    device (:class:`torch.device`, optional): the desired device of returned tensor.\n        Default: if None, same :class:`torch.device` as this tensor.\n    requires_grad (bool, optional): If autograd should record operations on the\n        returned tensor. Default: ``False``.\n    pin_memory (bool, optional): If set, returned tensor would be allocated in\n        the pinned memory. Works only for CPU tensors. Default: ``False``.\n')
torch._tensor_docs.add_docstr_all(method,docstr)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_classes.py----------------------------------------
A:torch._classes.proxy->torch._C._get_custom_class_python_wrapper(self.name, attr)
A:torch._classes.namespace->_ClassNamespace(name)
A:torch._classes.classes->_Classes()
torch._classes._ClassNamespace(self,name)
torch._classes._ClassNamespace.__getattr__(self,attr)
torch._classes._ClassNamespace.__init__(self,name)
torch._classes._Classes(self)
torch._classes._Classes.__getattr__(self,name)
torch._classes._Classes.__init__(self)
torch._classes._Classes.load_library(self,path)
torch._classes._Classes.loaded_libraries(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/hub.py----------------------------------------
A:torch.hub.HASH_REGEX->re.compile('-([a-f0-9]*)\\.')
A:torch.hub.spec->importlib.util.spec_from_file_location(name, path)
A:torch.hub.module->importlib.util.module_from_spec(spec)
A:torch.hub.torch_home->os.path.expanduser(os.getenv(ENV_TORCH_HOME, os.path.join(os.getenv(ENV_XDG_CACHE_HOME, DEFAULT_CACHE_DIR), 'torch')))
A:torch.hub.(repo_info, branch)->github.split(':')
A:torch.hub.(repo_owner, repo_name)->repo_info.split('/')
A:torch.hub.hub_dir->get_dir()
A:torch.hub.(repo_owner, repo_name, branch)->_parse_repo_info(github)
A:torch.hub.normalized_br->branch.replace('/', '_')
A:torch.hub.repo_dir->_get_cache_or_reload(github, force_reload, True)
A:torch.hub.cached_file->os.path.join(model_dir, filename)
A:torch.hub.url->_git_archive_link(repo_owner, repo_name, branch)
A:torch.hub.extracted_repo->os.path.join(hub_dir, extraced_repo_name)
A:torch.hub.result->sys.path_importer_cache.get(item).find_module(name, [item])
A:torch.hub.importer->sys.path_importer_cache.get(item)
A:torch.hub.dependencies->_load_attr_from_module(m, VAR_DEPENDENCY)
A:torch.hub.func->_load_attr_from_module(m, model)
A:torch.hub.hub_module->import_module(MODULE_HUBCONF, hubconf_path)
A:torch.hub.entry->_load_entry_from_hubconf(hub_module, model)
A:torch.hub.source->kwargs.pop('source', 'github').lower()
A:torch.hub.force_reload->kwargs.pop('force_reload', False)
A:torch.hub.verbose->kwargs.pop('verbose', True)
A:torch.hub.repo_or_dir->_get_cache_or_reload(repo_or_dir, force_reload, verbose)
A:torch.hub.model->entry(*args, **kwargs)
A:torch.hub.hubconf_path->os.path.join(hubconf_dir, MODULE_HUBCONF)
A:torch.hub.req->Request(url, headers={'User-Agent': 'torch.hub'})
A:torch.hub.u->urlopen(req)
A:torch.hub.meta->urlopen(req).info()
A:torch.hub.content_length->urlopen(req).info().get_all('Content-Length')
A:torch.hub.file_size->int(content_length[0])
A:torch.hub.dst->os.path.expanduser(dst)
A:torch.hub.dst_dir->os.path.dirname(dst)
A:torch.hub.f->tempfile.NamedTemporaryFile(delete=False, dir=dst_dir)
A:torch.hub.sha256->hashlib.sha256()
A:torch.hub.buffer->urlopen(req).read(8192)
A:torch.hub.digest->hashlib.sha256().hexdigest()
A:torch.hub.infolist->zipfile.ZipFile(filename).infolist()
A:torch.hub.members->tempfile.NamedTemporaryFile(delete=False, dir=dst_dir).infolist()
A:torch.hub.extracted_file->os.path.join(model_dir, extraced_name)
A:torch.hub.model_dir->os.path.join(hub_dir, 'checkpoints')
A:torch.hub.parts->urlparse(url)
A:torch.hub.filename->os.path.basename(parts.path)
A:torch.hub.r->re.compile('-([a-f0-9]*)\\.').search(filename)
torch.hub._check_dependencies(m)
torch.hub._check_module_exists(name)
torch.hub._download_url_to_file(url,dst,hash_prefix=None,progress=True)
torch.hub._get_cache_or_reload(github,force_reload,verbose=True)
torch.hub._get_torch_home()
torch.hub._git_archive_link(repo_owner,repo_name,branch)
torch.hub._is_legacy_zip_format(filename)
torch.hub._legacy_zip_load(filename,model_dir,map_location)
torch.hub._load_attr_from_module(module,func_name)
torch.hub._load_entry_from_hubconf(m,model)
torch.hub._load_local(hubconf_dir,model,*args,**kwargs)
torch.hub._parse_repo_info(github)
torch.hub._remove_if_exists(path)
torch.hub.download_url_to_file(url,dst,hash_prefix=None,progress=True)
torch.hub.get_dir()
torch.hub.help(github,model,force_reload=False)
torch.hub.import_module(name,path)
torch.hub.list(github,force_reload=False)
torch.hub.load(repo_or_dir,model,*args,**kwargs)
torch.hub.load_state_dict_from_url(url,model_dir=None,map_location=None,progress=True,check_hash=False,file_name=None)
torch.hub.set_dir(d)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/tensor.py----------------------------------------
A:torch.tensor.new_tensor->self.new()
A:torch.tensor.new_storage->self.storage().__deepcopy__(memo)
A:torch.tensor.self._backward_hooks->OrderedDict()
A:torch.tensor.handle->torch.utils.hooks.RemovableHandle(self._backward_hooks)
A:torch.tensor.detach->_add_docstr(_C._TensorBase.detach, '\n    Returns a new Tensor, detached from the current graph.\n\n    The result will never require gradient.\n\n    .. note::\n\n      Returned Tensor shares the same storage with the original one.\n      In-place modifications on either of them will be seen, and may trigger\n      errors in correctness checks.\n      IMPORTANT NOTE: Previously, in-place size / stride / storage changes\n      (such as `resize_` / `resize_as_` / `set_` / `transpose_`) to the returned tensor\n      also update the original tensor. Now, these in-place changes will not update the\n      original tensor anymore, and will instead trigger an error.\n      For sparse tensors:\n      In-place indices / values changes (such as `zero_` / `copy_` / `add_`) to the\n      returned tensor will not update the original tensor anymore, and will instead\n      trigger an error.\n    ')
A:torch.tensor.detach_->_add_docstr(_C._TensorBase.detach_, '\n    Detaches the Tensor from the graph that created it, making it a leaf.\n    Views cannot be detached in-place.\n    ')
A:torch.tensor.weak_self->weakref.ref(self)
A:torch.tensor.var->weak_self()
A:torch.tensor.var._grad->grad.clone(memory_format=torch.contiguous_format)
A:torch.tensor.(LU, pivots, infos)->torch._lu_with_info(self, pivot=pivot, check_errors=not get_infos)
A:torch.tensor.split_size->int(split_size)
A:torch.tensor.dtype->torch.result_type(other, self)
A:torch.tensor.__eq__->_wrap_type_error_to_not_implemented(_C._TensorBase.eq)
A:torch.tensor.__ne__->_wrap_type_error_to_not_implemented(_C._TensorBase.ne)
A:torch.tensor.__lt__->_wrap_type_error_to_not_implemented(_C._TensorBase.lt)
A:torch.tensor.__le__->_wrap_type_error_to_not_implemented(_C._TensorBase.le)
A:torch.tensor.__gt__->_wrap_type_error_to_not_implemented(_C._TensorBase.gt)
A:torch.tensor.__ge__->_wrap_type_error_to_not_implemented(_C._TensorBase.ge)
A:torch.tensor.tensor_methods->dir(self.__class__)
A:torch.tensor.attrs->list(self.__dict__.keys())
A:torch.tensor.array->array.astype('uint8').astype('uint8')
A:torch.tensor.itemsize->self.storage().element_size()
A:torch.tensor.shape->tuple(self.shape)
A:torch.tensor.strides->tuple((s * itemsize for s in self.stride()))
A:torch.tensor.names->resolve_ellipsis(names, self.names, 'refine_names')
A:torch.tensor.ellipsis_idx->single_ellipsis_index(names, 'align_to')
A:torch.tensor.(names, sizes)->unzip_namedshape(sizes)
A:torch.tensor.ret->tuple((_convert(r, cls) for r in ret))
torch.Tensor(torch._C._TensorBase)
torch.Tensor.__array__(self,dtype=None)
torch.Tensor.__array_wrap__(self,array)
torch.Tensor.__contains__(self,element)
torch.Tensor.__cuda_array_interface__(self)
torch.Tensor.__deepcopy__(self,memo)
torch.Tensor.__dir__(self)
torch.Tensor.__floordiv__(self,other)
torch.Tensor.__format__(self,format_spec)
torch.Tensor.__hash__(self)
torch.Tensor.__ipow__(self,other)
torch.Tensor.__iter__(self)
torch.Tensor.__len__(self)
torch.Tensor.__rdiv__(self,other)
torch.Tensor.__reduce_ex__(self,proto)
torch.Tensor.__repr__(self)
torch.Tensor.__reversed__(self)
torch.Tensor.__rfloordiv__(self,other)
torch.Tensor.__rpow__(self,other)
torch.Tensor.__rsub__(self,other)
torch.Tensor.__setstate__(self,state)
torch.Tensor.__torch_function__(cls,func,types,args=(),kwargs=None)
torch.Tensor._update_names(self,names,inplace)
torch.Tensor.align_to(self,*names)
torch.Tensor.backward(self,gradient=None,retain_graph=None,create_graph=False)
torch.Tensor.grad(self)
torch.Tensor.grad(self)
torch.Tensor.grad(self,new_grad)
torch.Tensor.is_shared(self)
torch.Tensor.istft(self,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:'Optional[Tensor]'=None,center:bool=True,normalized:bool=False,onesided:Optional[bool]=None,length:Optional[int]=None,return_complex:bool=False)
torch.Tensor.lu(self,pivot=True,get_infos=False)
torch.Tensor.norm(self,p='fro',dim=None,keepdim=False,dtype=None)
torch.Tensor.refine_names(self,*names)
torch.Tensor.register_hook(self,hook)
torch.Tensor.reinforce(self,reward)
torch.Tensor.rename(self,*names,**rename_map)
torch.Tensor.rename_(self,*names,**rename_map)
torch.Tensor.resize(self,*sizes)
torch.Tensor.resize_as(self,tensor)
torch.Tensor.retain_grad(self)
torch.Tensor.share_memory_(self)
torch.Tensor.split(self,split_size,dim=0)
torch.Tensor.stft(self,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:'Optional[Tensor]'=None,center:bool=True,pad_mode:str='reflect',normalized:bool=False,onesided:Optional[bool]=None,return_complex:Optional[bool]=None)
torch.Tensor.unflatten(self,dim,sizes)
torch.Tensor.unique(self,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch.Tensor.unique_consecutive(self,return_inverse=False,return_counts=False,dim=None)
torch.tensor.Tensor(torch._C._TensorBase)
torch.tensor.Tensor.__array__(self,dtype=None)
torch.tensor.Tensor.__array_wrap__(self,array)
torch.tensor.Tensor.__contains__(self,element)
torch.tensor.Tensor.__cuda_array_interface__(self)
torch.tensor.Tensor.__deepcopy__(self,memo)
torch.tensor.Tensor.__dir__(self)
torch.tensor.Tensor.__floordiv__(self,other)
torch.tensor.Tensor.__format__(self,format_spec)
torch.tensor.Tensor.__hash__(self)
torch.tensor.Tensor.__ipow__(self,other)
torch.tensor.Tensor.__iter__(self)
torch.tensor.Tensor.__len__(self)
torch.tensor.Tensor.__rdiv__(self,other)
torch.tensor.Tensor.__reduce_ex__(self,proto)
torch.tensor.Tensor.__repr__(self)
torch.tensor.Tensor.__reversed__(self)
torch.tensor.Tensor.__rfloordiv__(self,other)
torch.tensor.Tensor.__rpow__(self,other)
torch.tensor.Tensor.__rsub__(self,other)
torch.tensor.Tensor.__setstate__(self,state)
torch.tensor.Tensor.__torch_function__(cls,func,types,args=(),kwargs=None)
torch.tensor.Tensor._update_names(self,names,inplace)
torch.tensor.Tensor.align_to(self,*names)
torch.tensor.Tensor.backward(self,gradient=None,retain_graph=None,create_graph=False)
torch.tensor.Tensor.grad(self)
torch.tensor.Tensor.grad(self)
torch.tensor.Tensor.grad(self,new_grad)
torch.tensor.Tensor.is_shared(self)
torch.tensor.Tensor.istft(self,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:'Optional[Tensor]'=None,center:bool=True,normalized:bool=False,onesided:Optional[bool]=None,length:Optional[int]=None,return_complex:bool=False)
torch.tensor.Tensor.lu(self,pivot=True,get_infos=False)
torch.tensor.Tensor.norm(self,p='fro',dim=None,keepdim=False,dtype=None)
torch.tensor.Tensor.refine_names(self,*names)
torch.tensor.Tensor.register_hook(self,hook)
torch.tensor.Tensor.reinforce(self,reward)
torch.tensor.Tensor.rename(self,*names,**rename_map)
torch.tensor.Tensor.rename_(self,*names,**rename_map)
torch.tensor.Tensor.resize(self,*sizes)
torch.tensor.Tensor.resize_as(self,tensor)
torch.tensor.Tensor.retain_grad(self)
torch.tensor.Tensor.share_memory_(self)
torch.tensor.Tensor.split(self,split_size,dim=0)
torch.tensor.Tensor.stft(self,n_fft:int,hop_length:Optional[int]=None,win_length:Optional[int]=None,window:'Optional[Tensor]'=None,center:bool=True,pad_mode:str='reflect',normalized:bool=False,onesided:Optional[bool]=None,return_complex:Optional[bool]=None)
torch.tensor.Tensor.unflatten(self,dim,sizes)
torch.tensor.Tensor.unique(self,sorted=True,return_inverse=False,return_counts=False,dim=None)
torch.tensor.Tensor.unique_consecutive(self,return_inverse=False,return_counts=False,dim=None)
torch.tensor._convert(ret,cls)
torch.tensor._wrap_type_error_to_not_implemented(f)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_VF.py----------------------------------------
A:torch._VF.sys.modules[__name__]->VFModule(__name__)
torch._VF.VFModule(self,name)
torch._VF.VFModule.__getattr__(self,attr)
torch._VF.VFModule.__init__(self,name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_jit_internal.py----------------------------------------
A:torch._jit_internal.parts->qualified_name.split('.')
A:torch._jit_internal.remaining_pieces->'.'.join(parts[1:])
A:torch._jit_internal.module_value->getattr(module, base)
A:torch._jit_internal.base->lookupInModule(expr[:i].strip(), module)
A:torch._jit_internal.(part, part_len)->parseNestedExpr(expr[i:], module)
A:torch._jit_internal.(value, len_parsed)->parseNestedExpr(expr, module)
A:torch._jit_internal.frame->inspect.currentframe()
A:torch._jit_internal.closure->get_closure(fn)
A:torch._jit_internal.drop_on_export->kwargs.pop('drop_on_export', None)
A:torch._jit_internal.item->getattr(mod, name)
A:torch._jit_internal.attr->get_torchscript_modifier(orig)
A:torch._jit_internal.mod->get_torchscript_modifier(fn)
A:torch._jit_internal.qual_name->_qualified_name(method)
A:torch._jit_internal.fn_overload_list->_overloaded_fns.get(qual_name)
A:torch._jit_internal.current_frame->inspect.currentframe()
A:torch._jit_internal.class_name_map->_overloaded_methods.get(qual_name, None)
A:torch._jit_internal.(class_name, line_no)->get_class_name_lineno(func)
A:torch._jit_internal.method_overloads->_overloaded_methods.get(qual_name, None).get(class_name, None)
A:torch._jit_internal.overloads->_overloaded_methods.get(qual_name, None).get(mod_class.__name__, None)
A:torch._jit_internal.args->getattr(ann, '__args__', ())
A:torch._jit_internal.BroadcastingList1->BroadcastingListCls()
A:torch._jit_internal.fields->list(obj._fields)
A:torch._jit_internal.has_annotations->hasattr(obj, '__annotations__')
A:torch._jit_internal.the_type->torch.jit.annotations.ann_to_type(obj.__annotations__[field], fake_range())
A:torch._jit_internal.TupleType->collections.namedtuple(unqual_name, field_names)
A:torch._jit_internal.hooks->torch._C._jit_get_emit_hooks()
A:torch._jit_internal.self.hooks->torch._C._jit_get_emit_hooks()
torch._jit_internal.BroadcastingListCls(object)
torch._jit_internal.BroadcastingListCls.__getitem__(self,types)
torch._jit_internal.FunctionModifiers(object)
torch._jit_internal.SourceContext(self,source,filename,file_lineno,leading_whitespace_len,uses_true_division=True)
torch._jit_internal.SourceContext.__init__(self,source,filename,file_lineno,leading_whitespace_len,uses_true_division=True)
torch._jit_internal._clear_fn_overloads(qual_name)
torch._jit_internal._copy_to_script_wrapper(fn)
torch._jit_internal._create_named_tuple(t,unqual_name:str,field_names:List[str])
torch._jit_internal._disable_emit_hooks()
torch._jit_internal._disable_emit_hooks_decorator(_DecoratorContextManager)
torch._jit_internal._get_fn_overloads(qual_name)
torch._jit_internal._get_named_tuple_properties(obj)
torch._jit_internal._get_overloaded_methods(method,mod_class)
torch._jit_internal._is_exception(obj)
torch._jit_internal._overload(func)
torch._jit_internal._overload_method(func)
torch._jit_internal._qualified_name(obj)
torch._jit_internal._try_get_dispatched_fn(fn)
torch._jit_internal.boolean_dispatch(arg_name,arg_index,default,if_true,if_false,module_name,func_name)
torch._jit_internal.can_compile_class(cls)
torch._jit_internal.copy_torchscript_modifier(orig,new)
torch._jit_internal.createResolutionCallbackForClassMethods(cls)
torch._jit_internal.createResolutionCallbackFromClosure(fn)
torch._jit_internal.createResolutionCallbackFromEnv(lookup_base)
torch._jit_internal.createResolutionCallbackFromFrame(frames_up=0)
torch._jit_internal.export(fn)
torch._jit_internal.fake_range()
torch._jit_internal.get_class_name_lineno(method)
torch._jit_internal.get_closure(fn)
torch._jit_internal.get_static_fn(cls,fn)
torch._jit_internal.get_torchscript_modifier(fn)
torch._jit_internal.ignore(drop=False,**kwargs)
torch._jit_internal.is_dict(ann)
torch._jit_internal.is_final(ann)
torch._jit_internal.is_future(ann)
torch._jit_internal.is_ignored_fn(fn)
torch._jit_internal.is_list(ann)
torch._jit_internal.is_optional(ann)
torch._jit_internal.is_scripting()
torch._jit_internal.is_static_fn(cls,fn)
torch._jit_internal.is_tuple(ann)
torch._jit_internal.module_has_exports(mod)
torch._jit_internal.should_drop(fn)
torch._jit_internal.unused(fn)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_tensor_str.py----------------------------------------
A:torch._tensor_str.PRINT_OPTS->__PrinterOptions()
A:torch._tensor_str.tensor_view->tensor.reshape(-1)
A:torch._tensor_str.value_str->'{{:.{}f}}'.format(PRINT_OPTS.precision).format(value)
A:torch._tensor_str.self.max_width->max(self.max_width, len(value_str))
A:torch._tensor_str.nonzero_finite_vals->torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0))
A:torch._tensor_str.nonzero_finite_abs->torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0)).abs().double()
A:torch._tensor_str.nonzero_finite_min->torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0)).abs().double().min().double()
A:torch._tensor_str.nonzero_finite_max->torch.masked_select(tensor_view, torch.isfinite(tensor_view) & tensor_view.ne(0)).abs().double().max().double()
A:torch._tensor_str.ret->'{}'.format(value)
A:torch._tensor_str.real_str->formatter1.format(val.real)
A:torch._tensor_str.elements_per_line->max(1, int(math.floor((PRINT_OPTS.linewidth - indent) / element_length)))
A:torch._tensor_str.dim->self.float().dim()
A:torch._tensor_str.tensor_str->_tensor_str(self, indent)
A:torch._tensor_str.self->self.float().float()
A:torch._tensor_str.real_formatter->_Formatter(get_summarized_data(self.real) if summarize else self.real)
A:torch._tensor_str.imag_formatter->_Formatter(get_summarized_data(self.imag) if summarize else self.imag)
A:torch._tensor_str.formatter->_Formatter(get_summarized_data(self) if summarize else self)
A:torch._tensor_str.suffix_len->len(suffix)
A:torch._tensor_str.indent->len(prefix)
A:torch._tensor_str.indices->self.float().float()._indices().detach()
A:torch._tensor_str.indices_str->_tensor_str(indices, indent + len(indices_prefix))
A:torch._tensor_str.values->self.float().float()._values().detach()
A:torch._tensor_str.values_str->_tensor_str(values, indent + len(values_prefix))
torch._tensor_str._Formatter(self,tensor)
torch._tensor_str._Formatter.__init__(self,tensor)
torch._tensor_str._Formatter.format(self,value)
torch._tensor_str._Formatter.width(self)
torch._tensor_str.__PrinterOptions(object)
torch._tensor_str._add_suffixes(tensor_str,suffixes,indent,force_newline)
torch._tensor_str._scalar_str(self,formatter1,formatter2=None)
torch._tensor_str._str(self)
torch._tensor_str._str_intern(self)
torch._tensor_str._tensor_str(self,indent)
torch._tensor_str._tensor_str_with_formatter(self,indent,summarize,formatter1,formatter2=None)
torch._tensor_str._vector_str(self,indent,summarize,formatter1,formatter2=None)
torch._tensor_str.get_summarized_data(self)
torch._tensor_str.set_printoptions(precision=None,threshold=None,edgeitems=None,linewidth=None,profile=None,sci_mode=None)
torch.set_printoptions(precision=None,threshold=None,edgeitems=None,linewidth=None,profile=None,sci_mode=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/_utils.py----------------------------------------
A:torch.cuda._utils.device->torch.device(device)
torch.cuda._dummy_type(name:str)->type
torch.cuda._get_device_index(device:Union[Device,str,int],optional:bool=False,allow_cpu:bool=False)->int
torch.cuda._utils._dummy_type(name:str)->type
torch.cuda._utils._get_device_index(device:Union[Device,str,int],optional:bool=False,allow_cpu:bool=False)->int


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/nvtx.py----------------------------------------
A:torch.cuda.nvtx._nvtx->_NVTXStub()
torch.cuda.nvtx.mark(msg)
torch.cuda.nvtx.range_pop()
torch.cuda.nvtx.range_push(msg)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/profiler.py----------------------------------------
A:torch.cuda.profiler.rt->cudart()
torch.cuda.profiler.init(output_file,flags=None,output_mode='key_value')
torch.cuda.profiler.profile()
torch.cuda.profiler.start()
torch.cuda.profiler.stop()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/sparse.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/nccl.py----------------------------------------
A:torch.cuda.nccl.devices->set()
A:torch.cuda.nccl.device->tensor.get_device()
torch.cuda.nccl._check_sequence_type(inputs:Union[torch.Tensor,Sequence[torch.Tensor]])->None
torch.cuda.nccl.all_gather(inputs:Sequence[torch.Tensor],outputs:Sequence[torch.Tensor],streams=None,comms=None)->None
torch.cuda.nccl.all_reduce(inputs,outputs=None,op=SUM,streams=None,comms=None)
torch.cuda.nccl.broadcast(inputs:Sequence[torch.Tensor],root:int=0,streams=None,comms=None)->None
torch.cuda.nccl.init_rank(num_ranks,uid,rank)
torch.cuda.nccl.is_available(tensors)
torch.cuda.nccl.reduce(inputs:Sequence[torch.Tensor],output:Optional[Union[torch.Tensor,Sequence[torch.Tensor]]]=None,root:int=0,op:int=SUM,streams:Optional[Sequence[torch.cuda.Stream]]=None,comms=None,*,outputs:Optional[Sequence[torch.Tensor]]=None)->None
torch.cuda.nccl.reduce_scatter(inputs:Sequence[torch.Tensor],outputs:Sequence[torch.Tensor],op:int=SUM,streams=None,comms=None)->None
torch.cuda.nccl.unique_id()
torch.cuda.nccl.version()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/memory.py----------------------------------------
A:torch.cuda.memory.device->_get_device_index(device, optional=True)
A:torch.cuda.memory.stream->torch.cuda.current_stream(device)
A:torch.cuda.memory.stats->memory_stats(device=device)
A:torch.cuda.memory.handle->pynvml.nvmlDeviceGetHandleByIndex(device)
A:torch.cuda.memory.procs->pynvml.nvmlDeviceGetComputeRunningProcesses(handle)
torch.cuda._free_mutex()
torch.cuda._host_allocator()
torch.cuda.caching_allocator_alloc(size,device:Union[Device,int]=None,stream=None)
torch.cuda.caching_allocator_delete(mem_ptr)
torch.cuda.empty_cache()->None
torch.cuda.list_gpu_processes(device:Union[Device,int]=None)->str
torch.cuda.max_memory_allocated(device:Union[Device,int]=None)->int
torch.cuda.max_memory_cached(device:Union[Device,int]=None)->int
torch.cuda.max_memory_reserved(device:Union[Device,int]=None)->int
torch.cuda.memory._free_mutex()
torch.cuda.memory._host_allocator()
torch.cuda.memory.caching_allocator_alloc(size,device:Union[Device,int]=None,stream=None)
torch.cuda.memory.caching_allocator_delete(mem_ptr)
torch.cuda.memory.empty_cache()->None
torch.cuda.memory.list_gpu_processes(device:Union[Device,int]=None)->str
torch.cuda.memory.max_memory_allocated(device:Union[Device,int]=None)->int
torch.cuda.memory.max_memory_cached(device:Union[Device,int]=None)->int
torch.cuda.memory.max_memory_reserved(device:Union[Device,int]=None)->int
torch.cuda.memory.memory_allocated(device:Union[Device,int]=None)->int
torch.cuda.memory.memory_cached(device:Union[Device,int]=None)->int
torch.cuda.memory.memory_reserved(device:Union[Device,int]=None)->int
torch.cuda.memory.memory_snapshot()
torch.cuda.memory.memory_stats(device:Union[Device,int]=None)->Dict[str, Any]
torch.cuda.memory.memory_stats_as_nested_dict(device:Union[Device,int]=None)->Dict[str, Any]
torch.cuda.memory.memory_summary(device:Union[Device,int]=None,abbreviated:bool=False)->str
torch.cuda.memory.reset_accumulated_memory_stats(device:Union[Device,int]=None)->None
torch.cuda.memory.reset_max_memory_allocated(device:Union[Device,int]=None)->None
torch.cuda.memory.reset_max_memory_cached(device:Union[Device,int]=None)->None
torch.cuda.memory.reset_peak_memory_stats(device:Union[Device,int]=None)->None
torch.cuda.memory_allocated(device:Union[Device,int]=None)->int
torch.cuda.memory_cached(device:Union[Device,int]=None)->int
torch.cuda.memory_reserved(device:Union[Device,int]=None)->int
torch.cuda.memory_snapshot()
torch.cuda.memory_stats(device:Union[Device,int]=None)->Dict[str, Any]
torch.cuda.memory_stats_as_nested_dict(device:Union[Device,int]=None)->Dict[str, Any]
torch.cuda.memory_summary(device:Union[Device,int]=None,abbreviated:bool=False)->str
torch.cuda.reset_accumulated_memory_stats(device:Union[Device,int]=None)->None
torch.cuda.reset_max_memory_allocated(device:Union[Device,int]=None)->None
torch.cuda.reset_max_memory_cached(device:Union[Device,int]=None)->None
torch.cuda.reset_peak_memory_stats(device:Union[Device,int]=None)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/comm.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/streams.py----------------------------------------
A:torch.cuda.streams.torch._C.__dict__['_CudaStreamBase']->_dummy_type('_CudaStreamBase')
A:torch.cuda.streams.torch._C.__dict__['_CudaEventBase']->_dummy_type('_CudaEventBase')
A:torch.cuda.streams.event->Event()
A:torch.cuda.streams.stream->torch.cuda.current_stream()
torch.cuda.Event(cls,enable_timing=False,blocking=False,interprocess=False)
torch.cuda.Event.__repr__(self)
torch.cuda.Event._as_parameter_(self)
torch.cuda.Event.elapsed_time(self,end_event)
torch.cuda.Event.from_ipc_handle(cls,device,handle)
torch.cuda.Event.ipc_handle(self)
torch.cuda.Event.query(self)
torch.cuda.Event.record(self,stream=None)
torch.cuda.Event.synchronize(self)
torch.cuda.Event.wait(self,stream=None)
torch.cuda.Stream(cls,device=None,priority=0,**kwargs)
torch.cuda.Stream.__eq__(self,o)
torch.cuda.Stream.__hash__(self)
torch.cuda.Stream.__repr__(self)
torch.cuda.Stream._as_parameter_(self)
torch.cuda.Stream.query(self)
torch.cuda.Stream.record_event(self,event=None)
torch.cuda.Stream.synchronize(self)
torch.cuda.Stream.wait_event(self,event)
torch.cuda.Stream.wait_stream(self,stream)
torch.cuda.streams.Event(cls,enable_timing=False,blocking=False,interprocess=False)
torch.cuda.streams.Event.__new__(cls,enable_timing=False,blocking=False,interprocess=False)
torch.cuda.streams.Event.__repr__(self)
torch.cuda.streams.Event._as_parameter_(self)
torch.cuda.streams.Event.elapsed_time(self,end_event)
torch.cuda.streams.Event.from_ipc_handle(cls,device,handle)
torch.cuda.streams.Event.ipc_handle(self)
torch.cuda.streams.Event.query(self)
torch.cuda.streams.Event.record(self,stream=None)
torch.cuda.streams.Event.synchronize(self)
torch.cuda.streams.Event.wait(self,stream=None)
torch.cuda.streams.Stream(cls,device=None,priority=0,**kwargs)
torch.cuda.streams.Stream.__eq__(self,o)
torch.cuda.streams.Stream.__hash__(self)
torch.cuda.streams.Stream.__new__(cls,device=None,priority=0,**kwargs)
torch.cuda.streams.Stream.__repr__(self)
torch.cuda.streams.Stream._as_parameter_(self)
torch.cuda.streams.Stream.query(self)
torch.cuda.streams.Stream.record_event(self,event=None)
torch.cuda.streams.Stream.synchronize(self)
torch.cuda.streams.Stream.wait_event(self,event)
torch.cuda.streams.Stream.wait_stream(self,stream)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/error.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/random.py----------------------------------------
A:torch.cuda.random.device->torch.device('cuda', device)
A:torch.cuda.random.idx->current_device()
A:torch.cuda.random.new_state_copy->new_state.clone(memory_format=torch.contiguous_format)
A:torch.cuda.random.seed->int(seed)
A:torch.cuda.random.random_seed->default_generator.initial_seed()
torch.cuda.get_rng_state(device:Union[int,str,torch.device]='cuda')->Tensor
torch.cuda.get_rng_state_all()->List[Tensor]
torch.cuda.initial_seed()->int
torch.cuda.manual_seed(seed:int)->None
torch.cuda.manual_seed_all(seed:int)->None
torch.cuda.random.get_rng_state(device:Union[int,str,torch.device]='cuda')->Tensor
torch.cuda.random.get_rng_state_all()->List[Tensor]
torch.cuda.random.initial_seed()->int
torch.cuda.random.manual_seed(seed:int)->None
torch.cuda.random.manual_seed_all(seed:int)->None
torch.cuda.random.seed()->None
torch.cuda.random.seed_all()->None
torch.cuda.random.set_rng_state(new_state:Tensor,device:Union[int,str,torch.device]='cuda')->None
torch.cuda.random.set_rng_state_all(new_states:Iterable[Tensor])->None
torch.cuda.seed()->None
torch.cuda.seed_all()->None
torch.cuda.set_rng_state(new_state:Tensor,device:Union[int,str,torch.device]='cuda')->None
torch.cuda.set_rng_state_all(new_states:Iterable[Tensor])->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/__init__.py----------------------------------------
A:torch.cuda.__init__._tls->threading.local()
A:torch.cuda.__init__._initialization_lock->threading.Lock()
A:torch.cuda.__init__._is_in_bad_fork->getattr(torch._C, '_cuda_isInBadFork', lambda : False)
A:torch.cuda.__init__._CudaDeviceProperties->_dummy_type('_CudaDeviceProperties')
A:torch.cuda.__init__.CUDA_VERSION->torch._C._cuda_getCompiledVersion()
A:torch.cuda.__init__.capability->get_device_capability(d)
A:torch.cuda.__init__.name->get_device_name(d)
A:torch.cuda.__init__.arch_list->get_arch_list()
A:torch.cuda.__init__.(cap_major, cap_minor)->get_device_capability(idx)
A:torch.cuda.__init__.supported->any([sm // 10 == cap_major for sm in supported_sm])
A:torch.cuda.__init__.device_name->get_device_name(idx)
A:torch.cuda.__init__.msg->torch._C._cudart.cudaGetErrorString(_cudart.cudaError(code))
A:torch.cuda.__init__.self.idx->_get_device_index(device, optional=True)
A:torch.cuda.__init__.self.prev_idx->torch._C._cuda_getDevice()
A:torch.cuda.__init__.device->_get_device_index(device, optional=True)
A:torch.cuda.__init__.prop->get_device_properties(device)
A:torch.cuda.__init__.src_prev_stream->current_stream()
A:torch.cuda.__init__.dst_prev_stream->current_stream()
A:torch.cuda.__init__.arch_flags->torch._C._cuda_getArchFlags()
A:torch.cuda.__init__.storage_name->'Cuda{0}StorageBase'.format(t)
A:torch.cuda.__init__.tensor_name->'Cuda{0}TensorBase'.format(t)
A:torch.cuda.__init__.torch._C.__dict__[storage_name]->_dummy_type(storage_name)
A:torch.cuda.__init__.torch._C.__dict__[tensor_name]->_dummy_type(tensor_name)
A:torch.cuda.__init__.torch._C.__dict__['_CudaStreamBase']->_dummy_type('CudaStreamBase')
A:torch.cuda.__init__.torch._C.__dict__['_CudaEventBase']->_dummy_type('CudaEventBase')
torch.cuda.__init__.BFloat16Storage(_CudaBase,torch._C.CudaBFloat16StorageBase,_StorageBase)
torch.cuda.__init__.BoolStorage(_CudaBase,torch._C.CudaBoolStorageBase,_StorageBase)
torch.cuda.__init__.ByteStorage(_CudaBase,torch._C.CudaByteStorageBase,_StorageBase)
torch.cuda.__init__.CharStorage(_CudaBase,torch._C.CudaCharStorageBase,_StorageBase)
torch.cuda.__init__.ComplexDoubleStorage(_CudaBase,torch._C.CudaComplexDoubleStorageBase,_StorageBase)
torch.cuda.__init__.ComplexFloatStorage(_CudaBase,torch._C.CudaComplexFloatStorageBase,_StorageBase)
torch.cuda.__init__.CudaError(self,code:int)
torch.cuda.__init__.CudaError.__init__(self,code:int)
torch.cuda.__init__.DeferredCudaCallError(Exception)
torch.cuda.__init__.DoubleStorage(_CudaBase,torch._C.CudaDoubleStorageBase,_StorageBase)
torch.cuda.__init__.FloatStorage(_CudaBase,torch._C.CudaFloatStorageBase,_StorageBase)
torch.cuda.__init__.HalfStorage(_CudaBase,torch._C.CudaHalfStorageBase,_StorageBase)
torch.cuda.__init__.IntStorage(_CudaBase,torch._C.CudaIntStorageBase,_StorageBase)
torch.cuda.__init__.LongStorage(_CudaBase,torch._C.CudaLongStorageBase,_StorageBase)
torch.cuda.__init__.ShortStorage(_CudaBase,torch._C.CudaShortStorageBase,_StorageBase)
torch.cuda.__init__._CudaBase(object)
torch.cuda.__init__._CudaBase.type(self,*args,**kwargs)
torch.cuda.__init__._check_capability()
torch.cuda.__init__._check_cubins()
torch.cuda.__init__._lazy_call(callable)
torch.cuda.__init__._lazy_init()
torch.cuda.__init__._lazy_new(cls,*args,**kwargs)
torch.cuda.__init__._sleep(cycles)
torch.cuda.__init__.check_error(res:int)->None
torch.cuda.__init__.cudaStatus(object)
torch.cuda.__init__.cudart()
torch.cuda.__init__.current_blas_handle()
torch.cuda.__init__.current_device()->int
torch.cuda.__init__.current_stream(device:Optional[_device_t]=None)->Stream
torch.cuda.__init__.default_stream(device:Optional[_device_t]=None)->Stream
torch.cuda.__init__.device(self,device)
torch.cuda.__init__.device.__enter__(self)
torch.cuda.__init__.device.__exit__(self,*args)
torch.cuda.__init__.device.__init__(self,device)
torch.cuda.__init__.device_count()->int
torch.cuda.__init__.device_of(self,obj)
torch.cuda.__init__.device_of.__init__(self,obj)
torch.cuda.__init__.get_arch_list()->List[str]
torch.cuda.__init__.get_device_capability(device:Optional[_device_t]=None)->Tuple[int, int]
torch.cuda.__init__.get_device_name(device:Optional[_device_t]=None)->str
torch.cuda.__init__.get_device_properties(device:_device_t)->_CudaDeviceProperties
torch.cuda.__init__.get_gencode_flags()->str
torch.cuda.__init__.init()
torch.cuda.__init__.ipc_collect()
torch.cuda.__init__.is_available()->bool
torch.cuda.__init__.is_initialized()
torch.cuda.__init__.set_device(device:_device_t)->None
torch.cuda.__init__.stream(stream)
torch.cuda.__init__.synchronize(device:_device_t=None)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/amp/autocast_mode.py----------------------------------------
A:torch.cuda.amp.autocast_mode.self.prev->torch.is_autocast_enabled()
A:torch.cuda.amp.autocast_mode.iterable->map(lambda v: _cast(v, dtype), value)
A:torch.cuda.amp.autocast_mode.args[0]._fwd_used_autocast->torch.is_autocast_enabled()
A:torch.cuda.amp.autocast_mode.autocast_context->torch.is_autocast_enabled()
torch.cuda.amp.autocast(self,enabled=True)
torch.cuda.amp.autocast.__enter__(self)
torch.cuda.amp.autocast.__exit__(self,*args)
torch.cuda.amp.autocast_mode._cast(value,dtype)
torch.cuda.amp.autocast_mode.autocast(self,enabled=True)
torch.cuda.amp.autocast_mode.autocast.__enter__(self)
torch.cuda.amp.autocast_mode.autocast.__exit__(self,*args)
torch.cuda.amp.autocast_mode.autocast.__init__(self,enabled=True)
torch.cuda.amp.autocast_mode.custom_bwd(bwd)
torch.cuda.amp.autocast_mode.custom_fwd(fwd=None,**kwargs)
torch.cuda.amp.custom_bwd(bwd)
torch.cuda.amp.custom_fwd(fwd=None,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/amp/grad_scaler.py----------------------------------------
A:torch.cuda.amp.grad_scaler.retval->optimizer.step(*args, **kwargs)
A:torch.cuda.amp.grad_scaler.self._per_optimizer_states->defaultdict(_refresh_per_optimizer_state)
A:torch.cuda.amp.grad_scaler.self._scale->torch._amp_update_scale(_growth_tracker, _scale, found_inf_combined, self._growth_factor, self._backoff_factor, self._growth_interval)
A:torch.cuda.amp.grad_scaler.self._growth_tracker->torch.full((1,), self._init_growth_tracker, dtype=torch.int32, device=dev)
A:torch.cuda.amp.grad_scaler.iterable->map(apply_scale, val)
A:torch.cuda.amp.grad_scaler.per_device_inv_scale->_MultiDeviceReplicator(inv_scale)
A:torch.cuda.amp.grad_scaler.per_device_found_inf->_MultiDeviceReplicator(found_inf)
A:torch.cuda.amp.grad_scaler.param.grad->param.grad.coalesce()
A:torch.cuda.amp.grad_scaler.to_unscale->param.grad._values()
A:torch.cuda.amp.grad_scaler.inv_scale->self._scale.double().reciprocal().float()
A:torch.cuda.amp.grad_scaler.found_inf->torch.full((1,), 0.0, dtype=torch.float32, device=_scale.device)
A:torch.cuda.amp.grad_scaler.optimizer_state['found_inf_per_device']->self._unscale_grads_(optimizer, inv_scale, found_inf, False)
A:torch.cuda.amp.grad_scaler.(_scale, _growth_tracker)->self._check_scale_growth_tracker('update')
A:torch.cuda.amp.grad_scaler.state->self.__dict__.copy()
A:torch.cuda.amp.grad_scaler.state['_init_scale']->self.get_scale()
A:torch.cuda.amp.grad_scaler.state['_init_growth_tracker']->self._get_growth_tracker()
A:torch.cuda.amp.grad_scaler.(_scale, _)->self._check_scale_growth_tracker('_check_inf_per_device')
A:torch.cuda.amp.grad_scaler.dummy_inv_scale->torch.full((1,), 1.0, dtype=torch.float32, device=_scale.device)
A:torch.cuda.amp.grad_scaler.self._per_optimizer_states[id(optimizer)]['found_inf_per_device']->self._unscale_grads_(optimizer, dummy_inv_scale, found_inf, True)
torch.cuda.amp.GradScaler(self,init_scale=2.0**16,growth_factor=2.0,backoff_factor=0.5,growth_interval=2000,enabled=True)
torch.cuda.amp.GradScaler.__getstate__(self)
torch.cuda.amp.GradScaler.__setstate__(self,state)
torch.cuda.amp.GradScaler._check_inf_per_device(self,optimizer)
torch.cuda.amp.GradScaler._check_scale_growth_tracker(self,funcname)->Tuple[torch.Tensor, torch.Tensor]
torch.cuda.amp.GradScaler._found_inf_per_device(self,optimizer)
torch.cuda.amp.GradScaler._get_growth_tracker(self)
torch.cuda.amp.GradScaler._get_scale_async(self)
torch.cuda.amp.GradScaler._lazy_init_scale_growth_tracker(self,dev)
torch.cuda.amp.GradScaler._unscale_grads_(self,optimizer,inv_scale,found_inf,allow_fp16)
torch.cuda.amp.GradScaler.get_backoff_factor(self)
torch.cuda.amp.GradScaler.get_growth_factor(self)
torch.cuda.amp.GradScaler.get_growth_interval(self)
torch.cuda.amp.GradScaler.get_scale(self)
torch.cuda.amp.GradScaler.is_enabled(self)
torch.cuda.amp.GradScaler.load_state_dict(self,state_dict)
torch.cuda.amp.GradScaler.scale(self,outputs)
torch.cuda.amp.GradScaler.set_backoff_factor(self,new_factor)
torch.cuda.amp.GradScaler.set_growth_factor(self,new_factor)
torch.cuda.amp.GradScaler.set_growth_interval(self,new_interval)
torch.cuda.amp.GradScaler.state_dict(self)
torch.cuda.amp.GradScaler.step(self,optimizer,*args,**kwargs)
torch.cuda.amp.GradScaler.unscale_(self,optimizer)
torch.cuda.amp.GradScaler.update(self,new_scale=None)
torch.cuda.amp.grad_scaler.GradScaler(self,init_scale=2.0**16,growth_factor=2.0,backoff_factor=0.5,growth_interval=2000,enabled=True)
torch.cuda.amp.grad_scaler.GradScaler.__getstate__(self)
torch.cuda.amp.grad_scaler.GradScaler.__init__(self,init_scale=2.0**16,growth_factor=2.0,backoff_factor=0.5,growth_interval=2000,enabled=True)
torch.cuda.amp.grad_scaler.GradScaler.__setstate__(self,state)
torch.cuda.amp.grad_scaler.GradScaler._check_inf_per_device(self,optimizer)
torch.cuda.amp.grad_scaler.GradScaler._check_scale_growth_tracker(self,funcname)->Tuple[torch.Tensor, torch.Tensor]
torch.cuda.amp.grad_scaler.GradScaler._found_inf_per_device(self,optimizer)
torch.cuda.amp.grad_scaler.GradScaler._get_growth_tracker(self)
torch.cuda.amp.grad_scaler.GradScaler._get_scale_async(self)
torch.cuda.amp.grad_scaler.GradScaler._lazy_init_scale_growth_tracker(self,dev)
torch.cuda.amp.grad_scaler.GradScaler._unscale_grads_(self,optimizer,inv_scale,found_inf,allow_fp16)
torch.cuda.amp.grad_scaler.GradScaler.get_backoff_factor(self)
torch.cuda.amp.grad_scaler.GradScaler.get_growth_factor(self)
torch.cuda.amp.grad_scaler.GradScaler.get_growth_interval(self)
torch.cuda.amp.grad_scaler.GradScaler.get_scale(self)
torch.cuda.amp.grad_scaler.GradScaler.is_enabled(self)
torch.cuda.amp.grad_scaler.GradScaler.load_state_dict(self,state_dict)
torch.cuda.amp.grad_scaler.GradScaler.scale(self,outputs)
torch.cuda.amp.grad_scaler.GradScaler.set_backoff_factor(self,new_factor)
torch.cuda.amp.grad_scaler.GradScaler.set_growth_factor(self,new_factor)
torch.cuda.amp.grad_scaler.GradScaler.set_growth_interval(self,new_interval)
torch.cuda.amp.grad_scaler.GradScaler.state_dict(self)
torch.cuda.amp.grad_scaler.GradScaler.step(self,optimizer,*args,**kwargs)
torch.cuda.amp.grad_scaler.GradScaler.unscale_(self,optimizer)
torch.cuda.amp.grad_scaler.GradScaler.update(self,new_scale=None)
torch.cuda.amp.grad_scaler.OptState(Enum)
torch.cuda.amp.grad_scaler._MultiDeviceReplicator(self,master_tensor:torch.Tensor)
torch.cuda.amp.grad_scaler._MultiDeviceReplicator.__init__(self,master_tensor:torch.Tensor)
torch.cuda.amp.grad_scaler._MultiDeviceReplicator.get(self,device)->torch.Tensor
torch.cuda.amp.grad_scaler._refresh_per_optimizer_state()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/cuda/amp/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/bundled_inputs.py----------------------------------------
A:torch.utils.bundled_inputs.T->TypeVar('T')
A:torch.utils.bundled_inputs.(deflated, inflater)->_inflate_expr(arg, f'deflated[{inp_idx}][{arg_idx}]')
A:torch.utils.bundled_inputs.expr->'\n'.join(parts)
A:torch.utils.bundled_inputs.definition->textwrap.dedent('\n            def _generate_bundled_inputs(self):\n                deflated = self._bundled_inputs_deflated\n                return [\n            {}\n                ]\n            ').format(expr)
A:torch.utils.bundled_inputs.stub->torch.zeros(1, dtype=dtype).expand(*size)
torch.utils.bundled_inputs.InflatableArg(NamedTuple)
torch.utils.bundled_inputs._inflate_expr(arg:T,ref:str)->Tuple[Union[T, torch.Tensor], str]
torch.utils.bundled_inputs.augment_model_with_bundled_inputs(model:torch.jit.ScriptModule,inputs:Optional[List[Tuple[Any,...]]]=None,_receive_inflate_expr:Optional[List[str]]=None)->None
torch.utils.bundled_inputs.bundle_large_tensor(t)
torch.utils.bundled_inputs.bundle_randn(*size,dtype=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/collect_env.py----------------------------------------
A:torch.utils.collect_env.SystemEnv->namedtuple('SystemEnv', ['torch_version', 'is_debug_build', 'cuda_compiled_version', 'gcc_version', 'clang_version', 'cmake_version', 'os', 'python_version', 'is_cuda_available', 'cuda_runtime_version', 'nvidia_driver_version', 'nvidia_gpu_models', 'cudnn_version', 'pip_version', 'pip_packages', 'conda_packages', 'hip_compiled_version', 'hip_runtime_version', 'miopen_runtime_version'])
A:torch.utils.collect_env.p->subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True)
A:torch.utils.collect_env.(raw_output, raw_err)->subprocess.Popen(command, stdout=subprocess.PIPE, stderr=subprocess.PIPE, shell=True).communicate()
A:torch.utils.collect_env.enc->locale.getpreferredencoding()
A:torch.utils.collect_env.output->get_pretty_env_info()
A:torch.utils.collect_env.err->raw_err.decode(enc)
A:torch.utils.collect_env.(rc, out, _)->run_lambda(cudnn_cmd)
A:torch.utils.collect_env.match->re.search(regex, out)
A:torch.utils.collect_env.system_root->os.environ.get('SystemRoot', 'C:\\Windows')
A:torch.utils.collect_env.findstr_cmd->os.path.join(system_root, 'System32', 'findstr')
A:torch.utils.collect_env.grep_cmd->'{} /R "numpy torch"'.format(findstr_cmd)
A:torch.utils.collect_env.conda->os.environ.get('CONDA_EXE', 'conda')
A:torch.utils.collect_env.out->run_and_read_all(run_lambda, conda + ' list | ' + grep_cmd)
A:torch.utils.collect_env.comment_regex->re.compile('^#.*\\n')
A:torch.utils.collect_env.smi->get_nvidia_smi()
A:torch.utils.collect_env.uuid_regex->re.compile(' \\(UUID: .+?\\)')
A:torch.utils.collect_env.cuda_path->os.environ.get('CUDA_PATH', '%CUDA_PATH%')
A:torch.utils.collect_env.where_cmd->os.path.join(system_root, 'System32', 'where')
A:torch.utils.collect_env.cudnn_cmd->'{} /R "{}\\bin" cudnn*.dll'.format(where_cmd, cuda_path)
A:torch.utils.collect_env.l->os.environ.get('CUDNN_LIBRARY')
A:torch.utils.collect_env.files_set->set()
A:torch.utils.collect_env.fn->os.path.realpath(fn)
A:torch.utils.collect_env.files->list(sorted(files_set))
A:torch.utils.collect_env.result->'\n'.join(files)
A:torch.utils.collect_env.wmic_cmd->os.path.join(system_root, 'System32', 'Wbem', 'wmic')
A:torch.utils.collect_env.platform->get_platform()
A:torch.utils.collect_env.version->get_mac_version(run_lambda)
A:torch.utils.collect_env.desc->check_release_file(run_lambda)
A:torch.utils.collect_env.out2->run_with_pip('pip')
A:torch.utils.collect_env.out3->run_with_pip('pip3')
A:torch.utils.collect_env.num_pips->len([x for x in [out2, out3] if x is not None])
A:torch.utils.collect_env.(pip_version, pip_list_output)->get_pip_packages(run_lambda)
A:torch.utils.collect_env.debug_mode_str->str(torch.version.debug)
A:torch.utils.collect_env.cuda_available_str->str(torch.cuda.is_available())
A:torch.utils.collect_env.gpu_info->dict(is_cuda_available=cuda_available_str, cuda_compiled_version='N/A', hip_compiled_version=torch.version.hip, hip_runtime_version=hip_runtime_version, miopen_runtime_version=miopen_runtime_version, cuda_runtime_version='N/A', nvidia_gpu_models=get_gpu_info(run_lambda), nvidia_driver_version=get_nvidia_driver_version(run_lambda), cudnn_version='N/A')
A:torch.utils.collect_env.cfg->torch._C._show_config().split('\n')
A:torch.utils.collect_env.env_info_fmt->'\nPyTorch version: {torch_version}\nIs debug build: {is_debug_build}\nCUDA used to build PyTorch: {cuda_compiled_version}\nROCM used to build PyTorch: {hip_compiled_version}\n\nOS: {os}\nGCC version: {gcc_version}\nClang version: {clang_version}\nCMake version: {cmake_version}\n\nPython version: {python_version}\nIs CUDA available: {is_cuda_available}\nCUDA runtime version: {cuda_runtime_version}\nGPU models and configuration: {nvidia_gpu_models}\nNvidia driver version: {nvidia_driver_version}\ncuDNN version: {cudnn_version}\nHIP runtime version: {hip_runtime_version}\nMIOpen runtime version: {miopen_runtime_version}\n\nVersions of relevant libraries:\n{pip_packages}\n{conda_packages}\n'.strip()
A:torch.utils.collect_env.lines->text.split('\n')
A:torch.utils.collect_env.mutable_dict->replace_nones(mutable_dict)
A:torch.utils.collect_env.mutable_dict['nvidia_gpu_models']->maybe_start_on_next_line(envinfo.nvidia_gpu_models)
A:torch.utils.collect_env.all_dynamic_cuda_fields_missing->all((mutable_dict[field] is None for field in dynamic_cuda_fields))
A:torch.utils.collect_env.mutable_dict['pip_packages']->prepend(mutable_dict['pip_packages'], '[{}] '.format(envinfo.pip_version))
A:torch.utils.collect_env.mutable_dict['conda_packages']->prepend(mutable_dict['conda_packages'], '[conda] ')
torch.utils.collect_env.check_release_file(run_lambda)
torch.utils.collect_env.get_clang_version(run_lambda)
torch.utils.collect_env.get_cmake_version(run_lambda)
torch.utils.collect_env.get_conda_packages(run_lambda)
torch.utils.collect_env.get_cudnn_version(run_lambda)
torch.utils.collect_env.get_env_info()
torch.utils.collect_env.get_gcc_version(run_lambda)
torch.utils.collect_env.get_gpu_info(run_lambda)
torch.utils.collect_env.get_lsb_version(run_lambda)
torch.utils.collect_env.get_mac_version(run_lambda)
torch.utils.collect_env.get_nvidia_driver_version(run_lambda)
torch.utils.collect_env.get_nvidia_smi()
torch.utils.collect_env.get_os(run_lambda)
torch.utils.collect_env.get_pip_packages(run_lambda)
torch.utils.collect_env.get_platform()
torch.utils.collect_env.get_pretty_env_info()
torch.utils.collect_env.get_running_cuda_version(run_lambda)
torch.utils.collect_env.get_windows_version(run_lambda)
torch.utils.collect_env.main()
torch.utils.collect_env.pretty_str(envinfo)
torch.utils.collect_env.run(command)
torch.utils.collect_env.run_and_parse_first_match(run_lambda,command,regex)
torch.utils.collect_env.run_and_read_all(run_lambda,command)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/cpp_extension.py----------------------------------------
A:torch.utils.cpp_extension.nvcc->_join_cuda_home('bin', 'nvcc')
A:torch.utils.cpp_extension.cuda_home->os.path.dirname(os.path.dirname(nvcc))
A:torch.utils.cpp_extension.cuda_homes->glob.glob('C:/Program Files/NVIDIA GPU Computing Toolkit/CUDA/v*.*')
A:torch.utils.cpp_extension.hipcc->subprocess.check_output(['which', 'hipcc'], stderr=subprocess.DEVNULL).decode().rstrip('\r\n')
A:torch.utils.cpp_extension.rocm_home->os.path.dirname(rocm_home)
A:torch.utils.cpp_extension.ROCM_HOME->_find_rocm_home()
A:torch.utils.cpp_extension.ROCM_VERSION->tuple((int(v) for v in torch.version.hip.split('.')[:2]))
A:torch.utils.cpp_extension.CUDA_HOME->_find_cuda_home()
A:torch.utils.cpp_extension.BUILT_FROM_SOURCE_VERSION_PATTERN->re.compile('\\d+\\.\\d+\\.\\d+\\w+\\+\\w+')
A:torch.utils.cpp_extension.JIT_EXTENSION_VERSIONER->ExtensionVersioner()
A:torch.utils.cpp_extension.which->subprocess.check_output(['which', compiler], stderr=subprocess.STDOUT)
A:torch.utils.cpp_extension.compiler_path->os.path.realpath(results[0].strip())
A:torch.utils.cpp_extension.version_string->subprocess.check_output([compiler, '-v'], stderr=subprocess.STDOUT).decode()
A:torch.utils.cpp_extension.pattern->re.compile('^COLLECT_GCC=(.*)$', re.MULTILINE)
A:torch.utils.cpp_extension.results->re.findall(pattern, version_string)
A:torch.utils.cpp_extension.versionstr->subprocess.check_output([compiler, '-dumpfullversion', '-dumpversion'])
A:torch.utils.cpp_extension.version->ExtensionVersioner().bump_version_if_changed(name, sources, build_arguments=[extra_cflags, extra_cuda_cflags, extra_ldflags, extra_include_paths], build_directory=build_directory, with_cuda=with_cuda)
A:torch.utils.cpp_extension.compiler_info->subprocess.check_output(compiler, stderr=subprocess.STDOUT)
A:torch.utils.cpp_extension.match->re.search('(\\d+)\\.(\\d+)\\.(\\d+)', compiler_info.decode().strip())
A:torch.utils.cpp_extension.(_, error, _)->sys.exc_info()
A:torch.utils.cpp_extension.compiler->os.environ.get('CXX', 'c++')
A:torch.utils.cpp_extension.self.no_python_abi_suffix->kwargs.get('no_python_abi_suffix', False)
A:torch.utils.cpp_extension.self.use_ninja->kwargs.get('use_ninja', True)
A:torch.utils.cpp_extension.cpp_flag_prefix->cpp_format_prefix.format('std')
A:torch.utils.cpp_extension._ccbin->os.getenv('CC')
A:torch.utils.cpp_extension.paths[i]->os.path.abspath(paths[i])
A:torch.utils.cpp_extension.cflags->sanitize_flags(cflags)
A:torch.utils.cpp_extension.output_dir->os.path.abspath(output_dir)
A:torch.utils.cpp_extension.(_, objects, extra_postargs, pp_opts, _)->self.compiler._setup_compile(output_dir, macros, include_dirs, sources, depends, extra_postargs)
A:torch.utils.cpp_extension.common_cflags->self.compiler._get_cc_args(pp_opts, debug, extra_preargs)
A:torch.utils.cpp_extension.with_cuda->any(map(_is_cuda_file, sources))
A:torch.utils.cpp_extension.post_cflags->sanitize_flags(post_cflags)
A:torch.utils.cpp_extension.cuda_post_cflags->sanitize_flags(cuda_post_cflags)
A:torch.utils.cpp_extension.self.cflags->copy.deepcopy(extra_postargs)
A:torch.utils.cpp_extension.src_regex->re.compile('/T(p|c)(.*)')
A:torch.utils.cpp_extension.obj_regex->re.compile('/Fo(.*)')
A:torch.utils.cpp_extension.include_regex->re.compile('((\\-|\\/)I.*)')
A:torch.utils.cpp_extension.cuda_cflags->sanitize_flags(cuda_cflags)
A:torch.utils.cpp_extension.ext_filename->'.'.join(without_abi)
A:torch.utils.cpp_extension.ext_filename_parts->'.'.join(without_abi).split('.')
A:torch.utils.cpp_extension.extension.extra_compile_args->copy.deepcopy(extension.extra_compile_args)
A:torch.utils.cpp_extension.names->extension.name.split('.')
A:torch.utils.cpp_extension.define->'-DTORCH_EXTENSION_NAME={}'.format(name)
A:torch.utils.cpp_extension.include_dirs->kwargs.get('include_dirs', [])
A:torch.utils.cpp_extension.library_dirs->kwargs.get('library_dirs', [])
A:torch.utils.cpp_extension.libraries->kwargs.get('libraries', [])
A:torch.utils.cpp_extension.here->os.path.abspath(__file__)
A:torch.utils.cpp_extension.torch_path->os.path.dirname(os.path.dirname(here))
A:torch.utils.cpp_extension.lib_include->os.path.join(torch_path, 'include')
A:torch.utils.cpp_extension.cuda_home_include->_join_cuda_home('include')
A:torch.utils.cpp_extension.lib_path->os.path.join(torch_path, 'lib')
A:torch.utils.cpp_extension.functions->dict(((f, f) for f in functions))
A:torch.utils.cpp_extension.cpp_source_path->os.path.join(build_directory, 'main.cpp')
A:torch.utils.cpp_extension.cuda_source_path->os.path.join(build_directory, 'cuda.cu')
A:torch.utils.cpp_extension.with_cudnn->any(['cudnn' in f for f in extra_ldflags or []])
A:torch.utils.cpp_extension.old_version->ExtensionVersioner().get_version(name)
A:torch.utils.cpp_extension.name->'{}_v{}'.format(name, version)
A:torch.utils.cpp_extension.baton->FileBaton(os.path.join(build_directory, 'lock'))
A:torch.utils.cpp_extension.build_file_path->os.path.join(build_directory, 'build.ninja')
A:torch.utils.cpp_extension.extra_ldflags->_prepare_ldflags(extra_ldflags or [], with_cuda, verbose)
A:torch.utils.cpp_extension.python_path->os.path.dirname(sys.executable)
A:torch.utils.cpp_extension.python_lib_path->os.path.join(python_path, 'libs')
A:torch.utils.cpp_extension.named_arches->collections.OrderedDict([('Kepler+Tesla', '3.7'), ('Kepler', '3.5+PTX'), ('Maxwell+Tegra', '5.3'), ('Maxwell', '5.0;5.2+PTX'), ('Pascal', '6.0;6.1+PTX'), ('Volta', '7.0+PTX'), ('Turing', '7.5+PTX'), ('Ampere', '8.0;8.6+PTX')])
A:torch.utils.cpp_extension._arch_list->_arch_list.replace(named_arch, archval).replace(named_arch, archval)
A:torch.utils.cpp_extension.capability->torch.cuda.get_device_capability()
A:torch.utils.cpp_extension.arch_list->_arch_list.replace(named_arch, archval).replace(named_arch, archval).split(';')
A:torch.utils.cpp_extension.root_extensions_directory->get_default_build_root()
A:torch.utils.cpp_extension.build_directory->os.path.join(root_extensions_directory, name)
A:torch.utils.cpp_extension.max_jobs->os.environ.get('MAX_JOBS')
A:torch.utils.cpp_extension.num_workers->_get_num_workers(verbose)
A:torch.utils.cpp_extension.env->os.environ.copy()
A:torch.utils.cpp_extension.plat_name->get_platform()
A:torch.utils.cpp_extension.vc_env->_get_vc_env(plat_spec)
A:torch.utils.cpp_extension.uk->k.upper()
A:torch.utils.cpp_extension.(file, path, description)->imp.find_module(module_name, [path])
A:torch.utils.cpp_extension.system_includes->include_paths(with_cuda)
A:torch.utils.cpp_extension.cuda_flags->_nt_quote_args(cuda_flags)
A:torch.utils.cpp_extension.target->'{}.o'.format(file_name)
A:torch.utils.cpp_extension.objects->list(map(object_file_path, sources))
A:torch.utils.cpp_extension.ldflags->sanitize_flags(ldflags)
A:torch.utils.cpp_extension.library_target->'{}.{}'.format(name, ext)
A:torch.utils.cpp_extension.source_file->source_file.replace(' ', '$ ').replace(' ', '$ ')
A:torch.utils.cpp_extension.object_file->object_file.replace(' ', '$ ').replace(' ', '$ ')
A:torch.utils.cpp_extension.cl_paths->subprocess.check_output(['where', 'cl']).decode().split('\r\n')
A:torch.utils.cpp_extension.cl_path->os.path.dirname(cl_paths[0]).replace(':', '$:')
A:torch.utils.cpp_extension.lines->'\n'.join(block)
torch.utils.cpp_extension.BuildExtension(self,*args,**kwargs)
torch.utils.cpp_extension.BuildExtension.__init__(self,*args,**kwargs)
torch.utils.cpp_extension.BuildExtension._add_compile_flag(self,extension,flag)
torch.utils.cpp_extension.BuildExtension._add_gnu_cpp_abi_flag(self,extension)
torch.utils.cpp_extension.BuildExtension._check_abi(self)
torch.utils.cpp_extension.BuildExtension._define_torch_extension_name(self,extension)
torch.utils.cpp_extension.BuildExtension.build_extensions(self)->None
torch.utils.cpp_extension.BuildExtension.finalize_options(self)->None
torch.utils.cpp_extension.BuildExtension.get_ext_filename(self,ext_name)
torch.utils.cpp_extension.BuildExtension.with_options(cls,**options)
torch.utils.cpp_extension.CUDAExtension(name,sources,*args,**kwargs)
torch.utils.cpp_extension.CppExtension(name,sources,*args,**kwargs)
torch.utils.cpp_extension._accepted_compilers_for_platform()->List[str]
torch.utils.cpp_extension._find_cuda_home()->Optional[str]
torch.utils.cpp_extension._find_rocm_home()->Optional[str]
torch.utils.cpp_extension._get_build_directory(name:str,verbose:bool)->str
torch.utils.cpp_extension._get_cuda_arch_flags(cflags:Optional[List[str]]=None)->List[str]
torch.utils.cpp_extension._get_num_workers(verbose:bool)->Optional[int]
torch.utils.cpp_extension._get_rocm_arch_flags(cflags:Optional[List[str]]=None)->List[str]
torch.utils.cpp_extension._import_module_from_library(module_name,path,is_python_module)
torch.utils.cpp_extension._is_binary_build()->bool
torch.utils.cpp_extension._is_cuda_file(path:str)->bool
torch.utils.cpp_extension._jit_compile(name,sources,extra_cflags,extra_cuda_cflags,extra_ldflags,extra_include_paths,build_directory:str,verbose:bool,with_cuda:Optional[bool],is_python_module,keep_intermediates=True)->None
torch.utils.cpp_extension._join_cuda_home(*paths)->str
torch.utils.cpp_extension._join_rocm_home(*paths)->str
torch.utils.cpp_extension._prepare_ldflags(extra_ldflags,with_cuda,verbose)
torch.utils.cpp_extension._run_ninja_build(build_directory:str,verbose:bool,error_prefix:str)->None
torch.utils.cpp_extension._write_ninja_file(path,cflags,post_cflags,cuda_cflags,cuda_post_cflags,sources,objects,ldflags,library_target,with_cuda)->None
torch.utils.cpp_extension._write_ninja_file_and_build_library(name,sources:List[str],extra_cflags,extra_cuda_cflags,extra_ldflags,extra_include_paths,build_directory:str,verbose:bool,with_cuda:Optional[bool])->None
torch.utils.cpp_extension._write_ninja_file_and_compile_objects(sources:List[str],objects,cflags,post_cflags,cuda_cflags,cuda_post_cflags,build_directory:str,verbose:bool,with_cuda:Optional[bool])->None
torch.utils.cpp_extension._write_ninja_file_to_build_library(path,name,sources,extra_cflags,extra_cuda_cflags,extra_ldflags,extra_include_paths,with_cuda)->None
torch.utils.cpp_extension.check_compiler_abi_compatibility(compiler)->bool
torch.utils.cpp_extension.check_compiler_ok_for_platform(compiler:str)->bool
torch.utils.cpp_extension.get_default_build_root()->str
torch.utils.cpp_extension.include_paths(cuda:bool=False)->List[str]
torch.utils.cpp_extension.is_ninja_available()
torch.utils.cpp_extension.library_paths(cuda:bool=False)->List[str]
torch.utils.cpp_extension.load(name,sources:List[str],extra_cflags=None,extra_cuda_cflags=None,extra_ldflags=None,extra_include_paths=None,build_directory=None,verbose=False,with_cuda:Optional[bool]=None,is_python_module=True,keep_intermediates=True)
torch.utils.cpp_extension.load_inline(name,cpp_sources,cuda_sources=None,functions=None,extra_cflags=None,extra_cuda_cflags=None,extra_ldflags=None,extra_include_paths=None,build_directory=None,verbose=False,with_cuda=None,is_python_module=True,with_pytorch_error_handling=True,keep_intermediates=True)
torch.utils.cpp_extension.verify_ninja_availability()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/hooks.py----------------------------------------
A:torch.utils.hooks.self.hooks_dict_ref->weakref.ref(state[0])
A:torch.utils.hooks.hooks_dict->self.hooks_dict_ref()
A:torch.utils.hooks.RemovableHandle.next_id->max(RemovableHandle.next_id, self.id + 1)
torch.utils.hooks.RemovableHandle(self,hooks_dict:Any)
torch.utils.hooks.RemovableHandle.__enter__(self)->'RemovableHandle'
torch.utils.hooks.RemovableHandle.__exit__(self,type:Any,value:Any,tb:Any)->None
torch.utils.hooks.RemovableHandle.__getstate__(self)
torch.utils.hooks.RemovableHandle.__init__(self,hooks_dict:Any)
torch.utils.hooks.RemovableHandle.__setstate__(self,state)->None
torch.utils.hooks.RemovableHandle.remove(self)->None
torch.utils.hooks.unserializable_hook(f)
torch.utils.hooks.warn_if_has_hooks(tensor)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/checkpoint.py----------------------------------------
A:torch.utils.checkpoint.x->inp.detach()
A:torch.utils.checkpoint.fwd_gpu_devices->list(set((arg.get_device() for arg in args if isinstance(arg, torch.Tensor) and arg.is_cuda)))
A:torch.utils.checkpoint.ctx.fwd_cpu_state->torch.get_rng_state()
A:torch.utils.checkpoint.(ctx.fwd_gpu_devices, ctx.fwd_gpu_states)->get_device_states(*args)
A:torch.utils.checkpoint.outputs->ctx.run_function(*detached_inputs)
A:torch.utils.checkpoint.detached_inputs->detach_variable(inputs)
A:torch.utils.checkpoint.grads->tuple((inp.grad if isinstance(inp, torch.Tensor) else inp for inp in detached_inputs))
A:torch.utils.checkpoint.preserve->kwargs.pop('preserve_rng_state', True)
A:torch.utils.checkpoint.input->checkpoint(run_function(start, end, functions), input, preserve_rng_state=preserve)
A:torch.utils.checkpoint.functions->list(functions.children())
torch.utils.checkpoint.CheckpointFunction(torch.autograd.Function)
torch.utils.checkpoint.CheckpointFunction.backward(ctx,*args)
torch.utils.checkpoint.CheckpointFunction.forward(ctx,run_function,preserve_rng_state,*args)
torch.utils.checkpoint.check_backward_validity(inputs:Iterable[Any])->None
torch.utils.checkpoint.checkpoint(function,*args,**kwargs)
torch.utils.checkpoint.checkpoint_sequential(functions,segments,input,**kwargs)
torch.utils.checkpoint.detach_variable(inputs:Tuple[Any,...])->Tuple[torch.Tensor, ...]
torch.utils.checkpoint.get_device_states(*args)->Tuple[List[int], List[torch.Tensor]]
torch.utils.checkpoint.set_device_states(devices,states)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/throughput_benchmark.py----------------------------------------
A:torch.utils.throughput_benchmark.self._benchmark->torch._C.ThroughputBenchmark(module)
A:torch.utils.throughput_benchmark.config->torch._C.BenchmarkConfig()
A:torch.utils.throughput_benchmark.c_stats->self._benchmark.benchmark(config)
torch.utils.ThroughputBenchmark(self,module)
torch.utils.ThroughputBenchmark.add_input(self,*args,**kwargs)
torch.utils.ThroughputBenchmark.benchmark(self,num_calling_threads=1,num_warmup_iters=10,num_iters=100,profiler_output_path='')
torch.utils.ThroughputBenchmark.run_once(self,*args,**kwargs)
torch.utils.throughput_benchmark.ExecutionStats(self,c_stats,benchmark_config)
torch.utils.throughput_benchmark.ExecutionStats.__init__(self,c_stats,benchmark_config)
torch.utils.throughput_benchmark.ExecutionStats.__str__(self)
torch.utils.throughput_benchmark.ExecutionStats.iters_per_second(self)
torch.utils.throughput_benchmark.ExecutionStats.latency_avg_ms(self)
torch.utils.throughput_benchmark.ExecutionStats.num_iters(self)
torch.utils.throughput_benchmark.ExecutionStats.total_time_seconds(self)
torch.utils.throughput_benchmark.ThroughputBenchmark(self,module)
torch.utils.throughput_benchmark.ThroughputBenchmark.__init__(self,module)
torch.utils.throughput_benchmark.ThroughputBenchmark.add_input(self,*args,**kwargs)
torch.utils.throughput_benchmark.ThroughputBenchmark.benchmark(self,num_calling_threads=1,num_warmup_iters=10,num_iters=100,profiler_output_path='')
torch.utils.throughput_benchmark.ThroughputBenchmark.run_once(self,*args,**kwargs)
torch.utils.throughput_benchmark.format_time(time_us=None,time_ms=None,time_s=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/show_pickle.py----------------------------------------
A:torch.utils.show_pickle.value->cls(in_stream).load()
A:torch.utils.show_pickle.(zfname, mname)->fname.split('@', 1)
torch.utils.show_pickle.DumpUnpickler(pickle._Unpickler)
torch.utils.show_pickle.DumpUnpickler.dump(cls,in_stream,out_stream)
torch.utils.show_pickle.DumpUnpickler.find_class(self,module,name)
torch.utils.show_pickle.DumpUnpickler.persistent_load(self,pid)
torch.utils.show_pickle.FakeClass(self,module,name)
torch.utils.show_pickle.FakeClass.__init__(self,module,name)
torch.utils.show_pickle.FakeClass.__repr__(self)
torch.utils.show_pickle.FakeClass.fake_new(self,*args)
torch.utils.show_pickle.FakeObject(self,module,name,args)
torch.utils.show_pickle.FakeObject.__init__(self,module,name,args)
torch.utils.show_pickle.FakeObject.__repr__(self)
torch.utils.show_pickle.FakeObject.__setstate__(self,state)
torch.utils.show_pickle.FakeObject.pp_format(printer,obj,stream,indent,allowance,context,level)
torch.utils.show_pickle.main(argv,output_stream=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/file_baton.py----------------------------------------
A:torch.utils.file_baton.self.fd->os.open(self.lock_file_path, os.O_CREAT | os.O_EXCL)
torch.utils.file_baton.FileBaton(self,lock_file_path,wait_seconds=0.1)
torch.utils.file_baton.FileBaton.__init__(self,lock_file_path,wait_seconds=0.1)
torch.utils.file_baton.FileBaton.release(self)
torch.utils.file_baton.FileBaton.try_acquire(self)
torch.utils.file_baton.FileBaton.wait(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/dlpack.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/_cpp_extension_versioner.py----------------------------------------
A:torch.utils._cpp_extension_versioner.Entry->collections.namedtuple('Entry', 'version, hash')
A:torch.utils._cpp_extension_versioner.hash_value->update_hash(hash_value, with_cuda)
A:torch.utils._cpp_extension_versioner.entry->self.entries.get(name)
A:torch.utils._cpp_extension_versioner.self.entries[name]entry->Entry(entry.version + 1, hash_value)
torch.utils._cpp_extension_versioner.ExtensionVersioner(self)
torch.utils._cpp_extension_versioner.ExtensionVersioner.__init__(self)
torch.utils._cpp_extension_versioner.ExtensionVersioner.bump_version_if_changed(self,name,source_files,build_arguments,build_directory,with_cuda)
torch.utils._cpp_extension_versioner.ExtensionVersioner.get_version(self,name)
torch.utils._cpp_extension_versioner.hash_build_arguments(hash_value,build_arguments)
torch.utils._cpp_extension_versioner.hash_source_files(hash_value,source_files)
torch.utils._cpp_extension_versioner.update_hash(seed,value)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/__init__.py----------------------------------------
A:torch.utils.__init__.cmake_prefix_path->os.path.join(_osp.dirname(_osp.dirname(__file__)), 'share', 'cmake')
torch.utils.__init__.set_module(obj,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/model_zoo.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/mkldnn.py----------------------------------------
A:torch.utils.mkldnn.self.weight->state[0].to_mkldnn()
A:torch.utils.mkldnn.self.bias->state[1].to_mkldnn()
A:torch.utils.mkldnn.y_mkldnn->torch._C._nn.mkldnn_linear(x_mkldnn, self.weight, self.bias)
A:torch.utils.mkldnn.weight->self.weight.to_dense()
A:torch.utils.mkldnn.bias->self.bias.to_dense()
A:torch.utils.mkldnn.running_mean->self.running_mean.to_dense()
A:torch.utils.mkldnn.running_var->self.running_var.to_dense()
A:torch.utils.mkldnn.self.running_mean->state[2].to_mkldnn()
A:torch.utils.mkldnn.self.running_var->state[3].to_mkldnn()
A:torch.utils.mkldnn.new_m->m_fn(m)
torch.utils.mkldnn.MkldnnBatchNorm(self,dense_module)
torch.utils.mkldnn.MkldnnBatchNorm.__getstate__(self)
torch.utils.mkldnn.MkldnnBatchNorm.__init__(self,dense_module)
torch.utils.mkldnn.MkldnnBatchNorm.__setstate__(self,state)
torch.utils.mkldnn.MkldnnBatchNorm.forward(self,x)
torch.utils.mkldnn.MkldnnConv1d(self,dense_module)
torch.utils.mkldnn.MkldnnConv1d.__init__(self,dense_module)
torch.utils.mkldnn.MkldnnConv1d.__setstate__(self,state)
torch.utils.mkldnn.MkldnnConv2d(self,dense_module)
torch.utils.mkldnn.MkldnnConv2d.__init__(self,dense_module)
torch.utils.mkldnn.MkldnnConv2d.__setstate__(self,state)
torch.utils.mkldnn.MkldnnConv3d(self,dense_module)
torch.utils.mkldnn.MkldnnConv3d.__init__(self,dense_module)
torch.utils.mkldnn.MkldnnConv3d.__setstate__(self,state)
torch.utils.mkldnn.MkldnnLinear(self,dense_module)
torch.utils.mkldnn.MkldnnLinear.__getstate__(self)
torch.utils.mkldnn.MkldnnLinear.__init__(self,dense_module)
torch.utils.mkldnn.MkldnnLinear.__setstate__(self,state)
torch.utils.mkldnn.MkldnnLinear.forward(self,x)
torch.utils.mkldnn._MkldnnConvNd(self,dense_module)
torch.utils.mkldnn._MkldnnConvNd.__getstate__(self)
torch.utils.mkldnn._MkldnnConvNd.__init__(self,dense_module)
torch.utils.mkldnn._MkldnnConvNd.forward(self,x)
torch.utils.mkldnn.to_mkldnn(module)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/mobile_optimizer.py----------------------------------------
A:torch.utils.mobile_optimizer.optimization_blocklist->set()
A:torch.utils.mobile_optimizer.optimized_cpp_module->torch._C._jit_pass_vulkan_optimize_for_mobile(script_module._c, preserved_methods)
A:torch.utils.mobile_optimizer.op_names->torch.jit.export_opnames(script_module)
torch.utils.mobile_optimizer.LintCode(Enum)
torch.utils.mobile_optimizer.generate_mobile_module_lints(script_module:torch.jit.ScriptModule)
torch.utils.mobile_optimizer.optimize_for_mobile(script_module,optimization_blocklist:Set[MobileOptimizerType]=None,preserved_methods:List[AnyStr]=None,backend:str='CPU')


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/hipify/cuda_to_hip_mappings.py----------------------------------------
A:torch.utils.hipify.cuda_to_hip_mappings.MATH_TRANSPILATIONS->collections.OrderedDict([('std::max', '::max'), ('std::min', '::min'), ('std::ceil', '::ceil'), ('std::floor', '::floor'), ('std::exp', '::exp'), ('std::log', '::log'), ('std::pow', '::pow'), ('std::fabs', '::fabs'), ('std::fmod', '::fmod'), ('std::remainder', '::remainder')])
A:torch.utils.hipify.cuda_to_hip_mappings.CUDA_TYPE_NAME_MAP->collections.OrderedDict([('CUresult', ('hipError_t', CONV_TYPE, API_DRIVER)), ('cudaError_t', ('hipError_t', CONV_TYPE, API_RUNTIME)), ('CUDA_ARRAY3D_DESCRIPTOR', ('HIP_ARRAY3D_DESCRIPTOR', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY_DESCRIPTOR', ('HIP_ARRAY_DESCRIPTOR', CONV_TYPE, API_DRIVER)), ('CUDA_MEMCPY2D', ('hip_Memcpy2D', CONV_TYPE, API_DRIVER)), ('CUDA_MEMCPY3D', ('HIP_MEMCPY3D', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_MEMCPY3D_PEER', ('HIP_MEMCPY3D_PEER', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_POINTER_ATTRIBUTE_P2P_TOKENS', ('HIP_POINTER_ATTRIBUTE_P2P_TOKENS', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_RESOURCE_DESC', ('HIP_RESOURCE_DESC', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_RESOURCE_VIEW_DESC', ('HIP_RESOURCE_VIEW_DESC', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUipcEventHandle', ('hipIpcEventHandle', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUipcMemHandle', ('hipIpcMemHandle', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUaddress_mode', ('hipAddress_mode', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUarray_cubemap_face', ('hipArray_cubemap_face', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUarray_format', ('hipArray_format', CONV_TYPE, API_DRIVER)), ('CUcomputemode', ('hipComputemode', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUmem_advise', ('hipMemAdvise', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUmem_range_attribute', ('hipMemRangeAttribute', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUctx_flags', ('hipCctx_flags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUdevice', ('hipDevice_t', CONV_TYPE, API_DRIVER)), ('CUdevice_attribute_enum', ('hipDeviceAttribute_t', CONV_TYPE, API_DRIVER)), ('CUdevice_attribute', ('hipDeviceAttribute_t', CONV_TYPE, API_DRIVER)), ('CUdeviceptr', ('hipDeviceptr_t', CONV_TYPE, API_DRIVER)), ('CUarray_st', ('hipArray', CONV_TYPE, API_DRIVER)), ('CUarray', ('hipArray *', CONV_TYPE, API_DRIVER)), ('CUdevprop_st', ('hipDeviceProp_t', CONV_TYPE, API_DRIVER)), ('CUdevprop', ('hipDeviceProp_t', CONV_TYPE, API_DRIVER)), ('CUfunction', ('hipFunction_t', CONV_TYPE, API_DRIVER)), ('CUgraphicsResource', ('hipGraphicsResource_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUmipmappedArray', ('hipMipmappedArray_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUfunction_attribute', ('hipFuncAttribute_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUfunction_attribute_enum', ('hipFuncAttribute_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUgraphicsMapResourceFlags', ('hipGraphicsMapFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUgraphicsMapResourceFlags_enum', ('hipGraphicsMapFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUgraphicsRegisterFlags', ('hipGraphicsRegisterFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUgraphicsRegisterFlags_enum', ('hipGraphicsRegisterFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUoccupancy_flags', ('hipOccupancyFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUoccupancy_flags_enum', ('hipOccupancyFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUfunc_cache_enum', ('hipFuncCache', CONV_TYPE, API_DRIVER)), ('CUfunc_cache', ('hipFuncCache', CONV_TYPE, API_DRIVER)), ('CUipcMem_flags', ('hipIpcMemFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUipcMem_flags_enum', ('hipIpcMemFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUjit_cacheMode', ('hipJitCacheMode', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjit_cacheMode_enum', ('hipJitCacheMode', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjit_fallback', ('hipJitFallback', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjit_fallback_enum', ('hipJitFallback', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjit_option', ('hipJitOption', CONV_JIT, API_DRIVER)), ('CUjit_option_enum', ('hipJitOption', CONV_JIT, API_DRIVER)), ('CUjit_target', ('hipJitTarget', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjit_target_enum', ('hipJitTarget', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjitInputType', ('hipJitInputType', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUjitInputType_enum', ('hipJitInputType', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CUlimit', ('hipLimit_t', CONV_TYPE, API_DRIVER)), ('CUlimit_enum', ('hipLimit_t', CONV_TYPE, API_DRIVER)), ('CUmemAttach_flags', ('hipMemAttachFlags_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUmemAttach_flags_enum', ('hipMemAttachFlags_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUmemorytype', ('hipMemType_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUmemorytype_enum', ('hipMemType_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUresourcetype', ('hipResourceType', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('CUresourcetype_enum', ('hipResourceType', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('CUresourceViewFormat', ('hipResourceViewFormat', CONV_TEX, API_DRIVER)), ('CUresourceViewFormat_enum', ('hipResourceViewFormat', CONV_TEX, API_DRIVER)), ('CUsharedconfig', ('hipSharedMemConfig', CONV_TYPE, API_DRIVER)), ('CUsharedconfig_enum', ('hipSharedMemConfig', CONV_TYPE, API_DRIVER)), ('CUcontext', ('hipCtx_t', CONV_TYPE, API_DRIVER)), ('CUmodule', ('hipModule_t', CONV_TYPE, API_DRIVER)), ('CUstream', ('hipStream_t', CONV_TYPE, API_DRIVER)), ('CUstream_st', ('ihipStream_t', CONV_TYPE, API_DRIVER)), ('CUstreamCallback', ('hipStreamCallback_t', CONV_TYPE, API_DRIVER)), ('CUsurfObject', ('hipSurfaceObject', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUsurfref', ('hipSurfaceReference_t', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUtexObject', ('hipTextureObject_t', CONV_TYPE, API_DRIVER)), ('CUtexref', ('textureReference', CONV_TYPE, API_DRIVER)), ('CUstream_flags', ('hipStreamFlags', CONV_TYPE, API_DRIVER)), ('CUstreamWaitValue_flags', ('hipStreamWaitValueFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUstreamWriteValue_flags', ('hipStreamWriteValueFlags', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUstreamBatchMemOpType', ('hipStreamBatchMemOpType', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUdevice_P2PAttribute', ('hipDeviceP2PAttribute', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUevent', ('hipEvent_t', CONV_TYPE, API_DRIVER)), ('CUevent_st', ('ihipEvent_t', CONV_TYPE, API_DRIVER)), ('CUevent_flags', ('hipEventFlags', CONV_EVENT, API_DRIVER, HIP_UNSUPPORTED)), ('CUfilter_mode', ('hipTextureFilterMode', CONV_TEX, API_DRIVER)), ('CUGLDeviceList', ('hipGLDeviceList', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CUGLmap_flags', ('hipGLMapFlags', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d9DeviceList', ('hipD3D9DeviceList', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d9map_flags', ('hipD3D9MapFlags', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d9register_flags', ('hipD3D9RegisterFlags', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d10DeviceList', ('hipd3d10DeviceList', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d10map_flags', ('hipD3D10MapFlags', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d10register_flags', ('hipD3D10RegisterFlags', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CUd3d11DeviceList', ('hipd3d11DeviceList', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('CUeglStreamConnection_st', ('hipEglStreamConnection', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('CUeglStreamConnection', ('hipEglStreamConnection', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('libraryPropertyType_t', ('hipLibraryPropertyType_t', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('libraryPropertyType', ('hipLibraryPropertyType_t', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaStreamCallback_t', ('hipStreamCallback_t', CONV_TYPE, API_RUNTIME)), ('cudaArray', ('hipArray', CONV_MEM, API_RUNTIME)), ('cudaArray_t', ('hipArray_t', CONV_MEM, API_RUNTIME)), ('cudaArray_const_t', ('hipArray_const_t', CONV_MEM, API_RUNTIME)), ('cudaMipmappedArray_t', ('hipMipmappedArray_t', CONV_MEM, API_RUNTIME)), ('cudaMipmappedArray_const_t', ('hipMipmappedArray_const_t', CONV_MEM, API_RUNTIME)), ('cudaArrayDefault', ('hipArrayDefault', CONV_MEM, API_RUNTIME)), ('cudaArrayLayered', ('hipArrayLayered', CONV_MEM, API_RUNTIME)), ('cudaArraySurfaceLoadStore', ('hipArraySurfaceLoadStore', CONV_MEM, API_RUNTIME)), ('cudaArrayCubemap', ('hipArrayCubemap', CONV_MEM, API_RUNTIME)), ('cudaArrayTextureGather', ('hipArrayTextureGather', CONV_MEM, API_RUNTIME)), ('cudaMemoryAdvise', ('hipMemAdvise', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeAttribute', ('hipMemRangeAttribute', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpyKind', ('hipMemcpyKind', CONV_MEM, API_RUNTIME)), ('cudaMemoryType', ('hipMemoryType', CONV_MEM, API_RUNTIME)), ('cudaExtent', ('hipExtent', CONV_MEM, API_RUNTIME)), ('cudaPitchedPtr', ('hipPitchedPtr', CONV_MEM, API_RUNTIME)), ('cudaPos', ('hipPos', CONV_MEM, API_RUNTIME)), ('cudaEvent_t', ('hipEvent_t', CONV_TYPE, API_RUNTIME)), ('cudaStream_t', ('hipStream_t', CONV_TYPE, API_RUNTIME)), ('cudaPointerAttributes', ('hipPointerAttribute_t', CONV_TYPE, API_RUNTIME)), ('cudaDeviceAttr', ('hipDeviceAttribute_t', CONV_TYPE, API_RUNTIME)), ('cudaDeviceProp', ('hipDeviceProp_t', CONV_TYPE, API_RUNTIME)), ('cudaDeviceP2PAttr', ('hipDeviceP2PAttribute', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaComputeMode', ('hipComputeMode', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaFuncCache', ('hipFuncCache_t', CONV_CACHE, API_RUNTIME)), ('cudaFuncAttributes', ('hipFuncAttributes', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSharedMemConfig', ('hipSharedMemConfig', CONV_TYPE, API_RUNTIME)), ('cudaLimit', ('hipLimit_t', CONV_TYPE, API_RUNTIME)), ('cudaOutputMode', ('hipOutputMode', CONV_OTHER, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaTextureReadMode', ('hipTextureReadMode', CONV_TEX, API_RUNTIME)), ('cudaTextureFilterMode', ('hipTextureFilterMode', CONV_TEX, API_RUNTIME)), ('cudaChannelFormatKind', ('hipChannelFormatKind', CONV_TEX, API_RUNTIME)), ('cudaChannelFormatDesc', ('hipChannelFormatDesc', CONV_TEX, API_RUNTIME)), ('cudaResourceDesc', ('hipResourceDesc', CONV_TEX, API_RUNTIME)), ('cudaResourceViewDesc', ('hipResourceViewDesc', CONV_TEX, API_RUNTIME)), ('cudaTextureDesc', ('hipTextureDesc', CONV_TEX, API_RUNTIME)), ('surfaceReference', ('hipSurfaceReference', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaTextureObject_t', ('hipTextureObject_t', CONV_TEX, API_RUNTIME)), ('cudaResourceType', ('hipResourceType', CONV_TEX, API_RUNTIME)), ('cudaResourceViewFormat', ('hipResourceViewFormat', CONV_TEX, API_RUNTIME)), ('cudaTextureAddressMode', ('hipTextureAddressMode', CONV_TEX, API_RUNTIME)), ('cudaSurfaceBoundaryMode', ('hipSurfaceBoundaryMode', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSurfaceFormatMode', ('hipSurfaceFormatMode', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaTextureType1D', ('hipTextureType1D', CONV_TEX, API_RUNTIME)), ('cudaTextureType2D', ('hipTextureType2D', CONV_TEX, API_RUNTIME)), ('cudaTextureType3D', ('hipTextureType3D', CONV_TEX, API_RUNTIME)), ('cudaTextureTypeCubemap', ('hipTextureTypeCubemap', CONV_TEX, API_RUNTIME)), ('cudaTextureType1DLayered', ('hipTextureType1DLayered', CONV_TEX, API_RUNTIME)), ('cudaTextureType2DLayered', ('hipTextureType2DLayered', CONV_TEX, API_RUNTIME)), ('cudaTextureTypeCubemapLayered', ('hipTextureTypeCubemapLayered', CONV_TEX, API_RUNTIME)), ('cudaIpcEventHandle_t', ('hipIpcEventHandle_t', CONV_TYPE, API_RUNTIME)), ('cudaIpcEventHandle_st', ('hipIpcEventHandle_t', CONV_TYPE, API_RUNTIME)), ('cudaIpcMemHandle_t', ('hipIpcMemHandle_t', CONV_TYPE, API_RUNTIME)), ('cudaIpcMemHandle_st', ('hipIpcMemHandle_t', CONV_TYPE, API_RUNTIME)), ('cudaGraphicsCubeFace', ('hipGraphicsCubeFace', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsMapFlags', ('hipGraphicsMapFlags', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsRegisterFlags', ('hipGraphicsRegisterFlags', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLDeviceList', ('hipGLDeviceList', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLMapFlags', ('hipGLMapFlags', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9DeviceList', ('hipD3D9DeviceList', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9MapFlags', ('hipD3D9MapFlags', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9RegisterFlags', ('hipD3D9RegisterFlags', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10DeviceList', ('hipd3d10DeviceList', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10MapFlags', ('hipD3D10MapFlags', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10RegisterFlags', ('hipD3D10RegisterFlags', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11DeviceList', ('hipd3d11DeviceList', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEglStreamConnection', ('hipEglStreamConnection', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cublasHandle_t', ('rocblas_handle', CONV_TYPE, API_BLAS)), ('cublasOperation_t', ('rocblas_operation', CONV_TYPE, API_BLAS)), ('cublasStatus_t', ('rocblas_status', CONV_TYPE, API_BLAS)), ('cublasFillMode_t', ('rocblas_fill', CONV_TYPE, API_BLAS)), ('cublasDiagType_t', ('rocblas_diagonal', CONV_TYPE, API_BLAS)), ('cublasSideMode_t', ('rocblas_side', CONV_TYPE, API_BLAS)), ('cublasPointerMode_t', ('rocblas_pointer_mode', CONV_TYPE, API_BLAS)), ('cublasAtomicsMode_t', ('rocblas_atomics_mode', CONV_TYPE, API_BLAS, HIP_UNSUPPORTED)), ('cublasDataType_t', ('rocblas_data_type', CONV_TYPE, API_BLAS, HIP_UNSUPPORTED)), ('curandStatus', ('hiprandStatus_t', CONV_TYPE, API_RAND)), ('curandStatus_t', ('hiprandStatus_t', CONV_TYPE, API_RAND)), ('curandRngType', ('hiprandRngType_t', CONV_TYPE, API_RAND)), ('curandRngType_t', ('hiprandRngType_t', CONV_TYPE, API_RAND)), ('curandGenerator_st', ('hiprandGenerator_st', CONV_TYPE, API_RAND)), ('curandGenerator_t', ('hiprandGenerator_t', CONV_TYPE, API_RAND)), ('curandDirectionVectorSet', ('hiprandDirectionVectorSet_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDirectionVectorSet_t', ('hiprandDirectionVectorSet_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandOrdering', ('hiprandOrdering_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandOrdering_t', ('hiprandOrdering_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDistribution_st', ('hiprandDistribution_st', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandHistogramM2V_st', ('hiprandDistribution_st', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDistribution_t', ('hiprandDistribution_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandHistogramM2V_t', ('hiprandDistribution_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDistributionShift_st', ('hiprandDistributionShift_st', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDistributionShift_t', ('hiprandDistributionShift_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDistributionM2Shift_st', ('hiprandDistributionM2Shift_st', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDistributionM2Shift_t', ('hiprandDistributionM2Shift_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandHistogramM2_st', ('hiprandHistogramM2_st', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandHistogramM2_t', ('hiprandHistogramM2_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandHistogramM2K_st', ('hiprandHistogramM2K_st', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandHistogramM2K_t', ('hiprandHistogramM2K_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDiscreteDistribution_st', ('hiprandDiscreteDistribution_st', CONV_TYPE, API_RAND)), ('curandDiscreteDistribution_t', ('hiprandDiscreteDistribution_t', CONV_TYPE, API_RAND)), ('curandMethod', ('hiprandMethod_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandMethod_t', ('hiprandMethod_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandDirectionVectors32_t', ('hiprandDirectionVectors32_t', CONV_TYPE, API_RAND)), ('curandDirectionVectors64_t', ('hiprandDirectionVectors64_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandStateMtgp32_t', ('hiprandStateMtgp32_t', CONV_TYPE, API_RAND)), ('curandStateMtgp32', ('hiprandStateMtgp32_t', CONV_TYPE, API_RAND)), ('curandStateScrambledSobol64_t', ('hiprandStateScrambledSobol64_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandStateSobol64_t', ('hiprandStateSobol64_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandStateScrambledSobol32_t', ('hiprandStateScrambledSobol32_t', CONV_TYPE, API_RAND, HIP_UNSUPPORTED)), ('curandStateSobol32_t', ('hiprandStateSobol32_t', CONV_TYPE, API_RAND)), ('curandStateMRG32k3a_t', ('hiprandStateMRG32k3a_t', CONV_TYPE, API_RAND)), ('curandStatePhilox4_32_10_t', ('hiprandStatePhilox4_32_10_t', CONV_TYPE, API_RAND)), ('curandStateXORWOW_t', ('hiprandStateXORWOW_t', CONV_TYPE, API_RAND)), ('curandState_t', ('hiprandState_t', CONV_TYPE, API_RAND)), ('curandState', ('hiprandState_t', CONV_TYPE, API_RAND))])
A:torch.utils.hipify.cuda_to_hip_mappings.CUDA_INCLUDE_MAP->collections.OrderedDict([('include <cuda.h', ('include <hip/hip_runtime.h', CONV_INCLUDE_CUDA_MAIN_H, API_DRIVER)), ('include "cuda.h', ('include "hip/hip_runtime.h', CONV_INCLUDE_CUDA_MAIN_H, API_DRIVER)), ('cuda_runtime.h', ('hip/hip_runtime.h', CONV_INCLUDE_CUDA_MAIN_H, API_RUNTIME)), ('cuda_runtime_api.h', ('hip/hip_runtime_api.h', CONV_INCLUDE, API_RUNTIME)), ('channel_descriptor.h', ('hip/channel_descriptor.h', CONV_INCLUDE, API_RUNTIME)), ('device_functions.h', ('hip/device_functions.h', CONV_INCLUDE, API_RUNTIME)), ('driver_types.h', ('hip/driver_types.h', CONV_INCLUDE, API_RUNTIME)), ('cuComplex.h', ('hip/hip_complex.h', CONV_INCLUDE, API_RUNTIME)), ('cuda_fp16.h', ('hip/hip_fp16.h', CONV_INCLUDE, API_RUNTIME)), ('cuda_texture_types.h', ('hip/hip_texture_types.h', CONV_INCLUDE, API_RUNTIME)), ('vector_types.h', ('hip/hip_vector_types.h', CONV_INCLUDE, API_RUNTIME)), ('cublas.h', ('rocblas.h', CONV_INCLUDE_CUDA_MAIN_H, API_BLAS)), ('cublas_v2.h', ('rocblas.h', CONV_INCLUDE_CUDA_MAIN_H, API_BLAS)), ('curand.h', ('hiprand.h', CONV_INCLUDE_CUDA_MAIN_H, API_RAND)), ('curand_kernel.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_discrete.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_discrete2.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_globals.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_lognormal.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_mrg32k3a.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_mtgp32.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_mtgp32_host.h', ('hiprand_mtgp32_host.h', CONV_INCLUDE, API_RAND)), ('curand_mtgp32_kernel.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_mtgp32dc_p_11213.h', ('rocrand_mtgp32_11213.h', CONV_INCLUDE, API_RAND)), ('curand_normal.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_normal_static.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_philox4x32_x.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_poisson.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_precalc.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('curand_uniform.h', ('hiprand_kernel.h', CONV_INCLUDE, API_RAND)), ('cusparse.h', ('hipsparse.h', CONV_INCLUDE, API_RAND)), ('cufft.h', ('hipfft.h', CONV_INCLUDE, API_BLAS)), ('cufftXt.h', ('hipfft.h', CONV_INCLUDE, API_BLAS)), ('<nccl.h>', ('<rccl.h>', CONV_INCLUDE, API_RUNTIME)), ('nvrtc.h', ('hip/hiprtc.h', CONV_INCLUDE, API_RTC)), ('thrust/system/cuda', ('thrust/system/hip', CONV_INCLUDE, API_BLAS)), ('cub/util_allocator.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('cub/block/block_reduce.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('cub/cub.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('cub/block/block_load.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('cub/device/device_radix_sort.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('cub/device/device_reduce.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('cub/device/device_scan.cuh', ('hipcub/hipcub.hpp', CONV_INCLUDE, API_BLAS)), ('nvToolsExt.h', ('roctx.h', CONV_INCLUDE, API_ROCTX))])
A:torch.utils.hipify.cuda_to_hip_mappings.CUDA_IDENTIFIER_MAP->collections.OrderedDict([('__CUDACC__', ('__HIPCC__', CONV_DEF, API_RUNTIME)), ('CUDA_ERROR_INVALID_CONTEXT', ('hipErrorInvalidContext', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_CONTEXT_ALREADY_CURRENT', ('hipErrorContextAlreadyCurrent', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_ARRAY_IS_MAPPED', ('hipErrorArrayIsMapped', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_ALREADY_MAPPED', ('hipErrorAlreadyMapped', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_ALREADY_ACQUIRED', ('hipErrorAlreadyAcquired', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_NOT_MAPPED', ('hipErrorNotMapped', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_NOT_MAPPED_AS_ARRAY', ('hipErrorNotMappedAsArray', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_NOT_MAPPED_AS_POINTER', ('hipErrorNotMappedAsPointer', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_CONTEXT_ALREADY_IN_USE', ('hipErrorContextAlreadyInUse', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_INVALID_SOURCE', ('hipErrorInvalidSource', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_FILE_NOT_FOUND', ('hipErrorFileNotFound', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_NOT_FOUND', ('hipErrorNotFound', CONV_TYPE, API_DRIVER)), ('CUDA_ERROR_LAUNCH_INCOMPATIBLE_TEXTURING', ('hipErrorLaunchIncompatibleTexturing', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ERROR_PRIMARY_CONTEXT_ACTIVE', ('hipErrorPrimaryContextActive', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ERROR_CONTEXT_IS_DESTROYED', ('hipErrorContextIsDestroyed', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ERROR_NOT_PERMITTED', ('hipErrorNotPermitted', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ERROR_NOT_SUPPORTED', ('hipErrorNotSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorMissingConfiguration', ('hipErrorMissingConfiguration', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorPriorLaunchFailure', ('hipErrorPriorLaunchFailure', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidDeviceFunction', ('hipErrorInvalidDeviceFunction', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidConfiguration', ('hipErrorInvalidConfiguration', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidPitchValue', ('hipErrorInvalidPitchValue', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidSymbol', ('hipErrorInvalidSymbol', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidHostPointer', ('hipErrorInvalidHostPointer', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidDevicePointer', ('hipErrorInvalidDevicePointer', CONV_TYPE, API_RUNTIME)), ('cudaErrorInvalidTexture', ('hipErrorInvalidTexture', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidTextureBinding', ('hipErrorInvalidTextureBinding', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidChannelDescriptor', ('hipErrorInvalidChannelDescriptor', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidMemcpyDirection', ('hipErrorInvalidMemcpyDirection', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorAddressOfConstant', ('hipErrorAddressOfConstant', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorTextureFetchFailed', ('hipErrorTextureFetchFailed', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorTextureNotBound', ('hipErrorTextureNotBound', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorSynchronizationError', ('hipErrorSynchronizationError', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidFilterSetting', ('hipErrorInvalidFilterSetting', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidNormSetting', ('hipErrorInvalidNormSetting', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorMixedDeviceExecution', ('hipErrorMixedDeviceExecution', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorNotYetImplemented', ('hipErrorNotYetImplemented', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorMemoryValueTooLarge', ('hipErrorMemoryValueTooLarge', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInsufficientDriver', ('hipErrorInsufficientDriver', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorSetOnActiveProcess', ('hipErrorSetOnActiveProcess', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorInvalidSurface', ('hipErrorInvalidSurface', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorDuplicateVariableName', ('hipErrorDuplicateVariableName', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorDuplicateTextureName', ('hipErrorDuplicateTextureName', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorDuplicateSurfaceName', ('hipErrorDuplicateSurfaceName', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorDevicesUnavailable', ('hipErrorDevicesUnavailable', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorIncompatibleDriverContext', ('hipErrorIncompatibleDriverContext', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorDeviceAlreadyInUse', ('hipErrorDeviceAlreadyInUse', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorLaunchMaxDepthExceeded', ('hipErrorLaunchMaxDepthExceeded', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorLaunchFileScopedTex', ('hipErrorLaunchFileScopedTex', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorLaunchFileScopedSurf', ('hipErrorLaunchFileScopedSurf', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorSyncDepthExceeded', ('hipErrorSyncDepthExceeded', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorLaunchPendingCountExceeded', ('hipErrorLaunchPendingCountExceeded', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorNotPermitted', ('hipErrorNotPermitted', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorNotSupported', ('hipErrorNotSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorStartupFailure', ('hipErrorStartupFailure', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaErrorApiFailureBase', ('hipErrorApiFailureBase', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_SUCCESS', ('hipSuccess', CONV_TYPE, API_DRIVER)), ('cudaSuccess', ('hipSuccess', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_INVALID_VALUE', ('hipErrorInvalidValue', CONV_TYPE, API_DRIVER)), ('cudaErrorInvalidValue', ('hipErrorInvalidValue', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_OUT_OF_MEMORY', ('hipErrorMemoryAllocation', CONV_TYPE, API_DRIVER)), ('cudaErrorMemoryAllocation', ('hipErrorMemoryAllocation', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_NOT_INITIALIZED', ('hipErrorNotInitialized', CONV_TYPE, API_DRIVER)), ('cudaErrorInitializationError', ('hipErrorInitializationError', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_DEINITIALIZED', ('hipErrorDeinitialized', CONV_TYPE, API_DRIVER)), ('cudaErrorCudartUnloading', ('hipErrorDeinitialized', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_PROFILER_DISABLED', ('hipErrorProfilerDisabled', CONV_TYPE, API_DRIVER)), ('cudaErrorProfilerDisabled', ('hipErrorProfilerDisabled', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_PROFILER_NOT_INITIALIZED', ('hipErrorProfilerNotInitialized', CONV_TYPE, API_DRIVER)), ('cudaErrorProfilerNotInitialized', ('hipErrorProfilerNotInitialized', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_PROFILER_ALREADY_STARTED', ('hipErrorProfilerAlreadyStarted', CONV_TYPE, API_DRIVER)), ('cudaErrorProfilerAlreadyStarted', ('hipErrorProfilerAlreadyStarted', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_PROFILER_ALREADY_STOPPED', ('hipErrorProfilerAlreadyStopped', CONV_TYPE, API_DRIVER)), ('cudaErrorProfilerAlreadyStopped', ('hipErrorProfilerAlreadyStopped', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_NO_DEVICE', ('hipErrorNoDevice', CONV_TYPE, API_DRIVER)), ('cudaErrorNoDevice', ('hipErrorNoDevice', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_INVALID_DEVICE', ('hipErrorInvalidDevice', CONV_TYPE, API_DRIVER)), ('cudaErrorInvalidDevice', ('hipErrorInvalidDevice', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_INVALID_IMAGE', ('hipErrorInvalidImage', CONV_TYPE, API_DRIVER)), ('cudaErrorInvalidKernelImage', ('hipErrorInvalidImage', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_MAP_FAILED', ('hipErrorMapFailed', CONV_TYPE, API_DRIVER)), ('cudaErrorMapBufferObjectFailed', ('hipErrorMapFailed', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_UNMAP_FAILED', ('hipErrorUnmapFailed', CONV_TYPE, API_DRIVER)), ('cudaErrorUnmapBufferObjectFailed', ('hipErrorUnmapFailed', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_NO_BINARY_FOR_GPU', ('hipErrorNoBinaryForGpu', CONV_TYPE, API_DRIVER)), ('cudaErrorNoKernelImageForDevice', ('hipErrorNoBinaryForGpu', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_ECC_UNCORRECTABLE', ('hipErrorECCNotCorrectable', CONV_TYPE, API_DRIVER)), ('cudaErrorECCUncorrectable', ('hipErrorECCNotCorrectable', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_UNSUPPORTED_LIMIT', ('hipErrorUnsupportedLimit', CONV_TYPE, API_DRIVER)), ('cudaErrorUnsupportedLimit', ('hipErrorUnsupportedLimit', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_PEER_ACCESS_UNSUPPORTED', ('hipErrorPeerAccessUnsupported', CONV_TYPE, API_DRIVER)), ('cudaErrorPeerAccessUnsupported', ('hipErrorPeerAccessUnsupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_INVALID_PTX', ('hipErrorInvalidKernelFile', CONV_TYPE, API_DRIVER)), ('cudaErrorInvalidPtx', ('hipErrorInvalidKernelFile', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_INVALID_GRAPHICS_CONTEXT', ('hipErrorInvalidGraphicsContext', CONV_TYPE, API_DRIVER)), ('cudaErrorInvalidGraphicsContext', ('hipErrorInvalidGraphicsContext', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_NVLINK_UNCORRECTABLE', ('hipErrorNvlinkUncorrectable', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorNvlinkUncorrectable', ('hipErrorNvlinkUncorrectable', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_SHARED_OBJECT_SYMBOL_NOT_FOUND', ('hipErrorSharedObjectSymbolNotFound', CONV_TYPE, API_DRIVER)), ('cudaErrorSharedObjectSymbolNotFound', ('hipErrorSharedObjectSymbolNotFound', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_SHARED_OBJECT_INIT_FAILED', ('hipErrorSharedObjectInitFailed', CONV_TYPE, API_DRIVER)), ('cudaErrorSharedObjectInitFailed', ('hipErrorSharedObjectInitFailed', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_OPERATING_SYSTEM', ('hipErrorOperatingSystem', CONV_TYPE, API_DRIVER)), ('cudaErrorOperatingSystem', ('hipErrorOperatingSystem', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_INVALID_HANDLE', ('hipErrorInvalidResourceHandle', CONV_TYPE, API_DRIVER)), ('cudaErrorInvalidResourceHandle', ('hipErrorInvalidResourceHandle', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_NOT_READY', ('hipErrorNotReady', CONV_TYPE, API_DRIVER)), ('cudaErrorNotReady', ('hipErrorNotReady', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_ILLEGAL_ADDRESS', ('hipErrorIllegalAddress', CONV_TYPE, API_DRIVER)), ('cudaErrorIllegalAddress', ('hipErrorIllegalAddress', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_LAUNCH_OUT_OF_RESOURCES', ('hipErrorLaunchOutOfResources', CONV_TYPE, API_DRIVER)), ('cudaErrorLaunchOutOfResources', ('hipErrorLaunchOutOfResources', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_LAUNCH_TIMEOUT', ('hipErrorLaunchTimeOut', CONV_TYPE, API_DRIVER)), ('cudaErrorLaunchTimeout', ('hipErrorLaunchTimeOut', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_PEER_ACCESS_ALREADY_ENABLED', ('hipErrorPeerAccessAlreadyEnabled', CONV_TYPE, API_DRIVER)), ('cudaErrorPeerAccessAlreadyEnabled', ('hipErrorPeerAccessAlreadyEnabled', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_PEER_ACCESS_NOT_ENABLED', ('hipErrorPeerAccessNotEnabled', CONV_TYPE, API_DRIVER)), ('cudaErrorPeerAccessNotEnabled', ('hipErrorPeerAccessNotEnabled', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_ASSERT', ('hipErrorAssert', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorAssert', ('hipErrorAssert', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_TOO_MANY_PEERS', ('hipErrorTooManyPeers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorTooManyPeers', ('hipErrorTooManyPeers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_HOST_MEMORY_ALREADY_REGISTERED', ('hipErrorHostMemoryAlreadyRegistered', CONV_TYPE, API_DRIVER)), ('cudaErrorHostMemoryAlreadyRegistered', ('hipErrorHostMemoryAlreadyRegistered', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_HOST_MEMORY_NOT_REGISTERED', ('hipErrorHostMemoryNotRegistered', CONV_TYPE, API_DRIVER)), ('cudaErrorHostMemoryNotRegistered', ('hipErrorHostMemoryNotRegistered', CONV_TYPE, API_RUNTIME)), ('CUDA_ERROR_HARDWARE_STACK_ERROR', ('hipErrorHardwareStackError', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorHardwareStackError', ('hipErrorHardwareStackError', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_ILLEGAL_INSTRUCTION', ('hipErrorIllegalInstruction', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorIllegalInstruction', ('hipErrorIllegalInstruction', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_MISALIGNED_ADDRESS', ('hipErrorMisalignedAddress', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorMisalignedAddress', ('hipErrorMisalignedAddress', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_INVALID_ADDRESS_SPACE', ('hipErrorInvalidAddressSpace', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorInvalidAddressSpace', ('hipErrorInvalidAddressSpace', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_INVALID_PC', ('hipErrorInvalidPc', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorInvalidPc', ('hipErrorInvalidPc', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_LAUNCH_FAILED', ('hipErrorLaunchFailure', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorLaunchFailure', ('hipErrorLaunchFailure', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_ERROR_UNKNOWN', ('hipErrorUnknown', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cudaErrorUnknown', ('hipErrorUnknown', CONV_TYPE, API_RUNTIME)), ('CU_TR_ADDRESS_MODE_WRAP', ('HIP_TR_ADDRESS_MODE_WRAP', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TR_ADDRESS_MODE_CLAMP', ('HIP_TR_ADDRESS_MODE_CLAMP', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TR_ADDRESS_MODE_MIRROR', ('HIP_TR_ADDRESS_MODE_MIRROR', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TR_ADDRESS_MODE_BORDER', ('HIP_TR_ADDRESS_MODE_BORDER', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CUBEMAP_FACE_POSITIVE_X', ('HIP_CUBEMAP_FACE_POSITIVE_X', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CUBEMAP_FACE_NEGATIVE_X', ('HIP_CUBEMAP_FACE_NEGATIVE_X', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CUBEMAP_FACE_POSITIVE_Y', ('HIP_CUBEMAP_FACE_POSITIVE_Y', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CUBEMAP_FACE_NEGATIVE_Y', ('HIP_CUBEMAP_FACE_NEGATIVE_Y', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CUBEMAP_FACE_POSITIVE_Z', ('HIP_CUBEMAP_FACE_POSITIVE_Z', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CUBEMAP_FACE_NEGATIVE_Z', ('HIP_CUBEMAP_FACE_NEGATIVE_Z', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_AD_FORMAT_UNSIGNED_INT8', ('HIP_AD_FORMAT_UNSIGNED_INT8', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_UNSIGNED_INT16', ('HIP_AD_FORMAT_UNSIGNED_INT16', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_UNSIGNED_INT32', ('HIP_AD_FORMAT_UNSIGNED_INT32', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_SIGNED_INT8', ('HIP_AD_FORMAT_SIGNED_INT8', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_SIGNED_INT16', ('HIP_AD_FORMAT_SIGNED_INT16', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_SIGNED_INT32', ('HIP_AD_FORMAT_SIGNED_INT32', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_HALF', ('HIP_AD_FORMAT_HALF', CONV_TYPE, API_DRIVER)), ('CU_AD_FORMAT_FLOAT', ('HIP_AD_FORMAT_FLOAT', CONV_TYPE, API_DRIVER)), ('CU_COMPUTEMODE_DEFAULT', ('hipComputeModeDefault', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_COMPUTEMODE_EXCLUSIVE', ('hipComputeModeExclusive', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_COMPUTEMODE_PROHIBITED', ('hipComputeModeProhibited', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_COMPUTEMODE_EXCLUSIVE_PROCESS', ('hipComputeModeExclusiveProcess', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ADVISE_SET_READ_MOSTLY', ('hipMemAdviseSetReadMostly', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ADVISE_UNSET_READ_MOSTLY', ('hipMemAdviseUnsetReadMostly', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ADVISE_SET_PREFERRED_LOCATION', ('hipMemAdviseSetPreferredLocation', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ADVISE_UNSET_PREFERRED_LOCATION', ('hipMemAdviseUnsetPreferredLocation', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ADVISE_SET_ACCESSED_BY', ('hipMemAdviseSetAccessedBy', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ADVISE_UNSET_ACCESSED_BY', ('hipMemAdviseUnsetAccessedBy', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_RANGE_ATTRIBUTE_READ_MOSTLY', ('hipMemRangeAttributeReadMostly', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_RANGE_ATTRIBUTE_PREFERRED_LOCATION', ('hipMemRangeAttributePreferredLocation', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_RANGE_ATTRIBUTE_ACCESSED_BY', ('hipMemRangeAttributeAccessedBy', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_RANGE_ATTRIBUTE_LAST_PREFETCH_LOCATION', ('hipMemRangeAttributeLastPrefetchLocation', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_SCHED_AUTO', ('HIP_CTX_SCHED_AUTO', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_SCHED_SPIN', ('HIP_CTX_SCHED_SPIN', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_SCHED_YIELD', ('HIP_CTX_SCHED_YIELD', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_SCHED_BLOCKING_SYNC', ('HIP_CTX_SCHED_BLOCKING_SYNC', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_BLOCKING_SYNC', ('HIP_CTX_BLOCKING_SYNC', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_SCHED_MASK', ('HIP_CTX_SCHED_MASK', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_MAP_HOST', ('HIP_CTX_MAP_HOST', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_LMEM_RESIZE_TO_MAX', ('HIP_CTX_LMEM_RESIZE_TO_MAX', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_CTX_FLAGS_MASK', ('HIP_CTX_FLAGS_MASK', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_LAUNCH_PARAM_BUFFER_POINTER', ('HIP_LAUNCH_PARAM_BUFFER_POINTER', CONV_TYPE, API_DRIVER)), ('CU_LAUNCH_PARAM_BUFFER_SIZE', ('HIP_LAUNCH_PARAM_BUFFER_SIZE', CONV_TYPE, API_DRIVER)), ('CU_LAUNCH_PARAM_END', ('HIP_LAUNCH_PARAM_END', CONV_TYPE, API_DRIVER)), ('CU_IPC_HANDLE_SIZE', ('HIP_LAUNCH_PARAM_END', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMHOSTALLOC_DEVICEMAP', ('HIP_MEMHOSTALLOC_DEVICEMAP', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMHOSTALLOC_PORTABLE', ('HIP_MEMHOSTALLOC_PORTABLE', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMHOSTALLOC_WRITECOMBINED', ('HIP_MEMHOSTALLOC_WRITECOMBINED', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMHOSTREGISTER_DEVICEMAP', ('HIP_MEMHOSTREGISTER_DEVICEMAP', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMHOSTREGISTER_IOMEMORY', ('HIP_MEMHOSTREGISTER_IOMEMORY', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMHOSTREGISTER_PORTABLE', ('HIP_MEMHOSTREGISTER_PORTABLE', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_PARAM_TR_DEFAULT', ('HIP_PARAM_TR_DEFAULT', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_LEGACY', ('HIP_STREAM_LEGACY', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_PER_THREAD', ('HIP_STREAM_PER_THREAD', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TRSA_OVERRIDE_FORMAT', ('HIP_TRSA_OVERRIDE_FORMAT', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TRSF_NORMALIZED_COORDINATES', ('HIP_TRSF_NORMALIZED_COORDINATES', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TRSF_READ_AS_INTEGER', ('HIP_TRSF_READ_AS_INTEGER', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TRSF_SRGB', ('HIP_TRSF_SRGB', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY3D_2DARRAY', ('HIP_ARRAY3D_LAYERED', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY3D_CUBEMAP', ('HIP_ARRAY3D_CUBEMAP', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY3D_DEPTH_TEXTURE', ('HIP_ARRAY3D_DEPTH_TEXTURE', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY3D_LAYERED', ('HIP_ARRAY3D_LAYERED', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY3D_SURFACE_LDST', ('HIP_ARRAY3D_SURFACE_LDST', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_ARRAY3D_TEXTURE_GATHER', ('HIP_ARRAY3D_TEXTURE_GATHER', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_BLOCK', ('hipDeviceAttributeMaxThreadsPerBlock', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_X', ('hipDeviceAttributeMaxBlockDimX', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Y', ('hipDeviceAttributeMaxBlockDimY', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_BLOCK_DIM_Z', ('hipDeviceAttributeMaxBlockDimZ', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_X', ('hipDeviceAttributeMaxGridDimX', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Y', ('hipDeviceAttributeMaxGridDimY', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_GRID_DIM_Z', ('hipDeviceAttributeMaxGridDimZ', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_BLOCK', ('hipDeviceAttributeMaxSharedMemoryPerBlock', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_SHARED_MEMORY_PER_BLOCK', ('hipDeviceAttributeMaxSharedMemoryPerBlock', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_TOTAL_CONSTANT_MEMORY', ('hipDeviceAttributeTotalConstantMemory', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_WARP_SIZE', ('hipDeviceAttributeWarpSize', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_PITCH', ('hipDeviceAttributeMaxPitch', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_BLOCK', ('hipDeviceAttributeMaxRegistersPerBlock', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_REGISTERS_PER_BLOCK', ('hipDeviceAttributeMaxRegistersPerBlock', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_CLOCK_RATE', ('hipDeviceAttributeClockRate', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_TEXTURE_ALIGNMENT', ('hipDeviceAttributeTextureAlignment', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_GPU_OVERLAP', ('hipDeviceAttributeAsyncEngineCount', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MULTIPROCESSOR_COUNT', ('hipDeviceAttributeMultiprocessorCount', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_KERNEL_EXEC_TIMEOUT', ('hipDeviceAttributeKernelExecTimeout', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_INTEGRATED', ('hipDeviceAttributeIntegrated', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_CAN_MAP_HOST_MEMORY', ('hipDeviceAttributeCanMapHostMemory', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_COMPUTE_MODE', ('hipDeviceAttributeComputeMode', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_WIDTH', ('hipDeviceAttributeMaxTexture1DWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_WIDTH', ('hipDeviceAttributeMaxTexture2DWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_HEIGHT', ('hipDeviceAttributeMaxTexture2DHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH', ('hipDeviceAttributeMaxTexture3DWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT', ('hipDeviceAttributeMaxTexture3DHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH', ('hipDeviceAttributeMaxTexture3DDepth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_WIDTH', ('hipDeviceAttributeMaxTexture2DLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_HEIGHT', ('hipDeviceAttributeMaxTexture2DLayeredHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LAYERED_LAYERS', ('hipDeviceAttributeMaxTexture2DLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_WIDTH', ('hipDeviceAttributeMaxTexture2DLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_HEIGHT', ('hipDeviceAttributeMaxTexture2DLayeredHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_ARRAY_NUMSLICES', ('hipDeviceAttributeMaxTexture2DLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_SURFACE_ALIGNMENT', ('hipDeviceAttributeSurfaceAlignment', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_CONCURRENT_KERNELS', ('hipDeviceAttributeConcurrentKernels', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_ECC_ENABLED', ('hipDeviceAttributeEccEnabled', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_PCI_BUS_ID', ('hipDeviceAttributePciBusId', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_PCI_DEVICE_ID', ('hipDeviceAttributePciDeviceId', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_TCC_DRIVER', ('hipDeviceAttributeTccDriver', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MEMORY_CLOCK_RATE', ('hipDeviceAttributeMemoryClockRate', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_GLOBAL_MEMORY_BUS_WIDTH', ('hipDeviceAttributeMemoryBusWidth', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_L2_CACHE_SIZE', ('hipDeviceAttributeL2CacheSize', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_MAX_THREADS_PER_MULTIPROCESSOR', ('hipDeviceAttributeMaxThreadsPerMultiProcessor', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_ASYNC_ENGINE_COUNT', ('hipDeviceAttributeAsyncEngineCount', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_UNIFIED_ADDRESSING', ('hipDeviceAttributeUnifiedAddressing', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_WIDTH', ('hipDeviceAttributeMaxTexture1DLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LAYERED_LAYERS', ('hipDeviceAttributeMaxTexture1DLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_CAN_TEX2D_GATHER', ('hipDeviceAttributeCanTex2DGather', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_WIDTH', ('hipDeviceAttributeMaxTexture2DGatherWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_GATHER_HEIGHT', ('hipDeviceAttributeMaxTexture2DGatherHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_WIDTH_ALTERNATE', ('hipDeviceAttributeMaxTexture3DWidthAlternate', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_HEIGHT_ALTERNATE', ('hipDeviceAttributeMaxTexture3DHeightAlternate', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE3D_DEPTH_ALTERNATE', ('hipDeviceAttributeMaxTexture3DDepthAlternate', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_PCI_DOMAIN_ID', ('hipDeviceAttributePciDomainId', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_TEXTURE_PITCH_ALIGNMENT', ('hipDeviceAttributeTexturePitchAlignment', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_WIDTH', ('hipDeviceAttributeMaxTextureCubemapWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_WIDTH', ('hipDeviceAttributeMaxTextureCubemapLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURECUBEMAP_LAYERED_LAYERS', ('hipDeviceAttributeMaxTextureCubemapLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_WIDTH', ('hipDeviceAttributeMaxSurface1DWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_WIDTH', ('hipDeviceAttributeMaxSurface2DWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_HEIGHT', ('hipDeviceAttributeMaxSurface2DHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_WIDTH', ('hipDeviceAttributeMaxSurface3DWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_HEIGHT', ('hipDeviceAttributeMaxSurface3DHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE3D_DEPTH', ('hipDeviceAttributeMaxSurface3DDepth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_WIDTH', ('hipDeviceAttributeMaxSurface1DLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE1D_LAYERED_LAYERS', ('hipDeviceAttributeMaxSurface1DLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_WIDTH', ('hipDeviceAttributeMaxSurface2DLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_HEIGHT', ('hipDeviceAttributeMaxSurface2DLayeredHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACE2D_LAYERED_LAYERS', ('hipDeviceAttributeMaxSurface2DLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_WIDTH', ('hipDeviceAttributeMaxSurfaceCubemapWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_WIDTH', ('hipDeviceAttributeMaxSurfaceCubemapLayeredWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_SURFACECUBEMAP_LAYERED_LAYERS', ('hipDeviceAttributeMaxSurfaceCubemapLayeredLayers', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_LINEAR_WIDTH', ('hipDeviceAttributeMaxTexture1DLinearWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_WIDTH', ('hipDeviceAttributeMaxTexture2DLinearWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_HEIGHT', ('hipDeviceAttributeMaxTexture2DLinearHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_LINEAR_PITCH', ('hipDeviceAttributeMaxTexture2DLinearPitch', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_WIDTH', ('hipDeviceAttributeMaxTexture2DMipmappedWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE2D_MIPMAPPED_HEIGHT', ('hipDeviceAttributeMaxTexture2DMipmappedHeight', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MAJOR', ('hipDeviceAttributeComputeCapabilityMajor', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_COMPUTE_CAPABILITY_MINOR', ('hipDeviceAttributeComputeCapabilityMinor', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_MAXIMUM_TEXTURE1D_MIPMAPPED_WIDTH', ('hipDeviceAttributeMaxTexture1DMipmappedWidth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_STREAM_PRIORITIES_SUPPORTED', ('hipDeviceAttributeStreamPrioritiesSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_GLOBAL_L1_CACHE_SUPPORTED', ('hipDeviceAttributeGlobalL1CacheSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_LOCAL_L1_CACHE_SUPPORTED', ('hipDeviceAttributeLocalL1CacheSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX_SHARED_MEMORY_PER_MULTIPROCESSOR', ('hipDeviceAttributeMaxSharedMemoryPerMultiprocessor', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_MAX_REGISTERS_PER_MULTIPROCESSOR', ('hipDeviceAttributeMaxRegistersPerMultiprocessor', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MANAGED_MEMORY', ('hipDeviceAttributeManagedMemory', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD', ('hipDeviceAttributeIsMultiGpuBoard', CONV_TYPE, API_DRIVER)), ('CU_DEVICE_ATTRIBUTE_MULTI_GPU_BOARD_GROUP_ID', ('hipDeviceAttributeMultiGpuBoardGroupId', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_HOST_NATIVE_ATOMIC_SUPPORTED', ('hipDeviceAttributeHostNativeAtomicSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_SINGLE_TO_DOUBLE_PRECISION_PERF_RATIO', ('hipDeviceAttributeSingleToDoublePrecisionPerfRatio', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_PAGEABLE_MEMORY_ACCESS', ('hipDeviceAttributePageableMemoryAccess', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_CONCURRENT_MANAGED_ACCESS', ('hipDeviceAttributeConcurrentManagedAccess', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_COMPUTE_PREEMPTION_SUPPORTED', ('hipDeviceAttributeComputePreemptionSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_CAN_USE_HOST_POINTER_FOR_REGISTERED_MEM', ('hipDeviceAttributeCanUseHostPointerForRegisteredMem', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_ATTRIBUTE_MAX', ('hipDeviceAttributeMax', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_CONTEXT', ('hipPointerAttributeContext', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_MEMORY_TYPE', ('hipPointerAttributeMemoryType', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_DEVICE_POINTER', ('hipPointerAttributeDevicePointer', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_HOST_POINTER', ('hipPointerAttributeHostPointer', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_P2P_TOKENS', ('hipPointerAttributeP2pTokens', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_SYNC_MEMOPS', ('hipPointerAttributeSyncMemops', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_BUFFER_ID', ('hipPointerAttributeBufferId', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_POINTER_ATTRIBUTE_IS_MANAGED', ('hipPointerAttributeIsManaged', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_MAX_THREADS_PER_BLOCK', ('hipFuncAttributeMaxThreadsPerBlocks', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_SHARED_SIZE_BYTES', ('hipFuncAttributeSharedSizeBytes', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_CONST_SIZE_BYTES', ('hipFuncAttributeConstSizeBytes', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_LOCAL_SIZE_BYTES', ('hipFuncAttributeLocalSizeBytes', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_NUM_REGS', ('hipFuncAttributeNumRegs', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_PTX_VERSION', ('hipFuncAttributePtxVersion', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_BINARY_VERSION', ('hipFuncAttributeBinaryVersion', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_CACHE_MODE_CA', ('hipFuncAttributeCacheModeCA', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_ATTRIBUTE_MAX', ('hipFuncAttributeMax', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_MAP_RESOURCE_FLAGS_NONE', ('hipGraphicsMapFlagsNone', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_MAP_RESOURCE_FLAGS_READ_ONLY', ('hipGraphicsMapFlagsReadOnly', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_MAP_RESOURCE_FLAGS_WRITE_DISCARD', ('hipGraphicsMapFlagsWriteDiscard', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_REGISTER_FLAGS_NONE', ('hipGraphicsRegisterFlagsNone', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_REGISTER_FLAGS_READ_ONLY', ('hipGraphicsRegisterFlagsReadOnly', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_REGISTER_FLAGS_WRITE_DISCARD', ('hipGraphicsRegisterFlagsWriteDiscard', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_REGISTER_FLAGS_SURFACE_LDST', ('hipGraphicsRegisterFlagsSurfaceLoadStore', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GRAPHICS_REGISTER_FLAGS_TEXTURE_GATHER', ('hipGraphicsRegisterFlagsTextureGather', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_OCCUPANCY_DEFAULT', ('hipOccupancyDefault', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_OCCUPANCY_DISABLE_CACHING_OVERRIDE', ('hipOccupancyDisableCachingOverride', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_FUNC_CACHE_PREFER_NONE', ('hipFuncCachePreferNone', CONV_CACHE, API_DRIVER)), ('CU_FUNC_CACHE_PREFER_SHARED', ('hipFuncCachePreferShared', CONV_CACHE, API_DRIVER)), ('CU_FUNC_CACHE_PREFER_L1', ('hipFuncCachePreferL1', CONV_CACHE, API_DRIVER)), ('CU_FUNC_CACHE_PREFER_EQUAL', ('hipFuncCachePreferEqual', CONV_CACHE, API_DRIVER)), ('CU_IPC_MEM_LAZY_ENABLE_PEER_ACCESS', ('hipIpcMemLazyEnablePeerAccess', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CUDA_IPC_HANDLE_SIZE', ('HIP_IPC_HANDLE_SIZE', CONV_TYPE, API_DRIVER)), ('CU_JIT_CACHE_OPTION_NONE', ('hipJitCacheModeOptionNone', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_CACHE_OPTION_CG', ('hipJitCacheModeOptionCG', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_CACHE_OPTION_CA', ('hipJitCacheModeOptionCA', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_PREFER_PTX', ('hipJitFallbackPreferPtx', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_PREFER_BINARY', ('hipJitFallbackPreferBinary', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_MAX_REGISTERS', ('hipJitOptionMaxRegisters', CONV_JIT, API_DRIVER)), ('CU_JIT_THREADS_PER_BLOCK', ('hipJitOptionThreadsPerBlock', CONV_JIT, API_DRIVER)), ('CU_JIT_WALL_TIME', ('hipJitOptionWallTime', CONV_JIT, API_DRIVER)), ('CU_JIT_INFO_LOG_BUFFER', ('hipJitOptionInfoLogBuffer', CONV_JIT, API_DRIVER)), ('CU_JIT_INFO_LOG_BUFFER_SIZE_BYTES', ('hipJitOptionInfoLogBufferSizeBytes', CONV_JIT, API_DRIVER)), ('CU_JIT_ERROR_LOG_BUFFER', ('hipJitOptionErrorLogBuffer', CONV_JIT, API_DRIVER)), ('CU_JIT_ERROR_LOG_BUFFER_SIZE_BYTES', ('hipJitOptionErrorLogBufferSizeBytes', CONV_JIT, API_DRIVER)), ('CU_JIT_OPTIMIZATION_LEVEL', ('hipJitOptionOptimizationLevel', CONV_JIT, API_DRIVER)), ('CU_JIT_TARGET_FROM_CUCONTEXT', ('hipJitOptionTargetFromContext', CONV_JIT, API_DRIVER)), ('CU_JIT_TARGET', ('hipJitOptionTarget', CONV_JIT, API_DRIVER)), ('CU_JIT_FALLBACK_STRATEGY', ('hipJitOptionFallbackStrategy', CONV_JIT, API_DRIVER)), ('CU_JIT_GENERATE_DEBUG_INFO', ('hipJitOptionGenerateDebugInfo', CONV_JIT, API_DRIVER)), ('CU_JIT_LOG_VERBOSE', ('hipJitOptionLogVerbose', CONV_JIT, API_DRIVER)), ('CU_JIT_GENERATE_LINE_INFO', ('hipJitOptionGenerateLineInfo', CONV_JIT, API_DRIVER)), ('CU_JIT_CACHE_MODE', ('hipJitOptionCacheMode', CONV_JIT, API_DRIVER)), ('CU_JIT_NEW_SM3X_OPT', ('hipJitOptionSm3xOpt', CONV_JIT, API_DRIVER)), ('CU_JIT_FAST_COMPILE', ('hipJitOptionFastCompile', CONV_JIT, API_DRIVER)), ('CU_JIT_NUM_OPTIONS', ('hipJitOptionNumOptions', CONV_JIT, API_DRIVER)), ('CU_TARGET_COMPUTE_10', ('hipJitTargetCompute10', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_11', ('hipJitTargetCompute11', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_12', ('hipJitTargetCompute12', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_13', ('hipJitTargetCompute13', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_20', ('hipJitTargetCompute20', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_21', ('hipJitTargetCompute21', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_30', ('hipJitTargetCompute30', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_32', ('hipJitTargetCompute32', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_35', ('hipJitTargetCompute35', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_37', ('hipJitTargetCompute37', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_50', ('hipJitTargetCompute50', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_52', ('hipJitTargetCompute52', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_53', ('hipJitTargetCompute53', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_60', ('hipJitTargetCompute60', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_61', ('hipJitTargetCompute61', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TARGET_COMPUTE_62', ('hipJitTargetCompute62', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_INPUT_CUBIN', ('hipJitInputTypeBin', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_INPUT_PTX', ('hipJitInputTypePtx', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_INPUT_FATBINARY', ('hipJitInputTypeFatBinary', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_INPUT_OBJECT', ('hipJitInputTypeObject', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_INPUT_LIBRARY', ('hipJitInputTypeLibrary', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_JIT_NUM_INPUT_TYPES', ('hipJitInputTypeNumInputTypes', CONV_JIT, API_DRIVER, HIP_UNSUPPORTED)), ('CU_LIMIT_STACK_SIZE', ('hipLimitStackSize', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_LIMIT_PRINTF_FIFO_SIZE', ('hipLimitPrintfFifoSize', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_LIMIT_MALLOC_HEAP_SIZE', ('hipLimitMallocHeapSize', CONV_TYPE, API_DRIVER)), ('CU_LIMIT_DEV_RUNTIME_SYNC_DEPTH', ('hipLimitDevRuntimeSyncDepth', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_LIMIT_DEV_RUNTIME_PENDING_LAUNCH_COUNT', ('hipLimitDevRuntimePendingLaunchCount', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_LIMIT_STACK_SIZE', ('hipLimitStackSize', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ATTACH_GLOBAL', ('hipMemAttachGlobal', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ATTACH_HOST', ('hipMemAttachHost', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEM_ATTACH_SINGLE', ('hipMemAttachSingle', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMORYTYPE_HOST', ('hipMemTypeHost', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMORYTYPE_DEVICE', ('hipMemTypeDevice', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMORYTYPE_ARRAY', ('hipMemTypeArray', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_MEMORYTYPE_UNIFIED', ('hipMemTypeUnified', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_RESOURCE_TYPE_ARRAY', ('hipResourceTypeArray', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('CU_RESOURCE_TYPE_MIPMAPPED_ARRAY', ('hipResourceTypeMipmappedArray', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('CU_RESOURCE_TYPE_LINEAR', ('hipResourceTypeLinear', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('CU_RESOURCE_TYPE_PITCH2D', ('hipResourceTypePitch2D', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('CU_RES_VIEW_FORMAT_NONE', ('hipResViewFormatNone', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_1X8', ('hipResViewFormatUnsignedChar1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_2X8', ('hipResViewFormatUnsignedChar2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_4X8', ('hipResViewFormatUnsignedChar4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_1X8', ('hipResViewFormatSignedChar1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_2X8', ('hipResViewFormatSignedChar2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_4X8', ('hipResViewFormatSignedChar4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_1X16', ('hipResViewFormatUnsignedShort1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_2X16', ('hipResViewFormatUnsignedShort2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_4X16', ('hipResViewFormatUnsignedShort4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_1X16', ('hipResViewFormatSignedShort1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_2X16', ('hipResViewFormatSignedShort2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_4X16', ('hipResViewFormatSignedShort4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_1X32', ('hipResViewFormatUnsignedInt1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_2X32', ('hipResViewFormatUnsignedInt2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UINT_4X32', ('hipResViewFormatUnsignedInt4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_1X32', ('hipResViewFormatSignedInt1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_2X32', ('hipResViewFormatSignedInt2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SINT_4X32', ('hipResViewFormatSignedInt4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_FLOAT_1X16', ('hipResViewFormatHalf1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_FLOAT_2X16', ('hipResViewFormatHalf2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_FLOAT_4X16', ('hipResViewFormatHalf4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_FLOAT_1X32', ('hipResViewFormatFloat1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_FLOAT_2X32', ('hipResViewFormatFloat2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_FLOAT_4X32', ('hipResViewFormatFloat4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC1', ('hipResViewFormatUnsignedBlockCompressed1', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC2', ('hipResViewFormatUnsignedBlockCompressed2', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC3', ('hipResViewFormatUnsignedBlockCompressed3', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC4', ('hipResViewFormatUnsignedBlockCompressed4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SIGNED_BC4', ('hipResViewFormatSignedBlockCompressed4', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC5', ('hipResViewFormatUnsignedBlockCompressed5', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SIGNED_BC5', ('hipResViewFormatSignedBlockCompressed5', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC6H', ('hipResViewFormatUnsignedBlockCompressed6H', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_SIGNED_BC6H', ('hipResViewFormatSignedBlockCompressed6H', CONV_TEX, API_DRIVER)), ('CU_RES_VIEW_FORMAT_UNSIGNED_BC7', ('hipResViewFormatUnsignedBlockCompressed7', CONV_TEX, API_DRIVER)), ('CU_SHARED_MEM_CONFIG_DEFAULT_BANK_SIZE', ('hipSharedMemBankSizeDefault', CONV_TYPE, API_DRIVER)), ('CU_SHARED_MEM_CONFIG_FOUR_BYTE_BANK_SIZE', ('hipSharedMemBankSizeFourByte', CONV_TYPE, API_DRIVER)), ('CU_SHARED_MEM_CONFIG_EIGHT_BYTE_BANK_SIZE', ('hipSharedMemBankSizeEightByte', CONV_TYPE, API_DRIVER)), ('CU_STREAM_DEFAULT', ('hipStreamDefault', CONV_TYPE, API_DRIVER)), ('CU_STREAM_NON_BLOCKING', ('hipStreamNonBlocking', CONV_TYPE, API_DRIVER)), ('CU_STREAM_WAIT_VALUE_GEQ', ('hipStreamWaitValueGeq', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_WAIT_VALUE_EQ', ('hipStreamWaitValueEq', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_WAIT_VALUE_AND', ('hipStreamWaitValueAnd', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_WAIT_VALUE_FLUSH', ('hipStreamWaitValueFlush', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_WRITE_VALUE_DEFAULT', ('hipStreamWriteValueDefault', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_WRITE_VALUE_NO_MEMORY_BARRIER', ('hipStreamWriteValueNoMemoryBarrier', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_MEM_OP_WAIT_VALUE_32', ('hipStreamBatchMemOpWaitValue32', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_MEM_OP_WRITE_VALUE_32', ('hipStreamBatchMemOpWriteValue32', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_STREAM_MEM_OP_FLUSH_REMOTE_WRITES', ('hipStreamBatchMemOpFlushRemoteWrites', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('cuGetErrorName', ('hipGetErrorName___', CONV_ERROR, API_DRIVER, HIP_UNSUPPORTED)), ('cuGetErrorString', ('hipGetErrorString___', CONV_ERROR, API_DRIVER, HIP_UNSUPPORTED)), ('cuInit', ('hipInit', CONV_INIT, API_DRIVER)), ('cuDriverGetVersion', ('hipDriverGetVersion', CONV_VERSION, API_DRIVER)), ('cuCtxCreate_v2', ('hipCtxCreate', CONV_CONTEXT, API_DRIVER)), ('cuCtxDestroy_v2', ('hipCtxDestroy', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetApiVersion', ('hipCtxGetApiVersion', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetCacheConfig', ('hipCtxGetCacheConfig', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetCurrent', ('hipCtxGetCurrent', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetDevice', ('hipCtxGetDevice', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetFlags', ('hipCtxGetFlags', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetLimit', ('hipCtxGetLimit', CONV_CONTEXT, API_DRIVER, HIP_UNSUPPORTED)), ('cuCtxGetSharedMemConfig', ('hipCtxGetSharedMemConfig', CONV_CONTEXT, API_DRIVER)), ('cuCtxGetStreamPriorityRange', ('hipCtxGetStreamPriorityRange', CONV_CONTEXT, API_DRIVER, HIP_UNSUPPORTED)), ('cuCtxPopCurrent_v2', ('hipCtxPopCurrent', CONV_CONTEXT, API_DRIVER)), ('cuCtxPushCurrent_v2', ('hipCtxPushCurrent', CONV_CONTEXT, API_DRIVER)), ('cuCtxSetCacheConfig', ('hipCtxSetCacheConfig', CONV_CONTEXT, API_DRIVER)), ('cuCtxSetCurrent', ('hipCtxSetCurrent', CONV_CONTEXT, API_DRIVER)), ('cuCtxSetLimit', ('hipCtxSetLimit', CONV_CONTEXT, API_DRIVER, HIP_UNSUPPORTED)), ('cuCtxSetSharedMemConfig', ('hipCtxSetSharedMemConfig', CONV_CONTEXT, API_DRIVER)), ('cuCtxSynchronize', ('hipCtxSynchronize', CONV_CONTEXT, API_DRIVER)), ('cuCtxAttach', ('hipCtxAttach', CONV_CONTEXT, API_DRIVER, HIP_UNSUPPORTED)), ('cuCtxDetach', ('hipCtxDetach', CONV_CONTEXT, API_DRIVER, HIP_UNSUPPORTED)), ('cuCtxEnablePeerAccess', ('hipCtxEnablePeerAccess', CONV_PEER, API_DRIVER)), ('cuCtxDisablePeerAccess', ('hipCtxDisablePeerAccess', CONV_PEER, API_DRIVER)), ('cuDeviceCanAccessPeer', ('hipDeviceCanAccessPeer', CONV_PEER, API_DRIVER)), ('cuDeviceGetP2PAttribute', ('hipDeviceGetP2PAttribute', CONV_PEER, API_DRIVER, HIP_UNSUPPORTED)), ('cuDevicePrimaryCtxGetState', ('hipDevicePrimaryCtxGetState', CONV_CONTEXT, API_DRIVER)), ('cuDevicePrimaryCtxRelease', ('hipDevicePrimaryCtxRelease', CONV_CONTEXT, API_DRIVER)), ('cuDevicePrimaryCtxReset', ('hipDevicePrimaryCtxReset', CONV_CONTEXT, API_DRIVER)), ('cuDevicePrimaryCtxRetain', ('hipDevicePrimaryCtxRetain', CONV_CONTEXT, API_DRIVER)), ('cuDevicePrimaryCtxSetFlags', ('hipDevicePrimaryCtxSetFlags', CONV_CONTEXT, API_DRIVER)), ('cuDeviceGet', ('hipGetDevice', CONV_DEVICE, API_DRIVER)), ('cuDeviceGetName', ('hipDeviceGetName', CONV_DEVICE, API_DRIVER)), ('cuDeviceGetCount', ('hipGetDeviceCount', CONV_DEVICE, API_DRIVER)), ('cuDeviceGetAttribute', ('hipDeviceGetAttribute', CONV_DEVICE, API_DRIVER)), ('cuDeviceGetPCIBusId', ('hipDeviceGetPCIBusId', CONV_DEVICE, API_DRIVER)), ('cuDeviceGetByPCIBusId', ('hipDeviceGetByPCIBusId', CONV_DEVICE, API_DRIVER)), ('cuDeviceTotalMem_v2', ('hipDeviceTotalMem', CONV_DEVICE, API_DRIVER)), ('cuDeviceComputeCapability', ('hipDeviceComputeCapability', CONV_DEVICE, API_DRIVER)), ('cuDeviceGetProperties', ('hipGetDeviceProperties', CONV_DEVICE, API_DRIVER)), ('cuLinkAddData', ('hipLinkAddData', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLinkAddFile', ('hipLinkAddFile', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLinkComplete', ('hipLinkComplete', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLinkCreate', ('hipLinkCreate', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLinkDestroy', ('hipLinkDestroy', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuModuleGetFunction', ('hipModuleGetFunction', CONV_MODULE, API_DRIVER)), ('cuModuleGetGlobal_v2', ('hipModuleGetGlobal', CONV_MODULE, API_DRIVER)), ('cuModuleGetSurfRef', ('hipModuleGetSurfRef', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuModuleGetTexRef', ('hipModuleGetTexRef', CONV_MODULE, API_DRIVER)), ('cuModuleLoad', ('hipModuleLoad', CONV_MODULE, API_DRIVER)), ('cuModuleLoadData', ('hipModuleLoadData', CONV_MODULE, API_DRIVER)), ('cuModuleLoadDataEx', ('hipModuleLoadDataEx', CONV_MODULE, API_DRIVER)), ('cuModuleLoadFatBinary', ('hipModuleLoadFatBinary', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuModuleUnload', ('hipModuleUnload', CONV_MODULE, API_DRIVER)), ('CU_DEVICE_P2P_ATTRIBUTE_PERFORMANCE_RANK', ('hipDeviceP2PAttributePerformanceRank', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_P2P_ATTRIBUTE_ACCESS_SUPPORTED', ('hipDeviceP2PAttributeAccessSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_DEVICE_P2P_ATTRIBUTE_NATIVE_ATOMIC_SUPPORTED', ('hipDeviceP2PAttributeNativeAtomicSupported', CONV_TYPE, API_DRIVER, HIP_UNSUPPORTED)), ('CU_EVENT_DEFAULT', ('hipEventDefault', CONV_EVENT, API_DRIVER)), ('CU_EVENT_BLOCKING_SYNC', ('hipEventBlockingSync', CONV_EVENT, API_DRIVER)), ('CU_EVENT_DISABLE_TIMING', ('hipEventDisableTiming', CONV_EVENT, API_DRIVER)), ('CU_EVENT_INTERPROCESS', ('hipEventInterprocess', CONV_EVENT, API_DRIVER)), ('cuEventCreate', ('hipEventCreate', CONV_EVENT, API_DRIVER)), ('cuEventDestroy_v2', ('hipEventDestroy', CONV_EVENT, API_DRIVER)), ('cuEventElapsedTime', ('hipEventElapsedTime', CONV_EVENT, API_DRIVER)), ('cuEventQuery', ('hipEventQuery', CONV_EVENT, API_DRIVER)), ('cuEventRecord', ('hipEventRecord', CONV_EVENT, API_DRIVER)), ('cuEventSynchronize', ('hipEventSynchronize', CONV_EVENT, API_DRIVER)), ('cuFuncGetAttribute', ('hipFuncGetAttribute', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuFuncSetCacheConfig', ('hipFuncSetCacheConfig', CONV_MODULE, API_DRIVER)), ('cuFuncSetSharedMemConfig', ('hipFuncSetSharedMemConfig', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLaunchKernel', ('hipModuleLaunchKernel', CONV_MODULE, API_DRIVER)), ('cuFuncSetBlockShape', ('hipFuncSetBlockShape', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuFuncSetSharedSize', ('hipFuncSetSharedSize', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLaunch', ('hipLaunch', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLaunchGrid', ('hipLaunchGrid', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuLaunchGridAsync', ('hipLaunchGridAsync', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuParamSetf', ('hipParamSetf', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuParamSeti', ('hipParamSeti', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuParamSetSize', ('hipParamSetSize', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuParamSetSize', ('hipParamSetSize', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuParamSetv', ('hipParamSetv', CONV_MODULE, API_DRIVER, HIP_UNSUPPORTED)), ('cuOccupancyMaxActiveBlocksPerMultiprocessor', ('hipModuleOccupancyMaxActiveBlocksPerMultiprocessor', CONV_OCCUPANCY, API_DRIVER)), ('cuOccupancyMaxActiveBlocksPerMultiprocessorWithFlags', ('hipModuleOccupancyMaxActiveBlocksPerMultiprocessorWithFlags', CONV_OCCUPANCY, API_DRIVER, HIP_UNSUPPORTED)), ('cuOccupancyMaxPotentialBlockSize', ('hipModuleOccupancyMaxPotentialBlockSize', CONV_OCCUPANCY, API_DRIVER)), ('cuOccupancyMaxPotentialBlockSizeWithFlags', ('hipModuleOccupancyMaxPotentialBlockSizeWithFlags', CONV_OCCUPANCY, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamAddCallback', ('hipStreamAddCallback', CONV_STREAM, API_DRIVER)), ('cuStreamAttachMemAsync', ('hipStreamAttachMemAsync', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamCreate', ('hipStreamCreate__', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamCreateWithPriority', ('hipStreamCreateWithPriority', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamDestroy_v2', ('hipStreamDestroy', CONV_STREAM, API_DRIVER)), ('cuStreamGetFlags', ('hipStreamGetFlags', CONV_STREAM, API_DRIVER)), ('cuStreamGetPriority', ('hipStreamGetPriority', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamQuery', ('hipStreamQuery', CONV_STREAM, API_DRIVER)), ('cuStreamSynchronize', ('hipStreamSynchronize', CONV_STREAM, API_DRIVER)), ('cuStreamWaitEvent', ('hipStreamWaitEvent', CONV_STREAM, API_DRIVER)), ('cuStreamWaitValue32', ('hipStreamWaitValue32', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamWriteValue32', ('hipStreamWriteValue32', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuStreamBatchMemOp', ('hipStreamBatchMemOp', CONV_STREAM, API_DRIVER, HIP_UNSUPPORTED)), ('cuArray3DCreate', ('hipArray3DCreate', CONV_MEM, API_DRIVER)), ('cuArray3DGetDescriptor', ('hipArray3DGetDescriptor', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuArrayCreate', ('hipArrayCreate', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuArrayDestroy', ('hipArrayDestroy', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuArrayGetDescriptor', ('hipArrayGetDescriptor', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuIpcCloseMemHandle', ('hipIpcCloseMemHandle', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuIpcGetEventHandle', ('hipIpcGetEventHandle', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuIpcGetMemHandle', ('hipIpcGetMemHandle', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuIpcOpenEventHandle', ('hipIpcOpenEventHandle', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuIpcOpenMemHandle', ('hipIpcOpenMemHandle', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemAlloc_v2', ('hipMalloc', CONV_MEM, API_DRIVER)), ('cuMemAllocHost', ('hipMemAllocHost', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemAllocManaged', ('hipMemAllocManaged', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemAllocPitch', ('hipMemAllocPitch__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy', ('hipMemcpy__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy2D', ('hipMemcpy2D__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy2DAsync', ('hipMemcpy2DAsync__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy2DUnaligned', ('hipMemcpy2DUnaligned', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy3D', ('hipMemcpy3D__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy3DAsync', ('hipMemcpy3DAsync__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy3DPeer', ('hipMemcpy3DPeer__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpy3DPeerAsync', ('hipMemcpy3DPeerAsync__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyAsync', ('hipMemcpyAsync__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyAtoA', ('hipMemcpyAtoA', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyAtoD', ('hipMemcpyAtoD', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyAtoH', ('hipMemcpyAtoH', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyAtoHAsync', ('hipMemcpyAtoHAsync', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyDtoA', ('hipMemcpyDtoA', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyDtoD_v2', ('hipMemcpyDtoD', CONV_MEM, API_DRIVER)), ('cuMemcpyDtoDAsync_v2', ('hipMemcpyDtoDAsync', CONV_MEM, API_DRIVER)), ('cuMemcpyDtoH_v2', ('hipMemcpyDtoH', CONV_MEM, API_DRIVER)), ('cuMemcpyDtoHAsync_v2', ('hipMemcpyDtoHAsync', CONV_MEM, API_DRIVER)), ('cuMemcpyHtoA', ('hipMemcpyHtoA', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyHtoAAsync', ('hipMemcpyHtoAAsync', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyHtoD_v2', ('hipMemcpyHtoD', CONV_MEM, API_DRIVER)), ('cuMemcpyHtoDAsync_v2', ('hipMemcpyHtoDAsync', CONV_MEM, API_DRIVER)), ('cuMemcpyPeerAsync', ('hipMemcpyPeerAsync__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemcpyPeer', ('hipMemcpyPeer__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemFree_v2', ('hipFree', CONV_MEM, API_DRIVER)), ('cuMemFreeHost', ('hipHostFree', CONV_MEM, API_DRIVER)), ('cuMemGetAddressRange', ('hipMemGetAddressRange', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemGetInfo_v2', ('hipMemGetInfo', CONV_MEM, API_DRIVER)), ('cuMemHostAlloc', ('hipHostMalloc', CONV_MEM, API_DRIVER)), ('cuMemHostGetDevicePointer', ('hipMemHostGetDevicePointer', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemHostGetFlags', ('hipMemHostGetFlags', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemHostRegister_v2', ('hipHostRegister', CONV_MEM, API_DRIVER)), ('cuMemHostUnregister', ('hipHostUnregister', CONV_MEM, API_DRIVER)), ('cuMemsetD16_v2', ('hipMemsetD16', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD16Async', ('hipMemsetD16Async', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD2D16_v2', ('hipMemsetD2D16', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD2D16Async', ('hipMemsetD2D16Async', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD2D32_v2', ('hipMemsetD2D32', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD2D32Async', ('hipMemsetD2D32Async', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD2D8_v2', ('hipMemsetD2D8', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD2D8Async', ('hipMemsetD2D8Async', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD32_v2', ('hipMemset', CONV_MEM, API_DRIVER)), ('cuMemsetD32Async', ('hipMemsetAsync', CONV_MEM, API_DRIVER)), ('cuMemsetD8_v2', ('hipMemsetD8', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemsetD8Async', ('hipMemsetD8Async', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMipmappedArrayCreate', ('hipMipmappedArrayCreate', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMipmappedArrayDestroy', ('hipMipmappedArrayDestroy', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMipmappedArrayGetLevel', ('hipMipmappedArrayGetLevel', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemPrefetchAsync', ('hipMemPrefetchAsync__', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemAdvise', ('hipMemAdvise', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemRangeGetAttribute', ('hipMemRangeGetAttribute', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuMemRangeGetAttributes', ('hipMemRangeGetAttributes', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuPointerGetAttribute', ('hipPointerGetAttribute', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuPointerGetAttributes', ('hipPointerGetAttributes', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('cuPointerSetAttribute', ('hipPointerSetAttribute', CONV_MEM, API_DRIVER, HIP_UNSUPPORTED)), ('CU_TR_FILTER_MODE_POINT', ('hipFilterModePoint', CONV_TEX, API_DRIVER)), ('CU_TR_FILTER_MODE_LINEAR', ('hipFilterModeLinear', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetAddress', ('hipTexRefGetAddress', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetAddressMode', ('hipTexRefGetAddressMode', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetArray', ('hipTexRefGetArray', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetBorderColor', ('hipTexRefGetBorderColor', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetFilterMode', ('hipTexRefGetFilterMode', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetFlags', ('hipTexRefGetFlags', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetFormat', ('hipTexRefGetFormat', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetMaxAnisotropy', ('hipTexRefGetMaxAnisotropy', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetMipmapFilterMode', ('hipTexRefGetMipmapFilterMode', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetMipmapLevelBias', ('hipTexRefGetMipmapLevelBias', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetMipmapLevelClamp', ('hipTexRefGetMipmapLevelClamp', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefGetMipmappedArray', ('hipTexRefGetMipmappedArray', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetAddress', ('hipTexRefSetAddress', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetAddress2D', ('hipTexRefSetAddress2D', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetAddressMode', ('hipTexRefSetAddressMode', CONV_TEX, API_DRIVER)), ('cuTexRefSetArray', ('hipTexRefSetArray', CONV_TEX, API_DRIVER)), ('cuTexRefSetBorderColor', ('hipTexRefSetBorderColor', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetFilterMode', ('hipTexRefSetFilterMode', CONV_TEX, API_DRIVER)), ('cuTexRefSetFlags', ('hipTexRefSetFlags', CONV_TEX, API_DRIVER)), ('cuTexRefSetFormat', ('hipTexRefSetFormat', CONV_TEX, API_DRIVER)), ('cuTexRefSetMaxAnisotropy', ('hipTexRefSetMaxAnisotropy', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetMipmapFilterMode', ('hipTexRefSetMipmapFilterMode', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetMipmapLevelBias', ('hipTexRefSetMipmapLevelBias', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetMipmapLevelClamp', ('hipTexRefSetMipmapLevelClamp', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefSetMipmappedArray', ('hipTexRefSetMipmappedArray', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefCreate', ('hipTexRefCreate', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexRefDestroy', ('hipTexRefDestroy', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuSurfRefGetArray', ('hipSurfRefGetArray', CONV_SURFACE, API_DRIVER, HIP_UNSUPPORTED)), ('cuSurfRefSetArray', ('hipSurfRefSetArray', CONV_SURFACE, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexObjectCreate', ('hipTexObjectCreate', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexObjectDestroy', ('hipTexObjectDestroy', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexObjectGetResourceDesc', ('hipTexObjectGetResourceDesc', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexObjectGetResourceViewDesc', ('hipTexObjectGetResourceViewDesc', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuTexObjectGetTextureDesc', ('hipTexObjectGetTextureDesc', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuSurfObjectCreate', ('hipSurfObjectCreate', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuSurfObjectDestroy', ('hipSurfObjectDestroy', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuSurfObjectGetResourceDesc', ('hipSurfObjectGetResourceDesc', CONV_TEX, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsMapResources', ('hipGraphicsMapResources', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsResourceGetMappedMipmappedArray', ('hipGraphicsResourceGetMappedMipmappedArray', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsResourceGetMappedPointer', ('hipGraphicsResourceGetMappedPointer', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsResourceSetMapFlags', ('hipGraphicsResourceSetMapFlags', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsSubResourceGetMappedArray', ('hipGraphicsSubResourceGetMappedArray', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsUnmapResources', ('hipGraphicsUnmapResources', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsUnregisterResource', ('hipGraphicsUnregisterResource', CONV_GRAPHICS, API_DRIVER, HIP_UNSUPPORTED)), ('cuProfilerInitialize', ('hipProfilerInitialize', CONV_OTHER, API_DRIVER, HIP_UNSUPPORTED)), ('cuProfilerStart', ('hipProfilerStart', CONV_OTHER, API_DRIVER)), ('cuProfilerStop', ('hipProfilerStop', CONV_OTHER, API_DRIVER)), ('CU_GL_DEVICE_LIST_ALL', ('HIP_GL_DEVICE_LIST_ALL', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GL_DEVICE_LIST_CURRENT_FRAME', ('HIP_GL_DEVICE_LIST_CURRENT_FRAME', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GL_DEVICE_LIST_NEXT_FRAME', ('HIP_GL_DEVICE_LIST_NEXT_FRAME', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLGetDevices', ('hipGLGetDevices', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsGLRegisterBuffer', ('hipGraphicsGLRegisterBuffer', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsGLRegisterImage', ('hipGraphicsGLRegisterImage', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuWGLGetDevice', ('hipWGLGetDevice', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GL_MAP_RESOURCE_FLAGS_NONE', ('HIP_GL_MAP_RESOURCE_FLAGS_NONE', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GL_MAP_RESOURCE_FLAGS_READ_ONLY', ('HIP_GL_MAP_RESOURCE_FLAGS_READ_ONLY', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CU_GL_MAP_RESOURCE_FLAGS_WRITE_DISCARD', ('HIP_GL_MAP_RESOURCE_FLAGS_WRITE_DISCARD', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLCtxCreate', ('hipGLCtxCreate', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLInit', ('hipGLInit', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLMapBufferObject', ('hipGLMapBufferObject', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLMapBufferObjectAsync', ('hipGLMapBufferObjectAsync', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLRegisterBufferObject', ('hipGLRegisterBufferObject', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLSetBufferObjectMapFlags', ('hipGLSetBufferObjectMapFlags', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLUnmapBufferObject', ('hipGLUnmapBufferObject', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLUnmapBufferObjectAsync', ('hipGLUnmapBufferObjectAsync', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGLUnregisterBufferObject', ('hipGLUnregisterBufferObject', CONV_GL, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_DEVICE_LIST_ALL', ('HIP_D3D9_DEVICE_LIST_ALL', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_DEVICE_LIST_CURRENT_FRAME', ('HIP_D3D9_DEVICE_LIST_CURRENT_FRAME', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_DEVICE_LIST_NEXT_FRAME', ('HIP_D3D9_DEVICE_LIST_NEXT_FRAME', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9CtxCreate', ('hipD3D9CtxCreate', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9CtxCreateOnDevice', ('hipD3D9CtxCreateOnDevice', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9GetDevice', ('hipD3D9GetDevice', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9GetDevices', ('hipD3D9GetDevices', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9GetDirect3DDevice', ('hipD3D9GetDirect3DDevice', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsD3D9RegisterResource', ('hipGraphicsD3D9RegisterResource', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_MAPRESOURCE_FLAGS_NONE', ('HIP_D3D9_MAPRESOURCE_FLAGS_NONE', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_MAPRESOURCE_FLAGS_READONLY', ('HIP_D3D9_MAPRESOURCE_FLAGS_READONLY', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_MAPRESOURCE_FLAGS_WRITEDISCARD', ('HIP_D3D9_MAPRESOURCE_FLAGS_WRITEDISCARD', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_REGISTER_FLAGS_NONE', ('HIP_D3D9_REGISTER_FLAGS_NONE', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D9_REGISTER_FLAGS_ARRAY', ('HIP_D3D9_REGISTER_FLAGS_ARRAY', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9MapResources', ('hipD3D9MapResources', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9RegisterResource', ('hipD3D9RegisterResource', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9ResourceGetMappedArray', ('hipD3D9ResourceGetMappedArray', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9ResourceGetMappedPitch', ('hipD3D9ResourceGetMappedPitch', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9ResourceGetMappedPointer', ('hipD3D9ResourceGetMappedPointer', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9ResourceGetMappedSize', ('hipD3D9ResourceGetMappedSize', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9ResourceGetSurfaceDimensions', ('hipD3D9ResourceGetSurfaceDimensions', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9ResourceSetMapFlags', ('hipD3D9ResourceSetMapFlags', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9UnmapResources', ('hipD3D9UnmapResources', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D9UnregisterResource', ('hipD3D9UnregisterResource', CONV_D3D9, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_DEVICE_LIST_ALL', ('HIP_D3D10_DEVICE_LIST_ALL', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_DEVICE_LIST_CURRENT_FRAME', ('HIP_D3D10_DEVICE_LIST_CURRENT_FRAME', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_DEVICE_LIST_NEXT_FRAME', ('HIP_D3D10_DEVICE_LIST_NEXT_FRAME', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10GetDevice', ('hipD3D10GetDevice', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10GetDevices', ('hipD3D10GetDevices', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsD3D10RegisterResource', ('hipGraphicsD3D10RegisterResource', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_MAPRESOURCE_FLAGS_NONE', ('HIP_D3D10_MAPRESOURCE_FLAGS_NONE', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_MAPRESOURCE_FLAGS_READONLY', ('HIP_D3D10_MAPRESOURCE_FLAGS_READONLY', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_MAPRESOURCE_FLAGS_WRITEDISCARD', ('HIP_D3D10_MAPRESOURCE_FLAGS_WRITEDISCARD', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_REGISTER_FLAGS_NONE', ('HIP_D3D10_REGISTER_FLAGS_NONE', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D10_REGISTER_FLAGS_ARRAY', ('HIP_D3D10_REGISTER_FLAGS_ARRAY', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10CtxCreate', ('hipD3D10CtxCreate', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10CtxCreateOnDevice', ('hipD3D10CtxCreateOnDevice', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10GetDirect3DDevice', ('hipD3D10GetDirect3DDevice', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10MapResources', ('hipD3D10MapResources', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10RegisterResource', ('hipD3D10RegisterResource', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10ResourceGetMappedArray', ('hipD3D10ResourceGetMappedArray', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10ResourceGetMappedPitch', ('hipD3D10ResourceGetMappedPitch', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10ResourceGetMappedPointer', ('hipD3D10ResourceGetMappedPointer', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10ResourceGetMappedSize', ('hipD3D10ResourceGetMappedSize', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10ResourceGetSurfaceDimensions', ('hipD3D10ResourceGetSurfaceDimensions', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD310ResourceSetMapFlags', ('hipD3D10ResourceSetMapFlags', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10UnmapResources', ('hipD3D10UnmapResources', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D10UnregisterResource', ('hipD3D10UnregisterResource', CONV_D3D10, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D11_DEVICE_LIST_ALL', ('HIP_D3D11_DEVICE_LIST_ALL', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D11_DEVICE_LIST_CURRENT_FRAME', ('HIP_D3D11_DEVICE_LIST_CURRENT_FRAME', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('CU_D3D11_DEVICE_LIST_NEXT_FRAME', ('HIP_D3D11_DEVICE_LIST_NEXT_FRAME', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D11GetDevice', ('hipD3D11GetDevice', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D11GetDevices', ('hipD3D11GetDevices', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsD3D11RegisterResource', ('hipGraphicsD3D11RegisterResource', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D11CtxCreate', ('hipD3D11CtxCreate', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D11CtxCreateOnDevice', ('hipD3D11CtxCreateOnDevice', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuD3D11GetDirect3DDevice', ('hipD3D11GetDirect3DDevice', CONV_D3D11, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsVDPAURegisterOutputSurface', ('hipGraphicsVDPAURegisterOutputSurface', CONV_VDPAU, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsVDPAURegisterVideoSurface', ('hipGraphicsVDPAURegisterVideoSurface', CONV_VDPAU, API_DRIVER, HIP_UNSUPPORTED)), ('cuVDPAUGetDevice', ('hipVDPAUGetDevice', CONV_VDPAU, API_DRIVER, HIP_UNSUPPORTED)), ('cuVDPAUCtxCreate', ('hipVDPAUCtxCreate', CONV_VDPAU, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamConsumerAcquireFrame', ('hipEGLStreamConsumerAcquireFrame', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamConsumerConnect', ('hipEGLStreamConsumerConnect', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamConsumerConnectWithFlags', ('hipEGLStreamConsumerConnectWithFlags', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamConsumerDisconnect', ('hipEGLStreamConsumerDisconnect', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamConsumerReleaseFrame', ('hipEGLStreamConsumerReleaseFrame', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamProducerConnect', ('hipEGLStreamProducerConnect', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamProducerDisconnect', ('hipEGLStreamProducerDisconnect', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamProducerPresentFrame', ('hipEGLStreamProducerPresentFrame', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuEGLStreamProducerReturnFrame', ('hipEGLStreamProducerReturnFrame', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsEGLRegisterImage', ('hipGraphicsEGLRegisterImage', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cuGraphicsResourceGetMappedEglFrame', ('hipGraphicsResourceGetMappedEglFrame', CONV_EGL, API_DRIVER, HIP_UNSUPPORTED)), ('cudaDataType_t', ('hipDataType_t', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDataType', ('hipDataType_t', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_16F', ('hipR16F', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_16F', ('hipC16F', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_32F', ('hipR32F', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_32F', ('hipC32F', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_64F', ('hipR64F', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_64F', ('hipC64F', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_8I', ('hipR8I', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_8I', ('hipC8I', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_8U', ('hipR8U', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_8U', ('hipC8U', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_32I', ('hipR32I', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_32I', ('hipC32I', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_R_32U', ('hipR32U', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('CUDA_C_32U', ('hipC32U', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('MAJOR_VERSION', ('hipLibraryMajorVersion', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('MINOR_VERSION', ('hipLibraryMinorVersion', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('PATCH_LEVEL', ('hipLibraryPatchVersion', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAttachGlobal', ('hipMemAttachGlobal', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAttachHost', ('hipMemAttachHost', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAttachSingle', ('hipMemAttachSingle', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaOccupancyDefault', ('hipOccupancyDefault', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaOccupancyDisableCachingOverride', ('hipOccupancyDisableCachingOverride', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetLastError', ('hipGetLastError', CONV_ERROR, API_RUNTIME)), ('cudaPeekAtLastError', ('hipPeekAtLastError', CONV_ERROR, API_RUNTIME)), ('cudaGetErrorName', ('hipGetErrorName', CONV_ERROR, API_RUNTIME)), ('cudaGetErrorString', ('hipGetErrorString', CONV_ERROR, API_RUNTIME)), ('cudaMemcpy3DParms', ('hipMemcpy3DParms', CONV_MEM, API_RUNTIME)), ('cudaMemcpy3DPeerParms', ('hipMemcpy3DPeerParms', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy', ('hipMemcpy', CONV_MEM, API_RUNTIME)), ('cudaMemcpyToArray', ('hipMemcpyToArray', CONV_MEM, API_RUNTIME)), ('cudaMemcpyToSymbol', ('hipMemcpyToSymbol', CONV_MEM, API_RUNTIME)), ('cudaMemcpyToSymbolAsync', ('hipMemcpyToSymbolAsync', CONV_MEM, API_RUNTIME)), ('cudaMemcpyAsync', ('hipMemcpyAsync', CONV_MEM, API_RUNTIME)), ('cudaMemcpy2D', ('hipMemcpy2D', CONV_MEM, API_RUNTIME)), ('cudaMemcpy2DAsync', ('hipMemcpy2DAsync', CONV_MEM, API_RUNTIME)), ('cudaMemcpy2DToArray', ('hipMemcpy2DToArray', CONV_MEM, API_RUNTIME)), ('cudaMemcpy2DArrayToArray', ('hipMemcpy2DArrayToArray', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy2DFromArray', ('hipMemcpy2DFromArray', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy2DFromArrayAsync', ('hipMemcpy2DFromArrayAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy2DToArrayAsync', ('hipMemcpy2DToArrayAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy3D', ('hipMemcpy3D', CONV_MEM, API_RUNTIME)), ('cudaMemcpy3DAsync', ('hipMemcpy3DAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy3DPeer', ('hipMemcpy3DPeer', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpy3DPeerAsync', ('hipMemcpy3DPeerAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpyArrayToArray', ('hipMemcpyArrayToArray', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpyFromArrayAsync', ('hipMemcpyFromArrayAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpyFromSymbol', ('hipMemcpyFromSymbol', CONV_MEM, API_RUNTIME)), ('cudaMemcpyFromSymbolAsync', ('hipMemcpyFromSymbolAsync', CONV_MEM, API_RUNTIME)), ('cudaMemAdvise', ('hipMemAdvise', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeGetAttribute', ('hipMemRangeGetAttribute', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeGetAttributes', ('hipMemRangeGetAttributes', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAdviseSetReadMostly', ('hipMemAdviseSetReadMostly', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAdviseUnsetReadMostly', ('hipMemAdviseUnsetReadMostly', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAdviseSetPreferredLocation', ('hipMemAdviseSetPreferredLocation', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAdviseUnsetPreferredLocation', ('hipMemAdviseUnsetPreferredLocation', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAdviseSetAccessedBy', ('hipMemAdviseSetAccessedBy', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemAdviseUnsetAccessedBy', ('hipMemAdviseUnsetAccessedBy', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeAttributeReadMostly', ('hipMemRangeAttributeReadMostly', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeAttributePreferredLocation', ('hipMemRangeAttributePreferredLocation', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeAttributeAccessedBy', ('hipMemRangeAttributeAccessedBy', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemRangeAttributeLastPrefetchLocation', ('hipMemRangeAttributeLastPrefetchLocation', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemcpyHostToHost', ('hipMemcpyHostToHost', CONV_MEM, API_RUNTIME)), ('cudaMemcpyHostToDevice', ('hipMemcpyHostToDevice', CONV_MEM, API_RUNTIME)), ('cudaMemcpyDeviceToHost', ('hipMemcpyDeviceToHost', CONV_MEM, API_RUNTIME)), ('cudaMemcpyDeviceToDevice', ('hipMemcpyDeviceToDevice', CONV_MEM, API_RUNTIME)), ('cudaMemcpyDefault', ('hipMemcpyDefault', CONV_MEM, API_RUNTIME)), ('cudaMemset', ('hipMemset', CONV_MEM, API_RUNTIME)), ('cudaMemsetAsync', ('hipMemsetAsync', CONV_MEM, API_RUNTIME)), ('cudaMemset2D', ('hipMemset2D', CONV_MEM, API_RUNTIME)), ('cudaMemset2DAsync', ('hipMemset2DAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemset3D', ('hipMemset3D', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemset3DAsync', ('hipMemset3DAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemGetInfo', ('hipMemGetInfo', CONV_MEM, API_RUNTIME)), ('cudaArrayGetInfo', ('hipArrayGetInfo', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaFreeMipmappedArray', ('hipFreeMipmappedArray', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetMipmappedArrayLevel', ('hipGetMipmappedArrayLevel', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetSymbolAddress', ('hipGetSymbolAddress', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetSymbolSize', ('hipGetSymbolSize', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMemPrefetchAsync', ('hipMemPrefetchAsync', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMallocHost', ('hipHostMalloc', CONV_MEM, API_RUNTIME)), ('cudaMallocArray', ('hipMallocArray', CONV_MEM, API_RUNTIME)), ('cudaMalloc', ('hipMalloc', CONV_MEM, API_RUNTIME)), ('cudaMalloc3D', ('hipMalloc3D', CONV_MEM, API_RUNTIME)), ('cudaMalloc3DArray', ('hipMalloc3DArray', CONV_MEM, API_RUNTIME)), ('cudaMallocManaged', ('hipMallocManaged', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMallocMipmappedArray', ('hipMallocMipmappedArray', CONV_MEM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaMallocPitch', ('hipMallocPitch', CONV_MEM, API_RUNTIME)), ('cudaFreeHost', ('hipHostFree', CONV_MEM, API_RUNTIME)), ('cudaFreeArray', ('hipFreeArray', CONV_MEM, API_RUNTIME)), ('cudaFree', ('hipFree', CONV_MEM, API_RUNTIME)), ('cudaHostRegister', ('hipHostRegister', CONV_MEM, API_RUNTIME)), ('cudaHostUnregister', ('hipHostUnregister', CONV_MEM, API_RUNTIME)), ('cudaHostAlloc', ('hipHostMalloc', CONV_MEM, API_RUNTIME)), ('cudaMemoryTypeHost', ('hipMemoryTypeHost', CONV_MEM, API_RUNTIME)), ('cudaMemoryTypeDevice', ('hipMemoryTypeDevice', CONV_MEM, API_RUNTIME)), ('make_cudaExtent', ('make_hipExtent', CONV_MEM, API_RUNTIME)), ('make_cudaPitchedPtr', ('make_hipPitchedPtr', CONV_MEM, API_RUNTIME)), ('make_cudaPos', ('make_hipPos', CONV_MEM, API_RUNTIME)), ('cudaHostAllocDefault', ('hipHostMallocDefault', CONV_MEM, API_RUNTIME)), ('cudaHostAllocPortable', ('hipHostMallocPortable', CONV_MEM, API_RUNTIME)), ('cudaHostAllocMapped', ('hipHostMallocMapped', CONV_MEM, API_RUNTIME)), ('cudaHostAllocWriteCombined', ('hipHostMallocWriteCombined', CONV_MEM, API_RUNTIME)), ('cudaHostGetFlags', ('hipHostGetFlags', CONV_MEM, API_RUNTIME)), ('cudaHostRegisterDefault', ('hipHostRegisterDefault', CONV_MEM, API_RUNTIME)), ('cudaHostRegisterPortable', ('hipHostRegisterPortable', CONV_MEM, API_RUNTIME)), ('cudaHostRegisterMapped', ('hipHostRegisterMapped', CONV_MEM, API_RUNTIME)), ('cudaHostRegisterIoMemory', ('hipHostRegisterIoMemory', CONV_MEM, API_RUNTIME)), ('cudaEventCreate', ('hipEventCreate', CONV_EVENT, API_RUNTIME)), ('cudaEventCreateWithFlags', ('hipEventCreateWithFlags', CONV_EVENT, API_RUNTIME)), ('cudaEventDestroy', ('hipEventDestroy', CONV_EVENT, API_RUNTIME)), ('cudaEventRecord', ('hipEventRecord', CONV_EVENT, API_RUNTIME)), ('cudaEventElapsedTime', ('hipEventElapsedTime', CONV_EVENT, API_RUNTIME)), ('cudaEventSynchronize', ('hipEventSynchronize', CONV_EVENT, API_RUNTIME)), ('cudaEventQuery', ('hipEventQuery', CONV_EVENT, API_RUNTIME)), ('cudaEventDefault', ('hipEventDefault', CONV_EVENT, API_RUNTIME)), ('cudaEventBlockingSync', ('hipEventBlockingSync', CONV_EVENT, API_RUNTIME)), ('cudaEventDisableTiming', ('hipEventDisableTiming', CONV_EVENT, API_RUNTIME)), ('cudaEventInterprocess', ('hipEventInterprocess', CONV_EVENT, API_RUNTIME)), ('cudaStreamCreate', ('hipStreamCreate', CONV_STREAM, API_RUNTIME)), ('cudaStreamCreateWithFlags', ('hipStreamCreateWithFlags', CONV_STREAM, API_RUNTIME)), ('cudaStreamCreateWithPriority', ('hipStreamCreateWithPriority', CONV_STREAM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaStreamDestroy', ('hipStreamDestroy', CONV_STREAM, API_RUNTIME)), ('cudaStreamWaitEvent', ('hipStreamWaitEvent', CONV_STREAM, API_RUNTIME)), ('cudaStreamSynchronize', ('hipStreamSynchronize', CONV_STREAM, API_RUNTIME)), ('cudaStreamGetFlags', ('hipStreamGetFlags', CONV_STREAM, API_RUNTIME)), ('cudaStreamQuery', ('hipStreamQuery', CONV_STREAM, API_RUNTIME)), ('cudaStreamAddCallback', ('hipStreamAddCallback', CONV_STREAM, API_RUNTIME)), ('cudaStreamAttachMemAsync', ('hipStreamAttachMemAsync', CONV_STREAM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaStreamGetPriority', ('hipStreamGetPriority', CONV_STREAM, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaStreamDefault', ('hipStreamDefault', CONV_TYPE, API_RUNTIME)), ('cudaStreamNonBlocking', ('hipStreamNonBlocking', CONV_TYPE, API_RUNTIME)), ('cudaDeviceSynchronize', ('hipDeviceSynchronize', CONV_DEVICE, API_RUNTIME)), ('cudaDeviceReset', ('hipDeviceReset', CONV_DEVICE, API_RUNTIME)), ('cudaSetDevice', ('hipSetDevice', CONV_DEVICE, API_RUNTIME)), ('cudaGetDevice', ('hipGetDevice', CONV_DEVICE, API_RUNTIME)), ('cudaGetDeviceCount', ('hipGetDeviceCount', CONV_DEVICE, API_RUNTIME)), ('cudaChooseDevice', ('hipChooseDevice', CONV_DEVICE, API_RUNTIME)), ('cudaThreadExit', ('hipDeviceReset', CONV_THREAD, API_RUNTIME)), ('cudaThreadGetCacheConfig', ('hipDeviceGetCacheConfig', CONV_THREAD, API_RUNTIME)), ('cudaThreadGetLimit', ('hipThreadGetLimit', CONV_THREAD, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaThreadSetCacheConfig', ('hipDeviceSetCacheConfig', CONV_THREAD, API_RUNTIME)), ('cudaThreadSetLimit', ('hipThreadSetLimit', CONV_THREAD, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaThreadSynchronize', ('hipDeviceSynchronize', CONV_THREAD, API_RUNTIME)), ('cudaDeviceGetAttribute', ('hipDeviceGetAttribute', CONV_DEVICE, API_RUNTIME)), ('cudaDevAttrMaxThreadsPerBlock', ('hipDeviceAttributeMaxThreadsPerBlock', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxBlockDimX', ('hipDeviceAttributeMaxBlockDimX', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxBlockDimY', ('hipDeviceAttributeMaxBlockDimY', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxBlockDimZ', ('hipDeviceAttributeMaxBlockDimZ', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxGridDimX', ('hipDeviceAttributeMaxGridDimX', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxGridDimY', ('hipDeviceAttributeMaxGridDimY', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxGridDimZ', ('hipDeviceAttributeMaxGridDimZ', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxSharedMemoryPerBlock', ('hipDeviceAttributeMaxSharedMemoryPerBlock', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrTotalConstantMemory', ('hipDeviceAttributeTotalConstantMemory', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrWarpSize', ('hipDeviceAttributeWarpSize', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxPitch', ('hipDeviceAttributeMaxPitch', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxRegistersPerBlock', ('hipDeviceAttributeMaxRegistersPerBlock', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrClockRate', ('hipDeviceAttributeClockRate', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrTextureAlignment', ('hipDeviceAttributeTextureAlignment', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrGpuOverlap', ('hipDeviceAttributeGpuOverlap', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMultiProcessorCount', ('hipDeviceAttributeMultiprocessorCount', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrKernelExecTimeout', ('hipDeviceAttributeKernelExecTimeout', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrIntegrated', ('hipDeviceAttributeIntegrated', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrCanMapHostMemory', ('hipDeviceAttributeCanMapHostMemory', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrComputeMode', ('hipDeviceAttributeComputeMode', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxTexture1DWidth', ('hipDeviceAttributeMaxTexture1DWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DWidth', ('hipDeviceAttributeMaxTexture2DWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DHeight', ('hipDeviceAttributeMaxTexture2DHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture3DWidth', ('hipDeviceAttributeMaxTexture3DWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture3DHeight', ('hipDeviceAttributeMaxTexture3DHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture3DDepth', ('hipDeviceAttributeMaxTexture3DDepth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DLayeredWidth', ('hipDeviceAttributeMaxTexture2DLayeredWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DLayeredHeight', ('hipDeviceAttributeMaxTexture2DLayeredHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DLayeredLayers', ('hipDeviceAttributeMaxTexture2DLayeredLayers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrSurfaceAlignment', ('hipDeviceAttributeSurfaceAlignment', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrConcurrentKernels', ('hipDeviceAttributeConcurrentKernels', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrEccEnabled', ('hipDeviceAttributeEccEnabled', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrPciBusId', ('hipDeviceAttributePciBusId', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrPciDeviceId', ('hipDeviceAttributePciDeviceId', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrTccDriver', ('hipDeviceAttributeTccDriver', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMemoryClockRate', ('hipDeviceAttributeMemoryClockRate', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrGlobalMemoryBusWidth', ('hipDeviceAttributeMemoryBusWidth', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrL2CacheSize', ('hipDeviceAttributeL2CacheSize', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxThreadsPerMultiProcessor', ('hipDeviceAttributeMaxThreadsPerMultiProcessor', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrAsyncEngineCount', ('hipDeviceAttributeAsyncEngineCount', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrUnifiedAddressing', ('hipDeviceAttributeUnifiedAddressing', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture1DLayeredWidth', ('hipDeviceAttributeMaxTexture1DLayeredWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture1DLayeredLayers', ('hipDeviceAttributeMaxTexture1DLayeredLayers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DGatherWidth', ('hipDeviceAttributeMaxTexture2DGatherWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DGatherHeight', ('hipDeviceAttributeMaxTexture2DGatherHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture3DWidthAlt', ('hipDeviceAttributeMaxTexture3DWidthAlternate', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture3DHeightAlt', ('hipDeviceAttributeMaxTexture3DHeightAlternate', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture3DDepthAlt', ('hipDeviceAttributeMaxTexture3DDepthAlternate', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrPciDomainId', ('hipDeviceAttributePciDomainId', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrTexturePitchAlignment', ('hipDeviceAttributeTexturePitchAlignment', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTextureCubemapWidth', ('hipDeviceAttributeMaxTextureCubemapWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTextureCubemapLayeredWidth', ('hipDeviceAttributeMaxTextureCubemapLayeredWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTextureCubemapLayeredLayers', ('hipDeviceAttributeMaxTextureCubemapLayeredLayers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface1DWidth', ('hipDeviceAttributeMaxSurface1DWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface2DWidth', ('hipDeviceAttributeMaxSurface2DWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface2DHeight', ('hipDeviceAttributeMaxSurface2DHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface3DWidth', ('hipDeviceAttributeMaxSurface3DWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface3DHeight', ('hipDeviceAttributeMaxSurface3DHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface3DDepth', ('hipDeviceAttributeMaxSurface3DDepth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface1DLayeredWidth', ('hipDeviceAttributeMaxSurface1DLayeredWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface1DLayeredLayers', ('hipDeviceAttributeMaxSurface1DLayeredLayers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface2DLayeredWidth', ('hipDeviceAttributeMaxSurface2DLayeredWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface2DLayeredHeight', ('hipDeviceAttributeMaxSurface2DLayeredHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurface2DLayeredLayers', ('hipDeviceAttributeMaxSurface2DLayeredLayers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurfaceCubemapWidth', ('hipDeviceAttributeMaxSurfaceCubemapWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurfaceCubemapLayeredWidth', ('hipDeviceAttributeMaxSurfaceCubemapLayeredWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSurfaceCubemapLayeredLayers', ('hipDeviceAttributeMaxSurfaceCubemapLayeredLayers', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture1DLinearWidth', ('hipDeviceAttributeMaxTexture1DLinearWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DLinearWidth', ('hipDeviceAttributeMaxTexture2DLinearWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DLinearHeight', ('hipDeviceAttributeMaxTexture2DLinearHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DLinearPitch', ('hipDeviceAttributeMaxTexture2DLinearPitch', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DMipmappedWidth', ('hipDeviceAttributeMaxTexture2DMipmappedWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxTexture2DMipmappedHeight', ('hipDeviceAttributeMaxTexture2DMipmappedHeight', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrComputeCapabilityMajor', ('hipDeviceAttributeComputeCapabilityMajor', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrComputeCapabilityMinor', ('hipDeviceAttributeComputeCapabilityMinor', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxTexture1DMipmappedWidth', ('hipDeviceAttributeMaxTexture1DMipmappedWidth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrStreamPrioritiesSupported', ('hipDeviceAttributeStreamPrioritiesSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrGlobalL1CacheSupported', ('hipDeviceAttributeGlobalL1CacheSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrLocalL1CacheSupported', ('hipDeviceAttributeLocalL1CacheSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrMaxSharedMemoryPerMultiprocessor', ('hipDeviceAttributeMaxSharedMemoryPerMultiprocessor', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMaxRegistersPerMultiprocessor', ('hipDeviceAttributeMaxRegistersPerMultiprocessor', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrManagedMemory', ('hipDeviceAttributeManagedMemory', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrIsMultiGpuBoard', ('hipDeviceAttributeIsMultiGpuBoard', CONV_TYPE, API_RUNTIME)), ('cudaDevAttrMultiGpuBoardGroupID', ('hipDeviceAttributeMultiGpuBoardGroupID', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrHostNativeAtomicSupported', ('hipDeviceAttributeHostNativeAtomicSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrSingleToDoublePrecisionPerfRatio', ('hipDeviceAttributeSingleToDoublePrecisionPerfRatio', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrPageableMemoryAccess', ('hipDeviceAttributePageableMemoryAccess', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrConcurrentManagedAccess', ('hipDeviceAttributeConcurrentManagedAccess', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrComputePreemptionSupported', ('hipDeviceAttributeComputePreemptionSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevAttrCanUseHostPointerForRegisteredMem', ('hipDeviceAttributeCanUseHostPointerForRegisteredMem', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaPointerGetAttributes', ('hipPointerGetAttributes', CONV_MEM, API_RUNTIME)), ('cudaHostGetDevicePointer', ('hipHostGetDevicePointer', CONV_MEM, API_RUNTIME)), ('cudaGetDeviceProperties', ('hipGetDeviceProperties', CONV_DEVICE, API_RUNTIME)), ('cudaDeviceGetPCIBusId', ('hipDeviceGetPCIBusId', CONV_DEVICE, API_RUNTIME)), ('cudaDeviceGetByPCIBusId', ('hipDeviceGetByPCIBusId', CONV_DEVICE, API_RUNTIME)), ('cudaDeviceGetStreamPriorityRange', ('hipDeviceGetStreamPriorityRange', CONV_DEVICE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSetValidDevices', ('hipSetValidDevices', CONV_DEVICE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevP2PAttrPerformanceRank', ('hipDeviceP2PAttributePerformanceRank', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevP2PAttrAccessSupported', ('hipDeviceP2PAttributeAccessSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDevP2PAttrNativeAtomicSupported', ('hipDeviceP2PAttributeNativeAtomicSupported', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDeviceGetP2PAttribute', ('hipDeviceGetP2PAttribute', CONV_DEVICE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaComputeModeDefault', ('hipComputeModeDefault', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaComputeModeExclusive', ('hipComputeModeExclusive', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaComputeModeProhibited', ('hipComputeModeProhibited', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaComputeModeExclusiveProcess', ('hipComputeModeExclusiveProcess', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetDeviceFlags', ('hipGetDeviceFlags', CONV_DEVICE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSetDeviceFlags', ('hipSetDeviceFlags', CONV_DEVICE, API_RUNTIME)), ('cudaDeviceScheduleAuto', ('hipDeviceScheduleAuto', CONV_TYPE, API_RUNTIME)), ('cudaDeviceScheduleSpin', ('hipDeviceScheduleSpin', CONV_TYPE, API_RUNTIME)), ('cudaDeviceScheduleYield', ('hipDeviceScheduleYield', CONV_TYPE, API_RUNTIME)), ('cudaDeviceBlockingSync', ('hipDeviceScheduleBlockingSync', CONV_TYPE, API_RUNTIME)), ('cudaDeviceScheduleBlockingSync', ('hipDeviceScheduleBlockingSync', CONV_TYPE, API_RUNTIME)), ('cudaDeviceScheduleMask', ('hipDeviceScheduleMask', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDeviceMapHost', ('hipDeviceMapHost', CONV_TYPE, API_RUNTIME)), ('cudaDeviceLmemResizeToMax', ('hipDeviceLmemResizeToMax', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDeviceMask', ('hipDeviceMask', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDeviceSetCacheConfig', ('hipDeviceSetCacheConfig', CONV_CACHE, API_RUNTIME)), ('cudaDeviceGetCacheConfig', ('hipDeviceGetCacheConfig', CONV_CACHE, API_RUNTIME)), ('cudaFuncSetCacheConfig', ('hipFuncSetCacheConfig', CONV_CACHE, API_RUNTIME)), ('cudaFuncCachePreferNone', ('hipFuncCachePreferNone', CONV_CACHE, API_RUNTIME)), ('cudaFuncCachePreferShared', ('hipFuncCachePreferShared', CONV_CACHE, API_RUNTIME)), ('cudaFuncCachePreferL1', ('hipFuncCachePreferL1', CONV_CACHE, API_RUNTIME)), ('cudaFuncCachePreferEqual', ('hipFuncCachePreferEqual', CONV_CACHE, API_RUNTIME)), ('cudaFuncGetAttributes', ('hipFuncGetAttributes', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaFuncSetSharedMemConfig', ('hipFuncSetSharedMemConfig', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetParameterBuffer', ('hipGetParameterBuffer', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSetDoubleForDevice', ('hipSetDoubleForDevice', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSetDoubleForHost', ('hipSetDoubleForHost', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaConfigureCall', ('hipConfigureCall', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaLaunch', ('hipLaunch', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaSetupArgument', ('hipSetupArgument', CONV_EXEC, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDriverGetVersion', ('hipDriverGetVersion', CONV_VERSION, API_RUNTIME)), ('cudaRuntimeGetVersion', ('hipRuntimeGetVersion', CONV_VERSION, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaOccupancyMaxPotentialBlockSize', ('hipOccupancyMaxPotentialBlockSize', CONV_OCCUPANCY, API_RUNTIME)), ('cudaOccupancyMaxPotentialBlockSizeWithFlags', ('hipOccupancyMaxPotentialBlockSizeWithFlags', CONV_OCCUPANCY, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaOccupancyMaxActiveBlocksPerMultiprocessor', ('hipOccupancyMaxActiveBlocksPerMultiprocessor', CONV_OCCUPANCY, API_RUNTIME)), ('cudaOccupancyMaxActiveBlocksPerMultiprocessorWithFlags', ('hipOccupancyMaxActiveBlocksPerMultiprocessorWithFlags', CONV_OCCUPANCY, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaOccupancyMaxPotentialBlockSizeVariableSMem', ('hipOccupancyMaxPotentialBlockSizeVariableSMem', CONV_OCCUPANCY, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaOccupancyMaxPotentialBlockSizeVariableSMemWithFlags', ('hipOccupancyMaxPotentialBlockSizeVariableSMemWithFlags', CONV_OCCUPANCY, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDeviceCanAccessPeer', ('hipDeviceCanAccessPeer', CONV_PEER, API_RUNTIME)), ('cudaDeviceDisablePeerAccess', ('hipDeviceDisablePeerAccess', CONV_PEER, API_RUNTIME)), ('cudaDeviceEnablePeerAccess', ('hipDeviceEnablePeerAccess', CONV_PEER, API_RUNTIME)), ('cudaMemcpyPeerAsync', ('hipMemcpyPeerAsync', CONV_MEM, API_RUNTIME)), ('cudaMemcpyPeer', ('hipMemcpyPeer', CONV_MEM, API_RUNTIME)), ('cudaIpcMemLazyEnablePeerAccess', ('hipIpcMemLazyEnablePeerAccess', CONV_TYPE, API_RUNTIME)), ('cudaDeviceSetSharedMemConfig', ('hipDeviceSetSharedMemConfig', CONV_DEVICE, API_RUNTIME)), ('cudaDeviceGetSharedMemConfig', ('hipDeviceGetSharedMemConfig', CONV_DEVICE, API_RUNTIME)), ('cudaSharedMemBankSizeDefault', ('hipSharedMemBankSizeDefault', CONV_TYPE, API_RUNTIME)), ('cudaSharedMemBankSizeFourByte', ('hipSharedMemBankSizeFourByte', CONV_TYPE, API_RUNTIME)), ('cudaSharedMemBankSizeEightByte', ('hipSharedMemBankSizeEightByte', CONV_TYPE, API_RUNTIME)), ('cudaLimitStackSize', ('hipLimitStackSize', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaLimitPrintfFifoSize', ('hipLimitPrintfFifoSize', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaLimitMallocHeapSize', ('hipLimitMallocHeapSize', CONV_TYPE, API_RUNTIME)), ('cudaLimitDevRuntimeSyncDepth', ('hipLimitDevRuntimeSyncDepth', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaLimitDevRuntimePendingLaunchCount', ('hipLimitDevRuntimePendingLaunchCount', CONV_TYPE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDeviceGetLimit', ('hipDeviceGetLimit', CONV_DEVICE, API_RUNTIME)), ('cudaProfilerInitialize', ('hipProfilerInitialize', CONV_OTHER, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaProfilerStart', ('hipProfilerStart', CONV_OTHER, API_RUNTIME)), ('cudaProfilerStop', ('hipProfilerStop', CONV_OTHER, API_RUNTIME)), ('cudaKeyValuePair', ('hipKeyValuePair', CONV_OTHER, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaCSV', ('hipCSV', CONV_OTHER, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaReadModeElementType', ('hipReadModeElementType', CONV_TEX, API_RUNTIME)), ('cudaReadModeNormalizedFloat', ('hipReadModeNormalizedFloat', CONV_TEX, API_RUNTIME)), ('cudaFilterModePoint', ('hipFilterModePoint', CONV_TEX, API_RUNTIME)), ('cudaFilterModeLinear', ('hipFilterModeLinear', CONV_TEX, API_RUNTIME)), ('cudaBindTexture', ('hipBindTexture', CONV_TEX, API_RUNTIME)), ('cudaUnbindTexture', ('hipUnbindTexture', CONV_TEX, API_RUNTIME)), ('cudaBindTexture2D', ('hipBindTexture2D', CONV_TEX, API_RUNTIME)), ('cudaBindTextureToArray', ('hipBindTextureToArray', CONV_TEX, API_RUNTIME)), ('cudaBindTextureToMipmappedArray', ('hipBindTextureToMipmappedArray', CONV_TEX, API_RUNTIME)), ('cudaGetTextureAlignmentOffset', ('hipGetTextureAlignmentOffset', CONV_TEX, API_RUNTIME)), ('cudaGetTextureReference', ('hipGetTextureReference', CONV_TEX, API_RUNTIME)), ('cudaChannelFormatKindSigned', ('hipChannelFormatKindSigned', CONV_TEX, API_RUNTIME)), ('cudaChannelFormatKindUnsigned', ('hipChannelFormatKindUnsigned', CONV_TEX, API_RUNTIME)), ('cudaChannelFormatKindFloat', ('hipChannelFormatKindFloat', CONV_TEX, API_RUNTIME)), ('cudaChannelFormatKindNone', ('hipChannelFormatKindNone', CONV_TEX, API_RUNTIME)), ('cudaCreateChannelDesc', ('hipCreateChannelDesc', CONV_TEX, API_RUNTIME)), ('cudaGetChannelDesc', ('hipGetChannelDesc', CONV_TEX, API_RUNTIME)), ('cudaResourceTypeArray', ('hipResourceTypeArray', CONV_TEX, API_RUNTIME)), ('cudaResourceTypeMipmappedArray', ('hipResourceTypeMipmappedArray', CONV_TEX, API_RUNTIME)), ('cudaResourceTypeLinear', ('hipResourceTypeLinear', CONV_TEX, API_RUNTIME)), ('cudaResourceTypePitch2D', ('hipResourceTypePitch2D', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatNone', ('hipResViewFormatNone', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedChar1', ('hipResViewFormatUnsignedChar1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedChar2', ('hipResViewFormatUnsignedChar2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedChar4', ('hipResViewFormatUnsignedChar4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedChar1', ('hipResViewFormatSignedChar1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedChar2', ('hipResViewFormatSignedChar2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedChar4', ('hipResViewFormatSignedChar4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedShort1', ('hipResViewFormatUnsignedShort1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedShort2', ('hipResViewFormatUnsignedShort2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedShort4', ('hipResViewFormatUnsignedShort4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedShort1', ('hipResViewFormatSignedShort1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedShort2', ('hipResViewFormatSignedShort2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedShort4', ('hipResViewFormatSignedShort4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedInt1', ('hipResViewFormatUnsignedInt1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedInt2', ('hipResViewFormatUnsignedInt2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedInt4', ('hipResViewFormatUnsignedInt4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedInt1', ('hipResViewFormatSignedInt1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedInt2', ('hipResViewFormatSignedInt2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedInt4', ('hipResViewFormatSignedInt4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatHalf1', ('hipResViewFormatHalf1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatHalf2', ('hipResViewFormatHalf2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatHalf4', ('hipResViewFormatHalf4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatFloat1', ('hipResViewFormatFloat1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatFloat2', ('hipResViewFormatFloat2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatFloat4', ('hipResViewFormatFloat4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed1', ('hipResViewFormatUnsignedBlockCompressed1', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed2', ('hipResViewFormatUnsignedBlockCompressed2', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed3', ('hipResViewFormatUnsignedBlockCompressed3', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed4', ('hipResViewFormatUnsignedBlockCompressed4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedBlockCompressed4', ('hipResViewFormatSignedBlockCompressed4', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed5', ('hipResViewFormatUnsignedBlockCompressed5', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedBlockCompressed5', ('hipResViewFormatSignedBlockCompressed5', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed6H', ('hipResViewFormatUnsignedBlockCompressed6H', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatSignedBlockCompressed6H', ('hipResViewFormatSignedBlockCompressed6H', CONV_TEX, API_RUNTIME)), ('cudaResViewFormatUnsignedBlockCompressed7', ('hipResViewFormatUnsignedBlockCompressed7', CONV_TEX, API_RUNTIME)), ('cudaAddressModeWrap', ('hipAddressModeWrap', CONV_TEX, API_RUNTIME)), ('cudaAddressModeClamp', ('hipAddressModeClamp', CONV_TEX, API_RUNTIME)), ('cudaAddressModeMirror', ('hipAddressModeMirror', CONV_TEX, API_RUNTIME)), ('cudaAddressModeBorder', ('hipAddressModeBorder', CONV_TEX, API_RUNTIME)), ('cudaCreateTextureObject', ('hipCreateTextureObject', CONV_TEX, API_RUNTIME)), ('cudaDestroyTextureObject', ('hipDestroyTextureObject', CONV_TEX, API_RUNTIME)), ('cudaGetTextureObjectResourceDesc', ('hipGetTextureObjectResourceDesc', CONV_TEX, API_RUNTIME)), ('cudaGetTextureObjectResourceViewDesc', ('hipGetTextureObjectResourceViewDesc', CONV_TEX, API_RUNTIME)), ('cudaGetTextureObjectTextureDesc', ('hipGetTextureObjectTextureDesc', CONV_TEX, API_RUNTIME)), ('cudaBindSurfaceToArray', ('hipBindSurfaceToArray', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetSurfaceReference', ('hipGetSurfaceReference', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaBoundaryModeZero', ('hipBoundaryModeZero', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaBoundaryModeClamp', ('hipBoundaryModeClamp', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaBoundaryModeTrap', ('hipBoundaryModeTrap', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaFormatModeForced', ('hipFormatModeForced', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaFormatModeAuto', ('hipFormatModeAuto', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaCreateSurfaceObject', ('hipCreateSurfaceObject', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaDestroySurfaceObject', ('hipDestroySurfaceObject', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGetSurfaceObjectResourceDesc', ('hipGetSurfaceObjectResourceDesc', CONV_SURFACE, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaIpcCloseMemHandle', ('hipIpcCloseMemHandle', CONV_DEVICE, API_RUNTIME)), ('cudaIpcGetEventHandle', ('hipIpcGetEventHandle', CONV_DEVICE, API_RUNTIME)), ('cudaIpcGetMemHandle', ('hipIpcGetMemHandle', CONV_DEVICE, API_RUNTIME)), ('cudaIpcOpenEventHandle', ('hipIpcOpenEventHandle', CONV_DEVICE, API_RUNTIME)), ('cudaIpcOpenMemHandle', ('hipIpcOpenMemHandle', CONV_DEVICE, API_RUNTIME)), ('cudaGLGetDevices', ('hipGLGetDevices', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsGLRegisterBuffer', ('hipGraphicsGLRegisterBuffer', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsGLRegisterImage', ('hipGraphicsGLRegisterImage', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaWGLGetDevice', ('hipWGLGetDevice', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsMapResources', ('hipGraphicsMapResources', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsResourceGetMappedMipmappedArray', ('hipGraphicsResourceGetMappedMipmappedArray', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsResourceGetMappedPointer', ('hipGraphicsResourceGetMappedPointer', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsResourceSetMapFlags', ('hipGraphicsResourceSetMapFlags', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsSubResourceGetMappedArray', ('hipGraphicsSubResourceGetMappedArray', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsUnmapResources', ('hipGraphicsUnmapResources', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsUnregisterResource', ('hipGraphicsUnregisterResource', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsCubeFacePositiveX', ('hipGraphicsCubeFacePositiveX', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsCubeFaceNegativeX', ('hipGraphicsCubeFaceNegativeX', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsCubeFacePositiveY', ('hipGraphicsCubeFacePositiveY', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsCubeFaceNegativeY', ('hipGraphicsCubeFaceNegativeY', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsCubeFacePositiveZ', ('hipGraphicsCubeFacePositiveZ', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsCubeFaceNegativeZ', ('hipGraphicsCubeFaceNegativeZ', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsMapFlagsNone', ('hipGraphicsMapFlagsNone', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsMapFlagsReadOnly', ('hipGraphicsMapFlagsReadOnly', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsMapFlagsWriteDiscard', ('hipGraphicsMapFlagsWriteDiscard', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsRegisterFlagsNone', ('hipGraphicsRegisterFlagsNone', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsRegisterFlagsReadOnly', ('hipGraphicsRegisterFlagsReadOnly', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsRegisterFlagsWriteDiscard', ('hipGraphicsRegisterFlagsWriteDiscard', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsRegisterFlagsSurfaceLoadStore', ('hipGraphicsRegisterFlagsSurfaceLoadStore', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsRegisterFlagsTextureGather', ('hipGraphicsRegisterFlagsTextureGather', CONV_GRAPHICS, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLDeviceListAll', ('HIP_GL_DEVICE_LIST_ALL', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLDeviceListCurrentFrame', ('HIP_GL_DEVICE_LIST_CURRENT_FRAME', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLDeviceListNextFrame', ('HIP_GL_DEVICE_LIST_NEXT_FRAME', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLGetDevices', ('hipGLGetDevices', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsGLRegisterBuffer', ('hipGraphicsGLRegisterBuffer', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsGLRegisterImage', ('hipGraphicsGLRegisterImage', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaWGLGetDevice', ('hipWGLGetDevice', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLMapFlagsNone', ('HIP_GL_MAP_RESOURCE_FLAGS_NONE', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLMapFlagsReadOnly', ('HIP_GL_MAP_RESOURCE_FLAGS_READ_ONLY', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLMapFlagsWriteDiscard', ('HIP_GL_MAP_RESOURCE_FLAGS_WRITE_DISCARD', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLMapBufferObject', ('hipGLMapBufferObject__', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLMapBufferObjectAsync', ('hipGLMapBufferObjectAsync__', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLRegisterBufferObject', ('hipGLRegisterBufferObject', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLSetBufferObjectMapFlags', ('hipGLSetBufferObjectMapFlags', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLSetGLDevice', ('hipGLSetGLDevice', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLUnmapBufferObject', ('hipGLUnmapBufferObject', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLUnmapBufferObjectAsync', ('hipGLUnmapBufferObjectAsync', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGLUnregisterBufferObject', ('hipGLUnregisterBufferObject', CONV_GL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9DeviceListAll', ('HIP_D3D9_DEVICE_LIST_ALL', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9DeviceListCurrentFrame', ('HIP_D3D9_DEVICE_LIST_CURRENT_FRAME', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9DeviceListNextFrame', ('HIP_D3D9_DEVICE_LIST_NEXT_FRAME', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9GetDevice', ('hipD3D9GetDevice', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9GetDevices', ('hipD3D9GetDevices', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9GetDirect3DDevice', ('hipD3D9GetDirect3DDevice', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9SetDirect3DDevice', ('hipD3D9SetDirect3DDevice', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsD3D9RegisterResource', ('hipGraphicsD3D9RegisterResource', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9MapFlags', ('hipD3D9MapFlags', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9MapFlagsNone', ('HIP_D3D9_MAPRESOURCE_FLAGS_NONE', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9MapFlagsReadOnly', ('HIP_D3D9_MAPRESOURCE_FLAGS_READONLY', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9MapFlagsWriteDiscard', ('HIP_D3D9_MAPRESOURCE_FLAGS_WRITEDISCARD', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9RegisterFlagsNone', ('HIP_D3D9_REGISTER_FLAGS_NONE', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9RegisterFlagsArray', ('HIP_D3D9_REGISTER_FLAGS_ARRAY', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9MapResources', ('hipD3D9MapResources', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9RegisterResource', ('hipD3D9RegisterResource', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9ResourceGetMappedArray', ('hipD3D9ResourceGetMappedArray', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9ResourceGetMappedPitch', ('hipD3D9ResourceGetMappedPitch', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9ResourceGetMappedPointer', ('hipD3D9ResourceGetMappedPointer', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9ResourceGetMappedSize', ('hipD3D9ResourceGetMappedSize', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9ResourceGetSurfaceDimensions', ('hipD3D9ResourceGetSurfaceDimensions', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9ResourceSetMapFlags', ('hipD3D9ResourceSetMapFlags', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9UnmapResources', ('hipD3D9UnmapResources', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D9UnregisterResource', ('hipD3D9UnregisterResource', CONV_D3D9, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10DeviceListAll', ('HIP_D3D10_DEVICE_LIST_ALL', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10DeviceListCurrentFrame', ('HIP_D3D10_DEVICE_LIST_CURRENT_FRAME', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10DeviceListNextFrame', ('HIP_D3D10_DEVICE_LIST_NEXT_FRAME', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10GetDevice', ('hipD3D10GetDevice', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10GetDevices', ('hipD3D10GetDevices', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsD3D10RegisterResource', ('hipGraphicsD3D10RegisterResource', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10MapFlagsNone', ('HIP_D3D10_MAPRESOURCE_FLAGS_NONE', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10MapFlagsReadOnly', ('HIP_D3D10_MAPRESOURCE_FLAGS_READONLY', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10MapFlagsWriteDiscard', ('HIP_D3D10_MAPRESOURCE_FLAGS_WRITEDISCARD', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10RegisterFlagsNone', ('HIP_D3D10_REGISTER_FLAGS_NONE', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10RegisterFlagsArray', ('HIP_D3D10_REGISTER_FLAGS_ARRAY', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10GetDirect3DDevice', ('hipD3D10GetDirect3DDevice', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10MapResources', ('hipD3D10MapResources', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10RegisterResource', ('hipD3D10RegisterResource', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10ResourceGetMappedArray', ('hipD3D10ResourceGetMappedArray', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10ResourceGetMappedPitch', ('hipD3D10ResourceGetMappedPitch', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10ResourceGetMappedPointer', ('hipD3D10ResourceGetMappedPointer', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10ResourceGetMappedSize', ('hipD3D10ResourceGetMappedSize', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10ResourceGetSurfaceDimensions', ('hipD3D10ResourceGetSurfaceDimensions', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10ResourceSetMapFlags', ('hipD3D10ResourceSetMapFlags', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10SetDirect3DDevice', ('hipD3D10SetDirect3DDevice', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10UnmapResources', ('hipD3D10UnmapResources', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D10UnregisterResource', ('hipD3D10UnregisterResource', CONV_D3D10, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11DeviceListAll', ('HIP_D3D11_DEVICE_LIST_ALL', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11DeviceListCurrentFrame', ('HIP_D3D11_DEVICE_LIST_CURRENT_FRAME', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11DeviceListNextFrame', ('HIP_D3D11_DEVICE_LIST_NEXT_FRAME', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11GetDevice', ('hipD3D11GetDevice', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11GetDevices', ('hipD3D11GetDevices', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsD3D11RegisterResource', ('hipGraphicsD3D11RegisterResource', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11GetDevice', ('hipD3D11GetDevice', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaD3D11GetDevices', ('hipD3D11GetDevices', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsD3D11RegisterResource', ('hipGraphicsD3D11RegisterResource', CONV_D3D11, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsVDPAURegisterOutputSurface', ('hipGraphicsVDPAURegisterOutputSurface', CONV_VDPAU, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsVDPAURegisterVideoSurface', ('hipGraphicsVDPAURegisterVideoSurface', CONV_VDPAU, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaVDPAUGetDevice', ('hipVDPAUGetDevice', CONV_VDPAU, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaVDPAUSetVDPAUDevice', ('hipVDPAUSetDevice', CONV_VDPAU, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamConsumerAcquireFrame', ('hipEGLStreamConsumerAcquireFrame', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamConsumerConnect', ('hipEGLStreamConsumerConnect', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamConsumerConnectWithFlags', ('hipEGLStreamConsumerConnectWithFlags', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamConsumerReleaseFrame', ('hipEGLStreamConsumerReleaseFrame', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamProducerConnect', ('hipEGLStreamProducerConnect', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamProducerDisconnect', ('hipEGLStreamProducerDisconnect', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamProducerPresentFrame', ('hipEGLStreamProducerPresentFrame', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaEGLStreamProducerReturnFrame', ('hipEGLStreamProducerReturnFrame', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsEGLRegisterImage', ('hipGraphicsEGLRegisterImage', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cudaGraphicsResourceGetMappedEglFrame', ('hipGraphicsResourceGetMappedEglFrame', CONV_EGL, API_RUNTIME, HIP_UNSUPPORTED)), ('cublasInit', ('rocblas_init', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasShutdown', ('rocblas_shutdown', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasGetVersion', ('rocblas_get_version', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasGetError', ('rocblas_get_error', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasAlloc', ('rocblas_alloc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasFree', ('rocblas_free', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSetKernelStream', ('rocblas_set_kernel_stream', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasGetAtomicsMode', ('rocblas_get_atomics_mode', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSetAtomicsMode', ('rocblas_set_atomics_mode', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasGetMathMode', ('rocblas_get_math_mode', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSetMathMode', ('rocblas_set_math_mode', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('CUBLAS_OP_N', ('rocblas_operation_none', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_OP_T', ('rocblas_operation_transpose', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_OP_C', ('rocblas_operation_conjugate_transpose', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_SUCCESS', ('rocblas_status_success', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_NOT_INITIALIZED', ('rocblas_status_invalid_handle', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_ALLOC_FAILED', ('rocblas_status_memory_error', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_INVALID_VALUE', ('rocblas_status_invalid_pointer', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_MAPPING_ERROR', ('rocblas_status_internal_error', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_EXECUTION_FAILED', ('rocblas_status_internal_error', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_INTERNAL_ERROR', ('rocblas_status_internal_error', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_NOT_SUPPORTED', ('rocblas_status_not_implemented', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_STATUS_ARCH_MISMATCH', ('rocblas_status_not_implemented', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_FILL_MODE_LOWER', ('rocblas_fill_lower', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_FILL_MODE_UPPER', ('rocblas_fill_upper', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_DIAG_NON_UNIT', ('rocblas_diagonal_non_unit', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_DIAG_UNIT', ('rocblas_diagonal_unit', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_SIDE_LEFT', ('rocblas_side_left', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_SIDE_RIGHT', ('rocblas_side_right', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_POINTER_MODE_HOST', ('rocblas_pointer_mode_host', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_POINTER_MODE_DEVICE', ('rocblas_pointer_mode_device', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUBLAS_ATOMICS_NOT_ALLOWED', ('rocblas_atomics_not_allowed', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('CUBLAS_ATOMICS_ALLOWED', ('rocblas_atomics_allowed', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('CUBLAS_DATA_FLOAT', ('rocblas_precision_float', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('CUBLAS_DATA_DOUBLE', ('rocblas_precision_double', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('CUBLAS_DATA_HALF', ('rocblas_precision_half', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('CUBLAS_DATA_INT8', ('rocblas_precision_int8', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('cublasCreate', ('rocblas_create_handle', CONV_MATH_FUNC, API_BLAS)), ('cublasDestroy', ('rocblas_destroy_handle', CONV_MATH_FUNC, API_BLAS)), ('cublasSetVector', ('rocblas_set_vector', CONV_MATH_FUNC, API_BLAS)), ('cublasGetVector', ('rocblas_get_vector', CONV_MATH_FUNC, API_BLAS)), ('cublasSetVectorAsync', ('rocblas_set_vector_async', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasGetVectorAsync', ('rocblas_get_vector_async', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSetMatrix', ('rocblas_set_matrix', CONV_MATH_FUNC, API_BLAS)), ('cublasGetMatrix', ('rocblas_get_matrix', CONV_MATH_FUNC, API_BLAS)), ('cublasGetMatrixAsync', ('rocblas_get_matrix_async', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSetMatrixAsync', ('rocblas_set_matrix_async', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasXerbla', ('rocblas_xerbla', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSnrm2', ('rocblas_snrm2', CONV_MATH_FUNC, API_BLAS)), ('cublasDnrm2', ('rocblas_dnrm2', CONV_MATH_FUNC, API_BLAS)), ('cublasScnrm2', ('rocblas_scnrm2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDznrm2', ('rocblas_dznrm2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasNrm2Ex', ('rocblas_nrm2_ex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSdot', ('rocblas_sdot', CONV_MATH_FUNC, API_BLAS)), ('cublasSdotBatched', ('rocblas_sdot_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDdot', ('rocblas_ddot', CONV_MATH_FUNC, API_BLAS)), ('cublasDdotBatched', ('rocblas_ddot_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCdotu', ('rocblas_cdotu', CONV_MATH_FUNC, API_BLAS)), ('cublasCdotc', ('rocblas_cdotc', CONV_MATH_FUNC, API_BLAS)), ('cublasZdotu', ('rocblas_zdotu', CONV_MATH_FUNC, API_BLAS)), ('cublasZdotc', ('rocblas_zdotc', CONV_MATH_FUNC, API_BLAS)), ('cublasSscal', ('rocblas_sscal', CONV_MATH_FUNC, API_BLAS)), ('cublasSscalBatched', ('rocblas_sscal_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDscal', ('rocblas_dscal', CONV_MATH_FUNC, API_BLAS)), ('cublasDscalBatched', ('rocblas_dscal_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCscal', ('rocblas_cscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsscal', ('rocblas_csscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZscal', ('rocblas_zscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdscal', ('rocblas_zdscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSaxpy', ('rocblas_saxpy', CONV_MATH_FUNC, API_BLAS)), ('cublasSaxpyBatched', ('rocblas_saxpy_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDaxpy', ('rocblas_daxpy', CONV_MATH_FUNC, API_BLAS)), ('cublasCaxpy', ('rocblas_caxpy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZaxpy', ('rocblas_zaxpy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasScopy', ('rocblas_scopy', CONV_MATH_FUNC, API_BLAS)), ('cublasScopyBatched', ('rocblas_scopy_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDcopy', ('rocblas_dcopy', CONV_MATH_FUNC, API_BLAS)), ('cublasDcopyBatched', ('rocblas_dcopy_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCcopy', ('rocblas_ccopy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZcopy', ('rocblas_zcopy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSswap', ('rocblas_sswap', CONV_MATH_FUNC, API_BLAS)), ('cublasDswap', ('rocblas_dswap', CONV_MATH_FUNC, API_BLAS)), ('cublasCswap', ('rocblas_cswap', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZswap', ('rocblas_zswap', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIsamax', ('rocblas_isamax', CONV_MATH_FUNC, API_BLAS)), ('cublasIdamax', ('rocblas_idamax', CONV_MATH_FUNC, API_BLAS)), ('cublasIcamax', ('rocblas_icamax', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIzamax', ('rocblas_izamax', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIsamin', ('rocblas_isamin', CONV_MATH_FUNC, API_BLAS)), ('cublasIdamin', ('rocblas_idamin', CONV_MATH_FUNC, API_BLAS)), ('cublasIcamin', ('rocblas_icamin', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIzamin', ('rocblas_izamin', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSasum', ('rocblas_sasum', CONV_MATH_FUNC, API_BLAS)), ('cublasSasumBatched', ('rocblas_sasum_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDasum', ('rocblas_dasum', CONV_MATH_FUNC, API_BLAS)), ('cublasDasumBatched', ('rocblas_dasum_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasScasum', ('rocblas_scasum', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDzasum', ('rocblas_dzasum', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrot', ('rocblas_srot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrot', ('rocblas_drot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCrot', ('rocblas_crot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsrot', ('rocblas_csrot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZrot', ('rocblas_zrot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdrot', ('rocblas_zdrot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrotg', ('rocblas_srotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrotg', ('rocblas_drotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCrotg', ('rocblas_crotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZrotg', ('rocblas_zrotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrotm', ('rocblas_srotm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrotm', ('rocblas_drotm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrotmg', ('rocblas_srotmg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrotmg', ('rocblas_drotmg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgemv', ('rocblas_sgemv', CONV_MATH_FUNC, API_BLAS)), ('cublasSgemvBatched', ('rocblas_sgemv_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgemv', ('rocblas_dgemv', CONV_MATH_FUNC, API_BLAS)), ('cublasCgemv', ('rocblas_cgemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgemv', ('rocblas_zgemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgbmv', ('rocblas_sgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgbmv', ('rocblas_dgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgbmv', ('rocblas_cgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgbmv', ('rocblas_zgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrmv', ('rocblas_strmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrmv', ('rocblas_dtrmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrmv', ('rocblas_ctrmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrmv', ('rocblas_ztrmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStbmv', ('rocblas_stbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtbmv', ('rocblas_dtbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtbmv', ('rocblas_ctbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtbmv', ('rocblas_ztbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStpmv', ('rocblas_stpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtpmv', ('rocblas_dtpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtpmv', ('rocblas_ctpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtpmv', ('rocblas_ztpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrsv', ('rocblas_strsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrsv', ('rocblas_dtrsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrsv', ('rocblas_ctrsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrsv', ('rocblas_ztrsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStpsv', ('rocblas_stpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtpsv', ('rocblas_dtpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtpsv', ('rocblas_ctpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtpsv', ('rocblas_ztpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStbsv', ('rocblas_stbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtbsv', ('rocblas_dtbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtbsv', ('rocblas_ctbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtbsv', ('rocblas_ztbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsymv', ('rocblas_ssymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsymv', ('rocblas_dsymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsymv', ('rocblas_csymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsymv', ('rocblas_zsymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChemv', ('rocblas_chemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhemv', ('rocblas_zhemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsbmv', ('rocblas_ssbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsbmv', ('rocblas_dsbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChbmv', ('rocblas_chbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhbmv', ('rocblas_zhbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSspmv', ('rocblas_sspmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDspmv', ('rocblas_dspmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChpmv', ('rocblas_chpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhpmv', ('rocblas_zhpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSger', ('rocblas_sger', CONV_MATH_FUNC, API_BLAS)), ('cublasDger', ('rocblas_dger', CONV_MATH_FUNC, API_BLAS)), ('cublasCgeru', ('rocblas_cgeru', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgerc', ('rocblas_cgerc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgeru', ('rocblas_zgeru', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgerc', ('rocblas_zgerc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyr', ('rocblas_ssyr', CONV_MATH_FUNC, API_BLAS)), ('cublasDsyr', ('rocblas_dsyr', CONV_MATH_FUNC, API_BLAS)), ('cublasCher', ('rocblas_cher', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZher', ('rocblas_zher', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSspr', ('rocblas_sspr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDspr', ('rocblas_dspr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChpr', ('rocblas_chpr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhpr', ('rocblas_zhpr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyr2', ('rocblas_ssyr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyr2', ('rocblas_dsyr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCher2', ('rocblas_cher2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZher2', ('rocblas_zher2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSspr2', ('rocblas_sspr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDspr2', ('rocblas_dspr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChpr2', ('rocblas_chpr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhpr2', ('rocblas_zhpr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgemmBatched', ('rocblas_sgemm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgemmBatched', ('rocblas_dgemm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasHgemmBatched', ('rocblas_hgemm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgemmStridedBatched', ('rocblas_sgemm_strided_batched', CONV_MATH_FUNC, API_BLAS)), ('cublasDgemmStridedBatched', ('rocblas_dgemm_strided_batched', CONV_MATH_FUNC, API_BLAS)), ('cublasHgemmStridedBatched', ('rocblas_hgemm_strided_batched', CONV_MATH_FUNC, API_BLAS)), ('cublasCgemmBatched', ('rocblas_cgemm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgemm3mBatched', ('rocblas_cgemm_3m_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgemmBatched', ('rocblas_zgemm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgemmStridedBatched', ('rocblas_cgemm_strided_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgemm3mStridedBatched', ('rocblas_cgemm_3m_strided_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgemmStridedBatched', ('rocblas_zgemm_strided_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasHgemmStridedBatched', ('rocblas_hgemm_strided_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgemm', ('rocblas_sgemm', CONV_MATH_FUNC, API_BLAS)), ('cublasDgemm', ('rocblas_dgemm', CONV_MATH_FUNC, API_BLAS)), ('cublasCgemm', ('rocblas_cgemm', CONV_MATH_FUNC, API_BLAS)), ('cublasZgemm', ('rocblas_zgemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasHgemm', ('rocblas_hgemm', CONV_MATH_FUNC, API_BLAS)), ('cublasSsyrk', ('rocblas_ssyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyrk', ('rocblas_dsyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyrk', ('rocblas_csyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyrk', ('rocblas_zsyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCherk', ('rocblas_cherk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZherk', ('rocblas_zherk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyr2k', ('rocblas_ssyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyr2k', ('rocblas_dsyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyr2k', ('rocblas_csyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyr2k', ('rocblas_zyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyrkx', ('rocblas_ssyrkx', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyrkx', ('rocblas_dsyrkx', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyrkx', ('rocblas_csyrkx', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyrkx', ('rocblas_zsyrkx', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCher2k', ('rocblas_cher2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZher2k', ('rocblas_zher2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCherkx', ('rocblas_cherkx', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZherkx', ('rocblas_zherkx', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsymm', ('rocblas_ssymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsymm', ('rocblas_dsymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsymm', ('rocblas_csymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsymm', ('rocblas_zsymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChemm', ('rocblas_chemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhemm', ('rocblas_zhemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrsm', ('rocblas_strsm', CONV_MATH_FUNC, API_BLAS)), ('cublasDtrsm', ('rocblas_dtrsm', CONV_MATH_FUNC, API_BLAS)), ('cublasCtrsm', ('rocblas_ctrsm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrsm', ('rocblas_ztrsm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrsmBatched', ('rocblas_strsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrsmBatched', ('rocblas_dtrsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrsmBatched', ('rocblas_ctrsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrsmBatched', ('rocblas_ztrsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrmm', ('rocblas_strmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrmm', ('rocblas_dtrmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrmm', ('rocblas_ctrmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrmm', ('rocblas_ztrmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgeam', ('rocblas_sgeam', CONV_MATH_FUNC, API_BLAS)), ('cublasDgeam', ('rocblas_dgeam', CONV_MATH_FUNC, API_BLAS)), ('cublasCgeam', ('rocblas_cgeam', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgeam', ('rocblas_zgeam', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgetrfBatched', ('rocblas_sgetrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgetrfBatched', ('rocblas_dgetrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgetrfBatched', ('rocblas_cgetrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgetrfBatched', ('rocblas_zgetrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgetriBatched', ('rocblas_sgetri_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgetriBatched', ('rocblas_dgetri_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgetriBatched', ('rocblas_cgetri_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgetriBatched', ('rocblas_zgetri_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgetrsBatched', ('rocblas_sgetrs_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgetrsBatched', ('rocblas_dgetrs_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgetrsBatched', ('rocblas_cgetrs_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgetrsBatched', ('rocblas_zgetrs_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrsmBatched', ('rocblas_strsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrsmBatched', ('rocblas_dtrsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrsmBatched', ('rocblas_ctrsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrsmBatched', ('rocblas_dtrsm_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSmatinvBatched', ('rocblas_smatinv_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDmatinvBatched', ('rocblas_dmatinv_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCmatinvBatched', ('rocblas_cmatinv_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZmatinvBatched', ('rocblas_zmatinv_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgeqrfBatched', ('rocblas_sgeqrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgeqrfBatched', ('rocblas_dgeqrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgeqrfBatched', ('rocblas_cgeqrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgeqrfBatched', ('rocblas_zgeqrf_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgelsBatched', ('rocblas_sgels_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgelsBatched', ('rocblas_dgels_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgelsBatched', ('rocblas_cgels_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgelsBatched', ('rocblas_zgels_batched', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSdgmm', ('rocblas_sdgmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDdgmm', ('rocblas_ddgmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCdgmm', ('rocblas_cdgmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdgmm', ('rocblas_zdgmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStpttr', ('rocblas_stpttr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtpttr', ('rocblas_dtpttr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtpttr', ('rocblas_ctpttr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtpttr', ('rocblas_ztpttr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrttp', ('rocblas_strttp', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrttp', ('rocblas_dtrttp', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrttp', ('rocblas_ctrttp', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrttp', ('rocblas_ztrttp', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCreate_v2', ('rocblas_create_handle', CONV_MATH_FUNC, API_BLAS)), ('cublasDestroy_v2', ('rocblas_destroy_handle', CONV_MATH_FUNC, API_BLAS)), ('cublasGetVersion_v2', ('rocblas_get_version', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSetStream', ('rocblas_set_stream', CONV_MATH_FUNC, API_BLAS)), ('cublasGetStream', ('rocblas_get_stream', CONV_MATH_FUNC, API_BLAS)), ('cublasSetStream_v2', ('rocblas_set_stream', CONV_MATH_FUNC, API_BLAS)), ('cublasGetStream_v2', ('rocblas_get_stream', CONV_MATH_FUNC, API_BLAS)), ('cublasGetPointerMode', ('rocblas_get_pointer_mode', CONV_MATH_FUNC, API_BLAS)), ('cublasSetPointerMode', ('rocblas_set_pointer_mode', CONV_MATH_FUNC, API_BLAS)), ('cublasGetPointerMode_v2', ('rocblas_get_pointer_mode', CONV_MATH_FUNC, API_BLAS)), ('cublasSetPointerMode_v2', ('rocblas_set_pointer_mode', CONV_MATH_FUNC, API_BLAS)), ('cublasSgemv_v2', ('rocblas_sgemv', CONV_MATH_FUNC, API_BLAS)), ('cublasDgemv_v2', ('rocblas_dgemv', CONV_MATH_FUNC, API_BLAS)), ('cublasCgemv_v2', ('rocblas_cgemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgemv_v2', ('rocblas_zgemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgbmv_v2', ('rocblas_sgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDgbmv_v2', ('rocblas_dgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgbmv_v2', ('rocblas_cgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgbmv_v2', ('rocblas_zgbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrmv_v2', ('rocblas_strmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrmv_v2', ('rocblas_dtrmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrmv_v2', ('rocblas_ctrmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrmv_v2', ('rocblas_ztrmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStbmv_v2', ('rocblas_stbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtbmv_v2', ('rocblas_dtbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtbmv_v2', ('rocblas_ctbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtbmv_v2', ('rocblas_ztbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStpmv_v2', ('rocblas_stpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtpmv_v2', ('rocblas_dtpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtpmv_v2', ('rocblas_ctpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtpmv_v2', ('rocblas_ztpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrsv_v2', ('rocblas_strsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrsv_v2', ('rocblas_dtrsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrsv_v2', ('rocblas_ctrsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrsv_v2', ('rocblas_ztrsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStpsv_v2', ('rocblas_stpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtpsv_v2', ('rocblas_dtpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtpsv_v2', ('rocblas_ctpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtpsv_v2', ('rocblas_ztpsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStbsv_v2', ('rocblas_stbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtbsv_v2', ('rocblas_dtbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtbsv_v2', ('rocblas_ctbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtbsv_v2', ('rocblas_ztbsv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsymv_v2', ('rocblas_ssymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsymv_v2', ('rocblas_dsymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsymv_v2', ('rocblas_csymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsymv_v2', ('rocblas_zsymv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChemv_v2', ('rocblas_chemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhemv_v2', ('rocblas_zhemv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsbmv_v2', ('rocblas_ssbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsbmv_v2', ('rocblas_dsbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChbmv_v2', ('rocblas_chbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhbmv_v2', ('rocblas_zhbmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSspmv_v2', ('rocblas_sspmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDspmv_v2', ('rocblas_dspmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChpmv_v2', ('rocblas_chpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhpmv_v2', ('rocblas_zhpmv', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSger_v2', ('rocblas_sger', CONV_MATH_FUNC, API_BLAS)), ('cublasDger_v2', ('rocblas_dger', CONV_MATH_FUNC, API_BLAS)), ('cublasCgeru_v2', ('rocblas_cgeru', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgerc_v2', ('rocblas_cergc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgeru_v2', ('rocblas_zgeru', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgerc_v2', ('rocblas_zgerc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyr_v2', ('rocblas_ssyr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyr_v2', ('rocblas_dsyr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyr_v2', ('rocblas_csyr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyr_v2', ('rocblas_zsyr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCher_v2', ('rocblas_cher', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZher_v2', ('rocblas_zher', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSspr_v2', ('rocblas_sspr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDspr_v2', ('rocblas_dspr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChpr_v2', ('rocblas_chpr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhpr_v2', ('rocblas_zhpr', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyr2_v2', ('rocblas_ssyr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyr2_v2', ('rocblas_dsyr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyr2_v2', ('rocblas_csyr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyr2_v2', ('rocblas_zsyr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCher2_v2', ('rocblas_cher2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZher2_v2', ('rocblas_zher2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSspr2_v2', ('rocblas_sspr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDspr2_v2', ('rocblas_dspr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChpr2_v2', ('rocblas_chpr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhpr2_v2', ('rocblas_zhpr2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgemm_v2', ('rocblas_sgemm', CONV_MATH_FUNC, API_BLAS)), ('cublasDgemm_v2', ('rocblas_dgemm', CONV_MATH_FUNC, API_BLAS)), ('cublasCgemm_v2', ('rocblas_cgemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgemm3m', ('rocblas_cgemm_3m', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgemm3mEx', ('rocblas_cgemm_3mex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgemm_v2', ('rocblas_zgemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZgemm3m', ('rocblas_zgemm_3m', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSgemmEx', ('rocblas_sgemmex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasGemmEx', ('rocblas_gemmex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCgemmEx', ('rocblas_cgemmex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasUint8gemmBias', ('rocblas_uint8gemmbias', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyrk_v2', ('rocblas_ssyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyrk_v2', ('rocblas_dsyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyrk_v2', ('rocblas_csyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyrk_v2', ('rocblas_zsyrk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyrkEx', ('rocblas_csyrkex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyrk3mEx', ('rocblas_csyrk3mex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCherk_v2', ('rocblas_cherk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCherkEx', ('rocblas_cherkex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCherk3mEx', ('rocblas_cherk3mex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZherk_v2', ('rocblas_zherk', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsyr2k_v2', ('rocblas_ssyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsyr2k_v2', ('rocblas_dsyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsyr2k_v2', ('rocblas_csyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsyr2k_v2', ('rocblas_zsyr2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCher2k_v2', ('rocblas_cher2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZher2k_v2', ('rocblas_zher2k', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSsymm_v2', ('rocblas_ssymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDsymm_v2', ('rocblas_dsymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsymm_v2', ('rocblas_csymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZsymm_v2', ('rocblas_zsymm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasChemm_v2', ('rocblas_chemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZhemm_v2', ('rocblas_zhemm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrsm_v2', ('rocblas_strsm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrsm_v2', ('rocblas_dtrsm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrsm_v2', ('rocblas_ctrsm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrsm_v2', ('rocblas_ztrsm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasStrmm_v2', ('rocblas_strmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDtrmm_v2', ('rocblas_dtrmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCtrmm_v2', ('rocblas_ctrmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZtrmm_v2', ('rocblas_ztrmm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSnrm2_v2', ('rocblas_snrm2', CONV_MATH_FUNC, API_BLAS)), ('cublasDnrm2_v2', ('rocblas_dnrm2', CONV_MATH_FUNC, API_BLAS)), ('cublasScnrm2_v2', ('rocblas_scnrm2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDznrm2_v2', ('rocblas_dznrm2', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDotEx', ('rocblas_dotex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDotcEx', ('rocblas_dotcex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSdot_v2', ('rocblas_sdot', CONV_MATH_FUNC, API_BLAS)), ('cublasDdot_v2', ('rocblas_ddot', CONV_MATH_FUNC, API_BLAS)), ('cublasCdotu_v2', ('rocblas_cdotu', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCdotc_v2', ('rocblas_cdotc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdotu_v2', ('rocblas_zdotu', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdotc_v2', ('rocblas_zdotc', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasScalEx', ('rocblas_scalex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSscal_v2', ('rocblas_sscal', CONV_MATH_FUNC, API_BLAS)), ('cublasDscal_v2', ('rocblas_dscal', CONV_MATH_FUNC, API_BLAS)), ('cublasCscal_v2', ('rocblas_cscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsscal_v2', ('rocblas_csscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZscal_v2', ('rocblas_zcsal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdscal_v2', ('rocblas_zdscal', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasAxpyEx', ('rocblas_axpyex', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSaxpy_v2', ('rocblas_saxpy', CONV_MATH_FUNC, API_BLAS)), ('cublasDaxpy_v2', ('rocblas_daxpy', CONV_MATH_FUNC, API_BLAS)), ('cublasCaxpy_v2', ('rocblas_caxpy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZaxpy_v2', ('rocblas_zaxpy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasScopy_v2', ('rocblas_scopy', CONV_MATH_FUNC, API_BLAS)), ('cublasDcopy_v2', ('rocblas_dcopy', CONV_MATH_FUNC, API_BLAS)), ('cublasCcopy_v2', ('rocblas_ccopy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZcopy_v2', ('rocblas_zcopy', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSswap_v2', ('rocblas_sswap', CONV_MATH_FUNC, API_BLAS)), ('cublasDswap_v2', ('rocblas_dswap', CONV_MATH_FUNC, API_BLAS)), ('cublasCswap_v2', ('rocblas_cswap', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZswap_v2', ('rocblas_zswap', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIsamax_v2', ('rocblas_isamax', CONV_MATH_FUNC, API_BLAS)), ('cublasIdamax_v2', ('rocblas_idamax', CONV_MATH_FUNC, API_BLAS)), ('cublasIcamax_v2', ('rocblas_icamax', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIzamax_v2', ('rocblas_izamax', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIsamin_v2', ('rocblas_isamin', CONV_MATH_FUNC, API_BLAS)), ('cublasIdamin_v2', ('rocblas_idamin', CONV_MATH_FUNC, API_BLAS)), ('cublasIcamin_v2', ('rocblas_icamin', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasIzamin_v2', ('rocblas_izamin', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSasum_v2', ('rocblas_sasum', CONV_MATH_FUNC, API_BLAS)), ('cublasDasum_v2', ('rocblas_dasum', CONV_MATH_FUNC, API_BLAS)), ('cublasScasum_v2', ('rocblas_scasum', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDzasum_v2', ('rocblas_dzasum', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrot_v2', ('rocblas_srot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrot_v2', ('rocblas_drot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCrot_v2', ('rocblas_crot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCsrot_v2', ('rocblas_csrot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZrot_v2', ('rocblas_zrot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZdrot_v2', ('rocblas_zdrot', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrotg_v2', ('rocblas_srotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrotg_v2', ('rocblas_drotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasCrotg_v2', ('rocblas_crotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasZrotg_v2', ('rocblas_zrotg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrotm_v2', ('rocblas_srotm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrotm_v2', ('rocblas_drotm', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasSrotmg_v2', ('rocblas_srotmg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('cublasDrotmg_v2', ('rocblas_drotmg', CONV_MATH_FUNC, API_BLAS, HIP_UNSUPPORTED)), ('CURAND_STATUS_SUCCESS', ('HIPRAND_STATUS_SUCCESS', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_VERSION_MISMATCH', ('HIPRAND_STATUS_VERSION_MISMATCH', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_NOT_INITIALIZED', ('HIPRAND_STATUS_NOT_INITIALIZED', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_ALLOCATION_FAILED', ('HIPRAND_STATUS_ALLOCATION_FAILED', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_TYPE_ERROR', ('HIPRAND_STATUS_TYPE_ERROR', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_OUT_OF_RANGE', ('HIPRAND_STATUS_OUT_OF_RANGE', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_LENGTH_NOT_MULTIPLE', ('HIPRAND_STATUS_LENGTH_NOT_MULTIPLE', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_DOUBLE_PRECISION_REQUIRED', ('HIPRAND_STATUS_DOUBLE_PRECISION_REQUIRED', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_LAUNCH_FAILURE', ('HIPRAND_STATUS_LAUNCH_FAILURE', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_PREEXISTING_FAILURE', ('HIPRAND_STATUS_PREEXISTING_FAILURE', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_INITIALIZATION_FAILED', ('HIPRAND_STATUS_INITIALIZATION_FAILED', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_ARCH_MISMATCH', ('HIPRAND_STATUS_ARCH_MISMATCH', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_STATUS_INTERNAL_ERROR', ('HIPRAND_STATUS_INTERNAL_ERROR', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_TEST', ('HIPRAND_RNG_TEST', CONV_NUMERIC_LITERAL, API_RAND)), ('mtgp32dc_params_fast_11213', ('mtgp32dc_params_fast_11213', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_PSEUDO_DEFAULT', ('HIPRAND_RNG_PSEUDO_DEFAULT', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_PSEUDO_XORWOW', ('HIPRAND_RNG_PSEUDO_XORWOW', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_PSEUDO_MRG32K3A', ('HIPRAND_RNG_PSEUDO_MRG32K3A', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_PSEUDO_MTGP32', ('HIPRAND_RNG_PSEUDO_MTGP32', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_PSEUDO_MT19937', ('HIPRAND_RNG_PSEUDO_MT19937', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_PSEUDO_PHILOX4_32_10', ('HIPRAND_RNG_PSEUDO_PHILOX4_32_10', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_QUASI_DEFAULT', ('HIPRAND_RNG_QUASI_DEFAULT', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_QUASI_SOBOL32', ('HIPRAND_RNG_QUASI_SOBOL32', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_QUASI_SCRAMBLED_SOBOL32', ('HIPRAND_RNG_QUASI_SCRAMBLED_SOBOL32', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_QUASI_SOBOL64', ('HIPRAND_RNG_QUASI_SOBOL64', CONV_NUMERIC_LITERAL, API_RAND)), ('CURAND_RNG_QUASI_SCRAMBLED_SOBOL64', ('HIPRAND_RNG_QUASI_SCRAMBLED_SOBOL64', CONV_NUMERIC_LITERAL, API_RAND)), ('curand_ORDERING_PSEUDO_BEST', ('HIPRAND_ORDERING_PSEUDO_BEST', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_ORDERING_PSEUDO_DEFAULT', ('HIPRAND_ORDERING_PSEUDO_DEFAULT', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_ORDERING_PSEUDO_SEEDED', ('HIPRAND_ORDERING_PSEUDO_SEEDED', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_ORDERING_QUASI_DEFAULT', ('HIPRAND_ORDERING_QUASI_DEFAULT', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_DIRECTION_VECTORS_32_JOEKUO6', ('HIPRAND_DIRECTION_VECTORS_32_JOEKUO6', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_SCRAMBLED_DIRECTION_VECTORS_32_JOEKUO6', ('HIPRAND_SCRAMBLED_DIRECTION_VECTORS_32_JOEKUO6', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_DIRECTION_VECTORS_64_JOEKUO6', ('HIPRAND_DIRECTION_VECTORS_64_JOEKUO6', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_SCRAMBLED_DIRECTION_VECTORS_64_JOEKUO6', ('HIPRAND_SCRAMBLED_DIRECTION_VECTORS_64_JOEKUO6', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_CHOOSE_BEST', ('HIPRAND_CHOOSE_BEST', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_ITR', ('HIPRAND_ITR', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_KNUTH', ('HIPRAND_KNUTH', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_HITR', ('HIPRAND_HITR', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_M1', ('HIPRAND_M1', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_M2', ('HIPRAND_M2', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_BINARY_SEARCH', ('HIPRAND_BINARY_SEARCH', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_DISCRETE_GAUSS', ('HIPRAND_DISCRETE_GAUSS', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_REJECTION', ('HIPRAND_REJECTION', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_DEVICE_API', ('HIPRAND_DEVICE_API', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_FAST_REJECTION', ('HIPRAND_FAST_REJECTION', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_3RD', ('HIPRAND_3RD', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_DEFINITION', ('HIPRAND_DEFINITION', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curand_POISSON', ('HIPRAND_POISSON', CONV_NUMERIC_LITERAL, API_RAND, HIP_UNSUPPORTED)), ('curandCreateGenerator', ('hiprandCreateGenerator', CONV_MATH_FUNC, API_RAND)), ('curandCreateGeneratorHost', ('hiprandCreateGeneratorHost', CONV_MATH_FUNC, API_RAND)), ('curandCreatePoissonDistribution', ('hiprandCreatePoissonDistribution', CONV_MATH_FUNC, API_RAND)), ('curandDestroyDistribution', ('hiprandDestroyDistribution', CONV_MATH_FUNC, API_RAND)), ('curandDestroyGenerator', ('hiprandDestroyGenerator', CONV_MATH_FUNC, API_RAND)), ('curandGenerate', ('hiprandGenerate', CONV_MATH_FUNC, API_RAND)), ('curandGenerateLogNormal', ('hiprandGenerateLogNormal', CONV_MATH_FUNC, API_RAND)), ('curandGenerateLogNormalDouble', ('hiprandGenerateLogNormalDouble', CONV_MATH_FUNC, API_RAND)), ('curandGenerateLongLong', ('hiprandGenerateLongLong', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandGenerateNormal', ('hiprandGenerateNormal', CONV_MATH_FUNC, API_RAND)), ('curandGenerateNormalDouble', ('hiprandGenerateNormalDouble', CONV_MATH_FUNC, API_RAND)), ('curandGeneratePoisson', ('hiprandGeneratePoisson', CONV_MATH_FUNC, API_RAND)), ('curandGenerateSeeds', ('hiprandGenerateSeeds', CONV_MATH_FUNC, API_RAND)), ('curandGenerateUniform', ('hiprandGenerateUniform', CONV_MATH_FUNC, API_RAND)), ('curandGenerateUniformDouble', ('hiprandGenerateUniformDouble', CONV_MATH_FUNC, API_RAND)), ('curandGetDirectionVectors32', ('hiprandGetDirectionVectors32', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandGetDirectionVectors64', ('hiprandGetDirectionVectors64', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandGetProperty', ('hiprandGetProperty', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandGetScrambleConstants32', ('hiprandGetScrambleConstants32', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandGetScrambleConstants64', ('hiprandGetScrambleConstants64', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandGetVersion', ('hiprandGetVersion', CONV_MATH_FUNC, API_RAND)), ('curandSetGeneratorOffset', ('hiprandSetGeneratorOffset', CONV_MATH_FUNC, API_RAND)), ('curandSetGeneratorOrdering', ('hiprandSetGeneratorOrdering', CONV_MATH_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curandSetPseudoRandomGeneratorSeed', ('hiprandSetPseudoRandomGeneratorSeed', CONV_MATH_FUNC, API_RAND)), ('curandSetQuasiRandomGeneratorDimensions', ('hiprandSetQuasiRandomGeneratorDimensions', CONV_MATH_FUNC, API_RAND)), ('curandSetStream', ('hiprandSetStream', CONV_MATH_FUNC, API_RAND)), ('curand', ('hiprand', CONV_DEVICE_FUNC, API_RAND)), ('curand4', ('hiprand4', CONV_DEVICE_FUNC, API_RAND)), ('curand_init', ('hiprand_init', CONV_DEVICE_FUNC, API_RAND)), ('curand_log_normal', ('hiprand_log_normal', CONV_DEVICE_FUNC, API_RAND)), ('curand_log_normal_double', ('hiprand_log_normal_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_log_normal2', ('hiprand_log_normal2', CONV_DEVICE_FUNC, API_RAND)), ('curand_log_normal2_double', ('hiprand_log_normal2_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_log_normal4', ('hiprand_log_normal4', CONV_DEVICE_FUNC, API_RAND)), ('curand_log_normal4_double', ('hiprand_log_normal4_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_mtgp32_single', ('hiprand_mtgp32_single', CONV_DEVICE_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curand_mtgp32_single_specific', ('hiprand_mtgp32_single_specific', CONV_DEVICE_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curand_mtgp32_specific', ('hiprand_mtgp32_specific', CONV_DEVICE_FUNC, API_RAND, HIP_UNSUPPORTED)), ('curand_normal', ('hiprand_normal', CONV_DEVICE_FUNC, API_RAND)), ('curandMakeMTGP32Constants', ('hiprandMakeMTGP32Constants', CONV_DEVICE_FUNC, API_RAND)), ('curandMakeMTGP32KernelState', ('hiprandMakeMTGP32KernelState', CONV_DEVICE_FUNC, API_RAND)), ('curand_normal_double', ('hiprand_normal_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_normal2', ('hiprand_normal2', CONV_DEVICE_FUNC, API_RAND)), ('curand_normal2_double', ('hiprand_normal2_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_normal4', ('hiprand_normal4', CONV_DEVICE_FUNC, API_RAND)), ('curand_normal4_double', ('hiprand_normal4_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_uniform', ('hiprand_uniform', CONV_DEVICE_FUNC, API_RAND)), ('curand_uniform_double', ('hiprand_uniform_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_uniform2_double', ('hiprand_uniform2_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_uniform4', ('hiprand_uniform4', CONV_DEVICE_FUNC, API_RAND)), ('curand_uniform4_double', ('hiprand_uniform4_double', CONV_DEVICE_FUNC, API_RAND)), ('curand_discrete', ('hiprand_discrete', CONV_DEVICE_FUNC, API_RAND)), ('curand_discrete4', ('hiprand_discrete4', CONV_DEVICE_FUNC, API_RAND)), ('curand_poisson', ('hiprand_poisson', CONV_DEVICE_FUNC, API_RAND)), ('curand_poisson4', ('hiprand_poisson4', CONV_DEVICE_FUNC, API_RAND)), ('curand_Philox4x32_10', ('hiprand_Philox4x32_10', CONV_DEVICE_FUNC, API_RAND, HIP_UNSUPPORTED)), ('mtgp32_kernel_params', ('mtgp32_kernel_params_t', CONV_MATH_FUNC, API_RAND)), ('CUFFT_FORWARD', ('HIPFFT_FORWARD', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUFFT_INVERSE', ('HIPFFT_BACKWARD', CONV_NUMERIC_LITERAL, API_BLAS)), ('CUFFT_COMPATIBILITY_DEFAULT', ('HIPFFT_COMPATIBILITY_DEFAULT', CONV_NUMERIC_LITERAL, API_BLAS, HIP_UNSUPPORTED)), ('cuComplex', ('rocblas_float_complex', CONV_TYPE, API_BLAS)), ('cuDoubleComplex', ('rocblas_double_complex', CONV_TYPE, API_BLAS)), ('cufftResult_t', ('hipfftResult_t', CONV_TYPE, API_FFT)), ('cufftResult', ('hipfftResult', CONV_TYPE, API_FFT)), ('CUFFT_SUCCESS', ('HIPFFT_SUCCESS', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INVALID_PLAN', ('HIPFFT_INVALID_PLAN', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_ALLOC_FAILED', ('HIPFFT_ALLOC_FAILED', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INVALID_TYPE', ('HIPFFT_INVALID_TYPE', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INVALID_VALUE', ('HIPFFT_INVALID_VALUE', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INTERNAL_ERROR', ('HIPFFT_INTERNAL_ERROR', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_EXEC_FAILED', ('HIPFFT_EXEC_FAILED', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_SETUP_FAILED', ('HIPFFT_SETUP_FAILED', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INVALID_SIZE', ('HIPFFT_INVALID_SIZE', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_UNALIGNED_DATA', ('HIPFFT_UNALIGNED_DATA', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INCOMPLETE_PARAMETER_LIST', ('HIPFFT_INCOMPLETE_PARAMETER_LIST', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_INVALID_DEVICE', ('HIPFFT_INVALID_DEVICE', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_PARSE_ERROR', ('HIPFFT_PARSE_ERROR', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_NO_WORKSPACE', ('HIPFFT_NO_WORKSPACE', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_NOT_IMPLEMENTED', ('HIPFFT_NOT_IMPLEMENTED', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_LICENSE_ERROR', ('HIPFFT_LICENSE_ERROR', CONV_NUMERIC_LITERAL, API_FFT, HIP_UNSUPPORTED)), ('CUFFT_NOT_SUPPORTED', ('HIPFFT_NOT_SUPPORTED', CONV_NUMERIC_LITERAL, API_FFT)), ('cufftType_t', ('hipfftType_t', CONV_TYPE, API_FFT)), ('cufftType', ('hipfftType', CONV_TYPE, API_FFT)), ('CUFFT_R2C', ('HIPFFT_R2C', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_C2R', ('HIPFFT_C2R', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_C2C', ('HIPFFT_C2C', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_D2Z', ('HIPFFT_D2Z', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_Z2D', ('HIPFFT_Z2D', CONV_NUMERIC_LITERAL, API_FFT)), ('CUFFT_Z2Z', ('HIPFFT_Z2Z', CONV_NUMERIC_LITERAL, API_FFT)), ('cufftCompatibility_t', ('hipfftCompatibility_t', CONV_TYPE, API_FFT, HIP_UNSUPPORTED)), ('cufftCompatibility', ('hipfftCompatibility', CONV_TYPE, API_FFT, HIP_UNSUPPORTED)), ('CUFFT_COMPATIBILITY_FFTW_PADDING', ('HIPFFT_COMPATIBILITY_FFTW_PADDING', CONV_NUMERIC_LITERAL, API_FFT, HIP_UNSUPPORTED)), ('cufftReal', ('hipfftReal', CONV_TYPE, API_FFT)), ('cufftDoubleReal', ('hipfftDoubleReal', CONV_TYPE, API_FFT)), ('cufftComplex', ('hipfftComplex', CONV_TYPE, API_FFT)), ('cufftDoubleComplex', ('hipfftDoubleComplex', CONV_TYPE, API_FFT)), ('cufftHandle', ('hipfftHandle', CONV_TYPE, API_FFT)), ('cufftPlan1d', ('hipfftPlan1d', CONV_MATH_FUNC, API_FFT)), ('cufftPlan2d', ('hipfftPlan2d', CONV_MATH_FUNC, API_FFT)), ('cufftPlan3d', ('hipfftPlan3d', CONV_MATH_FUNC, API_FFT)), ('cufftPlanMany', ('hipfftPlanMany', CONV_MATH_FUNC, API_FFT)), ('cufftMakePlan1d', ('hipfftMakePlan1d', CONV_MATH_FUNC, API_FFT)), ('cufftMakePlan2d', ('hipfftMakePlan2d', CONV_MATH_FUNC, API_FFT)), ('cufftMakePlan3d', ('hipfftMakePlan3d', CONV_MATH_FUNC, API_FFT)), ('cufftMakePlanMany', ('hipfftMakePlanMany', CONV_MATH_FUNC, API_FFT)), ('cufftMakePlanMany64', ('hipfftMakePlanMany64', CONV_MATH_FUNC, API_FFT)), ('cufftGetSizeMany64', ('hipfftGetSizeMany64', CONV_MATH_FUNC, API_FFT)), ('cufftEstimate1d', ('hipfftEstimate1d', CONV_MATH_FUNC, API_FFT)), ('cufftEstimate2d', ('hipfftEstimate2d', CONV_MATH_FUNC, API_FFT)), ('cufftEstimate3d', ('hipfftEstimate3d', CONV_MATH_FUNC, API_FFT)), ('cufftEstimateMany', ('hipfftEstimateMany', CONV_MATH_FUNC, API_FFT)), ('cufftCreate', ('hipfftCreate', CONV_MATH_FUNC, API_FFT)), ('cufftGetSize1d', ('hipfftGetSize1d', CONV_MATH_FUNC, API_FFT)), ('cufftGetSize2d', ('hipfftGetSize2d', CONV_MATH_FUNC, API_FFT)), ('cufftGetSize3d', ('hipfftGetSize3d', CONV_MATH_FUNC, API_FFT)), ('cufftGetSizeMany', ('hipfftGetSizeMany', CONV_MATH_FUNC, API_FFT)), ('cufftGetSize', ('hipfftGetSize', CONV_MATH_FUNC, API_FFT)), ('cufftSetWorkArea', ('hipfftSetWorkArea', CONV_MATH_FUNC, API_FFT)), ('cufftSetAutoAllocation', ('hipfftSetAutoAllocation', CONV_MATH_FUNC, API_FFT)), ('cufftExecC2C', ('hipfftExecC2C', CONV_MATH_FUNC, API_FFT)), ('cufftExecR2C', ('hipfftExecR2C', CONV_MATH_FUNC, API_FFT)), ('cufftExecC2R', ('hipfftExecC2R', CONV_MATH_FUNC, API_FFT)), ('cufftExecZ2Z', ('hipfftExecZ2Z', CONV_MATH_FUNC, API_FFT)), ('cufftExecD2Z', ('hipfftExecD2Z', CONV_MATH_FUNC, API_FFT)), ('cufftExecZ2D', ('hipfftExecZ2D', CONV_MATH_FUNC, API_FFT)), ('cufftSetStream', ('hipfftSetStream', CONV_MATH_FUNC, API_FFT)), ('cufftDestroy', ('hipfftDestroy', CONV_MATH_FUNC, API_FFT)), ('cufftGetVersion', ('hipfftGetVersion', CONV_MATH_FUNC, API_FFT)), ('cufftGetProperty', ('hipfftGetProperty', CONV_MATH_FUNC, API_FFT, HIP_UNSUPPORTED)), ('nvrtcResult', ('hiprtcResult', CONV_TYPE, API_RTC)), ('NVRTC_SUCCESS', ('HIPRTC_SUCCESS', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_OUT_OF_MEMORY', ('HIPRTC_ERROR_OUT_OF_MEMORY', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_PROGRAM_CREATION_FAILURE', ('HIPRTC_ERROR_PROGRAM_CREATION_FAILURE', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_INVALID_INPUT', ('HIPRTC_ERROR_INVALID_INPUT', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_INVALID_PROGRAM', ('HIPRTC_ERROR_INVALID_PROGRAM', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_COMPILATION', ('HIPRTC_ERROR_COMPILATION', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_BUILTIN_OPERATION_FAILURE', ('HIPRTC_ERROR_BUILTIN_OPERATION_FAILURE', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_NO_NAME_EXPRESSIONS_AFTER_COMPILATION', ('HIPRTC_ERROR_NO_NAME_EXPRESSIONS_AFTER_COMPILATION', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_NAME_EXPRESSION_NOT_VALID', ('HIPRTC_ERROR_NAME_EXPRESSION_NOT_VALID', CONV_TYPE, API_RTC)), ('NVRTC_ERROR_INTERNAL_ERROR', ('HIPRTC_ERROR_INTERNAL_ERROR', CONV_TYPE, API_RTC)), ('nvrtcGetErrorString', ('hiprtcGetErrorString', CONV_JIT, API_RTC)), ('nvrtcVersion', ('hiprtcVersion', CONV_JIT, API_RTC)), ('nvrtcProgram', ('hiprtcProgram', CONV_TYPE, API_RTC)), ('nvrtcAddNameExpression', ('hiprtcAddNameExpression', CONV_JIT, API_RTC)), ('nvrtcCompileProgram', ('hiprtcCompileProgram', CONV_JIT, API_RTC)), ('nvrtcCreateProgram', ('hiprtcCreateProgram', CONV_JIT, API_RTC)), ('nvrtcDestroyProgram', ('hiprtcDestroyProgram', CONV_JIT, API_RTC)), ('nvrtcGetLoweredName', ('hiprtcGetLoweredName', CONV_JIT, API_RTC)), ('nvrtcGetProgramLog', ('hiprtcGetProgramLog', CONV_JIT, API_RTC)), ('nvrtcGetProgramLogSize', ('hiprtcGetProgramLogSize', CONV_JIT, API_RTC)), ('nvrtcGetPTX', ('hiprtcGetCode', CONV_JIT, API_RTC)), ('nvrtcGetPTXSize', ('hiprtcGetCodeSize', CONV_JIT, API_RTC)), ('thrust::cuda', ('thrust::hip', CONV_MATH_FUNC, API_BLAS)), ('cub::', ('hipcub::', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::ArgMax', ('hipcub::ArgMax', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::ArgMin', ('hipcub::ArgMin', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::BLOCK_REDUCE_WARP_REDUCTIONS', ('hipcub::BLOCK_REDUCE_WARP_REDUCTIONS', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::BlockReduce', ('hipcub::BlockReduce', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::CachingDeviceAllocator', ('hipcub::CachingDeviceAllocator', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::CountingInputIterator', ('hipcub::CountingInputIterator', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::DeviceRadixSort', ('hipcub::DeviceRadixSort', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::DeviceReduce', ('hipcub::DeviceReduce', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::DeviceScan', ('hipcub::DeviceScan', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::DeviceSegmentedRadixSort', ('hipcub::DeviceSegmentedRadixSort', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::DeviceSelect', ('hipcub::DeviceSelect', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::KeyValuePair', ('hipcub::KeyValuePair', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::Max', ('hipcub::Max', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::Min', ('hipcub::Min', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::Sum', ('hipcub::Sum', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::TransformInputIterator', ('hipcub::TransformInputIterator', CONV_SPECIAL_FUNC, API_RUNTIME)), ('cub::WarpReduce', ('hipcub::WarpReduce', CONV_SPECIAL_FUNC, API_RUNTIME)), ('namespace cub', ('namespace hipcub', CONV_SPECIAL_FUNC, API_RUNTIME)), ('nvtxMark', ('roctxMark', CONV_OTHER, API_ROCTX)), ('nvtxMarkA', ('roctxMarkA', CONV_OTHER, API_ROCTX)), ('nvtxRangePushA', ('roctxRangePushA', CONV_OTHER, API_ROCTX)), ('nvtxRangePop', ('roctxRangePop', CONV_OTHER, API_ROCTX))])
A:torch.utils.hipify.cuda_to_hip_mappings.CUDA_SPARSE_MAP->collections.OrderedDict([('cusparseStatus_t', ('hipsparseStatus_t', CONV_MATH_FUNC, API_SPARSE)), ('cusparseHandle_t', ('hipsparseHandle_t', CONV_MATH_FUNC, API_SPARSE)), ('cusparseOperation_t', ('hipsparseOperation_t', CONV_TYPE, API_SPARSE)), ('cusparseCreateMatDescr', ('hipsparseCreateMatDescr', CONV_MATH_FUNC, API_SPARSE)), ('cusparseCreate', ('hipsparseCreate', CONV_MATH_FUNC, API_SPARSE)), ('cusparseDestroyMatDescr', ('hipsparseDestroyMatDescr', CONV_MATH_FUNC, API_SPARSE)), ('cusparseDestroy', ('hipsparseDestroy', CONV_MATH_FUNC, API_SPARSE)), ('cusparseXcoo2csr', ('hipsparseXcoo2csr', CONV_MATH_FUNC, API_SPARSE)), ('cusparseMatDescr_t', ('hipsparseMatDescr_t', CONV_MATH_FUNC, API_SPARSE)), ('cusparseScsrmm2', ('hipsparseScsrmm2', CONV_MATH_FUNC, API_SPARSE)), ('cusparseDcsrmm2', ('hipsparseDcsrmm2', CONV_MATH_FUNC, API_SPARSE)), ('cusparseScsrmm', ('hipsparseScsrmm', CONV_MATH_FUNC, API_SPARSE)), ('cusparseDcsrmm', ('hipsparseDcsrmm', CONV_MATH_FUNC, API_SPARSE)), ('cusparseXcsrsort_bufferSizeExt', ('hipsparseXcsrsort_bufferSizeExt', CONV_MATH_FUNC, API_SPARSE)), ('cusparseXcsrsort', ('hipsparseXcsrsort', CONV_MATH_FUNC, API_SPARSE)), ('cusparseXcoosort_bufferSizeExt', ('hipsparseXcoosort_bufferSizeExt', CONV_MATH_FUNC, API_SPARSE)), ('cusparseXcoosortByRow', ('hipsparseXcoosortByRow', CONV_MATH_FUNC, API_SPARSE)), ('cusparseSetStream', ('hipsparseSetStream', CONV_MATH_FUNC, API_SPARSE)), ('cusparseCreateIdentityPermutation', ('hipsparseCreateIdentityPermutation', CONV_MATH_FUNC, API_SPARSE)), ('cusparseSetMatIndexBase', ('hipsparseSetMatIndexBase', CONV_MATH_FUNC, API_SPARSE)), ('cusparseSetMatType', ('hipsparseSetMatType', CONV_MATH_FUNC, API_SPARSE)), ('CUSPARSE_STATUS_SUCCESS', ('HIPSPARSE_STATUS_SUCCESS', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_NOT_INITIALIZED', ('HIPSPARSE_STATUS_NOT_INITIALIZED', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_ALLOC_FAILED', ('HIPSPARSE_STATUS_ALLOC_FAILED', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_INVALID_VALUE', ('HIPSPARSE_STATUS_INVALID_VALUE', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_MAPPING_ERROR', ('HIPSPARSE_STATUS_MAPPING_ERROR', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_EXECUTION_FAILED', ('HIPSPARSE_STATUS_EXECUTION_FAILED', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_INTERNAL_ERROR', ('HIPSPARSE_STATUS_INTERNAL_ERROR', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED', ('HIPSPARSE_STATUS_MATRIX_TYPE_NOT_SUPPORTED', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_ARCH_MISMATCH', ('HIPSPARSE_STATUS_ARCH_MISMATCH', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_STATUS_ZERO_PIVOT', ('HIPSPARSE_STATUS_ZERO_PIVOT', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_OPERATION_TRANSPOSE', ('HIPSPARSE_OPERATION_TRANSPOSE', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_OPERATION_NON_TRANSPOSE', ('HIPSPARSE_OPERATION_NON_TRANSPOSE', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_OPERATION_CONJUGATE_TRANSPOSE', ('HIPSPARSE_OPERATION_CONJUGATE_TRANSPOSE', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_INDEX_BASE_ZERO', ('HIPSPARSE_INDEX_BASE_ZERO', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_INDEX_BASE_ONE', ('HIPSPARSE_INDEX_BASE_ONE', CONV_NUMERIC_LITERAL, API_SPARSE)), ('CUSPARSE_MATRIX_TYPE_GENERAL', ('HIPSPARSE_MATRIX_TYPE_GENERAL', CONV_NUMERIC_LITERAL, API_SPARSE))])
A:torch.utils.hipify.cuda_to_hip_mappings.PYTORCH_SPECIFIC_MAPPINGS->collections.OrderedDict([('USE_CUDA', ('USE_ROCM', API_PYTORCH)), ('CUDA_VERSION', ('HIP_VERSION', API_PYTORCH)), ('cudaHostAllocator', ('hipHostAllocator', API_PYTORCH)), ('cudaDeviceAllocator', ('hipDeviceAllocator', API_PYTORCH)), ('define MAX_NUM_BLOCKS 200', ('define MAX_NUM_BLOCKS 64', API_PYTORCH)), ('cuda::CUDAGuard', ('hip::HIPGuardMasqueradingAsCUDA', API_PYTORCH)), ('CUDAGuard', ('HIPGuardMasqueradingAsCUDA', API_PYTORCH)), ('cuda::OptionalCUDAGuard', ('hip::OptionalHIPGuardMasqueradingAsCUDA', API_PYTORCH)), ('OptionalCUDAGuard', ('OptionalHIPGuardMasqueradingAsCUDA', API_PYTORCH)), ('cuda::CUDAStreamGuard', ('hip::HIPStreamGuardMasqueradingAsCUDA', API_PYTORCH)), ('CUDAStreamGuard', ('HIPStreamGuardMasqueradingAsCUDA', API_PYTORCH)), ('cuda::OptionalCUDAStreamGuard', ('hip::OptionalHIPStreamGuardMasqueradingAsCUDA', API_PYTORCH)), ('OptionalCUDAStreamGuard', ('OptionalHIPStreamGuardMasqueradingAsCUDA', API_PYTORCH)), ('cuda::CUDACachingAllocator::get', ('hip::HIPCachingAllocatorMasqueradingAsCUDA::get', API_PYTORCH)), ('CUDACachingAllocator::get', ('HIPCachingAllocatorMasqueradingAsCUDA::get', API_PYTORCH)), ('cuda::CUDACachingAllocator::recordStream', ('hip::HIPCachingAllocatorMasqueradingAsCUDA::recordStreamMasqueradingAsCUDA', API_PYTORCH)), ('CUDACachingAllocator::recordStream', ('HIPCachingAllocatorMasqueradingAsCUDA::recordStreamMasqueradingAsCUDA', API_PYTORCH)), ('cuda::CUDAStream', ('hip::HIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('CUDAStream', ('HIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('cuda::getStreamFromPool', ('hip::getStreamFromPoolMasqueradingAsCUDA', API_PYTORCH)), ('getStreamFromPool', ('getStreamFromPoolMasqueradingAsCUDA', API_PYTORCH)), ('cuda::getDefaultCUDAStream', ('hip::getDefaultHIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('getDefaultCUDAStream', ('getDefaultHIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('cuda::getCurrentCUDAStream', ('hip::getCurrentHIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('getCurrentCUDAStream', ('getCurrentHIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('cuda::setCurrentCUDAStream', ('hip::setCurrentHIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('setCurrentCUDAStream', ('setCurrentHIPStreamMasqueradingAsCUDA', API_PYTORCH)), ('c10/cuda/CUDAGuard.h', ('ATen/hip/impl/HIPGuardImplMasqueradingAsCUDA.h', API_PYTORCH)), ('c10/cuda/CUDACachingAllocator.h', ('ATen/hip/impl/HIPCachingAllocatorMasqueradingAsCUDA.h', API_PYTORCH)), ('c10/cuda/CUDAStream.h', ('ATen/hip/impl/HIPStreamMasqueradingAsCUDA.h', API_PYTORCH)), ('gloo/cuda.h', ('gloo/hip.h', API_PYTORCH)), ('gloo/cuda_allreduce_halving_doubling.h', ('gloo/hip_allreduce_halving_doubling.h', API_PYTORCH)), ('gloo/cuda_allreduce_halving_doubling_pipelined.h', ('gloo/hip_allreduce_halving_doubling_pipelined.h', API_PYTORCH)), ('gloo/cuda_allreduce_ring.h', ('gloo/hip_allreduce_ring.h', API_PYTORCH)), ('gloo/cuda_broadcast_one_to_all.h', ('gloo/hip_broadcast_one_to_all.h', API_PYTORCH)), ('gloo::CudaAllreduceHalvingDoublingPipelined', ('gloo::HipAllreduceHalvingDoublingPipelined', API_PYTORCH)), ('gloo::CudaBroadcastOneToAll', ('gloo::HipBroadcastOneToAll', API_PYTORCH)), ('gloo::CudaHostWorkspace', ('gloo::HipHostWorkspace', API_PYTORCH)), ('gloo::CudaDeviceWorkspace', ('gloo::HipDeviceWorkspace', API_PYTORCH)), ('CUDNN_RNN_RELU', ('miopenRNNRELU', API_PYTORCH)), ('CUDNN_RNN_TANH', ('miopenRNNTANH', API_PYTORCH)), ('CUDNN_LSTM', ('miopenLSTM', API_PYTORCH)), ('CUDNN_GRU', ('miopenGRU', API_PYTORCH)), ('cudnnRNNMode_t', ('miopenRNNMode_t', API_PYTORCH))])
A:torch.utils.hipify.cuda_to_hip_mappings.CAFFE2_SPECIFIC_MAPPINGS->collections.OrderedDict([('cuda_stream', ('hip_stream', API_CAFFE2)), ('/hip/', ('/hip/', API_CAFFE2)), ('/context_gpu', ('/hip/context_gpu', API_CAFFE2)), ('/common_gpu', ('/hip/common_gpu', API_CAFFE2)), ('/cuda_nccl_gpu', ('/hip/hip_nccl_gpu', API_CAFFE2)), ('/mixed_utils', ('/hip/mixed_utils', API_CAFFE2)), ('/operator_fallback_gpu', ('/hip/operator_fallback_gpu', API_CAFFE2)), ('/spatial_batch_norm_op_impl', ('/hip/spatial_batch_norm_op_impl', API_CAFFE2)), ('/recurrent_network_executor_gpu', ('/hip/recurrent_network_executor_gpu', API_CAFFE2)), ('/generate_proposals_op_util_nms_gpu', ('/hip/generate_proposals_op_util_nms_gpu', API_CAFFE2)), ('/max_pool_with_index_gpu', ('/hip/max_pool_with_index_gpu', API_CAFFE2)), ('/THCCachingAllocator_gpu', ('/hip/THCCachingAllocator_gpu', API_CAFFE2)), ('/top_k_heap_selection', ('/hip/top_k_heap_selection', API_CAFFE2)), ('/top_k_radix_selection', ('/hip/top_k_radix_selection', API_CAFFE2)), ('/GpuDefs', ('/hip/GpuDefs', API_CAFFE2)), ('/GpuScanUtils', ('/hip/GpuScanUtils', API_CAFFE2)), ('/GpuBitonicSort', ('/hip/GpuBitonicSort', API_CAFFE2)), ('/math/reduce.cuh', ('/math/hip/reduce.cuh', API_CAFFE2)), ('/sgd/adagrad_fused_op_gpu.cuh', ('/sgd/hip/adagrad_fused_op_gpu.cuh', API_CAFFE2)), ('/operators/segment_reduction_op_gpu.cuh', ('/operators/hip/segment_reduction_op_gpu.cuh', API_CAFFE2)), ('/gather_op.cuh', ('/hip/gather_op.cuh', API_CAFFE2)), ('caffe2/core/common_cudnn.h', ('caffe2/core/hip/common_miopen.h', API_CAFFE2)), ('REGISTER_CUDA_OPERATOR', ('REGISTER_HIP_OPERATOR', API_CAFFE2)), ('CUDA_1D_KERNEL_LOOP', ('HIP_1D_KERNEL_LOOP', API_CAFFE2)), ('CUDAContext', ('HIPContext', API_CAFFE2)), ('CAFFE_CUDA_NUM_THREADS', ('CAFFE_HIP_NUM_THREADS', API_CAFFE2)), ('HasCudaGPU', ('HasHipGPU', API_CAFFE2)), ('__expf', ('expf', API_CAFFE2)), ('CUBLAS_ENFORCE', ('ROCBLAS_ENFORCE', API_CAFFE2)), ('CUBLAS_CHECK', ('ROCBLAS_CHECK', API_CAFFE2)), ('cublas_handle', ('rocblashandle', API_CAFFE2)), ('CURAND_ENFORCE', ('HIPRAND_ENFORCE', API_CAFFE2)), ('CURAND_CHECK', ('HIPRAND_CHECK', API_CAFFE2)), ('curandGenerateUniform', ('hiprandGenerateUniform', API_CAFFE2)), ('curand_generator', ('hiprand_generator', API_CAFFE2)), ('CaffeCudaGetDevice', ('CaffeHipGetDevice', API_CAFFE2)), ('CUDA_KERNEL_ASSERT', ('CUDA_KERNEL_ASSERT', API_CAFFE2)), ('lazyInitCUDA', ('lazyInitCUDA', API_CAFFE2)), ('CUDA', ('HIP', API_CAFFE2)), ('Cuda', ('Hip', API_CAFFE2)), ('cuda_', ('hip_', API_CAFFE2)), ('_cuda', ('_hip', API_CAFFE2)), ('CUDNN', ('MIOPEN', API_CAFFE2)), ('CuDNN', ('MIOPEN', API_CAFFE2)), ('cudnn', ('miopen', API_CAFFE2)), ('namespace cuda', ('namespace hip', API_CAFFE2)), ('cuda::CUDAGuard', ('hip::HIPGuard', API_CAFFE2)), ('cuda::OptionalCUDAGuard', ('hip::OptionalHIPGuard', API_CAFFE2)), ('cuda::CUDAStreamGuard', ('hip::HIPStreamGuard', API_CAFFE2)), ('cuda::OptionalCUDAStreamGuard', ('hip::OptionalHIPStreamGuard', API_CAFFE2)), ('c10/cuda/CUDAGuard.h', ('c10/hip/HIPGuard.h', API_CAFFE2)), ('gloo/cuda', ('gloo/hip', API_CAFFE2))])
A:torch.utils.hipify.cuda_to_hip_mappings.C10_MAPPINGS->collections.OrderedDict([('cuda::compat::', ('hip::compat::', API_C10)), ('c10/cuda/CUDAException.h', ('c10/hip/HIPException.h', API_C10)), ('c10/cuda/CUDAMacros.h', ('c10/hip/HIPMacros.h', API_C10)), ('c10/cuda/CUDAMathCompat.h', ('c10/hip/HIPMathCompat.h', API_C10)), ('c10/cuda/CUDAFunctions.h', ('c10/hip/HIPFunctions.h', API_C10)), ('c10/cuda/CUDAStream.h', ('c10/hip/HIPStream.h', API_C10)), ('c10/cuda/CUDACachingAllocator.h', ('c10/hip/HIPCachingAllocator.h', API_C10)), ('c10/cuda/impl/CUDATest.h', ('c10/hip/impl/HIPTest.h', API_C10)), ('c10/cuda/impl/CUDAGuardImpl.h', ('c10/hip/impl/HIPGuardImpl.h', API_C10)), ('c10/cuda/impl/cuda_cmake_macros.h', ('c10/hip/impl/hip_cmake_macros.h', API_C10)), ('C10_CUDA_CHECK', ('C10_HIP_CHECK', API_C10)), ('C10_CUDA_CHECK_WARN', ('C10_HIP_CHECK_WARN', API_C10)), ('c10::cuda', ('c10::hip', API_C10)), ('cuda::CUDAStream', ('hip::HIPStream', API_C10)), ('CUDAStream', ('HIPStream', API_C10)), ('cuda::current_device', ('hip::current_device', API_C10)), ('cuda::set_device', ('hip::set_device', API_C10)), ('cuda::device_synchronize', ('hip::device_synchronize', API_C10)), ('cuda::getStreamFromPool', ('hip::getStreamFromPool', API_C10)), ('getStreamFromPool', ('getStreamFromPool', API_C10)), ('cuda::getDefaultCUDAStream', ('hip::getDefaultHIPStream', API_C10)), ('getDefaultCUDAStream', ('getDefaultHIPStream', API_C10)), ('cuda::getCurrentCUDAStream', ('hip::getCurrentHIPStream', API_C10)), ('getCurrentCUDAStream', ('getCurrentHIPStream', API_C10)), ('cuda::setCurrentCUDAStream', ('hip::setCurrentHIPStream', API_C10)), ('setCurrentCUDAStream', ('setCurrentHIPStream', API_C10)), ('cuda::CUDACachingAllocator', ('hip::HIPCachingAllocator', API_C10)), ('CUDACachingAllocator', ('HIPCachingAllocator', API_C10))])


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/hipify/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/hipify/hipify_python.py----------------------------------------
A:torch.utils.hipify.hipify_python.self.files_to_clean->set()
A:torch.utils.hipify.hipify_python.(parent, n)->os.path.split(parent)
A:torch.utils.hipify.hipify_python.exact_matches->set(includes)
A:torch.utils.hipify.hipify_python.rel_dirpath->os.path.relpath(abs_dirpath, root_path)
A:torch.utils.hipify.hipify_python.filepath->os.path.join(rel_dirpath, filename)
A:torch.utils.hipify.hipify_python.clean_ctx->GeneratedFileCleaner(keep_intermediates=True)
A:torch.utils.hipify.hipify_python.result->preprocessor(output_directory, filepath, stats, hip_clang_launch, is_pytorch_extension, clean_ctx)
A:torch.utils.hipify.hipify_python.kernel_string->kernel_string.replace('<<<', '').replace('>>>', '').replace('<<<', '').replace('>>>', '')
A:torch.utils.hipify.hipify_python.first_arg_clean->kernel_string[arg_locs[0]['start']:arg_locs[0]['end']].replace('\n', '').strip(' ')
A:torch.utils.hipify.hipify_python.second_arg_clean->kernel_string[arg_locs[1]['start']:arg_locs[1]['end']].replace('\n', '').strip(' ')
A:torch.utils.hipify.hipify_python.first_arg_dim3->'dim3({})'.format(first_arg_clean)
A:torch.utils.hipify.hipify_python.second_arg_dim3->'dim3({})'.format(second_arg_clean)
A:torch.utils.hipify.hipify_python.first_arg_raw_dim3->first_arg_raw.replace(first_arg_clean, first_arg_dim3)
A:torch.utils.hipify.hipify_python.second_arg_raw_dim3->second_arg_raw.replace(second_arg_clean, second_arg_dim3)
A:torch.utils.hipify.hipify_python.cuda_kernel->cuda_kernel.replace(first_arg_raw + second_arg_raw, first_arg_raw_dim3 + second_arg_raw_dim3).replace(first_arg_raw + second_arg_raw, first_arg_raw_dim3 + second_arg_raw_dim3)
A:torch.utils.hipify.hipify_python.RE_KERNEL_LAUNCH->re.compile('([ ]+)(detail?)::[ ]+\\\\\\n[ ]+')
A:torch.utils.hipify.hipify_python.string->re.compile('([ ]+)(detail?)::[ ]+\\\\\\n[ ]+').sub(lambda inp: '{0}{1}::'.format(inp.group(1), inp.group(2)), string)
A:torch.utils.hipify.hipify_python.kernel_start->re.compile('([ ]+)(detail?)::[ ]+\\\\\\n[ ]+').sub(lambda inp: '{0}{1}::'.format(inp.group(1), inp.group(2)), string).find('<<<', kernel_end)
A:torch.utils.hipify.hipify_python.get_kernel_positions->list(find_kernel_bounds(string))
A:torch.utils.hipify.hipify_python.params->grab_method_and_template(kernel)
A:torch.utils.hipify.hipify_python.parenthesis->re.compile('([ ]+)(detail?)::[ ]+\\\\\\n[ ]+').sub(lambda inp: '{0}{1}::'.format(inp.group(1), inp.group(2)), string).find('(', kernel['end'])
A:torch.utils.hipify.hipify_python.cuda_kernel_dim3->add_dim3(kernel_string, cuda_kernel)
A:torch.utils.hipify.hipify_python.num_klp->len(extract_arguments(0, kernel['group'].replace('<<<', '(').replace('>>>', ')')))
A:torch.utils.hipify.hipify_python.output_string->re.compile('extern\\s+([\\w\\(\\)]+)?\\s*__shared__\\s+([\\w:<>\\s]+)\\s+(\\w+)\\s*\\[\\s*\\]\\s*;').sub(lambda inp: 'HIP_DYNAMIC_SHARED({0} {1}, {2})'.format(inp.group(1) or '', inp.group(2), inp.group(3)), output_string)
A:torch.utils.hipify.hipify_python.RE_ASSERT->re.compile('\\bassert[ ]*\\(')
A:torch.utils.hipify.hipify_python.RE_SYNCTHREADS->re.compile('[:]?[:]?\\b(__syncthreads)\\b(\\w*\\()')
A:torch.utils.hipify.hipify_python.RE_EXTERN_SHARED->re.compile('extern\\s+([\\w\\(\\)]+)?\\s*__shared__\\s+([\\w:<>\\s]+)\\s+(\\w+)\\s*\\[\\s*\\]\\s*;')
A:torch.utils.hipify.hipify_python.(dirpath, filename)->os.path.split(filepath)
A:torch.utils.hipify.hipify_python.(root, ext)->os.path.splitext(filename)
A:torch.utils.hipify.hipify_python.dirpath->os.path.join(dirpath, 'hip')
A:torch.utils.hipify.hipify_python.root->root.replace('THC', 'THH').replace('THC', 'THH')
A:torch.utils.hipify.hipify_python.filename->os.path.basename(filepath)
A:torch.utils.hipify.hipify_python.(_, ext)->os.path.splitext(filename)
A:torch.utils.hipify.hipify_python.recurse->self._pattern(data[char])
A:torch.utils.hipify.hipify_python.CAFFE2_TRIE->Trie()
A:torch.utils.hipify.hipify_python.PYTORCH_TRIE->Trie()
A:torch.utils.hipify.hipify_python.RE_CAFFE2_PREPROCESSOR->re.compile(CAFFE2_TRIE.pattern())
A:torch.utils.hipify.hipify_python.RE_PYTORCH_PREPROCESSOR->re.compile('(?<=\\W)({0})(?=\\W)'.format(PYTORCH_TRIE.pattern()))
A:torch.utils.hipify.hipify_python.RE_QUOTE_HEADER->re.compile('#include "([^"]+)"')
A:torch.utils.hipify.hipify_python.RE_ANGLE_HEADER->re.compile('#include <([^>]+)>')
A:torch.utils.hipify.hipify_python.RE_THC_GENERIC_FILE->re.compile('#define THC_GENERIC_FILE "([^"]+)"')
A:torch.utils.hipify.hipify_python.RE_CU_SUFFIX->re.compile('\\.cu\\b')
A:torch.utils.hipify.hipify_python.fin_path->os.path.join(output_directory, filepath)
A:torch.utils.hipify.hipify_python.output_source->replace_extern_shared(output_source)
A:torch.utils.hipify.hipify_python.fout_path->os.path.join(output_directory, get_hip_file_path(filepath))
A:torch.utils.hipify.hipify_python.f->m.group(1)
A:torch.utils.hipify.hipify_python.contents->m.group(1).read()
A:torch.utils.hipify.hipify_python.header->'"{0}"'.format(header)
A:torch.utils.hipify.hipify_python.in_txt->in_txt.replace(' __global__ static', '__global__').replace(' __global__ static', '__global__')
A:torch.utils.hipify.hipify_python.RE_INCLUDE->re.compile('#include .*\\n')
A:torch.utils.hipify.hipify_python.project_directory->os.getcwd()
A:torch.utils.hipify.hipify_python.all_files->list(matched_files_iter(output_directory, includes=includes, ignores=ignores, extensions=extensions, out_of_place_only=out_of_place_only, is_pytorch_extension=is_pytorch_extension))
A:torch.utils.hipify.hipify_python.all_files_set->set(all_files)
torch.utils.hipify.hipify_python.GeneratedFileCleaner(self,keep_intermediates=False)
torch.utils.hipify.hipify_python.GeneratedFileCleaner.__enter__(self)
torch.utils.hipify.hipify_python.GeneratedFileCleaner.__exit__(self,type,value,traceback)
torch.utils.hipify.hipify_python.GeneratedFileCleaner.__init__(self,keep_intermediates=False)
torch.utils.hipify.hipify_python.GeneratedFileCleaner.makedirs(self,dn,exist_ok=False)
torch.utils.hipify.hipify_python.GeneratedFileCleaner.open(self,fn,*args,**kwargs)
torch.utils.hipify.hipify_python.InputError(self,message)
torch.utils.hipify.hipify_python.InputError.__init__(self,message)
torch.utils.hipify.hipify_python.InputError.__str__(self)
torch.utils.hipify.hipify_python.Trie(self)
torch.utils.hipify.hipify_python.Trie.__init__(self)
torch.utils.hipify.hipify_python.Trie._pattern(self,pData)
torch.utils.hipify.hipify_python.Trie.add(self,word)
torch.utils.hipify.hipify_python.Trie.dump(self)
torch.utils.hipify.hipify_python.Trie.pattern(self)
torch.utils.hipify.hipify_python.Trie.quote(self,char)
torch.utils.hipify.hipify_python.add_dim3(kernel_string,cuda_kernel)
torch.utils.hipify.hipify_python.bcolors
torch.utils.hipify.hipify_python.compute_stats(stats)
torch.utils.hipify.hipify_python.extract_arguments(start,string)
torch.utils.hipify.hipify_python.file_add_header(filepath,header)
torch.utils.hipify.hipify_python.file_specific_replacement(filepath,search_string,replace_string,strict=False)
torch.utils.hipify.hipify_python.find_bracket_group(input_string,start)
torch.utils.hipify.hipify_python.find_closure_group(input_string,start,group)
torch.utils.hipify.hipify_python.find_parentheses_group(input_string,start)
torch.utils.hipify.hipify_python.fix_static_global_kernels(in_txt)
torch.utils.hipify.hipify_python.get_hip_file_path(filepath)
torch.utils.hipify.hipify_python.hip_header_magic(input_string)
torch.utils.hipify.hipify_python.hipify(project_directory,show_detailed=False,extensions=('.cu','.cuh','.c','.cc','.cpp','.h','.in','.hpp'),output_directory='',includes=(),extra_files=(),out_of_place_only=False,ignores=(),show_progress=True,hip_clang_launch=False,is_pytorch_extension=False,clean_ctx=None)
torch.utils.hipify.hipify_python.is_caffe2_gpu_file(filepath)
torch.utils.hipify.hipify_python.is_out_of_place(filepath)
torch.utils.hipify.hipify_python.is_pytorch_file(filepath)
torch.utils.hipify.hipify_python.matched_files_iter(root_path,includes=('*',),ignores=(),extensions=(),out_of_place_only=False,is_pytorch_extension=False)
torch.utils.hipify.hipify_python.openf(filename,mode)
torch.utils.hipify.hipify_python.preprocess(output_directory,all_files,show_detailed=False,show_progress=True,hip_clang_launch=False,is_pytorch_extension=False,clean_ctx=None)
torch.utils.hipify.hipify_python.preprocessor(output_directory,filepath,stats,hip_clang_launch,is_pytorch_extension,clean_ctx)
torch.utils.hipify.hipify_python.processKernelLaunches(string,stats)
torch.utils.hipify.hipify_python.replace_extern_shared(input_string)
torch.utils.hipify.hipify_python.replace_math_functions(input_string)
torch.utils.hipify.hipify_python.str2bool(v)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/hipify/constants.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/ffi/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/timer.py----------------------------------------
A:torch.utils.benchmark.utils.timer.globals->dict(globals or {})
A:torch.utils.benchmark.utils.timer.self._timer->self._timer_cls(stmt=stmt, setup=setup, timer=timer, globals=globals)
A:torch.utils.benchmark.utils.timer.self._task_spec->torch.utils.benchmark.utils.common.TaskSpec(stmt=stmt, setup=setup, label=label, sub_label=sub_label, description=description, env=env, num_threads=num_threads)
A:torch.utils.benchmark.utils.timer.time_spent->time_hook()
A:torch.utils.benchmark.utils.timer.can_stop->stop_hook(times)
A:torch.utils.benchmark.utils.timer.overhead->numpy.median([self._timer.timeit(0) for _ in range(5)])
A:torch.utils.benchmark.utils.timer.time_taken->self._timer.timeit(number)
A:torch.utils.benchmark.utils.timer.number->self._estimate_block_size(min_run_time)
A:torch.utils.benchmark.utils.timer.times->self._threaded_measurement_loop(number, time_hook, stop_hook, min_run_time=min_run_time, callback=callback)
torch.utils.benchmark.Timer(self,stmt='pass',setup='pass',timer=timer,globals:Optional[dict]=None,label:Optional[str]=None,sub_label:Optional[str]=None,description:Optional[str]=None,env:Optional[str]=None,num_threads=1)
torch.utils.benchmark.Timer._estimate_block_size(self,min_run_time:float)
torch.utils.benchmark.Timer._threaded_measurement_loop(self,number:int,time_hook:Callable[[],float],stop_hook:Callable[[List[float]],bool],min_run_time:float,max_run_time:Optional[float]=None,callback:Optional[Callable[[int,float],NoReturn]]=None)
torch.utils.benchmark.Timer.adaptive_autorange(self,threshold=0.1,max_run_time=10,callback:Optional[Callable[[int,float],NoReturn]]=None,min_run_time=0.01)
torch.utils.benchmark.Timer.autorange(self,callback=None)
torch.utils.benchmark.Timer.blocked_autorange(self,callback=None,min_run_time=0.2)
torch.utils.benchmark.Timer.collect_callgrind(self,number=100,collect_baseline=True)
torch.utils.benchmark.Timer.repeat(self,repeat=-1,number=-1)
torch.utils.benchmark.Timer.timeit(self,number=1000000)
torch.utils.benchmark.utils.timer.Timer(self,stmt='pass',setup='pass',timer=timer,globals:Optional[dict]=None,label:Optional[str]=None,sub_label:Optional[str]=None,description:Optional[str]=None,env:Optional[str]=None,num_threads=1)
torch.utils.benchmark.utils.timer.Timer.__init__(self,stmt='pass',setup='pass',timer=timer,globals:Optional[dict]=None,label:Optional[str]=None,sub_label:Optional[str]=None,description:Optional[str]=None,env:Optional[str]=None,num_threads=1)
torch.utils.benchmark.utils.timer.Timer._estimate_block_size(self,min_run_time:float)
torch.utils.benchmark.utils.timer.Timer._threaded_measurement_loop(self,number:int,time_hook:Callable[[],float],stop_hook:Callable[[List[float]],bool],min_run_time:float,max_run_time:Optional[float]=None,callback:Optional[Callable[[int,float],NoReturn]]=None)
torch.utils.benchmark.utils.timer.Timer.adaptive_autorange(self,threshold=0.1,max_run_time=10,callback:Optional[Callable[[int,float],NoReturn]]=None,min_run_time=0.01)
torch.utils.benchmark.utils.timer.Timer.autorange(self,callback=None)
torch.utils.benchmark.utils.timer.Timer.blocked_autorange(self,callback=None,min_run_time=0.2)
torch.utils.benchmark.utils.timer.Timer.collect_callgrind(self,number=100,collect_baseline=True)
torch.utils.benchmark.utils.timer.Timer.repeat(self,repeat=-1,number=-1)
torch.utils.benchmark.utils.timer.Timer.timeit(self,number=1000000)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/fuzzer.py----------------------------------------
A:torch.utils.benchmark.utils.fuzzer.self._distribution->self._check_distribution(distribution)
A:torch.utils.benchmark.utils.fuzzer.output->int(2 ** state.uniform(low=np.log2(self._minval) if self._minval is not None else None, high=np.log2(self._maxval) if self._maxval is not None else None))
A:torch.utils.benchmark.utils.fuzzer.index->numpy.random.RandomState(self._seed).choice(np.arange(len(self._distribution)), p=tuple(self._distribution.values()))
A:torch.utils.benchmark.utils.fuzzer.(size, steps, allocation_size)->self._get_size_and_steps(params)
A:torch.utils.benchmark.utils.fuzzer.raw_tensor->raw_tensor.permute(tuple(np.argsort(order))).permute(tuple(np.argsort(order)))
A:torch.utils.benchmark.utils.fuzzer.dim->len(size)
A:torch.utils.benchmark.utils.fuzzer.order->numpy.random.RandomState(self._seed).permutation(raw_tensor.dim())
A:torch.utils.benchmark.utils.fuzzer.values->tuple((params.get(i, i) for i in values))
A:torch.utils.benchmark.utils.fuzzer.size->resolve(self._size, dim)
A:torch.utils.benchmark.utils.fuzzer.steps->resolve(self._steps or (), dim)
A:torch.utils.benchmark.utils.fuzzer.allocation_size->tuple((size_i * step_i for (size_i, step_i) in zip(size, steps)))
A:torch.utils.benchmark.utils.fuzzer.(size, _, allocation_size)->self._get_size_and_steps(params)
A:torch.utils.benchmark.utils.fuzzer.num_elements->prod(size)
A:torch.utils.benchmark.utils.fuzzer.allocation_bytes->prod(allocation_size, base=dtype_size(self._dtype))
A:torch.utils.benchmark.utils.fuzzer.seed->numpy.random.RandomState().randint(0, 2 ** 63)
A:torch.utils.benchmark.utils.fuzzer.self._parameters->Fuzzer._unpack(parameters, FuzzedParameter)
A:torch.utils.benchmark.utils.fuzzer.self._tensors->Fuzzer._unpack(tensors, FuzzedTensor)
A:torch.utils.benchmark.utils.fuzzer.name_overlap->p_names.intersection(t_names)
A:torch.utils.benchmark.utils.fuzzer.state->numpy.random.RandomState(self._seed)
A:torch.utils.benchmark.utils.fuzzer.params->dict(params)
A:torch.utils.benchmark.utils.fuzzer.(tensor, properties)->t._make_tensor(params, state)
A:torch.utils.benchmark.utils.fuzzer.candidate_params[p.name]->p.sample(state)
A:torch.utils.benchmark.utils.fuzzer.candidate_params->self._resolve_aliases(candidate_params)
A:torch.utils.benchmark.utils.fuzzer.alias_count->sum((isinstance(v, ParameterAlias) for v in params.values()))
A:torch.utils.benchmark.utils.fuzzer.keys->list(params.keys())
A:torch.utils.benchmark.utils.fuzzer.alias_count_new->sum((isinstance(v, ParameterAlias) for v in params.values()))
torch.utils.benchmark.FuzzedParameter(self,name:str,minval:Optional[Union[int,float]]=None,maxval:Optional[Union[int,float]]=None,distribution:Optional[Union[str,Dict[Any,float]]]=None,strict:bool=False)
torch.utils.benchmark.FuzzedParameter._check_distribution(self,distribution)
torch.utils.benchmark.FuzzedParameter._custom_distribution(self,state)
torch.utils.benchmark.FuzzedParameter._loguniform(self,state)
torch.utils.benchmark.FuzzedParameter._uniform(self,state)
torch.utils.benchmark.FuzzedParameter.name(self)
torch.utils.benchmark.FuzzedParameter.sample(self,state)
torch.utils.benchmark.FuzzedTensor(self,name:str,size:Tuple[Union[str,int],...],steps:Optional[Tuple[Union[str,int],...]]=None,probability_contiguous:float=0.5,min_elements:Optional[int]=None,max_elements:Optional[int]=None,max_allocation_bytes:Optional[int]=None,dim_parameter:Optional[str]=None,roll_parameter:Optional[str]=None,dtype=torch.float32,cuda=False,tensor_constructor:Optional[Callable]=None)
torch.utils.benchmark.FuzzedTensor._get_size_and_steps(self,params)
torch.utils.benchmark.FuzzedTensor._make_tensor(self,params,state)
torch.utils.benchmark.FuzzedTensor.default_tensor_constructor(size,dtype,**kwargs)
torch.utils.benchmark.FuzzedTensor.name(self)
torch.utils.benchmark.FuzzedTensor.satisfies_constraints(self,params)
torch.utils.benchmark.Fuzzer(self,parameters:List[Union[FuzzedParameter,List[FuzzedParameter]]],tensors:List[Union[FuzzedTensor,List[FuzzedTensor]]],constraints:Optional[List[Callable]]=None,seed:Optional[int]=None)
torch.utils.benchmark.Fuzzer._generate(self,state)
torch.utils.benchmark.Fuzzer._resolve_aliases(params)
torch.utils.benchmark.Fuzzer._unpack(values,cls)
torch.utils.benchmark.Fuzzer.rejection_rate(self)
torch.utils.benchmark.Fuzzer.take(self,n)
torch.utils.benchmark.ParameterAlias(self,alias_to)
torch.utils.benchmark.ParameterAlias.__repr__(self)
torch.utils.benchmark.dtype_size(dtype)
torch.utils.benchmark.prod(values,base=1)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter(self,name:str,minval:Optional[Union[int,float]]=None,maxval:Optional[Union[int,float]]=None,distribution:Optional[Union[str,Dict[Any,float]]]=None,strict:bool=False)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter.__init__(self,name:str,minval:Optional[Union[int,float]]=None,maxval:Optional[Union[int,float]]=None,distribution:Optional[Union[str,Dict[Any,float]]]=None,strict:bool=False)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter._check_distribution(self,distribution)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter._custom_distribution(self,state)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter._loguniform(self,state)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter._uniform(self,state)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter.name(self)
torch.utils.benchmark.utils.fuzzer.FuzzedParameter.sample(self,state)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor(self,name:str,size:Tuple[Union[str,int],...],steps:Optional[Tuple[Union[str,int],...]]=None,probability_contiguous:float=0.5,min_elements:Optional[int]=None,max_elements:Optional[int]=None,max_allocation_bytes:Optional[int]=None,dim_parameter:Optional[str]=None,roll_parameter:Optional[str]=None,dtype=torch.float32,cuda=False,tensor_constructor:Optional[Callable]=None)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor.__init__(self,name:str,size:Tuple[Union[str,int],...],steps:Optional[Tuple[Union[str,int],...]]=None,probability_contiguous:float=0.5,min_elements:Optional[int]=None,max_elements:Optional[int]=None,max_allocation_bytes:Optional[int]=None,dim_parameter:Optional[str]=None,roll_parameter:Optional[str]=None,dtype=torch.float32,cuda=False,tensor_constructor:Optional[Callable]=None)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor._get_size_and_steps(self,params)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor._make_tensor(self,params,state)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor.default_tensor_constructor(size,dtype,**kwargs)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor.name(self)
torch.utils.benchmark.utils.fuzzer.FuzzedTensor.satisfies_constraints(self,params)
torch.utils.benchmark.utils.fuzzer.Fuzzer(self,parameters:List[Union[FuzzedParameter,List[FuzzedParameter]]],tensors:List[Union[FuzzedTensor,List[FuzzedTensor]]],constraints:Optional[List[Callable]]=None,seed:Optional[int]=None)
torch.utils.benchmark.utils.fuzzer.Fuzzer.__init__(self,parameters:List[Union[FuzzedParameter,List[FuzzedParameter]]],tensors:List[Union[FuzzedTensor,List[FuzzedTensor]]],constraints:Optional[List[Callable]]=None,seed:Optional[int]=None)
torch.utils.benchmark.utils.fuzzer.Fuzzer._generate(self,state)
torch.utils.benchmark.utils.fuzzer.Fuzzer._resolve_aliases(params)
torch.utils.benchmark.utils.fuzzer.Fuzzer._unpack(values,cls)
torch.utils.benchmark.utils.fuzzer.Fuzzer.rejection_rate(self)
torch.utils.benchmark.utils.fuzzer.Fuzzer.take(self,n)
torch.utils.benchmark.utils.fuzzer.ParameterAlias(self,alias_to)
torch.utils.benchmark.utils.fuzzer.ParameterAlias.__init__(self,alias_to)
torch.utils.benchmark.utils.fuzzer.ParameterAlias.__repr__(self)
torch.utils.benchmark.utils.fuzzer.dtype_size(dtype)
torch.utils.benchmark.utils.fuzzer.prod(values,base=1)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/compare.py----------------------------------------
A:torch.utils.benchmark.utils.compare.self._flat_results->list(it.chain(*grouped_results))
A:torch.utils.benchmark.utils.compare.unit_digits->max((d for d in leading_digits if d is not None))
A:torch.utils.benchmark.utils.compare.value->torch.utils.benchmark.utils.common.trim_sigfig(value, estimated_sigfigs)
A:torch.utils.benchmark.utils.compare.env->env.ljust(self._env_str_len + 4).ljust(self._env_str_len + 4)
A:torch.utils.benchmark.utils.compare.best_value->min([v for v in group_values if v is not None])
A:torch.utils.benchmark.utils.compare.col_str->self.color_segment(col_str, result.median, group_medians)
A:torch.utils.benchmark.utils.compare.(self.time_unit, self.time_scale)->torch.utils.benchmark.utils.common.select_unit(min((r.median for r in results)))
A:torch.utils.benchmark.utils.compare.self.row_keys->torch.utils.benchmark.utils.common.ordered_unique([self.row_fn(i) for i in results])
A:torch.utils.benchmark.utils.compare.self.column_keys->torch.utils.benchmark.utils.common.ordered_unique([self.col_fn(i) for i in results])
A:torch.utils.benchmark.utils.compare.(self.rows, self.columns)->self.populate_rows_and_columns()
A:torch.utils.benchmark.utils.compare.row_name_str_len->max((len(r.as_row_name) for r in self.results))
A:torch.utils.benchmark.utils.compare.column->_Column(grouped_results=grouped_results, time_scale=self.time_scale, time_unit=self.time_unit, trim_significant_figures=self._trim_significant_figures, highlight_warnings=self._highlight_warnings)
A:torch.utils.benchmark.utils.compare.num_cols->max((len(i) for i in string_rows))
A:torch.utils.benchmark.utils.compare.overall_width->len(finalized_columns[0])
A:torch.utils.benchmark.utils.compare.results->self._group_by_label(results)
A:torch.utils.benchmark.utils.compare.table->Table(results, self._colorize, self._trim_significant_figures, self._highlight_warnings)
torch.utils.benchmark.Compare(self,results:List[common.Measurement])
torch.utils.benchmark.Compare.__str__(self)
torch.utils.benchmark.Compare._group_by_label(self,results:List[common.Measurement])
torch.utils.benchmark.Compare._layout(self,results:List[common.Measurement])
torch.utils.benchmark.Compare._render(self)
torch.utils.benchmark.Compare.colorize(self)
torch.utils.benchmark.Compare.extend_results(self,results)
torch.utils.benchmark.Compare.highlight_warnings(self)
torch.utils.benchmark.Compare.print(self)
torch.utils.benchmark.Compare.trim_significant_figures(self)
torch.utils.benchmark.Table(self,results:List[common.Measurement],colorize:bool,trim_significant_figures:bool,highlight_warnings:bool)
torch.utils.benchmark.Table.col_fn(m:common.Measurement)->Optional[str]
torch.utils.benchmark.Table.populate_rows_and_columns(self)->Tuple[Tuple[_Row, ...], Tuple[_Column, ...]]
torch.utils.benchmark.Table.render(self)->str
torch.utils.benchmark.Table.row_fn(m:common.Measurement)->Tuple[int, Optional[str], str]
torch.utils.benchmark._Column(self,grouped_results:List[Tuple[Optional[common.Measurement],...]],time_scale:float,time_unit:str,trim_significant_figures:bool,highlight_warnings:bool)
torch.utils.benchmark._Column.get_results_for(self,group)
torch.utils.benchmark._Column.num_to_str(self,value:Optional[float],estimated_sigfigs:int,spread:Optional[float])
torch.utils.benchmark._Row(self,results,row_group,render_env,env_str_len,row_name_str_len,time_scale,colorize,num_threads=None)
torch.utils.benchmark._Row.as_column_strings(self)
torch.utils.benchmark._Row.color_segment(segment,value,group_values)
torch.utils.benchmark._Row.finalize_column_strings(self,column_strings,col_widths)
torch.utils.benchmark._Row.register_columns(self,columns:Tuple[_Column,...])
torch.utils.benchmark._Row.row_separator(self,overall_width)
torch.utils.benchmark.utils.compare.Compare(self,results:List[common.Measurement])
torch.utils.benchmark.utils.compare.Compare.__init__(self,results:List[common.Measurement])
torch.utils.benchmark.utils.compare.Compare.__str__(self)
torch.utils.benchmark.utils.compare.Compare._group_by_label(self,results:List[common.Measurement])
torch.utils.benchmark.utils.compare.Compare._layout(self,results:List[common.Measurement])
torch.utils.benchmark.utils.compare.Compare._render(self)
torch.utils.benchmark.utils.compare.Compare.colorize(self)
torch.utils.benchmark.utils.compare.Compare.extend_results(self,results)
torch.utils.benchmark.utils.compare.Compare.highlight_warnings(self)
torch.utils.benchmark.utils.compare.Compare.print(self)
torch.utils.benchmark.utils.compare.Compare.trim_significant_figures(self)
torch.utils.benchmark.utils.compare.Table(self,results:List[common.Measurement],colorize:bool,trim_significant_figures:bool,highlight_warnings:bool)
torch.utils.benchmark.utils.compare.Table.__init__(self,results:List[common.Measurement],colorize:bool,trim_significant_figures:bool,highlight_warnings:bool)
torch.utils.benchmark.utils.compare.Table.col_fn(m:common.Measurement)->Optional[str]
torch.utils.benchmark.utils.compare.Table.populate_rows_and_columns(self)->Tuple[Tuple[_Row, ...], Tuple[_Column, ...]]
torch.utils.benchmark.utils.compare.Table.render(self)->str
torch.utils.benchmark.utils.compare.Table.row_fn(m:common.Measurement)->Tuple[int, Optional[str], str]
torch.utils.benchmark.utils.compare._Column(self,grouped_results:List[Tuple[Optional[common.Measurement],...]],time_scale:float,time_unit:str,trim_significant_figures:bool,highlight_warnings:bool)
torch.utils.benchmark.utils.compare._Column.__init__(self,grouped_results:List[Tuple[Optional[common.Measurement],...]],time_scale:float,time_unit:str,trim_significant_figures:bool,highlight_warnings:bool)
torch.utils.benchmark.utils.compare._Column.get_results_for(self,group)
torch.utils.benchmark.utils.compare._Column.num_to_str(self,value:Optional[float],estimated_sigfigs:int,spread:Optional[float])
torch.utils.benchmark.utils.compare._Row(self,results,row_group,render_env,env_str_len,row_name_str_len,time_scale,colorize,num_threads=None)
torch.utils.benchmark.utils.compare._Row.__init__(self,results,row_group,render_env,env_str_len,row_name_str_len,time_scale,colorize,num_threads=None)
torch.utils.benchmark.utils.compare._Row.as_column_strings(self)
torch.utils.benchmark.utils.compare._Row.color_segment(segment,value,group_values)
torch.utils.benchmark.utils.compare._Row.finalize_column_strings(self,column_strings,col_widths)
torch.utils.benchmark.utils.compare._Row.register_columns(self,columns:Tuple[_Column,...])
torch.utils.benchmark.utils.compare._Row.row_separator(self,overall_width)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/common.py----------------------------------------
A:torch.utils.benchmark.utils.common._TASKSPEC_FIELDS->tuple((i.name for i in dataclasses.fields(TaskSpec)))
A:torch.utils.benchmark.utils.common.n_total->len(self._sorted_times)
A:torch.utils.benchmark.utils.common.lower_bound->int(n_total // 4)
A:torch.utils.benchmark.utils.common.upper_bound->int(np.ceil(3 * n_total / 4))
A:torch.utils.benchmark.utils.common.std->numpy.std(interquartile_points)
A:torch.utils.benchmark.utils.common.sqrt_n->numpy.sqrt(len(interquartile_points))
A:torch.utils.benchmark.utils.common.confidence_interval->max(1.645 * std / sqrt_n, _MIN_CONFIDENCE_INTERVAL)
A:torch.utils.benchmark.utils.common.relative_ci->numpy.log10(self._median / confidence_interval)
A:torch.utils.benchmark.utils.common.num_significant_figures->int(np.floor(relative_ci))
A:torch.utils.benchmark.utils.common.self._sorted_times->tuple(sorted(self.times))
A:torch.utils.benchmark.utils.common.self._median->numpy.median(self._sorted_times)
A:torch.utils.benchmark.utils.common.self._mean->numpy.mean(self._sorted_times)
A:torch.utils.benchmark.utils.common.self._p25->numpy.percentile(self._sorted_times, 25)
A:torch.utils.benchmark.utils.common.self._p75->numpy.percentile(self._sorted_times, 75)
A:torch.utils.benchmark.utils.common.n->len(self._sorted_times)
A:torch.utils.benchmark.utils.common.(time_unit, time_scale)->select_unit(self._median)
A:torch.utils.benchmark.utils.common.repr_str->f"\n{super().__repr__()}\n{self.title}\n  {self.description or skip_line}\n  {('Median: ' if n > 1 else '')}{self._median / time_scale:.2f} {time_unit}\n  {iqr_filter}IQR:    {self.iqr / time_scale:.2f} {time_unit} ({self._p25 / time_scale:.2f} to {self._p75 / time_scale:.2f})\n  {n} measurement{('s' if n > 1 else '')}, {self.number_per_run} runs {('per measurement,' if n > 1 else ',')} {self.num_threads} thread{('s' if self.num_threads > 1 else '')}\n{newline.join(self._warnings)}".strip()
A:torch.utils.benchmark.utils.common.time_unit->{-3: 'ns', -2: 'us', -1: 'ms'}.get(int(np.log10(t) // 3), 's')
A:torch.utils.benchmark.utils.common.magnitude->int(np.ceil(np.log10(np.abs(x))))
A:torch.utils.benchmark.utils.common.prior_num_threads->torch.get_num_threads()
torch.utils.benchmark.Measurement
torch.utils.benchmark.Measurement.__getattr__(self,name)
torch.utils.benchmark.Measurement.__post_init__(self)
torch.utils.benchmark.Measurement.__repr__(self)
torch.utils.benchmark.Measurement._lazy_init(self)
torch.utils.benchmark.Measurement.as_row_name(self)->str
torch.utils.benchmark.Measurement.env(self)->str
torch.utils.benchmark.Measurement.has_warnings(self)->bool
torch.utils.benchmark.Measurement.iqr(self)->float
torch.utils.benchmark.Measurement.mean(self)->float
torch.utils.benchmark.Measurement.median(self)->float
torch.utils.benchmark.Measurement.meets_confidence(self,threshold=_IQR_WARN_THRESHOLD)->bool
torch.utils.benchmark.Measurement.merge(measurements)
torch.utils.benchmark.Measurement.significant_figures(self)->int
torch.utils.benchmark.Measurement.times(self)->List[float]
torch.utils.benchmark.Measurement.title(self)->str
torch.utils.benchmark.TaskSpec
torch.utils.benchmark.ordered_unique(elements)
torch.utils.benchmark.select_unit(t:float)
torch.utils.benchmark.set_torch_threads(n:int)
torch.utils.benchmark.trim_sigfig(x:float,n:int)->float
torch.utils.benchmark.unit_to_english(u:str)->str
torch.utils.benchmark.utils.common.Measurement
torch.utils.benchmark.utils.common.Measurement.__getattr__(self,name)
torch.utils.benchmark.utils.common.Measurement.__post_init__(self)
torch.utils.benchmark.utils.common.Measurement.__repr__(self)
torch.utils.benchmark.utils.common.Measurement._lazy_init(self)
torch.utils.benchmark.utils.common.Measurement.as_row_name(self)->str
torch.utils.benchmark.utils.common.Measurement.env(self)->str
torch.utils.benchmark.utils.common.Measurement.has_warnings(self)->bool
torch.utils.benchmark.utils.common.Measurement.iqr(self)->float
torch.utils.benchmark.utils.common.Measurement.mean(self)->float
torch.utils.benchmark.utils.common.Measurement.median(self)->float
torch.utils.benchmark.utils.common.Measurement.meets_confidence(self,threshold=_IQR_WARN_THRESHOLD)->bool
torch.utils.benchmark.utils.common.Measurement.merge(measurements)
torch.utils.benchmark.utils.common.Measurement.significant_figures(self)->int
torch.utils.benchmark.utils.common.Measurement.times(self)->List[float]
torch.utils.benchmark.utils.common.Measurement.title(self)->str
torch.utils.benchmark.utils.common.TaskSpec
torch.utils.benchmark.utils.common.ordered_unique(elements)
torch.utils.benchmark.utils.common.select_unit(t:float)
torch.utils.benchmark.utils.common.set_torch_threads(n:int)
torch.utils.benchmark.utils.common.trim_sigfig(x:float,n:int)->float
torch.utils.benchmark.utils.common.unit_to_english(u:str)->str


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/valgrind_wrapper/timer_interface.py----------------------------------------
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.FunctionCount->NamedTuple('FunctionCount', [('count', int), ('function', str)])
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.output->textwrap.dedent(f"\n        {super().__repr__()}\n          stmt:  {self.stmt.replace(newline, newline + ' ' * 9)}\n          setup: {self.setup.replace(newline, newline + ' ' * 9)}\n          {self.num_threads} thread{('s' if self.num_threads > 1 else '')}\n        {'':>25}All{'':>10}Noisy symbols removed\n          Instructions: {self._counts(self_stats, True):>12}{'':>15}{self._counts(self_stats, False):>12}\n          Baseline:     {self._counts(base_stats, True):>12}{'':>15}{self._counts(base_stats, False):>12}\n        ").strip()
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.first->self.stats(inclusive=inclusive)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.second->other.stats(inclusive=inclusive)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.fn->re.sub('\\s\\[.+\\]$', '', fn)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.counts->collections.defaultdict(int, {fn: c for (c, fn) in first})
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.build_search->re.search('BUILD_TYPE=(.+),', torch.__config__.show())
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.self._baseline_cache[cache_key]->self._invoke(stmt='pass', setup='pass', number=number, num_threads=num_threads)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.(stmt_inclusive_stats, stmt_exclusive_stats)->self._invoke(stmt=stmt, setup=setup, number=number, num_threads=num_threads)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.working_dir->tempfile.mkdtemp()
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.script_file->os.path.join(working_dir, 'timer_callgrind.py')
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.callgrind_out->os.path.join(working_dir, 'callgrind.out')
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.error_log->os.path.join(working_dir, 'error.txt')
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.stat_log->os.path.join(working_dir, 'callgrind_stat.txt')
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.stdout_stderr_log->os.path.join(working_dir, 'stdout_stderr.log')
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.f_stdout_stderr->open(stdout_stderr_log, 'wb')
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.invocation->subprocess.run(args, stdout=f_stdout_stderr, stderr=subprocess.STDOUT, **kwargs)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.(valgrind_invocation, valgrind_invocation_output)->run(['valgrind', '--tool=callgrind', f'--callgrind-out-file={callgrind_out}', '--dump-line=yes', '--dump-instr=yes', '--instr-atstart=yes', '--collect-atstart=no', 'python', script_file])
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.error_report->f.read()
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.(annotate_invocation, annotate_invocation_output)->run(['callgrind_annotate', f"--inclusive={('yes' if inclusive else 'no')}", callgrind_out], check=True)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.count_match->re.match('^\\s*([0-9,]+)\\s+(.+:.+)$', l)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.(ir_str, file_function)->re.match('^\\s*([0-9,]+)\\s+(.+:.+)$', l).groups()
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.ir->int(ir_str.replace(',', ''))
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.unrolled_stmts->textwrap.indent('\n'.join([stmt] * block_size), ' ' * 4)
A:torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CALLGRIND_SINGLETON->_ValgrindWrapper()
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats(object)
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats.__repr__(self)->str
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats._counts(stats:Tuple[FunctionCount,...],include_lookdict_unicode:bool)->int
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats._diff(first:Tuple[FunctionCount,...],second:Tuple[FunctionCount,...])->Tuple[FunctionCount, ...]
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats.as_standardized(self)->'CallgrindStats'
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats.counts(self,*,include_lookdict_unicode:bool=True)->int
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats.delta(self,other,inclusive:bool=False,subtract_baselines:bool=True)->Tuple[FunctionCount, ...]
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.CallgrindStats.stats(self,inclusive:bool=False)->Tuple[FunctionCount, ...]
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper(self)
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper.__init__(self)
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper._construct_script(stmt:str,setup:str,number:int,num_threads:int,error_log:str,stat_log:str)->str
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper._invoke(self,stmt:str,setup:str,number:int,num_threads:int)->Tuple[Tuple[FunctionCount, ...], Tuple[FunctionCount, ...]]
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper._validate(self)->None
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface._ValgrindWrapper.collect_callgrind(self,stmt:str,setup:str,number:int,num_threads:int,collect_baseline:bool)->CallgrindStats
torch.utils.benchmark.utils.valgrind_wrapper.timer_interface.wrapper_singleton()->_ValgrindWrapper


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/utils/valgrind_wrapper/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/op_fuzzers/unary.py----------------------------------------
A:torch.utils.benchmark.op_fuzzers.unary._POW_TWO_SIZES->tuple((2 ** i for i in range(int(np.log2(_MIN_DIM_SIZE)), int(np.log2(_MAX_DIM_SIZE)) + 1)))
torch.utils.benchmark.op_fuzzers.unary.UnaryOpFuzzer(self,seed,dtype=torch.float32,cuda=False)
torch.utils.benchmark.op_fuzzers.unary.UnaryOpFuzzer.__init__(self,seed,dtype=torch.float32,cuda=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/op_fuzzers/binary.py----------------------------------------
A:torch.utils.benchmark.op_fuzzers.binary._POW_TWO_SIZES->tuple((2 ** i for i in range(int(np.log2(_MIN_DIM_SIZE)), int(np.log2(_MAX_DIM_SIZE)) + 1)))
torch.utils.benchmark.op_fuzzers.binary.BinaryOpFuzzer(self,seed,dtype=torch.float32,cuda=False)
torch.utils.benchmark.op_fuzzers.binary.BinaryOpFuzzer.__init__(self,seed,dtype=torch.float32,cuda=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/op_fuzzers/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/examples/end_to_end.py----------------------------------------
A:torch.utils.benchmark.examples.end_to_end._AVAILABLE_GPUS->queue.Queue[int]()
A:torch.utils.benchmark.examples.end_to_end.parser->argparse.ArgumentParser()
A:torch.utils.benchmark.examples.end_to_end.args->parse_args()
A:torch.utils.benchmark.examples.end_to_end.args.num_gpus->torch.cuda.device_count()
A:torch.utils.benchmark.examples.end_to_end.state->numpy.random.RandomState(params['random_value'])
A:torch.utils.benchmark.examples.end_to_end.topk_dim->numpy.random.RandomState(params['random_value']).randint(low=0, high=dim)
A:torch.utils.benchmark.examples.end_to_end.k->max(int(np.floor(2 ** state.uniform(low=0, high=np.log2(dim_size)))), 1)
A:torch.utils.benchmark.examples.end_to_end.sort_dim->numpy.random.RandomState(params['random_value']).randint(low=0, high=params['dim'])
A:torch.utils.benchmark.examples.end_to_end.iterator->torch.utils.benchmark.op_fuzzers.unary.UnaryOpFuzzer(seed=seed, dtype=dtype, cuda=cuda).take(_RUNS_PER_LOOP)
A:torch.utils.benchmark.examples.end_to_end.(stmt, label)->construct_stmt_and_label(args.pr, params)
A:torch.utils.benchmark.examples.end_to_end.timer->Timer(stmt=stmt, globals=tensors, label=label, description=f'[{i}, seed={seed}] ({dtype_str}), stmt = {stmt}', env=args.DETAIL_env)
A:torch.utils.benchmark.examples.end_to_end.measurement->Timer(stmt=stmt, globals=tensors, label=label, description=f'[{i}, seed={seed}] ({dtype_str}), stmt = {stmt}', env=args.DETAIL_env).blocked_autorange(min_run_time=_MIN_RUN_SEC)
A:torch.utils.benchmark.examples.end_to_end.pools[_GPU]->multiprocessing.dummy.Pool(args.num_gpus)
A:torch.utils.benchmark.examples.end_to_end.map_iters[_GPU]->multiprocessing.dummy.Pool(args.num_gpus).imap(map_fn, trials)
A:torch.utils.benchmark.examples.end_to_end.cpu_workers->int(multiprocessing.cpu_count() / 3)
A:torch.utils.benchmark.examples.end_to_end.pools[_CPU]->multiprocessing.dummy.Pool(cpu_workers)
A:torch.utils.benchmark.examples.end_to_end.map_iters[_CPU]->multiprocessing.dummy.Pool(cpu_workers).imap(map_fn, trials)
A:torch.utils.benchmark.examples.end_to_end.merged_state['times']->list(it.chain(*times))
A:torch.utils.benchmark.examples.end_to_end.flagged_for_removal->set()
A:torch.utils.benchmark.examples.end_to_end.device_str->f"== {device_str} {(' (Variance Test)' if test_variance else '')}  ".ljust(40, '=')
A:torch.utils.benchmark.examples.end_to_end.results->sorted(((key, (r_ref, r_pr), r_pr.median / r_ref.median - 1) for (key, (r_ref, r_pr)) in results), key=lambda i: i[2])
A:torch.utils.benchmark.examples.end_to_end.n->len(results)
A:torch.utils.benchmark.examples.end_to_end.n_regressed->len([i for i in results if i[2] > 0.05])
A:torch.utils.benchmark.examples.end_to_end.n_improved->len([i for i in results if i[2] < -0.05])
A:torch.utils.benchmark.examples.end_to_end.(_, result_log_file)->tempfile.mkstemp(suffix='.log')
A:torch.utils.benchmark.examples.end_to_end.row->row_str(rel_diff, r_pr.median - r_ref.median, r_ref)
A:torch.utils.benchmark.examples.end_to_end.order->str('' if all((i == j for (i, j) in zip(order, range(dim)))) else order)
A:torch.utils.benchmark.examples.end_to_end.(dim_str, k_str)->Timer(stmt=stmt, globals=tensors, label=label, description=f'[{i}, seed={seed}] ({dtype_str}), stmt = {stmt}', env=args.DETAIL_env).blocked_autorange(min_run_time=_MIN_RUN_SEC).stmt[:-1].replace('torch.topk(x, ', '').split(', ')
A:torch.utils.benchmark.examples.end_to_end.task_specific->Timer(stmt=stmt, globals=tensors, label=label, description=f'[{i}, seed={seed}] ({dtype_str}), stmt = {stmt}', env=args.DETAIL_env).blocked_autorange(min_run_time=_MIN_RUN_SEC).stmt[:-1].replace('torch.sort(x, ', '')
A:torch.utils.benchmark.examples.end_to_end.result->run(f'source activate {env}')
A:torch.utils.benchmark.examples.end_to_end.(_, result_file)->tempfile.mkstemp(suffix='.pkl')
A:torch.utils.benchmark.examples.end_to_end.cmd->_SUBPROCESS_CMD_TEMPLATE.format(source_env=envs[0] if test_variance else env, env=env, pr=pr, device=_GPU if use_gpu else _CPU, result_file=result_file, seed=seed)
torch.utils.benchmark.examples.end_to_end._main(args)
torch.utils.benchmark.examples.end_to_end.construct_stmt_and_label(pr,params)
torch.utils.benchmark.examples.end_to_end.construct_table(results,device_str,test_variance)
torch.utils.benchmark.examples.end_to_end.main(args)
torch.utils.benchmark.examples.end_to_end.map_fn(args)
torch.utils.benchmark.examples.end_to_end.merge(measurements)
torch.utils.benchmark.examples.end_to_end.parse_args()
torch.utils.benchmark.examples.end_to_end.process_results(results,test_variance)
torch.utils.benchmark.examples.end_to_end.read_results(result_file:str)
torch.utils.benchmark.examples.end_to_end.row_str(rel_diff,diff_seconds,measurement)
torch.utils.benchmark.examples.end_to_end.run(cmd,cuda_visible_devices='')
torch.utils.benchmark.examples.end_to_end.subprocess_main(args)
torch.utils.benchmark.examples.end_to_end.test_source(envs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/examples/fuzzer.py----------------------------------------
A:torch.utils.benchmark.examples.fuzzer.add_fuzzer->torch.utils.benchmark.Fuzzer(parameters=[[benchmark_utils.FuzzedParameter(name=f'k{i}', minval=16, maxval=16 * 1024, distribution='loguniform') for i in range(3)], benchmark_utils.FuzzedParameter(name='d', distribution={2: 0.6, 3: 0.4})], tensors=[[benchmark_utils.FuzzedTensor(name=name, size=('k0', 'k1', 'k2'), dim_parameter='d', probability_contiguous=0.75, min_elements=64 * 1024, max_elements=128 * 1024) for name in ('x', 'y')]], seed=0)
A:torch.utils.benchmark.examples.fuzzer.shape->', '.join(tuple((f'{i:>4}' for i in x.shape)))
A:torch.utils.benchmark.examples.fuzzer.description->''.join([f'{x.numel():>7} | {shape:<16} | ', f"{('contiguous' if x.is_contiguous() else x_order):<12} | ", f"{('contiguous' if y.is_contiguous() else y_order):<12} | "])
A:torch.utils.benchmark.examples.fuzzer.timer->torch.utils.benchmark.Timer(stmt='x + y', globals=tensors, description=description)
torch.utils.benchmark.examples.fuzzer.main()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/examples/compare.py----------------------------------------
A:torch.utils.benchmark.examples.compare.numel->int(result.numel())
A:torch.utils.benchmark.examples.compare.comparison->torch.utils.benchmark.Compare([pickle.loads(i) for i in serialized_results])
torch.utils.benchmark.examples.compare.FauxTorch(self,real_torch,extra_ns_per_element)
torch.utils.benchmark.examples.compare.FauxTorch.__init__(self,real_torch,extra_ns_per_element)
torch.utils.benchmark.examples.compare.FauxTorch.add(self,*args,**kwargs)
torch.utils.benchmark.examples.compare.FauxTorch.cat(self,*args,**kwargs)
torch.utils.benchmark.examples.compare.FauxTorch.extra_overhead(self,result)
torch.utils.benchmark.examples.compare.FauxTorch.matmul(self,*args,**kwargs)
torch.utils.benchmark.examples.compare.FauxTorch.mul(self,*args,**kwargs)
torch.utils.benchmark.examples.compare.main()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/examples/op_benchmark.py----------------------------------------
A:torch.utils.benchmark.examples.op_benchmark.float_iter->fuzzer_cls(seed=0, dtype=torch.float32).take(n)
A:torch.utils.benchmark.examples.op_benchmark.int_iter->fuzzer_cls(seed=0, dtype=torch.int32).take(n)
A:torch.utils.benchmark.examples.op_benchmark.name_len->max(name_len, len(name))
A:torch.utils.benchmark.examples.op_benchmark.shape_len->max(shape_len, len(shape))
A:torch.utils.benchmark.examples.op_benchmark.order_len->max(order_len, len(order))
A:torch.utils.benchmark.examples.op_benchmark.steps_len->max(steps_len, len(steps))
A:torch.utils.benchmark.examples.op_benchmark.name->f'{name}:'.ljust(name_len + 1)
A:torch.utils.benchmark.examples.op_benchmark.shape->shape.ljust(shape_len + 10).ljust(shape_len + 10)
A:torch.utils.benchmark.examples.op_benchmark.order->order.ljust(order_len).ljust(order_len)
torch.utils.benchmark.examples.op_benchmark.assert_dicts_equal(dict_0,dict_1)
torch.utils.benchmark.examples.op_benchmark.main()
torch.utils.benchmark.examples.op_benchmark.run(n,stmt,fuzzer_cls)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/examples/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/benchmark/examples/simple_timeit.py----------------------------------------
A:torch.utils.benchmark.examples.simple_timeit.timer->torch.utils.benchmark.Timer(stmt='x + y', globals={'x': torch.ones((4, 8)), 'y': torch.ones((1, 8))}, label='Broadcasting add (4x8)')
torch.utils.benchmark.examples.simple_timeit.main()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_utils.py----------------------------------------
A:torch.utils.tensorboard._utils.canvas->numpy.zeros((3, H * nrows, W * ncols), dtype=I.dtype)
A:torch.utils.tensorboard._utils.data->numpy.frombuffer(canvas.buffer_rgba(), dtype=np.uint8)
A:torch.utils.tensorboard._utils.(w, h)->figure.canvas.get_width_height()
A:torch.utils.tensorboard._utils.image_chw->numpy.moveaxis(image_hwc, source=2, destination=0)
A:torch.utils.tensorboard._utils.image->render_to_rgb(figures)
A:torch.utils.tensorboard._utils.len_addition->int(2 ** V.shape[0].bit_length() - V.shape[0])
A:torch.utils.tensorboard._utils.V->numpy.reshape(V, newshape=(t, n_rows * h, n_cols * w, c))
A:torch.utils.tensorboard._utils.I->numpy.concatenate([I, I, I], 1)
A:torch.utils.tensorboard._utils.ncols->min(nimg, ncols)
A:torch.utils.tensorboard._utils.nrows->int(np.ceil(float(nimg) / ncols))
A:torch.utils.tensorboard._utils.input_format->input_format.upper().upper()
A:torch.utils.tensorboard._utils.tensor_NCHW->numpy.stack([tensor, tensor, tensor], 2).transpose(index)
A:torch.utils.tensorboard._utils.tensor_CHW->make_grid(tensor_NCHW)
A:torch.utils.tensorboard._utils.tensor_HWC->numpy.concatenate([tensor_HWC, tensor_HWC, tensor_HWC], 2)
A:torch.utils.tensorboard._utils.tensor->numpy.stack([tensor, tensor, tensor], 2)
torch.utils.tensorboard._utils._prepare_video(V)
torch.utils.tensorboard._utils.convert_to_HWC(tensor,input_format)
torch.utils.tensorboard._utils.figure_to_image(figures,close=True)
torch.utils.tensorboard._utils.make_grid(I,ncols=8)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_convert_np.py----------------------------------------
A:torch.utils.tensorboard._convert_np.x->caffe2.python.workspace.FetchBlob(x)
torch.utils.tensorboard._convert_np._prepare_caffe2(x)
torch.utils.tensorboard._convert_np._prepare_pytorch(x)
torch.utils.tensorboard._convert_np.make_np(x)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/writer.py----------------------------------------
A:torch.utils.tensorboard.writer.log_dir->os.path.join('runs', current_time + '_' + socket.gethostname() + comment)
A:torch.utils.tensorboard.writer.self.event_writer->EventFileWriter(log_dir, max_queue, flush_secs, filename_suffix)
A:torch.utils.tensorboard.writer.event.step->int(step)
A:torch.utils.tensorboard.writer.event->tensorboard.compat.proto.event_pb2.Event(graph_def=current_graph.SerializeToString())
A:torch.utils.tensorboard.writer.trm->tensorboard.compat.proto.event_pb2.TaggedRunMetadata(tag='step1', run_metadata=stepstats.SerializeToString())
A:torch.utils.tensorboard.writer.current_time->datetime.datetime.now().strftime('%b%d_%H-%M-%S')
A:torch.utils.tensorboard.writer.self.file_writer->FileWriter(self.log_dir, self.max_queue, self.flush_secs, self.filename_suffix)
A:torch.utils.tensorboard.writer.(exp, ssi, sei)->hparams(hparam_dict, metric_dict, hparam_domain_discrete)
A:torch.utils.tensorboard.writer.run_name->str(time.time())
A:torch.utils.tensorboard.writer.logdir->os.path.join(self._get_file_writer().get_logdir(), run_name)
A:torch.utils.tensorboard.writer.scalar_value->caffe2.python.workspace.FetchBlob(scalar_value)
A:torch.utils.tensorboard.writer.fw_logdir->self._get_file_writer().get_logdir()
A:torch.utils.tensorboard.writer.fw->FileWriter(fw_tag, self.max_queue, self.flush_secs, self.filename_suffix)
A:torch.utils.tensorboard.writer.values->caffe2.python.workspace.FetchBlob(values)
A:torch.utils.tensorboard.writer.img_tensor->caffe2.python.workspace.FetchBlob(img_tensor)
A:torch.utils.tensorboard.writer.box_tensor->caffe2.python.workspace.FetchBlob(box_tensor)
A:torch.utils.tensorboard.writer.snd_tensor->caffe2.python.workspace.FetchBlob(snd_tensor)
A:torch.utils.tensorboard.writer.current_graph->model_to_graph_def(model)
A:torch.utils.tensorboard.writer.retval->retval.replace('\\', '%%%02x' % ord('\\')).replace('\\', '%%%02x' % ord('\\'))
A:torch.utils.tensorboard.writer.mat->make_np(mat)
A:torch.utils.tensorboard.writer.save_path->os.path.join(self._get_file_writer().get_logdir(), subdir)
A:torch.utils.tensorboard.writer.fs->tensorboard.compat.tf.io.gfile.get_filesystem(save_path)
A:torch.utils.tensorboard.writer.self._projector_config->ProjectorConfig()
A:torch.utils.tensorboard.writer.embedding_info->get_embedding_info(metadata, label_img, fs, subdir, global_step, tag)
A:torch.utils.tensorboard.writer.config_pbtxt->google.protobuf.text_format.MessageToString(self._projector_config)
torch.utils.tensorboard.FileWriter(self,log_dir,max_queue=10,flush_secs=120,filename_suffix='')
torch.utils.tensorboard.FileWriter.add_event(self,event,step=None,walltime=None)
torch.utils.tensorboard.FileWriter.add_graph(self,graph_profile,walltime=None)
torch.utils.tensorboard.FileWriter.add_onnx_graph(self,graph,walltime=None)
torch.utils.tensorboard.FileWriter.add_summary(self,summary,global_step=None,walltime=None)
torch.utils.tensorboard.FileWriter.close(self)
torch.utils.tensorboard.FileWriter.flush(self)
torch.utils.tensorboard.FileWriter.get_logdir(self)
torch.utils.tensorboard.FileWriter.reopen(self)
torch.utils.tensorboard.SummaryWriter(self,log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')
torch.utils.tensorboard.SummaryWriter.__enter__(self)
torch.utils.tensorboard.SummaryWriter.__exit__(self,exc_type,exc_val,exc_tb)
torch.utils.tensorboard.SummaryWriter._check_caffe2_blob(self,item)
torch.utils.tensorboard.SummaryWriter._encode(rawstr)
torch.utils.tensorboard.SummaryWriter._get_file_writer(self)
torch.utils.tensorboard.SummaryWriter.add_audio(self,tag,snd_tensor,global_step=None,sample_rate=44100,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_custom_scalars(self,layout)
torch.utils.tensorboard.SummaryWriter.add_custom_scalars_marginchart(self,tags,category='default',title='untitled')
torch.utils.tensorboard.SummaryWriter.add_custom_scalars_multilinechart(self,tags,category='default',title='untitled')
torch.utils.tensorboard.SummaryWriter.add_embedding(self,mat,metadata=None,label_img=None,global_step=None,tag='default',metadata_header=None)
torch.utils.tensorboard.SummaryWriter.add_figure(self,tag,figure,global_step=None,close=True,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_graph(self,model,input_to_model=None,verbose=False)
torch.utils.tensorboard.SummaryWriter.add_histogram(self,tag,values,global_step=None,bins='tensorflow',walltime=None,max_bins=None)
torch.utils.tensorboard.SummaryWriter.add_histogram_raw(self,tag,min,max,num,sum,sum_squares,bucket_limits,bucket_counts,global_step=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_hparams(self,hparam_dict,metric_dict,hparam_domain_discrete=None,run_name=None)
torch.utils.tensorboard.SummaryWriter.add_image(self,tag,img_tensor,global_step=None,walltime=None,dataformats='CHW')
torch.utils.tensorboard.SummaryWriter.add_image_with_boxes(self,tag,img_tensor,box_tensor,global_step=None,walltime=None,rescale=1,dataformats='CHW',labels=None)
torch.utils.tensorboard.SummaryWriter.add_images(self,tag,img_tensor,global_step=None,walltime=None,dataformats='NCHW')
torch.utils.tensorboard.SummaryWriter.add_mesh(self,tag,vertices,colors=None,faces=None,config_dict=None,global_step=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_onnx_graph(self,prototxt)
torch.utils.tensorboard.SummaryWriter.add_pr_curve(self,tag,labels,predictions,global_step=None,num_thresholds=127,weights=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_pr_curve_raw(self,tag,true_positive_counts,false_positive_counts,true_negative_counts,false_negative_counts,precision,recall,global_step=None,num_thresholds=127,weights=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_scalar(self,tag,scalar_value,global_step=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_scalars(self,main_tag,tag_scalar_dict,global_step=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_text(self,tag,text_string,global_step=None,walltime=None)
torch.utils.tensorboard.SummaryWriter.add_video(self,tag,vid_tensor,global_step=None,fps=4,walltime=None)
torch.utils.tensorboard.SummaryWriter.close(self)
torch.utils.tensorboard.SummaryWriter.flush(self)
torch.utils.tensorboard.SummaryWriter.get_logdir(self)
torch.utils.tensorboard.writer.FileWriter(self,log_dir,max_queue=10,flush_secs=120,filename_suffix='')
torch.utils.tensorboard.writer.FileWriter.__init__(self,log_dir,max_queue=10,flush_secs=120,filename_suffix='')
torch.utils.tensorboard.writer.FileWriter.add_event(self,event,step=None,walltime=None)
torch.utils.tensorboard.writer.FileWriter.add_graph(self,graph_profile,walltime=None)
torch.utils.tensorboard.writer.FileWriter.add_onnx_graph(self,graph,walltime=None)
torch.utils.tensorboard.writer.FileWriter.add_summary(self,summary,global_step=None,walltime=None)
torch.utils.tensorboard.writer.FileWriter.close(self)
torch.utils.tensorboard.writer.FileWriter.flush(self)
torch.utils.tensorboard.writer.FileWriter.get_logdir(self)
torch.utils.tensorboard.writer.FileWriter.reopen(self)
torch.utils.tensorboard.writer.SummaryWriter(self,log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')
torch.utils.tensorboard.writer.SummaryWriter.__enter__(self)
torch.utils.tensorboard.writer.SummaryWriter.__exit__(self,exc_type,exc_val,exc_tb)
torch.utils.tensorboard.writer.SummaryWriter.__init__(self,log_dir=None,comment='',purge_step=None,max_queue=10,flush_secs=120,filename_suffix='')
torch.utils.tensorboard.writer.SummaryWriter._check_caffe2_blob(self,item)
torch.utils.tensorboard.writer.SummaryWriter._encode(rawstr)
torch.utils.tensorboard.writer.SummaryWriter._get_file_writer(self)
torch.utils.tensorboard.writer.SummaryWriter.add_audio(self,tag,snd_tensor,global_step=None,sample_rate=44100,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars(self,layout)
torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars_marginchart(self,tags,category='default',title='untitled')
torch.utils.tensorboard.writer.SummaryWriter.add_custom_scalars_multilinechart(self,tags,category='default',title='untitled')
torch.utils.tensorboard.writer.SummaryWriter.add_embedding(self,mat,metadata=None,label_img=None,global_step=None,tag='default',metadata_header=None)
torch.utils.tensorboard.writer.SummaryWriter.add_figure(self,tag,figure,global_step=None,close=True,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_graph(self,model,input_to_model=None,verbose=False)
torch.utils.tensorboard.writer.SummaryWriter.add_histogram(self,tag,values,global_step=None,bins='tensorflow',walltime=None,max_bins=None)
torch.utils.tensorboard.writer.SummaryWriter.add_histogram_raw(self,tag,min,max,num,sum,sum_squares,bucket_limits,bucket_counts,global_step=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_hparams(self,hparam_dict,metric_dict,hparam_domain_discrete=None,run_name=None)
torch.utils.tensorboard.writer.SummaryWriter.add_image(self,tag,img_tensor,global_step=None,walltime=None,dataformats='CHW')
torch.utils.tensorboard.writer.SummaryWriter.add_image_with_boxes(self,tag,img_tensor,box_tensor,global_step=None,walltime=None,rescale=1,dataformats='CHW',labels=None)
torch.utils.tensorboard.writer.SummaryWriter.add_images(self,tag,img_tensor,global_step=None,walltime=None,dataformats='NCHW')
torch.utils.tensorboard.writer.SummaryWriter.add_mesh(self,tag,vertices,colors=None,faces=None,config_dict=None,global_step=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_onnx_graph(self,prototxt)
torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve(self,tag,labels,predictions,global_step=None,num_thresholds=127,weights=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_pr_curve_raw(self,tag,true_positive_counts,false_positive_counts,true_negative_counts,false_negative_counts,precision,recall,global_step=None,num_thresholds=127,weights=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_scalar(self,tag,scalar_value,global_step=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_scalars(self,main_tag,tag_scalar_dict,global_step=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_text(self,tag,text_string,global_step=None,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.add_video(self,tag,vid_tensor,global_step=None,fps=4,walltime=None)
torch.utils.tensorboard.writer.SummaryWriter.close(self)
torch.utils.tensorboard.writer.SummaryWriter.flush(self)
torch.utils.tensorboard.writer.SummaryWriter.get_logdir(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_caffe2_graph.py----------------------------------------
A:torch.utils.tensorboard._caffe2_graph.WEIGHT->re.compile('(_w)$')
A:torch.utils.tensorboard._caffe2_graph.WEIGHT_->re.compile('(_w_)')
A:torch.utils.tensorboard._caffe2_graph.BN->re.compile('(_bn)$')
A:torch.utils.tensorboard._caffe2_graph.BN_->re.compile('(_bn_)')
A:torch.utils.tensorboard._caffe2_graph.BIAS->re.compile('(_b)$')
A:torch.utils.tensorboard._caffe2_graph.BIAS_->re.compile('(_b_)')
A:torch.utils.tensorboard._caffe2_graph.SCALE->re.compile('(_s)$')
A:torch.utils.tensorboard._caffe2_graph.SCALE_->re.compile('(_s_)')
A:torch.utils.tensorboard._caffe2_graph.SUM->re.compile('(_sum)$')
A:torch.utils.tensorboard._caffe2_graph.SUM_->re.compile('(_sum_)')
A:torch.utils.tensorboard._caffe2_graph.BRANCH->re.compile('(_branch)')
A:torch.utils.tensorboard._caffe2_graph.inter_name->re.compile('(_sum_)').sub('/sum_', SUM.sub('/sum', inter_name))
A:torch.utils.tensorboard._caffe2_graph.new_name->_make_unique_name(seen, rename_fn(name))
A:torch.utils.tensorboard._caffe2_graph.ir->caffe2.python.core.IR(ops)
A:torch.utils.tensorboard._caffe2_graph.inputs->list(op.input)
A:torch.utils.tensorboard._caffe2_graph.outputs->list(op.output)
A:torch.utils.tensorboard._caffe2_graph.names->set()
A:torch.utils.tensorboard._caffe2_graph.op.name->_make_unique_name(seen, name)
A:torch.utils.tensorboard._caffe2_graph.seen->set(input_blobs)
A:torch.utils.tensorboard._caffe2_graph.scope->os.path.commonprefix(name_list)
A:torch.utils.tensorboard._caffe2_graph.name->os.path.join(scope, op.type)
A:torch.utils.tensorboard._caffe2_graph.shape_proto->TensorShapeProto()
A:torch.utils.tensorboard._caffe2_graph.dim->tensorboard.compat.proto.tensor_shape_pb2.TensorShapeProto.Dim()
A:torch.utils.tensorboard._caffe2_graph.n->NodeDef()
A:torch.utils.tensorboard._caffe2_graph.n.device->_tf_device(device)
A:torch.utils.tensorboard._caffe2_graph.len_outputs->len(outputs)
A:torch.utils.tensorboard._caffe2_graph.name_list->list(outputs)
A:torch.utils.tensorboard._caffe2_graph.device->_tf_device(op.device_option)
A:torch.utils.tensorboard._caffe2_graph.produced_by->producing_ops.get(name, [])
A:torch.utils.tensorboard._caffe2_graph.in_blobs->set()
A:torch.utils.tensorboard._caffe2_graph.out_blobs->set()
A:torch.utils.tensorboard._caffe2_graph.input_blobs->list(in_blobs.difference(out_blobs))
A:torch.utils.tensorboard._caffe2_graph.output_blobs->list(out_blobs.difference(in_blobs))
A:torch.utils.tensorboard._caffe2_graph.ops->_filter_ops(ops, _check_if_cpu, show_simplified)
A:torch.utils.tensorboard._caffe2_graph.blobs->set()
A:torch.utils.tensorboard._caffe2_graph.(input_blobs, inter_blobs, _)->_compute_in_out(ops)
A:torch.utils.tensorboard._caffe2_graph.current_graph->GraphDef()
A:torch.utils.tensorboard._caffe2_graph.(shapes, _)->caffe2.python.workspace.InferShapesAndTypes(nets)
A:torch.utils.tensorboard._caffe2_graph.shapes->copy.deepcopy(shapes or {})
torch.utils.tensorboard._caffe2_graph._add_gradient_scope(shapes,blob_name_tracker,ops)
torch.utils.tensorboard._caffe2_graph._add_tf_shape(attr_dict,ints)
torch.utils.tensorboard._caffe2_graph._blob_to_node(producing_ops,shapes,name)
torch.utils.tensorboard._caffe2_graph._check_if_cpu(blob)
torch.utils.tensorboard._caffe2_graph._check_if_forward(blob)
torch.utils.tensorboard._caffe2_graph._clear_debug_info(ops,perform_clear)
torch.utils.tensorboard._caffe2_graph._compute_in_out(ops)
torch.utils.tensorboard._caffe2_graph._convert_to_ssa(shapes,blob_name_tracker,ops)
torch.utils.tensorboard._caffe2_graph._fill_missing_operator_names(ops)
torch.utils.tensorboard._caffe2_graph._filter_ops(ops,filter_fn,perform_filter)
torch.utils.tensorboard._caffe2_graph._get_blob_names(ops)
torch.utils.tensorboard._caffe2_graph._make_unique_name(seen:Set[str],name:str,min_version:int=0)
torch.utils.tensorboard._caffe2_graph._operator_to_node(shapes,op)
torch.utils.tensorboard._caffe2_graph._operator_to_node_simp(op,inter_blobs,seen)
torch.utils.tensorboard._caffe2_graph._operators_to_graph_def(shapes,ops,colon_replacement='$',with_ssa=True,with_gradient_scope=True,blob_name_tracker=None,show_simplified=False,custom_rename=None)
torch.utils.tensorboard._caffe2_graph._propagate_device_option(net_def)
torch.utils.tensorboard._caffe2_graph._remap_keys(old_dict,rename_fn)
torch.utils.tensorboard._caffe2_graph._rename_all(shapes,blob_name_tracker,ops,rename_fn)
torch.utils.tensorboard._caffe2_graph._rename_tensorflow_style(shapes,blob_name_tracker,ops)
torch.utils.tensorboard._caffe2_graph._replace_colons(shapes,blob_name_tracker,ops,repl)
torch.utils.tensorboard._caffe2_graph._set_tf_attr(attr_dict,arg)
torch.utils.tensorboard._caffe2_graph._tf_device(device_option)
torch.utils.tensorboard._caffe2_graph._try_get_shapes(nets)
torch.utils.tensorboard._caffe2_graph.model_to_graph_def(model,**kwargs)
torch.utils.tensorboard._caffe2_graph.nets_to_graph_def(nets,shapes=None,**kwargs)
torch.utils.tensorboard._caffe2_graph.protos_to_graph_def(net_defs,shapes=None,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_proto_graph.py----------------------------------------
A:torch.utils.tensorboard._proto_graph.attr['attr']->AttrValue(s=s.encode(encoding='utf_8'))
A:torch.utils.tensorboard._proto_graph.shapeproto->tensor_shape_proto(shape)
A:torch.utils.tensorboard._proto_graph.attr['_output_shapes']->AttrValue(list=AttrValue.ListValue(shape=[shapeproto]))
torch.utils.tensorboard._proto_graph.attr_value_proto(dtype,shape,s)
torch.utils.tensorboard._proto_graph.node_proto(name,op='UnSpecified',input=None,dtype=None,shape=None,outputsize=None,attributes='')
torch.utils.tensorboard._proto_graph.tensor_shape_proto(outputsize)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_embedding.py----------------------------------------
A:torch.utils.tensorboard._embedding.metadata_bytes->tensorboard.compat.tf.compat.as_bytes('\n'.join(metadata) + '\n')
A:torch.utils.tensorboard._embedding.fs->tensorboard.compat.tf.io.gfile.get_filesystem(save_path)
A:torch.utils.tensorboard._embedding.nrow->int(math.ceil(label_img.size(0) ** 0.5))
A:torch.utils.tensorboard._embedding.arranged_img_CHW->make_grid(make_np(label_img), ncols=nrow)
A:torch.utils.tensorboard._embedding.arranged_augment_square_HWC->numpy.zeros((arranged_img_CHW.shape[2], arranged_img_CHW.shape[2], 3))
A:torch.utils.tensorboard._embedding.arranged_img_HWC->make_grid(make_np(label_img), ncols=nrow).transpose(1, 2, 0)
A:torch.utils.tensorboard._embedding.im->PIL.Image.fromarray(np.uint8((arranged_augment_square_HWC * 255).clip(0, 255)))
A:torch.utils.tensorboard._embedding.im_bytes->buf.getvalue()
A:torch.utils.tensorboard._embedding.info->EmbeddingInfo()
A:torch.utils.tensorboard._embedding.info.tensor_name->'{}:{}'.format(tag, str(global_step).zfill(5))
A:torch.utils.tensorboard._embedding.info.tensor_path->filesys.join(subdir, 'tensors.tsv')
A:torch.utils.tensorboard._embedding.info.metadata_path->filesys.join(subdir, 'metadata.tsv')
A:torch.utils.tensorboard._embedding.info.sprite.image_path->filesys.join(subdir, 'sprite.png')
A:torch.utils.tensorboard._embedding.config_path->tensorboard.compat.tf.io.gfile.get_filesystem(save_path).join(save_path, 'projector_config.pbtxt')
torch.utils.tensorboard._embedding.get_embedding_info(metadata,label_img,filesys,subdir,global_step,tag)
torch.utils.tensorboard._embedding.make_mat(matlist,save_path)
torch.utils.tensorboard._embedding.make_sprite(label_img,save_path)
torch.utils.tensorboard._embedding.make_tsv(metadata,save_path,metadata_header=None)
torch.utils.tensorboard._embedding.write_pbtxt(save_path,contents)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_pytorch_graph.py----------------------------------------
A:torch.utils.tensorboard._pytorch_graph.list_of_node->list(getattr(node_cpp, m)())
A:torch.utils.tensorboard._pytorch_graph.tensor_size->node_cpp.type().sizes()
A:torch.utils.tensorboard._pytorch_graph.self.attributes->str({k: node_cpp[k] for k in node_cpp.attributeNames()}).replace("'", ' ')
A:torch.utils.tensorboard._pytorch_graph.self.kind->node_cpp.kind()
A:torch.utils.tensorboard._pytorch_graph.self.nodes_io->OrderedDict()
A:torch.utils.tensorboard._pytorch_graph.self.nodes_io[node_output]->NodeBase(node_output, node.inputs, node.scopeName, outputSize, op_type=node.kind, attributes=node.attributes)
A:torch.utils.tensorboard._pytorch_graph.n_inputs->len(args)
A:torch.utils.tensorboard._pytorch_graph.nodes_py->GraphPy()
A:torch.utils.tensorboard._pytorch_graph.attr_name->node.s('name')
A:torch.utils.tensorboard._pytorch_graph.parent->node.input().node()
A:torch.utils.tensorboard._pytorch_graph.parent_attr_name->node.input().node().s('name')
A:torch.utils.tensorboard._pytorch_graph.attr_to_scope[attr_name]->'__module.{}'.format(attr_name)
A:torch.utils.tensorboard._pytorch_graph.node_py->NodePyOP(node)
A:torch.utils.tensorboard._pytorch_graph.node_pyio->NodePyIO(node, 'output')
A:torch.utils.tensorboard._pytorch_graph.node_pyio.debugName->'output.{}'.format(i + 1)
A:torch.utils.tensorboard._pytorch_graph.module_name->getattr(module, 'original_name', 'Module')
A:torch.utils.tensorboard._pytorch_graph.alias_to_name->dict()
A:torch.utils.tensorboard._pytorch_graph.base_name->parse_traced_name(trace)
A:torch.utils.tensorboard._pytorch_graph.mod_name->parse_traced_name(module)
A:torch.utils.tensorboard._pytorch_graph.alias_to_name[name]->'{}[{}]'.format(mod_name, attr_name)
A:torch.utils.tensorboard._pytorch_graph.module_aliases->node.scopeName.split('/')
A:torch.utils.tensorboard._pytorch_graph.trace->torch.jit.trace(model, args)
A:torch.utils.tensorboard._pytorch_graph.list_of_nodes->parse(graph, trace, args)
A:torch.utils.tensorboard._pytorch_graph.stepstats->RunMetadata(step_stats=StepStats(dev_stats=[DeviceStepStats(device='/device:CPU:0')]))
torch.utils.tensorboard._pytorch_graph.GraphPy(self)
torch.utils.tensorboard._pytorch_graph.GraphPy.__init__(self)
torch.utils.tensorboard._pytorch_graph.GraphPy.append(self,x)
torch.utils.tensorboard._pytorch_graph.GraphPy.find_common_root(self)
torch.utils.tensorboard._pytorch_graph.GraphPy.populate_namespace_from_OP_to_IO(self)
torch.utils.tensorboard._pytorch_graph.GraphPy.printall(self)
torch.utils.tensorboard._pytorch_graph.GraphPy.to_proto(self)
torch.utils.tensorboard._pytorch_graph.NodeBase(self,debugName=None,inputs=None,scope=None,tensor_size=None,op_type='UnSpecified',attributes='')
torch.utils.tensorboard._pytorch_graph.NodeBase.__init__(self,debugName=None,inputs=None,scope=None,tensor_size=None,op_type='UnSpecified',attributes='')
torch.utils.tensorboard._pytorch_graph.NodeBase.__repr__(self)
torch.utils.tensorboard._pytorch_graph.NodePy(self,node_cpp,valid_methods)
torch.utils.tensorboard._pytorch_graph.NodePy.__init__(self,node_cpp,valid_methods)
torch.utils.tensorboard._pytorch_graph.NodePyIO(self,node_cpp,input_or_output=None)
torch.utils.tensorboard._pytorch_graph.NodePyIO.__init__(self,node_cpp,input_or_output=None)
torch.utils.tensorboard._pytorch_graph.NodePyOP(self,node_cpp)
torch.utils.tensorboard._pytorch_graph.NodePyOP.__init__(self,node_cpp)
torch.utils.tensorboard._pytorch_graph.graph(model,args,verbose=False)
torch.utils.tensorboard._pytorch_graph.parse(graph,trace,args=None,omit_useless_nodes=True)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/summary.py----------------------------------------
A:torch.utils.tensorboard.summary.font->PIL.ImageFont.load_default()
A:torch.utils.tensorboard.summary.draw->PIL.ImageDraw.Draw(image)
A:torch.utils.tensorboard.summary.(text_width, text_height)->PIL.ImageFont.load_default().getsize(display_str)
A:torch.utils.tensorboard.summary.margin->numpy.ceil(0.05 * text_height)
A:torch.utils.tensorboard.summary.ssi->Summary(value=[Summary.Value(tag=SESSION_START_INFO_TAG, metadata=smd)])
A:torch.utils.tensorboard.summary.domain_discrete->google.protobuf.struct_pb2.ListValue(values=[struct_pb2.Value(bool_value=d) for d in hparam_domain_discrete[k]])
A:torch.utils.tensorboard.summary.content->HParamsPluginData(session_end_info=sei, version=PLUGIN_DATA_VERSION)
A:torch.utils.tensorboard.summary.smd->SummaryMetadata(plugin_data=plugin_data)
A:torch.utils.tensorboard.summary.exp->Summary(value=[Summary.Value(tag=EXPERIMENT_TAG, metadata=smd)])
A:torch.utils.tensorboard.summary.sei->Summary(value=[Summary.Value(tag=SESSION_END_INFO_TAG, metadata=smd)])
A:torch.utils.tensorboard.summary.scalar->float(scalar)
A:torch.utils.tensorboard.summary.hist->make_histogram(values.astype(float), bins, max_bins)
A:torch.utils.tensorboard.summary.values->values.reshape(-1).reshape(-1)
A:torch.utils.tensorboard.summary.(counts, limits)->numpy.histogram(values, bins=bins)
A:torch.utils.tensorboard.summary.num_bins->len(counts)
A:torch.utils.tensorboard.summary.counts->counts.reshape(-1, subsampling).sum(axis=-1).reshape(-1, subsampling).sum(axis=-1)
A:torch.utils.tensorboard.summary.new_limits->numpy.empty((counts.size + 1,), limits.dtype)
A:torch.utils.tensorboard.summary.cum_counts->numpy.cumsum(np.greater(counts, 0, dtype=np.int32))
A:torch.utils.tensorboard.summary.(start, end)->numpy.searchsorted(cum_counts, [0, cum_counts[-1] - 1], side='right')
A:torch.utils.tensorboard.summary.start->int(start)
A:torch.utils.tensorboard.summary.sum_sq->values.reshape(-1).reshape(-1).dot(values)
A:torch.utils.tensorboard.summary.tensor->TensorProto(dtype='DT_FLOAT', float_val=tensor.reshape(-1).tolist(), tensor_shape=TensorShapeProto(dim=[TensorShapeProto.Dim(size=tensor.shape[0]), TensorShapeProto.Dim(size=tensor.shape[1]), TensorShapeProto.Dim(size=tensor.shape[2])]))
A:torch.utils.tensorboard.summary.scale_factor->_calc_scale_factor(tensor)
A:torch.utils.tensorboard.summary.image->image.resize((scaled_width, scaled_height), Image.ANTIALIAS).resize((scaled_width, scaled_height), Image.ANTIALIAS)
A:torch.utils.tensorboard.summary.tensor_image->convert_to_HWC(tensor_image, dataformats)
A:torch.utils.tensorboard.summary.tensor_boxes->make_np(tensor_boxes)
A:torch.utils.tensorboard.summary.list_gt->range(num_boxes)
A:torch.utils.tensorboard.summary.disp_image->_draw_single_box(disp_image, boxes[i, 0], boxes[i, 1], boxes[i, 2], boxes[i, 3], display_str=None if labels is None else labels[i], color='Red')
A:torch.utils.tensorboard.summary.scaled_height->int(height * rescale)
A:torch.utils.tensorboard.summary.scaled_width->int(width * rescale)
A:torch.utils.tensorboard.summary.output->io.BytesIO()
A:torch.utils.tensorboard.summary.image_string->io.BytesIO().getvalue()
A:torch.utils.tensorboard.summary.video->make_video(tensor, fps)
A:torch.utils.tensorboard.summary.clip->moviepy.editor.ImageSequenceClip(list(tensor), fps=fps)
A:torch.utils.tensorboard.summary.tensor_string->f.read()
A:torch.utils.tensorboard.summary.fio->io.BytesIO()
A:torch.utils.tensorboard.summary.wave_write->wave.open(fio, 'wb')
A:torch.utils.tensorboard.summary.audio_string->io.BytesIO().getvalue()
A:torch.utils.tensorboard.summary.audio->tensorboard.compat.proto.summary_pb2.Summary.Audio(sample_rate=sample_rate, num_channels=1, length_frames=tensor.shape[-1], encoded_audio_string=audio_string, content_type='audio/wav')
A:torch.utils.tensorboard.summary.mgcc->tensorboard.plugins.custom_scalar.layout_pb2.MarginChartContent(series=[layout_pb2.MarginChartContent.Series(value=tags[0], lower=tags[1], upper=tags[2])])
A:torch.utils.tensorboard.summary.chart->tensorboard.plugins.custom_scalar.layout_pb2.Chart(title=chart_name, multiline=mlcc)
A:torch.utils.tensorboard.summary.mlcc->tensorboard.plugins.custom_scalar.layout_pb2.MultilineChartContent(tag=tags)
A:torch.utils.tensorboard.summary.layout->tensorboard.plugins.custom_scalar.layout_pb2.Layout(category=categories)
A:torch.utils.tensorboard.summary.plugin_data->tensorboard.compat.proto.summary_pb2.SummaryMetadata.PluginData(plugin_name='pr_curves', content=pr_curve_plugin_data)
A:torch.utils.tensorboard.summary.data->compute_curve(labels, predictions, num_thresholds=num_thresholds, weights=weights)
A:torch.utils.tensorboard.summary.pr_curve_plugin_data->PrCurvePluginData(version=0, num_thresholds=num_thresholds).SerializeToString()
A:torch.utils.tensorboard.summary.num_thresholds->min(num_thresholds, 127)
A:torch.utils.tensorboard.summary.bucket_indices->numpy.int32(np.floor(predictions * (num_thresholds - 1)))
A:torch.utils.tensorboard.summary.float_labels->labels.astype(np.float)
A:torch.utils.tensorboard.summary.(tp_buckets, _)->numpy.histogram(bucket_indices, bins=num_thresholds, range=histogram_range, weights=float_labels * weights)
A:torch.utils.tensorboard.summary.(fp_buckets, _)->numpy.histogram(bucket_indices, bins=num_thresholds, range=histogram_range, weights=(1.0 - float_labels) * weights)
A:torch.utils.tensorboard.summary.tensor_metadata->tensorboard.plugins.mesh.metadata.create_summary_metadata(name, display_name, content_type, components, tensor.shape, description, json_config=json_config)
A:torch.utils.tensorboard.summary.tensor_summary->tensorboard.compat.proto.summary_pb2.Summary.Value(tag=metadata.get_instance_name(name, content_type), tensor=tensor, metadata=tensor_metadata)
A:torch.utils.tensorboard.summary.json_config->_get_json_config(config_dict)
A:torch.utils.tensorboard.summary.components->tensorboard.plugins.mesh.metadata.get_components_bitmask([content_type for (tensor, content_type) in tensors])
torch.utils.tensorboard.summary._calc_scale_factor(tensor)
torch.utils.tensorboard.summary._draw_single_box(image,xmin,ymin,xmax,ymax,display_str,color='black',color_text='black',thickness=2)
torch.utils.tensorboard.summary._get_json_config(config_dict)
torch.utils.tensorboard.summary._get_tensor_summary(name,display_name,description,tensor,content_type,components,json_config)
torch.utils.tensorboard.summary.audio(tag,tensor,sample_rate=44100)
torch.utils.tensorboard.summary.compute_curve(labels,predictions,num_thresholds=None,weights=None)
torch.utils.tensorboard.summary.custom_scalars(layout)
torch.utils.tensorboard.summary.draw_boxes(disp_image,boxes,labels=None)
torch.utils.tensorboard.summary.histogram(name,values,bins,max_bins=None)
torch.utils.tensorboard.summary.histogram_raw(name,min,max,num,sum,sum_squares,bucket_limits,bucket_counts)
torch.utils.tensorboard.summary.hparams(hparam_dict=None,metric_dict=None,hparam_domain_discrete=None)
torch.utils.tensorboard.summary.image(tag,tensor,rescale=1,dataformats='NCHW')
torch.utils.tensorboard.summary.image_boxes(tag,tensor_image,tensor_boxes,rescale=1,dataformats='CHW',labels=None)
torch.utils.tensorboard.summary.make_histogram(values,bins,max_bins=None)
torch.utils.tensorboard.summary.make_image(tensor,rescale=1,rois=None,labels=None)
torch.utils.tensorboard.summary.make_video(tensor,fps)
torch.utils.tensorboard.summary.mesh(tag,vertices,colors,faces,config_dict,display_name=None,description=None)
torch.utils.tensorboard.summary.pr_curve(tag,labels,predictions,num_thresholds=127,weights=None)
torch.utils.tensorboard.summary.pr_curve_raw(tag,tp,fp,tn,fn,precision,recall,num_thresholds=127,weights=None)
torch.utils.tensorboard.summary.scalar(name,scalar,collections=None)
torch.utils.tensorboard.summary.text(tag,text)
torch.utils.tensorboard.summary.video(tag,tensor,fps=4)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/tensorboard/_onnx_graph.py----------------------------------------
A:torch.utils.tensorboard._onnx_graph.m->onnx.load(fname)
A:torch.utils.tensorboard._onnx_graph.shapeproto->TensorShapeProto(dim=[TensorShapeProto.Dim(size=d.dim_value) for d in node.type.tensor_type.shape.dim])
A:torch.utils.tensorboard._onnx_graph.attr->', '.join(_attr).encode(encoding='utf_8')
torch.utils.tensorboard._onnx_graph.load_onnx_graph(fname)
torch.utils.tensorboard._onnx_graph.parse(graph)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/bottleneck/__main__.py----------------------------------------
A:torch.utils.bottleneck.__main__.env_summary->run_env_analysis()
A:torch.utils.bottleneck.__main__.info->get_env_info()
A:torch.utils.bottleneck.__main__.prof->cProfile.Profile()
A:torch.utils.bottleneck.__main__.cprof_summary->'\n--------------------------------------------------------------------------------\n  cProfile output\n--------------------------------------------------------------------------------\n'.strip()
A:torch.utils.bottleneck.__main__.cprofile_stats->pstats.Stats(prof).sort_stats(sortby)
A:torch.utils.bottleneck.__main__.autograd_prof_summary->'\n--------------------------------------------------------------------------------\n  autograd profiler output ({mode} mode)\n--------------------------------------------------------------------------------\n        {description}\n{cuda_warning}\n{output}\n'.strip()
A:torch.utils.bottleneck.__main__.sorted_events->sorted(prof.function_events, key=lambda x: getattr(x, sortby), reverse=True)
A:torch.utils.bottleneck.__main__.descript->"\n`bottleneck` is a tool that can be used as an initial step for debugging\nbottlenecks in your program.\n\nIt summarizes runs of your script with the Python profiler and PyTorch's\nautograd profiler. Because your script will be profiled, please ensure that it\nexits in a finite amount of time.\n\nFor more complicated uses of the profilers, please see\nhttps://docs.python.org/3/library/profile.html and\nhttps://pytorch.org/docs/master/autograd.html#profiler for more information.\n".strip()
A:torch.utils.bottleneck.__main__.parser->argparse.ArgumentParser(description=descript)
A:torch.utils.bottleneck.__main__.args->parse_args()
A:torch.utils.bottleneck.__main__.code->compile(stream.read(), scriptfile, 'exec')
A:torch.utils.bottleneck.__main__.cprofile_prof->run_cprofile(code, globs)
A:torch.utils.bottleneck.__main__.(autograd_prof_cpu, autograd_prof_cuda)->run_autograd_prof(code, globs)
A:torch.utils.bottleneck.__main__.cuda_prof_exec_time->cpu_time_total(autograd_prof_cuda)
A:torch.utils.bottleneck.__main__.cpu_prof_exec_time->cpu_time_total(autograd_prof_cpu)
torch.utils.bottleneck.__main__.compiled_with_cuda(sysinfo)
torch.utils.bottleneck.__main__.cpu_time_total(autograd_prof)
torch.utils.bottleneck.__main__.main()
torch.utils.bottleneck.__main__.parse_args()
torch.utils.bottleneck.__main__.print_autograd_prof_summary(prof,mode,sortby='cpu_time',topk=15)
torch.utils.bottleneck.__main__.print_cprofile_summary(prof,sortby='tottime',topk=15)
torch.utils.bottleneck.__main__.redirect_argv(new_argv)
torch.utils.bottleneck.__main__.run_autograd_prof(code,globs)
torch.utils.bottleneck.__main__.run_cprofile(code,globs,launch_blocking=False)
torch.utils.bottleneck.__main__.run_env_analysis()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/bottleneck/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/backcompat/__init__.py----------------------------------------
A:torch.utils.backcompat.__init__.enabled->property(get_enabled, set_enabled)
A:torch.utils.backcompat.__init__.broadcast_warning->Warning(_set_backcompat_broadcast_warn, _get_backcompat_broadcast_warn)
A:torch.utils.backcompat.__init__.keepdim_warning->Warning(_set_backcompat_keepdim_warn, _get_backcompat_keepdim_warn)
torch.utils.backcompat.__init__.Warning(self,setter,getter)
torch.utils.backcompat.__init__.Warning.__init__(self,setter,getter)
torch.utils.backcompat.__init__.Warning.get_enabled(self)
torch.utils.backcompat.__init__.Warning.set_enabled(self,value)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/distributed.py----------------------------------------
A:torch.utils.data.distributed.T_co->TypeVar('T_co', covariant=True)
A:torch.utils.data.distributed.num_replicas->torch.distributed.get_world_size()
A:torch.utils.data.distributed.rank->torch.distributed.get_rank()
A:torch.utils.data.distributed.self.num_samples->math.ceil(len(self.dataset) / self.num_replicas)
A:torch.utils.data.distributed.g->torch.Generator()
A:torch.utils.data.distributed.indices->list(range(len(self.dataset)))
torch.utils.data.DistributedSampler(self,dataset:Dataset,num_replicas:Optional[int]=None,rank:Optional[int]=None,shuffle:bool=True,seed:int=0,drop_last:bool=False)
torch.utils.data.DistributedSampler.__iter__(self)->Iterator[T_co]
torch.utils.data.DistributedSampler.__len__(self)->int
torch.utils.data.DistributedSampler.set_epoch(self,epoch:int)->None
torch.utils.data.distributed.DistributedSampler(self,dataset:Dataset,num_replicas:Optional[int]=None,rank:Optional[int]=None,shuffle:bool=True,seed:int=0,drop_last:bool=False)
torch.utils.data.distributed.DistributedSampler.__init__(self,dataset:Dataset,num_replicas:Optional[int]=None,rank:Optional[int]=None,shuffle:bool=True,seed:int=0,drop_last:bool=False)
torch.utils.data.distributed.DistributedSampler.__iter__(self)->Iterator[T_co]
torch.utils.data.distributed.DistributedSampler.__len__(self)->int
torch.utils.data.distributed.DistributedSampler.set_epoch(self,epoch:int)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/dataloader.py----------------------------------------
A:torch.utils.data.dataloader.T_co->TypeVar('T_co', covariant=True)
A:torch.utils.data.dataloader.T->TypeVar('T')
A:torch.utils.data.dataloader.sampler->SequentialSampler(dataset)
A:torch.utils.data.dataloader.batch_sampler->BatchSampler(sampler, batch_size, drop_last)
A:torch.utils.data.dataloader.valid_start_methods->torch.multiprocessing.get_all_start_methods()
A:torch.utils.data.dataloader.multiprocessing_context->torch.multiprocessing.get_context(multiprocessing_context)
A:torch.utils.data.dataloader.self._iterator->self._get_iterator()
A:torch.utils.data.dataloader.lengthself._IterableDataset_len_called->len(self.dataset)
A:torch.utils.data.dataloader.length->ceil(length / self.batch_size)
A:torch.utils.data.dataloader.self._sampler_iter->iter(self._index_sampler)
A:torch.utils.data.dataloader.self._base_seed->torch.empty((), dtype=torch.int64).random_(generator=loader.generator).item()
A:torch.utils.data.dataloader.data->self._data_queue.get(timeout=timeout)
A:torch.utils.data.dataloader.warn_msg->'Length of IterableDataset {} was reported to be {} (when accessing len(dataloader)), but {} samples have been fetched. '.format(self._dataset, self._IterableDataset_len_called, self._num_yielded)
A:torch.utils.data.dataloader.self._dataset_fetcher->_DatasetKind.create_fetcher(self._dataset_kind, self._dataset, self._auto_collation, self._collate_fn, self._drop_last)
A:torch.utils.data.dataloader.index->self._next_index()
A:torch.utils.data.dataloader.self._worker_queue_idx_cycle->itertools.cycle(range(self._num_workers))
A:torch.utils.data.dataloader.self._worker_result_queue->torch.multiprocessing.get_context(multiprocessing_context).Queue()
A:torch.utils.data.dataloader.self._workers_done_event->torch.multiprocessing.get_context(multiprocessing_context).Event()
A:torch.utils.data.dataloader.index_queue->torch.multiprocessing.get_context(multiprocessing_context).Queue()
A:torch.utils.data.dataloader.w->torch.multiprocessing.get_context(multiprocessing_context).Process(target=_utils.worker._worker_loop, args=(self._dataset_kind, self._dataset, index_queue, self._worker_result_queue, self._workers_done_event, self._auto_collation, self._collate_fn, self._drop_last, self._base_seed + i, self._worker_init_fn, i, self._num_workers, self._persistent_workers))
A:torch.utils.data.dataloader.self._pin_memory_thread_done_event->threading.Event()
A:torch.utils.data.dataloader.self._data_queue->torch._six.queue.Queue()
A:torch.utils.data.dataloader.pin_memory_thread->threading.Thread(target=_utils.pin_memory._pin_memory_loop, args=(self._worker_result_queue, self._data_queue, torch.cuda.current_device(), self._pin_memory_thread_done_event))
A:torch.utils.data.dataloader.pids_str->', '.join((str(w.pid) for w in failed_workers))
A:torch.utils.data.dataloader.(success, data)->self._try_get_data()
A:torch.utils.data.dataloader.(idx, data)->self._get_data()
A:torch.utils.data.dataloader.worker_queue_idx->next(self._worker_queue_idx_cycle)
torch.utils.data.DataLoader(self,dataset:Dataset[T_co],batch_size:Optional[int]=1,shuffle:bool=False,sampler:Optional[Sampler[int]]=None,batch_sampler:Optional[Sampler[Sequence[int]]]=None,num_workers:int=0,collate_fn:_collate_fn_t=None,pin_memory:bool=False,drop_last:bool=False,timeout:float=0,worker_init_fn:_worker_init_fn_t=None,multiprocessing_context=None,generator=None,*,prefetch_factor:int=2,persistent_workers:bool=False)
torch.utils.data.DataLoader.__iter__(self)->'_BaseDataLoaderIter'
torch.utils.data.DataLoader.__len__(self)->int
torch.utils.data.DataLoader.__setattr__(self,attr,val)
torch.utils.data.DataLoader._auto_collation(self)
torch.utils.data.DataLoader._get_iterator(self)->'_BaseDataLoaderIter'
torch.utils.data.DataLoader._index_sampler(self)
torch.utils.data.DataLoader.multiprocessing_context(self)
torch.utils.data.DataLoader.multiprocessing_context(self,multiprocessing_context)
torch.utils.data._DatasetKind(object)
torch.utils.data._DatasetKind.create_fetcher(kind,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data.dataloader.DataLoader(self,dataset:Dataset[T_co],batch_size:Optional[int]=1,shuffle:bool=False,sampler:Optional[Sampler[int]]=None,batch_sampler:Optional[Sampler[Sequence[int]]]=None,num_workers:int=0,collate_fn:_collate_fn_t=None,pin_memory:bool=False,drop_last:bool=False,timeout:float=0,worker_init_fn:_worker_init_fn_t=None,multiprocessing_context=None,generator=None,*,prefetch_factor:int=2,persistent_workers:bool=False)
torch.utils.data.dataloader.DataLoader.__init__(self,dataset:Dataset[T_co],batch_size:Optional[int]=1,shuffle:bool=False,sampler:Optional[Sampler[int]]=None,batch_sampler:Optional[Sampler[Sequence[int]]]=None,num_workers:int=0,collate_fn:_collate_fn_t=None,pin_memory:bool=False,drop_last:bool=False,timeout:float=0,worker_init_fn:_worker_init_fn_t=None,multiprocessing_context=None,generator=None,*,prefetch_factor:int=2,persistent_workers:bool=False)
torch.utils.data.dataloader.DataLoader.__iter__(self)->'_BaseDataLoaderIter'
torch.utils.data.dataloader.DataLoader.__len__(self)->int
torch.utils.data.dataloader.DataLoader.__setattr__(self,attr,val)
torch.utils.data.dataloader.DataLoader._auto_collation(self)
torch.utils.data.dataloader.DataLoader._get_iterator(self)->'_BaseDataLoaderIter'
torch.utils.data.dataloader.DataLoader._index_sampler(self)
torch.utils.data.dataloader.DataLoader.multiprocessing_context(self)
torch.utils.data.dataloader.DataLoader.multiprocessing_context(self,multiprocessing_context)
torch.utils.data.dataloader._BaseDataLoaderIter(self,loader:DataLoader)
torch.utils.data.dataloader._BaseDataLoaderIter.__getstate__(self)
torch.utils.data.dataloader._BaseDataLoaderIter.__init__(self,loader:DataLoader)
torch.utils.data.dataloader._BaseDataLoaderIter.__iter__(self)->'_BaseDataLoaderIter'
torch.utils.data.dataloader._BaseDataLoaderIter.__len__(self)->int
torch.utils.data.dataloader._BaseDataLoaderIter.__next__(self)->Any
torch.utils.data.dataloader._BaseDataLoaderIter._next_data(self)
torch.utils.data.dataloader._BaseDataLoaderIter._next_index(self)
torch.utils.data.dataloader._BaseDataLoaderIter._reset(self,loader,first_iter=False)
torch.utils.data.dataloader._DatasetKind(object)
torch.utils.data.dataloader._DatasetKind.create_fetcher(kind,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data.dataloader._InfiniteConstantSampler(self)
torch.utils.data.dataloader._InfiniteConstantSampler.__init__(self)
torch.utils.data.dataloader._InfiniteConstantSampler.__iter__(self)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter(self,loader)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter.__del__(self)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter.__init__(self,loader)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._get_data(self)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._mark_worker_as_unavailable(self,worker_id,shutdown=False)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._next_data(self)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._process_data(self,data)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._reset(self,loader,first_iter=False)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._shutdown_workers(self)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._try_get_data(self,timeout=_utils.MP_STATUS_CHECK_INTERVAL)
torch.utils.data.dataloader._MultiProcessingDataLoaderIter._try_put_index(self)
torch.utils.data.dataloader._SingleProcessDataLoaderIter(self,loader)
torch.utils.data.dataloader._SingleProcessDataLoaderIter.__init__(self,loader)
torch.utils.data.dataloader._SingleProcessDataLoaderIter._next_data(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/sampler.py----------------------------------------
A:torch.utils.data.sampler.T_co->TypeVar('T_co', covariant=True)
A:torch.utils.data.sampler.n->len(self.data_source)
A:torch.utils.data.sampler.generator->torch.Generator()
A:torch.utils.data.sampler.self.weights->torch.as_tensor(weights, dtype=torch.double)
A:torch.utils.data.sampler.rand_tensor->torch.multinomial(self.weights, self.num_samples, self.replacement, generator=self.generator)
torch.utils.data.BatchSampler(self,sampler:Sampler[int],batch_size:int,drop_last:bool)
torch.utils.data.BatchSampler.__iter__(self)
torch.utils.data.BatchSampler.__len__(self)
torch.utils.data.RandomSampler(self,data_source:Sized,replacement:bool=False,num_samples:Optional[int]=None,generator=None)
torch.utils.data.RandomSampler.__iter__(self)
torch.utils.data.RandomSampler.__len__(self)
torch.utils.data.RandomSampler.num_samples(self)->int
torch.utils.data.Sampler(self,data_source:Optional[Sized])
torch.utils.data.Sampler.__iter__(self)->Iterator[T_co]
torch.utils.data.SequentialSampler(self,data_source)
torch.utils.data.SequentialSampler.__iter__(self)
torch.utils.data.SequentialSampler.__len__(self)->int
torch.utils.data.SubsetRandomSampler(self,indices:Sequence[int],generator=None)
torch.utils.data.SubsetRandomSampler.__iter__(self)
torch.utils.data.SubsetRandomSampler.__len__(self)
torch.utils.data.WeightedRandomSampler(self,weights:Sequence[float],num_samples:int,replacement:bool=True,generator=None)
torch.utils.data.WeightedRandomSampler.__iter__(self)
torch.utils.data.WeightedRandomSampler.__len__(self)
torch.utils.data.sampler.BatchSampler(self,sampler:Sampler[int],batch_size:int,drop_last:bool)
torch.utils.data.sampler.BatchSampler.__init__(self,sampler:Sampler[int],batch_size:int,drop_last:bool)
torch.utils.data.sampler.BatchSampler.__iter__(self)
torch.utils.data.sampler.BatchSampler.__len__(self)
torch.utils.data.sampler.RandomSampler(self,data_source:Sized,replacement:bool=False,num_samples:Optional[int]=None,generator=None)
torch.utils.data.sampler.RandomSampler.__init__(self,data_source:Sized,replacement:bool=False,num_samples:Optional[int]=None,generator=None)
torch.utils.data.sampler.RandomSampler.__iter__(self)
torch.utils.data.sampler.RandomSampler.__len__(self)
torch.utils.data.sampler.RandomSampler.num_samples(self)->int
torch.utils.data.sampler.Sampler(self,data_source:Optional[Sized])
torch.utils.data.sampler.Sampler.__init__(self,data_source:Optional[Sized])
torch.utils.data.sampler.Sampler.__iter__(self)->Iterator[T_co]
torch.utils.data.sampler.SequentialSampler(self,data_source)
torch.utils.data.sampler.SequentialSampler.__init__(self,data_source)
torch.utils.data.sampler.SequentialSampler.__iter__(self)
torch.utils.data.sampler.SequentialSampler.__len__(self)->int
torch.utils.data.sampler.SubsetRandomSampler(self,indices:Sequence[int],generator=None)
torch.utils.data.sampler.SubsetRandomSampler.__init__(self,indices:Sequence[int],generator=None)
torch.utils.data.sampler.SubsetRandomSampler.__iter__(self)
torch.utils.data.sampler.SubsetRandomSampler.__len__(self)
torch.utils.data.sampler.WeightedRandomSampler(self,weights:Sequence[float],num_samples:int,replacement:bool=True,generator=None)
torch.utils.data.sampler.WeightedRandomSampler.__init__(self,weights:Sequence[float],num_samples:int,replacement:bool=True,generator=None)
torch.utils.data.sampler.WeightedRandomSampler.__iter__(self)
torch.utils.data.sampler.WeightedRandomSampler.__len__(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/dataset.py----------------------------------------
A:torch.utils.data.dataset.T_co->TypeVar('T_co', covariant=True)
A:torch.utils.data.dataset.T->TypeVar('T')
A:torch.utils.data.dataset.l->len(e)
A:torch.utils.data.dataset.self.datasets->list(datasets)
A:torch.utils.data.dataset.self.cumulative_sizes->self.cumsum(self.datasets)
A:torch.utils.data.dataset.dataset_idx->bisect.bisect_right(self.cumulative_sizes, idx)
A:torch.utils.data.dataset.indices->randperm(sum(lengths), generator=generator).tolist()
torch.utils.data.ChainDataset(self,datasets:Iterable[Dataset])
torch.utils.data.ChainDataset.__iter__(self)
torch.utils.data.ChainDataset.__len__(self)
torch.utils.data.ConcatDataset(self,datasets:Iterable[Dataset])
torch.utils.data.ConcatDataset.__getitem__(self,idx)
torch.utils.data.ConcatDataset.__len__(self)
torch.utils.data.ConcatDataset.cummulative_sizes(self)
torch.utils.data.ConcatDataset.cumsum(sequence)
torch.utils.data.Dataset(Generic[T_co])
torch.utils.data.Dataset.__add__(self,other:'Dataset[T_co]')->'ConcatDataset[T_co]'
torch.utils.data.Dataset.__getitem__(self,index)->T_co
torch.utils.data.IterableDataset(Dataset[T_co])
torch.utils.data.IterableDataset.__add__(self,other:Dataset[T_co])
torch.utils.data.IterableDataset.__iter__(self)->Iterator[T_co]
torch.utils.data.Subset(self,dataset:Dataset[T_co],indices:Sequence[int])
torch.utils.data.Subset.__getitem__(self,idx)
torch.utils.data.Subset.__len__(self)
torch.utils.data.TensorDataset(self,*tensors:Tensor)
torch.utils.data.TensorDataset.__getitem__(self,index)
torch.utils.data.TensorDataset.__len__(self)
torch.utils.data.dataset.ChainDataset(self,datasets:Iterable[Dataset])
torch.utils.data.dataset.ChainDataset.__init__(self,datasets:Iterable[Dataset])
torch.utils.data.dataset.ChainDataset.__iter__(self)
torch.utils.data.dataset.ChainDataset.__len__(self)
torch.utils.data.dataset.ConcatDataset(self,datasets:Iterable[Dataset])
torch.utils.data.dataset.ConcatDataset.__getitem__(self,idx)
torch.utils.data.dataset.ConcatDataset.__init__(self,datasets:Iterable[Dataset])
torch.utils.data.dataset.ConcatDataset.__len__(self)
torch.utils.data.dataset.ConcatDataset.cummulative_sizes(self)
torch.utils.data.dataset.ConcatDataset.cumsum(sequence)
torch.utils.data.dataset.Dataset(Generic[T_co])
torch.utils.data.dataset.Dataset.__add__(self,other:'Dataset[T_co]')->'ConcatDataset[T_co]'
torch.utils.data.dataset.Dataset.__getitem__(self,index)->T_co
torch.utils.data.dataset.IterableDataset(Dataset[T_co])
torch.utils.data.dataset.IterableDataset.__add__(self,other:Dataset[T_co])
torch.utils.data.dataset.IterableDataset.__iter__(self)->Iterator[T_co]
torch.utils.data.dataset.Subset(self,dataset:Dataset[T_co],indices:Sequence[int])
torch.utils.data.dataset.Subset.__getitem__(self,idx)
torch.utils.data.dataset.Subset.__init__(self,dataset:Dataset[T_co],indices:Sequence[int])
torch.utils.data.dataset.Subset.__len__(self)
torch.utils.data.dataset.TensorDataset(self,*tensors:Tensor)
torch.utils.data.dataset.TensorDataset.__getitem__(self,index)
torch.utils.data.dataset.TensorDataset.__init__(self,*tensors:Tensor)
torch.utils.data.dataset.TensorDataset.__len__(self)
torch.utils.data.dataset.random_split(dataset:Dataset[T],lengths:Sequence[int],generator:Optional[Generator]=default_generator)->List[Subset[T]]
torch.utils.data.random_split(dataset:Dataset[T],lengths:Sequence[int],generator:Optional[Generator]=default_generator)->List[Subset[T]]


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/_utils/worker.py----------------------------------------
A:torch.utils.data._utils.worker.self.manager_pid->os.getppid()
A:torch.utils.data._utils.worker.self.kernel32->ctypes.WinDLL('kernel32', use_last_error=True)
A:torch.utils.data._utils.worker.self.manager_handle->self.kernel32.OpenProcess(SYNCHRONIZE, 0, self.manager_pid)
A:torch.utils.data._utils.worker.self.__keys->tuple(kwargs.keys())
A:torch.utils.data._utils.worker._IterableDatasetStopIteration->namedtuple('_IterableDatasetStopIteration', ['worker_id'])
A:torch.utils.data._utils.worker._ResumeIteration->namedtuple('_ResumeIteration', [])
A:torch.utils.data._utils.worker._worker_info->WorkerInfo(id=worker_id, num_workers=num_workers, seed=seed, dataset=dataset)
A:torch.utils.data._utils.worker.fetcher->torch.utils.data._DatasetKind.create_fetcher(dataset_kind, dataset, auto_collation, collate_fn, drop_last)
A:torch.utils.data._utils.worker.init_exception->ExceptionWrapper(where='in DataLoader worker process {}'.format(worker_id))
A:torch.utils.data._utils.worker.watchdog->ManagerWatchdog()
A:torch.utils.data._utils.worker.r->index_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
A:torch.utils.data._utils.worker.data->ExceptionWrapper(where='in DataLoader worker process {}'.format(worker_id))
torch.utils.data._utils.worker.WorkerInfo(self,**kwargs)
torch.utils.data._utils.worker.WorkerInfo.__init__(self,**kwargs)
torch.utils.data._utils.worker.WorkerInfo.__repr__(self)
torch.utils.data._utils.worker.WorkerInfo.__setattr__(self,key,val)
torch.utils.data._utils.worker._worker_loop(dataset_kind,dataset,index_queue,data_queue,done_event,auto_collation,collate_fn,drop_last,seed,init_fn,worker_id,num_workers,persistent_workers)
torch.utils.data._utils.worker.get_worker_info()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/_utils/pin_memory.py----------------------------------------
A:torch.utils.data._utils.pin_memory.r->in_queue.get(timeout=MP_STATUS_CHECK_INTERVAL)
A:torch.utils.data._utils.pin_memory.data->ExceptionWrapper(where='in pin memory thread for device {}'.format(device_id))
torch.utils.data._utils.pin_memory._pin_memory_loop(in_queue,out_queue,device_id,done_event)
torch.utils.data._utils.pin_memory.pin_memory(data)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/_utils/collate.py----------------------------------------
A:torch.utils.data._utils.collate.np_str_obj_array_pattern->re.compile('[SaUO]')
A:torch.utils.data._utils.collate.elem_type->type(elem)
A:torch.utils.data._utils.collate.numel->sum([x.numel() for x in batch])
A:torch.utils.data._utils.collate.storage->elem.storage()._new_shared(numel)
A:torch.utils.data._utils.collate.out->elem.new(storage)
A:torch.utils.data._utils.collate.it->iter(batch)
A:torch.utils.data._utils.collate.elem_size->len(next(it))
A:torch.utils.data._utils.collate.transposed->zip(*batch)
torch.utils.data._utils.collate.default_collate(batch)
torch.utils.data._utils.collate.default_convert(data)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/_utils/signal_handling.py----------------------------------------
A:torch.utils.data._utils.signal_handling.previous_handler->signal.getsignal(signal.SIGCHLD)
torch.utils.data._utils.signal_handling._set_SIGCHLD_handler()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/_utils/__init__.py----------------------------------------
torch.utils.data._utils.__init__._set_python_exit_flag()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/utils/data/_utils/fetch.py----------------------------------------
A:torch.utils.data._utils.fetch.self.dataset_iter->iter(dataset)
A:torch.utils.data._utils.fetch.data->next(self.dataset_iter)
torch.utils.data._utils.fetch._BaseDatasetFetcher(self,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data._utils.fetch._BaseDatasetFetcher.__init__(self,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data._utils.fetch._BaseDatasetFetcher.fetch(self,possibly_batched_index)
torch.utils.data._utils.fetch._IterableDatasetFetcher(self,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data._utils.fetch._IterableDatasetFetcher.__init__(self,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data._utils.fetch._IterableDatasetFetcher.fetch(self,possibly_batched_index)
torch.utils.data._utils.fetch._MapDatasetFetcher(self,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data._utils.fetch._MapDatasetFetcher.__init__(self,dataset,auto_collation,collate_fn,drop_last)
torch.utils.data._utils.fetch._MapDatasetFetcher.fetch(self,possibly_batched_index)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/multiprocessing/pool.py----------------------------------------
A:torch.multiprocessing.pool.self._inqueue->SimpleQueue()
A:torch.multiprocessing.pool.self._outqueue->SimpleQueue()
A:torch.multiprocessing.pool.w->self.Process(target=clean_worker, args=args)
A:torch.multiprocessing.pool.w.name->self.Process(target=clean_worker, args=args).name.replace('Process', 'PoolWorker')
torch.multiprocessing.Pool(multiprocessing.pool.Pool)
torch.multiprocessing.Pool._repopulate_pool(self)
torch.multiprocessing.Pool._setup_queues(self)
torch.multiprocessing.pool.Pool(multiprocessing.pool.Pool)
torch.multiprocessing.pool.Pool._repopulate_pool(self)
torch.multiprocessing.pool.Pool._setup_queues(self)
torch.multiprocessing.pool.clean_worker(*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/multiprocessing/queue.py----------------------------------------
A:torch.multiprocessing.queue.buf->self.recv_bytes()
A:torch.multiprocessing.queue.self._reader->ConnectionWrapper(self._reader)
A:torch.multiprocessing.queue.self._writer->ConnectionWrapper(self._writer)
torch.multiprocessing.Queue(self,*args,**kwargs)
torch.multiprocessing.SimpleQueue(multiprocessing.queues.SimpleQueue)
torch.multiprocessing.SimpleQueue._make_methods(self)
torch.multiprocessing.queue.ConnectionWrapper(self,conn)
torch.multiprocessing.queue.ConnectionWrapper.__getattr__(self,name)
torch.multiprocessing.queue.ConnectionWrapper.__init__(self,conn)
torch.multiprocessing.queue.ConnectionWrapper.recv(self)
torch.multiprocessing.queue.ConnectionWrapper.send(self,obj)
torch.multiprocessing.queue.Queue(self,*args,**kwargs)
torch.multiprocessing.queue.Queue.__init__(self,*args,**kwargs)
torch.multiprocessing.queue.SimpleQueue(multiprocessing.queues.SimpleQueue)
torch.multiprocessing.queue.SimpleQueue._make_methods(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/multiprocessing/_atfork.py----------------------------------------
torch.multiprocessing._atfork.register_after_fork(func)
torch.register_after_fork(func)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/multiprocessing/reductions.py----------------------------------------
A:torch.multiprocessing.reductions.self.cdata->cls._new_shared_filename(manager, handle, size)._weak_ref()
A:torch.multiprocessing.reductions.self.lock->threading.Lock()
A:torch.multiprocessing.reductions.self.limit->max(128, live * 2)
A:torch.multiprocessing.reductions.shared_cache->SharedCache()
A:torch.multiprocessing.reductions.handle->event.ipc_handle()
A:torch.multiprocessing.reductions.t->torch.nn.parameter.Parameter(t)
A:torch.multiprocessing.reductions.storage->cls._new_shared_filename(manager, handle, size)
A:torch.multiprocessing.reductions.shared_cache[storage_handle, storage_offset_bytes]->StorageWeakRef(storage)
A:torch.multiprocessing.reductions.(device, handle, storage_size_bytes, storage_offset_bytes, ref_counter_handle, ref_counter_offset, event_handle, event_sync_required)->cls._new_shared_filename(manager, handle, size)._share_cuda_()
A:torch.multiprocessing.reductions.tensor_offset->tensor.storage_offset()
A:torch.multiprocessing.reductions.shared_cache[handle]->StorageWeakRef(storage)
A:torch.multiprocessing.reductions.stat->os.fstat(fd)
A:torch.multiprocessing.reductions.storage_ref->SharedCache().get(key)
A:torch.multiprocessing.reductions.fd->multiprocessing.reduction.DupFd(fd).detach()
A:torch.multiprocessing.reductions.shared_cache[fd_id(fd)]->StorageWeakRef(storage)
A:torch.multiprocessing.reductions.metadata->cls._new_shared_filename(manager, handle, size)._share_filename_()
A:torch.multiprocessing.reductions.(fd, size)->cls._new_shared_filename(manager, handle, size)._share_fd_()
A:torch.multiprocessing.reductions.df->multiprocessing.reduction.DupFd(fd)
A:torch.multiprocessing.reductions.cache_key->fd_id(fd)
A:torch.multiprocessing.reductions.shared_cache[cache_key]->StorageWeakRef(storage)
torch.multiprocessing.init_reductions()
torch.multiprocessing.reductions.SharedCache(self)
torch.multiprocessing.reductions.SharedCache.__init__(self)
torch.multiprocessing.reductions.SharedCache.__setitem__(self,key,storage_ref)
torch.multiprocessing.reductions.SharedCache._after_fork(self)
torch.multiprocessing.reductions.SharedCache.free_dead_references(self)
torch.multiprocessing.reductions.StorageWeakRef(self,storage)
torch.multiprocessing.reductions.StorageWeakRef.__del__(self)
torch.multiprocessing.reductions.StorageWeakRef.__init__(self,storage)
torch.multiprocessing.reductions.StorageWeakRef.expired(self)
torch.multiprocessing.reductions.fd_id(fd)
torch.multiprocessing.reductions.init_reductions()
torch.multiprocessing.reductions.rebuild_cuda_tensor(tensor_cls,tensor_size,tensor_stride,tensor_offset,storage_cls,storage_device,storage_handle,storage_size_bytes,storage_offset_bytes,requires_grad,ref_counter_handle,ref_counter_offset,event_handle,event_sync_required)
torch.multiprocessing.reductions.rebuild_event(device,handle)
torch.multiprocessing.reductions.rebuild_storage_empty(cls)
torch.multiprocessing.reductions.rebuild_storage_fd(cls,df,size)
torch.multiprocessing.reductions.rebuild_storage_filename(cls,manager,handle,size)
torch.multiprocessing.reductions.rebuild_tensor(cls,storage,metadata)
torch.multiprocessing.reductions.reduce_event(event)
torch.multiprocessing.reductions.reduce_storage(storage)
torch.multiprocessing.reductions.reduce_tensor(tensor)
torch.multiprocessing.reductions.storage_from_cache(cls,key)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/multiprocessing/__init__.py----------------------------------------
torch.multiprocessing.__init__.get_all_sharing_strategies()
torch.multiprocessing.__init__.get_sharing_strategy()
torch.multiprocessing.__init__.set_sharing_strategy(new_strategy)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/multiprocessing/spawn.py----------------------------------------
A:torch.multiprocessing.spawn.ready->multiprocessing.connection.wait(self.sentinels.keys(), timeout=timeout)
A:torch.multiprocessing.spawn.index->self.sentinels.pop(sentinel)
A:torch.multiprocessing.spawn.original_trace->self.error_queues[error_index].get()
A:torch.multiprocessing.spawn.mp->multiprocessing.get_context(start_method)
A:torch.multiprocessing.spawn.error_queue->multiprocessing.get_context(start_method).SimpleQueue()
A:torch.multiprocessing.spawn.process->multiprocessing.get_context(start_method).Process(target=_wrap, args=(fn, i, args, error_queue), daemon=daemon)
A:torch.multiprocessing.spawn.context->ProcessContext(processes, error_queues)
torch.multiprocessing.ProcessContext(self,processes,error_queues)
torch.multiprocessing.ProcessContext.join(self,timeout=None)
torch.multiprocessing.ProcessContext.pids(self)
torch.multiprocessing.SpawnContext(self,processes,error_queues)
torch.multiprocessing.spawn(fn,args=(),nprocs=1,join=True,daemon=False,start_method='spawn')
torch.multiprocessing.spawn.ProcessContext(self,processes,error_queues)
torch.multiprocessing.spawn.ProcessContext.__init__(self,processes,error_queues)
torch.multiprocessing.spawn.ProcessContext.join(self,timeout=None)
torch.multiprocessing.spawn.ProcessContext.pids(self)
torch.multiprocessing.spawn.SpawnContext(self,processes,error_queues)
torch.multiprocessing.spawn.SpawnContext.__init__(self,processes,error_queues)
torch.multiprocessing.spawn._python_version_check()
torch.multiprocessing.spawn._wrap(fn,i,args,error_queue)
torch.multiprocessing.spawn.spawn(fn,args=(),nprocs=1,join=True,daemon=False,start_method='spawn')
torch.multiprocessing.spawn.start_processes(fn,args=(),nprocs=1,join=True,daemon=False,start_method='spawn')
torch.multiprocessing.start_processes(fn,args=(),nprocs=1,join=True,daemon=False,start_method='spawn')


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/__init__.py----------------------------------------
torch.backends.__init__.ContextProp(self,getter,setter)
torch.backends.__init__.ContextProp.__get__(self,obj,objtype)
torch.backends.__init__.ContextProp.__init__(self,getter,setter)
torch.backends.__init__.ContextProp.__set__(self,obj,val)
torch.backends.__init__.PropModule(self,m,name)
torch.backends.__init__.PropModule.__getattr__(self,attr)
torch.backends.__init__.PropModule.__init__(self,m,name)
torch.backends.__init__.__allow_nonbracketed_mutation()
torch.backends.__init__.disable_global_flags()
torch.backends.__init__.flags_frozen()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/cuda/__init__.py----------------------------------------
A:torch.backends.cuda.__init__.size->cuFFTPlanCacheAttrContextProp(torch._cufft_get_plan_cache_size, '.size is a read-only property showing the number of plans currently in the cache. To change the cache capacity, set cufft_plan_cache.max_size.')
A:torch.backends.cuda.__init__.max_size->cuFFTPlanCacheAttrContextProp(torch._cufft_get_plan_cache_max_size, torch._cufft_set_plan_cache_max_size)
A:torch.backends.cuda.__init__.index->torch.cuda._utils._get_device_index(device)
A:torch.backends.cuda.__init__.cufft_plan_cache->cuFFTPlanCacheManager()
A:torch.backends.cuda.__init__.matmul->cuBLASModule()
torch.backends.cuda.__init__.cuBLASModule
torch.backends.cuda.__init__.cuBLASModule.__getattr__(self,name)
torch.backends.cuda.__init__.cuBLASModule.__setattr__(self,name,value)
torch.backends.cuda.__init__.cuFFTPlanCache(self,device_index)
torch.backends.cuda.__init__.cuFFTPlanCache.__init__(self,device_index)
torch.backends.cuda.__init__.cuFFTPlanCache.clear(self)
torch.backends.cuda.__init__.cuFFTPlanCacheAttrContextProp(self,getter,setter)
torch.backends.cuda.__init__.cuFFTPlanCacheAttrContextProp.__get__(self,obj,objtype)
torch.backends.cuda.__init__.cuFFTPlanCacheAttrContextProp.__init__(self,getter,setter)
torch.backends.cuda.__init__.cuFFTPlanCacheAttrContextProp.__set__(self,obj,val)
torch.backends.cuda.__init__.cuFFTPlanCacheManager(self)
torch.backends.cuda.__init__.cuFFTPlanCacheManager.__getattr__(self,name)
torch.backends.cuda.__init__.cuFFTPlanCacheManager.__getitem__(self,device)
torch.backends.cuda.__init__.cuFFTPlanCacheManager.__init__(self)
torch.backends.cuda.__init__.cuFFTPlanCacheManager.__setattr__(self,name,value)
torch.backends.cuda.__init__.is_built()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/cudnn/__init__.py----------------------------------------
A:torch.backends.cudnn.__init__.__cudnn_version->torch._C._cudnn.getVersionInt()
A:torch.backends.cudnn.__init__.runtime_version->torch._C._cudnn.getRuntimeVersion()
A:torch.backends.cudnn.__init__.compile_version->torch._C._cudnn.getCompileVersion()
A:torch.backends.cudnn.__init__.orig_flags->set_flags(enabled, benchmark, deterministic, allow_tf32)
A:torch.backends.cudnn.__init__.enabled->ContextProp(torch._C._get_cudnn_enabled, torch._C._set_cudnn_enabled)
A:torch.backends.cudnn.__init__.deterministic->ContextProp(torch._C._get_cudnn_deterministic, torch._C._set_cudnn_deterministic)
A:torch.backends.cudnn.__init__.benchmark->ContextProp(torch._C._get_cudnn_benchmark, torch._C._set_cudnn_benchmark)
A:torch.backends.cudnn.__init__.allow_tf32->ContextProp(torch._C._get_cudnn_allow_tf32, torch._C._set_cudnn_allow_tf32)
A:torch.backends.cudnn.__init__.sys.modules[__name__]->CudnnModule(sys.modules[__name__], __name__)
torch.backends.cudnn.__init__.CudnnModule(self,m,name)
torch.backends.cudnn.__init__.CudnnModule.__init__(self,m,name)
torch.backends.cudnn.__init__.flags(enabled=False,benchmark=False,deterministic=False,allow_tf32=True)
torch.backends.cudnn.__init__.is_acceptable(tensor)
torch.backends.cudnn.__init__.is_available()
torch.backends.cudnn.__init__.set_flags(_enabled=None,_benchmark=None,_deterministic=None,_allow_tf32=None)
torch.backends.cudnn.__init__.version()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/cudnn/rnn.py----------------------------------------
A:torch.backends.cudnn.rnn.dropout_state[dropout_desc_name]->Unserializable(torch._cudnn_init_dropout_state(dropout_p, train, dropout_seed, self_ty=torch.uint8, device=torch.device('cuda')))
A:torch.backends.cudnn.rnn.dropout_ts->Unserializable(torch._cudnn_init_dropout_state(dropout_p, train, dropout_seed, self_ty=torch.uint8, device=torch.device('cuda'))).get()
torch.backends.cudnn.rnn.Unserializable(self,inner)
torch.backends.cudnn.rnn.Unserializable.__getstate__(self)
torch.backends.cudnn.rnn.Unserializable.__init__(self,inner)
torch.backends.cudnn.rnn.Unserializable.__setstate__(self,state)
torch.backends.cudnn.rnn.Unserializable.get(self)
torch.backends.cudnn.rnn.get_cudnn_mode(mode)
torch.backends.cudnn.rnn.init_dropout_state(dropout,train,dropout_seed,dropout_state)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/openmp/__init__.py----------------------------------------
torch.backends.openmp.__init__.is_available()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/mkl/__init__.py----------------------------------------
torch.backends.mkl.__init__.is_available()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/mkldnn/__init__.py----------------------------------------
A:torch.backends.mkldnn.__init__.orig_flags->set_flags(enabled)
A:torch.backends.mkldnn.__init__.enabled->ContextProp(torch._C._get_mkldnn_enabled, torch._C._set_mkldnn_enabled)
A:torch.backends.mkldnn.__init__.sys.modules[__name__]->MkldnnModule(sys.modules[__name__], __name__)
torch.backends.mkldnn.__init__.MkldnnModule(self,m,name)
torch.backends.mkldnn.__init__.MkldnnModule.__init__(self,m,name)
torch.backends.mkldnn.__init__.flags(enabled=False)
torch.backends.mkldnn.__init__.is_available()
torch.backends.mkldnn.__init__.set_flags(_enabled)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/xnnpack/__init__.py----------------------------------------
A:torch.backends.xnnpack.__init__.enabled->_XNNPACKEnabled()
A:torch.backends.xnnpack.__init__.sys.modules[__name__]->XNNPACKEngine(sys.modules[__name__], __name__)
torch.backends.xnnpack.__init__.XNNPACKEngine(self,m,name)
torch.backends.xnnpack.__init__.XNNPACKEngine.__getattr__(self,attr)
torch.backends.xnnpack.__init__.XNNPACKEngine.__init__(self,m,name)
torch.backends.xnnpack.__init__._XNNPACKEnabled(object)
torch.backends.xnnpack.__init__._XNNPACKEnabled.__get__(self,obj,objtype)
torch.backends.xnnpack.__init__._XNNPACKEnabled.__set__(self,obj,val)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/backends/quantized/__init__.py----------------------------------------
A:torch.backends.quantized.__init__.qengines->torch._C._supported_qengines()
A:torch.backends.quantized.__init__.engine->_QEngineProp()
A:torch.backends.quantized.__init__.supported_engines->_SupportedQEnginesProp()
A:torch.backends.quantized.__init__.sys.modules[__name__]->QuantizedEngine(sys.modules[__name__], __name__)
torch.backends.quantized.__init__.QuantizedEngine(self,m,name)
torch.backends.quantized.__init__.QuantizedEngine.__getattr__(self,attr)
torch.backends.quantized.__init__.QuantizedEngine.__init__(self,m,name)
torch.backends.quantized.__init__._QEngineProp(object)
torch.backends.quantized.__init__._QEngineProp.__get__(self,obj,objtype)->str
torch.backends.quantized.__init__._QEngineProp.__set__(self,obj,val:str)->None
torch.backends.quantized.__init__._SupportedQEnginesProp(object)
torch.backends.quantized.__init__._SupportedQEnginesProp.__get__(self,obj,objtype)->List[str]
torch.backends.quantized.__init__._SupportedQEnginesProp.__set__(self,obj,val)->None
torch.backends.quantized.__init__._get_qengine_id(qengine:str)->int
torch.backends.quantized.__init__._get_qengine_str(qengine:int)->str


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/exporter.py----------------------------------------
A:torch._package.exporter.self.zip_file->torch._C.PyTorchFileWriter(filename)
A:torch._package.exporter.path->Path(file_or_directory)
A:torch._package.exporter.module_path->module_name.replace('.', '/')
A:torch._package.exporter.relative_path->getattr(module, '__file__', None).relative_to(path).as_posix()
A:torch._package.exporter.submodule_name->archivename[:-len('.py')].replace('/', '.')
A:torch._package.exporter.dep_pairs->find_files_source_depends_on(src, package)
A:torch._package.exporter.dep_str->''.join((f'  {dep}\n' for dep in dep_list.keys()))
A:torch._package.exporter.level[x]->max(level[x], visit(e) + 1)
A:torch._package.exporter.filename->getattr(module, '__file__', None)
A:torch._package.exporter.module->self._import_module(module_name)
A:torch._package.exporter.source->self._get_source_of_module(module)
A:torch._package.exporter.data_buf->io.BytesIO()
A:torch._package.exporter.pickler->self._create_pickler(data_buf)
A:torch._package.exporter.data_value->io.BytesIO().getvalue()
A:torch._package.exporter.(module, field)->arg.split(' ')
A:torch._package.exporter.dep_string->''.join((f'  {dep}\n' for dep in all_dependencies))
A:torch._package.exporter.is_package->hasattr(self._import_module(module_name), '__path__')
A:torch._package.exporter.storage_type->normalize_storage_type(type(obj))
A:torch._package.exporter.obj_key->str(obj._cdata)
A:torch._package.exporter.location->location_tag(obj)
A:torch._package.exporter.str_or_bytes->str_or_bytes.encode('utf-8').encode('utf-8')
A:torch._package.exporter.name->'data/{}'.format(key)
A:torch._package.exporter.buf->io.BytesIO()
A:torch._package.exporter.buf_value->io.BytesIO().getvalue()
A:torch._package.exporter.package_path->package.replace('.', '/')
A:torch._package.exporter.resource->_normalize_path(resource)
A:torch._package.exporter.standard_lib->get_python_lib(standard_lib=True)
A:torch._package.exporter.installed_libs->get_python_lib(standard_lib=False)
A:torch._package.exporter.in_standard_lib->getattr(module, '__file__', None).startswith(standard_lib + '/')
A:torch._package.exporter.in_installed_libs->getattr(module, '__file__', None).startswith(installed_libs + '/')
A:torch._package.exporter.b->f.read()
torch._package.PackageExporter(self,filename:str,verbose:bool=True)
torch._package.PackageExporter.__enter__(self)
torch._package.PackageExporter.__exit__(self,type,value,traceback)
torch._package.PackageExporter._can_implicitly_extern(self,module_name:str)
torch._package.PackageExporter._create_pickler(self,data_buf)
torch._package.PackageExporter._filename(self,package,resource)
torch._package.PackageExporter._get_source_of_module(self,module:types.ModuleType)->str
torch._package.PackageExporter._import_module(self,module_name)
torch._package.PackageExporter._module_exists(self,module_name:str)->bool
torch._package.PackageExporter._module_is_already_provided(self,qualified_name:str)->bool
torch._package.PackageExporter._persistent_id(self,obj)
torch._package.PackageExporter._write(self,filename,str_or_bytes)
torch._package.PackageExporter._write_dep_graph(self,failing_module=None,output_file=None)
torch._package.PackageExporter.close(self)
torch._package.PackageExporter.extern_module(self,module_name:str)
torch._package.PackageExporter.extern_modules(self,module_names:List[str])
torch._package.PackageExporter.mock_module(self,module_name:str)
torch._package.PackageExporter.mock_modules(self,module_names)
torch._package.PackageExporter.require_module(self,module_name:str,dependencies=True)
torch._package.PackageExporter.require_module_if_not_provided(self,module_name:str,dependencies=True)
torch._package.PackageExporter.save_binary(self,package,resource,binary:bytes)
torch._package.PackageExporter.save_module(self,module_name:str,dependencies=True)
torch._package.PackageExporter.save_pickle(self,package:str,resource:str,obj:Any,dependencies:bool=True)
torch._package.PackageExporter.save_source_file(self,module_name:str,file_or_directory:str,dependencies=True)
torch._package.PackageExporter.save_source_string(self,module_name:str,src:str,is_package:bool=False,dependencies:bool=True,orig_file_name:str=None)
torch._package.PackageExporter.save_text(self,package:str,resource:str,text:str)
torch._package.exporter.PackageExporter(self,filename:str,verbose:bool=True)
torch._package.exporter.PackageExporter.__enter__(self)
torch._package.exporter.PackageExporter.__exit__(self,type,value,traceback)
torch._package.exporter.PackageExporter.__init__(self,filename:str,verbose:bool=True)
torch._package.exporter.PackageExporter._can_implicitly_extern(self,module_name:str)
torch._package.exporter.PackageExporter._create_pickler(self,data_buf)
torch._package.exporter.PackageExporter._filename(self,package,resource)
torch._package.exporter.PackageExporter._get_source_of_module(self,module:types.ModuleType)->str
torch._package.exporter.PackageExporter._import_module(self,module_name)
torch._package.exporter.PackageExporter._module_exists(self,module_name:str)->bool
torch._package.exporter.PackageExporter._module_is_already_provided(self,qualified_name:str)->bool
torch._package.exporter.PackageExporter._persistent_id(self,obj)
torch._package.exporter.PackageExporter._write(self,filename,str_or_bytes)
torch._package.exporter.PackageExporter._write_dep_graph(self,failing_module=None,output_file=None)
torch._package.exporter.PackageExporter.close(self)
torch._package.exporter.PackageExporter.extern_module(self,module_name:str)
torch._package.exporter.PackageExporter.extern_modules(self,module_names:List[str])
torch._package.exporter.PackageExporter.mock_module(self,module_name:str)
torch._package.exporter.PackageExporter.mock_modules(self,module_names)
torch._package.exporter.PackageExporter.require_module(self,module_name:str,dependencies=True)
torch._package.exporter.PackageExporter.require_module_if_not_provided(self,module_name:str,dependencies=True)
torch._package.exporter.PackageExporter.save_binary(self,package,resource,binary:bytes)
torch._package.exporter.PackageExporter.save_module(self,module_name:str,dependencies=True)
torch._package.exporter.PackageExporter.save_pickle(self,package:str,resource:str,obj:Any,dependencies:bool=True)
torch._package.exporter.PackageExporter.save_source_file(self,module_name:str,file_or_directory:str,dependencies=True)
torch._package.exporter.PackageExporter.save_source_string(self,module_name:str,src:str,is_package:bool=False,dependencies:bool=True,orig_file_name:str=None)
torch._package.exporter.PackageExporter.save_text(self,package:str,resource:str,text:str)
torch._package.exporter._is_builtin_or_stdlib_module(module:types.ModuleType)->bool
torch._package.exporter._read_file(filename:str)->str


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/importer.py----------------------------------------
A:torch._package.importer.self.zip_reader->MockZipReader(self.filename)
A:torch._package.importer.self.root->_PackageNode(None)
A:torch._package.importer.self.extern_modules->self._read_extern()
A:torch._package.importer.self.patched_builtins->builtins.__dict__.copy()
A:torch._package.importer.path->self._zipfile_path(package, resource)
A:torch._package.importer.data->self.load_binary(package, resource)
A:torch._package.importer.pickle_file->self._zipfile_path(package, resource)
A:torch._package.importer.spec->importlib.machinery.ModuleSpec(name, self, is_package=is_package)
A:torch._package.importer.module->self.import_module(package)
A:torch._package.importer.code->self._compile_source(filename)
A:torch._package.importer.moduleself.modules[name]->importlib.import_module(name)
A:torch._package.importer.source->_normalize_line_endings(source)
A:torch._package.importer.msg->(_ERR_MSG + '; {!r} is not a package').format(name, parent)
A:torch._package.importer.message->'import of {} halted; None in sys.modules'.format(name)
A:torch._package.importer.name->'.'.join(atoms[:i])
A:torch._package.importer.from_name->'{}.{}'.format(module.__name__, x)
A:torch._package.importer.package->self._get_or_create_package(prefix)
A:torch._package.importer.resource->_normalize_path(resource)
A:torch._package.importer.node->cur.children.get(atom, None)
A:torch._package.importer.nodecur.children[atom]->_PackageNode(None)
A:torch._package.importer.(*prefix, last)->extern_name.split('.')
A:torch._package.importer.package.children[package_name]->_ModuleNode(filename)
A:torch._package.importer.package.children[last]->_ExternNode()
A:torch._package.importer._NEEDS_LOADING->object()
A:torch._package.importer.mod->self._importer.import_module(module)
torch._package.PackageImporter(self,filename:str,module_allowed:Callable[[str],bool]=lambdamodule_name:True)
torch._package.PackageImporter.__import__(self,name,globals=None,locals=None,fromlist=(),level=0)
torch._package.PackageImporter._add_extern(self,extern_name:str)
torch._package.PackageImporter._add_file(self,filename:str)
torch._package.PackageImporter._compile_source(self,fullpath)
torch._package.PackageImporter._do_find_and_load(self,name)
torch._package.PackageImporter._find_and_load(self,name)
torch._package.PackageImporter._gcd_import(self,name,package=None,level=0)
torch._package.PackageImporter._get_or_create_package(self,atoms:List[str])->'Union[_PackageNode, _ExternNode]'
torch._package.PackageImporter._get_package(self,package)
torch._package.PackageImporter._handle_fromlist(self,module,fromlist,*,recursive=False)
torch._package.PackageImporter._load_module(self,name:str)
torch._package.PackageImporter._make_module(self,name:str,filename:Optional[str],is_package:bool)
torch._package.PackageImporter._read_extern(self)
torch._package.PackageImporter._zipfile_path(self,package,resource)
torch._package.PackageImporter.get_source(self,module_name)->str
torch._package.PackageImporter.import_module(self,name:str,package=None)
torch._package.PackageImporter.load_binary(self,package:str,resource:str)->bytes
torch._package.PackageImporter.load_pickle(self,package:str,resource:str,map_location=None)->Any
torch._package.PackageImporter.load_text(self,package:str,resource:str,encoding:str='utf-8',errors:str='strict')->str
torch._package.importer.PackageImporter(self,filename:str,module_allowed:Callable[[str],bool]=lambdamodule_name:True)
torch._package.importer.PackageImporter.__import__(self,name,globals=None,locals=None,fromlist=(),level=0)
torch._package.importer.PackageImporter.__init__(self,filename:str,module_allowed:Callable[[str],bool]=lambdamodule_name:True)
torch._package.importer.PackageImporter._add_extern(self,extern_name:str)
torch._package.importer.PackageImporter._add_file(self,filename:str)
torch._package.importer.PackageImporter._compile_source(self,fullpath)
torch._package.importer.PackageImporter._do_find_and_load(self,name)
torch._package.importer.PackageImporter._find_and_load(self,name)
torch._package.importer.PackageImporter._gcd_import(self,name,package=None,level=0)
torch._package.importer.PackageImporter._get_or_create_package(self,atoms:List[str])->'Union[_PackageNode, _ExternNode]'
torch._package.importer.PackageImporter._get_package(self,package)
torch._package.importer.PackageImporter._handle_fromlist(self,module,fromlist,*,recursive=False)
torch._package.importer.PackageImporter._load_module(self,name:str)
torch._package.importer.PackageImporter._make_module(self,name:str,filename:Optional[str],is_package:bool)
torch._package.importer.PackageImporter._read_extern(self)
torch._package.importer.PackageImporter._zipfile_path(self,package,resource)
torch._package.importer.PackageImporter.get_source(self,module_name)->str
torch._package.importer.PackageImporter.import_module(self,name:str,package=None)
torch._package.importer.PackageImporter.load_binary(self,package:str,resource:str)->bytes
torch._package.importer.PackageImporter.load_pickle(self,package:str,resource:str,map_location=None)->Any
torch._package.importer.PackageImporter.load_text(self,package:str,resource:str,encoding:str='utf-8',errors:str='strict')->str
torch._package.importer._ExternNode(_PathNode)
torch._package.importer._ModuleNode(self,source_file:str)
torch._package.importer._ModuleNode.__init__(self,source_file:str)
torch._package.importer._PackageNode(self,source_file:Optional[str])
torch._package.importer._PackageNode.__init__(self,source_file:Optional[str])
torch._package.importer._PathNode
torch._package.importer._UnpicklerWrapper(self,importer,*args,**kwargs)
torch._package.importer._UnpicklerWrapper.__init__(self,importer,*args,**kwargs)
torch._package.importer._UnpicklerWrapper.find_class(self,module,name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/find_file_dependencies.py----------------------------------------
A:torch._package.find_file_dependencies.visitor->cls(package)
A:torch._package.find_file_dependencies.tree->ast.parse(src)
A:torch._package.find_file_dependencies.name->self._absmodule(node.module, 0 if node.level is None else node.level)
torch._package.find_file_dependencies._ExtractModuleReferences(self,package)
torch._package.find_file_dependencies._ExtractModuleReferences.__init__(self,package)
torch._package.find_file_dependencies._ExtractModuleReferences._absmodule(self,module_name:str,level:int)->str
torch._package.find_file_dependencies._ExtractModuleReferences.run(cls,src:str,package:str)->List[Tuple[str, Optional[str]]]
torch._package.find_file_dependencies._ExtractModuleReferences.visit_Import(self,node)
torch._package.find_file_dependencies._ExtractModuleReferences.visit_ImportFrom(self,node)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/_importlib.py----------------------------------------
A:torch._package._importlib.source->source.replace(b'\r', b'\n').replace(b'\r', b'\n')
A:torch._package._importlib.bits->globals.get('__package__').rsplit('.', level - 1)
A:torch._package._importlib.package->globals.get('__package__')
A:torch._package._importlib.spec->globals.get('__spec__')
A:torch._package._importlib.(parent, file_name)->os.path.split(path)
torch._package._importlib._calc___package__(globals)
torch._package._importlib._normalize_line_endings(source)
torch._package._importlib._normalize_path(path)
torch._package._importlib._resolve_name(name,package,level)
torch._package._importlib._sanity_check(name,package,level)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/_custom_import_pickler.py----------------------------------------
A:torch._package._custom_import_pickler.name->getattr(obj, '__qualname__', None)
A:torch._package._custom_import_pickler.module_name->whichmodule(obj, name)
A:torch._package._custom_import_pickler.module->self.import_module(module_name)
A:torch._package._custom_import_pickler.(obj2, parent)->_getattribute(module, name)
A:torch._package._custom_import_pickler.code->pickle._extension_registry.get((module_name, name))
torch._package._custom_import_pickler.CustomImportPickler(self,import_module,*args,**kwargs)
torch._package._custom_import_pickler.CustomImportPickler.__init__(self,import_module,*args,**kwargs)
torch._package._custom_import_pickler.CustomImportPickler.save_global(self,obj,name=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/_mock_zipreader.py----------------------------------------
torch._package._mock_zipreader.MockZipReader(self,directory)
torch._package._mock_zipreader.MockZipReader.__init__(self,directory)
torch._package._mock_zipreader.MockZipReader.get_all_records(self)
torch._package._mock_zipreader.MockZipReader.get_record(self,name)
torch._package._mock_zipreader.MockZipReader.get_storage_from_record(self,name,numel,dtype)
torch._package._mock_zipreader._HasStorage(self,storage)
torch._package._mock_zipreader._HasStorage.__init__(self,storage)
torch._package._mock_zipreader._HasStorage.storage(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_package/_mock.py----------------------------------------
torch._package._mock.MockedObject(self,name)
torch._package._mock.MockedObject.__init__(self,name)
torch._package._mock.MockedObject.__repr__(self)
torch._package._mock.install_method(method_name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/futures/__init__.py----------------------------------------
A:torch.futures.__init__.T->TypeVar('T')
A:torch.futures.__init__.S->TypeVar('S')
torch.futures.__init__.Future(torch._C.Future,Generic[T],metaclass=_PyFutureMeta)
torch.futures.__init__.Future.done(self)->bool
torch.futures.__init__.Future.set_result(self,result:T)->None
torch.futures.__init__.Future.then(self,callback)
torch.futures.__init__.Future.wait(self)->T
torch.futures.__init__.collect_all(futures:List[Future])->Future[List[Future]]
torch.futures.__init__.wait_all(futures:List[Future])->List


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/for_onnx/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/fft/__init__.py----------------------------------------
A:torch.fft.__init__.fft->_add_docstr(_fft.fft_fft, '\nfft(input, n=None, dim=-1, norm=None) -> Tensor\n\nComputes the one dimensional discrete Fourier transform of :attr:`input`.\n\nNote:\n\n    The Fourier domain representation of any real signal satisfies the\n    Hermitian property: `X[i] = conj(X[-i])`. This function always returns both\n    the positive and negative frequency terms even though, for real inputs, the\n    negative frequencies are redundant. :func:`~torch.fft.rfft` returns the\n    more compact one-sided representation where only the positive frequencies\n    are returned.\n\nArgs:\n    input (Tensor): the input tensor\n    n (int, optional): Signal length. If given, the input will either be zero-padded\n        or trimmed to this length before computing the FFT.\n    dim (int, optional): The dimension along which to take the one dimensional FFT.\n    norm (str, optional): Normalization mode. For the forward transform\n        (:func:`~torch.fft.fft`), these correspond to:\n\n        * ``"forward"`` - normalize by ``1/n``\n        * ``"backward"`` - no normalization\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the FFT orthonormal)\n\n        Calling the backward transform (:func:`~torch.fft.ifft`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.ifft`\n        the exact inverse.\n\n        Default is ``"backward"`` (no normalization).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.arange(4)\n    >>> t\n    tensor([0, 1, 2, 3])\n    >>> torch.fft.fft(t)\n    tensor([ 6.+0.j, -2.+2.j, -2.+0.j, -2.-2.j])\n\n    >>> t = tensor([0.+1.j, 2.+3.j, 4.+5.j, 6.+7.j])\n    >>> torch.fft.fft(t)\n    tensor([12.+16.j, -8.+0.j, -4.-4.j,  0.-8.j])\n')
A:torch.fft.__init__.ifft->_add_docstr(_fft.fft_ifft, '\nifft(input, n=None, dim=-1, norm=None) -> Tensor\n\nComputes the one dimensional inverse discrete Fourier transform of :attr:`input`.\n\nArgs:\n    input (Tensor): the input tensor\n    n (int, optional): Signal length. If given, the input will either be zero-padded\n        or trimmed to this length before computing the IFFT.\n    dim (int, optional): The dimension along which to take the one dimensional IFFT.\n    norm (str, optional): Normalization mode. For the backward transform\n        (:func:`~torch.fft.ifft`), these correspond to:\n\n        * ``"forward"`` - no normalization\n        * ``"backward"`` - normalize by ``1/n``\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the IFFT orthonormal)\n\n        Calling the forward transform (:func:`~torch.fft.fft`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.ifft`\n        the exact inverse.\n\n        Default is ``"backward"`` (normalize by ``1/n``).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.tensor([ 6.+0.j, -2.+2.j, -2.+0.j, -2.-2.j])\n    >>> torch.fft.ifft(t)\n    tensor([0.+0.j, 1.+0.j, 2.+0.j, 3.+0.j])\n')
A:torch.fft.__init__.fftn->_add_docstr(_fft.fft_fftn, '\nfftn(input, s=None, dim=None, norm=None) -> Tensor\n\nComputes the N dimensional discrete Fourier transform of :attr:`input`.\n\nNote:\n\n    The Fourier domain representation of any real signal satisfies the\n    Hermitian property: ``X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])``. This\n    function always returns all positive and negative frequency terms even\n    though, for real inputs, half of these values are redundant.\n    :func:`~torch.fft.rfftn` returns the more compact one-sided representation\n    where only the positive frequencies of the last dimension are returned.\n\nArgs:\n    input (Tensor): the input tensor\n    s (Tuple[int], optional): Signal size in the transformed dimensions.\n        If given, each dimension ``dim[i]`` will either be zero-padded or\n        trimmed to the length ``s[i]`` before computing the FFT.\n        If a length ``-1`` is specified, no padding is done in that dimension.\n        Default: ``s = [input.size(d) for d in dim]``\n    dim (Tuple[int], optional): Dimensions to be transformed.\n        Default: all dimensions, or the last ``len(s)`` dimensions if :attr:`s` is given.\n    norm (str, optional): Normalization mode. For the forward transform\n        (:func:`~torch.fft.fftn`), these correspond to:\n\n        * ``"forward"`` - normalize by ``1/n``\n        * ``"backward"`` - no normalization\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the FFT orthonormal)\n\n        Where ``n = prod(s)`` is the logical FFT size.\n        Calling the backward transform (:func:`~torch.fft.ifftn`) with the same\n        normalization mode will apply an overall normalization of ``1/n``\n        between the two transforms. This is required to make\n        :func:`~torch.fft.ifftn` the exact inverse.\n\n        Default is ``"backward"`` (no normalization).\n\nExample:\n\n    >>> import torch.fft\n    >>> x = torch.rand(10, 10, dtype=torch.complex64)\n    >>> fftn = torch.fft.fftn(t)\n\n    The discrete Fourier transform is separable, so :func:`~torch.fft.fftn`\n    here is equivalent to two one-dimensional :func:`~torch.fft.fft` calls:\n\n    >>> two_ffts = torch.fft.fft(torch.fft.fft(x, dim=0), dim=1)\n    >>> torch.allclose(fftn, two_ffts)\n\n')
A:torch.fft.__init__.ifftn->_add_docstr(_fft.fft_ifftn, '\nifftn(input, s=None, dim=None, norm=None) -> Tensor\n\nComputes the N dimensional inverse discrete Fourier transform of :attr:`input`.\n\nArgs:\n    input (Tensor): the input tensor\n    s (Tuple[int], optional): Signal size in the transformed dimensions.\n        If given, each dimension ``dim[i]`` will either be zero-padded or\n        trimmed to the length ``s[i]`` before computing the IFFT.\n        If a length ``-1`` is specified, no padding is done in that dimension.\n        Default: ``s = [input.size(d) for d in dim]``\n    dim (Tuple[int], optional): Dimensions to be transformed.\n        Default: all dimensions, or the last ``len(s)`` dimensions if :attr:`s` is given.\n    norm (str, optional): Normalization mode. For the backward transform\n        (:func:`~torch.fft.ifftn`), these correspond to:\n\n        * ``"forward"`` - no normalization\n        * ``"backward"`` - normalize by ``1/n``\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the IFFT orthonormal)\n\n        Where ``n = prod(s)`` is the logical IFFT size.\n        Calling the forward transform (:func:`~torch.fft.fftn`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.ifftn`\n        the exact inverse.\n\n        Default is ``"backward"`` (normalize by ``1/n``).\n\nExample:\n\n    >>> import torch.fft\n    >>> x = torch.rand(10, 10, dtype=torch.complex64)\n    >>> ifftn = torch.fft.ifftn(t)\n\n    The discrete Fourier transform is separable, so :func:`~torch.fft.ifftn`\n    here is equivalent to two one-dimensional :func:`~torch.fft.ifft` calls:\n\n    >>> two_iffts = torch.fft.ifft(torch.fft.ifft(x, dim=0), dim=1)\n    >>> torch.allclose(ifftn, two_iffts)\n\n')
A:torch.fft.__init__.rfft->_add_docstr(_fft.fft_rfft, '\nrfft(input, n=None, dim=-1, norm=None) -> Tensor\n\nComputes the one dimensional Fourier transform of real-valued :attr:`input`.\n\nThe FFT of a real signal is Hermitian-symmetric, ``X[i] = conj(X[-i])`` so\nthe output contains only the positive frequencies below the Nyquist frequency.\nTo compute the full output, use :func:`~torch.fft.fft`\n\nArgs:\n    input (Tensor): the real input tensor\n    n (int, optional): Signal length. If given, the input will either be zero-padded\n        or trimmed to this length before computing the real FFT.\n    dim (int, optional): The dimension along which to take the one dimensional real FFT.\n    norm (str, optional): Normalization mode. For the forward transform\n        (:func:`~torch.fft.rfft`), these correspond to:\n\n        * ``"forward"`` - normalize by ``1/n``\n        * ``"backward"`` - no normalization\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the FFT orthonormal)\n\n        Calling the backward transform (:func:`~torch.fft.irfft`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.irfft`\n        the exact inverse.\n\n        Default is ``"backward"`` (no normalization).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.arange(4)\n    >>> t\n    tensor([0, 1, 2, 3])\n    >>> torch.fft.rfft(t)\n    tensor([ 6.+0.j, -2.+2.j, -2.+0.j])\n\n    Compare against the full output from :func:`~torch.fft.fft`:\n\n    >>> torch.fft.fft(t)\n    tensor([ 6.+0.j, -2.+2.j, -2.+0.j, -2.-2.j])\n\n    Notice that the symmetric element ``T[-1] == T[1].conj()`` is omitted.\n    At the Nyquist frequency ``T[-2] == T[2]`` is it\'s own symmetric pair,\n    and therefore must always be real-valued.\n')
A:torch.fft.__init__.irfft->_add_docstr(_fft.fft_irfft, '\nirfft(input, n=None, dim=-1, norm=None) -> Tensor\n\nComputes the inverse of :func:`~torch.fft.rfft`.\n\n:attr:`input` is interpreted as a one-sided Hermitian signal in the Fourier\ndomain, as produced by :func:`~torch.fft.rfft`. By the Hermitian property, the\noutput will be real-valued.\n\nNote:\n    Some input frequencies must be real-valued to satisfy the Hermitian\n    property. In these cases the imaginary component will be ignored.\n    For example, any imaginary component in the zero-frequency term cannot\n    be represented in a real output and so will always be ignored.\n\nNote:\n    The correct interpretation of the Hermitian input depends on the length of\n    the original data, as given by :attr:`n`. This is because each input shape\n    could correspond to either an odd or even length signal. By default, the\n    signal is assumed to be even length and odd signals will not round-trip\n    properly. So, it is recommended to always pass the signal length :attr:`n`.\n\nArgs:\n    input (Tensor): the input tensor representing a half-Hermitian signal\n    n (int, optional): Output signal length. This determines the length of the\n        output signal. If given, the input will either be zero-padded or trimmed to this\n        length before computing the real IFFT.\n        Defaults to even output: ``n=2*(input.size(dim) - 1)``.\n    dim (int, optional): The dimension along which to take the one dimensional real IFFT.\n    norm (str, optional): Normalization mode. For the backward transform\n        (:func:`~torch.fft.irfft`), these correspond to:\n\n        * ``"forward"`` - no normalization\n        * ``"backward"`` - normalize by ``1/n``\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the real IFFT orthonormal)\n\n        Calling the forward transform (:func:`~torch.fft.rfft`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.irfft`\n        the exact inverse.\n\n        Default is ``"backward"`` (normalize by ``1/n``).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.arange(5)\n    >>> t\n    tensor([0, 1, 2, 3, 4])\n    >>> T = torch.fft.rfft(t)\n    >>> T\n    tensor([10.0000+0.0000j, -2.5000+3.4410j, -2.5000+0.8123j])\n\n    Without specifying the output length to :func:`~torch.fft.irfft`, the output\n    will not round-trip properly because the input is odd-length:\n\n    >>> torch.fft.irfft(T)\n    tensor([0.6250, 1.4045, 3.1250, 4.8455])\n\n    So, it is recommended to always pass the signal length :attr:`n`:\n\n    >>> torch.fft.irfft(T, t.numel())\n    tensor([0.0000, 1.0000, 2.0000, 3.0000, 4.0000])\n')
A:torch.fft.__init__.rfftn->_add_docstr(_fft.fft_rfftn, '\nrfftn(input, s=None, dim=None, norm=None) -> Tensor\n\nComputes the N-dimensional discrete Fourier transform of real :attr:`input`.\n\nThe FFT of a real signal is Hermitian-symmetric,\n``X[i_1, ..., i_n] = conj(X[-i_1, ..., -i_n])`` so the full\n:func:`~torch.fft.fftn` output contains redundant information.\n:func:`~torch.fft.rfftn` instead omits the negative frequencies in the\nlast dimension.\n\nArgs:\n    input (Tensor): the input tensor\n    s (Tuple[int], optional): Signal size in the transformed dimensions.\n        If given, each dimension ``dim[i]`` will either be zero-padded or\n        trimmed to the length ``s[i]`` before computing the real FFT.\n        If a length ``-1`` is specified, no padding is done in that dimension.\n        Default: ``s = [input.size(d) for d in dim]``\n    dim (Tuple[int], optional): Dimensions to be transformed.\n        Default: all dimensions, or the last ``len(s)`` dimensions if :attr:`s` is given.\n    norm (str, optional): Normalization mode. For the forward transform\n        (:func:`~torch.fft.rfftn`), these correspond to:\n\n        * ``"forward"`` - normalize by ``1/n``\n        * ``"backward"`` - no normalization\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the real FFT orthonormal)\n\n        Where ``n = prod(s)`` is the logical FFT size.\n        Calling the backward transform (:func:`~torch.fft.irfftn`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.irfftn`\n        the exact inverse.\n\n        Default is ``"backward"`` (no normalization).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.rand(10, 10)\n    >>> rfftn = torch.fft.rfftn(t)\n    >>> rfftn.size()\n    torch.Size([10, 6])\n\n    Compared against the full output from :func:`~torch.fft.fftn`, we have all\n    elements up to the Nyquist frequency.\n\n    >>> fftn = torch.fft.fftn(t)\n    >>> torch.allclose(fftn[..., :6], rfftn)\n    True\n\n    The discrete Fourier transform is separable, so :func:`~torch.fft.rfftn`\n    here is equivalent to a combination of :func:`~torch.fft.fft` and\n    :func:`~torch.fft.rfft`:\n\n    >>> two_ffts = torch.fft.fft(torch.fft.rfft(x, dim=1), dim=0)\n    >>> torch.allclose(rfftn, two_ffts)\n\n')
A:torch.fft.__init__.irfftn->_add_docstr(_fft.fft_irfftn, '\nirfftn(input, s=None, dim=None, norm=None) -> Tensor\n\nComputes the inverse of :func:`~torch.fft.rfftn`.\n\n:attr:`input` is interpreted as a one-sided Hermitian signal in the Fourier\ndomain, as produced by :func:`~torch.fft.rfftn`. By the Hermitian property, the\noutput will be real-valued.\n\nNote:\n    Some input frequencies must be real-valued to satisfy the Hermitian\n    property. In these cases the imaginary component will be ignored.\n    For example, any imaginary component in the zero-frequency term cannot\n    be represented in a real output and so will always be ignored.\n\nNote:\n    The correct interpretation of the Hermitian input depends on the length of\n    the original data, as given by :attr:`s`. This is because each input shape\n    could correspond to either an odd or even length signal. By default, the\n    signal is assumed to be even length and odd signals will not round-trip\n    properly. So, it is recommended to always pass the signal shape :attr:`s`.\n\nArgs:\n    input (Tensor): the input tensor\n    s (Tuple[int], optional): Signal size in the transformed dimensions.\n        If given, each dimension ``dim[i]`` will either be zero-padded or\n        trimmed to the length ``s[i]`` before computing the real FFT.\n        If a length ``-1`` is specified, no padding is done in that dimension.\n        Defaults to even output in the last dimension:\n        ``s[-1] = 2*(input.size(dim[-1]) - 1)``.\n    dim (Tuple[int], optional): Dimensions to be transformed.\n        The last dimension must be the half-Hermitian compressed dimension.\n        Default: all dimensions, or the last ``len(s)`` dimensions if :attr:`s` is given.\n    norm (str, optional): Normalization mode. For the backward transform\n        (:func:`~torch.fft.irfftn`), these correspond to:\n\n        * ``"forward"`` - no normalization\n        * ``"backward"`` - normalize by ``1/n``\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the real IFFT orthonormal)\n\n        Where ``n = prod(s)`` is the logical IFFT size.\n        Calling the forward transform (:func:`~torch.fft.rfftn`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.irfftn`\n        the exact inverse.\n\n        Default is ``"backward"`` (normalize by ``1/n``).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.rand(10, 9)\n    >>> T = torch.fft.rfftn(t)\n\n    Without specifying the output length to :func:`~torch.fft.irfft`, the output\n    will not round-trip properly because the input is odd-length in the last\n    dimension:\n\n    >>> torch.fft.irfftn(T).size()\n    torch.Size([10, 10])\n\n    So, it is recommended to always pass the signal shape :attr:`s`.\n\n    >>> roundtrip = torch.fft.irfftn(T, t.size())\n    >>> roundtrip.size()\n    torch.Size([10, 9])\n    >>> torch.allclose(roundtrip, t)\n    True\n\n')
A:torch.fft.__init__.hfft->_add_docstr(_fft.fft_hfft, '\nhfft(input, n=None, dim=-1, norm=None) -> Tensor\n\nComputes the one dimensional discrete Fourier transform of a Hermitian\nsymmetric :attr:`input` signal.\n\nNote:\n\n    :func:`~torch.fft.hfft`/:func:`~torch.fft.ihfft` are analogous to\n    :func:`~torch.fft.rfft`/:func:`~torch.fft.irfft`. The real FFT expects\n    a real signal in the time-domain and gives a Hermitian symmetry in the\n    frequency-domain. The Hermitian FFT is the opposite; Hermitian symmetric in\n    the time-domain and real-valued in the frequency-domain. For this reason,\n    special care needs to be taken with the length argument :attr:`n`, in the\n    same way as with :func:`~torch.fft.irfft`.\n\nNote:\n    Because the signal is Hermitian in the time-domain, the result will be\n    real in the frequency domain. Note that some input frequencies must be\n    real-valued to satisfy the Hermitian property. In these cases the imaginary\n    component will be ignored. For example, any imaginary component in\n    ``input[0]`` would result in one or more complex frequency terms which\n    cannot be represented in a real output and so will always be ignored.\n\nNote:\n    The correct interpretation of the Hermitian input depends on the length of\n    the original data, as given by :attr:`n`. This is because each input shape\n    could correspond to either an odd or even length signal. By default, the\n    signal is assumed to be even length and odd signals will not round-trip\n    properly. So, it is recommended to always pass the signal length :attr:`n`.\n\nArgs:\n    input (Tensor): the input tensor representing a half-Hermitian signal\n    n (int, optional): Output signal length. This determines the length of the\n        real output. If given, the input will either be zero-padded or trimmed to this\n        length before computing the Hermitian FFT.\n        Defaults to even output: ``n=2*(input.size(dim) - 1)``.\n    dim (int, optional): The dimension along which to take the one dimensional Hermitian FFT.\n    norm (str, optional): Normalization mode. For the forward transform\n        (:func:`~torch.fft.hfft`), these correspond to:\n\n        * ``"forward"`` - normalize by ``1/n``\n        * ``"backward"`` - no normalization\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the Hermitian FFT orthonormal)\n\n        Calling the backward transform (:func:`~torch.fft.ihfft`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.ihfft`\n        the exact inverse.\n\n        Default is ``"backward"`` (no normalization).\n\nExample:\n\n    Taking a real-valued frequency signal and bringing it into the time domain\n    gives Hermitian symmetric output:\n\n    >>> import torch.fft\n    >>> t = torch.arange(5)\n    >>> t\n    tensor([0, 1, 2, 3, 4])\n    >>> T = torch.fft.ifft(t)\n    >>> T\n    tensor([ 2.0000+-0.0000j, -0.5000-0.6882j, -0.5000-0.1625j, -0.5000+0.1625j,\n            -0.5000+0.6882j])\n\n    Note that ``T[1] == T[-1].conj()`` and ``T[2] == T[-2].conj()`` is\n    redundant. We can thus compute the forward transform without considering\n    negative frequencies:\n\n    >>> torch.fft.hfft(T[:3], n=5)\n    tensor([0., 1., 2., 3., 4.])\n\n    Like with :func:`~torch.fft.irfft`, the output length must be given in order\n    to recover an even length output:\n\n    >>> torch.fft.hfft(T[:3])\n    tensor([0.5000, 1.1236, 2.5000, 3.8764])\n')
A:torch.fft.__init__.ihfft->_add_docstr(_fft.fft_ihfft, '\nihfft(input, n=None, dim=-1, norm=None) -> Tensor\n\nComputes the inverse of :func:`~torch.fft.hfft`.\n\n:attr:`input` must be a real-valued signal, interpreted in the Fourier domain.\nThe IFFT of a real signal is Hermitian-symmetric, ``X[i] = conj(X[-i])``.\n:func:`~torch.fft.ihfft` represents this in the one-sided form where only the\npositive frequencies below the Nyquist frequency are included. To compute the\nfull output, use :func:`~torch.fft.ifft`.\n\nArgs:\n    input (Tensor): the real input tensor\n    n (int, optional): Signal length. If given, the input will either be zero-padded\n        or trimmed to this length before computing the Hermitian IFFT.\n    dim (int, optional): The dimension along which to take the one dimensional Hermitian IFFT.\n    norm (str, optional): Normalization mode. For the backward transform\n        (:func:`~torch.fft.ihfft`), these correspond to:\n\n        * ``"forward"`` - no normalization\n        * ``"backward"`` - normalize by ``1/n``\n        * ``"ortho"`` - normalize by ``1/sqrt(n)`` (making the IFFT orthonormal)\n\n        Calling the forward transform (:func:`~torch.fft.hfft`) with the same\n        normalization mode will apply an overall normalization of ``1/n`` between\n        the two transforms. This is required to make :func:`~torch.fft.ihfft`\n        the exact inverse.\n\n        Default is ``"backward"`` (normalize by ``1/n``).\n\nExample:\n\n    >>> import torch.fft\n    >>> t = torch.arange(5)\n    >>> t\n    tensor([0, 1, 2, 3, 4])\n    >>> torch.fft.ihfft(t)\n    tensor([ 2.0000+-0.0000j, -0.5000-0.6882j, -0.5000-0.1625j])\n\n    Compare against the full output from :func:`~torch.fft.ifft`:\n\n    >>> torch.fft.ifft(t)\n    tensor([ 2.0000+-0.0000j, -0.5000-0.6882j, -0.5000-0.1625j, -0.5000+0.1625j,\n        -0.5000+0.6882j])\n')


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/sparse/__init__.py----------------------------------------
torch.sparse.__init__.addmm(mat:Tensor,mat1:Tensor,mat2:Tensor,beta:float=1.0,alpha:float=1.0)->Tensor
torch.sparse.__init__.log_softmax(input:Tensor,dim:int,dtype:Optional[DType]=None)->Tensor
torch.sparse.__init__.mm(mat1:Tensor,mat2:Tensor)->Tensor
torch.sparse.__init__.softmax(input:Tensor,dim:int,dtype:Optional[DType]=None)->Tensor
torch.sparse.__init__.sum(input:Tensor,dim:DimOrDims=None,dtype:Optional[DType]=None)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/node.py----------------------------------------
torch._fx.Node(self,graph:'Graph',name:str,op:str,target:Target,args:Tuple[Argument,...],kwargs:Dict[str,Argument])
torch._fx.Node.__repr__(self)->str
torch._fx.node.Node(self,graph:'Graph',name:str,op:str,target:Target,args:Tuple[Argument,...],kwargs:Dict[str,Argument])
torch._fx.node.Node.__init__(self,graph:'Graph',name:str,op:str,target:Target,args:Tuple[Argument,...],kwargs:Dict[str,Argument])
torch._fx.node.Node.__repr__(self)->str


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/proxy.py----------------------------------------
A:torch._fx.proxy.r[k]->self.create_arg(v)
A:torch._fx.proxy.args->GraphAppendingTracer(node.graph).create_arg(args_)
A:torch._fx.proxy.kwargs->GraphAppendingTracer(node.graph).create_arg(kwargs_)
A:torch._fx.proxy.rn->GraphAppendingTracer(node.graph).create_node(op, target, args, kwargs, name)
A:torch._fx.proxy.tracer->GraphAppendingTracer(node.graph)
A:torch._fx.proxy.frame->inspect.currentframe()
A:torch._fx.proxy.target->getattr(operator, orig_method_name)
torch._fx.Proxy(self,node:Node,tracer:'Optional[TracerBase]'=None)
torch._fx.Proxy.__bool__(self)->NoReturn
torch._fx.Proxy.__getattr__(self,k)->'Attribute'
torch._fx.Proxy.__iter__(self)->Iterable['Proxy']
torch._fx.Proxy.__repr__(self)->str
torch._fx.Proxy.__torch_function__(self,orig_method,types,args=None,kwargs=None)
torch._fx.Proxy._no_arg_unpack(self)->NoReturn
torch._fx.Proxy._no_control_flow(self)->NoReturn
torch._fx.proxy.Attribute(self,root:Proxy,attr:str)
torch._fx.proxy.Attribute.__init__(self,root:Proxy,attr:str)
torch._fx.proxy.Attribute.node(self)
torch._fx.proxy.GraphAppendingTracer(self,graph:Graph)
torch._fx.proxy.GraphAppendingTracer.__init__(self,graph:Graph)
torch._fx.proxy.Proxy(self,node:Node,tracer:'Optional[TracerBase]'=None)
torch._fx.proxy.Proxy.__bool__(self)->NoReturn
torch._fx.proxy.Proxy.__getattr__(self,k)->'Attribute'
torch._fx.proxy.Proxy.__init__(self,node:Node,tracer:'Optional[TracerBase]'=None)
torch._fx.proxy.Proxy.__iter__(self)->Iterable['Proxy']
torch._fx.proxy.Proxy.__repr__(self)->str
torch._fx.proxy.Proxy.__torch_function__(self,orig_method,types,args=None,kwargs=None)
torch._fx.proxy.Proxy._no_arg_unpack(self)->NoReturn
torch._fx.proxy.Proxy._no_control_flow(self)->NoReturn
torch._fx.proxy.TraceError(ValueError)
torch._fx.proxy.TracerBase
torch._fx.proxy.TracerBase.create_arg(self,a:Any)->Argument
torch._fx.proxy.TracerBase.create_node(self,kind:str,target:Union[str,Callable],args:Tuple[Argument,...],kwargs:Dict[str,Argument],name:Optional[str]=None)->Node
torch._fx.proxy._create_proxy(tracer:'TracerBase',op:str,target:Target,args_:Tuple[Any,...],kwargs_:Dict[str,Any],name=None)
torch._fx.proxy._define_reflectable(orig_method_name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/graph_module.py----------------------------------------
A:torch._fx.graph_module.CodeOnlyModule.forward->_forward_from_src(body['code'])
A:torch._fx.graph_module.(*prefix, field)->target.split('.')
A:torch._fx.graph_module.f->getattr(from_module, item)
A:torch._fx.graph_module.t->torch.nn.Module()
A:torch._fx.graph_module.(body, result, free_variables)->self._graph.python_code(root_module='self')
A:torch._fx.graph_module.cls->type(self)
A:torch._fx.graph_module.cls.forward->_forward_from_src(self.code)
A:torch._fx.graph_module.dict_without_graph->self.__dict__.copy()
A:torch._fx.graph_module.fake_mod->torch.nn.Module()
A:torch._fx.graph_module.fake_mod.__dict__->copy.deepcopy(self.__dict__)
A:torch._fx.graph_module.orig_str->super().__str__()
torch._fx.GraphModule(self,root:Union[torch.nn.Module,Dict[str,Any]],graph:Graph)
torch._fx.GraphModule.__copy__(self)
torch._fx.GraphModule.__deepcopy__(self,memo)
torch._fx.GraphModule.__reduce__(self)
torch._fx.GraphModule.__str__(self)->str
torch._fx.GraphModule.graph(self)
torch._fx.GraphModule.graph(self,val)->None
torch._fx.graph_module.GraphModule(self,root:Union[torch.nn.Module,Dict[str,Any]],graph:Graph)
torch._fx.graph_module.GraphModule.__copy__(self)
torch._fx.graph_module.GraphModule.__deepcopy__(self,memo)
torch._fx.graph_module.GraphModule.__init__(self,root:Union[torch.nn.Module,Dict[str,Any]],graph:Graph)
torch._fx.graph_module.GraphModule.__reduce__(self)
torch._fx.graph_module.GraphModule.__str__(self)->str
torch._fx.graph_module.GraphModule.graph(self)
torch._fx.graph_module.GraphModule.graph(self,val)->None
torch._fx.graph_module._assign_attr(from_obj:Any,to_module:torch.nn.Module,target:str)
torch._fx.graph_module._copy_attr(from_module:torch.nn.Module,to_module:torch.nn.Module,target:str)
torch._fx.graph_module._forward_from_src(src:str)
torch._fx.graph_module.deserialize_graphmodule(body:dict)->torch.nn.Module
torch._fx.graph_module.exec_with_source(src:str,globals:Dict[str,Any])
torch._fx.graph_module.patched_getline(*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/graph.py----------------------------------------
A:torch._fx.graph.module->module.replace('torch._ops', 'torch.ops').replace('torch._ops', 'torch.ops')
A:torch._fx.graph.args_s->', '.join((repr(a) for a in args))
A:torch._fx.graph.kwargs_s->', '.join((f'{k} = {repr(v)}' for (k, v) in kwargs.items()))
A:torch._fx.graph.elems->target.split('.')
A:torch._fx.graph.val_map[node]->self.node_copy(node, lambda n: val_map[n])
A:torch._fx.graph.n->Node(self, sanitized_name, op, target, args, kwargs)
A:torch._fx.graph.args->map_arg(node.args, arg_transform)
A:torch._fx.graph.kwargs->map_arg(node.kwargs, arg_transform)
A:torch._fx.graph.(base, maybe_idx)->node.name.rsplit('_', 1)
A:torch._fx.graph.name->self._name(sanitized_name)
A:torch._fx.graph.op->snake_case(op)
A:torch._fx.graph.raw_name->node.target.replace('*', '')
A:torch._fx.graph.qualified_name->_qualified_name(node.target)
A:torch._fx.graph.src->''.join(body)
A:torch._fx.graph.items->', '.join((format_arg(a) for a in arg))
A:torch._fx.graph.items_str->', '.join((f'{k}: {format_arg(v)}' for (k, v) in arg.items()))
A:torch._fx.graph.param_str->', '.join(placeholder_names)
A:torch._fx.graph.target_atoms->node.target.split('.')
A:torch._fx.graph.m_itr->getattr(m_itr, atom, None)
A:torch._fx.graph.seen_qualname->'.'.join(target_atoms[:i])
A:torch._fx.graph.magic_methods->dict({'eq': '{} == {}', 'ne': '{} != {}', 'lt': '{} < {}', 'gt': '{} > {}', 'le': '{} <= {}', 'ge': '{} >= {}', 'pos': '+{}', 'neg': '-{}', 'invert': '~{}'}, **reflectable_magic_methods)
torch._fx.Graph(self)
torch._fx.Graph.__str__(self)->str
torch._fx.Graph._mark_uses(self,a:Argument)
torch._fx.Graph._name(self,target:Target)->str
torch._fx.Graph._register_name_used(self,op:str)->str
torch._fx.Graph.call_function(self,the_function:Callable[...,Any],args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None)->Node
torch._fx.Graph.call_method(self,method_name:str,args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None)->Node
torch._fx.Graph.call_module(self,module_name:str,args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None)->Node
torch._fx.Graph.create_node(self,op:str,target:Target,args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None,name:Optional[str]=None)->Node
torch._fx.Graph.get_attr(self,name:str)->Node
torch._fx.Graph.graph_copy(self,g:'Graph')
torch._fx.Graph.lint(self,root:Optional[torch.nn.Module]=None)
torch._fx.Graph.node_copy(self,node:Node,arg_transform:Callable[[Node],Argument]=lambdax:x)->Node
torch._fx.Graph.nodes(self)
torch._fx.Graph.output(self,result:Argument)
torch._fx.Graph.placeholder(self,name:str)->Node
torch._fx.Graph.python_code(self,root_module:str)->Tuple[str, str, List[str]]
torch._fx.graph.Graph(self)
torch._fx.graph.Graph.__init__(self)
torch._fx.graph.Graph.__str__(self)->str
torch._fx.graph.Graph._mark_uses(self,a:Argument)
torch._fx.graph.Graph._name(self,target:Target)->str
torch._fx.graph.Graph._register_name_used(self,op:str)->str
torch._fx.graph.Graph.call_function(self,the_function:Callable[...,Any],args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None)->Node
torch._fx.graph.Graph.call_method(self,method_name:str,args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None)->Node
torch._fx.graph.Graph.call_module(self,module_name:str,args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None)->Node
torch._fx.graph.Graph.create_node(self,op:str,target:Target,args:Optional[Tuple[Argument,...]]=None,kwargs:Optional[Dict[str,Argument]]=None,name:Optional[str]=None)->Node
torch._fx.graph.Graph.get_attr(self,name:str)->Node
torch._fx.graph.Graph.graph_copy(self,g:'Graph')
torch._fx.graph.Graph.lint(self,root:Optional[torch.nn.Module]=None)
torch._fx.graph.Graph.node_copy(self,node:Node,arg_transform:Callable[[Node],Argument]=lambdax:x)->Node
torch._fx.graph.Graph.nodes(self)
torch._fx.graph.Graph.output(self,result:Argument)
torch._fx.graph.Graph.placeholder(self,name:str)->Node
torch._fx.graph.Graph.python_code(self,root_module:str)->Tuple[str, str, List[str]]
torch._fx.graph._find_module_of_method(orig_method:Callable[...,Any])->str
torch._fx.graph._format_args(args:Tuple[Argument,...],kwargs:Dict[str,Argument])->str
torch._fx.graph._format_target(base:str,target:str)->str
torch._fx.graph._is_magic(x:str)->bool
torch._fx.graph._qualified_name(func:Callable[...,Any])->str
torch._fx.graph._shadows_builtin_name(name:str)->bool
torch._fx.graph.map_arg(a:Argument,fn:Callable[[Node],Argument])->Argument
torch._fx.graph.snake_case(s:str)->str
torch._fx.map_arg(a:Argument,fn:Callable[[Node],Argument])->Argument


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/symbolic_trace.py----------------------------------------
A:torch._fx.symbolic_trace.new_code->CodeType(*co_args)
A:torch._fx.symbolic_trace.self.graph->Graph()
A:torch._fx.symbolic_trace.names_iter->iter(co.co_varnames)
A:torch._fx.symbolic_trace.fn->_patch_function(fn, len(args))
A:torch._fx.symbolic_trace.module_qualified_name->_find_module(root, mod)
torch._fx.Tracer(self)
torch._fx.Tracer._proxy_placeholder(self,name:str)->Proxy
torch._fx.Tracer.create_arg(self,a:Any)->Argument
torch._fx.Tracer.is_leaf_module(self,m:torch.nn.Module,module_qualified_name:str)->bool
torch._fx.Tracer.trace(self,root:torch.nn.Module)->GraphModule
torch._fx.symbolic_trace(root:torch.nn.Module)->GraphModule
torch._fx.symbolic_trace.Tracer(self)
torch._fx.symbolic_trace.Tracer.__init__(self)
torch._fx.symbolic_trace.Tracer._proxy_placeholder(self,name:str)->Proxy
torch._fx.symbolic_trace.Tracer.create_arg(self,a:Any)->Argument
torch._fx.symbolic_trace.Tracer.is_leaf_module(self,m:torch.nn.Module,module_qualified_name:str)->bool
torch._fx.symbolic_trace.Tracer.trace(self,root:torch.nn.Module)->GraphModule
torch._fx.symbolic_trace._find_module(root:torch.nn.Module,m:torch.nn.Module)
torch._fx.symbolic_trace._patch_function(fn:FunctionType,nargs:int)->FunctionType
torch._fx.symbolic_trace.symbolic_trace(root:torch.nn.Module)->GraphModule


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/experimental/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_fx/experimental/GraphManipulation.py----------------------------------------
A:torch._fx.experimental.GraphManipulation.new_graph->Graph()
A:torch._fx.experimental.GraphManipulation.args->map_arg(node.args, lambda n: val_map[n])
A:torch._fx.experimental.GraphManipulation.kwargs->map_arg(node.kwargs, lambda n: val_map[n])
A:torch._fx.experimental.GraphManipulation.val_map[node]->Graph().node_copy(node, lambda n: val_map[n])
torch._fx.experimental.GraphManipulation.find_use(arg:Any,node:Node)->bool
torch._fx.experimental.GraphManipulation.get_all_users_of(fx_module:GraphModule,index:int)->List[int]
torch._fx.experimental.GraphManipulation.replace_target_nodes_with(fx_module:GraphModule,old_op:str,old_target:Target,new_op:str,new_target:Target)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/anomaly_mode.py----------------------------------------
A:torch.autograd.anomaly_mode.self.prev->torch.is_anomaly_enabled()
torch.autograd.anomaly_mode.detect_anomaly(self)
torch.autograd.anomaly_mode.detect_anomaly.__enter__(self)->None
torch.autograd.anomaly_mode.detect_anomaly.__exit__(self,*args:Any)->None
torch.autograd.anomaly_mode.detect_anomaly.__init__(self)
torch.autograd.anomaly_mode.set_detect_anomaly(self,mode:bool)
torch.autograd.anomaly_mode.set_detect_anomaly.__enter__(self)->None
torch.autograd.anomaly_mode.set_detect_anomaly.__exit__(self,*args:Any)->None
torch.autograd.anomaly_mode.set_detect_anomaly.__init__(self,mode:bool)
torch.autograd.detect_anomaly(self)
torch.autograd.detect_anomaly.__enter__(self)->None
torch.autograd.detect_anomaly.__exit__(self,*args:Any)->None
torch.autograd.set_detect_anomaly(self,mode:bool)
torch.autograd.set_detect_anomaly.__enter__(self)->None
torch.autograd.set_detect_anomaly.__exit__(self,*args:Any)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/profiler.py----------------------------------------
A:torch.autograd.profiler.use_cuda->kwargs.pop('use_cuda', True)
A:torch.autograd.profiler.profile_memory->kwargs.pop('profile_memory', False)
A:torch.autograd.profiler.events->EventList(sorted(events, key=lambda evt: getattr(evt, sort_by), reverse=True), use_cuda=use_cuda, profile_memory=profile_memory)
A:torch.autograd.profiler.threads->itertools.groupby(events, key=lambda event: (event.thread, event.node_id))
A:torch.autograd.profiler.thread_events_->sorted(thread_events, key=lambda event: [event.cpu_interval.start, -event.cpu_interval.end])
A:torch.autograd.profiler.p->bw_parent(evt)
A:torch.autograd.profiler.avg_list->EventList(stats.values(), use_cuda=self._use_cuda, profile_memory=self._profile_memory)
A:torch.autograd.profiler.total_stat->FunctionEventAvg()
A:torch.autograd.profiler.config->torch.autograd.ProfilerConfig(profiler_kind, self.record_shapes, self.profile_memory, self.with_stack)
A:torch.autograd.profiler.records->torch.autograd._disable_profiler()
A:torch.autograd.profiler.self.function_events->EventList(parse_event_records(records), use_cuda=self.use_cuda, profile_memory=self.profile_memory)
A:torch.autograd.profiler.self.handle->torch.ops.profiler._record_function_enter(self.name)
A:torch.autograd.profiler.profiled_future->torch.ops.profiler._call_end_callbacks_on_jit_fut(self.handle, fut)
A:torch.autograd.profiler.cpu_time_str->attr_formatter('cpu_time')
A:torch.autograd.profiler.cuda_time_str->attr_formatter('cuda_time')
A:torch.autograd.profiler.cpu_time_total_str->attr_formatter('cpu_time_total')
A:torch.autograd.profiler.cuda_time_total_str->attr_formatter('cuda_time_total')
A:torch.autograd.profiler.self_cpu_time_total_str->attr_formatter('self_cpu_time_total')
A:torch.autograd.profiler.self_cuda_time_total_str->attr_formatter('self_cuda_time_total')
A:torch.autograd.profiler.Kernel->namedtuple('Kernel', ['name', 'device', 'interval'])
A:torch.autograd.profiler.string_table->StringTable()
A:torch.autograd.profiler.name->record.name()
A:torch.autograd.profiler.filtered_handles->set()
A:torch.autograd.profiler.record_key->get_record_key(record)
A:torch.autograd.profiler.is_remote_event->record.is_remote()
A:torch.autograd.profiler.fe->FunctionEvent(id=record.handle(), node_id=record.node_id(), name=string_table[start.name()], thread=start.thread_id(), cpu_start=start_record.cpu_elapsed_us(start), cpu_end=start_record.cpu_elapsed_us(record), fwd_thread=start.fwd_thread_id(), input_shapes=start.shapes(), stack=[entry for entry in start.stack() if filter_stack_entry(entry)], scope=start.scope(), cpu_memory_usage=cpu_memory_usage, cuda_memory_usage=cuda_memory_usage, is_async=is_async, is_remote=is_remote_event, sequence_nr=start.sequence_nr())
A:torch.autograd.profiler.cuda_start->adjusted_time(start, cuda_records)
A:torch.autograd.profiler.cuda_end->adjusted_time(record, cuda_records)
A:torch.autograd.profiler.self.seen->set()
A:torch.autograd.profiler.conn->sqlite3.connect(path)
A:torch.autograd.profiler.strings[r['id']]->torch._C._demangle(r['value'])
A:torch.autograd.profiler.unique->EnforceUnique()
A:torch.autograd.profiler.evt->FunctionEvent(id=row['marker_id'], node_id=0, name=strings[row['name']], cpu_start=row['start_time'], cpu_end=row['end_time'], thread=0)
A:torch.autograd.profiler.has_input_shapes->any([event.input_shapes is not None and len(event.input_shapes) > 0 for event in events])
A:torch.autograd.profiler.shapes_column_width->min(shapes_column_width, 45)
A:torch.autograd.profiler.src_column_width->min(src_column_width, 75)
A:torch.autograd.profiler.append_node_id->any([evt.node_id != -1 for evt in events])
A:torch.autograd.profiler.self_cpu_time_total->sum([event.self_cpu_time_total for event in events])
A:torch.autograd.profiler.cuda_time_total->sum([evt.self_cuda_time_total for evt in events])
torch.autograd.profiler.EnforceUnique(self)
torch.autograd.profiler.EnforceUnique.__init__(self)
torch.autograd.profiler.EnforceUnique.see(self,*key)
torch.autograd.profiler.EventList(self,*args,**kwargs)
torch.autograd.profiler.EventList.__init__(self,*args,**kwargs)
torch.autograd.profiler.EventList.__str__(self)
torch.autograd.profiler.EventList.cpu_children_populated(self)
torch.autograd.profiler.EventList.export_chrome_trace(self,path)
torch.autograd.profiler.EventList.key_averages(self,group_by_input_shapes=False,group_by_stack_n=0)
torch.autograd.profiler.EventList.populate_cpu_children(self)
torch.autograd.profiler.EventList.self_cpu_time_total(self)
torch.autograd.profiler.EventList.set_backward_stacktraces(self)
torch.autograd.profiler.EventList.table(self,sort_by=None,row_limit=100,header=None,top_level_events_only=False)
torch.autograd.profiler.EventList.total_average(self)
torch.autograd.profiler.FormattedTimesMixin(object)
torch.autograd.profiler.FormattedTimesMixin.cpu_time(self)
torch.autograd.profiler.FormattedTimesMixin.cuda_time(self)
torch.autograd.profiler.FunctionEvent(self,id,node_id,name,thread,cpu_start,cpu_end,fwd_thread=None,input_shapes=None,stack=None,scope=0,cpu_memory_usage=0,cuda_memory_usage=0,is_async=False,is_remote=True,sequence_nr=-1)
torch.autograd.profiler.FunctionEvent.__init__(self,id,node_id,name,thread,cpu_start,cpu_end,fwd_thread=None,input_shapes=None,stack=None,scope=0,cpu_memory_usage=0,cuda_memory_usage=0,is_async=False,is_remote=True,sequence_nr=-1)
torch.autograd.profiler.FunctionEvent.__repr__(self)
torch.autograd.profiler.FunctionEvent.append_cpu_child(self,child)
torch.autograd.profiler.FunctionEvent.append_kernel(self,name,device,start,end)
torch.autograd.profiler.FunctionEvent.cpu_time_total(self)
torch.autograd.profiler.FunctionEvent.cuda_time_total(self)
torch.autograd.profiler.FunctionEvent.key(self)
torch.autograd.profiler.FunctionEvent.self_cpu_memory_usage(self)
torch.autograd.profiler.FunctionEvent.self_cpu_time_total(self)
torch.autograd.profiler.FunctionEvent.self_cuda_memory_usage(self)
torch.autograd.profiler.FunctionEvent.self_cuda_time_total(self)
torch.autograd.profiler.FunctionEvent.set_cpu_parent(self,parent)
torch.autograd.profiler.FunctionEventAvg(self)
torch.autograd.profiler.FunctionEventAvg.__iadd__(self,other)
torch.autograd.profiler.FunctionEventAvg.__init__(self)
torch.autograd.profiler.FunctionEventAvg.__repr__(self)
torch.autograd.profiler.FunctionEventAvg.add(self,other)
torch.autograd.profiler.Interval(self,start,end)
torch.autograd.profiler.Interval.__init__(self,start,end)
torch.autograd.profiler.Interval.elapsed_us(self)
torch.autograd.profiler.StringTable(defaultdict)
torch.autograd.profiler.StringTable.__missing__(self,key)
torch.autograd.profiler.attr_formatter(name)
torch.autograd.profiler.build_table(events,sort_by=None,header=None,row_limit=100,use_cuda=True,profile_memory=False,top_level_events_only=False)
torch.autograd.profiler.emit_nvtx(self,enabled=True,record_shapes=False)
torch.autograd.profiler.emit_nvtx.__enter__(self)
torch.autograd.profiler.emit_nvtx.__exit__(self,exc_type,exc_val,exc_tb)
torch.autograd.profiler.emit_nvtx.__init__(self,enabled=True,record_shapes=False)
torch.autograd.profiler.format_memory(nbytes)
torch.autograd.profiler.format_time(time_us)
torch.autograd.profiler.format_time_share(time_us,total_time_us)
torch.autograd.profiler.load_nvprof(path)
torch.autograd.profiler.parse_event_records(thread_records)
torch.autograd.profiler.parse_nvprof_trace(path)
torch.autograd.profiler.profile(self,enabled=True,use_cuda=False,record_shapes=False,profile_memory=False,with_stack=False)
torch.autograd.profiler.profile.__enter__(self)
torch.autograd.profiler.profile.__exit__(self,exc_type,exc_val,exc_tb)
torch.autograd.profiler.profile.__init__(self,enabled=True,use_cuda=False,record_shapes=False,profile_memory=False,with_stack=False)
torch.autograd.profiler.profile.__repr__(self)
torch.autograd.profiler.profile.__str__(self)
torch.autograd.profiler.profile._check_finish(self)
torch.autograd.profiler.profile.export_chrome_trace(self,path)
torch.autograd.profiler.profile.key_averages(self,group_by_input_shape=False,group_by_stack_n=0)
torch.autograd.profiler.profile.self_cpu_time_total(self)
torch.autograd.profiler.profile.table(self,sort_by=None,row_limit=100,header=None,top_level_events_only=False)
torch.autograd.profiler.profile.total_average(self)
torch.autograd.profiler.record_function(self,name:str)
torch.autograd.profiler.record_function.__enter__(self)
torch.autograd.profiler.record_function.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)
torch.autograd.profiler.record_function.__init__(self,name:str)
torch.autograd.profiler.record_function._call_end_callbacks_on_future(self,fut:Future[Any])->Future[Any]


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/variable.py----------------------------------------
A:torch.autograd.variable.Variable._execution_engine->ImperativeEngine()
torch.autograd.Variable(with_metaclass(VariableMeta,torch._C._LegacyVariableBase))
torch.autograd.VariableMeta(type)
torch.autograd.VariableMeta.__instancecheck__(cls,other)
torch.autograd.variable.Variable(with_metaclass(VariableMeta,torch._C._LegacyVariableBase))
torch.autograd.variable.VariableMeta(type)
torch.autograd.variable.VariableMeta.__instancecheck__(cls,other)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/grad_mode.py----------------------------------------
A:torch.autograd.grad_mode.F->TypeVar('F', bound=FuncType)
A:torch.autograd.grad_mode.gen->func(*args, **kwargs)
A:torch.autograd.grad_mode.x->next(gen)
A:torch.autograd.grad_mode.self.prev->torch.is_grad_enabled()
torch.autograd.grad_mode._DecoratorContextManager(self,func:F)
torch.autograd.grad_mode._DecoratorContextManager.__call__(self,func:F)
torch.autograd.grad_mode._DecoratorContextManager.__enter__(self)->None
torch.autograd.grad_mode._DecoratorContextManager.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None
torch.autograd.grad_mode._DecoratorContextManager._wrap_generator(self,func)
torch.autograd.grad_mode.enable_grad(_DecoratorContextManager)
torch.autograd.grad_mode.enable_grad.__enter__(self)->None
torch.autograd.grad_mode.enable_grad.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None
torch.autograd.grad_mode.no_grad(self)
torch.autograd.grad_mode.no_grad.__enter__(self)
torch.autograd.grad_mode.no_grad.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None
torch.autograd.grad_mode.no_grad.__init__(self)
torch.autograd.grad_mode.set_grad_enabled(self,mode:bool)
torch.autograd.grad_mode.set_grad_enabled.__enter__(self)->None
torch.autograd.grad_mode.set_grad_enabled.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None
torch.autograd.grad_mode.set_grad_enabled.__init__(self,mode:bool)
torch.enable_grad(_DecoratorContextManager)
torch.enable_grad.__enter__(self)->None
torch.enable_grad.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None
torch.no_grad(self)
torch.no_grad.__enter__(self)
torch.no_grad.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None
torch.set_grad_enabled(self,mode:bool)
torch.set_grad_enabled.__enter__(self)->None
torch.set_grad_enabled.__exit__(self,exc_type:Any,exc_value:Any,traceback:Any)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/functional.py----------------------------------------
A:torch.autograd.functional.res->jacobian(jac_func, inputs, create_graph=create_graph, strict=strict)
A:torch.autograd.functional.prepend->'Entry {} in '.format(idx)
A:torch.autograd.functional.grads_i->torch.zeros_like(refs[i])
A:torch.autograd.functional.(is_inputs_tuple, inputs)->_as_tuple(inputs, 'inputs', 'hvp')
A:torch.autograd.functional.inputs->_grad_preprocess(inputs, create_graph=create_graph, need_graph=True)
A:torch.autograd.functional.outputs->_grad_postprocess(outputs, create_graph)
A:torch.autograd.functional.(is_outputs_tuple, outputs)->_as_tuple(outputs, 'outputs of the user-provided function', 'hvp')
A:torch.autograd.functional.(_, v)->_as_tuple(v, 'v', 'hvp')
A:torch.autograd.functional.v->_grad_preprocess(v, create_graph=create_graph, need_graph=False)
A:torch.autograd.functional.grad_res->_autograd_grad(double_back, grad_jac, v, create_graph=create_graph)
A:torch.autograd.functional.vjp->_grad_postprocess(vjp, create_graph)
A:torch.autograd.functional.grad_outputs->tuple((torch.zeros_like(out, requires_grad=True) for out in outputs))
A:torch.autograd.functional.grad_inputs->_autograd_grad(outputs, inputs, grad_outputs, create_graph=True)
A:torch.autograd.functional.jvp->_grad_postprocess(jvp, create_graph)
A:torch.autograd.functional.vj->_autograd_grad((out.reshape(-1)[j],), inputs, retain_graph=True, create_graph=create_graph)
A:torch.autograd.functional.msg->'Output {} of the user-provided function is independent of input {}. This is not allowed in strict mode.'.format(i, el_idx)
A:torch.autograd.functional.jacobian->_grad_postprocess(jacobian, create_graph)
A:torch.autograd.functional.out->func(*inp)
A:torch.autograd.functional.(is_out_tuple, t_out)->_as_tuple(out, 'outputs of the user-provided function', 'hessian')
A:torch.autograd.functional.jac->_autograd_grad(outputs, inputs, create_graph=True)
A:torch.autograd.functional.vhp->_grad_postprocess(vhp, create_graph)
A:torch.autograd.functional.grad_jac->tuple((torch.zeros_like(inp, requires_grad=True) for inp in inputs))
A:torch.autograd.functional.double_back->_autograd_grad(jac, inputs, grad_jac, create_graph=True)
A:torch.autograd.functional.hvp->_grad_postprocess(hvp, create_graph)
torch.autograd._as_tuple(inp,arg_name,fn_name)
torch.autograd._autograd_grad(outputs,inputs,grad_outputs=None,create_graph=False,retain_graph=None)
torch.autograd._check_requires_grad(inputs,input_type,strict)
torch.autograd._fill_in_zeros(grads,refs,strict,create_graph,stage)
torch.autograd._grad_postprocess(inputs,create_graph)
torch.autograd._grad_preprocess(inputs,create_graph,need_graph)
torch.autograd._tuple_postprocess(res,to_unpack)
torch.autograd._validate_v(v,other,is_other_tuple)
torch.autograd.functional._as_tuple(inp,arg_name,fn_name)
torch.autograd.functional._autograd_grad(outputs,inputs,grad_outputs=None,create_graph=False,retain_graph=None)
torch.autograd.functional._check_requires_grad(inputs,input_type,strict)
torch.autograd.functional._fill_in_zeros(grads,refs,strict,create_graph,stage)
torch.autograd.functional._grad_postprocess(inputs,create_graph)
torch.autograd.functional._grad_preprocess(inputs,create_graph,need_graph)
torch.autograd.functional._tuple_postprocess(res,to_unpack)
torch.autograd.functional._validate_v(v,other,is_other_tuple)
torch.autograd.functional.hessian(func,inputs,create_graph=False,strict=False)
torch.autograd.functional.hvp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.functional.jacobian(func,inputs,create_graph=False,strict=False)
torch.autograd.functional.jvp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.functional.vhp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.functional.vjp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.hessian(func,inputs,create_graph=False,strict=False)
torch.autograd.hvp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.jacobian(func,inputs,create_graph=False,strict=False)
torch.autograd.jvp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.vhp(func,inputs,v=None,create_graph=False,strict=False)
torch.autograd.vjp(func,inputs,v=None,create_graph=False,strict=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/function.py----------------------------------------
A:torch.autograd.function.backward_hooks->OrderedDict()
A:torch.autograd.function.handle->torch.utils.hooks.RemovableHandle(backward_hooks)
A:torch.autograd.function.forward->super_cls.__dict__.get('forward')
A:torch.autograd.function.backward_fn->type(name + 'Backward', (BackwardCFunction,), {'_forward_cls': cls})
A:torch.autograd.function.outputs->fn(ctx, *args)
A:torch.autograd.function.requires_grad->any((isinstance(arg, torch.Tensor) and arg.requires_grad for arg in args))
A:torch.autograd.function.err_fn->torch._C._functions.DelayedError(b'trying to differentiate twice a function that was markedwith @once_differentiable', len(outputs))
A:torch.autograd.function.var->var.detach().detach()
A:torch.autograd.function.obj->conversion(obj)
A:torch.autograd.function.(res_e, input)->unflatten_helper(input, e)
A:torch.autograd.function._iter_jit_values->_iter_filter(lambda o: o is None or isinstance(o, torch._C.Value), condition_msg="jit's Values or None")
A:torch.autograd.function._iter_tensors->_iter_filter(lambda x: isinstance(x, torch.Tensor), condition_msg='Tensors', conversion=_jit_unwrap_structured)
A:torch.autograd.function._iter_tensors_permissive->_iter_filter(lambda x: isinstance(x, torch.Tensor), allow_unknown=True, condition_msg='Tensors (permissive)')
A:torch.autograd.function._iter_None_tensors->_iter_filter(lambda o: o is None or isinstance(o, torch.Tensor), condition_msg='Tensors or None')
A:torch.autograd.function._map_tensor_data->_nested_map(lambda x: isinstance(x, torch.Tensor), lambda o: o.data, condition_msg='Tensors')
A:torch.autograd.function.flat_input->tuple(_iter_tensors(input))
A:torch.autograd.function.flat_output->super(NestedIOFunction, self)._do_forward(*flat_input)
A:torch.autograd.function.nested_tensors->_map_tensor_data(self._nested_input)
A:torch.autograd.function.result->self.forward_extended(*nested_tensors)
A:torch.autograd.function.nested_gradients->_unflatten(gradients, self._nested_output)
A:torch.autograd.function.self.to_save->tuple(_iter_tensors(args))
A:torch.autograd.function.self.dirty_tensors->tuple(_iter_tensors((args, kwargs)))
A:torch.autograd.function.self.non_differentiable->tuple(_iter_tensors((args, kwargs)))
torch.autograd.Function(self,*args,**kwargs)
torch.autograd.Function.backward(ctx:Any,*grad_outputs:Any)->Any
torch.autograd.Function.forward(ctx:Any,*args:Any,**kwargs:Any)->Any
torch.autograd.FunctionMeta(cls,name,bases,attrs)
torch.autograd.NestedIOFunction(Function)
torch.autograd.NestedIOFunction._do_backward(self,gradients,retain_variables)
torch.autograd.NestedIOFunction._do_forward(self,*input)
torch.autograd.NestedIOFunction.backward(self,*gradients:Any)->Any
torch.autograd.NestedIOFunction.backward_extended(self,*grad_output:Any)->None
torch.autograd.NestedIOFunction.forward(self,*args:Any)->Any
torch.autograd.NestedIOFunction.forward_extended(self,*input:Any)->None
torch.autograd.NestedIOFunction.mark_dirty(self,*args:Any,**kwargs:Any)->None
torch.autograd.NestedIOFunction.mark_non_differentiable(self,*args:Any,**kwargs:Any)->None
torch.autograd.NestedIOFunction.save_for_backward(self,*args:Any)->None
torch.autograd.NestedIOFunction.saved_tensors(self)
torch.autograd.function.BackwardCFunction(_C._FunctionBase,_ContextMethodMixin,_HookMixin)
torch.autograd.function.BackwardCFunction.apply(self,*args)
torch.autograd.function.Function(self,*args,**kwargs)
torch.autograd.function.Function.__call__(self,*args,**kwargs)
torch.autograd.function.Function.backward(ctx:Any,*grad_outputs:Any)->Any
torch.autograd.function.Function.forward(ctx:Any,*args:Any,**kwargs:Any)->Any
torch.autograd.function.FunctionMeta(cls,name,bases,attrs)
torch.autograd.function.FunctionMeta.__init__(cls,name,bases,attrs)
torch.autograd.function.InplaceFunction(self,inplace=False)
torch.autograd.function.InplaceFunction.__init__(self,inplace=False)
torch.autograd.function.NestedIOFunction(Function)
torch.autograd.function.NestedIOFunction._do_backward(self,gradients,retain_variables)
torch.autograd.function.NestedIOFunction._do_forward(self,*input)
torch.autograd.function.NestedIOFunction.backward(self,*gradients:Any)->Any
torch.autograd.function.NestedIOFunction.backward_extended(self,*grad_output:Any)->None
torch.autograd.function.NestedIOFunction.forward(self,*args:Any)->Any
torch.autograd.function.NestedIOFunction.forward_extended(self,*input:Any)->None
torch.autograd.function.NestedIOFunction.mark_dirty(self,*args:Any,**kwargs:Any)->None
torch.autograd.function.NestedIOFunction.mark_non_differentiable(self,*args:Any,**kwargs:Any)->None
torch.autograd.function.NestedIOFunction.save_for_backward(self,*args:Any)->None
torch.autograd.function.NestedIOFunction.saved_tensors(self)
torch.autograd.function._ContextMethodMixin(object)
torch.autograd.function._ContextMethodMixin.mark_dirty(self,*args)
torch.autograd.function._ContextMethodMixin.mark_non_differentiable(self,*args)
torch.autograd.function._ContextMethodMixin.mark_shared_storage(self,*pairs)
torch.autograd.function._ContextMethodMixin.save_for_backward(self,*tensors)
torch.autograd.function._ContextMethodMixin.set_materialize_grads(self,value)
torch.autograd.function._HookMixin(object)
torch.autograd.function._HookMixin._register_hook(backward_hooks,hook)
torch.autograd.function._iter_filter(condition,allow_unknown=False,condition_msg=None,conversion=None)
torch.autograd.function._jit_unwrap_structured(obj)
torch.autograd.function._nested_map(condition,fn,condition_msg=None)
torch.autograd.function._unflatten(input,proto)
torch.autograd.function.once_differentiable(fn)
torch.autograd.function.traceable(fn_cls)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/__init__.py----------------------------------------
A:torch.autograd.__init__.grad_tensors_->_make_grads(tensors, grad_tensors_)
A:torch.autograd.__init__.grad_outputs_->_make_grads(outputs, grad_outputs_)
torch.autograd.__init__._is_checkpoint_valid()
torch.autograd.__init__._make_grads(outputs:Sequence[torch.Tensor],grads:Sequence[_OptionalTensor])->Tuple[_OptionalTensor, ...]
torch.autograd.__init__._tensor_or_tensors_to_tuple(tensors:Optional[_TensorOrTensors],length:int)->Tuple[_OptionalTensor, ...]
torch.autograd.__init__.backward(tensors:_TensorOrTensors,grad_tensors:Optional[_TensorOrTensors]=None,retain_graph:Optional[bool]=None,create_graph:bool=False,grad_variables:Optional[_TensorOrTensors]=None)->None
torch.autograd.__init__.grad(outputs:_TensorOrTensors,inputs:_TensorOrTensors,grad_outputs:Optional[_TensorOrTensors]=None,retain_graph:Optional[bool]=None,create_graph:bool=False,only_inputs:bool=True,allow_unused:bool=False)->Tuple[torch.Tensor, ...]
torch.autograd.__init__.variable(*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/gradcheck.py----------------------------------------
A:torch.autograd.gradcheck.jacobians->list(filter(lambda x: x is not None, (make_jacobian(elem, num_out) for elem in input)))
A:torch.autograd.gradcheck.output_size->fn(input).numel()
A:torch.autograd.gradcheck.jacobian->make_jacobian(input, output.numel())
A:torch.autograd.gradcheck.x_tensors->iter_tensors(target, True)
A:torch.autograd.gradcheck.j_tensors->iter_tensors(jacobian)
A:torch.autograd.gradcheck.orig->x[idx].item()
A:torch.autograd.gradcheck.outa->fn_out()
A:torch.autograd.gradcheck.outb->fn_out()
A:torch.autograd.gradcheck.ds_dx->compute_gradient(eps)
A:torch.autograd.gradcheck.ds_dy->compute_gradient(eps * 1j)
A:torch.autograd.gradcheck.d[d_idx]->torch.real(dL_dz_conj)
A:torch.autograd.gradcheck.dim->len(size)
A:torch.autograd.gradcheck.x_nnz->x_tensor._nnz()
A:torch.autograd.gradcheck.x_size->list(x_tensor.size())
A:torch.autograd.gradcheck.x_indices->x_tensor._indices().t()
A:torch.autograd.gradcheck.x_values->x_tensor._values()
A:torch.autograd.gradcheck.x_stride->get_stride(x_size)
A:torch.autograd.gradcheck.d_idx->sum((indices[k] * x_stride[k] for k in range(len(x_size))))
A:torch.autograd.gradcheck.x_tensor_dense->x_tensor.to_dense()
A:torch.autograd.gradcheck.diff_input_list->list(iter_tensors(input, True))
A:torch.autograd.gradcheck.jacobian_reentrant->make_jacobian(input, output.numel())
A:torch.autograd.gradcheck.grad_output->torch.zeros_like(output, memory_format=torch.legacy_contiguous_format)
A:torch.autograd.gradcheck.flat_grad_output->torch.zeros_like(output, memory_format=torch.legacy_contiguous_format).view(-1)
A:torch.autograd.gradcheck.grads_input->torch.autograd.grad(output_to_check, diff_input_list, grads_output, allow_unused=True)
A:torch.autograd.gradcheck.jacobian_x[:, i]->d_x_dense.contiguous().view(-1)
A:torch.autograd.gradcheck.tupled_inputs->_as_tuple(inputs)
A:torch.autograd.gradcheck.func_out->func(*tupled_inputs)
A:torch.autograd.gradcheck.output->_differentiable_outputs(func(*tupled_inputs))
A:torch.autograd.gradcheck.numerical->get_numerical_jacobian(fn, tupled_inputs, eps=eps)
A:torch.autograd.gradcheck.(analytical, reentrant, correct_grad_sizes, correct_grad_types)->get_analytical_jacobian(tupled_inputs, o, nondet_tol=nondet_tol)
A:torch.autograd.gradcheck.out_is_complex->o.is_complex()
A:torch.autograd.gradcheck.(analytical_with_imag_grad_out, reentrant_with_imag_grad_out, correct_grad_sizes_with_imag_grad_out, correct_grad_types_with_imag_grad_out)->get_analytical_jacobian(tupled_inputs, o, nondet_tol=nondet_tol, grad_out=1j)
A:torch.autograd.gradcheck.numerical_with_imag_grad_out->get_numerical_jacobian(fn, tupled_inputs, eps=eps, grad_out=1j)
A:torch.autograd.gradcheck.inp_tensors->iter_tensors(tupled_inputs, True)
A:torch.autograd.gradcheck.gi->gi.to_dense().to_dense()
A:torch.autograd.gradcheck.di->di.to_dense().to_dense()
A:torch.autograd.gradcheck.output_to_check->_differentiable_outputs(func(*tupled_inputs))
A:torch.autograd.gradcheck.y->torch.testing.make_non_contiguous(y)
A:torch.autograd.gradcheck.outputs->_differentiable_outputs(func(*input_args))
A:torch.autograd.gradcheck.tupled_grad_outputs->_as_tuple(grad_outputs)
A:torch.autograd.gradcheck.num_outputs->len(tupled_grad_outputs)
A:torch.autograd.gradcheck.input_args->tuple((x for x in input_args if isinstance(x, torch.Tensor) and x.requires_grad))
A:torch.autograd.gradcheck.grad_inputs->torch.autograd.grad(outputs, input_args, grad_outputs, create_graph=True)
torch.autograd.gradcheck(func:Callable[...,Union[_TensorOrTensors]],inputs:_TensorOrTensors,eps:float=1e-06,atol:float=1e-05,rtol:float=0.001,raise_exception:bool=True,check_sparse_nnz:bool=False,nondet_tol:float=0.0,check_undefined_grad:bool=True,check_grad_dtypes:bool=False)->bool
torch.autograd.gradcheck._as_tuple(x)
torch.autograd.gradcheck._differentiable_outputs(x)
torch.autograd.gradcheck.get_analytical_jacobian(input,output,nondet_tol=0.0,grad_out=1.0)
torch.autograd.gradcheck.get_numerical_jacobian(fn,input,target=None,eps=0.001,grad_out=1.0)
torch.autograd.gradcheck.gradcheck(func:Callable[...,Union[_TensorOrTensors]],inputs:_TensorOrTensors,eps:float=1e-06,atol:float=1e-05,rtol:float=0.001,raise_exception:bool=True,check_sparse_nnz:bool=False,nondet_tol:float=0.0,check_undefined_grad:bool=True,check_grad_dtypes:bool=False)->bool
torch.autograd.gradcheck.gradgradcheck(func:Callable[...,_TensorOrTensors],inputs:_TensorOrTensors,grad_outputs:Optional[_TensorOrTensors]=None,eps:float=1e-06,atol:float=1e-05,rtol:float=0.001,gen_non_contig_grad_outputs:bool=False,raise_exception:bool=True,nondet_tol:float=0.0,check_undefined_grad:bool=True,check_grad_dtypes:bool=False)->bool
torch.autograd.gradcheck.iter_tensors(x:Union[torch.Tensor,Iterable[torch.Tensor]],only_requiring_grad:bool=False)->Iterable[torch.Tensor]
torch.autograd.gradcheck.make_jacobian(input,num_out)
torch.autograd.gradcheck.zero_gradients(x)
torch.autograd.gradgradcheck(func:Callable[...,_TensorOrTensors],inputs:_TensorOrTensors,grad_outputs:Optional[_TensorOrTensors]=None,eps:float=1e-06,atol:float=1e-05,rtol:float=0.001,gen_non_contig_grad_outputs:bool=False,raise_exception:bool=True,nondet_tol:float=0.0,check_undefined_grad:bool=True,check_grad_dtypes:bool=False)->bool


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/_functions/utils.py----------------------------------------
A:torch.autograd._functions.utils.tensor->tensor.sum(dim, keepdim=True).sum(dim, keepdim=True)
A:torch.autograd._functions.utils.len1->len(dims1)
A:torch.autograd._functions.utils.len2->len(dims2)
A:torch.autograd._functions.utils.numel1->reduce(lambda x, y: x * y, dims1)
A:torch.autograd._functions.utils.numel2->reduce(lambda x, y: x * y, dims2)
torch.autograd._functions.utils.check_onnx_broadcast(dims1,dims2)
torch.autograd._functions.utils.maybe_unexpand(tensor,old_size,check_same_size=True)
torch.autograd._functions.utils.maybe_view(tensor,size,check_same_size=True)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/_functions/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/autograd/_functions/tensor.py----------------------------------------
A:torch.autograd._functions.tensor.ctx.input_type->type(i)
A:torch.autograd._functions.tensor.ctx.numel->reduce(lambda x, y: x * y, sizes, 1)
A:torch.autograd._functions.tensor.ctx.input_sizes->tensor.size()
A:torch.autograd._functions.tensor.result->tensor.new(tensor).contiguous().view(*sizes)
torch.autograd._functions.Resize(Function)
torch.autograd._functions.Resize.backward(ctx,grad_output)
torch.autograd._functions.Resize.forward(ctx,tensor,sizes)
torch.autograd._functions.Type(Function)
torch.autograd._functions.Type.backward(ctx,grad_output)
torch.autograd._functions.Type.forward(ctx,i,dest_type)
torch.autograd._functions.tensor.Resize(Function)
torch.autograd._functions.tensor.Resize.backward(ctx,grad_output)
torch.autograd._functions.tensor.Resize.forward(ctx,tensor,sizes)
torch.autograd._functions.tensor.Type(Function)
torch.autograd._functions.tensor.Type.backward(ctx,grad_output)
torch.autograd._functions.tensor.Type.forward(ctx,i,dest_type)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/__init__.py----------------------------------------
A:torch.testing.__init__.flat_index->int(flat_index // size)
A:torch.testing.__init__.a_flat->complex(a).to(torch.float64).flatten()
A:torch.testing.__init__.b_flat->complex(b).to(torch.float64).flatten()
A:torch.testing.__init__.count_non_identical->torch.sum(identity_mask, dtype=torch.long)
A:torch.testing.__init__.diff->abs(a - b)
A:torch.testing.__init__.greatest_diff_index->torch.argmax(diff)
A:torch.testing.__init__.debug_msg->'With rtol={0} and atol={1}, found {2} element(s) (out of {3}) whose difference(s) exceeded the margin of error (including {4} nan comparisons). The greatest difference was {5} ({6} vs. {7}), which occurred at index {8}.'.format(rtol, atol, count_outside_range + num_nans, a.numel(), num_nans, diff[greatest_diff_index], a_flat[greatest_diff_index], b_flat[greatest_diff_index], _unravel_index(greatest_diff_index, a.shape))
A:torch.testing.__init__.(real_result, debug_msg)->_compare_tensors_internal(a_real, b_real, rtol=rtol, atol=atol, equal_nan=equal_nan)
A:torch.testing.__init__.(imag_result, debug_msg)->_compare_tensors_internal(a_imag, b_imag, rtol=rtol, atol=atol, equal_nan=equal_nan)
A:torch.testing.__init__.close->torch.isclose(a_flat, b_flat, rtol, atol, equal_nan)
A:torch.testing.__init__.nans->torch.isnan(diff)
A:torch.testing.__init__.num_nans->torch.isnan(diff).sum()
A:torch.testing.__init__.count_outside_range->torch.sum(outside_range, dtype=torch.long)
A:torch.testing.__init__.msg->('Comparing' + s + '{0} and {1} gives a difference of {2}, but the allowed difference with rtol={3} and atol={4} is only {5}!').format(a, b, diff, rtol, atol, allowed_diff)
A:torch.testing.__init__.a->complex(a)
A:torch.testing.__init__.b->complex(b)
A:torch.testing.__init__.(result, msg)->_helper(a.real, b.real, ' the real part ')
A:torch.testing.__init__.actual->torch.tensor(actual)
A:torch.testing.__init__.expected->expected.expand_as(actual).expand_as(actual)
A:torch.testing.__init__.(rtol, atol)->_get_default_tolerance(actual, expected)
A:torch.testing.__init__.(result, debug_msg)->_compare_tensors_internal(actual, expected, rtol=rtol, atol=atol, equal_nan=equal_nan)
A:torch.testing.__init__.osize->list(tensor.size())
A:torch.testing.__init__.dim->random.randint(0, len(osize) - 1)
A:torch.testing.__init__.add->random.randint(4, 15)
A:torch.testing.__init__.input->input.narrow(i, bounds, tensor.size(i)).narrow(i, bounds, tensor.size(i))
A:torch.testing.__init__.bounds->random.randint(1, input.size(i) - tensor.size(i))
A:torch.testing.__init__._floating_types->_dispatch_dtypes((torch.float32, torch.float64))
A:torch.testing.__init__._integral_types->_dispatch_dtypes((torch.uint8, torch.int8, torch.int16, torch.int32, torch.int64))
A:torch.testing.__init__.a_tol->_get_default_tolerance(a)
A:torch.testing.__init__.b_tol->_get_default_tolerance(b)
torch.testing.__init__._compare_scalars_internal(a,b,*,rtol:float,atol:float,equal_nan:bool)->_compare_return_type
torch.testing.__init__._compare_tensors_internal(a:torch.Tensor,b:torch.Tensor,*,rtol,atol,equal_nan:bool)->_compare_return_type
torch.testing.__init__._dispatch_dtypes(tuple)
torch.testing.__init__._dispatch_dtypes.__add__(self,other)
torch.testing.__init__._get_default_tolerance(a,b=None)->Tuple[float, float]
torch.testing.__init__._unravel_index(flat_index,shape)
torch.testing.__init__._validate_dtypes(*dtypes)
torch.testing.__init__.all_types()
torch.testing.__init__.all_types_and(*dtypes)
torch.testing.__init__.all_types_and_complex()
torch.testing.__init__.all_types_and_complex_and(*dtypes)
torch.testing.__init__.all_types_and_half()
torch.testing.__init__.assert_allclose(actual,expected,rtol=None,atol=None,equal_nan=True,msg='')->None
torch.testing.__init__.complex_types()
torch.testing.__init__.floating_and_complex_types()
torch.testing.__init__.floating_and_complex_types_and(*dtypes)
torch.testing.__init__.floating_types()
torch.testing.__init__.floating_types_and(*dtypes)
torch.testing.__init__.floating_types_and_half()
torch.testing.__init__.get_all_complex_dtypes(include_complex32=False)->List[torch.dtype]
torch.testing.__init__.get_all_device_types()->List[str]
torch.testing.__init__.get_all_dtypes(include_half=True,include_bfloat16=True,include_bool=True,include_complex=True,include_complex32=False)->List[torch.dtype]
torch.testing.__init__.get_all_fp_dtypes(include_half=True,include_bfloat16=True)->List[torch.dtype]
torch.testing.__init__.get_all_int_dtypes()->List[torch.dtype]
torch.testing.__init__.get_all_math_dtypes(device)->List[torch.dtype]
torch.testing.__init__.integral_types()
torch.testing.__init__.integral_types_and(*dtypes)
torch.testing.__init__.is_integral(dtype:torch.dtype)->bool
torch.testing.__init__.make_non_contiguous(tensor:torch.Tensor)->torch.Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_distributed.py----------------------------------------
A:torch.testing._internal.common_distributed.message->'Need at least {} CUDA devices'.format(x)
A:torch.testing._internal.common_distributed.TEST_SKIPS['multi-gpu']->TestSkip(75, message)
A:torch.testing._internal.common_distributed.indices->torch.cat((indices, torch.zeros(1, rank + 1)))
A:torch.testing._internal.common_distributed.values->torch.ones([rank + 1] + [2 for _ in range(dense_dims)])
A:torch.testing._internal.common_distributed.tmp_dir->tempfile.TemporaryDirectory()
A:torch.testing._internal.common_distributed.init_dir_path->os.path.join(tmp_dir.name, 'init_dir')
A:torch.testing._internal.common_distributed.fn->getattr(self, method_name)
A:torch.testing._internal.common_distributed.self.old_test_skips->TEST_SKIPS.copy()
A:torch.testing._internal.common_distributed.test_skips_manager->Manager()
A:torch.testing._internal.common_distributed.test_skips->Manager().dict()
A:torch.testing._internal.common_distributed.process->proc(target=self.__class__._run, name='process ' + str(rank), args=(rank, self._current_test_name(), self.file_name))
A:torch.testing._internal.common_distributed.self->cls(test_name)
A:torch.testing._internal.common_distributed.timeout->get_timeout(self.id())
A:torch.testing._internal.common_distributed.start_time->time.time()
A:torch.testing._internal.common_distributed.active_children->torch.multiprocessing.active_children()
A:torch.testing._internal.common_distributed.error->'Processes {} exited with error code {}'.format(' '.join([str(i) for (i, _) in errored_processes]), MultiProcessTestCase.TEST_ERROR_EXIT_CODE)
torch.testing._internal.common_distributed.MultiProcessTestCase(self,method_name='runTest')
torch.testing._internal.common_distributed.MultiProcessTestCase.__init__(self,method_name='runTest')
torch.testing._internal.common_distributed.MultiProcessTestCase._check_no_test_errors(self,elapsed_time)
torch.testing._internal.common_distributed.MultiProcessTestCase._check_return_codes(self,elapsed_time)
torch.testing._internal.common_distributed.MultiProcessTestCase._current_test_name(self)
torch.testing._internal.common_distributed.MultiProcessTestCase._fork_processes(self)
torch.testing._internal.common_distributed.MultiProcessTestCase._join_processes(self,fn)
torch.testing._internal.common_distributed.MultiProcessTestCase._run(cls,rank,test_name,file_name)
torch.testing._internal.common_distributed.MultiProcessTestCase._spawn_processes(self)
torch.testing._internal.common_distributed.MultiProcessTestCase._start_processes(self,proc)
torch.testing._internal.common_distributed.MultiProcessTestCase.is_master(self)
torch.testing._internal.common_distributed.MultiProcessTestCase.join_or_run(self,fn)
torch.testing._internal.common_distributed.MultiProcessTestCase.setUp(self)
torch.testing._internal.common_distributed.MultiProcessTestCase.tearDown(self)
torch.testing._internal.common_distributed.MultiProcessTestCase.world_size(self)
torch.testing._internal.common_distributed.TestSkip(NamedTuple)
torch.testing._internal.common_distributed.cleanup_temp_dir()
torch.testing._internal.common_distributed.create_device(interface=None)
torch.testing._internal.common_distributed.get_timeout(test_id)
torch.testing._internal.common_distributed.initialize_temp_directories(init_method=None)
torch.testing._internal.common_distributed.require_n_gpus_for_nccl_backend(n,backend)
torch.testing._internal.common_distributed.requires_gloo()
torch.testing._internal.common_distributed.requires_mpi()
torch.testing._internal.common_distributed.requires_nccl()
torch.testing._internal.common_distributed.requires_nccl_version(version,msg)
torch.testing._internal.common_distributed.simple_sparse_reduce_tests(rank,world_size,num_inputs=1)
torch.testing._internal.common_distributed.skip_if_lt_x_gpu(x)
torch.testing._internal.common_distributed.skip_if_no_gpu(func)
torch.testing._internal.common_distributed.skip_if_not_multigpu(func)
torch.testing._internal.common_distributed.skip_if_rocm(func)
torch.testing._internal.common_distributed.skip_if_rocm_single_process(func)
torch.testing._internal.common_distributed.skip_if_small_worldsize(func)
torch.testing._internal.common_distributed.skip_if_win32()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/autocast_test_lists.py----------------------------------------
torch.testing._internal.autocast_test_lists.AutocastTestLists(self,dev)
torch.testing._internal.autocast_test_lists.AutocastTestLists.__init__(self,dev)
torch.testing._internal.autocast_test_lists.AutocastTestLists._rnn_cell_args(self,n,num_chunks,is_lstm,dev,dtype)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/expecttest.py----------------------------------------
A:torch.testing._internal.expecttest.ACCEPT->os.getenv('EXPECTTEST_ACCEPT')
A:torch.testing._internal.expecttest.pos->src.find('\n', pos + 1)
A:torch.testing._internal.expecttest.EDIT_HISTORY->EditHistory()
A:torch.testing._internal.expecttest.RE_EXPECT->re.compile('^(?P<suffix>[^\\n]*?)(?P<quote>\'\'\'|""")(?P<body>.*?)(?P=quote)(?P<raw>r?)', re.DOTALL)
A:torch.testing._internal.expecttest.i->nth_eol(src, lineno)
A:torch.testing._internal.expecttest.new_string->normalize_nl(new_string)
A:torch.testing._internal.expecttest.s->escape_trailing_quote(s, '"').replace('"""', '\\"\\"\\"')
A:torch.testing._internal.expecttest.tb->traceback.extract_stack(limit=2 + skip)
A:torch.testing._internal.expecttest.old->f.read()
A:torch.testing._internal.expecttest.lineno->EditHistory().adjust_lineno(fn, lineno)
A:torch.testing._internal.expecttest.(new, delta)->replace_string_literal(old, lineno, actual)
torch.testing._internal.expecttest.EditHistory(self)
torch.testing._internal.expecttest.EditHistory.__init__(self)
torch.testing._internal.expecttest.EditHistory.adjust_lineno(self,fn,lineno)
torch.testing._internal.expecttest.EditHistory.record_edit(self,fn,lineno,delta)
torch.testing._internal.expecttest.EditHistory.seen_file(self,fn)
torch.testing._internal.expecttest.TestCase(unittest.TestCase)
torch.testing._internal.expecttest.TestCase.assertExpectedInline(self,actual,expect,skip=0)
torch.testing._internal.expecttest.TestCase.assertExpectedRaisesInline(self,exc_type,callable,expect,*args,**kwargs)
torch.testing._internal.expecttest.escape_trailing_quote(s,quote)
torch.testing._internal.expecttest.normalize_nl(t)
torch.testing._internal.expecttest.nth_eol(src,lineno)
torch.testing._internal.expecttest.nth_line(src,lineno)
torch.testing._internal.expecttest.ok_for_raw_triple_quoted_string(s,quote)
torch.testing._internal.expecttest.replace_string_literal(src,lineno,new_string)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/dist_utils.py----------------------------------------
A:torch.testing._internal.dist_utils.self.rpc_backend_options->torch.distributed.rpc.backend_registry.construct_rpc_backend_options(self.rpc_backend, init_method=self.init_method, num_send_recv_threads=1)
A:torch.testing._internal.dist_utils.return_value->old_test_method(self, *arg, **kwargs)
A:torch.testing._internal.dist_utils.start->time.time()
A:torch.testing._internal.dist_utils.debug_info->_rref_context_get_debug_info()
A:torch.testing._internal.dist_utils.num_pending_futures->int(debug_info['num_pending_futures'])
A:torch.testing._internal.dist_utils.num_pending_users->int(debug_info['num_pending_users'])
A:torch.testing._internal.dist_utils.rref_dbg_info->_rref_context_get_debug_info()
A:torch.testing._internal.dist_utils.(num_owners_on_rank, num_forks_on_rank)->torch.distributed.rpc.rpc_sync(worker_name(rank), get_num_owners_and_forks, args=(), timeout=5)
A:torch.testing._internal.dist_utils.num_owners_on_rank->int(num_owners_on_rank)
A:torch.testing._internal.dist_utils.num_forks_on_rank->int(num_forks_on_rank)
torch.testing._internal.dist_utils.dist_init(old_test_method=None,setup_rpc=True,clean_shutdown=True,faulty_messages=None,messages_to_delay=None)
torch.testing._internal.dist_utils.get_function_event(function_events,partial_event_name)
torch.testing._internal.dist_utils.get_num_owners_and_forks()
torch.testing._internal.dist_utils.initialize_pg(init_method,rank,world_size)
torch.testing._internal.dist_utils.noop()
torch.testing._internal.dist_utils.single_threaded_process_group_agent(f)
torch.testing._internal.dist_utils.wait_until_node_failure(rank,expected_error_regex='.*')
torch.testing._internal.dist_utils.wait_until_owners_and_forks_on_rank(num_owners,num_forks,rank,timeout=20)
torch.testing._internal.dist_utils.wait_until_pending_futures_and_users_flushed(timeout=20)
torch.testing._internal.dist_utils.worker_name(rank)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/hypothesis_utils.py----------------------------------------
A:torch.testing._internal.hypothesis_utils._ENFORCED_ZERO_POINT->defaultdict(lambda : None, {torch.quint8: None, torch.qint8: None, torch.qint32: 0})
A:torch.testing._internal.hypothesis_utils._long_type_info->torch.iinfo(torch.long)
A:torch.testing._internal.hypothesis_utils.min_value->max((long_min - zero_point) * scale, long_min / scale + zero_point)
A:torch.testing._internal.hypothesis_utils.max_value->min((long_max - zero_point) * scale, long_max / scale + zero_point)
A:torch.testing._internal.hypothesis_utils.(min_value, max_value)->_get_valid_min_max(qparams)
A:torch.testing._internal.hypothesis_utils.quantized_type->draw(st.sampled_from(dtypes))
A:torch.testing._internal.hypothesis_utils._type_info->torch.iinfo(quantized_type)
A:torch.testing._internal.hypothesis_utils.zero_point->draw(st.integers(min_value=_zp_min, max_value=_zp_max))
A:torch.testing._internal.hypothesis_utils.scale->draw(floats(min_value=scale_min, max_value=scale_max, width=32))
A:torch.testing._internal.hypothesis_utils.max_dims->min(min_dims + 2, 32)
A:torch.testing._internal.hypothesis_utils.candidate->candidate.filter(lambda x: reduce(int.__mul__, x, 1) <= max_numel).filter(lambda x: reduce(int.__mul__, x, 1) <= max_numel)
A:torch.testing._internal.hypothesis_utils._shape->draw(st.sampled_from(shapes))
A:torch.testing._internal.hypothesis_utils.elements->floats(min_value, max_value, allow_infinity=False, allow_nan=False, width=32)
A:torch.testing._internal.hypothesis_utils.X->draw(tensor(shapes=((batch_size, input_channels) + tuple(feature_map_shape),), elements=elements, qparams=qparams[0]))
A:torch.testing._internal.hypothesis_utils.qparams->draw(qparams)
A:torch.testing._internal.hypothesis_utils.(scale, zp)->_calculate_dynamic_per_channel_qparams(X, qparams[2])
A:torch.testing._internal.hypothesis_utils.enforced_zp->defaultdict(lambda : None, {torch.quint8: None, torch.qint8: None, torch.qint32: 0}).get(qparams[2], None)
A:torch.testing._internal.hypothesis_utils.axis->int(np.random.randint(0, X.ndim, 1))
A:torch.testing._internal.hypothesis_utils.permute_axes->numpy.arange(X.ndim)
A:torch.testing._internal.hypothesis_utils.batch_size->draw(st.integers(*batch_size_range))
A:torch.testing._internal.hypothesis_utils.input_channels_per_group->draw(st.integers(*input_channels_per_group_range))
A:torch.testing._internal.hypothesis_utils.output_channels_per_group->draw(st.integers(*output_channels_per_group_range))
A:torch.testing._internal.hypothesis_utils.groups->draw(st.integers(1, max_groups))
A:torch.testing._internal.hypothesis_utils.spatial_dim->draw(st.sampled_from(spatial_dim))
A:torch.testing._internal.hypothesis_utils.tr->draw(st.booleans())
A:torch.testing._internal.hypothesis_utils.W->draw(tensor(shapes=(weight_shape,), elements=elements, qparams=qparams[1]))
A:torch.testing._internal.hypothesis_utils.b->draw(tensor(shapes=(bias_shape,), elements=elements, qparams=qparams[2]))
A:torch.testing._internal.hypothesis_utils.warning_message->'Your version of hypothesis is outdated. To avoid `DeadlineExceeded` errors, please update. Current hypothesis version: {}'.format(hypothesis.__version__)
torch.testing._internal.hypothesis_utils._floats_wrapper(*args,**kwargs)
torch.testing._internal.hypothesis_utils._get_valid_min_max(qparams)
torch.testing._internal.hypothesis_utils.array_shapes(draw,min_dims=1,max_dims=None,min_side=1,max_side=None,max_numel=None)
torch.testing._internal.hypothesis_utils.assert_deadline_disabled()
torch.testing._internal.hypothesis_utils.assume_not_overflowing(tensor,qparams)
torch.testing._internal.hypothesis_utils.floats(*args,**kwargs)
torch.testing._internal.hypothesis_utils.per_channel_tensor(draw,shapes=None,elements=None,qparams=None)
torch.testing._internal.hypothesis_utils.qparams(draw,dtypes=None,scale_min=None,scale_max=None,zero_point_min=None,zero_point_max=None)
torch.testing._internal.hypothesis_utils.tensor(draw,shapes=None,elements=None,qparams=None)
torch.testing._internal.hypothesis_utils.tensor_conv(draw,spatial_dim=2,batch_size_range=(1,4),input_channels_per_group_range=(3,7),output_channels_per_group_range=(3,7),feature_map_range=(6,12),kernel_range=(3,7),max_groups=1,can_be_transposed=False,elements=None,qparams=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_utils.py----------------------------------------
A:torch.testing._internal.common_utils.old_prof_exec_state->kwargs.get('torch', globals()['torch'])._C._jit_set_profiling_executor(True)
A:torch.testing._internal.common_utils.old_prof_mode_state->kwargs.get('torch', globals()['torch'])._C._jit_set_profiling_mode(True)
A:torch.testing._internal.common_utils.old_num_runs->kwargs.get('torch', globals()['torch'])._C._jit_set_num_profiled_runs(num_runs)
A:torch.testing._internal.common_utils.override->os.environ.get('TEST_REPORT_SOURCE_OVERRIDE')
A:torch.testing._internal.common_utils.parser->argparse.ArgumentParser(add_help=False)
A:torch.testing._internal.common_utils.(args, remaining)->argparse.ArgumentParser(add_help=False).parse_known_args()
A:torch.testing._internal.common_utils.GRAPH_EXECUTOR->cppProfilingFlagsToProfilingMode()
A:torch.testing._internal.common_utils.exit_status->subprocess.Popen(command, universal_newlines=True, cwd=cwd, env=env).wait(timeout=5)
A:torch.testing._internal.common_utils.p->subprocess.Popen(command, universal_newlines=True, cwd=cwd, env=env)
A:torch.testing._internal.common_utils.IS_PYTORCH_CI->bool(os.environ.get('IS_PYTORCH_CI'))
A:torch.testing._internal.common_utils.suite->unittest.TestLoader().loadTestsFromModule(__main__)
A:torch.testing._internal.common_utils.test_cases->discover_test_cases_recursively(suite)
A:torch.testing._internal.common_utils.exitcode->shell([sys.executable] + argv + [test_case_full_name])
A:torch.testing._internal.common_utils.test_batches->chunk_list(get_test_names(test_cases), RUN_PARALLEL)
A:torch.testing._internal.common_utils.f->tempfile.NamedTemporaryFile(delete=False)
A:torch.testing._internal.common_utils.spec->importlib.util.find_spec(name)
A:torch.testing._internal.common_utils.TEST_NUMPY->_check_module_exists('numpy')
A:torch.testing._internal.common_utils.TEST_SCIPY->_check_module_exists('scipy')
A:torch.testing._internal.common_utils.TEST_MKL->kwargs.get('torch', globals()['torch']).backends.mkl.is_available()
A:torch.testing._internal.common_utils.TEST_NUMBA->_check_module_exists('numba')
A:torch.testing._internal.common_utils.TEST_DILL->_check_module_exists('dill')
A:torch.testing._internal.common_utils.TEST_LIBROSA->_check_module_exists('librosa')
A:torch.testing._internal.common_utils.deterministic_restore->kwargs.get('torch', globals()['torch']).is_deterministic()
A:torch.testing._internal.common_utils.cublas_config_restore->os.environ.get(cublas_var_name)
A:torch.testing._internal.common_utils.cur_cublas_config->os.environ.get(cublas_var_name)
A:torch.testing._internal.common_utils.skipper->unittest.skip('Cannot import `caffe2.python.core`')
A:torch.testing._internal.common_utils.(module, name)->'{}.{}'.format(type_name.__module__, type_name.__name__).rsplit('.', 1)
A:torch.testing._internal.common_utils.type_name->'{}.{}'.format(type_name.__module__, type_name.__name__)
A:torch.testing._internal.common_utils.t->(torch.rand(size, device=device, dtype=torch.float32) * span + low).to(torch.bfloat16)
A:torch.testing._internal.common_utils.res->obj.clone().type(t)
A:torch.testing._internal.common_utils.rng_state->kwargs.get('torch', globals()['torch']).get_rng_state()
A:torch.testing._internal.common_utils.cuda_rng_state->kwargs.get('torch', globals()['torch']).cuda.get_rng_state()
A:torch.testing._internal.common_utils.saved_dtype->kwargs.get('torch', globals()['torch']).get_default_dtype()
A:torch.testing._internal.common_utils.beforeDevice->kwargs.get('torch', globals()['torch']).cuda.current_device()
A:torch.testing._internal.common_utils.deviceStream->kwargs.get('torch', globals()['torch']).cuda.Stream(device=d)
A:torch.testing._internal.common_utils.num_devices->kwargs.get('torch', globals()['torch']).cuda.device_count()
A:torch.testing._internal.common_utils.self.befores->self.get_cuda_memory_usage()
A:torch.testing._internal.common_utils.afters->self.get_cuda_memory_usage()
A:torch.testing._internal.common_utils.contents->urlopen(url, timeout=1).read().decode('utf-8')
A:torch.testing._internal.common_utils.the_response->json.loads(contents)
A:torch.testing._internal.common_utils.test_name->title[len(key):].strip()
A:torch.testing._internal.common_utils.compare_dtype->kwargs.get('torch', globals()['torch']).promote_types(a_dtype, b_dtype)
A:torch.testing._internal.common_utils.test_method->getattr(self, method_name)
A:torch.testing._internal.common_utils.fullname->self.id().lower()
A:torch.testing._internal.common_utils.v->kwargs.get('torch', globals()['torch']).full(shape, fv, dtype=dtype, layout=layout, device=device, requires_grad=rg)
A:torch.testing._internal.common_utils.i->random.randint(0, matrix_size - 1)
A:torch.testing._internal.common_utils.x->self.safeCoalesce(x)
A:torch.testing._internal.common_utils.r->self.safeCoalesce(t)
A:torch.testing._internal.common_utils.tc->(torch.rand(size, device=device, dtype=torch.float32) * span + low).to(torch.bfloat16).coalesce()
A:torch.testing._internal.common_utils.idx_tup->tuple(idx.tolist())
A:torch.testing._internal.common_utils.new_indices->(torch.rand(size, device=device, dtype=torch.float32) * span + low).to(torch.bfloat16)._indices().new(new_indices).t()
A:torch.testing._internal.common_utils.new_values->kwargs.get('torch', globals()['torch']).stack(_new_values)
A:torch.testing._internal.common_utils.tg->(torch.rand(size, device=device, dtype=torch.float32) * span + low).to(torch.bfloat16).new(new_indices, new_values, t.size())
A:torch.testing._internal.common_utils.a->a.to(dtype).to(dtype)
A:torch.testing._internal.common_utils.np_result->kwargs.get('torch', globals()['torch']).from_numpy(np_result.copy())
A:torch.testing._internal.common_utils.torch_result->torch_fn(t).cpu()
A:torch.testing._internal.common_utils.rtol->max(self.dtype_precisions.get(dtype0, (0, 0))[0], self.dtype_precisions.get(dtype1, (0, 0))[0])
A:torch.testing._internal.common_utils.atol->max(atol, self.precision)
A:torch.testing._internal.common_utils.b->b.to(dtype).to(dtype)
A:torch.testing._internal.common_utils.(rtol, atol)->self._getDefaultRtolAndAtol(torch.float32, torch.float32)
A:torch.testing._internal.common_utils.dtype->kwargs.get('dtype', torch.double)
A:torch.testing._internal.common_utils.y->self.safeCoalesce(y)
A:torch.testing._internal.common_utils.(indices_result, debug_msg)->self._compareTensors(x._indices(), y._indices(), rtol=rtol, atol=atol, equal_nan=equal_nan, exact_dtype=exact_dtype, exact_device=exact_device)
A:torch.testing._internal.common_utils.(values_result, debug_msg)->self._compareTensors(x._values(), y._values(), rtol=rtol, atol=atol, equal_nan=equal_nan, exact_dtype=exact_dtype, exact_device=exact_device)
A:torch.testing._internal.common_utils.(result, debug_msg)->self._compareScalars(x, y, rtol=rtol, atol=atol, equal_nan=equal_nan)
A:torch.testing._internal.common_utils.key_list->list(x.keys())
A:torch.testing._internal.common_utils.munged_id->remove_prefix(self.id(), module_id + '.')
A:torch.testing._internal.common_utils.test_file->os.path.realpath(sys.modules[module_id].__file__)
A:torch.testing._internal.common_utils.expected_file->os.path.join(os.path.dirname(test_file), 'expect', munged_id)
A:torch.testing._internal.common_utils.subname_output->' ({})'.format(subname)
A:torch.testing._internal.common_utils.s_tag->re.sub('(producer_version): "[0-9.]*"', '\\1producer_version: "CURRENT_VERSION"', s)
A:torch.testing._internal.common_utils.expected->expected.replace('producer_version: "CURRENT_VERSION"', 'producer_version: "{}"'.format(torch.onnx.producer_version)).replace('producer_version: "CURRENT_VERSION"', 'producer_version: "{}"'.format(torch.onnx.producer_version))
A:torch.testing._internal.common_utils.s->kwargs.get('torch', globals()['torch']).zeros(rows, columns, dtype=dtype, device=device)
A:torch.testing._internal.common_utils.env->os.environ.copy()
A:torch.testing._internal.common_utils.pipes->subprocess.Popen([sys.executable, '-c', code], stdout=subprocess.PIPE, stderr=subprocess.PIPE, env=env)
A:torch.testing._internal.common_utils.filename->os.path.basename(urlsplit(url)[2])
A:torch.testing._internal.common_utils.data_dir->get_writable_path(os.path.join(os.path.dirname(__file__), 'data'))
A:torch.testing._internal.common_utils.path->os.path.join(data_dir, filename)
A:torch.testing._internal.common_utils.data->dict([((i, i), float(i + 1) / matrix_size) for i in range(matrix_size)])
A:torch.testing._internal.common_utils.msg->"could not download test file '{}'".format(url)
A:torch.testing._internal.common_utils.sock->socket.socket(socket.AF_INET, socket.SOCK_STREAM)
A:torch.testing._internal.common_utils.sockname->socket.socket(socket.AF_INET, socket.SOCK_STREAM).getsockname()
A:torch.testing._internal.common_utils.low->math.floor(-9 if low is None else max(low, -9))
A:torch.testing._internal.common_utils.high->math.ceil(10 if high is None else min(high, 10))
A:torch.testing._internal.common_utils.c->kwargs.get('torch', globals()['torch']).complex(real, imag)
A:torch.testing._internal.common_utils.result->kwargs.get('torch', globals()['torch']).randn(dim_size, dim_size)
A:torch.testing._internal.common_utils.A->kwargs.get('torch', globals()['torch']).sparse_coo_tensor(indices_tensor, values, (rows, columns), device=device)
A:torch.testing._internal.common_utils.(u, s, v)->kwargs.get('torch', globals()['torch']).sparse_coo_tensor(indices_tensor, values, (rows, columns), device=device).svd()
A:torch.testing._internal.common_utils.device->kwargs.get('device', 'cpu')
A:torch.testing._internal.common_utils.det->det.item().item()
A:torch.testing._internal.common_utils.cond->((det < 0) ^ (sign < 0)).nonzero()
A:torch.testing._internal.common_utils.silent->kwargs.get('silent', False)
A:torch.testing._internal.common_utils.(u, _, v)->kwargs.get('torch', globals()['torch']).sparse_coo_tensor(indices_tensor, values, (rows, columns), device=device).svd(some=False)
A:torch.testing._internal.common_utils.singular->kwargs.get('singular', False)
A:torch.testing._internal.common_utils.k->min(rows, columns)
A:torch.testing._internal.common_utils.B->random_matrix(rows, rank, *batch_dims, **kwargs)
A:torch.testing._internal.common_utils.C->random_matrix(rank, columns, *batch_dims, **kwargs)
A:torch.testing._internal.common_utils.nonzero_elements->max(min(rows, columns), int(rows * columns * density))
A:torch.testing._internal.common_utils.values->kwargs.get('torch', globals()['torch']).randn(nonzero_elements, dtype=dtype, device=device)
A:torch.testing._internal.common_utils.indices_tensor->kwargs.get('torch', globals()['torch']).tensor([icoords, jcoords])
A:torch.testing._internal.common_utils.torch->kwargs.get('torch', globals()['torch'])
A:torch.testing._internal.common_utils.j->random.randint(0, matrix_size - 1)
A:torch.testing._internal.common_utils.theta->random.uniform(0, 2 * math.pi)
A:torch.testing._internal.common_utils.cs->math.cos(theta)
A:torch.testing._internal.common_utils.sn->math.sin(theta)
A:torch.testing._internal.common_utils.out->kwargs.get('torch', globals()['torch']).full(shape, fv, dtype=dtype, layout=layout, device=device, requires_grad=rg).new()
A:torch.testing._internal.common_utils.shape->kwargs.get('torch', globals()['torch']).Size([2, 3])
A:torch.testing._internal.common_utils.fill->tensor.new(shape).fill_(value)
A:torch.testing._internal.common_utils.module->'.'.join(str(dtype).split('.')[1:-1])
A:torch.testing._internal.common_utils.default_dtype->kwargs.get('torch', globals()['torch']).get_default_dtype()
A:torch.testing._internal.common_utils.int64_dtype->get_int64_dtype(dtype)
A:torch.testing._internal.common_utils.running_file->os.path.abspath(os.path.realpath(sys.argv[0]))
A:torch.testing._internal.common_utils.test_case_class_file->os.path.abspath(os.path.realpath(inspect.getfile(test_case.__class__)))
A:torch.testing._internal.common_utils.test_suite->unittest.TestSuite()
torch.testing._internal.common_utils.BytesIOContext(io.BytesIO)
torch.testing._internal.common_utils.BytesIOContext.__enter__(self)
torch.testing._internal.common_utils.BytesIOContext.__exit__(self,*args)
torch.testing._internal.common_utils.CudaMemoryLeakCheck(self,testcase,name=None)
torch.testing._internal.common_utils.CudaMemoryLeakCheck.__enter__(self)
torch.testing._internal.common_utils.CudaMemoryLeakCheck.__exit__(self,exec_type,exec_value,traceback)
torch.testing._internal.common_utils.CudaMemoryLeakCheck.__init__(self,testcase,name=None)
torch.testing._internal.common_utils.CudaMemoryLeakCheck.get_cuda_memory_usage()
torch.testing._internal.common_utils.CudaNonDefaultStream
torch.testing._internal.common_utils.CudaNonDefaultStream.__enter__(self)
torch.testing._internal.common_utils.CudaNonDefaultStream.__exit__(self,exec_type,exec_value,traceback)
torch.testing._internal.common_utils.ProfilingMode(Enum)
torch.testing._internal.common_utils.TestCase(self,method_name='runTest')
torch.testing._internal.common_utils.TestCase.__init__(self,method_name='runTest')
torch.testing._internal.common_utils.TestCase._compareScalars(self,a,b,*,rtol:Optional[float]=None,atol:Optional[float]=None,equal_nan=True)->_compare_return_type
torch.testing._internal.common_utils.TestCase._compareTensors(self,a,b,*,rtol:Optional[float]=None,atol=None,equal_nan=True,exact_dtype=True,exact_device=False)->_compare_return_type
torch.testing._internal.common_utils.TestCase._getDefaultRtolAndAtol(self,dtype0,dtype1)
torch.testing._internal.common_utils.TestCase.assertEqual(self,x,y,msg:Optional[str]=None,*,atol:Optional[float]=None,rtol:Optional[float]=None,equal_nan=True,exact_dtype=True,exact_device=False)->None
torch.testing._internal.common_utils.TestCase.assertEqualIgnoreType(self,*args,**kwargs)->None
torch.testing._internal.common_utils.TestCase.assertEqualTypeString(self,x,y)->None
torch.testing._internal.common_utils.TestCase.assertExpected(self,s,subname=None)
torch.testing._internal.common_utils.TestCase.assertExpectedRaises(self,exc_type,callable,*args,**kwargs)
torch.testing._internal.common_utils.TestCase.assertExpectedStripMangled(self,s,subname=None)
torch.testing._internal.common_utils.TestCase.assertLeaksNoCudaTensors(self,name=None)
torch.testing._internal.common_utils.TestCase.assertNotEqual(self,x,y,msg:Optional[str]=None,*,atol:Optional[float]=None,rtol:Optional[float]=None,**kwargs)->None
torch.testing._internal.common_utils.TestCase.assertNotWarn(self,callable,msg='')
torch.testing._internal.common_utils.TestCase.assertObjectIn(self,obj:Any,iterable:Iterable[Any])->None
torch.testing._internal.common_utils.TestCase.compare_with_numpy(self,torch_fn,np_fn,tensor_like,device=None,dtype=None,**kwargs)
torch.testing._internal.common_utils.TestCase.enforceNonDefaultStream(self)
torch.testing._internal.common_utils.TestCase.genSparseTensor(self,size,sparse_dim,nnz,is_uncoalesced,device='cpu')
torch.testing._internal.common_utils.TestCase.maybeWarnsRegex(self,category,regex='')
torch.testing._internal.common_utils.TestCase.precision(self)->float
torch.testing._internal.common_utils.TestCase.precision(self,prec:float)->None
torch.testing._internal.common_utils.TestCase.runWithPytorchAPIUsageStderr(code)
torch.testing._internal.common_utils.TestCase.safeCoalesce(self,t)
torch.testing._internal.common_utils.TestCase.safeToDense(self,t)
torch.testing._internal.common_utils.TestCase.setUp(self)
torch.testing._internal.common_utils.TestCase.wrap_method_with_cuda_policy(self,method,policy)
torch.testing._internal.common_utils.TestCase.wrap_with_cuda_memory_check(self,method)
torch.testing._internal.common_utils.TestCase.wrap_with_cuda_policy(self,method_name,policy)
torch.testing._internal.common_utils._assertGradAndGradgradChecks(test_case,apply_fn,inputs)
torch.testing._internal.common_utils._check_module_exists(name)
torch.testing._internal.common_utils._get_test_report_path()
torch.testing._internal.common_utils._test_function(fn,device)
torch.testing._internal.common_utils.check_disabled(test_name)
torch.testing._internal.common_utils.check_test_defined_in_running_script(test_case)
torch.testing._internal.common_utils.chunk_list(lst,nchunks)
torch.testing._internal.common_utils.cppProfilingFlagsToProfilingMode()
torch.testing._internal.common_utils.discover_test_cases_recursively(suite_or_case)
torch.testing._internal.common_utils.do_test_dtypes(self,dtypes,layout,device)
torch.testing._internal.common_utils.do_test_empty_full(self,dtypes,layout,device)
torch.testing._internal.common_utils.download_file(url,binary=True)
torch.testing._internal.common_utils.enable_profiling_mode()
torch.testing._internal.common_utils.enable_profiling_mode_for_profiling_tests()
torch.testing._internal.common_utils.find_free_port()
torch.testing._internal.common_utils.freeze_rng_state()
torch.testing._internal.common_utils.get_comparison_dtype(a,b)
torch.testing._internal.common_utils.get_cpu_type(type_name)
torch.testing._internal.common_utils.get_function_arglist(func)
torch.testing._internal.common_utils.get_gpu_type(type_name)
torch.testing._internal.common_utils.get_test_names(test_cases)
torch.testing._internal.common_utils.is_iterable(obj)
torch.testing._internal.common_utils.iter_indices(tensor)
torch.testing._internal.common_utils.load_tests(loader,tests,pattern)
torch.testing._internal.common_utils.make_nonzero_det(A,sign=None,min_singular_value=0.1)
torch.testing._internal.common_utils.make_tensor(size,device:torch.device,dtype:torch.dtype,*,low,high,requires_grad:bool=False)->torch.Tensor
torch.testing._internal.common_utils.num_profiled_runs(num_runs)
torch.testing._internal.common_utils.prod_single_zero(dim_size)
torch.testing._internal.common_utils.prof_callable(callable,*args,**kwargs)
torch.testing._internal.common_utils.prof_func_call(*args,**kwargs)
torch.testing._internal.common_utils.prof_meth_call(*args,**kwargs)
torch.testing._internal.common_utils.random_fullrank_matrix_distinct_singular_value(matrix_size,*batch_dims,**kwargs)
torch.testing._internal.common_utils.random_lowrank_matrix(rank,rows,columns,*batch_dims,**kwargs)
torch.testing._internal.common_utils.random_matrix(rows,columns,*batch_dims,**kwargs)
torch.testing._internal.common_utils.random_sparse_matrix(rows,columns,density=0.01,**kwargs)
torch.testing._internal.common_utils.random_sparse_pd_matrix(matrix_size,density=0.01,**kwargs)
torch.testing._internal.common_utils.random_square_matrix_of_rank(l,rank,dtype=torch.double,device='cpu')
torch.testing._internal.common_utils.random_symmetric_matrix(l,*batches,**kwargs)
torch.testing._internal.common_utils.random_symmetric_pd_matrix(matrix_size,*batch_dims,**kwargs)
torch.testing._internal.common_utils.random_symmetric_psd_matrix(l,*batches,**kwargs)
torch.testing._internal.common_utils.repeat_test_for_types(dtypes)
torch.testing._internal.common_utils.retry(ExceptionToCheck,tries=3,delay=3,skip_after_retries=False)
torch.testing._internal.common_utils.retry_on_connect_failures(func=None,connect_errors=ADDRESS_IN_USE)
torch.testing._internal.common_utils.run_tests(argv=UNITTEST_ARGS)
torch.testing._internal.common_utils.set_default_dtype(dtype)
torch.testing._internal.common_utils.set_rng_seed(seed)
torch.testing._internal.common_utils.set_running_script_path()
torch.testing._internal.common_utils.shell(command,cwd=None,env=None)
torch.testing._internal.common_utils.skipCUDAMemoryLeakCheckIf(condition)
torch.testing._internal.common_utils.skipCUDANonDefaultStreamIf(condition)
torch.testing._internal.common_utils.skipIfCompiledWithoutNumpy(fn)
torch.testing._internal.common_utils.skipIfNoLapack(fn)
torch.testing._internal.common_utils.skipIfNoSciPy(fn)
torch.testing._internal.common_utils.skipIfNotRegistered(op_name,message)
torch.testing._internal.common_utils.skipIfRocm(fn)
torch.testing._internal.common_utils.slowTest(fn)
torch.testing._internal.common_utils.suppress_warnings(fn)
torch.testing._internal.common_utils.to_gpu(obj,type_map=None)
torch.testing._internal.common_utils.wait_for_process(p)
torch.testing._internal.common_utils.wrapDeterministicFlagAPITest(fn)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/jit_metaprogramming_utils.py----------------------------------------
A:torch.testing._internal.jit_metaprogramming_utils.kwargs_str->', '.join([k + '=' + str(v) for (k, v) in kwargs.items()])
A:torch.testing._internal.jit_metaprogramming_utils.argument_str->', '.join(args)
A:torch.testing._internal.jit_metaprogramming_utils.call->'self.submodule({})'.format(call_args_str)
A:torch.testing._internal.jit_metaprogramming_utils.name->get_nn_module_name_from_kwargs(**kwargs)
A:torch.testing._internal.jit_metaprogramming_utils.(formals, tensors, actuals)->get_script_args(args)
A:torch.testing._internal.jit_metaprogramming_utils.script->script_method_template.format(method_args, call)
A:torch.testing._internal.jit_metaprogramming_utils.CU->torch.jit.CompilationUnit(script)
A:torch.testing._internal.jit_metaprogramming_utils.(fn, tensors)->gen_script_fn_and_args(method_name, func_type, *args, **kwargs)
A:torch.testing._internal.jit_metaprogramming_utils.output->traced(*inputs_tensors)
A:torch.testing._internal.jit_metaprogramming_utils.script_fn.last_graph->fn.graph_for(*tensors)
A:torch.testing._internal.jit_metaprogramming_utils.tensors->iter(tensors_)
A:torch.testing._internal.jit_metaprogramming_utils.(fn_tensors, inputs_tensors)->partial_apply_nontensors(fn, inputs, **kwargs)
A:torch.testing._internal.jit_metaprogramming_utils.traced->torch.jit.trace(fn_tensors, inputs_tensors, check_trace=False)
A:torch.testing._internal.jit_metaprogramming_utils.traced_fn.last_graph->torch.jit.trace(fn_tensors, inputs_tensors, check_trace=False).graph_for(*inputs_tensors)
A:torch.testing._internal.jit_metaprogramming_utils.(args_variable, kwargs_variable)->create_input(input)
A:torch.testing._internal.jit_metaprogramming_utils.self_tensor->deepcopy(self_variable.data)
A:torch.testing._internal.jit_metaprogramming_utils.args_tensor->deepcopy(unpack_variables(args_variable))
A:torch.testing._internal.jit_metaprogramming_utils.(script_fn, inputs)->gen_script_fn_and_args(name, 'nn_functional', *f_args_variable)
A:torch.testing._internal.jit_metaprogramming_utils.method_args->', '.join(['self'] + actuals)
A:torch.testing._internal.jit_metaprogramming_utils.call_args_str->', '.join(actuals)
A:torch.testing._internal.jit_metaprogramming_utils.self.submodule->nn_module(*constructor_args)
A:torch.testing._internal.jit_metaprogramming_utils.module->make_module(script)
A:torch.testing._internal.jit_metaprogramming_utils.test_name->get_nn_mod_test_name(**kwargs)
A:torch.testing._internal.jit_metaprogramming_utils.index->get_nn_module_name_from_kwargs(**kwargs).find('_')
A:torch.testing._internal.jit_metaprogramming_utils.nn_module->getattr(torch.nn, name)
A:torch.testing._internal.jit_metaprogramming_utils.constructor_args->kwargs.get('constructor_args', ())
A:torch.testing._internal.jit_metaprogramming_utils.input->kwargs['input_fn']()
A:torch.testing._internal.jit_metaprogramming_utils.f_args_variable->deepcopy(unpack_variables(args_variable))
A:torch.testing._internal.jit_metaprogramming_utils.out_var->deepcopy(f_args_variable)
torch.testing._internal.jit_metaprogramming_utils.create_script_fn(self,method_name,func_type,output_process_fn)
torch.testing._internal.jit_metaprogramming_utils.create_script_module(self,nn_module,constructor_args,*args,**kwargs)
torch.testing._internal.jit_metaprogramming_utils.create_traced_fn(self,fn)
torch.testing._internal.jit_metaprogramming_utils.gen_script_fn_and_args(method_name,func_type,*args,**kwargs)
torch.testing._internal.jit_metaprogramming_utils.get_all_nn_module_tests()
torch.testing._internal.jit_metaprogramming_utils.get_call(method_name,func_type,args,kwargs)
torch.testing._internal.jit_metaprogramming_utils.get_constant(x)
torch.testing._internal.jit_metaprogramming_utils.get_nn_functional_compiled_fn_and_inputs(name,self_size,args,variant_name='',*extra_args)
torch.testing._internal.jit_metaprogramming_utils.get_nn_mod_test_name(**kwargs)
torch.testing._internal.jit_metaprogramming_utils.get_nn_module_class_from_kwargs(**kwargs)
torch.testing._internal.jit_metaprogramming_utils.get_nn_module_name_from_kwargs(**kwargs)
torch.testing._internal.jit_metaprogramming_utils.get_script_args(args)
torch.testing._internal.jit_metaprogramming_utils.partial_apply_nontensors(fn,args,**kwargs)
torch.testing._internal.jit_metaprogramming_utils.try_get_nn_module_compiled_mod_and_inputs(*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_nn.py----------------------------------------
A:torch.testing._internal.common_nn.result->getattr(m, 'weight', None)
A:torch.testing._internal.common_nn.total->reduce(mul, size, 1)
A:torch.testing._internal.common_nn.t->torch.rand(5).mul(8).floor().long()
A:torch.testing._internal.common_nn.weights->torch.rand(10)
A:torch.testing._internal.common_nn.sigmoid->torch.nn.Sigmoid()
A:torch.testing._internal.common_nn.i->torch.rand(10, 10).log()
A:torch.testing._internal.common_nn.target->self._get_target()
A:torch.testing._internal.common_nn.weight->self._get_input().new(len(input)).fill_(1)
A:torch.testing._internal.common_nn.random_samples->torch.DoubleTensor(2, 4, 3).uniform_()
A:torch.testing._internal.common_nn.padding->tuple(range(1, d + 1))
A:torch.testing._internal.common_nn.safe_target_log->(safe_target + (target <= 0).type_as(target)).log()
A:torch.testing._internal.common_nn.N->self._get_input().size(0)
A:torch.testing._internal.common_nn.C->self._get_input().size(1)
A:torch.testing._internal.common_nn.output->module(input)
A:torch.testing._internal.common_nn.input_index->list(tup)
A:torch.testing._internal.common_nn.(losses, weights)->zip(*losses_and_weights)
A:torch.testing._internal.common_nn.losses_tensor->self._get_input().new_tensor(losses)
A:torch.testing._internal.common_nn.abs_diff->(input - target).abs()
A:torch.testing._internal.common_nn.ge_beta_mask->(abs_diff >= beta).type_as(abs_diff)
A:torch.testing._internal.common_nn.lt_beta_mask->(abs_diff < beta).type_as(abs_diff)
A:torch.testing._internal.common_nn.input_dim->self._get_input().dim()
A:torch.testing._internal.common_nn.n->self._get_input().size(0)
A:torch.testing._internal.common_nn.dim->self._get_input().size(1)
A:torch.testing._internal.common_nn.output[i]->_multilabelmarginloss_reference(input[i], target[i])
A:torch.testing._internal.common_nn.margin_clamp->(margin - input).clamp(min=0).type_as(input)
A:torch.testing._internal.common_nn.target_dim->self._get_target().dim()
A:torch.testing._internal.common_nn.output[x]->_multimarginloss_reference(input[x], target[x], p, margin, weight)
A:torch.testing._internal.common_nn.cos->a.new(a.size(0))
A:torch.testing._internal.common_nn.d_p->torch.pairwise_distance(anchor, positive, p, eps)
A:torch.testing._internal.common_nn.d_n->torch.min(d_n, d_s)
A:torch.testing._internal.common_nn.d_s->torch.pairwise_distance(positive, negative, p, eps)
A:torch.testing._internal.common_nn.input_lengths->torch.as_tensor(input_lengths, dtype=torch.long)
A:torch.testing._internal.common_nn.target_lengths->torch.as_tensor(target_lengths, dtype=torch.long)
A:torch.testing._internal.common_nn.log_probs->log_probs.double().double()
A:torch.testing._internal.common_nn.targets->targets.long().long()
A:torch.testing._internal.common_nn.cum_target_lengths->torch.as_tensor(target_lengths, dtype=torch.long).cumsum(0)
A:torch.testing._internal.common_nn.input_length->input_lengths[i].item()
A:torch.testing._internal.common_nn.target_length->target_lengths[i].item()
A:torch.testing._internal.common_nn.cum_target_length->cum_target_lengths[i].item()
A:torch.testing._internal.common_nn.targets_prime->targets.long().long().new_full((2 * target_length + 1,), blank)
A:torch.testing._internal.common_nn.probs->log_probs[:input_length, i].exp()
A:torch.testing._internal.common_nn.alpha->log_probs.double().double().new_zeros((target_length * 2 + 1,))
A:torch.testing._internal.common_nn.alpha_next->log_probs.double().double().new_zeros((target_length * 2 + 1,)).clone()
A:torch.testing._internal.common_nn.input->self._get_input()
A:torch.testing._internal.common_nn.output_size->module(input).nelement()
A:torch.testing._internal.common_nn.jacobian_inp->self._jacobian(input, output_size)
A:torch.testing._internal.common_nn.flat_jacobian_input->list(iter_tensors(jacobian_inp))
A:torch.testing._internal.common_nn.num_param->sum((p.numel() for p in self._get_parameters(module)[0]))
A:torch.testing._internal.common_nn.jacobian_param->torch.zeros(num_param, output_size)
A:torch.testing._internal.common_nn.(param, d_param)->self._get_parameters(module)
A:torch.testing._internal.common_nn.d_out->torch.zeros_like(output)
A:torch.testing._internal.common_nn.flat_d_out->torch.zeros_like(output).view(-1)
A:torch.testing._internal.common_nn.d_input->deepcopy(test_case._backward(module, input, output, grad_output))
A:torch.testing._internal.common_nn.jacobian_x[:, i]->d_x.contiguous().view(-1)
A:torch.testing._internal.common_nn.jacobian_param[:, i]->torch.cat(self._flatten_tensors(d_param), 0)
A:torch.testing._internal.common_nn.res->tuple()
A:torch.testing._internal.common_nn.(param, _)->self._get_parameters(module)
A:torch.testing._internal.common_nn.jacobian_parameters->bool(self._get_parameters(module)[0])
A:torch.testing._internal.common_nn.analytical->self._analytical_jacobian(module, input, jacobian_input, jacobian_parameters)
A:torch.testing._internal.common_nn.numerical->self._numerical_jacobian(module, input, jacobian_input, jacobian_parameters)
A:torch.testing._internal.common_nn.analytical_t->list(iter_tensors(analytical))
A:torch.testing._internal.common_nn.numerical_t->list(iter_tensors(numerical))
A:torch.testing._internal.common_nn.kwargs[name]->tuple()
A:torch.testing._internal.common_nn.self._arg_cache[name]->map_tensor_sizes(self._extra_kwargs[size_name])
A:torch.testing._internal.common_nn.self.jacobian_input->kwargs.get('jacobian_input', True)
A:torch.testing._internal.common_nn.self.should_test_cuda->kwargs.get('test_cuda', True)
A:torch.testing._internal.common_nn.self.should_test_pickle->kwargs.get('pickle', True)
A:torch.testing._internal.common_nn.self.check_gradgrad->kwargs.get('check_gradgrad', True)
A:torch.testing._internal.common_nn.self.FIXME_no_cuda_gradgrad_comparison->kwargs.get('FIXME_no_cuda_gradgrad_comparison', False)
A:torch.testing._internal.common_nn.self.precision->kwargs.get('precision', 0.0002)
A:torch.testing._internal.common_nn.self.check_forward_only->kwargs.get('check_forward_only', False)
A:torch.testing._internal.common_nn.module->self.constructor(*self.constructor_args)
A:torch.testing._internal.common_nn.out->test_case._forward_criterion(module, input, target, extra_args=self.extra_args)
A:torch.testing._internal.common_nn.ref_input->deepcopy(input)
A:torch.testing._internal.common_nn.ref_module->deepcopy(module)
A:torch.testing._internal.common_nn.expected_out->self.reference_fn(*ref_args)
A:torch.testing._internal.common_nn.module_copy->torch.load(f)
A:torch.testing._internal.common_nn.ndim->tensor.dim()
A:torch.testing._internal.common_nn.noncontig->torch.stack([torch.empty_like(tensor), tensor], dim).select(dim, 1).detach()
A:torch.testing._internal.common_nn.grad_output->module(input).new(output.shape).normal_()
A:torch.testing._internal.common_nn.d_param->deepcopy(test_case._get_parameters(module)[1])
A:torch.testing._internal.common_nn.nc_input->self.noncontiguize(input)
A:torch.testing._internal.common_nn.nc_grad_output->self.noncontiguize(grad_output)
A:torch.testing._internal.common_nn.go->deepcopy(grad_output if contig_g else nc_grad_output)
A:torch.testing._internal.common_nn.grad->module(input).data.clone().normal_()
A:torch.testing._internal.common_nn.cpu_input->self._get_input()
A:torch.testing._internal.common_nn.gpu_input_tuple->to_gpu(cpu_input_tuple, type_map=type_map)
A:torch.testing._internal.common_nn.cpu_module->self.constructor(*self.constructor_args)
A:torch.testing._internal.common_nn.gpu_module->self.constructor(*self.constructor_args)
A:torch.testing._internal.common_nn.cpu_param->test_case._get_parameters(cpu_module)
A:torch.testing._internal.common_nn.gpu_param->test_case._get_parameters(gpu_module)
A:torch.testing._internal.common_nn.cpu_output->test_case._forward_criterion(cpu_module, cpu_input, cpu_target, extra_args=extra_args)
A:torch.testing._internal.common_nn.gpu_output->test_case._forward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
A:torch.testing._internal.common_nn.cpu_gradOutput->torch.randn_like(cpu_output, requires_grad=True)
A:torch.testing._internal.common_nn.gpu_gradOutput->torch.randn_like(cpu_output, requires_grad=True).type_as(gpu_output).detach()
A:torch.testing._internal.common_nn.cpu_gradInput->test_case._backward_criterion(cpu_module, cpu_input, cpu_target, extra_args=extra_args)
A:torch.testing._internal.common_nn.gpu_gradInput->test_case._backward_criterion(gpu_module, gpu_input, gpu_target, extra_args=extra_args)
A:torch.testing._internal.common_nn.cpu_gradInputs->torch.autograd.grad(cpu_output, cpu_input_tuple + tuple(cpu_module.parameters()), cpu_gradOutput, create_graph=True)
A:torch.testing._internal.common_nn.gpu_gradInputs->torch.autograd.grad(gpu_output, gpu_input_tuple + tuple(gpu_module.parameters()), gpu_gradOutput, create_graph=True)
A:torch.testing._internal.common_nn.cpu_gg->torch.autograd.grad(cpu_output.sum() + sum(map(lambda x: x.sum(), cpu_gradInputs)), cpu_input_tuple + (cpu_gradOutput,) + tuple(cpu_module.parameters()), retain_graph=True)
A:torch.testing._internal.common_nn.gpu_gg->torch.autograd.grad(gpu_output.sum() + sum(map(lambda x: x.sum(), gpu_gradInputs)), gpu_input_tuple + (gpu_gradOutput,) + tuple(gpu_module.parameters()), retain_graph=True)
A:torch.testing._internal.common_nn.self.cudnn->kwargs.get('cudnn', False)
A:torch.testing._internal.common_nn.self.check_inplace->kwargs.get('check_inplace', False)
A:torch.testing._internal.common_nn.self.skip_double->kwargs.get('skip_double', False)
A:torch.testing._internal.common_nn.self.with_tf32->kwargs.get('with_tf32', True)
A:torch.testing._internal.common_nn.self.tf32_precision->kwargs.get('tf32_precision', 0.001)
A:torch.testing._internal.common_nn.self.test_cpu->kwargs.get('test_cpu', True)
A:torch.testing._internal.common_nn.num_threads->torch.get_num_threads()
A:torch.testing._internal.common_nn.params->tuple((x for x in module.parameters()))
A:torch.testing._internal.common_nn.num_inputs->len(input_tuple)
A:torch.testing._internal.common_nn.module_ip->self.constructor(*self.constructor_args, inplace=True)
A:torch.testing._internal.common_nn.input_ip->deepcopy(input)
A:torch.testing._internal.common_nn.input_ip_clone->deepcopy(input).clone()
A:torch.testing._internal.common_nn.output_ip->module_ip(input_ip_clone)
A:torch.testing._internal.common_nn.input_tuple->tuple((t.half().cuda() if not isinstance(t, torch.LongTensor) else t.cuda() for t in input_tuple))
A:torch.testing._internal.common_nn._required_arg_names->TestBase._required_arg_names.union({'target'})
A:torch.testing._internal.common_nn.self.check_half->kwargs.get('check_half', True)
A:torch.testing._internal.common_nn.self.check_bfloat16->kwargs.get('check_bfloat16', False)
A:torch.testing._internal.common_nn.cpu_target->self._get_target()
A:torch.testing._internal.common_nn.gpu_input->to_gpu(cpu_input)
A:torch.testing._internal.common_nn.gpu_target->to_gpu(cpu_target)
torch.testing._internal.common_nn.CriterionTest(self,*args,**kwargs)
torch.testing._internal.common_nn.CriterionTest.__init__(self,*args,**kwargs)
torch.testing._internal.common_nn.CriterionTest._get_target(self)
torch.testing._internal.common_nn.CriterionTest.constructor_args(self)
torch.testing._internal.common_nn.CriterionTest.extra_args(self)
torch.testing._internal.common_nn.CriterionTest.test_cuda(self,test_case,dtype,extra_args=None)
torch.testing._internal.common_nn.InputVariableMixin(object)
torch.testing._internal.common_nn.InputVariableMixin._get_input(self)
torch.testing._internal.common_nn.ModuleTest(self,*args,**kwargs)
torch.testing._internal.common_nn.ModuleTest.__init__(self,*args,**kwargs)
torch.testing._internal.common_nn.ModuleTest.noncontiguize(self,obj)
torch.testing._internal.common_nn.ModuleTest.test_cuda(self,test_case)
torch.testing._internal.common_nn.ModuleTest.test_noncontig(self,test_case,module,input)
torch.testing._internal.common_nn.NNTestCase(TestCase)
torch.testing._internal.common_nn.NNTestCase._analytical_jacobian(self,module,input:_TensorOrTensors,jacobian_input=True,jacobian_parameters=True)
torch.testing._internal.common_nn.NNTestCase._flatten_tensors(self,x)
torch.testing._internal.common_nn.NNTestCase._jacobian(self,input,num_out)
torch.testing._internal.common_nn.NNTestCase._numerical_jacobian(self,module,input:_TensorOrTensors,jacobian_input=True,jacobian_parameters=True)
torch.testing._internal.common_nn.NNTestCase._zero_grad_input(self,input)
torch.testing._internal.common_nn.NNTestCase.check_jacobian(self,module,input:_TensorOrTensors,jacobian_input=True)
torch.testing._internal.common_nn.NewModuleTest(self,*args,**kwargs)
torch.testing._internal.common_nn.NewModuleTest.__init__(self,*args,**kwargs)
torch.testing._internal.common_nn.NewModuleTest._do_test(self,test_case,module,input)
torch.testing._internal.common_nn.NewModuleTest._get_target(self)
torch.testing._internal.common_nn.NewModuleTest.constructor_args(self)
torch.testing._internal.common_nn.TestBase(self,constructor,desc='',reference_fn=None,fullname=None,**kwargs)
torch.testing._internal.common_nn.TestBase.__init__(self,constructor,desc='',reference_fn=None,fullname=None,**kwargs)
torch.testing._internal.common_nn.TestBase._get_arg(self,name,unpack)
torch.testing._internal.common_nn.TestBase._get_input(self,unpack=True)
torch.testing._internal.common_nn.TestBase._unpack(self,value)
torch.testing._internal.common_nn.TestBase.constructor_args(self)
torch.testing._internal.common_nn.TestBase.extra_args(self)
torch.testing._internal.common_nn.TestBase.get_name(self)
torch.testing._internal.common_nn._multilabelmarginloss_reference(input,target)
torch.testing._internal.common_nn._multimarginloss_reference(input,target_idx,p,margin,weight)
torch.testing._internal.common_nn._rand_tensor_non_equal(*size)
torch.testing._internal.common_nn.bce_with_logistic_legacy_enum_test()
torch.testing._internal.common_nn.bce_with_logistic_no_reduce_scalar_test()
torch.testing._internal.common_nn.bce_with_logistic_no_reduce_test()
torch.testing._internal.common_nn.bceloss_no_reduce_scalar_test()
torch.testing._internal.common_nn.bceloss_no_reduce_test()
torch.testing._internal.common_nn.bceloss_weights_no_reduce_scalar_test()
torch.testing._internal.common_nn.bceloss_weights_no_reduce_test()
torch.testing._internal.common_nn.cosineembeddingloss_reference(input1,input2,target,margin=0,reduction='mean')
torch.testing._internal.common_nn.ctcloss_reference(log_probs,targets,input_lengths,target_lengths,blank=0,reduction='mean')
torch.testing._internal.common_nn.fractional_max_pool2d_test(test_case)
torch.testing._internal.common_nn.fractional_max_pool3d_test(test_case)
torch.testing._internal.common_nn.get_reduction(m)
torch.testing._internal.common_nn.get_weight(m)
torch.testing._internal.common_nn.hingeembeddingloss_margin_no_reduce_test()
torch.testing._internal.common_nn.hingeembeddingloss_no_reduce_test()
torch.testing._internal.common_nn.hingeembeddingloss_reference(input,target,margin=1.0,reduction='mean')
torch.testing._internal.common_nn.kldivloss_log_target_reference(input,target,reduction='mean')
torch.testing._internal.common_nn.kldivloss_no_reduce_log_target_test()
torch.testing._internal.common_nn.kldivloss_no_reduce_scalar_log_target_test()
torch.testing._internal.common_nn.kldivloss_no_reduce_scalar_test()
torch.testing._internal.common_nn.kldivloss_no_reduce_test()
torch.testing._internal.common_nn.kldivloss_reference(input,target,reduction='mean')
torch.testing._internal.common_nn.kldivloss_with_log_target_no_reduce_test()
torch.testing._internal.common_nn.kldivloss_with_target_no_reduce_test()
torch.testing._internal.common_nn.l1loss_no_reduce_scalar_test()
torch.testing._internal.common_nn.l1loss_no_reduce_test()
torch.testing._internal.common_nn.marginrankingloss_reference(input1,input2,target,margin=0,reduction='mean')
torch.testing._internal.common_nn.mseloss_no_reduce_scalar_test()
torch.testing._internal.common_nn.mseloss_no_reduce_test()
torch.testing._internal.common_nn.multilabelmarginloss_0d_no_reduce_test()
torch.testing._internal.common_nn.multilabelmarginloss_1d_no_reduce_test()
torch.testing._internal.common_nn.multilabelmarginloss_index_neg_test()
torch.testing._internal.common_nn.multilabelmarginloss_no_reduce_test()
torch.testing._internal.common_nn.multilabelmarginloss_reference(input,target,reduction='mean')
torch.testing._internal.common_nn.multilabelsoftmarginloss_no_reduce_test()
torch.testing._internal.common_nn.multilabelsoftmarginloss_weights_no_reduce_test()
torch.testing._internal.common_nn.multimarginloss_1d_input_0d_target_no_reduce_test()
torch.testing._internal.common_nn.multimarginloss_1d_no_reduce_test()
torch.testing._internal.common_nn.multimarginloss_margin_no_reduce_test()
torch.testing._internal.common_nn.multimarginloss_no_reduce_test()
torch.testing._internal.common_nn.multimarginloss_p_no_reduce_test()
torch.testing._internal.common_nn.multimarginloss_reference(input,target,p=1,margin=1,weight=None,reduction='mean')
torch.testing._internal.common_nn.multimarginloss_weights_no_reduce_test()
torch.testing._internal.common_nn.nllloss2d_no_reduce_ignore_index_test()
torch.testing._internal.common_nn.nllloss2d_no_reduce_test()
torch.testing._internal.common_nn.nllloss2d_no_reduce_weights_test()
torch.testing._internal.common_nn.nlllossNd_no_reduce_ignore_index_test()
torch.testing._internal.common_nn.nlllossNd_no_reduce_test()
torch.testing._internal.common_nn.nlllossNd_no_reduce_weights_test()
torch.testing._internal.common_nn.nlllossNd_reference(input,target,weight=None,ignore_index=-100,reduction='mean')
torch.testing._internal.common_nn.nllloss_no_reduce_ignore_index_test()
torch.testing._internal.common_nn.nllloss_no_reduce_test()
torch.testing._internal.common_nn.nllloss_no_reduce_weights_ignore_index_neg_test()
torch.testing._internal.common_nn.nllloss_no_reduce_weights_ignore_index_test()
torch.testing._internal.common_nn.nllloss_no_reduce_weights_test()
torch.testing._internal.common_nn.nllloss_reference(input,target,weight=None,ignore_index=-100,reduction='mean')
torch.testing._internal.common_nn.padding1d_circular(input,pad)
torch.testing._internal.common_nn.padding2d_circular(input,pad)
torch.testing._internal.common_nn.padding3d_circular(input,pad)
torch.testing._internal.common_nn.poissonnllloss_no_reduce_test()
torch.testing._internal.common_nn.smoothl1loss_beta_test()
torch.testing._internal.common_nn.smoothl1loss_no_reduce_scalar_test()
torch.testing._internal.common_nn.smoothl1loss_no_reduce_test()
torch.testing._internal.common_nn.smoothl1loss_reference(input,target,reduction='mean',beta=1.0)
torch.testing._internal.common_nn.smoothl1loss_zero_beta_test()
torch.testing._internal.common_nn.softmarginloss_no_reduce_test()
torch.testing._internal.common_nn.softmarginloss_reference(input,target,reduction='mean')
torch.testing._internal.common_nn.tripletmarginloss_reference(anchor,positive,negative,margin=1.0,p=2,eps=1e-06,swap=False,reduction='mean')
torch.testing._internal.common_nn.wrap_functional(fn,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_cuda.py----------------------------------------
A:torch.testing._internal.common_cuda.TEST_CUDA->torch.cuda.is_available()
A:torch.testing._internal.common_cuda.TEST_NUMBA_CUDA->numba.cuda.is_available()
A:torch.testing._internal.common_cuda.nargs->len(inspect.signature(f).parameters)
A:torch.testing._internal.common_cuda.cuda_version->str(torch.version.cuda)
torch.testing._internal.common_cuda._get_torch_cuda_version()
torch.testing._internal.common_cuda.initialize_cuda_context_rng()
torch.testing._internal.common_cuda.tf32_is_not_fp32()
torch.testing._internal.common_cuda.tf32_off()
torch.testing._internal.common_cuda.tf32_on(self,tf32_precision=1e-05)
torch.testing._internal.common_cuda.tf32_on_and_off(tf32_precision=1e-05)
torch.testing._internal.common_cuda.with_tf32_off(f)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_quantization.py----------------------------------------
A:torch.testing._internal.common_quantization.output->model(image)
A:torch.testing._internal.common_quantization._default_loss_fn->torch.nn.CrossEntropyLoss()
A:torch.testing._internal.common_quantization.optimizer->torch.optim.SGD(model_with_ddp.parameters(), lr=0.0001)
A:torch.testing._internal.common_quantization.loss->criterion(output, target)
A:torch.testing._internal.common_quantization.(_, predicted)->torch.max(output, 1)
A:torch.testing._internal.common_quantization.maxk->max(topk)
A:torch.testing._internal.common_quantization.batch_size->target.size(0)
A:torch.testing._internal.common_quantization.(_, pred)->model(image).topk(maxk, 1, True, True)
A:torch.testing._internal.common_quantization.pred->pred.t().t()
A:torch.testing._internal.common_quantization.correct->pred.t().t().eq(target.view(1, -1).expand_as(pred))
A:torch.testing._internal.common_quantization.correct_k->correct[:k].view(-1).float().sum(0, keepdim=True)
A:torch.testing._internal.common_quantization.start_time->time.time()
A:torch.testing._internal.common_quantization.(acc1, acc5)->accuracy(output, target, topk=(1, 5))
A:torch.testing._internal.common_quantization.prepared->prepare(original, qconfig_dict)
A:torch.testing._internal.common_quantization.X_init->torch.randint(X_value_min, X_value_max, (batch_size, in_channels) + input_feature_map_size)
A:torch.testing._internal.common_quantization.X_q->torch.quantize_per_tensor(X, scale=X_scale, zero_point=X_zero_point, dtype=torch.quint8)
A:torch.testing._internal.common_quantization.W_init->torch.randint(W_value_min, W_value_max, (out_channels, in_channels_per_group) + kernel_size)
A:torch.testing._internal.common_quantization.b_init->torch.randint(0, 10, (out_channels,))
A:torch.testing._internal.common_quantization.W_scales_tensor->torch.tensor(W_scale, dtype=torch.float)
A:torch.testing._internal.common_quantization.W_zero_points_tensor->torch.tensor(W_zero_point, dtype=torch.float)
A:torch.testing._internal.common_quantization.W_q->torch.quantize_per_tensor(W, scale=W_scale[0], zero_point=W_zero_point[0], dtype=torch.qint8)
A:torch.testing._internal.common_quantization.skip_if_no_torchvision->unittest.skipIf(not HAS_TORCHVISION, 'no torchvision')
A:torch.testing._internal.common_quantization.tt->torch.from_numpy(np.cumsum(tt, dtype=offset_type))
A:torch.testing._internal.common_quantization.propagate_qconfig_list->get_qconfig_propagation_list()
A:torch.testing._internal.common_quantization.model_dict->ref_model.state_dict()
A:torch.testing._internal.common_quantization.b->io.BytesIO()
A:torch.testing._internal.common_quantization.loaded_dict->torch.load(b)
A:torch.testing._internal.common_quantization.ref_out->ref_model(*x)
A:torch.testing._internal.common_quantization.load_out->loaded(*x)
A:torch.testing._internal.common_quantization.loaded->torch.load(b)
A:torch.testing._internal.common_quantization.weight->ref_model.get_weight()
A:torch.testing._internal.common_quantization.bias->ref_model.get_bias()
A:torch.testing._internal.common_quantization.scripted->torch.jit.script(orig_mod)
A:torch.testing._internal.common_quantization.traced->torch.jit.trace(orig_mod, calib_data[0])
A:torch.testing._internal.common_quantization.buffer->io.BytesIO()
A:torch.testing._internal.common_quantization.loaded_mod->torch.jit.load(buffer)
A:torch.testing._internal.common_quantization.ref_output->orig_mod(*inp)
A:torch.testing._internal.common_quantization.scripted_output->test_mod(*inp)
A:torch.testing._internal.common_quantization.module->module.eval().eval()
A:torch.testing._internal.common_quantization.model->get_script_module(module, tracing, inputs[0]).eval()
A:torch.testing._internal.common_quantization.models[d]->quantize_jit(model, qconfig_dict, test_only_eval_fn, [inputs_copy], inplace=False, debug=d)
A:torch.testing._internal.common_quantization.outputs[d]->models[d](*inputs[0])
A:torch.testing._internal.common_quantization.inputs_copy->copy.deepcopy(inputs)
A:torch.testing._internal.common_quantization.nodes_in_graph->dict()
A:torch.testing._internal.common_quantization.modules->dict(graph_module.named_modules())
A:torch.testing._internal.common_quantization.n->NodeSpec(node.op, type(modules[node.target]))
A:torch.testing._internal.common_quantization.node_info->' '.join(map(repr, [n.op, n.name, n.target, n.args, n.kwargs]))
A:torch.testing._internal.common_quantization.str_to_print->'\n'.join(node_infos)
A:torch.testing._internal.common_quantization.original->symbolic_trace(model)
A:torch.testing._internal.common_quantization.qgraph->convert(prepared)
A:torch.testing._internal.common_quantization.qgraph_debug->convert(prepared, debug=True)
A:torch.testing._internal.common_quantization.result->qgraph(*inputs)
A:torch.testing._internal.common_quantization.result_debug->qgraph_debug(*inputs)
A:torch.testing._internal.common_quantization.emb_dict->qemb.state_dict()
A:torch.testing._internal.common_quantization.emb_weight->embedding_unpack(emb_dict[key])
A:torch.testing._internal.common_quantization.loaded_weight->embedding_unpack(loaded_dict[key])
A:torch.testing._internal.common_quantization.loaded_qemb->torch.nn.quantized.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)
A:torch.testing._internal.common_quantization.float_embedding->torch.nn.Embedding(num_embeddings=num_embeddings, embedding_dim=embedding_dim)
A:torch.testing._internal.common_quantization.q_embeddingbag->torch.nn.quantized.Embedding.from_float(float_embedding)
A:torch.testing._internal.common_quantization.self.fc1->torch.nn.Linear(64, 10).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.x->self.dequant(x)
A:torch.testing._internal.common_quantization.self.qconfig->torch.quantization.get_default_qat_qconfig('qnnpack')
A:torch.testing._internal.common_quantization.self.mod->torch.nn.RNNCell(2, 2, nonlinearity='tanh').to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.lstm->torch.nn.LSTM(2, 2).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.(x, hid)->self.lstm(x, hid)
A:torch.testing._internal.common_quantization.self.conv->torch.nn.Conv2d(2, 2, 1, bias=None).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.quant->QuantStub()
A:torch.testing._internal.common_quantization.self.dequant->DeQuantStub()
A:torch.testing._internal.common_quantization.self.bn->torch.nn.BatchNorm2d(2).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.relu->torch.nn.ReLU(inplace=False).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.fc2->torch.nn.Linear(10, 10).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.subm->TwoLayerLinearModel()
A:torch.testing._internal.common_quantization.self.fc->torch.nn.Linear(5, 5)
A:torch.testing._internal.common_quantization.self.fc2.qconfig->torch.quantization.get_default_qconfig('fbgemm')
A:torch.testing._internal.common_quantization.self.hardswish->torch.nn.Hardswish().to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.elu->torch.nn.ELU().to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.layer_norm->torch.nn.LayerNorm(8)
A:torch.testing._internal.common_quantization.self.group_norm->torch.nn.GroupNorm(2, 8)
A:torch.testing._internal.common_quantization.self.instance_norm1d->torch.nn.InstanceNorm1d(8)
A:torch.testing._internal.common_quantization.self.instance_norm2d->torch.nn.InstanceNorm2d(8)
A:torch.testing._internal.common_quantization.self.instance_norm3d->torch.nn.InstanceNorm3d(8)
A:torch.testing._internal.common_quantization.self.sub1->SubModelForFusion()
A:torch.testing._internal.common_quantization.self.sub2->SubModelWithoutFusion()
A:torch.testing._internal.common_quantization.self.fc3->torch.nn.Linear(5, 5).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.sub2.fc1->QuantWrapper(self.sub2.fc1)
A:torch.testing._internal.common_quantization.custom_qconfig->QConfig(activation=default_observer.with_args(**custom_options), weight=default_weight_observer)
A:torch.testing._internal.common_quantization.self.sub2.fc2->QuantWrapper(self.sub2.fc2)
A:torch.testing._internal.common_quantization.self.relu1->torch.nn.ReLU()
A:torch.testing._internal.common_quantization.self.relu2->torch.nn.ReLU()
A:torch.testing._internal.common_quantization.named_children->list(self.named_children())
A:torch.testing._internal.common_quantization.self.sub->QuantWrapper(InnerModule())
A:torch.testing._internal.common_quantization.self.conv1->torch.nn.Conv2d(inplanes, inplanes, (1, 1), bias=False)
A:torch.testing._internal.common_quantization.self.bn1->norm_layer(inplanes)
A:torch.testing._internal.common_quantization.self.conv2->torch.nn.Conv2d(inplanes, inplanes, (1, 1), bias=False)
A:torch.testing._internal.common_quantization.self.bn2->torch.nn.BatchNorm2d(2).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.relu3->torch.nn.ReLU(inplace=True).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.conv3->torch.nn.Conv1d(3, 3, 2).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.bn3->torch.nn.BatchNorm1d(3).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.self.relu4->torch.nn.ReLU(inplace=True).to(dtype=torch.float)
A:torch.testing._internal.common_quantization.y->self.mycat.cat([x, x, x])
A:torch.testing._internal.common_quantization.self.features->torch.nn.Sequential(*layers)
A:torch.testing._internal.common_quantization.self.classifier->torch.nn.Sequential(*head)
A:torch.testing._internal.common_quantization.self.seq->torch.nn.Sequential()
A:torch.testing._internal.common_quantization.self.mycat->torch.nn.quantized.FloatFunctional()
A:torch.testing._internal.common_quantization.self.myadd->torch.nn.quantized.FloatFunctional()
A:torch.testing._internal.common_quantization.self.myadd_relu->torch.nn.quantized.FloatFunctional()
A:torch.testing._internal.common_quantization.z->self.myadd.add(y, y)
A:torch.testing._internal.common_quantization.w->self.myadd_relu.add_relu(z, z)
A:torch.testing._internal.common_quantization.self.downsample->torch.nn.Identity()
A:torch.testing._internal.common_quantization.self.myop->torch.nn.quantized.FloatFunctional()
A:torch.testing._internal.common_quantization.self.avgpool->torch.nn.AdaptiveAvgPool2d((4, 4))
A:torch.testing._internal.common_quantization.out->self.fc(out)
A:torch.testing._internal.common_quantization.identity->self.downsample(x)
A:torch.testing._internal.common_quantization.self.skip_add->torch.nn.quantized.FloatFunctional()
A:torch.testing._internal.common_quantization.self.cat->torch.nn.quantized.FloatFunctional()
A:torch.testing._internal.common_quantization.self.maxpool->torch.nn.MaxPool2d((4, 4))
A:torch.testing._internal.common_quantization.skip->self.conv2(x)
A:torch.testing._internal.common_quantization.self.emb->torch.nn.Embedding(num_embeddings=10, embedding_dim=12)
torch.testing._internal.common_quantization.ActivationsTestModel(self)
torch.testing._internal.common_quantization.ActivationsTestModel.__init__(self)
torch.testing._internal.common_quantization.ActivationsTestModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedConvBnModel(self)
torch.testing._internal.common_quantization.AnnotatedConvBnModel.__init__(self)
torch.testing._internal.common_quantization.AnnotatedConvBnModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel(self,qengine='fbgemm')
torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel.__init__(self,qengine='fbgemm')
torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedConvBnReLUModel.fuse_model(self)
torch.testing._internal.common_quantization.AnnotatedConvModel(self,qengine)
torch.testing._internal.common_quantization.AnnotatedConvModel.__init__(self,qengine)
torch.testing._internal.common_quantization.AnnotatedConvModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedConvTransposeModel(self,qengine)
torch.testing._internal.common_quantization.AnnotatedConvTransposeModel.__init__(self,qengine)
torch.testing._internal.common_quantization.AnnotatedConvTransposeModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel(self)
torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel.__init__(self)
torch.testing._internal.common_quantization.AnnotatedCustomConfigNestedModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedNestedModel(self,qengine)
torch.testing._internal.common_quantization.AnnotatedNestedModel.__init__(self,qengine)
torch.testing._internal.common_quantization.AnnotatedNestedModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel(self,qengine='fbgemm')
torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel.__init__(self,qengine='fbgemm')
torch.testing._internal.common_quantization.AnnotatedSingleLayerLinearModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedSkipQuantModel(self,qengine)
torch.testing._internal.common_quantization.AnnotatedSkipQuantModel.__init__(self,qengine)
torch.testing._internal.common_quantization.AnnotatedSkipQuantModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedSkipQuantModel.fuse_modules(self)
torch.testing._internal.common_quantization.AnnotatedSubNestedModel(self)
torch.testing._internal.common_quantization.AnnotatedSubNestedModel.__init__(self)
torch.testing._internal.common_quantization.AnnotatedSubNestedModel.forward(self,x)
torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel(self)
torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel.__init__(self)
torch.testing._internal.common_quantization.AnnotatedTwoLayerLinearModel.forward(self,x)
torch.testing._internal.common_quantization.AverageMeter(self,name,fmt=':f')
torch.testing._internal.common_quantization.AverageMeter.__init__(self,name,fmt=':f')
torch.testing._internal.common_quantization.AverageMeter.__str__(self)
torch.testing._internal.common_quantization.AverageMeter.reset(self)
torch.testing._internal.common_quantization.AverageMeter.update(self,val,n=1)
torch.testing._internal.common_quantization.ConvBNReLU(self)
torch.testing._internal.common_quantization.ConvBNReLU.__init__(self)
torch.testing._internal.common_quantization.ConvBnModel(self)
torch.testing._internal.common_quantization.ConvBnModel.__init__(self)
torch.testing._internal.common_quantization.ConvBnModel.forward(self,x)
torch.testing._internal.common_quantization.ConvModel(self)
torch.testing._internal.common_quantization.ConvModel.__init__(self)
torch.testing._internal.common_quantization.ConvModel.forward(self,x)
torch.testing._internal.common_quantization.ConvTransposeModel(self)
torch.testing._internal.common_quantization.ConvTransposeModel.__init__(self)
torch.testing._internal.common_quantization.ConvTransposeModel.forward(self,x)
torch.testing._internal.common_quantization.DummyObserver(torch.nn.Module)
torch.testing._internal.common_quantization.DummyObserver.calculate_qparams(self)
torch.testing._internal.common_quantization.DummyObserver.forward(self,x)
torch.testing._internal.common_quantization.EmbeddingBagModule(self)
torch.testing._internal.common_quantization.EmbeddingBagModule.__init__(self)
torch.testing._internal.common_quantization.EmbeddingBagModule.forward(self,indices,offsets,per_sample_weights)
torch.testing._internal.common_quantization.EmbeddingModule(self)
torch.testing._internal.common_quantization.EmbeddingModule.__init__(self)
torch.testing._internal.common_quantization.EmbeddingModule.forward(self,indices)
torch.testing._internal.common_quantization.EmbeddingWithLinear(self)
torch.testing._internal.common_quantization.EmbeddingWithLinear.__init__(self)
torch.testing._internal.common_quantization.EmbeddingWithLinear.forward(self,indices,linear_in)
torch.testing._internal.common_quantization.InnerModule(self)
torch.testing._internal.common_quantization.InnerModule.__init__(self)
torch.testing._internal.common_quantization.InnerModule.forward(self,x)
torch.testing._internal.common_quantization.InnerModule.fuse_modules(self)
torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel(self,qengine='fbgemm')
torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel.__init__(self,qengine='fbgemm')
torch.testing._internal.common_quantization.LSTMwithHiddenDynamicModel.forward(self,x,hid)
torch.testing._internal.common_quantization.LinearModelWithSubmodule(self)
torch.testing._internal.common_quantization.LinearModelWithSubmodule.__init__(self)
torch.testing._internal.common_quantization.LinearModelWithSubmodule.forward(self,x)
torch.testing._internal.common_quantization.LinearReluModel(self)
torch.testing._internal.common_quantization.LinearReluModel.__init__(self)
torch.testing._internal.common_quantization.LinearReluModel.forward(self,x)
torch.testing._internal.common_quantization.ManualConvLinearQATModel(self)
torch.testing._internal.common_quantization.ManualConvLinearQATModel.__init__(self)
torch.testing._internal.common_quantization.ManualConvLinearQATModel.forward(self,x)
torch.testing._internal.common_quantization.ManualLinearQATModel(self,qengine)
torch.testing._internal.common_quantization.ManualLinearQATModel.__init__(self,qengine)
torch.testing._internal.common_quantization.ManualLinearQATModel.forward(self,x)
torch.testing._internal.common_quantization.ModelForFusion(self,qconfig)
torch.testing._internal.common_quantization.ModelForFusion.__init__(self,qconfig)
torch.testing._internal.common_quantization.ModelForFusion.forward(self,x)
torch.testing._internal.common_quantization.ModelForFusionWithBias(self)
torch.testing._internal.common_quantization.ModelForFusionWithBias.__init__(self)
torch.testing._internal.common_quantization.ModelForFusionWithBias.forward(self,x)
torch.testing._internal.common_quantization.ModelMultipleOps(self)
torch.testing._internal.common_quantization.ModelMultipleOps.__init__(self)
torch.testing._internal.common_quantization.ModelMultipleOps.forward(self,x)
torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool(self)
torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool.__init__(self)
torch.testing._internal.common_quantization.ModelMultipleOpsNoAvgPool.forward(self,x)
torch.testing._internal.common_quantization.ModelWithFunctionals(self)
torch.testing._internal.common_quantization.ModelWithFunctionals.__init__(self)
torch.testing._internal.common_quantization.ModelWithFunctionals.forward(self,x)
torch.testing._internal.common_quantization.ModelWithSequentialFusion(self)
torch.testing._internal.common_quantization.ModelWithSequentialFusion.__init__(self)
torch.testing._internal.common_quantization.ModelWithSequentialFusion.forward(self,x)
torch.testing._internal.common_quantization.NestedModel(self)
torch.testing._internal.common_quantization.NestedModel.__init__(self)
torch.testing._internal.common_quantization.NestedModel.forward(self,x)
torch.testing._internal.common_quantization.NodeSpec(self,op,target)
torch.testing._internal.common_quantization.NodeSpec.__eq__(self,other)
torch.testing._internal.common_quantization.NodeSpec.__hash__(self)
torch.testing._internal.common_quantization.NodeSpec.__init__(self,op,target)
torch.testing._internal.common_quantization.NodeSpec.__repr__(self)
torch.testing._internal.common_quantization.NodeSpec.call_function(cls,target)
torch.testing._internal.common_quantization.NodeSpec.call_method(cls,target)
torch.testing._internal.common_quantization.NodeSpec.call_module(cls,target)
torch.testing._internal.common_quantization.NormalizationTestModel(self)
torch.testing._internal.common_quantization.NormalizationTestModel.__init__(self)
torch.testing._internal.common_quantization.NormalizationTestModel.forward(self,x)
torch.testing._internal.common_quantization.QuantStubModel(self)
torch.testing._internal.common_quantization.QuantStubModel.__init__(self)
torch.testing._internal.common_quantization.QuantStubModel.forward(self,x)
torch.testing._internal.common_quantization.QuantSubModel(self)
torch.testing._internal.common_quantization.QuantSubModel.__init__(self)
torch.testing._internal.common_quantization.QuantSubModel.forward(self,x)
torch.testing._internal.common_quantization.QuantizationTestCase(TestCase)
torch.testing._internal.common_quantization.QuantizationTestCase._checkModuleCorrectnessAgainstOrig(self,orig_mod,test_mod,calib_data)
torch.testing._internal.common_quantization.QuantizationTestCase._checkScriptable(self,orig_mod,script_mod,calib_data,check_save_load)
torch.testing._internal.common_quantization.QuantizationTestCase.checkDynamicQuantizedLSTM(self,mod,reference_module_type,dtype)
torch.testing._internal.common_quantization.QuantizationTestCase.checkDynamicQuantizedLinear(self,mod,dtype)
torch.testing._internal.common_quantization.QuantizationTestCase.checkDynamicQuantizedModule(self,mod,reference_module_type,dtype)
torch.testing._internal.common_quantization.QuantizationTestCase.checkEmbeddingSerialization(self,qemb,num_embeddings,embedding_dim,indices,offsets,set_qconfig,is_emb_bag)
torch.testing._internal.common_quantization.QuantizationTestCase.checkGraphModeFxOp(self,model,inputs,quant_type,expected_node=None,expected_node_occurrence=None,expected_node_list=None,debug=False,print_debug_info=False)
torch.testing._internal.common_quantization.QuantizationTestCase.checkGraphModeOp(self,module,inputs,quantized_op,tracing=False,debug=False,check=True,eval_mode=True,dynamic=False,qconfig=None)
torch.testing._internal.common_quantization.QuantizationTestCase.checkGraphModuleNodes(self,graph_module,expected_node=None,expected_node_occurrence=None,expected_node_list=None)
torch.testing._internal.common_quantization.QuantizationTestCase.checkHasPrepModules(self,module)
torch.testing._internal.common_quantization.QuantizationTestCase.checkLinear(self,mod)
torch.testing._internal.common_quantization.QuantizationTestCase.checkNoPrepModules(self,module)
torch.testing._internal.common_quantization.QuantizationTestCase.checkNoQconfig(self,module)
torch.testing._internal.common_quantization.QuantizationTestCase.checkObservers(self,module,propagate_qconfig_list=None)
torch.testing._internal.common_quantization.QuantizationTestCase.checkQuantDequant(self,mod)
torch.testing._internal.common_quantization.QuantizationTestCase.checkQuantizedLinear(self,mod)
torch.testing._internal.common_quantization.QuantizationTestCase.checkScriptable(self,orig_mod,calib_data,check_save_load=False)
torch.testing._internal.common_quantization.QuantizationTestCase.checkWrappedQuantizedLinear(self,mod)
torch.testing._internal.common_quantization.QuantizationTestCase.check_eager_serialization(self,ref_model,loaded_model,x)
torch.testing._internal.common_quantization.QuantizationTestCase.check_weight_bias_api(self,ref_model,weight_keys,bias_keys)
torch.testing._internal.common_quantization.QuantizationTestCase.printGraphModule(self,graph_module,print_str=True)
torch.testing._internal.common_quantization.QuantizationTestCase.setUp(self)
torch.testing._internal.common_quantization.RNNCellDynamicModel(self,mod_type)
torch.testing._internal.common_quantization.RNNCellDynamicModel.__init__(self,mod_type)
torch.testing._internal.common_quantization.RNNCellDynamicModel.forward(self,x)
torch.testing._internal.common_quantization.RNNDynamicModel(self,mod_type)
torch.testing._internal.common_quantization.RNNDynamicModel.__init__(self,mod_type)
torch.testing._internal.common_quantization.RNNDynamicModel.forward(self,x)
torch.testing._internal.common_quantization.ResNetBase(self)
torch.testing._internal.common_quantization.ResNetBase.__init__(self)
torch.testing._internal.common_quantization.ResNetBase.forward(self,x)
torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel(self,qengine='fbgemm')
torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel.__init__(self,qengine='fbgemm')
torch.testing._internal.common_quantization.SingleLayerLinearDynamicModel.forward(self,x)
torch.testing._internal.common_quantization.SingleLayerLinearModel(self)
torch.testing._internal.common_quantization.SingleLayerLinearModel.__init__(self)
torch.testing._internal.common_quantization.SingleLayerLinearModel.forward(self,x)
torch.testing._internal.common_quantization.SkipQuantModel(self)
torch.testing._internal.common_quantization.SkipQuantModel.__init__(self)
torch.testing._internal.common_quantization.SkipQuantModel.forward(self,x)
torch.testing._internal.common_quantization.SkipQuantModel.fuse_modules(self)
torch.testing._internal.common_quantization.SubModelForFusion(self)
torch.testing._internal.common_quantization.SubModelForFusion.__init__(self)
torch.testing._internal.common_quantization.SubModelForFusion.forward(self,x)
torch.testing._internal.common_quantization.SubModelWithoutFusion(self)
torch.testing._internal.common_quantization.SubModelWithoutFusion.__init__(self)
torch.testing._internal.common_quantization.SubModelWithoutFusion.forward(self,x)
torch.testing._internal.common_quantization.TwoLayerLinearModel(self)
torch.testing._internal.common_quantization.TwoLayerLinearModel.__init__(self)
torch.testing._internal.common_quantization.TwoLayerLinearModel.forward(self,x)
torch.testing._internal.common_quantization._make_conv_test_input(batch_size,in_channels_per_group,input_feature_map_size,out_channels_per_group,groups,kernel_size,X_scale,X_zero_point,W_scale,W_zero_point,use_bias,use_channelwise)
torch.testing._internal.common_quantization.accuracy(output,target,topk=(1,))
torch.testing._internal.common_quantization.convert_dynamic(module)
torch.testing._internal.common_quantization.ddp_cleanup()
torch.testing._internal.common_quantization.ddp_setup(rank,world_size)
torch.testing._internal.common_quantization.get_script_module(model,tracing,data)
torch.testing._internal.common_quantization.lengths_to_offsets(t,offset_type=np.int64,use_begin_offset=True)
torch.testing._internal.common_quantization.prepare_dynamic(model,qconfig_dict=None)
torch.testing._internal.common_quantization.run_ddp(rank,world_size,prepared)
torch.testing._internal.common_quantization.skipIfNoFBGEMM(fn)
torch.testing._internal.common_quantization.test_only_eval_fn(model,calib_data)
torch.testing._internal.common_quantization.test_only_train_fn(model,train_data,loss_fn=_default_loss_fn)
torch.testing._internal.common_quantization.train_one_epoch(model,criterion,optimizer,data_loader,device,ntrain_batches)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_methods_invocations.py----------------------------------------
A:torch.testing._internal.common_methods_invocations.index->torch.LongTensor(*shape)
A:torch.testing._internal.common_methods_invocations.result->torch.randn(dim_size, dim_size, dim_size)
A:torch.testing._internal.common_methods_invocations.v->maybe_non_contig(arg).detach().to(device=device).clone()
A:torch.testing._internal.common_methods_invocations.non_differentiable->collections.namedtuple('non_differentiable', ['tensor'])
A:torch.testing._internal.common_methods_invocations.NO_ARGS->NoArgsClass()
A:torch.testing._internal.common_methods_invocations.var->torch.randn((), dtype=dtype, device=device)
A:torch.testing._internal.common_methods_invocations.arg->arg.to(torch.cdouble).to(torch.cdouble)
A:torch.testing._internal.common_methods_invocations.args_out->tuple((map_arg(arg) for arg in call_args))
A:torch.testing._internal.common_methods_invocations.l->torch.ones(3, 3, dtype=torch.long, device=device, layout=torch.strided).tril(0).nonzero().transpose(0, 1)
A:torch.testing._internal.common_methods_invocations.x->torch.ones(3, 3, dtype=torch.long, device=device, layout=torch.strided)
A:torch.testing._internal.common_methods_invocations.u->torch.ones(3, 3, dtype=torch.long, device=device, layout=torch.strided).triu(0).nonzero().transpose(0, 1)
torch.testing._internal.common_methods_invocations.NoArgsClass(object)
torch.testing._internal.common_methods_invocations.NoArgsClass.__iter__(self)
torch.testing._internal.common_methods_invocations.NoArgsClass.__len__(self)
torch.testing._internal.common_methods_invocations.NoArgsClass.__next__(self)
torch.testing._internal.common_methods_invocations.OpInfo(self,name,*,op=None,dtypes=floating_types(),dtypesIfCPU=None,dtypesIfCUDA=None,dtypesIfROCM=None,test_inplace_grad=True,supports_tensor_out=True,skips=tuple(),decorators=None)
torch.testing._internal.common_methods_invocations.OpInfo.__init__(self,name,*,op=None,dtypes=floating_types(),dtypesIfCPU=None,dtypesIfCUDA=None,dtypesIfROCM=None,test_inplace_grad=True,supports_tensor_out=True,skips=tuple(),decorators=None)
torch.testing._internal.common_methods_invocations.OpInfo.get_inplace(self)
torch.testing._internal.common_methods_invocations.OpInfo.get_method(self)
torch.testing._internal.common_methods_invocations.OpInfo.get_op(self)
torch.testing._internal.common_methods_invocations.OpInfo.sample_inputs(self,device,dtype,requires_grad=False)
torch.testing._internal.common_methods_invocations.OpInfo.should_skip(self,cls_name,test_name,device_type,dtype)
torch.testing._internal.common_methods_invocations.OpInfo.supports_dtype(self,dtype,device_type)
torch.testing._internal.common_methods_invocations.SampleInput(self,input,*,args=tuple(),kwargs=None)
torch.testing._internal.common_methods_invocations.SampleInput.__init__(self,input,*,args=tuple(),kwargs=None)
torch.testing._internal.common_methods_invocations.SkipInfo(self,cls_name=None,test_name=None,*,device_type=None,dtypes=None,active_if=True)
torch.testing._internal.common_methods_invocations.SkipInfo.__init__(self,cls_name=None,test_name=None,*,device_type=None,dtypes=None,active_if=True)
torch.testing._internal.common_methods_invocations.UnaryUfuncInfo(self,name,*,ref,dtypes=floating_types(),dtypesIfCPU=floating_and_complex_types_and(torch.bfloat16),dtypesIfCUDA=floating_and_complex_types_and(torch.half),dtypesIfROCM=floating_types_and(torch.half),domain=(None,None),handles_large_floats=True,handles_extremals=True,handles_complex_extremals=True,**kwargs)
torch.testing._internal.common_methods_invocations.UnaryUfuncInfo.__init__(self,name,*,ref,dtypes=floating_types(),dtypesIfCPU=floating_and_complex_types_and(torch.bfloat16),dtypesIfCUDA=floating_and_complex_types_and(torch.half),dtypesIfROCM=floating_types_and(torch.half),domain=(None,None),handles_large_floats=True,handles_extremals=True,handles_complex_extremals=True,**kwargs)
torch.testing._internal.common_methods_invocations.UnaryUfuncInfo.sample_inputs(self,device,dtype,requires_grad=False)
torch.testing._internal.common_methods_invocations._compare_large_trilu_indices(self,row,col,offset=0,dtype=torch.long,device='cpu')
torch.testing._internal.common_methods_invocations._compare_trilu_indices(self,row,col,offset=0,dtype=torch.long,device='cpu')
torch.testing._internal.common_methods_invocations.bernoulli_scalar()
torch.testing._internal.common_methods_invocations.create_input(call_args,requires_grad=True,non_contiguous=False,call_kwargs=None,dtype=torch.double,device=None)
torch.testing._internal.common_methods_invocations.dont_convert(tuple)
torch.testing._internal.common_methods_invocations.exclude_tensor_method(name,test_name)
torch.testing._internal.common_methods_invocations.gather_variable(shape,index_dim,max_indices,duplicate=False)
torch.testing._internal.common_methods_invocations.ident(x)
torch.testing._internal.common_methods_invocations.index_perm_variable(shape,max_indices)
torch.testing._internal.common_methods_invocations.index_variable(shape,max_indices)
torch.testing._internal.common_methods_invocations.mask_not_all_zeros(shape)
torch.testing._internal.common_methods_invocations.method_tests()
torch.testing._internal.common_methods_invocations.normal_scalar_clamp(amin,amax,requires_grad=False)
torch.testing._internal.common_methods_invocations.prod_zeros(dim_size,dim_select)
torch.testing._internal.common_methods_invocations.run_additional_tri_tests(self,device)
torch.testing._internal.common_methods_invocations.uniform_scalar(offset=0,requires_grad=False)
torch.testing._internal.common_methods_invocations.unpack_variables(args)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/jit_utils.py----------------------------------------
A:torch.testing._internal.jit_utils.RUN_CUDA->torch.cuda.is_available()
A:torch.testing._internal.jit_utils.CUDA_VERSION->torch._C._cuda_getCompiledVersion()
A:torch.testing._internal.jit_utils.torch.jit._recursive.concrete_type_store->torch.jit._recursive.ConcreteTypeStore()
A:torch.testing._internal.jit_utils.execution_plans->list(graph_executor_state.execution_plans.values())
A:torch.testing._internal.jit_utils.num_plans->len(execution_plans)
A:torch.testing._internal.jit_utils.self.stringio->StringIO()
A:torch.testing._internal.jit_utils.se->str(e)
A:torch.testing._internal.jit_utils.archive->zipfile.ZipFile(buffer)
A:torch.testing._internal.jit_utils.files->list(filter(lambda x: x.startswith('archive/code/'), archive.namelist()))
A:torch.testing._internal.jit_utils.code_files_str->filter(lambda x: x.endswith('.py'), files)
A:torch.testing._internal.jit_utils.code_files_stream->map(lambda f: archive.open(f), code_files_str)
A:torch.testing._internal.jit_utils.code_files->map(lambda file: ''.join([line.decode() for line in file]), code_files_stream)
A:torch.testing._internal.jit_utils.debug_files_str->filter(lambda f: f.endswith('.debug_pkl'), files)
A:torch.testing._internal.jit_utils.debug_files_stream->map(lambda f: archive.open(f), debug_files_str)
A:torch.testing._internal.jit_utils.debug_files->map(lambda f: pickle.load(f), debug_files_stream)
A:torch.testing._internal.jit_utils.buffer->io.BytesIO()
A:torch.testing._internal.jit_utils.buffer_copy->io.BytesIO().getvalue()
A:torch.testing._internal.jit_utils.(code_files, debug_files)->extract_files(buffer)
A:torch.testing._internal.jit_utils.buffer2->io.BytesIO(buffer_copy)
A:torch.testing._internal.jit_utils.imported->torch.jit.load(buffer, map_location=map_location)
A:torch.testing._internal.jit_utils.saved_module_buffer_2->io.BytesIO()
A:torch.testing._internal.jit_utils.(code_files_2, debug_files_2)->extract_files(saved_module_buffer_2)
A:torch.testing._internal.jit_utils.f->tempfile.NamedTemporaryFile(delete=False)
A:torch.testing._internal.jit_utils.result->getattr(torch._C, '_jit_pass_' + name)(graph)
A:torch.testing._internal.jit_utils.strgraph->str(graph)
A:torch.testing._internal.jit_utils.out_nodes->nodes(graph)
A:torch.testing._internal.jit_utils.g->torch.onnx._optimize_trace(g, operator_export_type=OperatorExportTypes.ONNX)
A:torch.testing._internal.jit_utils.graph->trace.graph()
A:torch.testing._internal.jit_utils.diff_nodes->trace.graph().findAllNodes('prim::DifferentiableGraph')
A:torch.testing._internal.jit_utils.fusion_nodes->list(chain.from_iterable([g.findAllNodes('prim::FusionGroup') for g in diff_subgraphs]))
A:torch.testing._internal.jit_utils.frame->self.get_frame_vars(frames_up)
A:torch.testing._internal.jit_utils.source->textwrap.dedent(inspect.getsource(script))
A:torch.testing._internal.jit_utils.cu->torch.jit.CompilationUnit(script, _frames_up=frames_up)
A:torch.testing._internal.jit_utils.ge->self.getExportImportCopy(ge)
A:torch.testing._internal.jit_utils.state->model.get_debug_state()
A:torch.testing._internal.jit_utils.plan->get_execution_plan(state)
A:torch.testing._internal.jit_utils.num_bailouts->get_execution_plan(state).code.num_bailouts()
A:torch.testing._internal.jit_utils.bailout_outputs->model(*inputs)
A:torch.testing._internal.jit_utils.scripted_fn->torch.jit.script(script, _frames_up=1)
A:torch.testing._internal.jit_utils.recording_inputs->do_input_map(lambda t: Variable(t, requires_grad=True), reference_tensors)
A:torch.testing._internal.jit_utils.script_outputs->scripted_fn(*recording_inputs)
A:torch.testing._internal.jit_utils.opt_script_outputs->scripted_fn(*recording_inputs)
A:torch.testing._internal.jit_utils.python_outputs->python_fn(*inputs)
A:torch.testing._internal.jit_utils.flattened_recording_inputs->flatten_inputs(recording_inputs)
A:torch.testing._internal.jit_utils.outputs->func(*recording_inputs)
A:torch.testing._internal.jit_utils.outputs_ge->ge(*recording_inputs)
A:torch.testing._internal.jit_utils.grads->torch.autograd.grad(l1, flattened_recording_inputs, create_graph=True, allow_unused=allow_unused)
A:torch.testing._internal.jit_utils.grads_ge->torch.autograd.grad(l1_ge, flattened_recording_inputs, create_graph=True, allow_unused=allow_unused)
A:torch.testing._internal.jit_utils.l1->allSum(outputs)
A:torch.testing._internal.jit_utils.grads2->torch.autograd.grad(l2, flattened_recording_inputs, allow_unused=allow_unused)
A:torch.testing._internal.jit_utils.l1_ge->allSum(outputs_ge)
A:torch.testing._internal.jit_utils.grads2_ge->torch.autograd.grad(l2_ge, flattened_recording_inputs, allow_unused=allow_unused)
A:torch.testing._internal.jit_utils.m->self.createFunctionFromGraph(trace)
A:torch.testing._internal.jit_utils.m_import->self.getExportImportCopy(m)
A:torch.testing._internal.jit_utils.a->self.runAndSaveRNG(m, inputs)
A:torch.testing._internal.jit_utils.b->self.runAndSaveRNG(m_import, inputs)
A:torch.testing._internal.jit_utils.results->func(*inputs, **kwargs)
A:torch.testing._internal.jit_utils.sm->torch.jit.script(nn_module)
A:torch.testing._internal.jit_utils.eager_out->nn_module(*args)
A:torch.testing._internal.jit_utils.script_out->sm(*args)
A:torch.testing._internal.jit_utils.old->torch._C._jit_get_inline_everything_mode()
A:torch.testing._internal.jit_utils.r->torch.autograd.grad(f, *args)
torch.testing._internal.jit_utils.JitTestCase(TestCase)
torch.testing._internal.jit_utils.JitTestCase._compared_saved_loaded(self,m)
torch.testing._internal.jit_utils.JitTestCase._isHookExceptionOk(self,e)
torch.testing._internal.jit_utils.JitTestCase.assertAutodiffNode(self,graph,should_autodiff_node,nonfusible_nodes,fusible_nodes)
torch.testing._internal.jit_utils.JitTestCase.assertExpectedGraph(self,trace,*args,**kwargs)
torch.testing._internal.jit_utils.JitTestCase.assertExpectedONNXGraph(self,g,*args,**kwargs)
torch.testing._internal.jit_utils.JitTestCase.assertExportImport(self,trace,inputs)
torch.testing._internal.jit_utils.JitTestCase.assertExportImportModule(self,m,inputs)
torch.testing._internal.jit_utils.JitTestCase.assertGraphContains(self,graph,kind)
torch.testing._internal.jit_utils.JitTestCase.assertGraphContainsExactly(self,graph,kind,num_kind_nodes,consider_subgraphs=False)
torch.testing._internal.jit_utils.JitTestCase.assertRaisesRegexWithHighlight(self,exception,regex,highlight)
torch.testing._internal.jit_utils.JitTestCase.capture_stdout(list)
torch.testing._internal.jit_utils.JitTestCase.capture_stdout.__enter__(self)
torch.testing._internal.jit_utils.JitTestCase.capture_stdout.__exit__(self,*args)
torch.testing._internal.jit_utils.JitTestCase.checkBailouts(self,model,inputs,expected)
torch.testing._internal.jit_utils.JitTestCase.checkModule(self,nn_module,args)
torch.testing._internal.jit_utils.JitTestCase.checkScript(self,script,inputs,name='func',optimize=True,inputs_requires_grad=False,capture_output=False,frames_up=1,profiling=ProfilingMode.PROFILING)
torch.testing._internal.jit_utils.JitTestCase.checkScriptRaisesRegex(self,script,inputs,exception,regex,outputs=None,capture_output=False,profiling=ProfilingMode.PROFILING)
torch.testing._internal.jit_utils.JitTestCase.checkTrace(self,func,reference_tensors,input_tensors=None,drop=None,allow_unused=False,verbose=False,inputs_require_grads=True,check_tolerance=1e-05,export_import=True,_force_outplace=False)
torch.testing._internal.jit_utils.JitTestCase.clearHooks(self)
torch.testing._internal.jit_utils.JitTestCase.createFunctionFromGraph(self,trace)
torch.testing._internal.jit_utils.JitTestCase.emitFunctionHook(self,func)
torch.testing._internal.jit_utils.JitTestCase.emitModuleHook(self,module)
torch.testing._internal.jit_utils.JitTestCase.getExportImportCopy(self,m,also_test_file=True,map_location=None)
torch.testing._internal.jit_utils.JitTestCase.getExportImportCopyWithPacking(self,m,also_test_file=True,map_location=None)
torch.testing._internal.jit_utils.JitTestCase.get_frame_vars(self,frames_up)
torch.testing._internal.jit_utils.JitTestCase.runAndSaveRNG(self,func,inputs,kwargs=None)
torch.testing._internal.jit_utils.JitTestCase.run_pass(self,name,trace)
torch.testing._internal.jit_utils.JitTestCase.setHooks(self)
torch.testing._internal.jit_utils.JitTestCase.setUp(self)
torch.testing._internal.jit_utils.JitTestCase.tearDown(self)
torch.testing._internal.jit_utils._AssertRaisesRegexWithHighlightContext(self,test_case,exception,regex,highlight)
torch.testing._internal.jit_utils._AssertRaisesRegexWithHighlightContext.__enter__(self)
torch.testing._internal.jit_utils._AssertRaisesRegexWithHighlightContext.__exit__(self,type,value,traceback)
torch.testing._internal.jit_utils._AssertRaisesRegexWithHighlightContext.__init__(self,test_case,exception,regex,highlight)
torch.testing._internal.jit_utils._inline_everything(fn)
torch.testing._internal.jit_utils._tmp_donotuse_dont_inline_everything(fn)
torch.testing._internal.jit_utils._trace(*args,**kwargs)
torch.testing._internal.jit_utils.attrs_with_prefix(module,prefix)
torch.testing._internal.jit_utils.clear_class_registry()
torch.testing._internal.jit_utils.disable_autodiff_subgraph_inlining(enabled=True)
torch.testing._internal.jit_utils.do_input_map(fn,input)
torch.testing._internal.jit_utils.enable_cpu_fuser(fn)
torch.testing._internal.jit_utils.enable_cpu_fuser_if(cond)
torch.testing._internal.jit_utils.execWrapper(code,glob,loc)
torch.testing._internal.jit_utils.get_execution_plan(graph_executor_state)
torch.testing._internal.jit_utils.get_forward(c)
torch.testing._internal.jit_utils.get_forward_graph(c)
torch.testing._internal.jit_utils.get_module_method(m,module,method)
torch.testing._internal.jit_utils.inline_everything_mode(should_inline)
torch.testing._internal.jit_utils.warmup_backward(f,*args)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/te_utils.py----------------------------------------
A:torch.testing._internal.te_utils.self.start_value->self.try_get_trigger_value()
A:torch.testing._internal.te_utils.value->self.try_get_trigger_value()
torch.testing._internal.te_utils.CudaCodeGenCreated(self)
torch.testing._internal.te_utils.CudaCodeGenCreated.__init__(self)
torch.testing._internal.te_utils.CudaCodeGenExecuted(self)
torch.testing._internal.te_utils.CudaCodeGenExecuted.__init__(self)
torch.testing._internal.te_utils.ExecutionCounter(self,name)
torch.testing._internal.te_utils.ExecutionCounter.__init__(self,name)
torch.testing._internal.te_utils.ExecutionCounter.elapsed_value(self)
torch.testing._internal.te_utils.ExecutionCounter.try_get_trigger_value(self)
torch.testing._internal.te_utils.LLVMCodeGenCreated(self)
torch.testing._internal.te_utils.LLVMCodeGenCreated.__init__(self)
torch.testing._internal.te_utils.LLVMCodeGenExecuted(self)
torch.testing._internal.te_utils.LLVMCodeGenExecuted.__init__(self)
torch.testing._internal.te_utils.SimpleIREvalExecuted(self)
torch.testing._internal.te_utils.SimpleIREvalExecuted.__init__(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_device_type.py----------------------------------------
A:torch.testing._internal.common_device_type._tls->threading.local()
A:torch.testing._internal.common_device_type.test_name->_construct_test_name(name, op, cls.device_type, dtype)
A:torch.testing._internal.common_device_type.test_wrapper->decorator(test_wrapper)
A:torch.testing._internal.common_device_type.device_arg->cls.get_all_devices()
A:torch.testing._internal.common_device_type.self.precision->self._get_precision_override(test_fn, dtype)
A:torch.testing._internal.common_device_type.result->test_fn(self, *args)
A:torch.testing._internal.common_device_type.dtypes->cls._get_dtypes(test)
A:torch.testing._internal.common_device_type.primary_device_idx->int(cls.get_primary_device().split(':')[1])
A:torch.testing._internal.common_device_type.num_devices->torch.cuda.device_count()
A:torch.testing._internal.common_device_type.prim_device->cls.get_primary_device()
A:torch.testing._internal.common_device_type.t->torch.ones(1).cuda()
A:torch.testing._internal.common_device_type.cls.primary_device->'cuda:{0}'.format(torch.cuda.current_device())
A:torch.testing._internal.common_device_type._TORCH_TEST_DEVICES->os.environ.get('TORCH_TEST_DEVICES', None)
A:torch.testing._internal.common_device_type.mod->runpy.run_path(path, init_globals=globals())
A:torch.testing._internal.common_device_type.empty_class->type(empty_name, generic_test_class.__bases__, {})
A:torch.testing._internal.common_device_type.test->getattr(generic_test_class, name)
A:torch.testing._internal.common_device_type.sig->inspect.signature(device_type_test_class.instantiate_test)
A:torch.testing._internal.common_device_type.nontest->getattr(generic_test_class, name)
A:torch.testing._internal.common_device_type.reason->'cuDNN version {0} is available but {1} required'.format(self.cudnn_version, version)
A:torch.testing._internal.common_device_type.self.device_type->kwargs.get('device_type', 'all')
A:torch.testing._internal.common_device_type.d->getattr(fn, 'dtypes', {})
A:torch.testing._internal.common_device_type.deterministic_restore->torch.is_deterministic()
torch.testing._internal.common_device_type.CPUTestBase(DeviceTypeTestBase)
torch.testing._internal.common_device_type.CUDATestBase(DeviceTypeTestBase)
torch.testing._internal.common_device_type.CUDATestBase.get_all_devices(cls)
torch.testing._internal.common_device_type.CUDATestBase.get_primary_device(cls)
torch.testing._internal.common_device_type.CUDATestBase.has_cudnn(self)
torch.testing._internal.common_device_type.CUDATestBase.setUpClass(cls)
torch.testing._internal.common_device_type.DeviceTypeTestBase(TestCase)
torch.testing._internal.common_device_type.DeviceTypeTestBase._get_dtypes(cls,test)
torch.testing._internal.common_device_type.DeviceTypeTestBase._get_precision_override(self,test,dtype)
torch.testing._internal.common_device_type.DeviceTypeTestBase.get_all_devices(cls)
torch.testing._internal.common_device_type.DeviceTypeTestBase.get_primary_device(cls)
torch.testing._internal.common_device_type.DeviceTypeTestBase.instantiate_test(cls,name,test,*,generic_cls=None)
torch.testing._internal.common_device_type.DeviceTypeTestBase.precision(self)
torch.testing._internal.common_device_type.DeviceTypeTestBase.precision(self,prec)
torch.testing._internal.common_device_type._construct_test_name(test_name,op,device_type,dtype)
torch.testing._internal.common_device_type._has_sufficient_memory(device,size)
torch.testing._internal.common_device_type.deviceCountAtLeast(self,num_required_devices)
torch.testing._internal.common_device_type.deviceCountAtLeast.__init__(self,num_required_devices)
torch.testing._internal.common_device_type.dtypes(self,*args,**kwargs)
torch.testing._internal.common_device_type.dtypes.__init__(self,*args,**kwargs)
torch.testing._internal.common_device_type.dtypesIfCPU(self,*args)
torch.testing._internal.common_device_type.dtypesIfCPU.__init__(self,*args)
torch.testing._internal.common_device_type.dtypesIfCUDA(self,*args)
torch.testing._internal.common_device_type.dtypesIfCUDA.__init__(self,*args)
torch.testing._internal.common_device_type.expectedAlertNondeterministic(self,caller_name,device_type=None,fn_has_device_arg=True)
torch.testing._internal.common_device_type.expectedAlertNondeterministic.__init__(self,caller_name,device_type=None,fn_has_device_arg=True)
torch.testing._internal.common_device_type.expectedFailure(self,device_type)
torch.testing._internal.common_device_type.expectedFailure.__init__(self,device_type)
torch.testing._internal.common_device_type.expectedFailureCUDA(fn)
torch.testing._internal.common_device_type.instantiate_device_type_tests(generic_test_class,scope,except_for=None,only_for=None)
torch.testing._internal.common_device_type.largeCUDATensorTest(size)
torch.testing._internal.common_device_type.largeTensorTest(size)
torch.testing._internal.common_device_type.onlyCPU(fn)
torch.testing._internal.common_device_type.onlyCUDA(fn)
torch.testing._internal.common_device_type.onlyOn(self,device_type)
torch.testing._internal.common_device_type.onlyOn.__init__(self,device_type)
torch.testing._internal.common_device_type.onlyOnCPUAndCUDA(fn)
torch.testing._internal.common_device_type.ops(self,op_list,*,unsupported_dtypes_only=False)
torch.testing._internal.common_device_type.ops.__init__(self,op_list,*,unsupported_dtypes_only=False)
torch.testing._internal.common_device_type.precisionOverride(self,d)
torch.testing._internal.common_device_type.precisionOverride.__init__(self,d)
torch.testing._internal.common_device_type.skipCPUIf(self,dep,reason)
torch.testing._internal.common_device_type.skipCPUIf.__init__(self,dep,reason)
torch.testing._internal.common_device_type.skipCPUIfNoLapack(fn)
torch.testing._internal.common_device_type.skipCPUIfNoMkl(fn)
torch.testing._internal.common_device_type.skipCUDAIf(self,dep,reason)
torch.testing._internal.common_device_type.skipCUDAIf.__init__(self,dep,reason)
torch.testing._internal.common_device_type.skipCUDAIfCudnnVersionLessThan(version=0)
torch.testing._internal.common_device_type.skipCUDAIfNoCudnn(fn)
torch.testing._internal.common_device_type.skipCUDAIfNoMagma(fn)
torch.testing._internal.common_device_type.skipCUDAIfNotRocm(fn)
torch.testing._internal.common_device_type.skipCUDAIfRocm(fn)
torch.testing._internal.common_device_type.skipIf(self,dep,reason,device_type=None)
torch.testing._internal.common_device_type.skipIf.__init__(self,dep,reason,device_type=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/common_quantized.py----------------------------------------
A:torch.testing._internal.common_quantized.qx->numpy.clip(qx, qmin, qmax).astype(qtype)
A:torch.testing._internal.common_quantized.X->X.numpy().numpy()
A:torch.testing._internal.common_quantized.min_val->min(min_val, 0.0)
A:torch.testing._internal.common_quantized.max_val->max(max_val, 0.0)
A:torch.testing._internal.common_quantized.scale->numpy.zeros(X.shape[0], dtype=np.float64)
A:torch.testing._internal.common_quantized.zero_point->numpy.zeros(X.shape[0], dtype=np.int64)
A:torch.testing._internal.common_quantized.scale[i]->max(scale[i], np.finfo(np.float32).eps)
A:torch.testing._internal.common_quantized.zero_point[i]->min(qmax, zero_point[i])
torch.testing._internal.common_quantized._calculate_dynamic_per_channel_qparams(X,dtype)
torch.testing._internal.common_quantized._calculate_dynamic_qparams(X,dtype,reduce_range=False)
torch.testing._internal.common_quantized._conv_output_shape(input_size,kernel_size,padding,stride,dilation,output_padding=0)
torch.testing._internal.common_quantized._dequantize(qx,scale,zero_point)
torch.testing._internal.common_quantized._quantize(x,scale,zero_point,qmin=None,qmax=None,dtype=np.uint8)
torch.testing._internal.common_quantized._requantize(x,multiplier,zero_point,qmin=0,qmax=255,qtype=np.uint8)
torch.testing._internal.common_quantized.override_qengines(qfunction)
torch.testing._internal.common_quantized.override_quantized_engine(qengine)
torch.testing._internal.common_quantized.qengine_is_fbgemm()
torch.testing._internal.common_quantized.qengine_is_qnnpack()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/generated/annotated_fn_args.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/generated/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/distributed_test.py----------------------------------------
A:torch.testing._internal.distributed.distributed_test.f->Foo(10)
A:torch.testing._internal.distributed.distributed_test.skipIfNoTorchVision->unittest.skipIf(not HAS_TORCHVISION, 'no torchvision')
A:torch.testing._internal.distributed.distributed_test.INIT_METHOD->os.getenv('INIT_METHOD', 'env://')
A:torch.testing._internal.distributed.distributed_test.self.fc->torch.nn.Linear(10, 50, bias=True)
A:torch.testing._internal.distributed.distributed_test.x->cls(test_name).fc2(x)
A:torch.testing._internal.distributed.distributed_test.self.fc1->torch.nn.Linear(2, 40, bias=False)
A:torch.testing._internal.distributed.distributed_test.self.fc2->torch.nn.Linear(40, 4, bias=False)
A:torch.testing._internal.distributed.distributed_test.self.fc3->torch.nn.Linear(50, 4, bias=False)
A:torch.testing._internal.distributed.distributed_test.self.relu->torch.nn.ReLU()
A:torch.testing._internal.distributed.distributed_test.self.no_grad_param->torch.nn.Parameter(torch.tensor([2, 2]).long(), requires_grad=False)
A:torch.testing._internal.distributed.distributed_test.self.p->torch.nn.Parameter(torch.ones(2, 2))
A:torch.testing._internal.distributed.distributed_test.self.bn->torch.nn.BatchNorm1d(4)
A:torch.testing._internal.distributed.distributed_test.DDP_NET->Net()
A:torch.testing._internal.distributed.distributed_test.BN_NET->BatchNormNet()
A:torch.testing._internal.distributed.distributed_test.ONLY_SBN_NET->torch.nn.SyncBatchNorm(2, momentum=0.99)
A:torch.testing._internal.distributed.distributed_test.backends->map(lambda b: dist.Backend(b), backends)
A:torch.testing._internal.distributed.distributed_test.lockfile->os.path.join(TEMP_DIR, 'lockfile')
A:torch.testing._internal.distributed.distributed_test.barrier_dir->os.path.join(os.environ['TEMP_DIR'], 'barrier')
A:torch.testing._internal.distributed.distributed_test.wait_for->torch.distributed.get_world_size()
A:torch.testing._internal.distributed.distributed_test.pid->str(os.getpid())
A:torch.testing._internal.distributed.distributed_test.barrier_file->os.path.join(barrier_dir, pid)
A:torch.testing._internal.distributed.distributed_test.start_time->time.time()
A:torch.testing._internal.distributed.distributed_test.data->Foo(10).read()
A:torch.testing._internal.distributed.distributed_test.os.environ['MASTER_ADDR']->str(MASTER_ADDR)
A:torch.testing._internal.distributed.distributed_test.os.environ['MASTER_PORT']->str(MASTER_PORT)
A:torch.testing._internal.distributed.distributed_test.self->cls(test_name)
A:torch.testing._internal.distributed.distributed_test.group_id->torch.distributed.ProcessGroupNCCL(store, rank, size, opts)
A:torch.testing._internal.distributed.distributed_test.rank->torch.distributed.get_rank()
A:torch.testing._internal.distributed.distributed_test.group->torch.distributed.new_group([0, 1])
A:torch.testing._internal.distributed.distributed_test.nGPUs->torch.cuda.device_count()
A:torch.testing._internal.distributed.distributed_test.world_size->torch.distributed.get_world_size()
A:torch.testing._internal.distributed.distributed_test.visible_devices->range(nGPUs)
A:torch.testing._internal.distributed.distributed_test.lines->net(inp).getvalue().splitlines()
A:torch.testing._internal.distributed.distributed_test.line->format_line(var)
A:torch.testing._internal.distributed.distributed_test.test_dir->os.path.join(os.environ['TEMP_DIR'], 'test_dir')
A:torch.testing._internal.distributed.distributed_test.num_processes->torch.distributed.get_world_size()
A:torch.testing._internal.distributed.distributed_test.all_ranks->set()
A:torch.testing._internal.distributed.distributed_test.backend_str->BACKEND.lower()
A:torch.testing._internal.distributed.distributed_test.backend->BACKEND.lower()
A:torch.testing._internal.distributed.distributed_test.(_, group_id, _)->cls(test_name)._init_full_group_test(timeout=timeout)
A:torch.testing._internal.distributed.distributed_test.local_rank->torch.distributed.get_rank(group_id)
A:torch.testing._internal.distributed.distributed_test.timeout->timedelta(seconds=1)
A:torch.testing._internal.distributed.distributed_test.(group, group_id, rank)->cls(test_name)._init_global_test()
A:torch.testing._internal.distributed.distributed_test.group_rank->torch.distributed.get_rank(group_id)
A:torch.testing._internal.distributed.distributed_test.tensor->tensor.cuda(rank_to_GPU[rank][0]).cuda(rank_to_GPU[rank][0])
A:torch.testing._internal.distributed.distributed_test.expected_tensor->torch.tensor(inp[self.rank % 2]).to(self.rank).clone()
A:torch.testing._internal.distributed.distributed_test.output_tensor->_build_tensor(10, value=-1)
A:torch.testing._internal.distributed.distributed_test.recv_ranks->set()
A:torch.testing._internal.distributed.distributed_test.sender->torch.distributed.recv(output_tensor)
A:torch.testing._internal.distributed.distributed_test.opts->AllreduceOptions()
A:torch.testing._internal.distributed.distributed_test.rank_to_GPU->cls(test_name)._init_multigpu_helper()
A:torch.testing._internal.distributed.distributed_test.(group, _, rank)->cls(test_name)._init_global_test()
A:torch.testing._internal.distributed.distributed_test.new_port->str(MASTER_PORT + 1)
A:torch.testing._internal.distributed.distributed_test.gen_iterator->torch.distributed.rendezvous('env://', rank, dist.get_world_size())
A:torch.testing._internal.distributed.distributed_test.(store, rank, size)->next(gen_iterator)
A:torch.testing._internal.distributed.distributed_test.store->torch.distributed.PrefixStore(new_port, store)
A:torch.testing._internal.distributed.distributed_test.work->torch.distributed.ProcessGroupNCCL(store, rank, size, opts).allreduce([tensor], opts)
A:torch.testing._internal.distributed.distributed_test.result->torch.distributed.ProcessGroupNCCL(store, rank, size, opts).allreduce([tensor], opts).result()
A:torch.testing._internal.distributed.distributed_test.tests->simple_sparse_reduce_tests(rank, dist.get_world_size(), num_inputs=1)
A:torch.testing._internal.distributed.distributed_test.(master_values, worker_values, expected_values)->test_case_func(len(group))
A:torch.testing._internal.distributed.distributed_test.tensors->list(map(tensors, lambda t: t.cuda(rank_to_GPU[rank][0])))
A:torch.testing._internal.distributed.distributed_test.one->torch.ones([1])
A:torch.testing._internal.distributed.distributed_test.size->len(group)
A:torch.testing._internal.distributed.distributed_test.in_tensor->in_tensor.cuda(rank_to_GPU[rank][0]).cuda(rank_to_GPU[rank][0])
A:torch.testing._internal.distributed.distributed_test.out_tensor->out_tensor.cuda(rank_to_GPU[rank][0]).cuda(rank_to_GPU[rank][0])
A:torch.testing._internal.distributed.distributed_test.expected_time->expected_time.cuda(rank_to_GPU[rank][0]).cuda(rank_to_GPU[rank][0])
A:torch.testing._internal.distributed.distributed_test.tensors[0]->torch.tensor(inp[self.rank % 2]).to(self.rank).clone().cuda(device=rank_to_GPU[rank][0])
A:torch.testing._internal.distributed.distributed_test.input_cpu->torch.randn(global_bs, 2)
A:torch.testing._internal.distributed.distributed_test.target->torch.randn(global_bs, 2)
A:torch.testing._internal.distributed.distributed_test.loss->net(inp).sum()
A:torch.testing._internal.distributed.distributed_test.output->model(input_var)
A:torch.testing._internal.distributed.distributed_test.model_DDP->torch.nn.parallel.DistributedDataParallel(model_DDP, device_ids=gpus)
A:torch.testing._internal.distributed.distributed_test.saved_model->torch.load(tmp_file)
A:torch.testing._internal.distributed.distributed_test.model_gpu->copy.deepcopy(model)
A:torch.testing._internal.distributed.distributed_test.local_bs->len(gpu_subset)
A:torch.testing._internal.distributed.distributed_test.(global_bs, input_cpu, target, loss)->cls(test_name)._prepare_dummy_data(local_bs)
A:torch.testing._internal.distributed.distributed_test.stream->torch.cuda.Stream(self.rank)
A:torch.testing._internal.distributed.distributed_test.net->torch.nn.parallel.DistributedDataParallel(model.cuda(devices[0]), device_ids=devices, process_group=group)
A:torch.testing._internal.distributed.distributed_test.batch->torch.tensor([rank]).float().cuda(rank)
A:torch.testing._internal.distributed.distributed_test.avg->grad.clone()
A:torch.testing._internal.distributed.distributed_test.gpus->list(map(lambda i: torch.device('cuda:' + str(i)), gpus))
A:torch.testing._internal.distributed.distributed_test.bs_offset->int((rank + 3) * rank / 2)
A:torch.testing._internal.distributed.distributed_test.global_bs->int((num_processes + 3) * num_processes / 2)
A:torch.testing._internal.distributed.distributed_test.model->torch.nn.Linear(1, 1, bias=False)
A:torch.testing._internal.distributed.distributed_test.input_var_rank->torch.cat([torch.ones(2, 1, 10 ** (i + 1)) * 0.1 ** (i - 1), torch.ones(2, 1, 10 ** (i + 1)) * 0.3 ** (i - 1)], dim=1)
A:torch.testing._internal.distributed.distributed_test.all_input_var->torch.cat([x.permute(1, 0, 2).contiguous().view(ONLY_SBN_NET.num_features, -1) for x in input_var], dim=1).cuda(rank)
A:torch.testing._internal.distributed.distributed_test.y->model(input_var[rank].cuda(rank))
A:torch.testing._internal.distributed.distributed_test.process_group->torch.distributed.new_group([process_ids])
A:torch.testing._internal.distributed.distributed_test.res50_model->torchvision.models.resnet50()
A:torch.testing._internal.distributed.distributed_test.res50_model_sync->torch.nn.SyncBatchNorm.convert_sync_batchnorm(copy.deepcopy(res50_model), process_group)
A:torch.testing._internal.distributed.distributed_test.input_tensor->torch.tensor(inp[self.rank % 2]).to(self.rank)
A:torch.testing._internal.distributed.distributed_test.input_tensor_copy->torch.tensor(inp[self.rank % 2]).to(self.rank).clone()
A:torch.testing._internal.distributed.distributed_test.expected->torch.tensor([False, False]).to(self.rank)
A:torch.testing._internal.distributed.distributed_test.bcast_tensor->torch.tensor([random.random() < 0.5 if self.rank == 0 else False for _ in range(tensor_size)]).to(self.rank)
A:torch.testing._internal.distributed.distributed_test.dist_sampler->DistributedSampler(dataset=dataset, drop_last=True)
A:torch.testing._internal.distributed.distributed_test.indices_list->list(iter(dist_sampler_added_samples))
A:torch.testing._internal.distributed.distributed_test.dist_sampler_added_samples->DistributedSampler(dataset=dataset)
A:torch.testing._internal.distributed.distributed_test.my_rank->torch.distributed.get_rank()
A:torch.testing._internal.distributed.distributed_test.b->Bar()
A:torch.testing._internal.distributed.distributed_test.net_module_states->list(net.module.state_dict().values())
A:torch.testing._internal.distributed.distributed_test.new_model->torch.nn.Linear(dim, dim, bias=False).cuda(rank)
A:torch.testing._internal.distributed.distributed_test.net.module->copy.deepcopy(new_model)
A:torch.testing._internal.distributed.distributed_test.expected_states->torch.nn.Linear(dim, dim, bias=False).cuda(rank).state_dict().values()
A:torch.testing._internal.distributed.distributed_test.effective_ws->torch.distributed.get_world_size()
A:torch.testing._internal.distributed.distributed_test.inp->torch.rand(1, 10)
A:torch.testing._internal.distributed.distributed_test.local_model->local_model.cuda(self.rank).cuda(self.rank)
A:torch.testing._internal.distributed.distributed_test.local_iters->sum(rank_to_iter_mapping.values())
A:torch.testing._internal.distributed.distributed_test.local_optim->torch.optim.SGD(local_model.parameters(), lr=learning_rate)
A:torch.testing._internal.distributed.distributed_test.out->net(inp)
A:torch.testing._internal.distributed.distributed_test.ddp_optim->torch.optim.SGD(model.parameters(), lr=learning_rate * dist.get_world_size())
A:torch.testing._internal.distributed.distributed_test.context->suppress()
A:torch.testing._internal.distributed.distributed_test.final_rank_tensor->torch.tensor([net._authoritative_rank], device=self.rank)
A:torch.testing._internal.distributed.distributed_test.large_model->torch.nn.Sequential(nn.Conv2d(1, 20, 5), nn.ReLU(), nn.Conv2d(20, 32, 5), nn.ReLU(), nn.Conv2d(32, 256, 5), nn.ReLU())
A:torch.testing._internal.distributed.distributed_test.small_model->torch.nn.Linear(dim, dim, bias=False)
A:torch.testing._internal.distributed.distributed_test.bn_net->BatchNormNet()
A:torch.testing._internal.distributed.distributed_test.self.t0->Task()
A:torch.testing._internal.distributed.distributed_test.self.t1->Task()
A:torch.testing._internal.distributed.distributed_test.unjoined_rank_with_unused_params_model->UnusedParamModule(1)
A:torch.testing._internal.distributed.distributed_test.joined_rank_with_unused_params_model->UnusedParamModule(0)
A:torch.testing._internal.distributed.distributed_test.resnet_model->torchvision.models.resnet50()
A:torch.testing._internal.distributed.distributed_test.self.param->torch.nn.Parameter(torch.ones(1, requires_grad=True))
A:torch.testing._internal.distributed.distributed_test.exception_module->ExceptionModule()
A:torch.testing._internal.distributed.distributed_test.self.net1->torch.nn.Linear(10, 10, bias=False)
A:torch.testing._internal.distributed.distributed_test.self.net2->torch.nn.Linear(10, 10, bias=False)
A:torch.testing._internal.distributed.distributed_test.ddp->torch.nn.parallel.DistributedDataParallel(ToyModel().cuda(self.rank), device_ids=[self.rank])
torch.testing._internal.distributed.distributed_test.Barrier(object)
torch.testing._internal.distributed.distributed_test.Barrier.init(cls)
torch.testing._internal.distributed.distributed_test.Barrier.sync(cls,wait_for=None,timeout=10)
torch.testing._internal.distributed.distributed_test.BatchNormNet(self)
torch.testing._internal.distributed.distributed_test.BatchNormNet.__init__(self)
torch.testing._internal.distributed.distributed_test.BatchNormNet.forward(self,x)
torch.testing._internal.distributed.distributed_test.DistributedTest
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._all_reduce_coalesced_max_test_cases(group_size)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._all_reduce_coalesced_min_test_cases(group_size)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._all_reduce_coalesced_product_test_cases(group_size)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._all_reduce_coalesced_sum_test_cases(group_size)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._assert_equal_param(self,param_gpu,param_DDP)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._barrier(self,*args,**kwargs)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._init_full_group_test(self,**kwargs)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._init_global_test(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._init_group_test(self,**kwargs)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._init_multigpu_helper(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._model_step(self,model)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._model_step_with_zero_grad(self,model)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._prepare_dummy_data(self,local_bs)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._run_all_gather_coalesced_and_verify(self,output_tensor_lists,input_tensors,expected_tensors,group_id)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._run_reduction_test(self,tensor,expected_tensor,op,reduction_fn=dist.all_reduce,dst=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._run_uneven_inputs_test(self,test_case,iteration_mapping,find_unused_params)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_DDP_5iter(self,model_base,model_DDP,input,target,loss,local_bs,rank,batch_size,test_save,offset=None,world_size=0,zero_grad=False)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_DDP_helper(self,model,input_var,target,loss,scale_factor=1.0)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_DistributedDataParallel(self,gpu_subset,rank,output_device=None,gradient_as_bucket_view=False)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_DistributedDataParallelCPU(self,gradient_as_bucket_view=False)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_DistributedDataParallel_SyncBatchNorm(self,gpu_subset,rank,local_bs,global_bs,offset,output_device=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_gather_coalesced_helper(self,group,group_id,rank)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_gather_helper(self,group,group_id,rank,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_gather_multigpu_helper(self,group,group_id,rank,rank_to_GPU)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_reduce_coalesced_helper(self,group,group_id,rank,op,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_reduce_helper(self,group,group_id,rank,op,master_value,worker_value,expected_value,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_reduce_multigpu_helper(self,group,group_id,rank,rank_to_GPU,op,master_value,worker_value,expected_value)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_to_all_helper(self,group,group_id,rank)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_to_all_single_equal_split_helper(self,group,group_id,rank,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_all_to_all_single_unequal_split_helper(self,group,group_id,rank,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_barrier_helper(self,group,group_id,rank,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_barrier_timeout(self,group_id,timeout)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_broadcast_helper(self,group,group_id,rank,cuda=False,rank_to_GPU=None,with_options=False)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_broadcast_multigpu_helper(self,group,group_id,rank,rank_to_GPU)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_gather_helper(self,group,group_id,rank)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_group_override_backend(self,initializer)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_reduce_helper(self,group,group_id,rank,op,master_value,worker_value,expected_value,cuda=False,rank_to_GPU=None)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_reduce_multigpu_helper(self,group,group_id,rank,rank_to_GPU,op,master_value,worker_value,expected_value)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_scatter_helper(self,group,group_id,rank)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase._test_sparse_all_reduce_sum(self,fn)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_Backend_enum_class(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallelCPU(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallelCPU_grad_is_view(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_SyncBatchNorm(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_SyncBatchNorm_2D_Input(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_Running_Value(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_SyncBatchNorm_Diff_Input_Sizes_gradient(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_SyncBatchNorm_Single_Input_Per_Process(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_non_default_stream(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_requires_grad(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedDataParallel_with_grad_is_view(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_DistributedSampler_padding(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_SyncBatchNorm_process_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_coalesced_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_coalesced_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_coalesced_simple(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_coalesced_with_empty(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_gather_multigpu(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_full_group_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_full_group_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_full_group_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_full_group_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_group_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_group_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_group_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_group_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_coalesced_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_full_group_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_full_group_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_full_group_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_full_group_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_group_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_group_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_group_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_group_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_multigpu(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_result_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_reduce_sum_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_equal_split(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_equal_split_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_equal_split_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_equal_split_full_group_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_equal_split_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_equal_split_group_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_unequal_split(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_unequal_split_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_unequal_split_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_unequal_split_full_group_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_unequal_split_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_all_to_all_single_unequal_split_group_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_allgather_object(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_backend_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_backend_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_full_group_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_group_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_timeout_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_timeout_global(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_barrier_timeout_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_broadcast(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_broadcast_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_broadcast_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_broadcast_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_broadcast_multigpu(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_broadcast_object_list(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_grad_div_uneven_inputs(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_join_model_equivalence(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_sync_params_and_buffers(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_input_exception(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_input_join_disable(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_uneven_inputs_replicated_error(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_ddp_unused_params_rebuild_buckets_exception(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_destroy_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_destroy_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_dump_DDP_relevant_env_vars(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_gather(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_gather_checks(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_gather_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_gather_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_gather_object(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_get_backend(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_get_rank(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_get_rank_size_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_get_rank_size_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_irecv(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_isend(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_nccl_backend_bool_allgather(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_nccl_backend_bool_allreduce(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_nccl_backend_bool_broadcast(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_nccl_backend_bool_reduce(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_nccl_gather_object_err(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_nccl_high_priority_stream(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_full_group_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_full_group_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_full_group_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_full_group_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_group_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_group_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_group_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_group_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_max(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_min(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_multigpu(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_product(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_reduce_sum_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_scatter(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_scatter_checks(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_scatter_full_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_scatter_group(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_send_recv(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_send_recv_any_source(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_send_recv_with_tag(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_sparse_all_reduce_sum(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.test_sparse_all_reduce_sum_cuda(self)
torch.testing._internal.distributed.distributed_test.DistributedTest._DistTestBase.validate_net_equivalence(self,net)
torch.testing._internal.distributed.distributed_test.Foo(self,x)
torch.testing._internal.distributed.distributed_test.Foo.__eq__(self,other)
torch.testing._internal.distributed.distributed_test.Foo.__init__(self,x)
torch.testing._internal.distributed.distributed_test.Net(self)
torch.testing._internal.distributed.distributed_test.Net.__init__(self)
torch.testing._internal.distributed.distributed_test.Net.forward(self,x)
torch.testing._internal.distributed.distributed_test.Task(self)
torch.testing._internal.distributed.distributed_test.Task.__init__(self)
torch.testing._internal.distributed.distributed_test.Task.forward(self,x)
torch.testing._internal.distributed.distributed_test.TestDistBackend(MultiProcessTestCase)
torch.testing._internal.distributed.distributed_test.TestDistBackend._run(cls,rank,test_name,file_name)
torch.testing._internal.distributed.distributed_test.TestDistBackend.init_method(self)
torch.testing._internal.distributed.distributed_test.TestDistBackend.setUp(self)
torch.testing._internal.distributed.distributed_test.TestDistBackend.setUpClass(cls)
torch.testing._internal.distributed.distributed_test.TestDistBackend.tearDown(self)
torch.testing._internal.distributed.distributed_test.TestDistBackend.world_size(self)
torch.testing._internal.distributed.distributed_test._FC2(self)
torch.testing._internal.distributed.distributed_test._FC2.__init__(self)
torch.testing._internal.distributed.distributed_test._FC2.forward(self,x)
torch.testing._internal.distributed.distributed_test._build_multidim_tensor(dim,dim_size,value=None)
torch.testing._internal.distributed.distributed_test._build_tensor(size,value=None,dtype=torch.float)
torch.testing._internal.distributed.distributed_test._captured_output()
torch.testing._internal.distributed.distributed_test._lock()
torch.testing._internal.distributed.distributed_test.apply_hack_for_nccl()
torch.testing._internal.distributed.distributed_test.get_timeout(test_id)
torch.testing._internal.distributed.distributed_test.require_backend(backends)
torch.testing._internal.distributed.distributed_test.require_backends_available(backends)
torch.testing._internal.distributed.distributed_test.require_world_size(world_size)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc_utils.py----------------------------------------
A:torch.testing._internal.distributed.rpc_utils.FORK->auto()
A:torch.testing._internal.distributed.rpc_utils.SPAWN->auto()
A:torch.testing._internal.distributed.rpc_utils.class_->type(name, (test_class, mixin, mp_helper), dict())
torch.testing._internal.distributed.rpc_utils.ForkHelper(MultiProcessTestCase)
torch.testing._internal.distributed.rpc_utils.ForkHelper.setUp(self)
torch.testing._internal.distributed.rpc_utils.MultiProcess(Flag)
torch.testing._internal.distributed.rpc_utils.SpawnHelper(MultiProcessTestCase)
torch.testing._internal.distributed.rpc_utils.SpawnHelper.setUp(self)
torch.testing._internal.distributed.rpc_utils.generate_tests(prefix:str,mixin:Type[RpcAgentTestFixture],tests:List[Type[RpcAgentTestFixture]],mp_type_filter:MultiProcess,module_name:str)->Dict[str, Type[RpcAgentTestFixture]]


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/ddp_under_dist_autograd_test.py----------------------------------------
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.TRAINER_RANKS->list(range(NUM_TRAINERS))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.NONE->enum.auto()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.OUTSIDE->enum.auto()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.INSIDE->enum.auto()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.logger->logging.getLogger(__name__)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.console->logging.StreamHandler()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.formatter->logging.Formatter('%(asctime)s %(filename)s:%(lineno)s %(levelname)s p:%(processName)s t:%(threadName)s: %(message)s')
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.gLogger->init_logger()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.args_tup->tuple([method, rref] + list(args))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.self.em->torch.nn.EmbeddingBag(num_embeddings, embedding_dim, _weight=torch.Tensor([init_em] * num_embeddings))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.l->torch.nn.Linear(d_in, d_out, bias=False)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.w->torch.ones((d_out, d_in))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.self.fc->getLinear(d_in, d_out)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.self.relu->torch.nn.ReLU()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.self.fc1->getLinear(D_DENSE, D_DENSE)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.self.fc2->DistributedDataParallel(self.fc2, check_reduction=True, process_group=process_group_for_ddp)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.sparse->_remote_method(RemoteEM.forward, self.remote_em_rref, input.sparse_features)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.dense->self.fc1(input.dense_features)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.x->_remote_method(RemoteNet.forward, self.remote_net_rref, x)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.self.hybrid_module->DistributedDataParallel(self.hybrid_module, check_reduction=True, process_group=self.trainer_group)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.dense_microbatch->torch.split(dense_features, 2)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.sparse_microbatch->torch.split(sparse_features, 2)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.values_microbatch->torch.split(values, 2)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.feature_set->FeatureSet(dense_features=d, sparse_features=s, values=v)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.output->self.hybrid_module.forward(b)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.loss->ddp_layer4(remote_layer3(ddp_layer2(remote_layer1(inputs).cuda(self.rank)).cpu()).cuda(self.rank)).sum()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.grads_dict->torch.distributed.autograd.get_gradients(context_id)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.training_examples->get_training_examples()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.training_examples.dense_features[idx, :]->torch.Tensor((x, y))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.examples_per_trainer->int(n / NUM_TRAINERS)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.shutdown_signal->threading.Condition()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.remote_em_rref->torch.distributed.rpc.remote(self.remote_worker_name(), RemoteEM, args=(NUM_EM_ROW, D_SPARSE))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.remote_net_rref->torch.distributed.rpc.remote(self.remote_worker_name(), RemoteNet, args=(D_DENSE + D_SPARSE, D_HID))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.trainer->self.trainer_name(rank)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.num_trainers->len(trainer_rrefs)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.(ddp_grads, non_ddp_grads)->future.wait()
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.net->torch.nn.Linear(2, 3)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.ddp_net->DistributedDataParallel(net)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.model->torch.nn.EmbeddingBag(10, 3, sparse=True)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.ddp_model->DistributedDataParallel(layer2)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.input->torch.LongTensor(10).random_(0, 10)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.offsets->torch.LongTensor([0, 4])
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.remote_layer1->RemoteModule('worker0', device='cpu', module_cls=nn.Linear, args=(10, 7, False))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.layer1->torch.nn.Linear(10, 7, False)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.layer2->torch.nn.Linear(7, 5).cuda(self.rank)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.inputs->torch.rand((10, 10))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.ddp_layer2->DistributedDataParallel(layer2, device_ids=[self.rank])
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.remote_layer3->RemoteModule('worker0', device='cpu', module_cls=nn.Linear, args=(5, 3, False))
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.layer3->torch.nn.Linear(5, 3, False)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.layer4->torch.nn.Linear(3, 1).cuda(self.rank)
A:torch.testing._internal.distributed.ddp_under_dist_autograd_test.ddp_layer4->DistributedDataParallel(layer4, device_ids=[self.rank])
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest(RpcAgentTestFixture)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest._run_test_ddp_comparision(self,simulate_uneven_inputs=False)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.get_remote_grads(rref,context_id)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.test_ddp_comparison(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.test_ddp_comparison_uneven_inputs(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.test_ddp_dist_autograd_local_vs_remote(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.test_ddp_dist_autograd_local_vs_remote_gpu(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.test_ddp_dist_autograd_sparse_grads(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.trainer_name(self,rank)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpComparisonTest.world_size(self)->int
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpMode(enum.Enum)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest(RpcAgentTestFixture)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest._do_test(self,ddp_mode,simulate_uneven_inputs=False)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest._master_process(self,ddp_mode:DdpMode,simulate_uneven_inputs:bool)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest._remote_worker_process(self,ddp_mode)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest._trainer_process(self,rank:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.do_test_on_master(self,ddp_mode:DdpMode,simulate_uneven_inputs:bool,remote_em_rref:rpc.RRef,remote_net_rref:rpc.RRef)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.remote_worker_name(self)->str
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.test_backward_ddp_inside(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.test_backward_ddp_outside(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.test_backward_ddp_outside_uneven_inputs(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.test_backward_no_ddp(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.trainer_name(self,rank)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.DdpUnderDistAutogradTest.world_size(self)->int
torch.testing._internal.distributed.ddp_under_dist_autograd_test.FeatureSet(NamedTuple)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel(self,remote_em_rref:rpc.RRef,remote_net_rref:rpc.RRef,process_group_for_ddp:dist.ProcessGroup=None)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel.__init__(self,remote_em_rref:rpc.RRef,remote_net_rref:rpc.RRef,process_group_for_ddp:dist.ProcessGroup=None)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.HybridModel.forward(self,input:FeatureSet)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteEM(self,num_embeddings:int,embedding_dim:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteEM.__init__(self,num_embeddings:int,embedding_dim:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteEM.forward(self,input:torch.Tensor)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet(self,d_in:int,d_out:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet.__init__(self,d_in:int,d_out:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.RemoteNet.forward(self,input:torch.Tensor)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer(self,remote_em_rref:rpc.RRef,remote_net_rref:rpc.RRef,ddp_mode:DdpMode,rank:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer.__init__(self,remote_em_rref:rpc.RRef,remote_net_rref:rpc.RRef,ddp_mode:DdpMode,rank:int)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer.destroy_pg(self)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.Trainer.train_batch(self,mini_batch:FeatureSet,trainer_has_less_inputs:bool,simulate_uneven_inputs:bool)
torch.testing._internal.distributed.ddp_under_dist_autograd_test._call_method(method,rref,*args,**kwargs)
torch.testing._internal.distributed.ddp_under_dist_autograd_test._remote_method(method,rref,*args,**kwargs)
torch.testing._internal.distributed.ddp_under_dist_autograd_test._remote_method_async(method,rref,*args,**kwargs)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.getLinear(d_in,d_out)
torch.testing._internal.distributed.ddp_under_dist_autograd_test.get_training_examples()
torch.testing._internal.distributed.ddp_under_dist_autograd_test.init_logger()
torch.testing._internal.distributed.ddp_under_dist_autograd_test.set_shutdown_signal()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/tensorpipe_rpc_agent_test_fixture.py----------------------------------------
torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture.get_shutdown_error_regex(self)
torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture.get_timeout_error_regex(self)
torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture.rpc_backend(self)
torch.testing._internal.distributed.rpc.tensorpipe_rpc_agent_test_fixture.TensorPipeRpcAgentTestFixture.rpc_backend_options(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/dist_autograd_test.py----------------------------------------
A:torch.testing._internal.distributed.rpc.dist_autograd_test.known_context_ids->set()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.requires_grad_tensor->torch.ones(3, 3, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.grads->torch.distributed.autograd.get_gradients(context_id)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.ret->self._verify_backwards(exec_mode, [t6.sum()], context_id, local_grads, t1, t2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t1->torch.ones(3, 3, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.start->time.time()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.context_id_to_raised->set()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.fut->torch.distributed.rpc.rpc_async(worker_name(dst), method, args=args)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.send_functions->torch.distributed.autograd._current_context()._send_functions()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t2->torch.zeros(3, 3, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.ctx->torch.distributed.autograd._current_context()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.recv_functions->torch.distributed.autograd._current_context()._recv_functions()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.dst_rank->self._next_rank()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.worker_ids->torch.distributed.autograd._current_context()._known_worker_ids()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.success->_all_contexts_cleaned_up()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.loss->torch.distributed.rpc.remote(dst, DistAutogradTest._slow_add, args=(t1, t2)).to_here().sum()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.send_event->get_event('SendRpcBackward')
A:torch.testing._internal.distributed.rpc.dist_autograd_test.recv_event->get_event('RecvRpcBackward')
A:torch.testing._internal.distributed.rpc.dist_autograd_test.backward_event->get_event('torch::distributed::autograd::backward')
A:torch.testing._internal.distributed.rpc.dist_autograd_test.nargs->len(args)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.loss_local->torch.add(t1, t2).sum()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.local_ret->torch.add(t1, t2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.rref_t1->torch.distributed.rpc.remote(worker_name(self.rank), create_ref_fn, args=())
A:torch.testing._internal.distributed.rpc.dist_autograd_test.rref->torch.distributed.rpc.remote(dst, DistAutogradTest._slow_add, args=(t1, t2))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.callee->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.rref_owner->worker_name((self.rank + 2) % self.world_size)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.local_t1->torch.distributed.rpc.remote(worker_name(self.rank), create_ref_fn, args=()).to_here()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t3->self._exec_func(exec_mode, torch.add, t2, t2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t4->torch.distributed.rpc.rpc_sync('worker0', torch.mul, args=(t2, t3))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t5->self._exec_func(exec_mode, torch.add, t4.cpu(), t2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.val->torch.distributed.rpc.rpc_sync(worker_name(self._next_rank()), torch.div, args=(val, t2))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.s1->self._exec_func(exec_mode, torch.stack, (t4, val))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.s2->self._exec_func(exec_mode, torch.stack, (t5, val))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.s->self._exec_func(exec_mode, torch.stack, (t1, t2, t3))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t->torch.rand(10, 10, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.tensor_list->self._exec_func(exec_mode, torch.split, t, 2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.res->torch.distributed.rpc.rpc_sync(worker_name(dst), DistAutogradTest._call_remote_embedding, args=(remote_embedding, input, offsets, per_sample_weights))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.shutdown_error_regex->self.get_shutdown_error_regex()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.r1->self._exec_func(exec_mode, torch.add, t1, t2).sum()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.r2->self._exec_func(exec_mode, torch.mul, t1, t2).sum()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.r3->self._exec_func(exec_mode, torch.cos, t1).sum()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.r4->self._exec_func(exec_mode, torch.div, t1, t2).sum()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.local_grads->self._verify_backwards(exec_mode, [loss], context_id, local_grads, t1, t2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.forward_ret->self._exec_func(exec_mode, my_script_add, t1, t2)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.dst->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.store->torch.distributed.distributed_c10d._get_default_store()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.context->torch.distributed.autograd._new_context()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.context_id->torch.distributed.autograd._new_context()._context_id()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.embedding->embedding_rref.local_value()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.grad_map->torch.distributed.autograd.get_gradients(context_id)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.remote_embedding->torch.distributed.rpc.remote(worker_name(dst), torch.nn.EmbeddingBag, args=(16, 16), kwargs={'mode': 'sum', 'sparse': True})
A:torch.testing._internal.distributed.rpc.dist_autograd_test.local_embedding->torch.nn.EmbeddingBag(16, 16, mode='sum', sparse=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.input->torch.tensor([1, 2, 4, 5, 4, 3, 2, 9])
A:torch.testing._internal.distributed.rpc.dist_autograd_test.per_sample_weights->torch.rand(8, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.offsets->torch.tensor([0, 4])
A:torch.testing._internal.distributed.rpc.dist_autograd_test.local_res->local_embedding(input, offsets, per_sample_weights)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.remote_grad->torch.distributed.rpc.rpc_sync(worker_name(dst), DistAutogradTest._get_grad, args=(remote_embedding, context_id))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.debug_info->torch.distributed.autograd._get_debug_info()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.backward_passes->int(debug_info['num_current_backward_passes'])
A:torch.testing._internal.distributed.rpc.dist_autograd_test.res[i + 1]->torch.distributed.rpc.rpc_sync(worker_name(rank), torch.add, args=(res[i], t2))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.num_autograd_context->int(debug_info['num_autograd_contexts'])
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t6->torch.distributed.rpc.rpc_sync('worker0', torch.add, args=(t4, t5))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.MyFunc.static_grad_ptr->grad._values().data_ptr()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.MyFuncSingleGrad.static_grad_ptr->grad.data_ptr()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.ctx.size->inp1.size()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.a->torch.randn(10, 3, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.b->torch.randn(10, 3, requires_grad=True)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.p_a->grads[a]._values().data_ptr()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.p_b->grads[b]._values().data_ptr()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.v->torch.rand(1, 3)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.i->torch.ones(1, 1, dtype=torch.long)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.nv->torch.rand(1, 3).expand(8, 3)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.ni->torch.ones(1, 1, dtype=torch.long).expand(1, 8)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.ngrad->torch.sparse.FloatTensor(ni, nv, torch.Size([10, 3]))
A:torch.testing._internal.distributed.rpc.dist_autograd_test.NonContGradFunc.static_grad_ptr->torch.sparse.FloatTensor(ni, nv, torch.Size([10, 3]))._values().data_ptr()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.emb_matrix->MyFunc.apply(a)
A:torch.testing._internal.distributed.rpc.dist_autograd_test.MyFunc.static_grad_indices_ref->grad._indices()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.MyFunc.static_grad_values_ref->grad._values()
A:torch.testing._internal.distributed.rpc.dist_autograd_test.t7->self._exec_func(exec_mode, torch.add, t6.cpu(), t5)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.MyBackwardFunc(Function)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.MyBackwardFunc.backward(ctx,input)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.MyBackwardFunc.forward(ctx,input)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.TestDebugInfoFunc(Function)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.TestDebugInfoFunc.backward(ctx,input)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.TestDebugInfoFunc.forward(ctx,input)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._call_remote_embedding(cls,embedding_rref,input,offsets,per_sample_weights)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._check_rpc_done(self,rank_distance)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._complex_python_udf(t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._exec_func(self,exec_mode,method,*args)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._exec_func_with_dst(self,dst,exec_mode,method,*args)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._get_grad(cls,embedding_rref,context_id)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._mixed_requires_grad(cls,t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._nested_python_udf(t1,t2,dst)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._nested_rpc_call_backward_error(t1,t2,dst)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._next_rank(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._python_udf_with_backward_error(t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._run_test_backward_unused_send_function_in_thread(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._slow_add(t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_backward_rref(self,callee,rref_owner)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_backward_simple(self,dst)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_grad_only_on_return_value(self,exec_mode)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_graph(self,fn,exec_mode)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_graph_for_py_nested_call(self,exec_mode)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_graph_for_py_nested_call_itself(self,exec_mode)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_nested_backward_accumulate_grads(t1,t2,dst_rank)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_no_graph_with_tensors_not_require_grad(self,exec_mode)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_rpc_complex_args(self,exec_mode)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._test_trainer_ps(self,create_ref_fn,trainer_fn)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._verify_backwards(self,exec_mode,tensors,context_id,local_grads,*args)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._verify_backwards_remote(self,tensors,context_id,local_grads,*args)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._verify_graph_for_first_rpc_call(self,send_function,recv_function,t1,t2,ret)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._verify_graph_for_nested_rpc_call(self,ctx)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._verify_graph_for_rpc_call_exec(self,send_function)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest._workload_thread()
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.context_cleanup_test_helper(self,rpc_args,func,nested=False)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_async_dist_autograd(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_autograd_context(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_accumulate_grads(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_autograd_engine_error(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_complex_python_udf(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_different_dtypes(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_different_tensor_dims(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_invalid_args(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_multiple_output_tensors(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_multiple_roots(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_multiple_round_trips(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_no_grad_on_tensor(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_node_failure(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_node_failure_python_udf(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_python_udf_error(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_rref(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_rref_multi(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_rref_nested(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_simple(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_simple_python_udf(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_simple_script_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_simple_self(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_unused_send_function(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_unused_tensors(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_verify_hooks(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_without_context(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backward_without_rpc(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_backwards_nested_python_udf(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_clean_context_during_backward(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_context_cleanup_nested_rpc(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_context_cleanup_no_tensors(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_context_cleanup_tensor_no_grad(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_context_cleanup_tensor_with_grad(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_debug_info(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_dist_autograd_profiling(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_embedding_bag_with_no_grad_tensors(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_error_in_context(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_gpu_simple(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_gpu_to_cpu_continuation(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_gpu_to_cpu_continuation_gpu_root(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_grad_copy_sparse_indices_extra_ref(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_grad_only_on_return_value(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_grad_only_on_return_value_remote(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_builtin_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_builtin_remote_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_py_nested_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_py_nested_call_itself(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_py_nested_remote_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_py_nested_remote_call_itself(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_python_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_graph_for_python_remote_call(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_mixed_requires_grad(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_multiple_backward(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_multiple_backward_with_errors(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_nested_backward_accumulate_grads(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_nested_context(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_grad_copy_sparse(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_graph_with_tensors_not_require_grad(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_no_graph_with_tensors_not_require_grad_remote(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_post_hooks(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_remote_complex_args(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_rpc_complex_args(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_thread_local_context_id(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_trainer_ps(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_trainer_ps_torchscript_functions(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.DistAutogradTest.test_worker_ids_recorded(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.ExecMode(Enum)
torch.testing._internal.distributed.rpc.dist_autograd_test.FaultyAgentDistAutogradTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.dist_autograd_test.FaultyAgentDistAutogradTest.context_cleanup_test_helper(self,rpc_args,func)
torch.testing._internal.distributed.rpc.dist_autograd_test.FaultyAgentDistAutogradTest.test_context_cleanup_tensor_with_grad(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.FaultyAgentDistAutogradTest.test_verify_backend_options(self)
torch.testing._internal.distributed.rpc.dist_autograd_test.SimulateBackwardError(Function)
torch.testing._internal.distributed.rpc.dist_autograd_test.SimulateBackwardError.backward(ctx,input)
torch.testing._internal.distributed.rpc.dist_autograd_test.SimulateBackwardError.forward(ctx,input)
torch.testing._internal.distributed.rpc.dist_autograd_test._all_contexts_cleaned_up(timeout_seconds=10)
torch.testing._internal.distributed.rpc.dist_autograd_test._check_rpc_done(rank_distance)
torch.testing._internal.distributed.rpc.dist_autograd_test._compare_owner_value(context_id,rref,grad)
torch.testing._internal.distributed.rpc.dist_autograd_test._run_trainer(rref_t1,t2,ps,rank_diff)
torch.testing._internal.distributed.rpc.dist_autograd_test._run_trainer_torchscript(rref_t1,t2,ps,rank_diff)
torch.testing._internal.distributed.rpc.dist_autograd_test._set_rpc_done(ctx_id,rank_distance)
torch.testing._internal.distributed.rpc.dist_autograd_test._torch_ones(sizes,requires_grad=False)
torch.testing._internal.distributed.rpc.dist_autograd_test.create_tensor()
torch.testing._internal.distributed.rpc.dist_autograd_test.create_torchscript_tensor()
torch.testing._internal.distributed.rpc.dist_autograd_test.my_nested_rref_add(dst,rref_t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.my_py_add(t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.my_py_nested_call(t1,t2,dst,world_size,hops)
torch.testing._internal.distributed.rpc.dist_autograd_test.my_rref_add(rref_t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.my_scalar_add(a,b)
torch.testing._internal.distributed.rpc.dist_autograd_test.my_script_add(t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.my_script_ref_add(ref_t1,t2)
torch.testing._internal.distributed.rpc.dist_autograd_test.ret_requires_grad()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/dist_optimizer_test.py----------------------------------------
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.lock->threading.Lock()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.g_cpu->torch.Generator()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.self.w->torch.rand((3, 3), requires_grad=True, generator=g_cpu)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.remote_module1->torch.distributed.rpc.remote(owner1, MyModule)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.remote_module2->torch.distributed.rpc.remote(owner2, MyModule)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.remote_param1->remote_method(MyModule.get_w, remote_module1)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.remote_param2->remote_method(MyModule.get_w, remote_module2)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.dist_optim->DistributedOptimizer(optim.Adagrad, [remote_param1, remote_param2], lr=0.05)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.t1->torch.rand((3, 3), requires_grad=True, generator=g_cpu)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.t2->torch.rand((3, 3), requires_grad=True, generator=g_cpu)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.output1->rpc_async_method(MyModule.forward, remote_module1, t2)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.output2->rpc_async_method(MyModule.forward, remote_module2, output1.wait())
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.loss->torch.add(output2.wait(), t1)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.module1->MyModule()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.module2->MyModule()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.local_optim->torch.optim.Adagrad(params, lr=0.05)
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.old_w1->MyModule().w.clone().detach()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.old_w2->MyModule().w.clone().detach()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.old_w1_remote->remote_method(MyModule.get_w, remote_module1).to_here()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.new_w1->rpc_async_method(MyModule.get_w, remote_module1).wait()
A:torch.testing._internal.distributed.rpc.dist_optimizer_test.new_w2->rpc_async_method(MyModule.get_w, remote_module2).wait()
torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest.test_dist_optim(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest.test_dist_optim_exception(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest.test_dist_optim_exception_on_constructor(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.DistOptimizerTest.test_dist_optim_functional(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.FailingOptimizer(self,params)
torch.testing._internal.distributed.rpc.dist_optimizer_test.FailingOptimizer.__init__(self,params)
torch.testing._internal.distributed.rpc.dist_optimizer_test.FailingOptimizer.step(self,closure=None)
torch.testing._internal.distributed.rpc.dist_optimizer_test.MyModule(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.MyModule.__init__(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.MyModule.forward(self,t1)
torch.testing._internal.distributed.rpc.dist_optimizer_test.MyModule.get_w(self)
torch.testing._internal.distributed.rpc.dist_optimizer_test.OptimizerFailingOnConstructor(self,params)
torch.testing._internal.distributed.rpc.dist_optimizer_test.OptimizerFailingOnConstructor.__init__(self,params)
torch.testing._internal.distributed.rpc.dist_optimizer_test.OptimizerFailingOnConstructor.step(self,closure=None)
torch.testing._internal.distributed.rpc.dist_optimizer_test._call_method(method,obj_rref,*args,**kwargs)
torch.testing._internal.distributed.rpc.dist_optimizer_test.remote_method(method,obj_rref,*args,**kwargs)
torch.testing._internal.distributed.rpc.dist_optimizer_test.rpc_async_method(method,obj_rref,*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/rpc_agent_test_fixture.py----------------------------------------
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture(ABC)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.get_shutdown_error_regex(self)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.get_timeout_error_regex(self)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.init_method(self)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.rpc_backend(self)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.rpc_backend_options(self)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.setup_fault_injection(self,faulty_messages,messages_to_delay)
torch.testing._internal.distributed.rpc.rpc_agent_test_fixture.RpcAgentTestFixture.world_size(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/process_group_agent_test_fixture.py----------------------------------------
torch.testing._internal.distributed.rpc.process_group_agent_test_fixture.ProcessGroupRpcAgentTestFixture(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.process_group_agent_test_fixture.ProcessGroupRpcAgentTestFixture.get_shutdown_error_regex(self)
torch.testing._internal.distributed.rpc.process_group_agent_test_fixture.ProcessGroupRpcAgentTestFixture.get_timeout_error_regex(self)
torch.testing._internal.distributed.rpc.process_group_agent_test_fixture.ProcessGroupRpcAgentTestFixture.rpc_backend(self)
torch.testing._internal.distributed.rpc.process_group_agent_test_fixture.ProcessGroupRpcAgentTestFixture.rpc_backend_options(self)
torch.testing._internal.distributed.rpc.process_group_agent_test_fixture.ProcessGroupRpcAgentTestFixture.rpc_backend_options(self,new_rpc_backend_options)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/rpc_test.py----------------------------------------
A:torch.testing._internal.distributed.rpc.rpc_test.t->torch.rand(5, 5)
A:torch.testing._internal.distributed.rpc.rpc_test.VALUE_FUTURE->concurrent.futures.Future()
A:torch.testing._internal.distributed.rpc.rpc_test.DONE_FUTURE->concurrent.futures.Future()
A:torch.testing._internal.distributed.rpc.rpc_test.TensorClass->namedtuple('TensorClass', ['tensors'])
A:torch.testing._internal.distributed.rpc.rpc_test.(pickled_python_udf, tensors)->torch.distributed.rpc.internal._internal_rpc_pickler.serialize(PythonUDF(my_tensor_function, (torch.ones(2, 2), torch.ones(2, 2)), None))
A:torch.testing._internal.distributed.rpc.rpc_test.python_udf->torch.distributed.rpc.internal._internal_rpc_pickler.deserialize(obj[0], obj[1])
A:torch.testing._internal.distributed.rpc.rpc_test.result->torch.distributed.rpc.rpc_sync(dst_worker, _call_method_on_rref, args=(MyClass.get_value, rref))
A:torch.testing._internal.distributed.rpc.rpc_test.a->MyClass(1)
A:torch.testing._internal.distributed.rpc.rpc_test.current_dst->worker_name(dst)
A:torch.testing._internal.distributed.rpc.rpc_test.rref->torch.distributed.rpc.remote(dst_worker, torch.add, args=(torch.tensor(1), torch.tensor(1)))
A:torch.testing._internal.distributed.rpc.rpc_test.ret_rref->torch.distributed.rpc.remote(worker_name(dst_rank), check_rref_confirmed, args=(rref,))
A:torch.testing._internal.distributed.rpc.rpc_test.out->torch.futures.wait_all(futs).wait()
A:torch.testing._internal.distributed.rpc.rpc_test.fut->torch.distributed.rpc.rpc_async(dst_worker, my_script_func, args=(torch.tensor(1),), timeout=0)
A:torch.testing._internal.distributed.rpc.rpc_test.fut2->torch.distributed.rpc.rpc_async(dst, torch.add, args=(fut0.wait(), 1)).then(lambda fut1: fut1.wait() + 1)
A:torch.testing._internal.distributed.rpc.rpc_test.fut1->torch.distributed.rpc.rpc_async(dst, raise_func).then(callback)
A:torch.testing._internal.distributed.rpc.rpc_test.x->torch.ones(2, 2)
A:torch.testing._internal.distributed.rpc.rpc_test.y->torch.ones(2)
A:torch.testing._internal.distributed.rpc.rpc_test.lock->Lock()
A:torch.testing._internal.distributed.rpc.rpc_test.ret_future->torch.futures.Future()
A:torch.testing._internal.distributed.rpc.rpc_test.ret_fut->torch.futures.Future()
A:torch.testing._internal.distributed.rpc.rpc_test.self_worker_info->torch.distributed.rpc.get_worker_info()
A:torch.testing._internal.distributed.rpc.rpc_test.peer_worker_info->torch.distributed.rpc.get_worker_info(worker_name(peer_rank))
A:torch.testing._internal.distributed.rpc.rpc_test.unknown_worker_id->torch.distributed.rpc.get_worker_info('WorkerUnknown')
A:torch.testing._internal.distributed.rpc.rpc_test.worker_infos->torch.distributed.rpc.api._get_current_rpc_agent().get_worker_infos()
A:torch.testing._internal.distributed.rpc.rpc_test.expected_worker_ids->set(range(self.world_size))
A:torch.testing._internal.distributed.rpc.rpc_test.self_worker_name->worker_name(self.rank)
A:torch.testing._internal.distributed.rpc.rpc_test.ret->torch.futures.wait_all(futs)
A:torch.testing._internal.distributed.rpc.rpc_test.dst->worker_name(callee_rank)
A:torch.testing._internal.distributed.rpc.rpc_test.proxy_rpc_sync->torch.distributed.rpc.remote(dst_worker, torch.add, args=(torch.tensor(1), torch.tensor(1))).rpc_sync()
A:torch.testing._internal.distributed.rpc.rpc_test.proxy_rpc_async->torch.distributed.rpc.remote(dst_worker, torch.add, args=(torch.tensor(1), torch.tensor(1))).rpc_async()
A:torch.testing._internal.distributed.rpc.rpc_test.proxy_remote->torch.distributed.rpc.remote(dst_worker, torch.add, args=(torch.tensor(1), torch.tensor(1))).remote()
A:torch.testing._internal.distributed.rpc.rpc_test.expected->torch.add(torch.tensor(1), torch.tensor(1))
A:torch.testing._internal.distributed.rpc.rpc_test.backend->torch.distributed.rpc.backend_registry.register_backend(backend_name, _stub_construct_rpc_backend_options_handler, _stub_init_rpc_backend_handler)
A:torch.testing._internal.distributed.rpc.rpc_test.(store, _, _)->next(torch.distributed.rendezvous(self.init_method, rank=self.rank, world_size=self.world_size))
A:torch.testing._internal.distributed.rpc.rpc_test.info->torch.distributed.rpc.api._get_current_rpc_agent().get_debug_info()
A:torch.testing._internal.distributed.rpc.rpc_test.workder_info->torch.distributed.rpc.get_worker_info(worker_name(dst_rank))
A:torch.testing._internal.distributed.rpc.rpc_test.results->torch.distributed.rpc.api._all_gather(info.id)
A:torch.testing._internal.distributed.rpc.rpc_test.value->concurrent.futures.Future().result()
A:torch.testing._internal.distributed.rpc.rpc_test.rpc_profiling_key->_build_rpc_profiling_key(RPCExecMode.ASYNC, udf_with_torch_ops.__qualname__, worker_name(self.rank), worker_name(dst))
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker->worker_name(next_rank)
A:torch.testing._internal.distributed.rpc.rpc_test.res->torch.distributed.rpc.rpc_async(dst_worker, my_script_func, args=(torch.tensor(1),), timeout=0).wait()
A:torch.testing._internal.distributed.rpc.rpc_test.event_cpu_mem_usages->set((event.cpu_memory_usage for event in function_events))
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker_cuda_0->worker_name(dst_cuda_0)
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker_cuda_1->worker_name(dst_cuda_1)
A:torch.testing._internal.distributed.rpc.rpc_test.trace->json.load(f)
A:torch.testing._internal.distributed.rpc.rpc_test.event_exists->any([expected_event_name in event_name for event_name in event_names])
A:torch.testing._internal.distributed.rpc.rpc_test.remote_event_name_set->set(EXPECTED_REMOTE_EVENTS)
A:torch.testing._internal.distributed.rpc.rpc_test.rpc_event->get_function_event(events, torch._jit_internal._qualified_name(my_script_func))
A:torch.testing._internal.distributed.rpc.rpc_test.dst1->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.rpc_test.dst2->worker_name((self.rank + 2) % self.world_size)
A:torch.testing._internal.distributed.rpc.rpc_test.key_prefix->_build_rpc_profiling_key(RPCExecMode.ASYNC, slow_async_add.__qualname__, worker_name(self.rank), dst1)
A:torch.testing._internal.distributed.rpc.rpc_test.nested_rpc_key_prefix->_build_rpc_profiling_key(RPCExecMode.ASYNC, slow_add.__qualname__, dst1, dst2)
A:torch.testing._internal.distributed.rpc.rpc_test.local_name->convert_remote_to_local(evt.name)
A:torch.testing._internal.distributed.rpc.rpc_test.scope_event->get_function_event(events, 'foo')
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker_name->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.rpc_test.foo_event_ix->next((i for (i, event) in enumerate(events) if 'foo' in event.name))
A:torch.testing._internal.distributed.rpc.rpc_test.rpc_event_idx->next((i for (i, event) in enumerate(events) if rpc_exec_mode.value in event.name))
A:torch.testing._internal.distributed.rpc.rpc_test.outer_profile_rref->torch.distributed.rpc.remote(dst_worker_name, rpc._server_process_global_profile)
A:torch.testing._internal.distributed.rpc.rpc_test.inner_profile_rref->torch.distributed.rpc.remote(dst_worker_name, rpc._server_process_global_profile)
A:torch.testing._internal.distributed.rpc.rpc_test.inner_events->torch.distributed.rpc.rpc_sync(dst_worker_name, get_events_from_profile, (inner_profile_rref,))
A:torch.testing._internal.distributed.rpc.rpc_test.outer_events->torch.distributed.rpc.rpc_sync(dst_worker_name, get_events_from_profile, (outer_profile_rref,))
A:torch.testing._internal.distributed.rpc.rpc_test.key->_build_rpc_profiling_key(RPCExecMode.ASYNC, torch._jit_internal._qualified_name(my_script_func), 'worker1', 'worker0')
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker_info->torch.distributed.rpc.get_worker_info(worker_name(dst_rank))
A:torch.testing._internal.distributed.rpc.rpc_test.b->MyClass(2)
A:torch.testing._internal.distributed.rpc.rpc_test.m->MyPickleClass()
A:torch.testing._internal.distributed.rpc.rpc_test.tik->time.time()
A:torch.testing._internal.distributed.rpc.rpc_test.tok->time.time()
A:torch.testing._internal.distributed.rpc.rpc_test.rref_a->torch.distributed.rpc.remote(worker_name(dst_rank), torch.add, args=(torch.ones(n, n), 2))
A:torch.testing._internal.distributed.rpc.rpc_test.rref_b->torch.distributed.rpc.remote(worker_name(dst_rank), torch.add, args=(torch.ones(n, n), 1))
A:torch.testing._internal.distributed.rpc.rpc_test.rref_c->torch.distributed.rpc.remote(worker_name(dst_rank), my_rref_function, args=(rref_a, rref_b))
A:torch.testing._internal.distributed.rpc.rpc_test.c->torch.distributed.rpc.rpc_sync(worker_name(dst_rank), my_rref_function, args=(rref_a, rref_b))
A:torch.testing._internal.distributed.rpc.rpc_test.rref_of_rrefs->torch.distributed.rpc.remote(worker_name(dst_rank1), nested_rref, args=(worker_name(dst_rank2),))
A:torch.testing._internal.distributed.rpc.rpc_test.rrefs->torch.distributed.rpc.remote(worker_name(dst_rank1), nested_rref, args=(worker_name(dst_rank2),)).to_here()
A:torch.testing._internal.distributed.rpc.rpc_test.local_rref->RRef(35)
A:torch.testing._internal.distributed.rpc.rpc_test.rref_list->torch.distributed.rpc.rpc_sync(worker_name(dst_rank), get_rref_list, args=([1, 2, 3],))
A:torch.testing._internal.distributed.rpc.rpc_test.other_a->torch.distributed.rpc.remote(worker_name(other_rank), torch.add, args=(torch.ones(1), 1))
A:torch.testing._internal.distributed.rpc.rpc_test.other_b->torch.distributed.rpc.remote(worker_name(other_rank), torch.add, args=(torch.ones(1), 1))
A:torch.testing._internal.distributed.rpc.rpc_test.rref1->RRef(self.rank)
A:torch.testing._internal.distributed.rpc.rpc_test.rref2->torch.distributed.rpc.remote(worker_name(dst_rank), torch.add, args=(torch.ones(2, 2), 1))
A:torch.testing._internal.distributed.rpc.rpc_test.rref3->torch.distributed.rpc.remote(worker_name(dst_rank), torch.add, args=(torch.ones(2, 2), 1))
A:torch.testing._internal.distributed.rpc.rpc_test.rref_info->_rref_context_get_debug_info()
A:torch.testing._internal.distributed.rpc.rpc_test.agent_info->torch.distributed.rpc.api._get_current_rpc_agent().get_debug_info()
A:torch.testing._internal.distributed.rpc.rpc_test.autograd_info->torch.distributed.autograd._get_debug_info()
A:torch.testing._internal.distributed.rpc.rpc_test.error_str->self.get_shutdown_error_regex()
A:torch.testing._internal.distributed.rpc.rpc_test.dist_initialized->torch.distributed.is_initialized()
A:torch.testing._internal.distributed.rpc.rpc_test.set_timeout->torch.distributed.rpc.get_rpc_timeout()
A:torch.testing._internal.distributed.rpc.rpc_test.expected_error->self.get_timeout_error_regex()
A:torch.testing._internal.distributed.rpc.rpc_test.test_pickler->TestPickler()
A:torch.testing._internal.distributed.rpc.rpc_test.a.rref->torch.distributed.rpc.remote(dst_worker_name, torch.add, args=(torch.ones(n, n), 2))
A:torch.testing._internal.distributed.rpc.rpc_test.t1->torch.rand(3, 3).cuda(0)
A:torch.testing._internal.distributed.rpc.rpc_test.t2->torch.rand(3, 3).cuda(1)
A:torch.testing._internal.distributed.rpc.rpc_test.t3->torch.rand(3, 3)
A:torch.testing._internal.distributed.rpc.rpc_test.t_view->torch.rand(5, 5).narrow(1, 2, 2)
A:torch.testing._internal.distributed.rpc.rpc_test.t_cont->torch.rand(5, 5).narrow(1, 2, 2).contiguous()
A:torch.testing._internal.distributed.rpc.rpc_test.t_ret->torch.distributed.rpc.rpc_sync(worker_name(next_rank), non_cont_test, args=(t_view, t_cont))
A:torch.testing._internal.distributed.rpc.rpc_test.set_by_cb->concurrent.futures.Future()
A:torch.testing._internal.distributed.rpc.rpc_test.cb_fut->torch.distributed.rpc.rpc_async(dst_worker, my_script_func, args=(torch.tensor(1),), timeout=0).then(my_function)
A:torch.testing._internal.distributed.rpc.rpc_test.fut0->torch.distributed.rpc.rpc_async(dst, torch.add, args=(torch.ones(2, 2), 1))
A:torch.testing._internal.distributed.rpc.rpc_test.fut3->torch.distributed.rpc.rpc_async(dst, torch.add, args=(torch.ones(2, 2), 1)).then(callback)
A:torch.testing._internal.distributed.rpc.rpc_test.rpc_backend_options->torch.distributed.rpc.TensorPipeRpcBackendOptions(init_method=self.rpc_backend_options.init_method, num_worker_threads=self.rpc_backend_options.num_worker_threads, rpc_timeout=timeout)
A:torch.testing._internal.distributed.rpc.rpc_test.num_owner_rrefs->int(info['num_owner_rrefs'])
A:torch.testing._internal.distributed.rpc.rpc_test.num_idle_threads->int(info['agent.num_idle_threads'])
A:torch.testing._internal.distributed.rpc.rpc_test.default_timeout->torch.distributed.rpc.get_rpc_timeout()
A:torch.testing._internal.distributed.rpc.rpc_test.timeout->timedelta()
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker_b->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.rpc_test.dst_worker_c->worker_name((self.rank + 2) % self.world_size)
A:torch.testing._internal.distributed.rpc.rpc_test.slow_rref->torch.distributed.rpc.remote(dst_worker, func, args=args, timeout=2)
torch.testing._internal.distributed.rpc.rpc_test.AsyncExecutionClass
torch.testing._internal.distributed.rpc.rpc_test.AsyncExecutionClass.bound_async_add(self,to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.AsyncExecutionClass.class_async_add(cls,to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.AsyncExecutionClass.static_async_add(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest._test_remote_message_delay_timeout(self,func,args,dst=None)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest._test_remote_message_dropped_pickle(self,dst=None)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest._test_remote_message_dropped_timeout(self,func,args,dst=None)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_builtin_remote_message_dropped_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_builtin_remote_message_dropped_timeout_to_self(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_check_failed_messages(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_custom_faulty_messages(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_custom_messages_to_delay(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_no_faulty_messages(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_remote_message_builtin_delay_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_remote_message_builtin_delay_timeout_to_self(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_remote_message_dropped_pickle(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_remote_message_dropped_pickle_to_self(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_remote_message_script_delay_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_remote_message_script_delay_timeout_to_self(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_rpc_builtin_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_rpc_script_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_rref_to_here_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_udf_remote_message_delay_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_udf_remote_message_delay_timeout_to_self(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_udf_remote_message_dropped_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_udf_remote_message_dropped_timeout_to_self(self)
torch.testing._internal.distributed.rpc.rpc_test.FaultyAgentRpcTest.test_verify_backend_options(self)
torch.testing._internal.distributed.rpc.rpc_test.FooBackendOptions(self,init_method)
torch.testing._internal.distributed.rpc.rpc_test.FooBackendOptions.__init__(self,init_method)
torch.testing._internal.distributed.rpc.rpc_test.MyClass(self,a)
torch.testing._internal.distributed.rpc.rpc_test.MyClass.__init__(self,a)
torch.testing._internal.distributed.rpc.rpc_test.MyClass.get_value(self)
torch.testing._internal.distributed.rpc.rpc_test.MyClass.increment_value(self,increment)
torch.testing._internal.distributed.rpc.rpc_test.MyClass.my_class_method(cls,d,e)
torch.testing._internal.distributed.rpc.rpc_test.MyClass.my_instance_method(self,b)
torch.testing._internal.distributed.rpc.rpc_test.MyClass.my_static_method(f)
torch.testing._internal.distributed.rpc.rpc_test.MyPickleClass(self)
torch.testing._internal.distributed.rpc.rpc_test.MyPickleClass.__getstate__(self)
torch.testing._internal.distributed.rpc.rpc_test.MyPickleClass.__init__(self)
torch.testing._internal.distributed.rpc.rpc_test.MyPickleClass.__setstate__(self,obj)
torch.testing._internal.distributed.rpc.rpc_test.MyPickleClass.set(self,val)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_infer_backend_from_options(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_logs_deprecation_warning(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_mismatched_type_for_options(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_process_group_debug_info(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_process_group_options_throw_on_timedelta_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_process_group_set_default_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_set_and_get_num_send_recv_threads(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_single_threaded_rref_owner(self)
torch.testing._internal.distributed.rpc.rpc_test.ProcessGroupAgentRpcTest.test_single_threaded_rref_to_here(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._assert_top_level_events(self,process_global_events,expected_top_level_event_names)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._create_rref(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._gpu_tensor_list_arg(tensor_list)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._profiler_test_with_rpc(self,rpc_exec_mode,func,args,use_record_function=False,dst=None)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._return_gpu_tensor()
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._return_gpu_tensor_list()
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_func_in_mode(self,to,fn,mode,args=None,kwargs=None)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_rpc_profiling_async_function(self,device='cpu')
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_remote_events_profiled(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_async_rpc_builtin(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_async_rpc_udf(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_autograd_context(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_remote_builtin(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_remote_udf(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_script_async_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_script_remote_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_script_sync_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_sync_rpc_builtin(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_test_profiler_with_sync_rpc_udf(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._run_uneven_workload(self,num_repeat=30)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._slow_add(x,y)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._stress_test_rpc(self,f,repeat=1000,args=())
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_async_function(self,fn,mode=RPCExecMode.SYNC)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_async_function_multi(self,fn,mode=RPCExecMode.SYNC)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_async_function_raise(self,mode)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_async_function_wrong_return_type(self,mode)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_future_cb(self,func)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_multi_remote_call(self,fn,args_fn=lambdax:(),kwargs_fn=lambdax:{})
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_return_future(self,mode)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_rref_leak(self,_mock_delete_all_user_and_unforked_owner_rrefs,ignore_leak)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_rref_proxy_class(self,dst)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_rref_proxy_tensor(self,dst)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_self_remote_rref_as_remote_arg(self,dst)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_self_remote_rref_as_rpc_arg(self,dst)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest._test_test_async_class_rref_proxy(self,mode=RPCExecMode.SYNC)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.check_profiling_info(self,self_worker_name,dst_worker_name,func,rpc_event,rpc_exec_mode)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.run_profiling_workload(self,dst)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_add(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_add_with_id(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_all_gather(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_all_gather_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_add(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_class_method(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_class_method_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_class_rref_proxy(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_class_rref_proxy_async(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_class_rref_proxy_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_chained(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_chained_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_multi_chained(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_multi_chained_async(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_multi_chained_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_multi_fanout(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_multi_fanout_async(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_multi_fanout_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_nested(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_nested_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_raise(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_raise_async(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_raise_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_simple(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_with_future_ctor(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_with_future_ctor_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_wrong_return_type(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_wrong_return_type_async(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_function_wrong_return_type_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_record_function_cbs_jit_call(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_record_function_double_end_callbacks(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_static_method(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_async_static_method_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_build_rpc_profiling_key(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_builtin_remote_ret(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_builtin_remote_self(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_call_method_on_rref(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_chain(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_in_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_multi(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_none(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_simple(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_with_error(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_with_ret(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_wrong_arg_num(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_callback_wrong_arg_type(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_cannot_infer_backend_from_options(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_cuda(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_deadlock(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_debug_info(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_default_timeout_used(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_disable_gil_profiling(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_dist_init_decorator(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_duplicate_name(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_expected_src(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_function_not_on_callee(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_future_done(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_future_done_exception(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_future_in_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_future_nested_callback(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_get_worker_infos(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_graceful_shutdown_with_uneven_workload(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_handle_send_exceptions(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_ignore_rref_leak(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_init_pg_then_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_init_rpc_then_pg(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_init_rpc_twice(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_invalid_names(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_local_rref_no_fork(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_local_shutdown(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_local_shutdown_with_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_local_value_not_on_owner(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_mark_future_twice(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_multi_builtin_remote_ret(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_multi_layer_nested_async_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_multi_py_udf_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_multi_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_nested_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_nested_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_nested_rref(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_nested_rref_stress(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_non_cont_tensors(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_non_garbage_collected_user_rref_due_to_local_circular_dependency(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_nonzero(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_owner_equality(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_pass_local_rrefs(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_pickle_future(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_export_trace(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_remote_cuda(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_remote_events_profiled(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_remote_events_profiled_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_rpc_key_names(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_rpc_memory(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_rpc_record_shapes(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_async_rpc_builtin(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_async_rpc_builtin_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_async_rpc_udf(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_async_rpc_udf_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_autograd_context(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_autograd_context_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_remote_builtin(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_remote_builtin_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_remote_udf(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_remote_udf_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_script_async_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_script_async_rpc_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_script_remote_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_script_remote_rpc_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_script_sync_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_script_sync_rpc_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_sync_rpc_builtin(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_sync_rpc_builtin_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_sync_rpc_udf(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_profiler_with_sync_rpc_udf_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_built_in(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_class_constructor(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_class_instance_method(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_class_method(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_class_static_method(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_function_exception(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_multi_async_call(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_nested_pickle(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_no_return_result(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_raise_in_user_func(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_rpc_rref_args(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_rref_args(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_rref_args_user_share(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_tensors(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_tensors_in_container(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_tensors_multi_async_call(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_udf_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_py_user_defined(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_register_rpc_backend_and_set_and_start_rpc_backend(self,mock_rpc_agent,mock_dist_autograd_init)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_reinit(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_remote_same_worker(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_remote_throw(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_remote_with_exception(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_return_future(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_return_future_async(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_return_future_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_return_local_rrefs(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rpc_profiling_async_function(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rpc_profiling_async_function_single_threaded(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rpc_profiling_remote_record_function(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rpc_return_rref(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rpc_timeouts(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_context_debug_info(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_forward_chain(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_get_future(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_leak(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_proxy_class(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_proxy_class_self(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_proxy_non_exist(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_proxy_reuse(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_proxy_tensor(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_proxy_tensor_self(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_py_pickle_not_supported(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_str(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_type(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_type_owner(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_type_slow_init(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_rref_type_with_error(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_scalar_add(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_self_add(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_self_py_udf_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_self_remote_rref_as_remote_arg(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_self_remote_rref_as_rpc_arg(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_self_remote_rref_as_self_remote_arg(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_self_remote_rref_as_self_rpc_arg(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_server_process_global_profiler(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_set_and_get_default_rpc_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_shutdown_followed_by_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_stress_heavy_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_stress_heavy_rpc_torchscript(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_stress_light_rpc(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_use_rpc_pickler(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_use_rref_after_shutdown(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_user_rrefs_confirmed(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_user_rrefs_confirmed_remote(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_wait_all_with_exception(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_wait_all_with_partial_exception(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_wait_all_workers(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_wait_all_workers_twice(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_worker_id(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_world_size_one(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.test_wrong_types(self)
torch.testing._internal.distributed.rpc.rpc_test.RpcTest.validate_profiling_workload(self,dst,prof)
torch.testing._internal.distributed.rpc.rpc_test.SlowPickleClass(self,t)
torch.testing._internal.distributed.rpc.rpc_test.SlowPickleClass.__getstate__(self)
torch.testing._internal.distributed.rpc.rpc_test.SlowPickleClass.__init__(self,t)
torch.testing._internal.distributed.rpc.rpc_test.SlowPickleClass.__setstate__(self,obj)
torch.testing._internal.distributed.rpc.rpc_test.StubRpcAgent(self,world_size)
torch.testing._internal.distributed.rpc.rpc_test.StubRpcAgent.__init__(self,world_size)
torch.testing._internal.distributed.rpc.rpc_test.StubRpcAgent.get_worker_infos(self)
torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest.test_infer_backend_from_options(self)
torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest.test_mismatched_type_for_options(self)
torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest.test_set_and_get_num_worker_threads(self)
torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest.test_tensorpipe_options_throw_on_timedelta_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test.TensorPipeAgentRpcTest.test_tensorpipe_set_default_timeout(self)
torch.testing._internal.distributed.rpc.rpc_test._call_method_on_rref(method,rref,*args,**kwargs)
torch.testing._internal.distributed.rpc.rpc_test._stub_construct_rpc_backend_options_handler(**kwargs)
torch.testing._internal.distributed.rpc.rpc_test._stub_init_rpc_backend_handler(store,name,rank,world_size,rpc_backend_options)
torch.testing._internal.distributed.rpc.rpc_test.add_rref_to_value(rref,value)
torch.testing._internal.distributed.rpc.rpc_test.add_use_future_cb(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.add_use_future_nested_cb(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.add_use_future_set_result(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.async_add(to,x,y)
torch.testing._internal.distributed.rpc.rpc_test.async_add_chained(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.async_add_chained_multi(to,x,num,step)
torch.testing._internal.distributed.rpc.rpc_test.async_add_multi_fanout(to,x,num,step)
torch.testing._internal.distributed.rpc.rpc_test.async_add_nested(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.async_add_with_future_ctor(to,x,y,z)
torch.testing._internal.distributed.rpc.rpc_test.async_raise_func()
torch.testing._internal.distributed.rpc.rpc_test.async_wrong_type()
torch.testing._internal.distributed.rpc.rpc_test.build_complex_tensors()
torch.testing._internal.distributed.rpc.rpc_test.check_rref_confirmed(rref)
torch.testing._internal.distributed.rpc.rpc_test.clear_global_rref()
torch.testing._internal.distributed.rpc.rpc_test.delayed_add(a,b,seconds=0.05)
torch.testing._internal.distributed.rpc.rpc_test.fail_on_fut(fut)
torch.testing._internal.distributed.rpc.rpc_test.foo_add()
torch.testing._internal.distributed.rpc.rpc_test.get_events_from_profile(profile_rref)
torch.testing._internal.distributed.rpc.rpc_test.get_rref_debug_info()
torch.testing._internal.distributed.rpc.rpc_test.get_rref_list(values)
torch.testing._internal.distributed.rpc.rpc_test.heavy_rpc(tensor)
torch.testing._internal.distributed.rpc.rpc_test.heavy_rpc_torchscript(tensor)
torch.testing._internal.distributed.rpc.rpc_test.light_rpc()
torch.testing._internal.distributed.rpc.rpc_test.multi_layer_nested_async_rpc(dst,world_size,ttl)
torch.testing._internal.distributed.rpc.rpc_test.my_complex_tensor_function(list_input,tensor_class_input,dict_input)
torch.testing._internal.distributed.rpc.rpc_test.my_function(a,b,c)
torch.testing._internal.distributed.rpc.rpc_test.my_rref_function(rref_a,rref_b)
torch.testing._internal.distributed.rpc.rpc_test.my_script_func(tensor)
torch.testing._internal.distributed.rpc.rpc_test.my_sleep_func(seconds=1)
torch.testing._internal.distributed.rpc.rpc_test.my_tensor_function(a,b)
torch.testing._internal.distributed.rpc.rpc_test.nested_remote(dst)
torch.testing._internal.distributed.rpc.rpc_test.nested_rpc(dst)
torch.testing._internal.distributed.rpc.rpc_test.nested_rref(dst)
torch.testing._internal.distributed.rpc.rpc_test.no_result()
torch.testing._internal.distributed.rpc.rpc_test.non_cont_test(t_view,t_cont)
torch.testing._internal.distributed.rpc.rpc_test.raise_func()
torch.testing._internal.distributed.rpc.rpc_test.raise_or_inc(value)
torch.testing._internal.distributed.rpc.rpc_test.return_future()
torch.testing._internal.distributed.rpc.rpc_test.rpc_return_rref(dst)
torch.testing._internal.distributed.rpc.rpc_test.rref_forward_chain(dst,world_size,rref,ttl)
torch.testing._internal.distributed.rpc.rpc_test.run_nested_pickle(pickle_cls_instance,tensor)
torch.testing._internal.distributed.rpc.rpc_test.set_and_check_done(value)
torch.testing._internal.distributed.rpc.rpc_test.set_global_rref(rref)
torch.testing._internal.distributed.rpc.rpc_test.set_value(value)
torch.testing._internal.distributed.rpc.rpc_test.slow_add(x,y,device='cpu')
torch.testing._internal.distributed.rpc.rpc_test.slow_async_add(to,x,y,device='cpu')
torch.testing._internal.distributed.rpc.rpc_test.udf_with_torch_ops(device=-1,use_record_function=False)
torch.testing._internal.distributed.rpc.rpc_test.wait_for_value_future()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/faulty_rpc_agent_test_fixture.py----------------------------------------
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture(self,*args,**kwargs)
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture.__init__(self,*args,**kwargs)
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture.get_shutdown_error_regex(self)
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture.get_timeout_error_regex(self)
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture.rpc_backend(self)
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture.rpc_backend_options(self)
torch.testing._internal.distributed.rpc.faulty_rpc_agent_test_fixture.FaultyRpcAgentTestFixture.setup_fault_injection(self,faulty_messages,messages_to_delay)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/jit/dist_autograd_test.py----------------------------------------
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.fut->torch.jit._fork(remote_add, t1, t2, dst)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.t1->torch.ones((2, 3), requires_grad=True)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.t2->torch.ones((2, 3), requires_grad=True)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.t3->torch.add(t1, t2)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.grads->torch.distributed.autograd.get_gradients(context_id)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.dst_worker_name->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.loss->fork_add(t1, t2, dst_worker_name).sum()
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.res->fork_add(t1, t2, dst_worker_name)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.res1_fut->torch.distributed.rpc.rpc_async(dst_worker_name, local_add, (t1, t1))
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.res1->torch.distributed.rpc.rpc_async(dst_worker_name, local_add, (t1, t1)).wait()
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.loss1->torch.distributed.rpc.rpc_async(dst_worker_name, local_add, (t1, t1)).wait().sum()
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.res2_fut->torch.distributed.rpc.rpc_async(dst_worker_name, local_add, (t2, t2))
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.res2->torch.distributed.rpc.rpc_async(dst_worker_name, local_add, (t2, t2)).wait()
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.loss2->torch.distributed.rpc.rpc_async(dst_worker_name, local_add, (t2, t2)).wait().sum()
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.(loss0, loss1)->forward_script(context_id, dst_worker_name, t1, t2)
A:torch.testing._internal.distributed.rpc.jit.dist_autograd_test.(grad0, grad1)->torch.distributed.autograd.get_gradients(context_id)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest.test_dist_backward(self)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest.test_get_gradients(self)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest.test_jit_fork_within_context(self)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.JitDistAutogradTest.test_restore_context_after_swtich_to_jit_thread(self)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.fork_add(t1,t2,dst:str)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.local_add(t1,t2)
torch.testing._internal.distributed.rpc.jit.dist_autograd_test.remote_add(t1,t2,dst:str)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/jit/rpc_test_faulty.py----------------------------------------
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.fut->rpc_async_call_with_timeout_future_ret(dst_worker_name, args, kwargs, 0)
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.ret->rpc_async_call_with_timeout(dst_worker_name, args, kwargs, 0)
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.dst_worker_name->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.expected_error->self.get_timeout_error_regex()
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.result->rpc_async_call_with_timeout_future_ret(dst_worker_name, args, kwargs, 0).wait()
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.dst_worker->'worker{}'.format(dst_rank)
A:torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rref->torch.distributed.rpc.remote(dst_worker, torch.add, args=(torch.tensor(1), torch.tensor(1)))
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest(RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest.test_remote_timeout_to_here_in_jit(self)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest.test_rref_timeout_pickle_in_jit(self)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest.test_rref_timeout_pickle_script_func(self)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest.test_rref_to_here_timeout_in_jit(self)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest.test_timeout_in_python(self)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.JitFaultyAgentRpcTest.test_timeout_in_torchscript_function(self)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rpc_async_call_future_ret(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor])
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rpc_async_call_with_timeout(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor],timeout:float)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rpc_async_call_with_timeout_future_ret(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor],timeout:float)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rpc_async_with_rref_arg(dst_worker_name,args)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rref_to_here(rref_var)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.rref_to_here_with_timeout(rref_var,timeout)
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.script_rpc_async_call(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor])
torch.testing._internal.distributed.rpc.jit.rpc_test_faulty.two_args_two_kwargs(first_arg,second_arg,first_kwarg=torch.tensor([3,3]),second_kwarg=torch.tensor([4,4]))


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/jit/rpc_test.py----------------------------------------
A:torch.testing._internal.distributed.rpc.jit.rpc_test.dst_worker_name->worker_name(dst_rank)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref_var->rpc_return_rref(worker_name(dst_rank))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.res->torch.distributed.rpc.rpc_sync(dst_worker_name, two_args_two_kwargs, args, kwargs)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref->torch.distributed.rpc.remote(worker_name((self.rank + 1) % self.world_size), async_wrong_type)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.retret->torch.distributed.rpc.rpc_sync(dst_worker_name, rref_local_value, (rref,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.ret->torch.distributed.rpc.rpc_sync(dst1, async_add, args=(dst2, torch.ones(2, 2), torch.ones(2, 2)))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.ret_rref->torch.distributed.rpc.remote(worker_name(dst_rank), script_check_rref_confirmed, args=(rref,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.dst->worker_name(n % self.world_size)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.list_rref->torch.distributed.rpc.remote(dst, list_create)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.fut1->torch.distributed.rpc.rpc_async(dst_worker_name, script_add_ones, (t,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.fut2->torch.distributed.rpc.rpc_async(dst_worker_name, script_add_ones, (t,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.fut->torch.jit._fork(sleep, sleep_interval)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.x->torch.jit._wait(fut)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.value->torch.jit._wait(fut)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.res_tensor->torch.ones(2, 2)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.local_ret->one_arg(torch.ones(2, 2))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref1->torch.distributed.rpc.rpc_sync(worker_name(dst_rank), return_rref, args=(rref,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref2->torch.distributed.rpc.remote(worker_name(dst_rank), rref_to_here, args=(rref,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref3->torch.distributed.rpc.remote(worker_name(dst_rank), return_rref, args=(rref,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.module_with_rrefs->MyScriptModuleWithRRefs(worker_name(dst_rank))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.ret_fut->torch.distributed.rpc.rpc_async(worker_name(dst_rank), two_args_two_kwargs, args=inputs)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.expected_res->torch.add(input_0, input_1)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.fut_res->future_return_to_python(dst_rank, inputs)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.input_0->torch.ones(2, 2)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.self.a->torch.ones(rank)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref_script_class->torch.distributed.rpc.RRef(MyScriptClass(self.rank))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref_script_module->torch.distributed.rpc.RRef(MyScriptModule(self.rank))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.use_rref_on_owner_script->torch.jit.script(use_rref_on_owner)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.rref_res->torch.distributed.rpc.remote(dst_worker_name, two_args_two_kwargs, args, kwargs)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.module->ref_script_module.to_here()
A:torch.testing._internal.distributed.rpc.jit.rpc_test.f->io.BytesIO()
A:torch.testing._internal.distributed.rpc.jit.rpc_test.m->torch.jit.load(f)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.local_rref->torch.distributed.rpc.remote(worker_name(self.rank), one_arg, args=(torch.ones(2, 2),))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.my_local_script_module->MyScriptModule(self.rank)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.remote_ref->torch.distributed.rpc.remote(worker_name(dst_rank), construct_my_script_module, args=(self.rank,))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.dst_name->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.m1->MyScriptModuleWithRRefs(dst_name)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.m2->MyScriptModuleWithRRefs(dst_name)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.out1->torch.distributed.rpc.rpc_sync(dst_name, load_script_module_with_pickled_rref, args=(f.getvalue(),))
A:torch.testing._internal.distributed.rpc.jit.rpc_test.out2->m2()
A:torch.testing._internal.distributed.rpc.jit.rpc_test.future->torch.distributed.rpc.rpc_async(worker_name((self.rank + 1) % self.world_size), script_fork_wait_throw, args=(torch.ones(2),)).then(callback)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.prof_key->_build_rpc_profiling_key(RPCExecMode.ASYNC, torch._jit_internal._qualified_name(one_arg), 'worker0', 'worker1')
A:torch.testing._internal.distributed.rpc.jit.rpc_test.function_event->get_function_event(events, 'foo')
A:torch.testing._internal.distributed.rpc.jit.rpc_test.qual_name->torch._jit_internal._qualified_name(two_args_two_kwargs)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.profiled_name->_build_rpc_profiling_key(RPCExecMode.ASYNC_JIT, qual_name, worker_name(self.rank), dst_worker_name)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.expected_key->_build_rpc_profiling_key(RPCExecMode.ASYNC_JIT, torch._jit_internal._qualified_name(script_add_ones), worker_name(self.rank), dst_worker_name)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.sleep_event->get_function_event(function_events, 'foo')
A:torch.testing._internal.distributed.rpc.jit.rpc_test.dst1->worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.rpc.jit.rpc_test.dst2->worker_name((self.rank + 2) % self.world_size)
torch.testing._internal.distributed.rpc.jit.rpc_test.FutureTypingTest
torch.testing._internal.distributed.rpc.jit.rpc_test.FutureTypingTest.test_future_passed_between_python_and_jit(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.FutureTypingTest.test_future_python_annotation(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_all_kwargs_are_populated_by_defaults(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_args_and_kwargs_contain_different_types(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_args_kwargs_are_neither_passed(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_call_python_function_remotely_from_script_not_supported(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_call_script_function_that_not_exists_remotely_from_script(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_call_script_function_that_raises_remotely_from_script(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_kwargs_not_passed(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_less_than_needed_args_are_specified(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_more_than_needed_args_are_specified(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_no_kwargs_are_populated_by_defaults(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_some_kwargs_are_populated_by_defaults(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcOpTest.test_unexepected_kwarg_is_specified(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest(RRefAPITest,RRefTypingTest,LocalRRefTest,JitRpcOpTest,FutureTypingTest,RpcAgentTestFixture)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_function_remote(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_function_remote_multi(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_function_simple(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_function_wrong_decorator_order(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_function_wrong_return_type(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_function_wrong_return_type_remote(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_script_throw(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_async_script_udf(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_call_fork_in_jit_with_profiling(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_call_rpc_with_profiling(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_callback_chain(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_callback_simple(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_callback_with_exception(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_load_script_module_with_pickled_rref(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_record_function_jit_end_callbacks_with_fork(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_record_function_on_caller_rpc_async(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_remote_script_module(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_remote_script_throw(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_remote_script_udf(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_rpc_async_jit_profiled(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_rpc_torchscript_record_function(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_rref_jit_pickle_not_supported(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_torchscript_function(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_torchscript_function_exception(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.JitRpcTest.test_torchscript_functions_not_supported(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest
torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest.test_create_local_script_class_rref_in_py(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest.test_create_local_script_module_rref_in_py(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest.test_return_local_script_class_rref_in_py_and_use_in_script(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.LocalRRefTest.test_return_local_script_module_rref_in_py_and_use_in_script(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyModuleInterface(torch.nn.Module)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyModuleInterface.forward(self)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptClass(self,a:int)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptClass.__init__(self,a:int)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptClass.get_value(self)->int
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModule(self,rank)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModule.__init__(self,rank)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModule.forward(self)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModuleWithRRefs(self,dst_worker)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModuleWithRRefs.__init__(self,dst_worker)
torch.testing._internal.distributed.rpc.jit.rpc_test.MyScriptModuleWithRRefs.forward(self)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest._create_rref(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest.test_local_rref_local_value(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest.test_rref_is_owner(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest.test_rref_list_mutate(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest.test_rref_local_value(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest.test_user_rrefs_confirmed(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefAPITest.test_user_rrefs_confirmed_remote(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefTypingTest
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefTypingTest.test_my_script_module_with_rrefs(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefTypingTest.test_rref_as_arg_and_return(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.RRefTypingTest.test_rref_python_annotation(self)
torch.testing._internal.distributed.rpc.jit.rpc_test.assorted_types_args_kwargs(tensor_arg:Tensor,str_arg:str,int_arg:int,tensor_kwarg:Tensor=torch.tensor([2,2]),str_kwarg:str='str_kwarg',int_kwarg:int=2)
torch.testing._internal.distributed.rpc.jit.rpc_test.async_add(to:str,x:Tensor,y:Tensor)->Future[Tensor]
torch.testing._internal.distributed.rpc.jit.rpc_test.async_wrong_type()->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.call_fork_with_profiling(handle:Tensor)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.call_rpc_torchscript_with_record_function(dst_worker_name:str,block:str)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.call_rpc_with_profiling(handle:Tensor,dst_worker_name:str)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.construct_my_script_module(rank:int)->MyModuleInterface
torch.testing._internal.distributed.rpc.jit.rpc_test.list_create()->List[int]
torch.testing._internal.distributed.rpc.jit.rpc_test.load_script_module_with_pickled_rref(pickled_script_module)
torch.testing._internal.distributed.rpc.jit.rpc_test.my_script_module_init(rank:int)->MyModuleInterface
torch.testing._internal.distributed.rpc.jit.rpc_test.no_arg()
torch.testing._internal.distributed.rpc.jit.rpc_test.one_arg(value)
torch.testing._internal.distributed.rpc.jit.rpc_test.owner_create_rref_my_script_class(a)
torch.testing._internal.distributed.rpc.jit.rpc_test.owner_create_rref_my_script_module(a)
torch.testing._internal.distributed.rpc.jit.rpc_test.python_function()
torch.testing._internal.distributed.rpc.jit.rpc_test.raise_script()
torch.testing._internal.distributed.rpc.jit.rpc_test.record_function_on_caller_rpc_async(dst_worker_name:str,block:str)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.return_rref(rref_var:RRef[Tensor])->RRef[Tensor]
torch.testing._internal.distributed.rpc.jit.rpc_test.return_value(value:int)->int
torch.testing._internal.distributed.rpc.jit.rpc_test.rpc_return_rref(dst)
torch.testing._internal.distributed.rpc.jit.rpc_test.rref_list_mutate(rref:RRef[List[int]])->None
torch.testing._internal.distributed.rpc.jit.rpc_test.rref_local_value(rref:RRef[Tensor])->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.rref_python_annotation(rref_var:RRef[Tensor])->RRef[Tensor]
torch.testing._internal.distributed.rpc.jit.rpc_test.rref_script_annotation(rref_var:RRef[Tensor])->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.rref_to_here(rref_var:RRef[Tensor])->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.run_ref_script_module(ref_script_module:RRef[MyModuleInterface],t:Tensor)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.save_rref(rref_var:RRef[Tensor],fname:str)->None
torch.testing._internal.distributed.rpc.jit.rpc_test.script_add(x:Tensor,y:Tensor)->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.script_add_ones(x)
torch.testing._internal.distributed.rpc.jit.rpc_test.script_add_ones_with_record_function(x,block:str)
torch.testing._internal.distributed.rpc.jit.rpc_test.script_check_rref_confirmed(rref:RRef[Tensor])->bool
torch.testing._internal.distributed.rpc.jit.rpc_test.script_fork_wait_throw(invalue)
torch.testing._internal.distributed.rpc.jit.rpc_test.script_fork_wait_udf(tensor)
torch.testing._internal.distributed.rpc.jit.rpc_test.script_raise_func(value)
torch.testing._internal.distributed.rpc.jit.rpc_test.script_rpc_async_call(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor])
torch.testing._internal.distributed.rpc.jit.rpc_test.script_rpc_remote_call(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor])
torch.testing._internal.distributed.rpc.jit.rpc_test.script_rpc_sync_call(dst_worker_name:str,args:Tuple[Tensor,Tensor],kwargs:Dict[str,Tensor])
torch.testing._internal.distributed.rpc.jit.rpc_test.script_rref_get_value_my_script_class(rref:RRef[MyScriptClass])->int
torch.testing._internal.distributed.rpc.jit.rpc_test.script_rref_run_forward_my_script_module(rref:RRef[MyModuleInterface])->Tensor
torch.testing._internal.distributed.rpc.jit.rpc_test.sleep(t)
torch.testing._internal.distributed.rpc.jit.rpc_test.two_args_two_kwargs(first_arg,second_arg,first_kwarg=torch.tensor([3,3]),second_kwarg=torch.tensor([4,4]))


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/rpc/jit/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/nn/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/nn/api/remote_module_test.py----------------------------------------
A:torch.testing._internal.distributed.nn.api.remote_module_test._PARAM_VAL->torch.nn.Parameter(torch.ones(1))
A:torch.testing._internal.distributed.nn.api.remote_module_test.module->MyModule(first_arg, first_kwarg=first_kwarg)
A:torch.testing._internal.distributed.nn.api.remote_module_test.scripted_module->torch.jit.script(module)
A:torch.testing._internal.distributed.nn.api.remote_module_test.modes->ModuleCreationMode.__members__.values()
A:torch.testing._internal.distributed.nn.api.remote_module_test.kwargs->dict(word='3')
A:torch.testing._internal.distributed.nn.api.remote_module_test.remote_module->_RemoteModule(dst_worker_name, device, create_scripted_module, args, kwargs, _module_interface_cls=MyModuleInterface)
A:torch.testing._internal.distributed.nn.api.remote_module_test.scripted_remote_module->next(self._create_remote_module_iter(dst_worker_name, modes=[ModuleCreationMode.MODULE_CTOR_WITH_INTERFACE]))
A:torch.testing._internal.distributed.nn.api.remote_module_test.dst_worker_name->torch.testing._internal.dist_utils.worker_name((self.rank + 1) % self.world_size)
A:torch.testing._internal.distributed.nn.api.remote_module_test.ret_fut->_RemoteModule(dst_worker_name, device, create_scripted_module, args, kwargs, _module_interface_cls=MyModuleInterface).forward_async(*args, **kwargs)
A:torch.testing._internal.distributed.nn.api.remote_module_test.ret->_RemoteModule(dst_worker_name, device, create_scripted_module, args, kwargs, _module_interface_cls=MyModuleInterface).forward(*args, **kwargs)
A:torch.testing._internal.distributed.nn.api.remote_module_test.param_rrefs->_RemoteModule(dst_worker_name, device, create_scripted_module, args, kwargs, _module_interface_cls=MyModuleInterface).remote_parameters()
A:torch.testing._internal.distributed.nn.api.remote_module_test.device->torch.distributed.rpc.rpc_sync(dst_worker_name, remote_device, (remote_module.module_rref,))
A:torch.testing._internal.distributed.nn.api.remote_module_test.fn->torch.rand((3, 3), requires_grad=False)
torch.testing._internal.distributed.nn.api.remote_module_test.BadModule(self,first_arg,first_kwarg=-1)
torch.testing._internal.distributed.nn.api.remote_module_test.BadModule.__init__(self,first_arg,first_kwarg=-1)
torch.testing._internal.distributed.nn.api.remote_module_test.ModuleCreationMode(enum.Enum)
torch.testing._internal.distributed.nn.api.remote_module_test.MyModule(self,first_arg,first_kwarg=-1)
torch.testing._internal.distributed.nn.api.remote_module_test.MyModule.__init__(self,first_arg,first_kwarg=-1)
torch.testing._internal.distributed.nn.api.remote_module_test.MyModule.forward(self,tensor:Tensor,number:int,word:str='default')->Tuple[str, int, Tensor]
torch.testing._internal.distributed.nn.api.remote_module_test.MyModuleInterface
torch.testing._internal.distributed.nn.api.remote_module_test.MyModuleInterface.forward(self,tensor:Tensor,number:int,word:str='default')->Tuple[str, int, Tensor]
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest(RpcAgentTestFixture)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest._create_remote_module_iter(dst_worker_name,device='cpu',modes=None)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_bad_module(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_forward_async(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_forward_async_script(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_forward_sync(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_forward_sync_script(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_forward_with_kwargs(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_invalid_devices(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_remote_parameters(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_unsupported_methods(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.test_valid_device(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteModuleTest.world_size(self)
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteMyModuleInterface
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteMyModuleInterface.forward(self,tensor:Tensor,number:int,word:str='default')->Tuple[str, int, Tensor]
torch.testing._internal.distributed.nn.api.remote_module_test.RemoteMyModuleInterface.forward_async(self,tensor:Tensor,number:int,word:str='default')->Future[Tuple[str, int, Tensor]]
torch.testing._internal.distributed.nn.api.remote_module_test.create_scripted_module(first_arg,first_kwarg=-1)
torch.testing._internal.distributed.nn.api.remote_module_test.remote_device(module_rref)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/distributed/nn/api/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/test_module/no_future_div.py----------------------------------------
torch.testing._internal.test_module.no_future_div.div_float_nofuture()
torch.testing._internal.test_module.no_future_div.div_int_nofuture()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/test_module/future_div.py----------------------------------------
torch.testing._internal.test_module.future_div.div_float_future()
torch.testing._internal.test_module.future_div.div_int_future()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/test_module/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/codegen/random_topo_test.py----------------------------------------
A:torch.testing._internal.codegen.random_topo_test.max_dim->len(tensor_shape)
A:torch.testing._internal.codegen.random_topo_test.num_b_dims->numpy.random.randint(0, max_dim + 1)
A:torch.testing._internal.codegen.random_topo_test.trim_head->numpy.random.randint(0, min(num_b_dims + 1, max_dim))
A:torch.testing._internal.codegen.random_topo_test.num_tensor->numpy.random.randint(1, max_tensor_num)
A:torch.testing._internal.codegen.random_topo_test.num_const->numpy.random.randint(0, num_tensor + 1)
A:torch.testing._internal.codegen.random_topo_test.const_list->numpy.random.random(num_const)
A:torch.testing._internal.codegen.random_topo_test.candidate->list(range(num_tensor))
A:torch.testing._internal.codegen.random_topo_test.u_op_size->len(unary_operations)
A:torch.testing._internal.codegen.random_topo_test.b_op_size->len(binary_operations)
A:torch.testing._internal.codegen.random_topo_test.num_operations->numpy.random.randint(num_sets - 1, num_sets * GRAPH_FACTOR)
A:torch.testing._internal.codegen.random_topo_test.index->numpy.random.randint(0, len(candidate))
A:torch.testing._internal.codegen.random_topo_test.op_index->numpy.random.randint(0, u_op_size + b_op_size)
A:torch.testing._internal.codegen.random_topo_test.out_tensor->binary_operations[op_index - u_op_size](tensor_list[lh_index], tensor_list[rh_index])
A:torch.testing._internal.codegen.random_topo_test.op_2_index->numpy.random.randint(0, len(tensor_list) + num_const)
A:torch.testing._internal.codegen.random_topo_test.cand_index->numpy.random.randint(0, len(candidate))
A:torch.testing._internal.codegen.random_topo_test.candidate[index]->len(tensor_list)
A:torch.testing._internal.codegen.random_topo_test.lh_root->get_root(lh_index, d_map)
A:torch.testing._internal.codegen.random_topo_test.rh_root->get_root(rh_index, d_map)
A:torch.testing._internal.codegen.random_topo_test.d_map[rh_root]->len(tensor_list)
A:torch.testing._internal.codegen.random_topo_test.d_map[lh_root]->len(tensor_list)
A:torch.testing._internal.codegen.random_topo_test.out_list->numpy.random.choice(range(num_tensor, len(tensor_list)), np.random.randint(0, len(tensor_list) - num_tensor), False)
A:torch.testing._internal.codegen.random_topo_test.seed_tensor->torch.tensor(np.random.randint(0, seed))
A:torch.testing._internal.codegen.random_topo_test.tensor_dim->numpy.random.randint(1, max_tensor_dim)
A:torch.testing._internal.codegen.random_topo_test.size_i->min(size_i, 128 + size_i % 128)
A:torch.testing._internal.codegen.random_topo_test.num_broadcasted_tensors->numpy.random.randint(0, 1)
A:torch.testing._internal.codegen.random_topo_test.broadcasted_tensors_indices->numpy.random.choice(torch.arange(num_tensor), num_broadcasted_tensors, replace=False)
A:torch.testing._internal.codegen.random_topo_test.compatible_shape->get_broadcast_compatible_shape(tensor_shape)
A:torch.testing._internal.codegen.random_topo_test.repro_str->'python {0}'.format(__file__)
A:torch.testing._internal.codegen.random_topo_test.(seed_tensor, tensor_list)->prepareInputTensorsToRandomTopoTest(seed, args.max_num_tensor, args.max_tensor_dim, args.max_tensor_size, args.debug_tensor, 'cuda' if not args.cpu else 'cpu', torch.float32 if not args.fp16 else torch.float16)
A:torch.testing._internal.codegen.random_topo_test.o->random_topology_test(seed_tensor, *tensor_list)
A:torch.testing._internal.codegen.random_topo_test.traced_model->torch.jit.trace(random_topology_test, (seed_tensor, *tensor_list))
A:torch.testing._internal.codegen.random_topo_test.jit_o->traced_model(seed_tensor, *tensor_list)
A:torch.testing._internal.codegen.random_topo_test.validate_o->zip(o, jit_o)
A:torch.testing._internal.codegen.random_topo_test.parser->argparse.ArgumentParser()
A:torch.testing._internal.codegen.random_topo_test.group->argparse.ArgumentParser().add_mutually_exclusive_group()
A:torch.testing._internal.codegen.random_topo_test.args->parse_args()
torch.testing._internal.codegen.random_topo_test.WrongResultException(Exception)
torch.testing._internal.codegen.random_topo_test.get_broadcast_compatible_shape(tensor_shape)
torch.testing._internal.codegen.random_topo_test.parse_args()
torch.testing._internal.codegen.random_topo_test.prepareInputTensorsToRandomTopoTest(seed,max_tensor_num,max_tensor_dim,max_tensor_size,debug_tensor,device,dtype)
torch.testing._internal.codegen.random_topo_test.random_topology_test(seed,*inp_tensor_list)
torch.testing._internal.codegen.random_topo_test.reproString(current_seed,args)
torch.testing._internal.codegen.random_topo_test.runDefaultTestWithSeed(seed)
torch.testing._internal.codegen.random_topo_test.runTest(seed,args)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/codegen/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/data/network1.py----------------------------------------
A:torch.testing._internal.data.network1.self.linear->torch.nn.Linear(10, 20)
torch.testing._internal.data.network1.Net(self)
torch.testing._internal.data.network1.Net.__init__(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/data/network2.py----------------------------------------
A:torch.testing._internal.data.network2.self.linear->torch.nn.Linear(10, 20)
A:torch.testing._internal.data.network2.self.relu->torch.nn.ReLU()
torch.testing._internal.data.network2.Net(self)
torch.testing._internal.data.network2.Net.__init__(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/testing/_internal/data/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/contrib/_tensorboard_vis.py----------------------------------------
A:torch.contrib._tensorboard_vis.pb_graph->visualize(graph_executor)
A:torch.contrib._tensorboard_vis.evt->tensorflow.core.util.event_pb2.Event(wall_time=time.time(), graph_def=pb_graph.SerializeToString())
A:torch.contrib._tensorboard_vis.input_node->visualize(graph_executor).node.add(op='input', name=name_prefix + 'input')
A:torch.contrib._tensorboard_vis.return_node->visualize(graph_executor).node.add(op='output', name=name_prefix + 'output')
A:torch.contrib._tensorboard_vis.input_kinds->visualize(graph_executor).node.add(op='INPUT_KIND', name=subgraph_name)
A:torch.contrib._tensorboard_vis.input_kinds.attr['inputs'].s->repr(arg_spec).encode('ascii')
A:torch.contrib._tensorboard_vis.op_id_counter->defaultdict(int)
A:torch.contrib._tensorboard_vis.(op, name)->name_for(node)
A:torch.contrib._tensorboard_vis.ge->next(executors_it)
A:torch.contrib._tensorboard_vis.pb_node->visualize(graph_executor).node.add(op=op, name=name)
torch.contrib._tensorboard_vis.dump_tensorboard_summary(graph_executor,logdir)
torch.contrib._tensorboard_vis.visualize(graph,name_prefix='',pb_graph=None,executors_it=None)
torch.contrib._tensorboard_vis.visualize_graph_executor(state,name_prefix,pb_graph,inline_graph)
torch.contrib._tensorboard_vis.visualize_rec(graph,value_map,name_prefix,pb_graph,executors_it=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/contrib/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/frontend.py----------------------------------------
A:torch.jit.frontend._identifier_chars->set(string.ascii_lowercase + string.ascii_uppercase + string.digits)
A:torch.jit.frontend.self.error_report->torch._C.ErrorReport(self.source_range)
A:torch.jit.frontend.node_type->type(offending_node)
A:torch.jit.frontend.range_len->len(node_start_tokens.get(node_type, ' '))
A:torch.jit.frontend.source_range->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).make_range(stmt.lineno, stmt.col_offset, stmt.col_offset + len('del'))
A:torch.jit.frontend.feature_name->pretty_node_names.get(node_type, node_type.__name__)
A:torch.jit.frontend.msg->"{} {}aren't supported".format(feature_name, reason + ' ' if reason else '')
A:torch.jit.frontend.props->inspect.getmembers(cls, predicate=lambda m: isinstance(m, property))
A:torch.jit.frontend.unused_properties->getattr(cls, '__jit_unused_properties__', [])
A:torch.jit.frontend.getter->get_jit_def(prop[1].fget, f'__{prop[0]}_getter', self_name=self_name)
A:torch.jit.frontend.methods->inspect.getmembers(cls, predicate=lambda m: (inspect.ismethod(m) or inspect.isfunction(m)) and (not is_static_fn(cls, m.__name__)) and (m.__name__ in cls.__dict__))
A:torch.jit.frontend.properties->get_class_properties(cls, self_name)
A:torch.jit.frontend.(sourcelines, file_lineno, filename)->get_source_lines_and_file(fn, torch._C.ErrorReport.call_stack())
A:torch.jit.frontend.source->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).source.encode('utf-8')
A:torch.jit.frontend.dedent_src->dedent(source)
A:torch.jit.frontend.py_ast->ast.parse(dedent_src)
A:torch.jit.frontend.ctx->SourceContext(source, filename, file_lineno, leading_whitespace_len, True)
A:torch.jit.frontend.type_line->torch.jit.annotations.get_type_line(source)
A:torch.jit.frontend.unused_fn_def->ast.parse('def unused_fn(self: Any):\n\traise RuntimeError("Cannot call @unused methods")')
A:torch.jit.frontend.method->getattr(self, 'build_' + node.__class__.__name__, None)
A:torch.jit.frontend.r->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).make_range(expr.lineno, expr.col_offset, expr.col_offset + 1)
A:torch.jit.frontend.param_list->build_param_list(ctx, py_def.args, self_name)
A:torch.jit.frontend.return_type->build_expr(ctx, py_def.returns)
A:torch.jit.frontend.decl->torch._C.merge_type_from_type_comment(decl, type_comment_decl, is_method)
A:torch.jit.frontend.type_comment_decl->torch._C.parse_type_comment(type_line)
A:torch.jit.frontend.ctx_range->build_expr(ctx, arg).range()
A:torch.jit.frontend.annotation_expr->EmptyTypeAnnotation(r)
A:torch.jit.frontend.signature->inspect.signature(fn)
A:torch.jit.frontend.rhs->build_expr(ctx, expr.right)
A:torch.jit.frontend.lhs->BinOp(op_token, lhs, rhs)
A:torch.jit.frontend.the_type->build_expr(ctx, stmt.annotation)
A:torch.jit.frontend.expr->build_expr(ctx, stmt.exc)
A:torch.jit.frontend.test->build_expr(ctx, stmt.test)
A:torch.jit.frontend.op->type(op_)
A:torch.jit.frontend.base->build_expr(ctx, expr.value)
A:torch.jit.frontend.name_range->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).make_raw_range(start_pos, end_pos)
A:torch.jit.frontend.func->build_expr(ctx, expr.func)
A:torch.jit.frontend.stararg_expr->build_expr(ctx, expr.starargs)
A:torch.jit.frontend.kw_expr->build_expr(ctx, kw.value)
A:torch.jit.frontend.err_range->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).make_raw_range(sub_exprs[0].range().end, sub_exprs[1].range().start)
A:torch.jit.frontend.op_token->ExprBuilder.cmpop_map.get(op)
A:torch.jit.frontend.sub_expr->build_expr(ctx, expr.operand)
A:torch.jit.frontend.in_expr->BinOp('in', lhs, rhs)
A:torch.jit.frontend.cmp_expr->BinOp(op_token, lhs, rhs)
A:torch.jit.frontend.result->BinOp('and', result, cmp_expr)
A:torch.jit.frontend.sub_type->type(expr.slice)
A:torch.jit.frontend.value->str(expr.s)
A:torch.jit.frontend.error_range->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).make_range(expr.lineno, expr.col_offset, expr.col_offset + len(str(value)))
A:torch.jit.frontend.elt_expr->build_expr(ctx, stmt.elt)
A:torch.jit.frontend.target_expr->build_expr(ctx, stmt.generators[0].target)
A:torch.jit.frontend.iter_expr->build_expr(ctx, stmt.generators[0].iter)
A:torch.jit.frontend.build_expr->ExprBuilder()
A:torch.jit.frontend.build_stmt->StmtBuilder()
A:torch.jit.frontend.build_withitem->WithItemBuilder()
A:torch.jit.frontend.new_pos->SourceContext(source, filename, file_lineno, leading_whitespace_len, True).source[:pos].rindex(substr)
torch.jit.frontend.Builder(self,ctx,node)
torch.jit.frontend.Builder.__call__(self,ctx,node)
torch.jit.frontend.ExprBuilder(Builder)
torch.jit.frontend.ExprBuilder.build_Attribute(ctx,expr)
torch.jit.frontend.ExprBuilder.build_BinOp(ctx,expr)
torch.jit.frontend.ExprBuilder.build_BoolOp(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Call(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Compare(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Constant(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Dict(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Ellipsis(ctx,expr)
torch.jit.frontend.ExprBuilder.build_IfExp(ctx,expr)
torch.jit.frontend.ExprBuilder.build_JoinedStr(ctx,expr)
torch.jit.frontend.ExprBuilder.build_List(ctx,expr)
torch.jit.frontend.ExprBuilder.build_ListComp(ctx,stmt)
torch.jit.frontend.ExprBuilder.build_Name(ctx,expr)
torch.jit.frontend.ExprBuilder.build_NameConstant(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Num(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Starred(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Str(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Subscript(ctx,expr)
torch.jit.frontend.ExprBuilder.build_Tuple(ctx,expr)
torch.jit.frontend.ExprBuilder.build_UnaryOp(ctx,expr)
torch.jit.frontend.FrontendError(self,source_range,msg)
torch.jit.frontend.FrontendError.__init__(self,source_range,msg)
torch.jit.frontend.FrontendError.__str__(self)
torch.jit.frontend.FrontendTypeError(FrontendError)
torch.jit.frontend.NotSupportedError(FrontendError)
torch.jit.frontend.StmtBuilder(Builder)
torch.jit.frontend.StmtBuilder.build_AnnAssign(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Assert(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Assign(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_AugAssign(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Break(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Continue(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Delete(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Expr(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_For(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_If(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Pass(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Print(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Raise(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_Return(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_While(ctx,stmt)
torch.jit.frontend.StmtBuilder.build_With(ctx,stmt)
torch.jit.frontend.UnsupportedNodeError(self,ctx,offending_node,reason='')
torch.jit.frontend.UnsupportedNodeError.__init__(self,ctx,offending_node,reason='')
torch.jit.frontend.WithItemBuilder(Builder)
torch.jit.frontend.WithItemBuilder.build_withitem(ctx,item)
torch.jit.frontend.build_class_def(ctx,py_def,methods,properties,self_name)
torch.jit.frontend.build_def(ctx,py_def,type_line,def_name,self_name=None)
torch.jit.frontend.build_param(ctx,py_arg,self_name,kwarg_only)
torch.jit.frontend.build_param_list(ctx,py_args,self_name)
torch.jit.frontend.build_stmts(ctx,stmts)
torch.jit.frontend.build_withitems(ctx,items)
torch.jit.frontend.find_before(ctx,pos,substr,offsets=(0,0))
torch.jit.frontend.get_class_properties(cls,self_name)
torch.jit.frontend.get_default_args(fn)
torch.jit.frontend.get_default_args_for_class(cls)
torch.jit.frontend.get_jit_class_def(cls,self_name)
torch.jit.frontend.get_jit_def(fn,def_name,self_name=None)
torch.jit.frontend.is_reserved_name(name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_trace.py----------------------------------------
A:torch.jit._trace.frame->inspect.currentframe()
A:torch.jit._trace.state_dict->make_module(mod, _module_class, _compilation_unit).state_dict(keep_vars=True)
A:torch.jit._trace.filtered_dict->type(state_dict)()
A:torch.jit._trace.filtered_dict[k]->a.detach().clone(memory_format=torch.preserve_format).requires_grad_(a.requires_grad).detach()
A:torch.jit._trace.(in_vars, in_desc)->_flatten(args)
A:torch.jit._trace.module_state->list(_unique_state_dict(self, keep_vars=True).values())
A:torch.jit._trace.trace_inputs->_unflatten(in_args, in_desc)
A:torch.jit._trace.(out_vars, _)->_flatten(out)
A:torch.jit._trace.(graph, out)->torch._C._create_graph_by_tracing(wrapper, in_vars + module_state, _create_interpreter_name_lookup_fn(), self.strict, self._force_outplace)
A:torch.jit._trace.v->a.detach().clone(memory_format=torch.preserve_format).requires_grad_(a.requires_grad)
A:torch.jit._trace.v.grad->clone_input(v.grad)
A:torch.jit._trace._JIT_TIME->os.environ.get('PYTORCH_JIT_TIME', False)
A:torch.jit._trace._JIT_DISABLE->os.environ.get('PYTORCH_JIT_DISABLE', False)
A:torch.jit._trace._JIT_STATS->os.environ.get('PYTORCH_JIT_STATS', False)
A:torch.jit._trace.stream->torch.cuda.current_stream()
A:torch.jit._trace.start->torch.cuda.Event(enable_timing=True)
A:torch.jit._trace.end->torch.cuda.Event(enable_timing=True)
A:torch.jit._trace.is_module->isinstance(model, Module)
A:torch.jit._trace.saved_args->_clone_inputs(args)
A:torch.jit._trace.saved_state->copy.deepcopy(model.state_dict())
A:torch.jit._trace.(in_vars, _)->_flatten((args, params))
A:torch.jit._trace.out->model(*args)
A:torch.jit._trace.loss->loss_fn(*out)
A:torch.jit._trace.grads->torch.autograd.grad([loss], in_vars)
A:torch.jit._trace.(uncompiled_outs, uncompiled_grads)->run_fwd_bwd(args, force_trace=True)
A:torch.jit._trace.(compiled_outs, compiled_grads)->run_fwd_bwd(args, assert_compiled=True)
A:torch.jit._trace.copied_dict[name]->_clone_inputs(data)
A:torch.jit._trace.check_mod->torch.jit.trace(func, _clone_inputs(inputs), check_trace=False, strict=strict, _force_outplace=force_outplace, _module_class=_module_class)
A:torch.jit._trace.check_mod_func->torch.jit.trace(func, _clone_inputs(inputs), check_trace=False, strict=strict, _force_outplace=force_outplace, _module_class=_module_class)._c._get_method(traced_func.name)
A:torch.jit._trace.mod_canonicalized->torch._C._jit_pass_canonicalize(traced_func.graph)
A:torch.jit._trace.mod_str->re.sub('___torch_mangle_[0-9]+\\.', '', mod_str)
A:torch.jit._trace.check_canonicalized->torch._C._jit_pass_canonicalize(check_mod_func.graph)
A:torch.jit._trace.check_str->re.sub('___torch_mangle_[0-9]+\\.', '', check_str)
A:torch.jit._trace.graph_diff->difflib.ndiff(mod_str.splitlines(True), check_str.splitlines(True))
A:torch.jit._trace.node_diff->difflib.ndiff(str(n_mod).splitlines(True), str(n_check).splitlines(True))
A:torch.jit._trace.mod_stack->n_mod.sourceRange()
A:torch.jit._trace.check_stack->n_check.sourceRange()
A:torch.jit._trace.mod_tensor_val->n_mod.t('value')
A:torch.jit._trace.check_tensor_val->n_check.t('value')
A:torch.jit._trace.compare_stack->n_mod.sourceRange()
A:torch.jit._trace.outs->ONNXTracedModule(f, strict, _force_outplace, return_inputs, _return_inputs_states)(*args, **kwargs)
A:torch.jit._trace.(graph_diff_errors, tensor_compare_errors)->graph_diagnostic_info()
A:torch.jit._trace.orig->orig.dequantize().dequantize()
A:torch.jit._trace.ref->ref.dequantize().dequantize()
A:torch.jit._trace.traced_outs->run_mod_and_filter_tensor_outputs(traced_func, inputs, 'trace')
A:torch.jit._trace.fn_outs->run_mod_and_filter_tensor_outputs(func, inputs, 'Python function')
A:torch.jit._trace.check_outs->run_mod_and_filter_tensor_outputs(check_mod_func, inputs, 'repeated trace')
A:torch.jit._trace.diag_info->graph_diagnostic_info()
A:torch.jit._trace.example_inputs->make_tuple(example_inputs)
A:torch.jit._trace.var_lookup_fn->_create_interpreter_name_lookup_fn(0)
A:torch.jit._trace.name->_qualified_name(func)
A:torch.jit._trace.traced->torch._C._create_function_from_trace(name, func, example_inputs, var_lookup_fn, strict, _force_outplace)
A:torch.jit._trace.module->make_module(mod, _module_class, _compilation_unit)
A:torch.jit._trace.check_trace_method->make_module(mod, _module_class, _compilation_unit)._c._get_method(method_name)
A:torch.jit._trace.id_set->set()
A:torch.jit._trace.QualnameWrapper._jit_override_qualname->torch._jit_internal._qualified_name(type(orig))
A:torch.jit._trace.tmp_module->QualnameWrapper()
A:torch.jit._trace.tmp_module._modules[name]->make_module(submodule, TracedModule, _compilation_unit=None)
A:torch.jit._trace.script_module->torch.jit._recursive.create_script_module(tmp_module, lambda module: (), share_types=False)
A:torch.jit._trace.forward->_CachedForward()
A:torch.jit._trace.compiled_fn->script(wrapper.__original_fn)
torch.jit.ONNXTracedModule(self,inner,strict=True,force_outplace=False,return_inputs=False,return_inputs_states=False)
torch.jit.ONNXTracedModule.forward(self,*args:torch.Tensor)
torch.jit.TopLevelTracedModule(TracedModule)
torch.jit.TopLevelTracedModule._reconstruct(self,cpp_module)
torch.jit.TracedModule(self,orig,id_set=None,_compilation_unit=None)
torch.jit.TracedModule.__getattr__(self,attr)
torch.jit.TracedModule.__setattr__(self,attr,value)
torch.jit.TracedModule._get_name(self)
torch.jit.TracedModule.extra_repr(self)
torch.jit.TracedModule.forward(self,*args,**kwargs)
torch.jit.TracerWarning(Warning)
torch.jit.TracerWarning.ignore_lib_warnings()
torch.jit.TracingCheckError(self,graph_diff_error,tensor_compare_error,extra_msg=None)
torch.jit._get_trace_graph(f,args=(),kwargs=None,strict=True,_force_outplace=False,return_inputs=False,_return_inputs_states=False)
torch.jit._script_if_tracing(fn)
torch.jit._trace.ONNXTracedModule(self,inner,strict=True,force_outplace=False,return_inputs=False,return_inputs_states=False)
torch.jit._trace.ONNXTracedModule.__init__(self,inner,strict=True,force_outplace=False,return_inputs=False,return_inputs_states=False)
torch.jit._trace.ONNXTracedModule.forward(self,*args:torch.Tensor)
torch.jit._trace.TopLevelTracedModule(TracedModule)
torch.jit._trace.TopLevelTracedModule._reconstruct(self,cpp_module)
torch.jit._trace.TracedModule(self,orig,id_set=None,_compilation_unit=None)
torch.jit._trace.TracedModule.__getattr__(self,attr)
torch.jit._trace.TracedModule.__init__(self,orig,id_set=None,_compilation_unit=None)
torch.jit._trace.TracedModule.__setattr__(self,attr,value)
torch.jit._trace.TracedModule._get_name(self)
torch.jit._trace.TracedModule.extra_repr(self)
torch.jit._trace.TracedModule.forward(self,*args,**kwargs)
torch.jit._trace.TracerWarning(Warning)
torch.jit._trace.TracerWarning.ignore_lib_warnings()
torch.jit._trace.TracingCheckError(self,graph_diff_error,tensor_compare_error,extra_msg=None)
torch.jit._trace.TracingCheckError.__init__(self,graph_diff_error,tensor_compare_error,extra_msg=None)
torch.jit._trace._check_trace(check_inputs,func,traced_func,check_tolerance,strict,force_outplace,is_trace_module,_module_class)
torch.jit._trace._clone_inputs(args)
torch.jit._trace._create_interpreter_name_lookup_fn(frames_up=1)
torch.jit._trace._get_trace_graph(f,args=(),kwargs=None,strict=True,_force_outplace=False,return_inputs=False,_return_inputs_states=False)
torch.jit._trace._script_if_tracing(fn)
torch.jit._trace._time(trace_name,name,time=True)
torch.jit._trace._unique_state_dict(module,keep_vars=False)
torch.jit._trace._verify_equal(xs,ys)
torch.jit._trace.indent(s)
torch.jit._trace.is_tracing()
torch.jit._trace.make_module(mod,_module_class,_compilation_unit)
torch.jit._trace.make_tuple(example_inputs)
torch.jit._trace.trace(func,example_inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-05,strict=True,_force_outplace=False,_module_class=None,_compilation_unit=_python_cu)
torch.jit._trace.trace_module(mod,inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-05,strict=True,_force_outplace=False,_module_class=None,_compilation_unit=_python_cu)
torch.jit._trace.verify(model,args,loss_fn=torch.sum,devices=None)
torch.jit._trace.wrap_check_inputs(check_inputs)
torch.jit._unique_state_dict(module,keep_vars=False)
torch.jit.is_tracing()
torch.jit.trace(func,example_inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-05,strict=True,_force_outplace=False,_module_class=None,_compilation_unit=_python_cu)
torch.jit.trace_module(mod,inputs,optimize=None,check_trace=True,check_inputs=None,check_tolerance=1e-05,strict=True,_force_outplace=False,_module_class=None,_compilation_unit=_python_cu)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/annotations.py----------------------------------------
A:torch.jit.annotations.signature->parse_type_line(type_line, rcb, loc)
A:torch.jit.annotations.source->dedent(''.join(get_source_lines_and_file(fn)[0]))
A:torch.jit.annotations.type_line->get_type_line(source)
A:torch.jit.annotations.fn->inspect.unwrap(fn)
A:torch.jit.annotations.py_ast->ast.parse(source)
A:torch.jit.annotations.(arg_ann_str, ret_ann_str)->split_type_line(type_line)
A:torch.jit.annotations.arg_ann->eval(arg_ann_str, {}, EvalEnv(rcb))
A:torch.jit.annotations.ret_ann->eval(ret_ann_str, {}, EvalEnv(rcb))
A:torch.jit.annotations.lines->dedent(''.join(get_source_lines_and_file(fn)[0])).split('\n')
A:torch.jit.annotations.type_lines->list(filter(lambda line: not line[1].endswith('# type: ignore'), type_lines))
A:torch.jit.annotations.lines_with_type->list(filter(lambda line: 'type' in line[1], lines))
A:torch.jit.annotations.type_pattern->re.compile('#[\t ]*type[\t ]*(?!: ignore$):')
A:torch.jit.annotations.wrong_type_lines->list(filter(lambda line: type_pattern.search(line[1]), lines))
A:torch.jit.annotations.types->map(get_parameter_type, parameter_type_lines)
A:torch.jit.annotations.parameter_types->', '.join(types)
A:torch.jit.annotations.start_offset->len('# type:')
A:torch.jit.annotations.arrow_pos->get_type_line(source).index('->')
A:torch.jit.annotations.sig->inspect.signature(fn)
A:torch.jit.annotations.return_type->ann_to_type(as_ann(sig.return_annotation), loc)
A:torch.jit.annotations.elem_type->try_ann_to_type(ann.__args__[0], loc)
A:torch.jit.annotations.key->try_ann_to_type(ann.__args__[0], loc)
A:torch.jit.annotations.value->try_ann_to_type(ann.__args__[1], loc)
A:torch.jit.annotations.valid_type->try_ann_to_type(contained, loc)
A:torch.jit.annotations.qualified_name->_qualified_name(ann)
A:torch.jit.annotations.the_type->try_ann_to_type(ann, loc)
torch.jit.annotations.EvalEnv(self,rcb)
torch.jit.annotations.EvalEnv.__getitem__(self,name)
torch.jit.annotations.EvalEnv.__init__(self,rcb)
torch.jit.annotations.Module(self,name,members)
torch.jit.annotations.Module.__getattr__(self,name)
torch.jit.annotations.Module.__init__(self,name,members)
torch.jit.annotations.ann_to_type(ann,loc)
torch.jit.annotations.check_fn(fn,loc)
torch.jit.annotations.get_enum_value_type(e:Type[enum.Enum],loc)
torch.jit.annotations.get_param_names(fn,n_args)
torch.jit.annotations.get_signature(fn,rcb,loc,is_method)
torch.jit.annotations.get_type_line(source)
torch.jit.annotations.is_function_or_method(the_callable)
torch.jit.annotations.is_vararg(the_callable)
torch.jit.annotations.parse_type_line(type_line,rcb,loc)
torch.jit.annotations.split_type_line(type_line)
torch.jit.annotations.try_ann_to_type(ann,loc)
torch.jit.annotations.try_real_annotations(fn,loc)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_script.py----------------------------------------
A:torch.jit._script.Attribute->collections.namedtuple('Attribute', ['value', 'type'])
A:torch.jit._script.ast->get_jit_class_def(obj, obj.__name__)
A:torch.jit._script.defaults->torch.jit.frontend.get_default_args_for_class(obj)
A:torch.jit._script.r->self._c.find_function(attr)
A:torch.jit._script.cls._constants_set->type(module)._constants_set.union(base_constants)
A:torch.jit._script.base_constants->getattr(base, '_constants_set', set())
A:torch.jit._script.original_init->getattr(cls, '__init__', lambda self: None)
A:torch.jit._script.num_methods->len(cls._methods)
A:torch.jit._script.cls->type(module)
A:torch.jit._script.self.__dict__['_actual_script_module']->torch.jit._recursive.create_script_module(self, make_stubs, share_types=not added_methods_in_init)
A:torch.jit._script._rcb->torch._jit_internal.createResolutionCallbackFromClosure(impl_fn)
A:torch.jit._script.forward->_CachedForward()
A:torch.jit._script.rcb->torch._jit_internal.createResolutionCallbackFromFrame(_frames_up + 1)
A:torch.jit._script.self._methods[ast.name().name]->ScriptMethodStub(rcb, ast, None)
A:torch.jit._script.script_module->RecursiveScriptModule(cpp_module)
A:torch.jit._script.script_module._parameters->OrderedDictWrapper(torch._C.ParameterDict(script_module._c))
A:torch.jit._script.script_module._buffers->OrderedDictWrapper(torch._C.BufferDict(script_module._c))
A:torch.jit._script.script_module._modules->OrderedModuleDict(script_module._c, script_module._modules)
A:torch.jit._script.self._concrete_type->torch._C.ConcreteModuleType.from_jit_type(self._c._type())
A:torch.jit._script.modules[name]->wrap_cpp_module(cpp_module)
A:torch.jit._script.self._modules->OrderedModuleDict(self._c, modules)
A:torch.jit._script.self._parameters->OrderedDictWrapper(torch._C.ParameterDict(self._c))
A:torch.jit._script.self._buffers->OrderedDictWrapper(torch._C.BufferDict(self._c))
A:torch.jit._script.script_method->self._c._get_method(attr)
A:torch.jit._script.self_method->getattr(self, method_name)
A:torch.jit._script.qualified_name->_qualified_name(obj)
A:torch.jit._script.maybe_already_compiled_fn->_try_get_jit_cached_function(obj)
A:torch.jit._script.fn->torch._C._jit_script_compile_overload(qual_name, overload_decl, impl_ast, _rcb, implementation_defaults, overload_signature)
A:torch.jit._script.overload_decl->get_jit_def(overload_fn, overload_fn.__name__).decl()
A:torch.jit._script.overload_signature->torch.jit.annotations.get_signature(overload_fn, None, None, inspect.ismethod(overload_fn))
A:torch.jit._script.impl_ast->get_jit_def(impl_fn, impl_fn.__name__)
A:torch.jit._script.overload_defaults->get_default_args(overload_fn)
A:torch.jit._script.implementation_defaults->get_default_args(impl_fn)
A:torch.jit._script.existing_compiled_fns->_try_get_jit_cached_overloads(obj)
A:torch.jit._script.qual_name->_qualified_name(obj)
A:torch.jit._script.uncompiled_overloads->torch._jit_internal._get_fn_overloads(qual_name)
A:torch.jit._script._qual_name->_qualified_name(obj)
A:torch.jit._script.error_stack->torch._C.CallStack(_qual_name, loc)
A:torch.jit._script.self._c->torch._C.CompilationUnit()
torch.jit.CompilationUnit(self,lang=None,_frames_up=0)
torch.jit.CompilationUnit.__getattr__(self,attr)
torch.jit.CompilationUnit.define(self,lang,rcb=None,_frames_up=0)
torch.jit.ScriptWarning(Warning)
torch.jit._script.CompilationUnit(self,lang=None,_frames_up=0)
torch.jit._script.CompilationUnit.__getattr__(self,attr)
torch.jit._script.CompilationUnit.__init__(self,lang=None,_frames_up=0)
torch.jit._script.CompilationUnit.define(self,lang,rcb=None,_frames_up=0)
torch.jit._script.ConstMap(self,const_mapping)
torch.jit._script.ConstMap.__getattr__(self,attr)
torch.jit._script.ConstMap.__init__(self,const_mapping)
torch.jit._script.OrderedDictWrapper(self,_c)
torch.jit._script.OrderedDictWrapper.__contains__(self,k)
torch.jit._script.OrderedDictWrapper.__delitem__(self,k)
torch.jit._script.OrderedDictWrapper.__getitem__(self,k)
torch.jit._script.OrderedDictWrapper.__init__(self,_c)
torch.jit._script.OrderedDictWrapper.__len__(self)
torch.jit._script.OrderedDictWrapper.__setitem__(self,k,v)
torch.jit._script.OrderedDictWrapper.items(self)
torch.jit._script.OrderedDictWrapper.keys(self)
torch.jit._script.OrderedDictWrapper.values(self)
torch.jit._script.OrderedModuleDict(self,module,python_dict)
torch.jit._script.OrderedModuleDict.__contains__(self,k)
torch.jit._script.OrderedModuleDict.__getitem__(self,k)
torch.jit._script.OrderedModuleDict.__init__(self,module,python_dict)
torch.jit._script.OrderedModuleDict.__setitem__(self,k,v)
torch.jit._script.OrderedModuleDict.items(self)
torch.jit._script.ScriptMeta(cls,name,bases,attrs)
torch.jit._script.ScriptMeta.__init__(cls,name,bases,attrs)
torch.jit._script.ScriptWarning(Warning)
torch.jit._script._CachedForward(object)
torch.jit._script._CachedForward.__get__(self,obj,cls)
torch.jit._script._check_directly_compile_overloaded(obj)
torch.jit._script._check_overload_defaults(impl_defaults,overload_defaults,loc)
torch.jit._script._compile_and_register_class(obj,rcb,qualified_name)
torch.jit._script._compile_function_with_overload(overload_fn,qual_name,impl_fn)
torch.jit._script._get_overloads(obj)
torch.jit._script._is_new_style_class(cls)
torch.jit._script._recursive_compile_class(obj,loc)
torch.jit._script._unwrap_optional(x)
torch.jit._script.interface(obj)
torch.jit._script.script(obj,optimize=None,_frames_up=0,_rcb=None)
torch.jit._script.script_method(fn)
torch.jit._unwrap_optional(x)
torch.jit.interface(obj)
torch.jit.script(obj,optimize=None,_frames_up=0,_rcb=None)
torch.jit.script_method(fn)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_async.py----------------------------------------
torch.jit._async.fork(func,*args,**kwargs)
torch.jit._async.wait(future)
torch.jit.fork(func,*args,**kwargs)
torch.jit.wait(future)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_recursive.py----------------------------------------
A:torch.jit._recursive.ScriptMethodStub->collections.namedtuple('ScriptMethodStub', ('resolution_callback', 'def_', 'original_method'))
A:torch.jit._recursive.PropertyStub->collections.namedtuple('Property', ('resolution_callback', 'def_'))
A:torch.jit._recursive.rcb->torch._jit_internal.createResolutionCallbackFromClosure(fn)
A:torch.jit._recursive.ast->get_jit_def(func, name, self_name='RecursiveScriptModule')
A:torch.jit._recursive.func->getattr(nn_module, method_name)
A:torch.jit._recursive.item->getattr(orig_class, name, None)
A:torch.jit._recursive.constants->', '.join((torch.typename(typ) for typ in _constant_types))
A:torch.jit._recursive.concrete_type_builder->infer_concrete_type_builder(nn_module, share_types)
A:torch.jit._recursive.class_annotations->getattr(nn_module, '__annotations__', {})
A:torch.jit._recursive.attr_type->infer_type(name, value)
A:torch.jit._recursive.added_names->set()
A:torch.jit._recursive.sub_concrete_type->get_module_concrete_type(item, share_types)
A:torch.jit._recursive.constants_set->getattr(nn_module, '__constants__', set())
A:torch.jit._recursive.value->getattr(nn_module, name)
A:torch.jit._recursive.overloads->getattr(nn_module, '__overloads__', {})
A:torch.jit._recursive.scripted_fn->torch.jit.script(value)
A:torch.jit._recursive.hint->"(This attribute exists on the Python module, but we failed to convert Python type: '{}' to a TorchScript type.)".format(torch.typename(type(value)))
A:torch.jit._recursive.builtin_symbol_name->_find_builtin(value)
A:torch.jit._recursive.self.methods_compiled->set()
A:torch.jit._recursive.nn_module_type->type(nn_module)
A:torch.jit._recursive.concrete_type->get_module_concrete_type(nn_module, share_types)
A:torch.jit._recursive.concrete_type_store->ConcreteTypeStore()
A:torch.jit._recursive.cpp_module->torch._C._create_module_with_type(concrete_type.jit_type)
A:torch.jit._recursive.method_stubs->stubs_fn(nn_module)
A:torch.jit._recursive.property_stubs->get_property_stubs(nn_module)
A:torch.jit._recursive.orig_value->getattr(nn_module, name)
A:torch.jit._recursive.scripted->create_script_module_impl(orig_value, sub_concrete_type, stubs_fn)
A:torch.jit._recursive.unbound_function->getattr(type(nn_module), name)
A:torch.jit._recursive.bound_method->getattr(type(nn_module), name).__get__(script_module)
A:torch.jit._recursive.script_module->torch.jit.RecursiveScriptModule._construct(cpp_module, init_fn)
A:torch.jit._recursive.keys->repr(list(nn_module.keys()))
A:torch.jit._recursive.script_method->torch._C._create_module_with_type(concrete_type.jit_type)._get_method(name)
A:torch.jit._recursive.wrapped_script_method->functools.wraps(method_stub.original_method)(script_method)
A:torch.jit._recursive.fget->torch._C._create_module_with_type(concrete_type.jit_type)._get_method(property_stub.def_.getter_name().name)
A:torch.jit._recursive.setter_name->property_stub.def_.setter_name()
A:torch.jit._recursive.script_module.__dict__[property_name]->property(property_name, fget, fset)
A:torch.jit._recursive.script_attr->getattr(script_model, attr, None)
A:torch.jit._recursive.default_attr->get_function_from_type(torch.jit.RecursiveScriptModule, attr)
A:torch.jit._recursive.method_overloads->torch._jit_internal._get_overloaded_methods(item, mod.__class__)
A:torch.jit._recursive.overloads[item]->list(zip(names, method_overloads))
A:torch.jit._recursive.signature->torch.jit.annotations.get_signature(func, None, _jit_internal.fake_range(), inspect.ismethod(func))
A:torch.jit._recursive.qual_name->torch._jit_internal._qualified_name(func)
A:torch.jit._recursive.orig_ast->get_jit_def(orig_fn, orig_fn.__name__, self_name='RecursiveScriptModule')
A:torch.jit._recursive.over_ast->get_jit_def(overload_fn, overload_fn.__name__, self_name='RecursiveScriptModule')
A:torch.jit._recursive.new_ast->torch._C._replace_overloaded_method_decl(over_ast.decl(), orig_ast, overload_name)
A:torch.jit._recursive._rcb->torch._jit_internal.createResolutionCallbackFromClosure(orig_fn)
A:torch.jit._recursive.forward_func->getattr(nn_module.forward, '__func__', None)
A:torch.jit._recursive.module_forward->get_function_from_type(torch.nn.Module, 'forward')
A:torch.jit._recursive.overload_name_mappings->dict(getattr(nn_module, '__overloads__', {}))
A:torch.jit._recursive.overload_info->get_overload_annotations(nn_module)
A:torch.jit._recursive.overload_stubs->make_stubs_for_overloads(overload_info)
A:torch.jit._recursive.filtered_methods->filter(ignore_overloaded, methods)
A:torch.jit._recursive.module_ty->type(nn_module)
A:torch.jit._recursive.properties_asts->get_class_properties(module_ty, self_name='RecursiveScriptModule')
A:torch.jit._recursive.rcbs[name]->torch._jit_internal.createResolutionCallbackFromClosure(item.fget)
A:torch.jit._recursive.script_module._concrete_type->torch._C.ConcreteModuleType.from_jit_type(script_module._c._type())
A:torch.jit._recursive.stub->make_stub(fn, fn.__name__)
A:torch.jit._recursive.method->bind_method(unbound_method, script_module, torch.jit.RecursiveScriptModule)
torch.jit._recursive.ConcreteTypeStore(self)
torch.jit._recursive.ConcreteTypeStore.__init__(self)
torch.jit._recursive.ConcreteTypeStore.get_or_create_concrete_type(self,nn_module)
torch.jit._recursive.SourceContext(self,source,filename,file_lineno,leading_whitespace_len)
torch.jit._recursive.SourceContext.__init__(self,source,filename,file_lineno,leading_whitespace_len)
torch.jit._recursive._check_no_signature(func)
torch.jit._recursive._get_valid_constant(attr,v,owner_type)
torch.jit._recursive.add_python_attr_to_scripted_model(script_model,orig,attr)
torch.jit._recursive.check_module_initialized(mod)
torch.jit._recursive.compile_unbound_method(concrete_type,fn)
torch.jit._recursive.create_methods_and_properties_from_stubs(concrete_type,method_stubs,property_stubs)
torch.jit._recursive.create_script_module(nn_module,stubs_fn,share_types=True)
torch.jit._recursive.create_script_module_impl(nn_module,concrete_type,stubs_fn)
torch.jit._recursive.get_module_concrete_type(nn_module,share_types=True)
torch.jit._recursive.get_overload_annotations(mod)
torch.jit._recursive.get_overload_name_mapping(overload_info)
torch.jit._recursive.get_property_stubs(nn_module)
torch.jit._recursive.infer_concrete_type_builder(nn_module,share_types=True)
torch.jit._recursive.infer_methods_to_compile(nn_module)
torch.jit._recursive.interface_script(mod_interface,nn_module)
torch.jit._recursive.lazy_bind(concrete_type,unbound_method)
torch.jit._recursive.make_stub(func,name)
torch.jit._recursive.make_stub_from_method(nn_module,method_name)
torch.jit._recursive.make_stubs_for_overloads(overload_info)
torch.jit._recursive.make_stubs_from_exported_methods(mod)
torch.jit._recursive.script_model_defines_attr(script_model,attr)
torch.jit._recursive.try_compile_fn(fn,loc)
torch.jit._recursive.wrap_cpp_module(cpp_module)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/supported_ops.py----------------------------------------
A:torch.jit.supported_ops.v->'\n{}{}'.format(' ' * indent, v)
A:torch.jit.supported_ops.qualified_name->'{}.{}'.format(mod, name)
A:torch.jit.supported_ops.schema_str->_emit_schema(mod.__name__, fn.__name__, schema)
A:torch.jit.supported_ops.schemas->torch._C._jit_get_schemas_for_operator(op_name)
A:torch.jit.supported_ops.attr->getattr(mod, elem)
A:torch.jit.supported_ops.attr_module->inspect.getmodule(attr)
A:torch.jit.supported_ops.scripted->torch.jit.script(attr)
A:torch.jit.supported_ops.builtin->_find_builtin(fn)
A:torch.jit.supported_ops.mod->inspect.getmodule(fn)
A:torch.jit.supported_ops.builtins->filter(lambda fn: _is_math_fn(fn[0]), _get_builtins_helper())
A:torch.jit.supported_ops.builtins_list->list(builtins)
A:torch.jit.supported_ops.op_name->'aten::{}'.format(fn)
A:torch.jit.supported_ops.table_row->'":any:`{}`", "{}"'.format(fn, schemaless_op_explanations[fn])
A:torch.jit.supported_ops.schematized_ops_str->textwrap.indent(schematized_ops_str, '\t')
A:torch.jit.supported_ops.schemaless_ops_str->textwrap.indent(schemaless_ops_str, '\t')
A:torch.jit.supported_ops.magic_methods_rows_str->textwrap.indent(magic_methods_rows_str, '\t')
A:torch.jit.supported_ops.section->'{}\n{}\n{}'.format(header, '~' * len(header), emit_block(items))
A:torch.jit.supported_ops.(header, items)->fn()
A:torch.jit.supported_ops.link_target->header.replace('`', '').replace('-', '').lower().replace(' ', '-')
A:torch.jit.supported_ops.__doc__->_list_supported_ops()
torch.jit.supported_ops._emit_arg(indent,i,arg)
torch.jit.supported_ops._emit_args(indent,arguments)
torch.jit.supported_ops._emit_ret(ret)
torch.jit.supported_ops._emit_rets(returns)
torch.jit.supported_ops._emit_schema(mod,name,schema,arg_start=0,padding=4)
torch.jit.supported_ops._emit_type(type)
torch.jit.supported_ops._get_builtins_helper()
torch.jit.supported_ops._get_global_builtins()
torch.jit.supported_ops._get_math_builtins()
torch.jit.supported_ops._get_nn_functional_ops()
torch.jit.supported_ops._get_tensor_ops()
torch.jit.supported_ops._get_torchscript_builtins()
torch.jit.supported_ops._hidden(name)
torch.jit.supported_ops._is_math_fn(fn)
torch.jit.supported_ops._list_supported_ops()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_state.py----------------------------------------
A:torch.jit._state.self.enabled->self.parse_env('PYTORCH_JIT', True, '> Using PyTorch JIT', '> PyTorch JIT DISABLED')
A:torch.jit._state.value->os.environ.get(name)
A:torch.jit._state._enabled->EnabledProxy()
A:torch.jit._state._python_cu->torch._C.CompilationUnit()
A:torch.jit._state.qual_names->_jit_function_overload_caching.get(key, None)
A:torch.jit._state.qual_name->_jit_caching_layer.get(key, None)
torch.jit._state.EnabledProxy(self)
torch.jit._state.EnabledProxy.__bool__(self)
torch.jit._state.EnabledProxy.__init__(self)
torch.jit._state.EnabledProxy.parse_env(self,name,default,true_message,false_message)
torch.jit._state._add_script_class(cls,name)
torch.jit._state._get_script_class(name)
torch.jit._state._set_jit_function_cache(key,value)
torch.jit._state._set_jit_overload_cache(key,compiled_fns)
torch.jit._state._try_get_jit_cached_function(key)
torch.jit._state._try_get_jit_cached_overloads(key)
torch.jit._state.disable()
torch.jit._state.enable()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_pickle.py----------------------------------------
torch.jit._pickle.build_boollist(data)
torch.jit._pickle.build_doublelist(data)
torch.jit._pickle.build_intlist(data)
torch.jit._pickle.build_tensor_from_id(data)
torch.jit._pickle.build_tensorlist(data)
torch.jit._pickle.restore_type_tag(value,type_str)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_freeze.py----------------------------------------
A:torch.jit._freeze.out->RecursiveScriptModule(torch._C._freeze_module(mod._c, preserved_attrs))
torch.jit._freeze.freeze(mod,preserved_attrs:Optional[List[str]]=None)
torch.jit.freeze(mod,preserved_attrs:Optional[List[str]]=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/quantized.py----------------------------------------
A:torch.jit.quantized.(self.weight, self.col_offsets, self.scale, self.zero_point)->torch.fbgemm_linear_quantize_weight(other.weight.clone(memory_format=torch.contiguous_format).float())
A:torch.jit.quantized.self.weight->torch.fbgemm_pack_gemm_matrix_fp16(other.weight.clone(memory_format=torch.contiguous_format).float())
A:torch.jit.quantized.self.col_offsets->torch.nn.Parameter(self.col_offsets, requires_grad=False)
A:torch.jit.quantized.self.bias->torch.nn.Parameter(other.bias.clone(memory_format=torch.contiguous_format).float(), requires_grad=False)
A:torch.jit.quantized.out->torch.fbgemm_linear_fp16_weight_fp32_activation(input.float(), self.packed_weight, self.bias)
A:torch.jit.quantized.repr->'in_features={in_features}, out_features={out_features}, '.format(**self.__dict__)
A:torch.jit.quantized.(weight_ih, col_offsets_ih, self.scale_ih, self.zero_point_ih)->torch.fbgemm_linear_quantize_weight(other.weight_ih.clone(memory_format=torch.contiguous_format).float())
A:torch.jit.quantized.(weight_hh, col_offsets_hh, self.scale_hh, self.zero_point_hh)->torch.fbgemm_linear_quantize_weight(other.weight_hh.clone(memory_format=torch.contiguous_format).float())
A:torch.jit.quantized.packed_ih->torch.ops.quantized.linear_prepack_fp16(weight_ih.float(), bias_ih)
A:torch.jit.quantized.packed_hh->torch.ops.quantized.linear_prepack_fp16(weight_hh.float(), bias_hh)
A:torch.jit.quantized.self.bias_ih->torch.nn.Parameter(other.bias_ih.clone(memory_format=torch.contiguous_format).float(), requires_grad=False)
A:torch.jit.quantized.self.bias_hh->torch.nn.Parameter(other.bias_hh.clone(memory_format=torch.contiguous_format).float(), requires_grad=False)
A:torch.jit.quantized.hx->self.permute_hidden(hx, sorted_indices)
A:torch.jit.quantized.ret->torch._VF.quantized_rnn_relu_cell(input, hx, self.weight_ih, self.weight_hh, self.bias_ih, self.bias_hh, self.packed_ih, self.packed_hh, self.col_offsets_ih, self.col_offsets_hh, self.scale_ih, self.scale_hh, self.zero_point_ih, self.zero_point_hh)
A:torch.jit.quantized.zeros->torch.zeros(self.num_layers * num_directions, max_batch_size, self.hidden_size, dtype=input.dtype, device=input.device)
A:torch.jit.quantized.weight_name->'weight_{}_l{}{}'.format(ihhh, layer, suffix)
A:torch.jit.quantized.bias_name->'bias_{}_l{}{}'.format(ihhh, layer, suffix)
A:torch.jit.quantized.weight->getattr(other, weight_name)
A:torch.jit.quantized.bias->getattr(other, bias_name)
A:torch.jit.quantized.(weight_ih, bias_ih)->get_weight_bias('ih')
A:torch.jit.quantized.(weight_hh, bias_hh)->get_weight_bias('hh')
A:torch.jit.quantized.cell_params->torch.ops.quantized.make_quantized_cell_params_fp16(packed_ih, packed_hh)
A:torch.jit.quantized.mini_batch->int(batch_sizes[0])
A:torch.jit.quantized.expected_hidden_size->self.get_expected_hidden_size(input, batch_sizes)
A:torch.jit.quantized.result->torch.quantized_gru(input, batch_sizes, hx, self.all_weights, self.bias, self.num_layers, float(self.dropout), self.training, self.bidirectional)
A:torch.jit.quantized.(output, hidden)->self.forward_impl(input, hx, batch_sizes, max_batch_size, sorted_indices)
A:torch.jit.quantized.max_batch_size->int(max_batch_size)
A:torch.jit.quantized.output->PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)
A:torch.jit.quantized.new_mod->quantize_rnn_modules(mod, dtype)
torch.jit.quantized.QuantizedGRU(QuantizedRNNBase)
torch.jit.quantized.QuantizedGRU.forward(self,input,hx=None)
torch.jit.quantized.QuantizedGRU.forward_impl(self,input,hx,batch_sizes,max_batch_size,sorted_indices)
torch.jit.quantized.QuantizedGRU.forward_packed(self,input,hx=None)
torch.jit.quantized.QuantizedGRU.forward_tensor(self,input,hx=None)
torch.jit.quantized.QuantizedGRUCell(self,other)
torch.jit.quantized.QuantizedGRUCell.__init__(self,other)
torch.jit.quantized.QuantizedGRUCell.forward(self,input,hx=None)
torch.jit.quantized.QuantizedLSTM(self,other,dtype)
torch.jit.quantized.QuantizedLSTM.__init__(self,other,dtype)
torch.jit.quantized.QuantizedLSTM.check_forward_args(self,input,hidden,batch_sizes)
torch.jit.quantized.QuantizedLSTM.forward(self,input,hx=None)
torch.jit.quantized.QuantizedLSTM.forward_impl(self,input,hx,batch_sizes,max_batch_size,sorted_indices)
torch.jit.quantized.QuantizedLSTM.forward_packed(self,input,hx=None)
torch.jit.quantized.QuantizedLSTM.forward_tensor(self,input,hx=None)
torch.jit.quantized.QuantizedLSTM.permute_hidden(self,hx,permutation)
torch.jit.quantized.QuantizedLSTMCell(self,other)
torch.jit.quantized.QuantizedLSTMCell.__init__(self,other)
torch.jit.quantized.QuantizedLSTMCell.forward(self,input,hx=None)
torch.jit.quantized.QuantizedLinear(self,other)
torch.jit.quantized.QuantizedLinear.__init__(self,other)
torch.jit.quantized.QuantizedLinear._pack(self)
torch.jit.quantized.QuantizedLinear._unpack(self)
torch.jit.quantized.QuantizedLinear.extra_repr(self)
torch.jit.quantized.QuantizedLinear.forward(self,input)
torch.jit.quantized.QuantizedLinearFP16(self,other)
torch.jit.quantized.QuantizedLinearFP16.__init__(self,other)
torch.jit.quantized.QuantizedLinearFP16._pack(self)
torch.jit.quantized.QuantizedLinearFP16._unpack(self)
torch.jit.quantized.QuantizedLinearFP16.extra_repr(self)
torch.jit.quantized.QuantizedLinearFP16.forward(self,input)
torch.jit.quantized.QuantizedRNNBase(self,other,dtype=torch.int8)
torch.jit.quantized.QuantizedRNNBase.__init__(self,other,dtype=torch.int8)
torch.jit.quantized.QuantizedRNNBase.check_forward_args(self,input,hidden,batch_sizes)
torch.jit.quantized.QuantizedRNNBase.check_hidden_size(self,hx,expected_hidden_size,msg='Expectedhiddensize{},got{}')
torch.jit.quantized.QuantizedRNNBase.check_input(self,input,batch_sizes)
torch.jit.quantized.QuantizedRNNBase.get_expected_hidden_size(self,input,batch_sizes)
torch.jit.quantized.QuantizedRNNBase.permute_hidden(self,hx,permutation)
torch.jit.quantized.QuantizedRNNCell(self,other)
torch.jit.quantized.QuantizedRNNCell.__init__(self,other)
torch.jit.quantized.QuantizedRNNCell.forward(self,input,hx=None)
torch.jit.quantized.QuantizedRNNCellBase(self,other)
torch.jit.quantized.QuantizedRNNCellBase.__init__(self,other)
torch.jit.quantized.QuantizedRNNCellBase._pack(self)
torch.jit.quantized.QuantizedRNNCellBase._unpack(self)
torch.jit.quantized.QuantizedRNNCellBase.check_forward_hidden(self,input,hx,hidden_label='')
torch.jit.quantized.QuantizedRNNCellBase.check_forward_input(self,input)
torch.jit.quantized.QuantizedRNNCellBase.extra_repr(self)
torch.jit.quantized.apply_permutation(tensor,permutation,dim=1)
torch.jit.quantized.quantize_linear_modules(module,dtype=torch.int8)
torch.jit.quantized.quantize_rnn_cell_modules(module)
torch.jit.quantized.quantize_rnn_modules(module,dtype=torch.int8)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/unsupported_tensor_ops.py----------------------------------------
A:torch.jit.unsupported_tensor_ops.tensor_attrs->set(filter(lambda x: x[0] != '_', dir(torch.Tensor)))
A:torch.jit.unsupported_tensor_ops.tensor->torch.tensor([2])
A:torch.jit.unsupported_tensor_ops.funcs_template->dedent('\n    def func(x):\n        return x.{op}()\n    ')
A:torch.jit.unsupported_tensor_ops.deprecated_apis->set(['volatile', 'resize', 'reinforce', 'new', 'name', 'map2_', 'has_names', 'grad_fn', 'resize_as'])
A:torch.jit.unsupported_tensor_ops.sorted_tensor_attrs->sorted(list(tensor_attrs), key=lambda x: x.lower())
A:torch.jit.unsupported_tensor_ops.funcs_str->dedent('\n    def func(x):\n        return x.{op}()\n    ').format(op=attr)
A:torch.jit.unsupported_tensor_ops.cu->torch.jit.CompilationUnit(funcs_str)
A:torch.jit.unsupported_tensor_ops.attr_repr->repr(getattr(tensor, attr))
A:torch.jit.unsupported_tensor_ops.mapped_methods->map(lambda x: '\t*  :meth:`~torch.Tensor.' + x + '`', methods)
A:torch.jit.unsupported_tensor_ops.mapped_properties->map(lambda x: '\t*  :attr:`~torch.Tensor.' + x + '`', properties)
A:torch.jit.unsupported_tensor_ops.(methods, properties)->_gen_unsupported_methods_properties()
A:torch.jit.unsupported_tensor_ops.__doc__->_list_unsupported_tensor_ops()
torch.jit.unsupported_tensor_ops._gen_unsupported_methods_properties()
torch.jit.unsupported_tensor_ops._list_unsupported_tensor_ops()
torch.jit.unsupported_tensor_ops.execWrapper(code,glob,loc)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_serialization.py----------------------------------------
A:torch.jit._serialization.ret->m.save_to_buffer(_extra_files=_extra_files)
A:torch.jit._serialization.map_location->torch.device(map_location)
A:torch.jit._serialization.cu->torch._C.CompilationUnit()
A:torch.jit._serialization.cpp_module->torch._C.import_ir_module_from_buffer(cu, f.read(), map_location, _extra_files)
torch.jit._serialization.load(f,map_location=None,_extra_files=None)
torch.jit._serialization.save(m,f,_extra_files=None)
torch.jit._serialization.validate_map_location(map_location=None)
torch.jit.load(f,map_location=None,_extra_files=None)
torch.jit.save(m,f,_extra_files=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/__init__.py----------------------------------------
torch.jit.__init__.annotate(the_type,the_value)
torch.jit.__init__.export_opnames(m)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_builtins.py----------------------------------------
A:torch.jit._builtins._functional_registered_ops->_gen_torch_functional_registered_ops()
A:torch.jit._builtins.v->getattr(mod, name)
torch.jit._builtins._find_builtin(fn)
torch.jit._builtins._gen_torch_functional_registered_ops()
torch.jit._builtins._get_builtin_table()
torch.jit._builtins._is_special_functional_bound_op(fn)
torch.jit._builtins._register_builtin(fn,op)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_logging.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/_fuser.py----------------------------------------
A:torch.jit._fuser.stored_flag->torch._C._get_graph_executor_optimize()
A:torch.jit._fuser.old_cpu_fuse->torch._C._jit_can_fuse_on_cpu()
A:torch.jit._fuser.old_gpu_fuse->torch._C._jit_can_fuse_on_gpu()
A:torch.jit._fuser.old_texpr_fuser_state->torch._C._jit_texpr_fuser_enabled()
A:torch.jit._fuser.old_nvfuser_state->torch._C._jit_nvfuser_enabled()
A:torch.jit._fuser.old_profiling_executor->torch._C._jit_set_profiling_executor(True)
A:torch.jit._fuser.old_profiling_mode->torch._C._jit_set_profiling_mode(True)
torch.jit._fuser._graph_for(self,*args,**kwargs)
torch.jit._fuser.fuser(name)
torch.jit._fuser.optimized_execution(should_optimize)
torch.jit.fuser(name)
torch.jit.optimized_execution(should_optimize)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/jit/mobile/__init__.py----------------------------------------
A:torch.jit.mobile.__init__.map_location->validate_map_location(map_location)
A:torch.jit.mobile.__init__.cpp_module->torch._C._load_for_lite_interpreter_from_buffer(f.read(), map_location)
torch.jit.mobile.__init__.LiteScriptModule(self,cpp_module)
torch.jit.mobile.__init__.LiteScriptModule.__init__(self,cpp_module)
torch.jit.mobile.__init__.LiteScriptModule.find_method(self,method_name)
torch.jit.mobile.__init__.LiteScriptModule.forward(self,*input)
torch.jit.mobile.__init__.LiteScriptModule.run_method(self,method_name,*input)
torch.jit.mobile.__init__._load_for_lite_interpreter(f,map_location=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_opset8.py----------------------------------------
A:torch.onnx.symbolic_opset8.vars()[block_listed_op]->_block_list_in_opset(block_listed_op)
A:torch.onnx.symbolic_opset8.(scales, align_corners)->torch.onnx.symbolic_helper._get_interpolate_attributes(g, interpolate_mode, args)
A:torch.onnx.symbolic_opset8.align_corners->torch.onnx.symbolic_helper._maybe_get_const(align_corners, 'b')
A:torch.onnx.symbolic_opset8.output_size->torch.onnx.symbolic_helper._maybe_get_const(output_size, 'is')
A:torch.onnx.symbolic_opset8.upsample_nearest1d->_interpolate('upsample_nearest1d', 3, 'nearest')
A:torch.onnx.symbolic_opset8.upsample_nearest2d->_interpolate('upsample_nearest2d', 4, 'nearest')
A:torch.onnx.symbolic_opset8.upsample_nearest3d->_interpolate('upsample_nearest3d', 5, 'nearest')
A:torch.onnx.symbolic_opset8.upsample_linear1d->_interpolate('upsample_linear1d', 3, 'linear')
A:torch.onnx.symbolic_opset8.upsample_bilinear2d->_interpolate('upsample_bilinear2d', 4, 'linear')
A:torch.onnx.symbolic_opset8.upsample_trilinear3d->_interpolate('upsample_trilinear3d', 5, 'linear')
A:torch.onnx.symbolic_opset8.(scales, mode)->torch.onnx.symbolic_helper._interpolate_get_scales_and_mode(g, input, size, scale_factor, mode, align_corners)
A:torch.onnx.symbolic_opset8.arg0_type->args[0].type().scalarType()
A:torch.onnx.symbolic_opset8.args->tuple((_cast_Float(g, arg, False) for arg in args))
A:torch.onnx.symbolic_opset8.other->torch.onnx.symbolic_helper._if_scalar_type_as(g, other, input)
A:torch.onnx.symbolic_opset8.(_, input, other)->_try_cast_integer_to_float(g, input, other)
A:torch.onnx.symbolic_opset8.(old_type, self, other)->_try_cast_integer_to_float(g, self, other)
A:torch.onnx.symbolic_opset8.self_sizes->torch.onnx.symbolic_opset9.view(g, self, g.op('Constant', value_t=torch.tensor([1] * diff_dims + sizes))).type().sizes()
A:torch.onnx.symbolic_opset8.weight->g.op('Unsqueeze', weight, axes_i=list(range(1, len(self_sizes) - 1)))
A:torch.onnx.symbolic_opset8.(old_type, self, weight)->_try_cast_integer_to_float(g, self, weight)
A:torch.onnx.symbolic_opset8.ty->torch.onnx.symbolic_helper._try_get_scalar_type(self, other).lower()
A:torch.onnx.symbolic_opset8.C->g.constant(0, [1], ty)
A:torch.onnx.symbolic_opset8.(old_type, self, other, C)->_try_cast_integer_to_float(g, self, other, C)
A:torch.onnx.symbolic_opset8.(old_type, self, mat1, mat2)->_try_cast_integer_to_float(g, self, mat1, mat2)
A:torch.onnx.symbolic_opset8.start_dim_i->torch.onnx.symbolic_helper._get_const(start_dim, 'i', 'start_dim')
A:torch.onnx.symbolic_opset8.end_dim_i->torch.onnx.symbolic_helper._get_const(end_dim, 'i', 'end_dim')
A:torch.onnx.symbolic_opset8.dim->input.type().dim()
A:torch.onnx.symbolic_opset8.(old_type, input)->_try_cast_integer_to_float(g, input)
A:torch.onnx.symbolic_opset8.result->g.op('ConstantFill', sizes, dtype_i=sym_help.cast_pytorch_to_onnx['Float'], input_as_shape_i=1, value_f=const_value)
A:torch.onnx.symbolic_opset8.shape->g.op('Shape', input)
A:torch.onnx.symbolic_opset8.const_value->torch.onnx.symbolic_helper._maybe_get_const(value, 't')
A:torch.onnx.symbolic_opset8.tmp->zeros(g, sizes, dtype, layout, device)
A:torch.onnx.symbolic_opset8.dtype->torch.onnx.symbolic_helper._get_const(dtype, 'i', 'dtype')
A:torch.onnx.symbolic_opset8.repeats->g.op('Constant', value_t=torch.LongTensor(repeats))
A:torch.onnx.symbolic_opset8.repeat_size_len->len(const_repeats)
A:torch.onnx.symbolic_opset8.const_repeats->torch.onnx.symbolic_helper._maybe_get_const(repeats, 'is')
A:torch.onnx.symbolic_opset8.sizes->torch.onnx.symbolic_opset9.view(g, self, g.op('Constant', value_t=torch.tensor([1] * diff_dims + sizes))).type().sizes()
A:torch.onnx.symbolic_opset8.self->torch.onnx.symbolic_opset9.view(g, self, g.op('Constant', value_t=torch.tensor([1] * diff_dims + sizes)))
torch.onnx.symbolic_opset8.__interpolate(g,input,size,scale_factor,mode,align_corners,recompute_scale_factor)
torch.onnx.symbolic_opset8._cast_to_type(g,input,to_type)
torch.onnx.symbolic_opset8._comparison_operator(g,input,other,op_name)
torch.onnx.symbolic_opset8._constant_fill(g,sizes,dtype,const_value)
torch.onnx.symbolic_opset8._interpolate(name,dim,interpolate_mode)
torch.onnx.symbolic_opset8._try_cast_integer_to_float(g,*args)
torch.onnx.symbolic_opset8.addmm(g,self,mat1,mat2,beta,alpha)
torch.onnx.symbolic_opset8.bmm(g,self,other)
torch.onnx.symbolic_opset8.empty(g,sizes,dtype,layout,device,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset8.empty_like(g,input,dtype,layout,device,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset8.flatten(g,input,start_dim,end_dim)
torch.onnx.symbolic_opset8.full(g,sizes,value,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset8.full_like(g,input,fill_value,dtype,layout,device,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset8.gt(g,input,other)
torch.onnx.symbolic_opset8.lt(g,input,other)
torch.onnx.symbolic_opset8.matmul(g,self,other)
torch.onnx.symbolic_opset8.mm(g,self,other)
torch.onnx.symbolic_opset8.ones(g,sizes,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset8.ones_like(g,input,dtype,layout,device,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset8.prelu(g,self,weight)
torch.onnx.symbolic_opset8.repeat(g,self,repeats)
torch.onnx.symbolic_opset8.zeros(g,sizes,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset8.zeros_like(g,input,dtype,layout,device,pin_memory=False,memory_format=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/utils.py----------------------------------------
A:torch.onnx.utils.output_type->node.output().type()
A:torch.onnx.utils.input->g.insertConstant(val)
A:torch.onnx.utils.lc->g.create('prim::ListConstruct', inputs).insertBefore(node).output().setType(ListType.ofTensors())
A:torch.onnx.utils.graph->_optimize_graph(graph, operator_export_type, _disable_torch_constant_prop=_disable_torch_constant_prop, fixed_batch_size=fixed_batch_size, params_dict=params_dict, use_new_jit_passes=use_new_jit_passes, dynamic_axes=dynamic_axes, input_names=input_names)
A:torch.onnx.utils.do_constant_folding->_resolve_args_by_export_type('do_constant_folding', do_constant_folding, operator_export_type)
A:torch.onnx.utils.val_use_external_data_format->_resolve_args_by_export_type('use_external_data_format', use_external_data_format, operator_export_type)
A:torch.onnx.utils.(trace_graph, torch_out, inputs_states)->torch.jit._get_trace_graph(model, args, strict=False, _force_outplace=False, _return_inputs_states=True)
A:torch.onnx.utils.trace_graph->_optimize_graph(trace_graph, operator_export_type)
A:torch.onnx.utils.orig_state_dict_keys->_unique_state_dict(model).keys()
A:torch.onnx.utils.(method_graph, params)->torch._C._jit_pass_lower_graph(graph, model._c)
A:torch.onnx.utils.freezed_m->torch._C._freeze_module(model._c)
A:torch.onnx.utils.(in_vars, in_desc)->torch.jit._flatten(tuple(args))
A:torch.onnx.utils.(graph, torch_out)->_trace_and_get_graph_from_model(model, args)
A:torch.onnx.utils.state_dict->_unique_state_dict(model)
A:torch.onnx.utils.params->list(state_dict.values())
A:torch.onnx.utils.graph_inputs->list(graph.inputs())
A:torch.onnx.utils.param_names->list(state_dict.keys())
A:torch.onnx.utils.(graph, params, torch_out)->_create_jit_graph(model, args, _retain_param_name, use_new_jit_passes)
A:torch.onnx.utils.params_dict->torch._C._jit_pass_filter_non_tensor_arguments(params_dict)
A:torch.onnx.utils.(out_vars, _)->torch.jit._flatten(tuple(example_outputs))
A:torch.onnx.utils.(output_tensors, _)->torch._C._jit_flatten(torch_out)
A:torch.onnx.utils.(flatten_args, _)->torch._C._jit_flatten(args)
A:torch.onnx.utils.val_keep_init_as_ip->_decide_keep_init_as_input(keep_initializers_as_inputs, operator_export_type, opset_version)
A:torch.onnx.utils.val_add_node_names->_decide_add_node_names(add_node_names, operator_export_type)
A:torch.onnx.utils.val_do_constant_folding->_decide_constant_folding(do_constant_folding, operator_export_type, training)
A:torch.onnx.utils.(graph, params_dict, torch_out)->_model_to_graph(model, args, verbose, input_names, output_names, operator_export_type, example_outputs, _retain_param_name, val_do_constant_folding, fixed_batch_size=fixed_batch_size, training=training, use_new_jit_passes=use_new_jit_passes, dynamic_axes=dynamic_axes)
A:torch.onnx.utils.unsupported_ops->list()
A:torch.onnx.utils.(val_use_external_data_format, model_file_location)->_decide_external_data_format(use_external_data_format, operator_export_type, f)
A:torch.onnx.utils.(proto, export_map)->_optimize_graph(graph, operator_export_type, _disable_torch_constant_prop=_disable_torch_constant_prop, fixed_batch_size=fixed_batch_size, params_dict=params_dict, use_new_jit_passes=use_new_jit_passes, dynamic_axes=dynamic_axes, input_names=input_names)._export_onnx({}, opset_version, dynamic_axes, False, operator_export_type, strip_doc_string, val_keep_init_as_ip, custom_opsets, val_add_node_names, val_use_external_data_format, model_file_location)
A:torch.onnx.utils.model_proto_file->os.path.join(f, ONNX_ARCHIVE_MODEL_PROTO_NAME)
A:torch.onnx.utils.weight_proto_file->os.path.join(f, k)
A:torch.onnx.utils.attr_pattern->re.compile('^(.+)_([ifstgz])$')
A:torch.onnx.utils.m->re.compile('^(.+)_([ifstgz])$').match(key)
A:torch.onnx.utils.value->_scalar(value)
A:torch.onnx.utils.aten->dict(((k, v) for (k, v) in kwargs.items() if v is not None)).pop('aten', False)
A:torch.onnx.utils.n->b.addNode(ns_opname, list(args))
A:torch.onnx.utils.outputs->b.addNode(ns_opname, list(args)).outputsSize()
A:torch.onnx.utils.kwargs->dict(((k, v) for (k, v) in kwargs.items() if v is not None))
A:torch.onnx.utils.args->list((const_if_tensor(arg) for arg in raw_args))
A:torch.onnx.utils.new_output->block.registerOutput(value)
A:torch.onnx.utils.ns_op_name->b.addNode(ns_opname, list(args)).kind()
A:torch.onnx.utils.(ns, op_name)->symbolic_name.split('::')
A:torch.onnx.utils.is_exportable_aten_op->torch.onnx.symbolic_registry.is_registered_op(op_name, '', opset_version)
A:torch.onnx.utils.symbolic_fn->_find_symbolic_in_registry(domain, op_name, opset_version, operator_export_type)
A:torch.onnx.utils.vals->b.addNode(ns_opname, list(args)).output().toIValue()
A:torch.onnx.utils.new_op_outputs->torch._C._jit_pass_fixup_onnx_controlflow_node(new_node, opset_version)
A:torch.onnx.utils.new_block->new_node.addBlock()
A:torch.onnx.utils.type->type.lower().lower()
A:torch.onnx.utils.tensor->torch.DoubleTensor(*dims)
A:torch.onnx.utils.sel->self.kindOf(k)
A:torch.onnx.utils.valid_names->set((input_names or []) + (output_names or []))
torch.onnx.utils._add_attribute(node,key,value,aten)
torch.onnx.utils._add_block(node)
torch.onnx.utils._add_input_to_block(block)
torch.onnx.utils._add_output_to_block(block,value)
torch.onnx.utils._block_op(b,opname,*args,**kwargs)
torch.onnx.utils._create_jit_graph(model,args,_retain_param_name,use_new_jit_passes)
torch.onnx.utils._decide_add_node_names(add_node_names,operator_export_type)
torch.onnx.utils._decide_constant_folding(do_constant_folding,operator_export_type,training)
torch.onnx.utils._decide_external_data_format(use_external_data_format,operator_export_type,f)
torch.onnx.utils._decide_keep_init_as_input(keep_initializers_as_inputs,operator_export_type,opset_version)
torch.onnx.utils._export(model,args,f,export_params=True,verbose=False,training=None,input_names=None,output_names=None,operator_export_type=None,export_type=ExportTypes.PROTOBUF_FILE,example_outputs=None,opset_version=None,_retain_param_name=False,do_constant_folding=True,strip_doc_string=True,dynamic_axes=None,keep_initializers_as_inputs=None,fixed_batch_size=False,custom_opsets=None,add_node_names=True,enable_onnx_checker=True,use_external_data_format=False,onnx_shape_inference=False,use_new_jit_passes=False)
torch.onnx.utils._export_to_pretty_string(model,args,f,export_params=True,verbose=False,training=None,input_names=None,output_names=None,operator_export_type=OperatorExportTypes.ONNX,export_type=ExportTypes.PROTOBUF_FILE,example_outputs=None,google_printer=False,opset_version=None,_retain_param_name=False,do_constant_folding=True,keep_initializers_as_inputs=None,fixed_batch_size=False,custom_opsets=None,add_node_names=True)
torch.onnx.utils._find_missing_ops_onnx_export(model,args,f,verbose=False,training=TrainingMode.EVAL,input_names=None,output_names=None,opset_version=None,dynamic_axes=None)
torch.onnx.utils._find_symbolic_in_registry(domain,op_name,opset_version,operator_export_type)
torch.onnx.utils._graph_at(g,opname,*args,**kwargs)
torch.onnx.utils._graph_constant(g,value,dims,type,*args,**kwargs)
torch.onnx.utils._graph_op(g,opname,*raw_args,**kwargs)
torch.onnx.utils._is_constant_tensor_list(node)
torch.onnx.utils._is_onnx_list(value)
torch.onnx.utils._model_to_graph(model,args,verbose=False,input_names=None,output_names=None,operator_export_type=OperatorExportTypes.ONNX,example_outputs=None,_retain_param_name=False,do_constant_folding=True,_disable_torch_constant_prop=False,fixed_batch_size=False,training=None,use_new_jit_passes=False,dynamic_axes=None)
torch.onnx.utils._newNode(g,opname,outputs,*args,**kwargs)
torch.onnx.utils._node_getitem(self,k)
torch.onnx.utils._optimize_graph(graph,operator_export_type,_disable_torch_constant_prop=False,fixed_batch_size=False,params_dict=None,use_new_jit_passes=False,dynamic_axes=None,input_names=None)
torch.onnx.utils._resolve_args_by_export_type(arg_name,arg_value,operator_export_type)
torch.onnx.utils._run_symbolic_function(g,n,inputs,env,operator_export_type=OperatorExportTypes.ONNX)
torch.onnx.utils._run_symbolic_method(op_name,symbolic_fn,args)
torch.onnx.utils._scalar(x)
torch.onnx.utils._set_input_and_output_names(graph,input_names,output_names)
torch.onnx.utils._split_tensor_list_constants(g,block)
torch.onnx.utils._trace(func,args,operator_export_type,return_outs=False)
torch.onnx.utils._trace_and_get_graph_from_model(model,args)
torch.onnx.utils._validate_dynamic_axes(dynamic_axes,model,input_names,output_names)
torch.onnx.utils.export(model,args,f,export_params=True,verbose=False,training=None,input_names=None,output_names=None,aten=False,export_raw_ir=False,operator_export_type=None,opset_version=None,_retain_param_name=True,do_constant_folding=True,example_outputs=None,strip_doc_string=True,dynamic_axes=None,keep_initializers_as_inputs=None,custom_opsets=None,enable_onnx_checker=True,use_external_data_format=False)
torch.onnx.utils.export_to_pretty_string(model,args,f,export_params=True,verbose=False,training=None,input_names=None,output_names=None,aten=False,export_raw_ir=False,operator_export_type=None,export_type=ExportTypes.PROTOBUF_FILE,example_outputs=None,google_printer=False,opset_version=None,_retain_param_name=True,keep_initializers_as_inputs=None,custom_opsets=None,add_node_names=True,do_constant_folding=True)
torch.onnx.utils.is_in_onnx_export()
torch.onnx.utils.register_custom_op_symbolic(symbolic_name,symbolic_fn,opset_version)
torch.onnx.utils.select_model_mode_for_export(model,mode)
torch.onnx.utils.warn_on_static_input_change(input_states)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_helper.py----------------------------------------
A:torch.onnx.symbolic_helper.value_t->_maybe_get_const(value, 't')
A:torch.onnx.symbolic_helper.list_node->list_value.node()
A:torch.onnx.symbolic_helper.wrapper->wraps(fn)(wrapper)
A:torch.onnx.symbolic_helper.scalar_type->tensor.type().scalarType()
A:torch.onnx.symbolic_helper.ty->tensor.type().scalarType().lower()
A:torch.onnx.symbolic_helper.type->scalar_type_to_pytorch_type.index(torch.get_default_dtype())
A:torch.onnx.symbolic_helper.shape_->g.op('Shape', input)
A:torch.onnx.symbolic_helper.dim_size_->g.op('Gather', shape_, g.op('Constant', value_t=torch.tensor([dim], dtype=torch.int64)))
A:torch.onnx.symbolic_helper.k->g.op('Reshape', k, g.op('Constant', value_t=torch.tensor([1])))
A:torch.onnx.symbolic_helper.output_size->_maybe_get_const(output_size, 'is')
A:torch.onnx.symbolic_helper.offsets->g.op('Constant', value_t=torch.ones(2, dtype=torch.float32))
A:torch.onnx.symbolic_helper.dividend->g.op('Cast', output_size, to_i=cast_pytorch_to_onnx['Float'])
A:torch.onnx.symbolic_helper.divisor->g.op('Cast', divisor, to_i=cast_pytorch_to_onnx['Float'])
A:torch.onnx.symbolic_helper.scale_dims->g.op('Div', dividend, divisor)
A:torch.onnx.symbolic_helper.scales->_interpolate_get_scales_if_available(g, scales)
A:torch.onnx.symbolic_helper.scales_list->g.op('Constant', value_t=torch.tensor(_maybe_get_const(scales[0], 'fs')))
A:torch.onnx.symbolic_helper.scale_factor->_interpolate_size_to_scales(g, input, size, dim)
A:torch.onnx.symbolic_helper.mode->_maybe_get_const(mode, 's')
A:torch.onnx.symbolic_helper.align_corners->_maybe_get_const(align_corners, 'b')
A:torch.onnx.symbolic_helper.dim->input.type().dim()
A:torch.onnx.symbolic_helper.size->g.op('Concat', *size, axis_i=0)
A:torch.onnx.symbolic_helper.full_shape->g.op('Shape', self)
A:torch.onnx.symbolic_helper.self_dim->self.type().dim()
A:torch.onnx.symbolic_helper.dim_value->_parse_arg(dim, 'i')
A:torch.onnx.symbolic_helper.unsqueezed_index->g.op('Unsqueeze', index, axes_i=[i for i in range(self_dim) if i != dim_value])
A:torch.onnx.symbolic_helper.expanded_index_shape->scatter(g, g.op('Shape', self), 0, g.op('Unsqueeze', dim, axes_i=[0]), g.op('Shape', index))
A:torch.onnx.symbolic_helper.expanded_index->expand(g, unsqueezed_index, expanded_index_shape, None)
A:torch.onnx.symbolic_helper.padding->tuple(tuple_fn(padding))
A:torch.onnx.symbolic_helper.input_size->g.op('Shape', input)
A:torch.onnx.symbolic_helper.slice1->_slice_helper(g, input_size, axes=[0], starts=[0], ends=[start_dim])
A:torch.onnx.symbolic_helper.slice3->_slice_helper(g, input_size, axes=[0], starts=[end_dim + 1], ends=[dim])
A:torch.onnx.symbolic_helper.final_shape->g.op('Concat', *slices, axis_i=0)
A:torch.onnx.symbolic_helper._quantized_ops->set()
torch.onnx.symbolic_helper._arange_cast_helper(g,end,start=None,step=None,dtype=None)
torch.onnx.symbolic_helper._avgpool_helper(tuple_fn,padding,kernel_size,stride,divisor_override,name)
torch.onnx.symbolic_helper._block_list_in_opset(name)
torch.onnx.symbolic_helper._cast_func_template(to_i,g,input,non_blocking)
torch.onnx.symbolic_helper._flatten_helper(g,input,start_dim,end_dim,dim)
torch.onnx.symbolic_helper._get_const(value,desc,arg_name)
torch.onnx.symbolic_helper._get_interpolate_attributes(g,mode,args)
torch.onnx.symbolic_helper._if_scalar_type_as(g,self,tensor)
torch.onnx.symbolic_helper._index_fill_reshape_helper(g,self,dim,index)
torch.onnx.symbolic_helper._interpolate_get_scales(g,scale_factor,dim)
torch.onnx.symbolic_helper._interpolate_get_scales_and_mode(g,input,size,scale_factor,mode,align_corners)
torch.onnx.symbolic_helper._interpolate_get_scales_if_available(g,scales)
torch.onnx.symbolic_helper._interpolate_size_to_scales(g,input,output_size,dim)
torch.onnx.symbolic_helper._interpolate_warning(interpolate_mode)
torch.onnx.symbolic_helper._is_fp(value)
torch.onnx.symbolic_helper._is_none(x)
torch.onnx.symbolic_helper._is_packed_list(list_value)
torch.onnx.symbolic_helper._is_split_static(split_size_or_sizes,_outputs)
torch.onnx.symbolic_helper._is_tensor(x)
torch.onnx.symbolic_helper._is_tensor_list(x)
torch.onnx.symbolic_helper._is_value(x)
torch.onnx.symbolic_helper._maybe_get_const(value,desc)
torch.onnx.symbolic_helper._maybe_get_scalar(value)
torch.onnx.symbolic_helper._onnx_opset_unsupported(op_name,current_opset,supported_opset)
torch.onnx.symbolic_helper._onnx_opset_unsupported_detailed(op_name,current_opset,supported_opset,reason)
torch.onnx.symbolic_helper._onnx_unsupported(op_name)
torch.onnx.symbolic_helper._parse_arg(value,desc)
torch.onnx.symbolic_helper._scalar(x)
torch.onnx.symbolic_helper._scatter_helper(g,self,dim,index,src)
torch.onnx.symbolic_helper._set_onnx_shape_inference(onnx_shape_inference)
torch.onnx.symbolic_helper._set_operator_export_type(operator_export_type)
torch.onnx.symbolic_helper._set_opset_version(opset_version)
torch.onnx.symbolic_helper._set_training_mode(training_mode)
torch.onnx.symbolic_helper._size_helper(g,self,dim)
torch.onnx.symbolic_helper._slice_helper(g,input,axes,starts,ends,steps=None,dynamic_slice=False)
torch.onnx.symbolic_helper._sort_helper(g,input,dim,decending=True,out=None)
torch.onnx.symbolic_helper._topk_helper(g,input,k,dim,largest=True,sorted=False,out=None)
torch.onnx.symbolic_helper._try_get_scalar_type(*args)
torch.onnx.symbolic_helper._unimplemented(op,msg)
torch.onnx.symbolic_helper._unpack_list(list_value)
torch.onnx.symbolic_helper._unsqueeze_helper(g,input,dim)
torch.onnx.symbolic_helper.assert_training_mode(op_mode,op_name)
torch.onnx.symbolic_helper.parse_args(*arg_descriptors)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_registry.py----------------------------------------
A:torch.onnx.symbolic_registry.module->importlib.import_module('torch.onnx.symbolic_opset{}'.format(opset_version))
A:torch.onnx.symbolic_registry.version_ops->get_ops_in_version(iter_version)
A:torch.onnx.symbolic_registry.supported_version->get_op_supported_version(opname, domain, version)
torch.onnx.symbolic_registry.get_op_supported_version(opname,domain,version)
torch.onnx.symbolic_registry.get_ops_in_version(version)
torch.onnx.symbolic_registry.get_registered_op(opname,domain,version)
torch.onnx.symbolic_registry.is_registered_op(opname,domain,version)
torch.onnx.symbolic_registry.is_registered_version(domain,version)
torch.onnx.symbolic_registry.register_op(opname,op,domain,version)
torch.onnx.symbolic_registry.register_ops_helper(domain,version,iter_version)
torch.onnx.symbolic_registry.register_ops_in_version(domain,version)
torch.onnx.symbolic_registry.register_version(domain,version)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_opset11.py----------------------------------------
A:torch.onnx.symbolic_opset11.dtype->_get_arange_dtype(args[2])
A:torch.onnx.symbolic_opset11.min_val->g.op('Constant', value_t=torch.tensor(min_val, dtype=sym_help.scalar_type_to_pytorch_type[dtype]))
A:torch.onnx.symbolic_opset11.max_val->g.op('Constant', value_t=torch.tensor(max_val, dtype=sym_help.scalar_type_to_pytorch_type[dtype]))
A:torch.onnx.symbolic_opset11.min->unused(g)
A:torch.onnx.symbolic_opset11.max->unused(g)
A:torch.onnx.symbolic_opset11.indices_list->torch.onnx.symbolic_helper._unpack_list(indices_list_value)
A:torch.onnx.symbolic_opset11.accumulate->torch.onnx.symbolic_helper._parse_arg(accumulate, 'b')
A:torch.onnx.symbolic_opset11.index->nonzero(g, expand_as(g, mask, self))
A:torch.onnx.symbolic_opset11.broadcast_index_shape->g.op('Shape', index)
A:torch.onnx.symbolic_opset11.sub_data_shape->torch.onnx.symbolic_helper._slice_helper(g, g.op('Shape', self), axes=[0], starts=[len(indices_list)], ends=[maxsize])
A:torch.onnx.symbolic_opset11.values_shape->g.op('Concat', broadcast_index_shape, sub_data_shape, axis_i=0)
A:torch.onnx.symbolic_opset11.values->g.op('Reshape', values, values_shape)
A:torch.onnx.symbolic_opset11.zeros->g.op('ConstantOfShape', g.op('Shape', self), value_t=torch.tensor([0], dtype=dtype))
A:torch.onnx.symbolic_opset11.result->g.op('ScatterND', self, index, values)
A:torch.onnx.symbolic_opset11.dims->self.type().sizes()
A:torch.onnx.symbolic_opset11.(scales, align_corners)->torch.onnx.symbolic_helper._get_interpolate_attributes(g, interpolate_mode, args)
A:torch.onnx.symbolic_opset11.align_corners->torch.onnx.symbolic_helper._maybe_get_const(align_corners, 'b')
A:torch.onnx.symbolic_opset11.empty_tensor->g.op('Constant', value_t=torch.tensor([], dtype=torch.float32))
A:torch.onnx.symbolic_opset11.input_size->torch.onnx.symbolic_helper._slice_helper(g, input_size, axes=[0], ends=[2], starts=[0])
A:torch.onnx.symbolic_opset11.input_size_beg->torch.onnx.symbolic_helper._slice_helper(g, input_size, axes=[0], ends=[2], starts=[0])
A:torch.onnx.symbolic_opset11.output_size->g.op('Concat', input_size_beg, output_size, axis_i=0)
A:torch.onnx.symbolic_opset11.scales->torch.onnx.symbolic_helper._interpolate_get_scales(g, scale_factor, input.type().dim())
A:torch.onnx.symbolic_opset11.upsample_nearest1d->_interpolate('upsample_nearest1d', 3, 'nearest')
A:torch.onnx.symbolic_opset11.upsample_nearest2d->_interpolate('upsample_nearest2d', 4, 'nearest')
A:torch.onnx.symbolic_opset11.upsample_nearest3d->_interpolate('upsample_nearest3d', 5, 'nearest')
A:torch.onnx.symbolic_opset11.upsample_linear1d->_interpolate('upsample_linear1d', 3, 'linear')
A:torch.onnx.symbolic_opset11.upsample_bilinear2d->_interpolate('upsample_bilinear2d', 4, 'linear')
A:torch.onnx.symbolic_opset11.upsample_trilinear3d->_interpolate('upsample_trilinear3d', 5, 'linear')
A:torch.onnx.symbolic_opset11.upsample_bicubic2d->_interpolate('upsample_bicubic2d', 4, 'cubic')
A:torch.onnx.symbolic_opset11.mode->torch.onnx.symbolic_helper._maybe_get_const(mode, 's')
A:torch.onnx.symbolic_opset11.roi->g.op('Constant', value_t=torch.tensor([], dtype=torch.float32))
A:torch.onnx.symbolic_opset11.size->torch.onnx.symbolic_helper._size_helper(g, self, dim_constant)
A:torch.onnx.symbolic_opset11.src_type->g.op('Cast', src, to_i=sym_help.cast_pytorch_to_onnx[self.type().scalarType()]).type().scalarType()
A:torch.onnx.symbolic_opset11.src->g.op('Cast', src, to_i=sym_help.cast_pytorch_to_onnx[self.type().scalarType()])
A:torch.onnx.symbolic_opset11.dim_tensor->g.op('Constant', value_t=torch.tensor(dim, dtype=torch.int))
A:torch.onnx.symbolic_opset11.parsed_dtype->torch.onnx.symbolic_helper._get_const(dtype, 'i', 'dtype')
A:torch.onnx.symbolic_opset11.cast->g.op('Cast', self, to_i=sym_help.scalar_type_to_onnx[parsed_dtype])
A:torch.onnx.symbolic_opset11.csum->g.op('CumSum', cast, dim_tensor)
A:torch.onnx.symbolic_opset11.source->torch.onnx.symbolic_helper._slice_helper(g, source, axes=torch.LongTensor([0]), starts=torch.LongTensor([0]), ends=size(g, index, torch.LongTensor([0])), dynamic_slice=True)
A:torch.onnx.symbolic_opset11.tensor_list_node->g.op('Cast', other, to_i=sym_help.cast_pytorch_to_onnx['Float']).node()
A:torch.onnx.symbolic_opset11.tensors->torch.onnx.symbolic_helper._unpack_list(other)
A:torch.onnx.symbolic_opset11.l->g.op('SequenceInsert', l, t)
A:torch.onnx.symbolic_opset11.dim->g.op('Pad', input, g.op('Constant', value_t=torch.tensor(((0,) * 2 + padding) * 2)), mode_s='constant').type().dim()
A:torch.onnx.symbolic_opset11.(u, indices, inverse_indices, counts)->g.op('Unique', self, axis_i=dim, sorted_i=sorted, outputs=4)
A:torch.onnx.symbolic_opset11.padding->torch.onnx.symbolic_helper._avgpool_helper(tuple_fn, padding, kernel_size, stride, divisor_override, name)
A:torch.onnx.symbolic_opset11.input->g.op('Pad', input, g.op('Constant', value_t=torch.tensor(((0,) * 2 + padding) * 2)), mode_s='constant')
A:torch.onnx.symbolic_opset11.output->g.op('Transpose', output, perm_i=[0, 1, 2, 4, 3, 5])
A:torch.onnx.symbolic_opset11.avg_pool1d->_avg_pool('avg_pool1d', _single)
A:torch.onnx.symbolic_opset11.avg_pool2d->_avg_pool('avg_pool2d', _pair)
A:torch.onnx.symbolic_opset11.avg_pool3d->_avg_pool('avg_pool3d', _triple)
A:torch.onnx.symbolic_opset11.split_out->g.op('SplitToSequence', self, split_size_or_sizes, axis_i=dim)
A:torch.onnx.symbolic_opset11.start->g.op('Constant', value_t=torch.tensor([0], dtype=torch.long))
A:torch.onnx.symbolic_opset11.axis->g.op('Constant', value_t=torch.tensor([dim], dtype=torch.long))
A:torch.onnx.symbolic_opset11.end->g.op('Add', start, length)
A:torch.onnx.symbolic_opset11.pad_len->torch.onnx.symbolic_opset9.size(g, pad, g.op('Constant', value_t=torch.tensor([0])))
A:torch.onnx.symbolic_opset11.extension->g.op('Sub', g.op('Mul', g.op('Constant', value_t=torch.tensor(dim, dtype=torch.int64)), g.op('Constant', value_t=torch.tensor(2, dtype=torch.int64))), pad_len)
A:torch.onnx.symbolic_opset11.pad->g.op('Constant', value_t=torch.LongTensor([0, 0, padding_h, padding_w] * 2))
A:torch.onnx.symbolic_opset11.paddings->_prepare_onnx_paddings(g, input.type().dim(), padding)
A:torch.onnx.symbolic_opset11.padding_c->g.op('Cast', paddings, to_i=sym_help.cast_pytorch_to_onnx['Long'])
A:torch.onnx.symbolic_opset11.value->torch.onnx.symbolic_helper._if_scalar_type_as(g, value, self)
A:torch.onnx.symbolic_opset11.(type, end, start, step)->torch.onnx.symbolic_helper._arange_cast_helper(g, start=args[0], end=args[1], dtype=dtype)
A:torch.onnx.symbolic_opset11.start_default->g.op('Constant', value_t=torch.tensor(0, dtype=sym_help.scalar_type_to_pytorch_type[type]))
A:torch.onnx.symbolic_opset11.delta_default->g.op('Constant', value_t=torch.tensor(1, dtype=sym_help.scalar_type_to_pytorch_type[type]))
A:torch.onnx.symbolic_opset11.arange_tensor->g.op('Range', start, end, delta_default)
A:torch.onnx.symbolic_opset11.like_shape->g.op('Shape', like)
A:torch.onnx.symbolic_opset11.stop->g.op('Gather', like_shape, g.op('Constant', value_t=torch.tensor(dim)), axis_i=0)
A:torch.onnx.symbolic_opset11.dim_constant->g.op('Constant', value_t=torch.tensor([dim]))
A:torch.onnx.symbolic_opset11.const_one->g.op('Constant', value_t=torch.ones(1, dtype=torch.int64))
A:torch.onnx.symbolic_opset11.cond->g.op('Equal', size, const_one)
A:torch.onnx.symbolic_opset11.if_node_outputs->g.op('If', cond)
A:torch.onnx.symbolic_opset11.if_node->g.op('If', cond).node()
A:torch.onnx.symbolic_opset11.if_block->torch.onnx.utils._add_block(if_node)
A:torch.onnx.symbolic_opset11.squeeze_->torch.onnx.utils._add_block(if_node).op('Squeeze', self, axes_i=[dim])
A:torch.onnx.symbolic_opset11.else_block->torch.onnx.utils._add_block(if_node)
A:torch.onnx.symbolic_opset11.identity_->torch.onnx.utils._add_block(if_node).op('Identity', self)
A:torch.onnx.symbolic_opset11.dim_value->torch.onnx.symbolic_helper._parse_arg(dim, 'i')
A:torch.onnx.symbolic_opset11.(expanded_index_shape, expanded_index)->torch.onnx.symbolic_helper._index_fill_reshape_helper(g, self, dim, index)
A:torch.onnx.symbolic_opset11.expanded_value->expand(g, value, expanded_index_shape, None)
A:torch.onnx.symbolic_opset11.other->g.op('Cast', other, to_i=sym_help.cast_pytorch_to_onnx['Float'])
A:torch.onnx.symbolic_opset11.two->g.op('Constant', value_t=torch.tensor(2, dtype=torch.float32))
A:torch.onnx.symbolic_opset11.two_pow->g.op('Pow', two, other)
A:torch.onnx.symbolic_opset11.rshift->g.op('Div', self, two_pow)
A:torch.onnx.symbolic_opset11.lshift->g.op('Mul', self, two_pow)
A:torch.onnx.symbolic_opset11.blocks_d->g.op('Sub', blocks_d, g.op('Constant', value_t=torch.tensor(dilation_d * (kernel_size_d - 1))))
A:torch.onnx.symbolic_opset11.blocks_d_indices->g.op('Unsqueeze', blocks_d_indices, axes_i=[0])
A:torch.onnx.symbolic_opset11.kernel_grid->g.op('Constant', value_t=torch.tensor([kernel_grid]))
A:torch.onnx.symbolic_opset11.kernel_mask->g.op('Reshape', kernel_grid, g.op('Constant', value_t=torch.tensor([-1, 1])))
A:torch.onnx.symbolic_opset11.block_mask->g.op('Add', blocks_d_indices, kernel_mask)
A:torch.onnx.symbolic_opset11.batch_dim->size(g, input, g.op('Constant', value_t=torch.tensor(0)))
A:torch.onnx.symbolic_opset11.channel_dim->size(g, input, g.op('Constant', value_t=torch.tensor(1)))
A:torch.onnx.symbolic_opset11.channel_unfolded->g.op('Mul', channel_dim, g.op('Constant', value_t=torch.tensor(kernel_h * kernel_w)))
A:torch.onnx.symbolic_opset11.input_h->size(g, input, g.op('Constant', value_t=torch.tensor(2)))
A:torch.onnx.symbolic_opset11.input_w->size(g, input, g.op('Constant', value_t=torch.tensor(3)))
A:torch.onnx.symbolic_opset11.blocks_row_indices->_get_im2col_indices_along_dim(g, input_h, kernel_h, dilation_h, padding_h, stride_h)
A:torch.onnx.symbolic_opset11.blocks_col_indices->_get_im2col_indices_along_dim(g, input_w, kernel_w, dilation_w, padding_w, stride_w)
A:torch.onnx.symbolic_opset11.output_shape->_get_im2col_output_shape(g, input, kernel_h, kernel_w)
A:torch.onnx.symbolic_opset11.padded_input->_get_im2col_padded_input(g, input, padding_h, padding_w)
A:torch.onnx.symbolic_opset11.loop_condition->g.op('Constant', value_t=torch.tensor(1))
A:torch.onnx.symbolic_opset11.zero->g.op('Constant', value_t=torch.tensor([0]))
A:torch.onnx.symbolic_opset11.indices_len->g.op('Unsqueeze', sym_help._size_helper(g, indices, g.op('Constant', value_t=torch.tensor(0))), axes_i=[0])
A:torch.onnx.symbolic_opset11.offsets->g.op('Concat', *offsets, axis_i=0)
A:torch.onnx.symbolic_opset11.offsets_starts->torch.onnx.symbolic_helper._slice_helper(g, offsets, axes=[0], starts=[0], ends=[maxsize], steps=[1])
A:torch.onnx.symbolic_opset11.offsets_ends->torch.onnx.symbolic_helper._slice_helper(g, offsets, axes=[0], starts=[1], ends=[maxsize], steps=[1])
A:torch.onnx.symbolic_opset11.loop_len->torch.onnx.symbolic_helper._size_helper(g, offsets_ends, g.op('Constant', value_t=torch.tensor(0)))
A:torch.onnx.symbolic_opset11.loop->g.op('Loop', loop_len, loop_condition)
A:torch.onnx.symbolic_opset11.loop_block->_add_block(loop.node())
A:torch.onnx.symbolic_opset11.block_input_iter->_add_input_to_block(loop_block)
A:torch.onnx.symbolic_opset11.indices_start->_add_block(loop.node()).op('Unsqueeze', indices_start, axes_i=[0])
A:torch.onnx.symbolic_opset11.indices_end->_add_block(loop.node()).op('Unsqueeze', indices_end, axes_i=[0])
A:torch.onnx.symbolic_opset11.indices_row->_add_block(loop.node()).op('Slice', indices, indices_start, indices_end, zero)
A:torch.onnx.symbolic_opset11.embeddings->_add_block(loop.node()).op('ReduceMax', embeddings, axes_i=[0], keepdims_i=0)
A:torch.onnx.symbolic_opset11.per_sample_weights_row->_add_block(loop.node()).op('Unsqueeze', per_sample_weights_row, axes_i=[1])
torch.onnx.symbolic_opset11.__getitem_(g,self,i)
torch.onnx.symbolic_opset11.__interpolate(g,input,size,scale_factor,mode,align_corners,recompute_scale_factor)
torch.onnx.symbolic_opset11.__lshift_(g,self,other)
torch.onnx.symbolic_opset11.__rshift_(g,self,other)
torch.onnx.symbolic_opset11._avg_pool(name,tuple_fn)
torch.onnx.symbolic_opset11._dim_arange(g,like,dim)
torch.onnx.symbolic_opset11._get_im2col_indices_along_dim(g,input_d,kernel_size_d,dilation_d,padding_d,stride_d)
torch.onnx.symbolic_opset11._get_im2col_output_shape(g,input,kernel_h,kernel_w)
torch.onnx.symbolic_opset11._get_im2col_padded_input(g,input,padding_h,padding_w)
torch.onnx.symbolic_opset11._interpolate(name,dim,interpolate_mode)
torch.onnx.symbolic_opset11._len(g,self)
torch.onnx.symbolic_opset11._prepare_onnx_paddings(g,dim,pad)
torch.onnx.symbolic_opset11._unique2(g,self,sorted,return_inverse,return_counts)
torch.onnx.symbolic_opset11.add(g,self,other,alpha=None)
torch.onnx.symbolic_opset11.append(g,self,tensor)
torch.onnx.symbolic_opset11.arange(g,*args)
torch.onnx.symbolic_opset11.cat(g,tensor_list,dim)
torch.onnx.symbolic_opset11.clamp(g,self,min,max)
torch.onnx.symbolic_opset11.clamp_max(g,self,max)
torch.onnx.symbolic_opset11.clamp_min(g,self,min)
torch.onnx.symbolic_opset11.constant_pad_nd(g,input,padding,value=None)
torch.onnx.symbolic_opset11.cumsum(g,self,dim,dtype=None)
torch.onnx.symbolic_opset11.det(g,self)
torch.onnx.symbolic_opset11.embedding_bag(g,embedding_matrix,indices,offsets,scale_grad_by_freq,mode,sparse,per_sample_weights,include_last_offset)
torch.onnx.symbolic_opset11.flatten(g,input,start_dim,end_dim)
torch.onnx.symbolic_opset11.gather(g,self,dim,index,sparse_grad=False)
torch.onnx.symbolic_opset11.hardtanh(g,self,min_val,max_val)
torch.onnx.symbolic_opset11.im2col(g,input,kernel_size,dilation,padding,stride)
torch.onnx.symbolic_opset11.index_copy(g,self,dim,index,source)
torch.onnx.symbolic_opset11.index_fill(g,self,dim,index,value)
torch.onnx.symbolic_opset11.index_put(g,self,indices_list_value,values,accumulate=False)
torch.onnx.symbolic_opset11.insert(g,self,pos,tensor)
torch.onnx.symbolic_opset11.logdet(g,input)
torch.onnx.symbolic_opset11.masked_scatter(g,self,mask,source)
torch.onnx.symbolic_opset11.masked_select(g,self,mask)
torch.onnx.symbolic_opset11.mm(g,self,other)
torch.onnx.symbolic_opset11.narrow(g,input,dim,start,length)
torch.onnx.symbolic_opset11.pixel_shuffle(g,self,upscale_factor)
torch.onnx.symbolic_opset11.pop(g,tensor_list,dim)
torch.onnx.symbolic_opset11.reflection_pad(g,input,padding)
torch.onnx.symbolic_opset11.replication_pad(g,input,padding)
torch.onnx.symbolic_opset11.round(g,self)
torch.onnx.symbolic_opset11.scatter(g,self,dim,index,src)
torch.onnx.symbolic_opset11.select(g,self,dim,index)
torch.onnx.symbolic_opset11.size(g,self,dim=None)
torch.onnx.symbolic_opset11.sort(g,self,dim,decending,out=None)
torch.onnx.symbolic_opset11.split(g,self,split_size_or_sizes,dim,_outputs=None)
torch.onnx.symbolic_opset11.split_with_sizes(g,self,split_sizes,dim,_outputs=None)
torch.onnx.symbolic_opset11.squeeze(g,self,dim=None)
torch.onnx.symbolic_opset11.stack(g,tensor_list,dim)
torch.onnx.symbolic_opset11.topk(g,self,k,dim,largest,sorted,out=None)
torch.onnx.symbolic_opset11.unbind(g,self,dim=0,_outputs=None)
torch.onnx.symbolic_opset11.unique_dim(g,self,dim,sorted,return_inverse,return_counts)
torch.onnx.symbolic_opset11.unsqueeze(g,self,dim)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_caffe2.py----------------------------------------
A:torch.onnx.symbolic_caffe2.module->importlib.import_module('torch.onnx.symbolic_caffe2')
A:torch.onnx.symbolic_caffe2.quant_version_ops->getmembers(sym_registry._symbolic_versions['caffe2'])
A:torch.onnx.symbolic_caffe2.output->g.op('_caffe2::Int8Sigmoid', input, **kwargs)
A:torch.onnx.symbolic_caffe2.output_size->torch.onnx.symbolic_helper._parse_arg(output_size, 'is')
A:torch.onnx.symbolic_caffe2.input->nchw2nhwc(g, input)
A:torch.onnx.symbolic_caffe2.start->torch.onnx.symbolic_helper._parse_arg(start, 'i')
A:torch.onnx.symbolic_caffe2.end->torch.onnx.symbolic_helper._parse_arg(end, 'i')
A:torch.onnx.symbolic_caffe2.dim->torch.onnx.symbolic_helper._parse_arg(dim, 'i')
A:torch.onnx.symbolic_caffe2.tensors->torch.onnx.symbolic_helper._unpack_list(tensor_list)
torch.onnx.symbolic_caffe2._empty_affine_quantized(g,input,shape,scale,zero_point,dtype,pin_memory,memory_format,layout)
torch.onnx.symbolic_caffe2._permute_helper(g,input,axes)
torch.onnx.symbolic_caffe2.add(g,input_a,input_b,scale,zero_point)
torch.onnx.symbolic_caffe2.avg_pool2d(g,input,kernel_size,stride,padding,ceil_mode,count_include_pad,divisor_override=None)
torch.onnx.symbolic_caffe2.cat(g,tensor_list,dim,scale=None,zero_point=None)
torch.onnx.symbolic_caffe2.conv2d(g,input,weight,bias,stride,padding,dilation,groups,scale,zero_point)
torch.onnx.symbolic_caffe2.conv2d_relu(g,input,weight,bias,stride,padding,dilation,groups,scale,zero_point)
torch.onnx.symbolic_caffe2.conv_prepack(g,input,weight,bias,stride,padding,dilation,groups)
torch.onnx.symbolic_caffe2.dequantize(g,input)
torch.onnx.symbolic_caffe2.linear(g,input,weight,bias,scale,zero_point)
torch.onnx.symbolic_caffe2.linear_prepack(g,weight,bias)
torch.onnx.symbolic_caffe2.max_pool2d(g,input,kernel_size,stride,padding,dilation,ceil_mode)
torch.onnx.symbolic_caffe2.nchw2nhwc(g,input)
torch.onnx.symbolic_caffe2.nhwc2nchw(g,input)
torch.onnx.symbolic_caffe2.quantize_per_tensor(g,input,scale,zero_point,dtype)
torch.onnx.symbolic_caffe2.register_quantized_ops(domain,version)
torch.onnx.symbolic_caffe2.relu(g,input)
torch.onnx.symbolic_caffe2.reshape(g,input,shape)
torch.onnx.symbolic_caffe2.sigmoid(g,input)
torch.onnx.symbolic_caffe2.slice(g,input,dim,start,end,step)
torch.onnx.symbolic_caffe2.upsample_nearest2d(g,input,output_size,align_corners=None,scales_h=None,scales_w=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/operators.py----------------------------------------
torch.onnx.operators.reshape_from_tensor_shape(x,shape)
torch.onnx.operators.shape_as_tensor(x)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_opset9.py----------------------------------------
A:torch.onnx.symbolic_opset9.n->g.op('ConvTranspose' if transposed else 'Conv', *args, **kwargs)
A:torch.onnx.symbolic_opset9.shape->g.op('Shape', self)
A:torch.onnx.symbolic_opset9.out->reshape_as(g, out, index)
A:torch.onnx.symbolic_opset9.scalar_type->torch.get_default_dtype()
A:torch.onnx.symbolic_opset9.other->g.op('Cast', other, to_i=sym_help.cast_pytorch_to_onnx['Float'])
A:torch.onnx.symbolic_opset9.self->g.op('Transpose', self, perm_i=adv_idx_permute)
A:torch.onnx.symbolic_opset9.tensors->torch.onnx.symbolic_helper._unpack_list(tensor_list)
A:torch.onnx.symbolic_opset9.C->g.op('Constant', value_t=torch.tensor([1]))
A:torch.onnx.symbolic_opset9.dtype->g.op('Transpose', self, perm_i=adv_idx_permute).type().scalarType()
A:torch.onnx.symbolic_opset9.overloads->fn(g, *args)
A:torch.onnx.symbolic_opset9.symbolic->_reduce_op_symbolic(onnx_op, allow_multi_dim_support=allow_multi_dim_support)
A:torch.onnx.symbolic_opset9.sum->g.op('ReduceSum', exp, axes_i=[dim])
A:torch.onnx.symbolic_opset9.mean->g.op('ReduceMean', input, axes_i=dim, keepdims_i=keepdim)
A:torch.onnx.symbolic_opset9.prod->_reduce_with_dtype('ReduceProd', 'prod', allow_multi_dim_support=False)
A:torch.onnx.symbolic_opset9.size->select(g, sizes, g.op('Constant', value_t=torch.tensor([0])), g.op('Constant', value_t=torch.tensor(i)))
A:torch.onnx.symbolic_opset9.ones->ones_like(g, size, dtype)
A:torch.onnx.symbolic_opset9.neg_ones->mul(g, ones, g.op('Constant', value_t=torch.tensor(-1)))
A:torch.onnx.symbolic_opset9.rank->len(strides)
A:torch.onnx.symbolic_opset9.dim->_parse_arg(dim, 'i')
A:torch.onnx.symbolic_opset9.axes->list(range(rank))
A:torch.onnx.symbolic_opset9.split_size->torch.onnx.symbolic_helper._get_const(split_size_or_sizes, 'i', 'split_size')
A:torch.onnx.symbolic_opset9.outputs->g.op('Split', self, split_i=[1] * _outputs, axis_i=dim, outputs=_outputs)
A:torch.onnx.symbolic_opset9.index->squeeze(g, nonzero(g, index), dim=1)
A:torch.onnx.symbolic_opset9.slice_node->torch.onnx.symbolic_helper._slice_helper(g, self, axes=[dim], starts=[index], ends=[end_index])
A:torch.onnx.symbolic_opset9.squeeze_dim->torch.onnx.symbolic_helper._get_const(dim, 'i', 'dim')
A:torch.onnx.symbolic_opset9.input_shape->g.op('Transpose', self, perm_i=adv_idx_permute).type().sizes()
A:torch.onnx.symbolic_opset9.self_sizes->g.op('Transpose', self, perm_i=adv_idx_permute).type().sizes()
A:torch.onnx.symbolic_opset9.weight->g.op('Constant', value_t=weight_value)
A:torch.onnx.symbolic_opset9.negative_slope->torch.onnx.symbolic_helper._get_const(negative_slope, 't', 'negative_slope')
A:torch.onnx.symbolic_opset9.(first, second)->g.op('Split', input, axis_i=dim, outputs=2)
A:torch.onnx.symbolic_opset9.input_dim->g.op('Transpose', input, perm_i=[1, 0, 2]).type().dim()
A:torch.onnx.symbolic_opset9.input->g.op('Transpose', input, perm_i=[1, 0, 2])
A:torch.onnx.symbolic_opset9.softmax->g.op('Cast', softmax, to_i=sym_help.scalar_type_to_onnx[parsed_dtype])
A:torch.onnx.symbolic_opset9.parsed_dtype->torch.onnx.symbolic_helper._get_const(dtype, 'i', 'dtype')
A:torch.onnx.symbolic_opset9.exp->g.op('Exp', input)
A:torch.onnx.symbolic_opset9.padding->_convert_padding_node(padding)
A:torch.onnx.symbolic_opset9.padding_ceil->get_pool_ceil_padding(input, kernel_size, stride, padding)
A:torch.onnx.symbolic_opset9.(r, indices)->g.op('MaxPool', input, outputs=2, **kwargs)
A:torch.onnx.symbolic_opset9.(_, flattened_indices)->g.op('MaxPool', input, outputs=2, kernel_shape_i=[1 for _ in range(ndims)], strides_i=[1 for _ in range(ndims)])
A:torch.onnx.symbolic_opset9.s->torch.onnx.symbolic_helper._slice_helper(g, flattened_indices, axes=[2 + i for i in range(ndims)], starts=tuple_fn(0), ends=tuple_fn(1))
A:torch.onnx.symbolic_opset9.indices->torch.onnx.symbolic_helper._unpack_list(index)
A:torch.onnx.symbolic_opset9.r->g.op('MaxPool', input, outputs=1, **kwargs)
A:torch.onnx.symbolic_opset9.max_pool1d->_max_pool('max_pool1d', _single, 1, return_indices=False)
A:torch.onnx.symbolic_opset9.max_pool2d->_max_pool('max_pool2d', _pair, 2, return_indices=False)
A:torch.onnx.symbolic_opset9.max_pool3d->_max_pool('max_pool3d', _triple, 3, return_indices=False)
A:torch.onnx.symbolic_opset9.max_pool1d_with_indices->_max_pool('max_pool1d_with_indices', _single, 1, return_indices=True)
A:torch.onnx.symbolic_opset9.max_pool2d_with_indices->_max_pool('max_pool2d_with_indices', _pair, 2, return_indices=True)
A:torch.onnx.symbolic_opset9.max_pool3d_with_indices->_max_pool('max_pool3d_with_indices', _triple, 3, return_indices=True)
A:torch.onnx.symbolic_opset9.output->_kl_div_non_log_target_impl(g, input, target)
A:torch.onnx.symbolic_opset9.avg_pool1d->_avg_pool('avg_pool1d', _single)
A:torch.onnx.symbolic_opset9.avg_pool2d->_avg_pool('avg_pool2d', _pair)
A:torch.onnx.symbolic_opset9.avg_pool3d->_avg_pool('avg_pool3d', _triple)
A:torch.onnx.symbolic_opset9.output_size->_parse_arg(output_size, 'is')
A:torch.onnx.symbolic_opset9.adaptive_avg_pool1d->_adaptive_pool('adaptive_avg_pool1d', 'AveragePool', _single)
A:torch.onnx.symbolic_opset9.adaptive_avg_pool2d->_adaptive_pool('adaptive_avg_pool2d', 'AveragePool', _pair)
A:torch.onnx.symbolic_opset9.adaptive_avg_pool3d->_adaptive_pool('adaptive_avg_pool3d', 'AveragePool', _triple)
A:torch.onnx.symbolic_opset9.adaptive_max_pool1d->_adaptive_pool('adaptive_max_pool1d', 'MaxPool', _single, max_pool1d_with_indices)
A:torch.onnx.symbolic_opset9.adaptive_max_pool2d->_adaptive_pool('adaptive_max_pool2d', 'MaxPool', _pair, max_pool2d_with_indices)
A:torch.onnx.symbolic_opset9.adaptive_max_pool3d->_adaptive_pool('adaptive_max_pool3d', 'MaxPool', _triple, max_pool3d_with_indices)
A:torch.onnx.symbolic_opset9.input_list->list()
A:torch.onnx.symbolic_opset9.value->torch.onnx.symbolic_helper._maybe_get_scalar(value)
A:torch.onnx.symbolic_opset9.paddings->_prepare_onnx_paddings(input.type().dim(), padding)
A:torch.onnx.symbolic_opset9.(scales, align_corners)->torch.onnx.symbolic_helper._get_interpolate_attributes(g, interpolate_mode, args)
A:torch.onnx.symbolic_opset9.align_corners->torch.onnx.symbolic_helper._maybe_get_scalar(align_corners)
A:torch.onnx.symbolic_opset9.scales->torch.onnx.symbolic_helper._interpolate_size_to_scales(g, input, output_size, dim)
A:torch.onnx.symbolic_opset9.upsample_nearest1d->_interpolate('upsample_nearest1d', 3, 'nearest')
A:torch.onnx.symbolic_opset9.upsample_nearest2d->_interpolate('upsample_nearest2d', 4, 'nearest')
A:torch.onnx.symbolic_opset9.upsample_nearest3d->_interpolate('upsample_nearest3d', 5, 'nearest')
A:torch.onnx.symbolic_opset9.upsample_linear1d->_interpolate('upsample_linear1d', 3, 'linear')
A:torch.onnx.symbolic_opset9.upsample_bilinear2d->_interpolate('upsample_bilinear2d', 4, 'linear')
A:torch.onnx.symbolic_opset9.upsample_trilinear3d->_interpolate('upsample_trilinear3d', 5, 'linear')
A:torch.onnx.symbolic_opset9.(scales, mode)->torch.onnx.symbolic_helper._interpolate_get_scales_and_mode(g, input, size, scale_factor, mode, align_corners)
A:torch.onnx.symbolic_opset9.from_cast_func->wrap_logical_op_with_cast_to(input.type().scalarType())(fn)
A:torch.onnx.symbolic_opset9.two->g.op('Constant', value_t=torch.tensor(2, dtype=torch.float32))
A:torch.onnx.symbolic_opset9.two_pow->g.op('Pow', two, other)
A:torch.onnx.symbolic_opset9.rshift->g.op('Div', self, two_pow)
A:torch.onnx.symbolic_opset9.lshift->g.op('Mul', self, two_pow)
A:torch.onnx.symbolic_opset9.condition->torch.onnx.symbolic_opset9.nonzero(g, condition)
A:torch.onnx.symbolic_opset9.return_op->g.op('Transpose', return_op, perm_i=axes)
A:torch.onnx.symbolic_opset9.weight_size->g.op('Constant', value_t=weight_value).type().sizes()
A:torch.onnx.symbolic_opset9.input_sizes->g.op('Transpose', input, perm_i=[1, 0, 2]).type().sizes()
A:torch.onnx.symbolic_opset9.weight_value->torch.tensor([1.0]).type('torch.' + input.type().scalarType() + 'Tensor')
A:torch.onnx.symbolic_opset9.bias_value->torch.tensor([0.0]).type('torch.' + input.type().scalarType() + 'Tensor')
A:torch.onnx.symbolic_opset9.bias->g.op('Constant', value_t=bias_value)
A:torch.onnx.symbolic_opset9.two_cst->g.op('Constant', value_t=torch.tensor(2.0))
A:torch.onnx.symbolic_opset9.eps_cst->g.op('Constant', value_t=torch.tensor(eps))
A:torch.onnx.symbolic_opset9.numerator->sub(g, input, mean)
A:torch.onnx.symbolic_opset9.variance->g.op('ReduceMean', pow(g, numerator, two_cst), axes_i=axes)
A:torch.onnx.symbolic_opset9.denominator->sqrt(g, add(g, variance, eps_cst))
A:torch.onnx.symbolic_opset9.layer_norm->add(g, layer_norm, bias)
A:torch.onnx.symbolic_opset9.low_indices->range(0, sizedim, step)
A:torch.onnx.symbolic_opset9.hi_indices->range(size, sizedim + 1, step)
A:torch.onnx.symbolic_opset9.ndim->g.op('Transpose', input, perm_i=[1, 0, 2]).type().dim()
A:torch.onnx.symbolic_opset9.perm->list(range(0, ndim))
A:torch.onnx.symbolic_opset9.index_const->torch.onnx.symbolic_helper._maybe_get_scalar(index)
A:torch.onnx.symbolic_opset9.index_dim->squeeze(g, nonzero(g, index), dim=1).type().dim()
A:torch.onnx.symbolic_opset9.indices_list->torch.onnx.symbolic_helper._unpack_list(indices_list_value)
A:torch.onnx.symbolic_opset9.dim_value->torch.onnx.symbolic_helper._parse_arg(dim, 'i')
A:torch.onnx.symbolic_opset9.(expanded_index_shape, expanded_index)->torch.onnx.symbolic_helper._index_fill_reshape_helper(g, self, dim, index)
A:torch.onnx.symbolic_opset9.expanded_value->expand(g, value, expanded_index_shape, None)
A:torch.onnx.symbolic_opset9.other_type_name->g.op('Cast', other, to_i=sym_help.cast_pytorch_to_onnx['Float']).type().scalarType()
A:torch.onnx.symbolic_opset9.f_dtypeself_dtype->g.op('Transpose', self, perm_i=adv_idx_permute).type().scalarType()
A:torch.onnx.symbolic_opset9.exponent->g.op('Cast', exponent, to_i=sym_help.cast_pytorch_to_onnx[f_dtype])
A:torch.onnx.symbolic_opset9.pow->g.op('Cast', pow, to_i=sym_help.cast_pytorch_to_onnx[self_dtype])
A:torch.onnx.symbolic_opset9.min->g.op('ReduceMin', self, axes_i=[dim], keepdims_i=keepdim)
A:torch.onnx.symbolic_opset9.max->g.op('ReduceMax', self, axes_i=[dim], keepdims_i=keepdim)
A:torch.onnx.symbolic_opset9.keepdim->_parse_arg(keepdim, 'i')
A:torch.onnx.symbolic_opset9.(r, _)->g.op('Dropout', input, ratio_f=p, outputs=2)
A:torch.onnx.symbolic_opset9.feature_dropout->_unsupported_dropout('feature_dropout')
A:torch.onnx.symbolic_opset9.alpha_dropout->_unsupported_dropout('alpha_dropout')
A:torch.onnx.symbolic_opset9.feature_alpha_dropout->_unsupported_dropout('feature_alpha_dropout')
A:torch.onnx.symbolic_opset9.f->_reduce_op_symbolic('ReduceL2')
A:torch.onnx.symbolic_opset9.name->'_cast_{}'.format(k)
A:torch.onnx.symbolic_opset9.globals()[name]->parse_args('v', 'i')(partial(sym_help._cast_func_template, v))
A:torch.onnx.symbolic_opset9.scalar->g.op('Cast', scalar, to_i=sym_help.scalar_type_to_onnx[dtype])
A:torch.onnx.symbolic_opset9.shape_reference->g.op('Constant', value_t=torch.LongTensor([1]))
A:torch.onnx.symbolic_opset9.t->g.op('Cast', t, to_i=sym_help.scalar_type_to_onnx[dtype])
A:torch.onnx.symbolic_opset9.const_value->torch.onnx.symbolic_helper._maybe_get_const(value, 't')
A:torch.onnx.symbolic_opset9.tmp->zeros_like(g, input, dtype, layout, device)
A:torch.onnx.symbolic_opset9.fill_value->torch.onnx.symbolic_helper._maybe_get_const(fill_value, 'f')
A:torch.onnx.symbolic_opset9.tensor->zeros(g, shape, dtype, layout, device)
A:torch.onnx.symbolic_opset9.step->g.op('Unsqueeze', args[2], axes_i=[0])
A:torch.onnx.symbolic_opset9.start_unsqueezed->g.op('Unsqueeze', start, axes_i=[0])
A:torch.onnx.symbolic_opset9.end_unsqueezed->g.op('Unsqueeze', end, axes_i=[0])
A:torch.onnx.symbolic_opset9.dim_unsqueezed->g.op('Unsqueeze', dim, axes_i=[0])
A:torch.onnx.symbolic_opset9.start->g.op('Unsqueeze', args[0], axes_i=[0])
A:torch.onnx.symbolic_opset9.end->g.op('Unsqueeze', args[1], axes_i=[0])
A:torch.onnx.symbolic_opset9.shape_->ones_like(g, repeats, dtype)
A:torch.onnx.symbolic_opset9.dims->g.op('Transpose', self, perm_i=adv_idx_permute).type().sizes()
A:torch.onnx.symbolic_opset9.after_view->view(g, self, g.op('Constant', value_t=torch.tensor([-1, output_channel, upscale_factor, upscale_factor, dims[2], dims[3]])))
A:torch.onnx.symbolic_opset9.after_transpose->g.op('Transpose', after_view, perm_i=[0, 1, 4, 2, 5, 3])
A:torch.onnx.symbolic_opset9.variantToOnnxActivationMap->dict(zip([act_fun.lower() for act_fun in onnxActivations], onnxActivations))
A:torch.onnx.symbolic_opset9.bias_concat->unused(g)
A:torch.onnx.symbolic_opset9.(weight_ih, weight_hh, bias_concat)->transform_weights(i)
A:torch.onnx.symbolic_opset9.(weight_ih, weight_hh)->transform_weights_no_bias(i)
A:torch.onnx.symbolic_opset9.(weight_ih_f, weight_hh_f, bias_f)->transform_weights(2 * i)
A:torch.onnx.symbolic_opset9.(weight_ih_b, weight_hh_b, bias_b)->transform_weights(2 * i + 1)
A:torch.onnx.symbolic_opset9.(weight_ih_f, weight_hh_f)->transform_weights_no_bias(2 * i)
A:torch.onnx.symbolic_opset9.(weight_ih_b, weight_hh_b)->transform_weights_no_bias(2 * i + 1)
A:torch.onnx.symbolic_opset9.weight_ih->g.op('Concat', weight_ih_f, weight_ih_b, axis_i=0)
A:torch.onnx.symbolic_opset9.weight_hh->g.op('Concat', weight_hh_f, weight_hh_b, axis_i=0)
A:torch.onnx.symbolic_opset9.(prev_output, h_out)->g.op('GRU', *inputs, outputs=2, hidden_size_i=hidden_size, linear_before_reset_i=1, **extra_kwargs)
A:torch.onnx.symbolic_opset9.(prev_output, h_out, c_out)->g.op('LSTM', *inputs, outputs=3, hidden_size_i=hidden_size, **extra_kwargs)
A:torch.onnx.symbolic_opset9.prev_output->g.op('Transpose', prev_output, perm_i=[1, 0, 2])
A:torch.onnx.symbolic_opset9.gru->_one_hidden_rnn('GRU')
A:torch.onnx.symbolic_opset9.rnn_tanh->_one_hidden_rnn('RNN_TANH')
A:torch.onnx.symbolic_opset9.rnn_relu->_one_hidden_rnn('RNN_RELU')
A:torch.onnx.symbolic_opset9.like_shape->g.op('Shape', like)
A:torch.onnx.symbolic_opset9.stop->g.op('Gather', like_shape, g.op('Constant', value_t=torch.tensor(dim)), axis_i=0)
A:torch.onnx.symbolic_opset9.lengths->_cast_Int(g, lengths, False)
A:torch.onnx.symbolic_opset9.(data, lengths)->g.op('prim::PadPacked', data, batch_sizes, outputs=2)
A:torch.onnx.symbolic_opset9.data->g.op('Transpose', data, perm_i=[1, 0, 2])
A:torch.onnx.symbolic_opset9.shape_const->g.op('ConstantOfShape', shapes, value_t=torch.tensor([0], dtype=sym_help.scalar_type_to_pytorch_type[6]))
A:torch.onnx.symbolic_opset9.p->g.op('Sigmoid', input)
A:torch.onnx.symbolic_opset9.flattened->reshape(g, input, g.op('Constant', value_t=torch.tensor([-1])))
A:torch.onnx.symbolic_opset9.src_type->g.op('Cast', src, to_i=sym_help.cast_pytorch_to_onnx[self.type().scalarType()]).type().scalarType()
A:torch.onnx.symbolic_opset9.src->g.op('Cast', src, to_i=sym_help.cast_pytorch_to_onnx[self.type().scalarType()])
A:torch.onnx.symbolic_opset9.sizes->torch.onnx.symbolic_helper._maybe_get_const(sizes, 'is')
A:torch.onnx.symbolic_opset9.to_add->torch.onnx.symbolic_helper._scatter_helper(g, to_add, dim, index, src)
A:torch.onnx.symbolic_opset9.values->g.op('Constant', value_t=torch.LongTensor([0, 1]))
A:torch.onnx.symbolic_opset9.depth->size(g, self, g.op('Constant', value_t=torch.LongTensor([dim])))
A:torch.onnx.symbolic_opset9.mul->g.op('Mul', var, g.op('Constant', value_t=torch.tensor(count, dtype=torch.float)))
A:torch.onnx.symbolic_opset9.sqrd->g.op('Mul', input, input)
A:torch.onnx.symbolic_opset9.sqrdmean->g.op('ReduceMean', sqrd, axes_i=dim, keepdims_i=keepdim)
A:torch.onnx.symbolic_opset9.redudced_dims->g.op('Transpose', input, perm_i=[1, 0, 2]).type().sizes()
A:torch.onnx.symbolic_opset9.meansqrd->g.op('Mul', mean, mean)
A:torch.onnx.symbolic_opset9.var->g.op('Div', mul, g.op('Constant', value_t=torch.tensor(count - 1, dtype=torch.float)))
A:torch.onnx.symbolic_opset9.count->numpy.prod(redudced_dims)
A:torch.onnx.symbolic_opset9.std->g.op('Sqrt', var)
A:torch.onnx.symbolic_opset9.arange_tensor->g.op('Add', g.op('Mul', arange_tensor, step), start)
A:torch.onnx.symbolic_opset9.range_tensor->g.op('Div', g.op('Sub', end, start), step)
A:torch.onnx.symbolic_opset9.mask->_cast_Bool(g, mask, False)
A:torch.onnx.symbolic_opset9.adv_idx_count->len(adv_idx_indices)
A:torch.onnx.symbolic_opset9.shape_tensor->_shape_as_tensor(g, self)
A:torch.onnx.symbolic_opset9.adv_index->g.op('Mul', indices[adv_idx_indices[i]], multiplier)
A:torch.onnx.symbolic_opset9.cum_adv_index->g.op('Add', cum_adv_index, adv_index)
A:torch.onnx.symbolic_opset9.multiplier->g.op('Mul', multiplier, dim_tensor_list[adv_idx_indices[i]])
A:torch.onnx.symbolic_opset9.cum_adv_index_shape_tensor->_shape_as_tensor(g, cum_adv_index)
A:torch.onnx.symbolic_opset9.folded_adv_idx_shape->g.op('Concat', *folded_adv_idx_shape_list, axis_i=0)
A:torch.onnx.symbolic_opset9.final_shape->g.op('Concat', cum_adv_index_shape_tensor, *[dim_tensor_list[i] for i in range(rank) if i not in adv_idx_indices], axis_i=0)
A:torch.onnx.symbolic_opset9.sqr->g.op('Mul', self, self)
A:torch.onnx.symbolic_opset9.sumsqr->g.op('ReduceSum', sqr, axes_i=dim, keepdims_i=keepdim)
A:torch.onnx.symbolic_opset9.log_input->log(g, input)
A:torch.onnx.symbolic_opset9.batch_mul->matmul(g, batch1, batch2)
A:torch.onnx.symbolic_opset9.mul_a->mul(g, batch_mul, g.op('Cast', alpha, to_i=sym_help.cast_pytorch_to_onnx[dtype]))
A:torch.onnx.symbolic_opset9.mul_b->mul(g, self, g.op('Cast', beta, to_i=sym_help.cast_pytorch_to_onnx[dtype]))
A:torch.onnx.symbolic_opset9.out_shape->g.op('Concat', *tensors_shape, axis_i=0)
A:torch.onnx.symbolic_opset9.t_reshaped->_reshape_from_tensor(g, t, g.op('Concat', *shape_i, axis_i=0))
A:torch.onnx.symbolic_opset9.div->g.op('Div', weight_v, norm_v)
A:torch.onnx.symbolic_opset9.quo->g.op('Mul', div, other)
A:torch.onnx.symbolic_opset9.erf->g.op('Erf', g.op('Div', self, torch.tensor(_sqrt2)))
A:torch.onnx.symbolic_opset9.erf_plusone->add(g, erf, g.op('Constant', value_t=torch.tensor(1, dtype=torch.float)))
A:torch.onnx.symbolic_opset9.input_reshaped->g.op('Reshape', input, g.op('Constant', value_t=torch.LongTensor(shape)))
A:torch.onnx.symbolic_opset9.weight_->g.op('Constant', value_t=torch.tensor([1.0] * num_groups).type('torch.' + input.type().scalarType() + 'Tensor'))
A:torch.onnx.symbolic_opset9.bias_->g.op('Constant', value_t=torch.tensor([0.0] * num_groups).type('torch.' + input.type().scalarType() + 'Tensor'))
A:torch.onnx.symbolic_opset9.norm_reshaped->g.op('InstanceNormalization', input_reshaped, weight_, bias_, epsilon_f=eps)
A:torch.onnx.symbolic_opset9.norm->g.op('Reshape', norm_reshaped, g.op('Shape', input))
A:torch.onnx.symbolic_opset9.norm_v->norm(g, weight_v, 2, axes, 1)
A:torch.onnx.symbolic_opset9.self_flattened->g.op('Reshape', self, g.op('Constant', value_t=torch.tensor([-1], dtype=torch.int64)))
A:torch.onnx.symbolic_opset9.diff_->sub(g, log_, input)
A:torch.onnx.symbolic_opset9.exp_->exp(g, target)
A:torch.onnx.symbolic_opset9.log_->log(g, target)
A:torch.onnx.symbolic_opset9.output_pos->mul(g, target, diff_)
A:torch.onnx.symbolic_opset9.zeros_->zeros_like(g, output_pos)
A:torch.onnx.symbolic_opset9.mask_->gt(g, target, g.op('Constant', value_t=torch.tensor(0)))
A:torch.onnx.symbolic_opset9.self_1d->g.op('Reshape', self, g.op('Constant', value_t=torch.tensor([-1], dtype=torch.int64)))
A:torch.onnx.symbolic_opset9.ind->g.op('Add', ind, g.op('Constant', torch.tensor([offset])))
A:torch.onnx.symbolic_opset9.tmp_ind->g.op('Mul', tmp_ind, g.op('Constant', value_t=torch.tensor([stride])))
torch.onnx.symbolic_opset9.__and_(g,input,other)
torch.onnx.symbolic_opset9.__getitem_(g,self,i)
torch.onnx.symbolic_opset9.__interpolate(g,input,size,scale_factor,mode,align_corners,recompute_scale_factor)
torch.onnx.symbolic_opset9.__lshift_(g,self,other)
torch.onnx.symbolic_opset9.__or_(g,input,other)
torch.onnx.symbolic_opset9.__rshift_(g,self,other)
torch.onnx.symbolic_opset9._adaptive_pool(name,type,tuple_fn,fn=None)
torch.onnx.symbolic_opset9._avg_pool(name,tuple_fn)
torch.onnx.symbolic_opset9._convert_padding_node(padding)
torch.onnx.symbolic_opset9._convolution(g,input,weight,bias,stride,padding,dilation,transposed,output_padding,groups,benchmark,deterministic,cudnn_enabled,allow_tf32)
torch.onnx.symbolic_opset9._dim_arange(g,like,dim)
torch.onnx.symbolic_opset9._generic_rnn(g,variant,input,initial_states,all_weights,has_biases,num_layers,dropout,train,bidirectional,batch_first=None,batch_sizes=None)
torch.onnx.symbolic_opset9._interpolate(name,dim,interpolate_mode)
torch.onnx.symbolic_opset9._kl_div_log_target_impl(g,input,target)
torch.onnx.symbolic_opset9._kl_div_non_log_target_impl(g,input,target)
torch.onnx.symbolic_opset9._len(g,self)
torch.onnx.symbolic_opset9._list(g,self)
torch.onnx.symbolic_opset9._lstm_full(g,input,hidden_v,weight_v,has_biases,num_layers,dropout,train,bidirectional,batch_first)
torch.onnx.symbolic_opset9._lstm_packed(g,input,batch_sizes,hidden_v,weight_v,has_biases,num_layers,dropout,train,bidirectional)
torch.onnx.symbolic_opset9._max_pool(name,tuple_fn,ndims,return_indices)
torch.onnx.symbolic_opset9._maybe_cast_reduce_op_input(g,self)
torch.onnx.symbolic_opset9._one_hidden_rnn(kind)
torch.onnx.symbolic_opset9._pack_padded_sequence(g,input,lengths,batch_first)
torch.onnx.symbolic_opset9._pad_packed_sequence(g,data,batch_sizes,batch_first,padding_value,total_length)
torch.onnx.symbolic_opset9._prepare_onnx_paddings(dim,pad)
torch.onnx.symbolic_opset9._reduce_op_symbolic(onnx_op_name,allow_multi_dim_support=True)
torch.onnx.symbolic_opset9._reduce_with_dtype(onnx_op,name,allow_multi_dim_support=True)
torch.onnx.symbolic_opset9._reshape_from_tensor(g,input,shape)
torch.onnx.symbolic_opset9._sample_dirichlet(g,self,generator)
torch.onnx.symbolic_opset9._shape_as_tensor(g,input)
torch.onnx.symbolic_opset9._slice(g,input,axes,starts,ends)
torch.onnx.symbolic_opset9._standard_gamma(g,self,generator)
torch.onnx.symbolic_opset9._std(g,input,dim,unbiased,keepdim)
torch.onnx.symbolic_opset9._unique(g,input,sorted,return_inverse)
torch.onnx.symbolic_opset9._unique2(g,input,sorted,return_inverse,return_counts)
torch.onnx.symbolic_opset9._unsupported_dropout(name)
torch.onnx.symbolic_opset9._weight_norm(g,weight_v,weight_g,dim)
torch.onnx.symbolic_opset9.abs(g,self)
torch.onnx.symbolic_opset9.acos(g,self)
torch.onnx.symbolic_opset9.add(g,self,other,alpha=None)
torch.onnx.symbolic_opset9.addmm(g,self,mat1,mat2,beta,alpha)
torch.onnx.symbolic_opset9.alias(g,self)
torch.onnx.symbolic_opset9.arange(g,*args)
torch.onnx.symbolic_opset9.argmax(g,input,dim,keepdim)
torch.onnx.symbolic_opset9.argmin(g,input,dim,keepdim)
torch.onnx.symbolic_opset9.as_strided(g,self,sizes,strides,offset=None)
torch.onnx.symbolic_opset9.asin(g,self)
torch.onnx.symbolic_opset9.atan(g,self)
torch.onnx.symbolic_opset9.baddbmm(g,self,batch1,batch2,beta,alpha)
torch.onnx.symbolic_opset9.batch_norm(g,input,weight,bias,running_mean,running_var,training,momentum,eps,cudnn_enabled)
torch.onnx.symbolic_opset9.bitwise_not(g,inp)
torch.onnx.symbolic_opset9.bmm(g,self,other)
torch.onnx.symbolic_opset9.cat(g,tensor_list,dim)
torch.onnx.symbolic_opset9.ceil(g,input)
torch.onnx.symbolic_opset9.clamp(g,self,min,max)
torch.onnx.symbolic_opset9.clamp_max(g,self,max)
torch.onnx.symbolic_opset9.clamp_min(g,self,min)
torch.onnx.symbolic_opset9.clone(g,input,unused_memory_format)
torch.onnx.symbolic_opset9.constant_pad_nd(g,input,padding,value)
torch.onnx.symbolic_opset9.contiguous(g,input,memory_format)
torch.onnx.symbolic_opset9.conv1d(g,input,weight,bias,stride,padding,dilation,groups)
torch.onnx.symbolic_opset9.conv2d(g,input,weight,bias,stride,padding,dilation,groups)
torch.onnx.symbolic_opset9.conv3d(g,input,weight,bias,stride,padding,dilation,groups)
torch.onnx.symbolic_opset9.conv_tbc(g,input,weight,bias,pad)
torch.onnx.symbolic_opset9.conv_transpose1d(g,input,weight,bias,stride,padding,output_padding,groups,dilation)
torch.onnx.symbolic_opset9.conv_transpose2d(g,input,weight,bias,stride,padding,output_padding,groups,dilation)
torch.onnx.symbolic_opset9.conv_transpose3d(g,input,weight,bias,stride,padding,output_padding,groups,dilation)
torch.onnx.symbolic_opset9.cos(g,self)
torch.onnx.symbolic_opset9.cosine_similarity(g,x1,x2,dim,eps)
torch.onnx.symbolic_opset9.cumsum(g,input,dim,dtype)
torch.onnx.symbolic_opset9.detach(g,input)
torch.onnx.symbolic_opset9.dim(g,self)
torch.onnx.symbolic_opset9.div(g,self,other)
torch.onnx.symbolic_opset9.dropout(g,input,p,train)
torch.onnx.symbolic_opset9.elu(g,input,alpha,scale,input_scale)
torch.onnx.symbolic_opset9.embedding(g,weight,indices,padding_idx,scale_grad_by_freq,sparse)
torch.onnx.symbolic_opset9.embedding_bag(g,embedding_matrix,indices,offsets,scale_grad_by_freq,mode,sparse,per_sample_weights,include_last_offset)
torch.onnx.symbolic_opset9.empty(g,sizes,dtype,layout,device,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset9.empty_like(g,input,dtype=None,layout=None,device=None,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset9.eq(g,self,other)
torch.onnx.symbolic_opset9.erf(g,input)
torch.onnx.symbolic_opset9.exp(g,self)
torch.onnx.symbolic_opset9.expand(g,self,size,implicit)
torch.onnx.symbolic_opset9.expand_as(g,self,other)
torch.onnx.symbolic_opset9.eye(g,n,m,dtype=None,layout=None,device=None,pin_memory=False)
torch.onnx.symbolic_opset9.flatten(g,input,start_dim,end_dim)
torch.onnx.symbolic_opset9.floor(g,input)
torch.onnx.symbolic_opset9.floor_divide(g,self,other)
torch.onnx.symbolic_opset9.floordiv(g,self,other)
torch.onnx.symbolic_opset9.frobenius_norm(g,self,dim=None,keepdim=False)
torch.onnx.symbolic_opset9.full(g,sizes,value,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset9.full_like(g,input,fill_value,dtype=None,layout=None,device=None,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset9.gather(g,self,dim,index,sparse_grad=False)
torch.onnx.symbolic_opset9.ge(g,input,other)
torch.onnx.symbolic_opset9.gelu(g,self)
torch.onnx.symbolic_opset9.get_pool_ceil_padding(input,kernel_size,stride,padding)
torch.onnx.symbolic_opset9.glu(g,input,dim)
torch.onnx.symbolic_opset9.group_norm(g,input,num_groups,weight,bias,eps,cudnn_enabled)
torch.onnx.symbolic_opset9.gt(g,input,other)
torch.onnx.symbolic_opset9.gt_impl(g,input,other)
torch.onnx.symbolic_opset9.hardtanh(g,self,min_val,max_val)
torch.onnx.symbolic_opset9.index(g,self,index)
torch.onnx.symbolic_opset9.index_copy(g,self,dim,index,source)
torch.onnx.symbolic_opset9.index_fill(g,self,dim,index,value)
torch.onnx.symbolic_opset9.index_put(g,self,indices_list_value,values,accumulate)
torch.onnx.symbolic_opset9.index_select(g,self,dim,index)
torch.onnx.symbolic_opset9.instance_norm(g,input,weight,bias,running_mean,running_var,use_input_stats,momentum,eps,cudnn_enabled)
torch.onnx.symbolic_opset9.isnan(g,input)
torch.onnx.symbolic_opset9.kl_div(g,input,target,reduction,log_target)
torch.onnx.symbolic_opset9.layer_norm(g,input,normalized_shape,weight,bias,eps,cudnn_enable)
torch.onnx.symbolic_opset9.le(g,input,other)
torch.onnx.symbolic_opset9.leaky_relu(g,input,negative_slope,inplace=False)
torch.onnx.symbolic_opset9.log(g,self)
torch.onnx.symbolic_opset9.log1p(g,self)
torch.onnx.symbolic_opset9.log2(g,self)
torch.onnx.symbolic_opset9.log_sigmoid(g,input)
torch.onnx.symbolic_opset9.log_softmax(g,input,dim,dtype=None)
torch.onnx.symbolic_opset9.logsumexp(g,input,dim,keepdim)
torch.onnx.symbolic_opset9.lstm(g,*args)
torch.onnx.symbolic_opset9.lt(g,input,other)
torch.onnx.symbolic_opset9.lt_impl(g,input,other)
torch.onnx.symbolic_opset9.masked_fill(g,self,mask,value)
torch.onnx.symbolic_opset9.matmul(g,self,other)
torch.onnx.symbolic_opset9.max(g,self,dim_or_y=None,keepdim=None)
torch.onnx.symbolic_opset9.meshgrid(g,tensor_list)
torch.onnx.symbolic_opset9.min(g,self,dim_or_y=None,keepdim=None)
torch.onnx.symbolic_opset9.mm(g,self,other)
torch.onnx.symbolic_opset9.mul(g,self,other)
torch.onnx.symbolic_opset9.multinomial(g,input,num_samples,replacement=False,generator=None)
torch.onnx.symbolic_opset9.narrow(g,input,dim,start,length)
torch.onnx.symbolic_opset9.ne(g,self,other)
torch.onnx.symbolic_opset9.neg(g,self)
torch.onnx.symbolic_opset9.new_empty(g,self,sizes,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset9.new_full(g,self,size,fill_value,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset9.new_zeros(g,self,sizes,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset9.nonzero(g,input)
torch.onnx.symbolic_opset9.norm(g,self,p,dim,keepdim)
torch.onnx.symbolic_opset9.numel(g,self)
torch.onnx.symbolic_opset9.one_hot(g,self,num_classes)
torch.onnx.symbolic_opset9.ones(g,sizes,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset9.ones_like(g,input,dtype=None,layout=None,device=None,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset9.overload_by_arg_count(fn)
torch.onnx.symbolic_opset9.permute(g,self,dims)
torch.onnx.symbolic_opset9.pixel_shuffle(g,self,upscale_factor)
torch.onnx.symbolic_opset9.pow(g,self,exponent)
torch.onnx.symbolic_opset9.prelu(g,self,weight)
torch.onnx.symbolic_opset9.prim_ConstantChunk(g,self,chunks,dim)
torch.onnx.symbolic_opset9.prim_ConstantSplit(g,self,split_size,dim)
torch.onnx.symbolic_opset9.prim_shape(g,self)
torch.onnx.symbolic_opset9.rand(g,shapes,dtype,*options)
torch.onnx.symbolic_opset9.rand_like(g,self,dtype,layout=None,device=None,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset9.randn(g,shapes,dtype,*options)
torch.onnx.symbolic_opset9.randn_like(g,self,dtype,layout=None,device=None,pin_memory=False,memory_format=None)
torch.onnx.symbolic_opset9.reciprocal(g,self)
torch.onnx.symbolic_opset9.reflection_pad(g,input,padding)
torch.onnx.symbolic_opset9.relu(g,input)
torch.onnx.symbolic_opset9.remainder(g,input,other)
torch.onnx.symbolic_opset9.repeat(g,self,repeats)
torch.onnx.symbolic_opset9.replication_pad(g,input,padding)
torch.onnx.symbolic_opset9.reshape(g,self,shape)
torch.onnx.symbolic_opset9.reshape_as(g,self,other)
torch.onnx.symbolic_opset9.rrelu(g,input,lower,upper,training,generator)
torch.onnx.symbolic_opset9.rsqrt(g,self)
torch.onnx.symbolic_opset9.rsub(g,self,other,alpha=None)
torch.onnx.symbolic_opset9.scalar_tensor(g,scalar,dtype,*options)
torch.onnx.symbolic_opset9.scatter(g,self,dim,index,src)
torch.onnx.symbolic_opset9.scatter_add(g,self,dim,index,src)
torch.onnx.symbolic_opset9.select(g,self,dim,index)
torch.onnx.symbolic_opset9.selu(g,input)
torch.onnx.symbolic_opset9.sigmoid(g,self)
torch.onnx.symbolic_opset9.sign(g,self)
torch.onnx.symbolic_opset9.sin(g,self)
torch.onnx.symbolic_opset9.size(g,self,dim=None)
torch.onnx.symbolic_opset9.slice(g,self,*args)
torch.onnx.symbolic_opset9.softmax(g,input,dim,dtype=None)
torch.onnx.symbolic_opset9.softplus(g,self,beta,threshold)
torch.onnx.symbolic_opset9.sort(g,self,dim,decending,out=None)
torch.onnx.symbolic_opset9.split(g,self,split_size_or_sizes,dim,_outputs=None)
torch.onnx.symbolic_opset9.split_with_sizes(g,self,split_sizes,dim,_outputs=None)
torch.onnx.symbolic_opset9.sqrt(g,self)
torch.onnx.symbolic_opset9.squeeze(g,self,dim=None)
torch.onnx.symbolic_opset9.stack(g,tensor_list,dim)
torch.onnx.symbolic_opset9.std(g,input,*args)
torch.onnx.symbolic_opset9.sub(g,self,other,alpha=None)
torch.onnx.symbolic_opset9.t(g,self)
torch.onnx.symbolic_opset9.take(g,self,index)
torch.onnx.symbolic_opset9.tan(g,self)
torch.onnx.symbolic_opset9.tanh(g,self)
torch.onnx.symbolic_opset9.tensor(g,data,dtype=None,device=None,requires_grad=False)
torch.onnx.symbolic_opset9.threshold(g,self,threshold,value)
torch.onnx.symbolic_opset9.to(g,self,*args)
torch.onnx.symbolic_opset9.topk(g,self,k,dim,largest,sorted,out=None)
torch.onnx.symbolic_opset9.transpose(g,self,dim0,dim1)
torch.onnx.symbolic_opset9.true_divide(g,self,other)
torch.onnx.symbolic_opset9.type_as(g,self,other)
torch.onnx.symbolic_opset9.unbind(g,self,dim=0,_outputs=None)
torch.onnx.symbolic_opset9.unfold(g,input,dimension,size,step)
torch.onnx.symbolic_opset9.unsafe_chunk(g,self,chunks,dim,_outputs=None)
torch.onnx.symbolic_opset9.unsafe_split(g,self,split_size_or_sizes,dim,_outputs=None)
torch.onnx.symbolic_opset9.unsafe_split_with_sizes(g,self,split_sizes,dim,_outputs=None)
torch.onnx.symbolic_opset9.unsqueeze(g,self,dim)
torch.onnx.symbolic_opset9.unused(g)
torch.onnx.symbolic_opset9.view(g,self,size)
torch.onnx.symbolic_opset9.view_as(g,self,other)
torch.onnx.symbolic_opset9.where(g,condition,self=None,other=None,_outputs=None)
torch.onnx.symbolic_opset9.wrap_logical_op_with_cast_to(to_type)
torch.onnx.symbolic_opset9.wrap_logical_op_with_cast_to_and_from(to_type)
torch.onnx.symbolic_opset9.wrap_logical_op_with_negation(func)
torch.onnx.symbolic_opset9.zeros(g,sizes,dtype,layout,device,pin_memory=False)
torch.onnx.symbolic_opset9.zeros_like(g,input,dtype=None,layout=None,device=None,pin_memory=False,memory_format=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/__init__.py----------------------------------------
A:torch.onnx.__init__.result->torch.onnx.utils._export(*args, **kwargs)
torch.onnx.__init__.ExportTypes
torch.onnx.__init__._export(*args,**kwargs)
torch.onnx.__init__._export_to_pretty_string(*args,**kwargs)
torch.onnx.__init__._optimize_trace(graph,operator_export_type)
torch.onnx.__init__._run_symbolic_function(*args,**kwargs)
torch.onnx.__init__._run_symbolic_method(*args,**kwargs)
torch.onnx.__init__.export(model,args,f,export_params=True,verbose=False,training=TrainingMode.EVAL,input_names=None,output_names=None,aten=False,export_raw_ir=False,operator_export_type=None,opset_version=None,_retain_param_name=True,do_constant_folding=True,example_outputs=None,strip_doc_string=True,dynamic_axes=None,keep_initializers_as_inputs=None,custom_opsets=None,enable_onnx_checker=True,use_external_data_format=False)
torch.onnx.__init__.export_to_pretty_string(*args,**kwargs)
torch.onnx.__init__.is_in_onnx_export()
torch.onnx.__init__.register_custom_op_symbolic(symbolic_name,symbolic_fn,opset_version)
torch.onnx.__init__.select_model_mode_for_export(model,mode)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_opset10.py----------------------------------------
A:torch.onnx.symbolic_opset10.kwargs['dilations_i']->tuple_fn(dilation)
A:torch.onnx.symbolic_opset10.(r, indices)->g.op('MaxPool', input, outputs=2, **kwargs)
A:torch.onnx.symbolic_opset10.(_, flattened_indices)->g.op('MaxPool', input, outputs=2, kernel_shape_i=[1 for _ in range(ndims)], strides_i=[1 for _ in range(ndims)])
A:torch.onnx.symbolic_opset10.s->torch.onnx.symbolic_helper._slice_helper(g, flattened_indices, axes=[2 + i for i in range(ndims)], starts=tuple_fn(0), ends=tuple_fn(1))
A:torch.onnx.symbolic_opset10.indices->sub(g, indices, s)
A:torch.onnx.symbolic_opset10.r->g.op('MaxPool', input, outputs=1, **kwargs)
A:torch.onnx.symbolic_opset10.max_pool1d->_max_pool('max_pool1d', _single, 1, return_indices=False)
A:torch.onnx.symbolic_opset10.max_pool2d->_max_pool('max_pool2d', _pair, 2, return_indices=False)
A:torch.onnx.symbolic_opset10.max_pool3d->_max_pool('max_pool3d', _triple, 3, return_indices=False)
A:torch.onnx.symbolic_opset10.max_pool1d_with_indices->_max_pool('max_pool1d_with_indices', _single, 1, return_indices=True)
A:torch.onnx.symbolic_opset10.max_pool2d_with_indices->_max_pool('max_pool2d_with_indices', _pair, 2, return_indices=True)
A:torch.onnx.symbolic_opset10.max_pool3d_with_indices->_max_pool('max_pool3d_with_indices', _triple, 3, return_indices=True)
A:torch.onnx.symbolic_opset10.padding->torch.onnx.symbolic_helper._avgpool_helper(tuple_fn, padding, kernel_size, stride, divisor_override, name)
A:torch.onnx.symbolic_opset10.input->g.op('Pad', input, pads_i=((0,) * 2 + padding) * 2, mode_s='constant', value_f=0.0)
A:torch.onnx.symbolic_opset10.output->g.op('Concat', *list_, axis_i=0)
A:torch.onnx.symbolic_opset10.avg_pool1d->_avg_pool('avg_pool1d', _single)
A:torch.onnx.symbolic_opset10.avg_pool2d->_avg_pool('avg_pool2d', _pair)
A:torch.onnx.symbolic_opset10.avg_pool3d->_avg_pool('avg_pool3d', _triple)
A:torch.onnx.symbolic_opset10.(scales, align_corners)->torch.onnx.symbolic_helper._get_interpolate_attributes(g, interpolate_mode, args)
A:torch.onnx.symbolic_opset10.align_corners->torch.onnx.symbolic_helper._maybe_get_scalar(align_corners)
A:torch.onnx.symbolic_opset10.scales->torch.onnx.symbolic_helper._interpolate_size_to_scales(g, input, output_size, dim)
A:torch.onnx.symbolic_opset10.upsample_nearest1d->_interpolate('upsample_nearest1d', 3, 'nearest')
A:torch.onnx.symbolic_opset10.upsample_nearest2d->_interpolate('upsample_nearest2d', 4, 'nearest')
A:torch.onnx.symbolic_opset10.upsample_nearest3d->_interpolate('upsample_nearest3d', 5, 'nearest')
A:torch.onnx.symbolic_opset10.upsample_linear1d->_interpolate('upsample_linear1d', 3, 'linear')
A:torch.onnx.symbolic_opset10.upsample_bilinear2d->_interpolate('upsample_bilinear2d', 4, 'linear')
A:torch.onnx.symbolic_opset10.upsample_trilinear3d->_interpolate('upsample_trilinear3d', 5, 'linear')
A:torch.onnx.symbolic_opset10.(scales, mode)->torch.onnx.symbolic_helper._interpolate_get_scales_and_mode(g, input, size, scale_factor, mode, align_corners)
A:torch.onnx.symbolic_opset10.starts->g.op('Constant', value_t=torch.tensor(starts))
A:torch.onnx.symbolic_opset10.ends->g.op('Constant', value_t=torch.tensor(ends))
A:torch.onnx.symbolic_opset10.axes->g.op('Constant', value_t=torch.tensor(axes))
A:torch.onnx.symbolic_opset10.steps->g.op('Constant', value_t=torch.tensor(steps))
A:torch.onnx.symbolic_opset10.step->torch.onnx.symbolic_helper._parse_arg(step, 'i')
A:torch.onnx.symbolic_opset10.offsets_extended->g.op('Concat', *offsets_extended, axis_i=0)
A:torch.onnx.symbolic_opset10.start_->g.op('Unsqueeze', select(g, offsets_extended, torch.tensor(0), torch.tensor(i)), axes_i=[0])
A:torch.onnx.symbolic_opset10.end_->g.op('Unsqueeze', select(g, offsets_extended, torch.tensor(0), torch.tensor(i + 1)), axes_i=[0])
A:torch.onnx.symbolic_opset10.axes_->g.op('Constant', value_t=torch.tensor([0]))
A:torch.onnx.symbolic_opset10.indices_row->g.op('Slice', indices, start_, end_, axes_)
A:torch.onnx.symbolic_opset10.embeddings->g.op('Unsqueeze', embeddings, axes_i=[0])
A:torch.onnx.symbolic_opset10.per_sample_weights_row->g.op('Unsqueeze', per_sample_weights_row, axes_i=[1])
A:torch.onnx.symbolic_opset10.zero_point->torch.tensor(zero_point, dtype=zero_point_dtype)
torch.onnx.symbolic_opset10.__interpolate(g,input,size,scale_factor,mode,align_corners,recompute_scale_factor)
torch.onnx.symbolic_opset10._avg_pool(name,tuple_fn)
torch.onnx.symbolic_opset10._interpolate(name,dim,interpolate_mode)
torch.onnx.symbolic_opset10._max_pool(name,tuple_fn,ndims,return_indices)
torch.onnx.symbolic_opset10._slice(g,input,axes,starts,ends,steps=None,dynamic_slice=False)
torch.onnx.symbolic_opset10.embedding_bag(g,embedding_matrix,indices,offsets,scale_grad_by_freq,mode,sparse,per_sample_weights,include_last_offset)
torch.onnx.symbolic_opset10.fake_quantize_per_tensor_affine(g,inputs,scale,zero_point,quant_min=-128,quant_max=127)
torch.onnx.symbolic_opset10.flip(g,input,dims)
torch.onnx.symbolic_opset10.fmod(g,input,other)
torch.onnx.symbolic_opset10.slice(g,self,*args)
torch.onnx.symbolic_opset10.sort(g,self,dim,decending,out=None)
torch.onnx.symbolic_opset10.topk(g,self,k,dim,largest,sorted,out=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_opset7.py----------------------------------------
A:torch.onnx.symbolic_opset7.vars()[block_listed_op]->_block_list_in_opset(block_listed_op)
torch.onnx.symbolic_opset7.max(g,self,dim_or_y=None,keepdim=None)
torch.onnx.symbolic_opset7.min(g,self,dim_or_y=None,keepdim=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/onnx/symbolic_opset12.py----------------------------------------
A:torch.onnx.symbolic_opset12.tensors->torch.onnx.symbolic_helper._unpack_list(tensor_list)
A:torch.onnx.symbolic_opset12.p->g.op('Constant', value_t=torch.tensor(p))
A:torch.onnx.symbolic_opset12.t->g.op('Constant', value_t=torch.tensor(True))
A:torch.onnx.symbolic_opset12.(r, _)->g.op('Dropout', input, p, t, outputs=2)
A:torch.onnx.symbolic_opset12.reduction->torch.onnx.symbolic_helper._maybe_get_const(reduction, 'i')
A:torch.onnx.symbolic_opset12.ignore_index->torch.onnx.symbolic_helper._maybe_get_const(ignore_index, 'i')
A:torch.onnx.symbolic_opset12.nllloss->g.op('NegativeLogLikelihoodLoss', self, target, weight, reduction_s=reduction, ignore_index_i=ignore_index)
A:torch.onnx.symbolic_opset12.alpha->torch.onnx.symbolic_helper._maybe_get_const(alpha, 'f')
A:torch.onnx.symbolic_opset12.self->g.op('Cast', self, to_i=sym_help.cast_pytorch_to_onnx['Float'])
A:torch.onnx.symbolic_opset12.out->g.op('Celu', self, alpha_f=alpha)
A:torch.onnx.symbolic_opset12.flattened->reshape(g, input, g.op('Constant', value_t=torch.tensor([-1])))
A:torch.onnx.symbolic_opset12.dim->_parse_arg(dim, 'i')
A:torch.onnx.symbolic_opset12.keepdim->_parse_arg(keepdim, 'i')
torch.onnx.symbolic_opset12.argmax(g,input,dim,keepdim)
torch.onnx.symbolic_opset12.argmin(g,input,dim,keepdim)
torch.onnx.symbolic_opset12.celu(g,self,alpha)
torch.onnx.symbolic_opset12.dropout(g,input,p,train)
torch.onnx.symbolic_opset12.einsum(g,equation,tensor_list)
torch.onnx.symbolic_opset12.ge(g,input,other)
torch.onnx.symbolic_opset12.le(g,input,other)
torch.onnx.symbolic_opset12.nll_loss(g,self,target,weight,reduction,ignore_index)
torch.onnx.symbolic_opset12.nll_loss2d(g,self,target,weight,reduction,ignore_index)
torch.onnx.symbolic_opset12.pow(g,self,exponent)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rendezvous.py----------------------------------------
A:torch.distributed.rendezvous.result->urlparse(url)
A:torch.distributed.rendezvous.query_dict->dict((pair.split('=') for pair in filter(None, result.query.split('&'))))
A:torch.distributed.rendezvous.url->urlunparse(result)
A:torch.distributed.rendezvous.path->urllib.request.url2pathname(result.path)
A:torch.distributed.rendezvous.query->dict((pair.split('=') for pair in filter(None, result.query.split('&'))))
A:torch.distributed.rendezvous.rank->int(rank)
A:torch.distributed.rendezvous.world_size->int(world_size)
A:torch.distributed.rendezvous.store->TCPStore(master_addr, master_port, world_size, start_daemon, timeout)
A:torch.distributed.rendezvous.master_addr->os.environ.get('MASTER_ADDR', None)
A:torch.distributed.rendezvous.master_port->int(master_port)
torch.distributed.rendezvous._env_rendezvous_handler(url,timeout=default_pg_timeout,**kwargs)
torch.distributed.rendezvous._file_rendezvous_handler(url,**kwargs)
torch.distributed.rendezvous._rendezvous_error(msg)
torch.distributed.rendezvous._tcp_rendezvous_handler(url,timeout=default_pg_timeout,**kwargs)
torch.distributed.rendezvous.register_rendezvous_handler(scheme,handler)
torch.distributed.rendezvous.rendezvous(url,rank=-1,world_size=-1,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/distributed_c10d.py----------------------------------------
A:torch.distributed.distributed_c10d.value->getattr(Backend, name.upper(), Backend.UNDEFINED)
A:torch.distributed.distributed_c10d.reduce_op->reduce_op()
A:torch.distributed.distributed_c10d.WORLD->object()
A:torch.distributed.distributed_c10d.NON_GROUP_MEMBER->object()
A:torch.distributed.distributed_c10d.backend->Backend(backend)
A:torch.distributed.distributed_c10d._default_pg->_new_process_group_helper(world_size, rank, [], backend, store, group_name=group_name, timeout=timeout)
A:torch.distributed.distributed_c10d.rendezvous_iterator->rendezvous(init_method, rank, world_size, timeout=timeout)
A:torch.distributed.distributed_c10d.(store, rank, world_size)->next(rendezvous_iterator)
A:torch.distributed.distributed_c10d.group_name->str(_group_count)
A:torch.distributed.distributed_c10d.pg->_new_process_group_helper(group_world_size, group_rank, ranks, backend, default_store, timeout=timeout)
A:torch.distributed.distributed_c10d.global_rank->_new_process_group_helper(world_size, rank, [], backend, store, group_name=group_name, timeout=timeout).rank()
A:torch.distributed.distributed_c10d.prefix_store->PrefixStore(group_name, store)
A:torch.distributed.distributed_c10d.group_dst_rank->_get_group_rank(group, dst)
A:torch.distributed.distributed_c10d.group_src_rank->_get_group_rank(group, src)
A:torch.distributed.distributed_c10d.work->group.barrier()
A:torch.distributed.distributed_c10d.src_rank->group.barrier()._source_rank()
A:torch.distributed.distributed_c10d.opts->AllToAllOptions()
A:torch.distributed.distributed_c10d.buffer->pickle.dumps(obj)
A:torch.distributed.distributed_c10d.byte_storage->torch.ByteStorage.from_buffer(buffer)
A:torch.distributed.distributed_c10d.byte_tensor->torch.ByteTensor(byte_storage)
A:torch.distributed.distributed_c10d.local_size->torch.LongTensor([byte_tensor.numel()])
A:torch.distributed.distributed_c10d.out->pickle.loads(buf)
A:torch.distributed.distributed_c10d.(input_tensor, local_size)->_object_to_tensor(obj)
A:torch.distributed.distributed_c10d.group_backend->get_backend(group)
A:torch.distributed.distributed_c10d.my_rank->get_rank()
A:torch.distributed.distributed_c10d.group_size->get_world_size(group=group)
A:torch.distributed.distributed_c10d.object_sizes_tensor->object_sizes_tensor.to(my_rank).to(my_rank)
A:torch.distributed.distributed_c10d.max_object_size->max(object_size_list)
A:torch.distributed.distributed_c10d.coalesced_output_tensor->torch.empty(max_object_size * group_size, dtype=torch.uint8).to(my_rank if is_nccl_backend else 'cpu')
A:torch.distributed.distributed_c10d.tensor->tensor.type(torch.ByteTensor).type(torch.ByteTensor)
A:torch.distributed.distributed_c10d.object_list[i]->_tensor_to_object(obj_view, obj_size)
A:torch.distributed.distributed_c10d.object_gather_list[i]->_tensor_to_object(tensor, tensor_size)
A:torch.distributed.distributed_c10d.(tensor_list, size_list)->zip(*[_object_to_tensor(obj) for obj in object_list])
A:torch.distributed.distributed_c10d.object_tensor->object_tensor.to(my_rank).to(my_rank)
A:torch.distributed.distributed_c10d.obj_view->obj_view.type(torch.ByteTensor).type(torch.ByteTensor)
A:torch.distributed.distributed_c10d.global_world_size->_new_process_group_helper(world_size, rank, [], backend, store, group_name=group_name, timeout=timeout).size()
A:torch.distributed.distributed_c10d.ranks->list(range(global_world_size))
A:torch.distributed.distributed_c10d.group_world_size->len(ranks)
A:torch.distributed.distributed_c10d.group_rank->list(range(global_world_size)).index(global_rank)
torch.distributed.Backend(cls,name)
torch.distributed.Backend.register_backend(cls,name,func)
torch.distributed.GroupMember(object)
torch.distributed._check_default_pg()
torch.distributed._check_single_tensor(param,param_name)
torch.distributed._check_tensor_list(param,param_name)
torch.distributed._get_default_group()
torch.distributed._get_default_store()
torch.distributed._get_global_rank(group,group_rank)
torch.distributed._get_group_rank(group,rank)
torch.distributed._get_group_size(group)
torch.distributed._new_process_group_helper(world_size,rank,group_ranks,backend,store,group_name=None,timeout=default_pg_timeout)
torch.distributed._object_to_tensor(obj)
torch.distributed._rank_not_in_group(group)
torch.distributed._tensor_to_object(tensor,tensor_size)
torch.distributed._validate_output_list_for_rank(my_rank,dst,gather_list)
torch.distributed.all_gather(tensor_list,tensor,group=group.WORLD,async_op=False)
torch.distributed.all_gather_coalesced(output_tensor_lists,input_tensor_list,group=group.WORLD,async_op=False)
torch.distributed.all_gather_multigpu(output_tensor_lists,input_tensor_list,group=group.WORLD,async_op=False)
torch.distributed.all_gather_object(object_list,obj,group=group.WORLD)
torch.distributed.all_reduce(tensor,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.all_reduce_coalesced(tensors,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.all_reduce_multigpu(tensor_list,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.all_to_all(output_tensor_list,input_tensor_list,group=group.WORLD,async_op=False)
torch.distributed.all_to_all_single(output,input,output_split_sizes=None,input_split_sizes=None,group=group.WORLD,async_op=False)
torch.distributed.barrier(group=group.WORLD,async_op=False)
torch.distributed.broadcast(tensor,src,group=group.WORLD,async_op=False)
torch.distributed.broadcast_multigpu(tensor_list,src,group=group.WORLD,async_op=False,src_tensor=0)
torch.distributed.broadcast_object_list(object_list,src,group=group.WORLD)
torch.distributed.destroy_process_group(group=group.WORLD)
torch.distributed.distributed_c10d.Backend(cls,name)
torch.distributed.distributed_c10d.Backend.__new__(cls,name)
torch.distributed.distributed_c10d.Backend.register_backend(cls,name,func)
torch.distributed.distributed_c10d.GroupMember(object)
torch.distributed.distributed_c10d._check_default_pg()
torch.distributed.distributed_c10d._check_single_tensor(param,param_name)
torch.distributed.distributed_c10d._check_tensor_list(param,param_name)
torch.distributed.distributed_c10d._get_default_group()
torch.distributed.distributed_c10d._get_default_store()
torch.distributed.distributed_c10d._get_global_rank(group,group_rank)
torch.distributed.distributed_c10d._get_group_rank(group,rank)
torch.distributed.distributed_c10d._get_group_size(group)
torch.distributed.distributed_c10d._new_process_group_helper(world_size,rank,group_ranks,backend,store,group_name=None,timeout=default_pg_timeout)
torch.distributed.distributed_c10d._object_to_tensor(obj)
torch.distributed.distributed_c10d._rank_not_in_group(group)
torch.distributed.distributed_c10d._tensor_to_object(tensor,tensor_size)
torch.distributed.distributed_c10d._validate_output_list_for_rank(my_rank,dst,gather_list)
torch.distributed.distributed_c10d.all_gather(tensor_list,tensor,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_gather_coalesced(output_tensor_lists,input_tensor_list,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_gather_multigpu(output_tensor_lists,input_tensor_list,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_gather_object(object_list,obj,group=group.WORLD)
torch.distributed.distributed_c10d.all_reduce(tensor,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_reduce_coalesced(tensors,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_reduce_multigpu(tensor_list,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_to_all(output_tensor_list,input_tensor_list,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.all_to_all_single(output,input,output_split_sizes=None,input_split_sizes=None,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.barrier(group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.broadcast(tensor,src,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.broadcast_multigpu(tensor_list,src,group=group.WORLD,async_op=False,src_tensor=0)
torch.distributed.distributed_c10d.broadcast_object_list(object_list,src,group=group.WORLD)
torch.distributed.distributed_c10d.destroy_process_group(group=group.WORLD)
torch.distributed.distributed_c10d.gather(tensor,gather_list=None,dst=0,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.gather_object(obj,object_gather_list=None,dst=0,group=group.WORLD)
torch.distributed.distributed_c10d.get_backend(group=group.WORLD)
torch.distributed.distributed_c10d.get_rank(group=group.WORLD)
torch.distributed.distributed_c10d.get_world_size(group=group.WORLD)
torch.distributed.distributed_c10d.group(object)
torch.distributed.distributed_c10d.init_process_group(backend,init_method=None,timeout=default_pg_timeout,world_size=-1,rank=-1,store=None,group_name='')
torch.distributed.distributed_c10d.irecv(tensor,src,group=group.WORLD,tag=0)
torch.distributed.distributed_c10d.is_gloo_available()
torch.distributed.distributed_c10d.is_initialized()
torch.distributed.distributed_c10d.is_mpi_available()
torch.distributed.distributed_c10d.is_nccl_available()
torch.distributed.distributed_c10d.isend(tensor,dst,group=group.WORLD,tag=0)
torch.distributed.distributed_c10d.new_group(ranks=None,timeout=default_pg_timeout,backend=None)
torch.distributed.distributed_c10d.recv(tensor,src=None,group=group.WORLD,tag=0)
torch.distributed.distributed_c10d.reduce(tensor,dst,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.reduce_multigpu(tensor_list,dst,op=ReduceOp.SUM,group=group.WORLD,async_op=False,dst_tensor=0)
torch.distributed.distributed_c10d.reduce_op(self)
torch.distributed.distributed_c10d.reduce_op.__getattribute__(self,key)
torch.distributed.distributed_c10d.reduce_op.__init__(self)
torch.distributed.distributed_c10d.reduce_scatter(output,input_list,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.reduce_scatter_multigpu(output_tensor_list,input_tensor_lists,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.scatter(tensor,scatter_list=None,src=0,group=group.WORLD,async_op=False)
torch.distributed.distributed_c10d.send(tensor,dst,group=group.WORLD,tag=0)
torch.distributed.gather(tensor,gather_list=None,dst=0,group=group.WORLD,async_op=False)
torch.distributed.gather_object(obj,object_gather_list=None,dst=0,group=group.WORLD)
torch.distributed.get_backend(group=group.WORLD)
torch.distributed.get_rank(group=group.WORLD)
torch.distributed.get_world_size(group=group.WORLD)
torch.distributed.group(object)
torch.distributed.init_process_group(backend,init_method=None,timeout=default_pg_timeout,world_size=-1,rank=-1,store=None,group_name='')
torch.distributed.irecv(tensor,src,group=group.WORLD,tag=0)
torch.distributed.is_gloo_available()
torch.distributed.is_initialized()
torch.distributed.is_mpi_available()
torch.distributed.is_nccl_available()
torch.distributed.isend(tensor,dst,group=group.WORLD,tag=0)
torch.distributed.new_group(ranks=None,timeout=default_pg_timeout,backend=None)
torch.distributed.recv(tensor,src=None,group=group.WORLD,tag=0)
torch.distributed.reduce(tensor,dst,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.reduce_multigpu(tensor_list,dst,op=ReduceOp.SUM,group=group.WORLD,async_op=False,dst_tensor=0)
torch.distributed.reduce_op(self)
torch.distributed.reduce_op.__getattribute__(self,key)
torch.distributed.reduce_scatter(output,input_list,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.reduce_scatter_multigpu(output_tensor_list,input_tensor_lists,op=ReduceOp.SUM,group=group.WORLD,async_op=False)
torch.distributed.scatter(tensor,scatter_list=None,src=0,group=group.WORLD,async_op=False)
torch.distributed.send(tensor,dst,group=group.WORLD,tag=0)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/launch.py----------------------------------------
A:torch.distributed.launch.parser->ArgumentParser(description='PyTorch distributed training launch helper utility that will spawn up multiple distributed processes')
A:torch.distributed.launch.args->parse_args()
A:torch.distributed.launch.current_env->os.environ.copy()
A:torch.distributed.launch.current_env['MASTER_PORT']->str(args.master_port)
A:torch.distributed.launch.current_env['WORLD_SIZE']->str(dist_world_size)
A:torch.distributed.launch.current_env['OMP_NUM_THREADS']->str(1)
A:torch.distributed.launch.current_env['RANK']->str(dist_rank)
A:torch.distributed.launch.current_env['LOCAL_RANK']->str(local_rank)
A:torch.distributed.launch.process->subprocess.Popen(cmd, env=current_env)
torch.distributed.launch.main()
torch.distributed.launch.parse_args()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/__init__.py----------------------------------------
torch.distributed.__init__.is_available()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/constants.py----------------------------------------
A:torch.distributed.constants.default_pg_timeout->timedelta(minutes=30)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/autograd/__init__.py----------------------------------------
A:torch.distributed.autograd.__init__.self.autograd_context->_new_context()
torch.distributed.autograd.__init__.context(object)
torch.distributed.autograd.__init__.context.__enter__(self)
torch.distributed.autograd.__init__.context.__exit__(self,type,value,traceback)
torch.distributed.autograd.__init__.is_available()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/server_process_global_profiler.py----------------------------------------
A:torch.distributed.rpc.server_process_global_profiler.profiler_config->torch.autograd.ProfilerConfig(profiler_kind, self.record_shapes, self.profile_memory, False)
A:torch.distributed.rpc.server_process_global_profiler.process_global_events->_disable_server_process_global_profiler()
A:torch.distributed.rpc.server_process_global_profiler.thread_local_function_events->torch.autograd.profiler.parse_event_records(thread_local_events)
A:torch.distributed.rpc.server_process_global_profiler.flattened_function_events->list(itertools.chain(*process_global_function_events))
A:torch.distributed.rpc.server_process_global_profiler.self.function_events->torch.autograd.profiler.EventList(flattened_function_events, use_cuda=self.use_cuda, profile_memory=self.profile_memory)
torch.distributed.rpc._server_process_global_profile(self,*args,**kwargs)
torch.distributed.rpc._server_process_global_profile.__enter__(self)
torch.distributed.rpc._server_process_global_profile.__exit__(self,exc_type,exc_val,exc_tb)
torch.distributed.rpc.server_process_global_profiler._server_process_global_profile(self,*args,**kwargs)
torch.distributed.rpc.server_process_global_profiler._server_process_global_profile.__enter__(self)
torch.distributed.rpc.server_process_global_profiler._server_process_global_profile.__exit__(self,exc_type,exc_val,exc_tb)
torch.distributed.rpc.server_process_global_profiler._server_process_global_profile.__init__(self,*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/rref_proxy.py----------------------------------------
A:torch.distributed.rpc.rref_proxy.rref_type->rref._get_type()
A:torch.distributed.rpc.rref_proxy.func->getattr(rref_type, func_name)
torch.distributed.rpc.rref_proxy.RRefProxy(self,rref,rpc_api)
torch.distributed.rpc.rref_proxy.RRefProxy.__getattr__(self,func_name)
torch.distributed.rpc.rref_proxy.RRefProxy.__init__(self,rref,rpc_api)
torch.distributed.rpc.rref_proxy._invoke_rpc(rref,rpc_api,func_name,*args,**kwargs)
torch.distributed.rpc.rref_proxy._local_invoke(rref,func_name,args,kwargs)
torch.distributed.rpc.rref_proxy._local_invoke_async_execution(rref,func_name,args,kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/functions.py----------------------------------------
torch.distributed.rpc.functions.async_execution(fn)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/options.py----------------------------------------
torch.distributed.rpc.TensorPipeRpcBackendOptions(self,*,num_worker_threads:int=rpc_contants.DEFAULT_NUM_WORKER_THREADS,rpc_timeout:float=rpc_contants.DEFAULT_RPC_TIMEOUT_SEC,init_method:str=rpc_contants.DEFAULT_INIT_METHOD,_transports:List=None,_channels:List=None)
torch.distributed.rpc.options.TensorPipeRpcBackendOptions(self,*,num_worker_threads:int=rpc_contants.DEFAULT_NUM_WORKER_THREADS,rpc_timeout:float=rpc_contants.DEFAULT_RPC_TIMEOUT_SEC,init_method:str=rpc_contants.DEFAULT_INIT_METHOD,_transports:List=None,_channels:List=None)
torch.distributed.rpc.options.TensorPipeRpcBackendOptions.__init__(self,*,num_worker_threads:int=rpc_contants.DEFAULT_NUM_WORKER_THREADS,rpc_timeout:float=rpc_contants.DEFAULT_RPC_TIMEOUT_SEC,init_method:str=rpc_contants.DEFAULT_INIT_METHOD,_transports:List=None,_channels:List=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/internal.py----------------------------------------
A:torch.distributed.rpc.internal._thread_local_tensor_tables->threading.local()
A:torch.distributed.rpc.internal.self._dispatch_table->copyreg.dispatch_table.copy()
A:torch.distributed.rpc.internal.rref_fork_data->py_rref._serialize()
A:torch.distributed.rpc.internal.f->io.BytesIO()
A:torch.distributed.rpc.internal.p->pickle.Pickler(f)
A:torch.distributed.rpc.internal.ret->AttributeError(except_str)
A:torch.distributed.rpc.internal._internal_rpc_pickler->_InternalRPCPickler()
A:torch.distributed.rpc.internal.result->RemoteException(except_str, type(e))
A:torch.distributed.rpc.internal.profile_key->'rpc_{}#{}({} -> {})'.format(exec_type.value, str(func_name), current_worker_name, dest_worker_name)
A:torch.distributed.rpc.internal.rf->torch.autograd._RecordFunction()
A:torch.distributed.rpc.internal.PythonUDF->collections.namedtuple('PythonUDF', ['func', 'args', 'kwargs'])
A:torch.distributed.rpc.internal.RemoteException->collections.namedtuple('RemoteException', ['msg', 'exception_type'])
torch.distributed.rpc.internal.RPCExecMode(Enum)
torch.distributed.rpc.internal._InternalRPCPickler(self)
torch.distributed.rpc.internal._InternalRPCPickler.__init__(self)
torch.distributed.rpc.internal._InternalRPCPickler._py_rref_receiver(cls,rref_fork_data)
torch.distributed.rpc.internal._InternalRPCPickler._py_rref_reducer(self,py_rref)
torch.distributed.rpc.internal._InternalRPCPickler._rref_reducer(self,rref)
torch.distributed.rpc.internal._InternalRPCPickler._tensor_receiver(cls,tensor_index)
torch.distributed.rpc.internal._InternalRPCPickler._tensor_reducer(self,tensor)
torch.distributed.rpc.internal._InternalRPCPickler.deserialize(self,binary_data,tensor_table)
torch.distributed.rpc.internal._InternalRPCPickler.serialize(self,obj)
torch.distributed.rpc.internal._build_rpc_profiling_key(exec_type,func_name,current_worker_name,dst_worker_name)
torch.distributed.rpc.internal._handle_exception(result)
torch.distributed.rpc.internal._run_function(python_udf)
torch.distributed.rpc.internal._start_record_function(exec_type,func_name,current_worker_name,dest_worker_name)
torch.distributed.rpc.internal.deserialize(binary_data,tensor_table)
torch.distributed.rpc.internal.serialize(obj)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/api.py----------------------------------------
A:torch.distributed.rpc.api.logger->logging.getLogger(__name__)
A:torch.distributed.rpc.api.self.proceed_signal->threading.Event()
A:torch.distributed.rpc.api._all_gather_dict_lock->threading.RLock()
A:torch.distributed.rpc.api._all_gather_sequence_id_to_states->collections.defaultdict(AllGatherStates)
A:torch.distributed.rpc.api.worker_infos->agent.get_worker_infos()
A:torch.distributed.rpc.api.timeout->get_rpc_timeout()
A:torch.distributed.rpc.api.worker_name_to_response_future_dict->dict()
A:torch.distributed.rpc.api.fut->_invoke_rpc(to, func, RPCExecMode.SYNC, args, kwargs, timeout)
A:torch.distributed.rpc.api.T->TypeVar('T')
A:torch.distributed.rpc.api.docstring->docstring.replace('torch.distributed.rpc.PyRRef', 'torch.distributed.rpc.RRef').replace('torch.distributed.rpc.PyRRef', 'torch.distributed.rpc.RRef')
A:torch.distributed.rpc.api.new_method->method_factory(method_name, docstring)
A:torch.distributed.rpc.api.qualified_name->torch.jit._builtins._find_builtin(func)
A:torch.distributed.rpc.api.dst_worker_info->_to_worker_info(to)
A:torch.distributed.rpc.api.should_profile->torch.autograd._profiler_enabled()
A:torch.distributed.rpc.api.ctx_manager->torch.autograd.profiler.record_function(rpc_profiling_key)
A:torch.distributed.rpc.api.rpc_profiling_key->_build_rpc_profiling_key(rpc_type, func_name, get_worker_info().name, dst_worker_info.name)
A:torch.distributed.rpc.api.is_async_exec->hasattr(func, '_wrapped_async_rpc_function')
A:torch.distributed.rpc.api.rref->_invoke_remote_python_udf(dst_worker_info, pickled_python_udf, tensors, timeout, is_async_exec)
A:torch.distributed.rpc.api.(pickled_python_udf, tensors)->_default_pickler.serialize(PythonUDF(func, args, kwargs))
torch.distributed.rpc.AllGatherStates(self)
torch.distributed.rpc._all_gather(obj,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc._broadcast_to_followers(sequence_id,objects_map)
torch.distributed.rpc._gather_to_leader(sequence_id,worker_name,obj)
torch.distributed.rpc._init_rpc_states(agent)
torch.distributed.rpc._invoke_rpc(to,func,rpc_type,args=None,kwargs=None,rpc_timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc._require_initialized(func)
torch.distributed.rpc._rref_typeof_on_owner(rref)
torch.distributed.rpc._rref_typeof_on_user(rref)
torch.distributed.rpc._to_worker_info(name_or_info)
torch.distributed.rpc._use_rpc_pickler(rpc_pickler)
torch.distributed.rpc._wait_all_workers()
torch.distributed.rpc.api.AllGatherStates(self)
torch.distributed.rpc.api.AllGatherStates.__init__(self)
torch.distributed.rpc.api._all_gather(obj,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.api._broadcast_to_followers(sequence_id,objects_map)
torch.distributed.rpc.api._gather_to_leader(sequence_id,worker_name,obj)
torch.distributed.rpc.api._init_rpc_states(agent)
torch.distributed.rpc.api._invoke_rpc(to,func,rpc_type,args=None,kwargs=None,rpc_timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.api._require_initialized(func)
torch.distributed.rpc.api._rref_typeof_on_owner(rref)
torch.distributed.rpc.api._rref_typeof_on_user(rref)
torch.distributed.rpc.api._to_worker_info(name_or_info)
torch.distributed.rpc.api._use_rpc_pickler(rpc_pickler)
torch.distributed.rpc.api._wait_all_workers()
torch.distributed.rpc.api.get_worker_info(worker_name=None)
torch.distributed.rpc.api.method_factory(method_name,docstring)
torch.distributed.rpc.api.remote(to,func,args=None,kwargs=None,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.api.rpc_async(to,func,args=None,kwargs=None,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.api.rpc_sync(to,func,args=None,kwargs=None,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.api.shutdown(graceful=True)
torch.distributed.rpc.get_worker_info(worker_name=None)
torch.distributed.rpc.method_factory(method_name,docstring)
torch.distributed.rpc.remote(to,func,args=None,kwargs=None,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.rpc_async(to,func,args=None,kwargs=None,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.rpc_sync(to,func,args=None,kwargs=None,timeout=UNSET_RPC_TIMEOUT)
torch.distributed.rpc.shutdown(graceful=True)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/backend_registry.py----------------------------------------
A:torch.distributed.rpc.backend_registry.BackendValue->collections.namedtuple('BackendValue', ['construct_rpc_backend_options_handler', 'init_backend_handler'])
A:torch.distributed.rpc.backend_registry.BackendType->enum.Enum(value='BackendType', names=extended_enum_dict)
A:torch.distributed.rpc.backend_registry.extended_enum_dict->dict({backend_name: BackendValue(construct_rpc_backend_options_handler=construct_rpc_backend_options_handler, init_backend_handler=init_backend_handler)}, **existing_enum_dict)
A:torch.distributed.rpc.backend_registry.group->_init_process_group(store, rank, world_size)
torch.distributed.rpc.backend_registry._backend_type_repr(self)
torch.distributed.rpc.backend_registry._init_process_group(store,rank,world_size)
torch.distributed.rpc.backend_registry._process_group_construct_rpc_backend_options_handler(rpc_timeout,init_method,num_send_recv_threads=rpc_constants.DEFAULT_NUM_SEND_RECV_THREADS,**kwargs)
torch.distributed.rpc.backend_registry._process_group_init_backend_handler(store,name,rank,world_size,rpc_backend_options)
torch.distributed.rpc.backend_registry._tensorpipe_construct_rpc_backend_options_handler(rpc_timeout,init_method,num_worker_threads=rpc_constants.DEFAULT_NUM_WORKER_THREADS,_transports=None,_channels=None,**kwargs)
torch.distributed.rpc.backend_registry._tensorpipe_init_backend_handler(store,name,rank,world_size,rpc_backend_options)
torch.distributed.rpc.backend_registry.backend_registered(backend_name)
torch.distributed.rpc.backend_registry.construct_rpc_backend_options(backend,rpc_timeout=rpc_constants.DEFAULT_RPC_TIMEOUT_SEC,init_method=rpc_constants.DEFAULT_INIT_METHOD,**kwargs)
torch.distributed.rpc.backend_registry.init_backend(backend,*args,**kwargs)
torch.distributed.rpc.backend_registry.register_backend(backend_name,construct_rpc_backend_options_handler,init_backend_handler)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/__init__.py----------------------------------------
A:torch.distributed.rpc.__init__.logger->logging.getLogger(__name__)
A:torch.distributed.rpc.__init__._init_counter_lock->threading.Lock()
A:torch.distributed.rpc.__init__.rpc_backend_options->backend_registry.construct_rpc_backend_options(backend)
A:torch.distributed.rpc.__init__.rendezvous_iterator->torch.distributed.rendezvous(rpc_backend_options.init_method, rank=rank, world_size=world_size)
A:torch.distributed.rpc.__init__.(store, _, _)->next(rendezvous_iterator)
A:torch.distributed.rpc.__init__.store->torch.distributed.PrefixStore(str('rpc_prefix_{}'.format(_init_counter)), store)
A:torch.distributed.rpc.__init__.rpc_agent->backend_registry.init_backend(backend, store=store, name=name, rank=rank, world_size=world_size, rpc_backend_options=rpc_backend_options)
A:torch.distributed.rpc.__init__.info->_rref_context_get_debug_info()
torch.distributed.rpc.__init__.is_available()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/constants.py----------------------------------------
A:torch.distributed.rpc.constants.DEFAULT_PROCESS_GROUP_TIMEOUT->timedelta(milliseconds=2 ** 31 - 1)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/_testing/faulty_agent_backend_registry.py----------------------------------------
A:torch.distributed.rpc._testing.faulty_agent_backend_registry.group->torch.distributed.distributed_c10d._get_default_group()
torch.distributed.rpc._testing.faulty_agent_backend_registry._faulty_process_group_construct_rpc_backend_options_handler(rpc_timeout,init_method,num_send_recv_threads,messages_to_fail,messages_to_delay,num_fail_sends,**kwargs)
torch.distributed.rpc._testing.faulty_agent_backend_registry._faulty_process_group_init_backend_handler(store,name,rank,world_size,rpc_backend_options)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/rpc/_testing/__init__.py----------------------------------------
torch.distributed.rpc._testing.__init__.is_available()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/api/remote_module.py----------------------------------------
A:torch.distributed.nn.api.remote_module.T->TypeVar('T', bound='Module')
A:torch.distributed.nn.api.remote_module._NON_SCRIPTABLE_REMOTE_MODULE_MODULE->torch.distributed.nn.jit.instantiator.instantiate_non_scriptable_remote_module_template()
A:torch.distributed.nn.api.remote_module.module->torch.jit.script(module)
A:torch.distributed.nn.api.remote_module.fut->torch.distributed.rpc.rpc_async(on, _instantiate_template, (_module_interface_cls,))
A:torch.distributed.nn.api.remote_module.generated_module->torch.distributed.nn.jit.instantiator.instantiate_scriptable_remote_module_template(_module_interface_cls)
A:torch.distributed.nn.api.remote_module.self.module_rref->torch.distributed.rpc.rpc_sync(on, _create_module, (module_cls, args, kwargs, device, _module_interface_cls))
A:torch.distributed.nn.api.remote_module.method->torch.jit.export(method)
torch.distributed.nn.RemoteModule(self,on:str,device:torch.device,module_cls:nn.Module,args:Tuple=None,kwargs:Dict[str,Any]=None)
torch.distributed.nn.api.remote_module.RemoteModule(self,on:str,device:torch.device,module_cls:nn.Module,args:Tuple=None,kwargs:Dict[str,Any]=None)
torch.distributed.nn.api.remote_module.RemoteModule.__init__(self,on:str,device:torch.device,module_cls:nn.Module,args:Tuple=None,kwargs:Dict[str,Any]=None)
torch.distributed.nn.api.remote_module._RemoteModule(self,on:str,device:torch.device,module_cls:nn.Module,args:Tuple=None,kwargs:Dict[str,Any]=None,_module_interface_cls:Any=None)
torch.distributed.nn.api.remote_module._RemoteModule.__init__(self,on:str,device:torch.device,module_cls:nn.Module,args:Tuple=None,kwargs:Dict[str,Any]=None,_module_interface_cls:Any=None)
torch.distributed.nn.api.remote_module._RemoteModule.add_module(self,name:str,module:Optional['Module'])->None
torch.distributed.nn.api.remote_module._RemoteModule.apply(self:T,fn:Callable[['Module'],None])->T
torch.distributed.nn.api.remote_module._RemoteModule.bfloat16(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.buffers(self,recurse:bool=True)->Iterator[Tensor]
torch.distributed.nn.api.remote_module._RemoteModule.children(self)->Iterator['Module']
torch.distributed.nn.api.remote_module._RemoteModule.cpu(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.cuda(self:T,device:Optional[Union[int,device]]=None)->T
torch.distributed.nn.api.remote_module._RemoteModule.double(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.eval(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.extra_repr(self)->str
torch.distributed.nn.api.remote_module._RemoteModule.float(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.half(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.load_state_dict(self,state_dict:Union[Dict[str,Tensor],Dict[str,Tensor]],strict:bool=True)
torch.distributed.nn.api.remote_module._RemoteModule.modules(self)->Iterator['Module']
torch.distributed.nn.api.remote_module._RemoteModule.named_buffers(self,prefix:str='',recurse:bool=True)->Iterator[Tuple[str, Tensor]]
torch.distributed.nn.api.remote_module._RemoteModule.named_children(self)->Iterator[Tuple[str, 'Module']]
torch.distributed.nn.api.remote_module._RemoteModule.named_modules(self,memo:Optional[Set['Module']]=None,prefix:str='')
torch.distributed.nn.api.remote_module._RemoteModule.named_parameters(self,prefix:str='',recurse:bool=True)->Iterator[Tuple[str, Tensor]]
torch.distributed.nn.api.remote_module._RemoteModule.parameters(self,recurse:bool=True)->Iterator[Parameter]
torch.distributed.nn.api.remote_module._RemoteModule.register_backward_hook(self,hook:Callable[['Module',_grad_t,_grad_t],Union[None,Tensor]])->RemovableHandle
torch.distributed.nn.api.remote_module._RemoteModule.register_buffer(self,name:str,tensor:Optional[Tensor],persistent:bool=True)->None
torch.distributed.nn.api.remote_module._RemoteModule.register_forward_hook(self,hook:Callable[...,None])->RemovableHandle
torch.distributed.nn.api.remote_module._RemoteModule.register_forward_pre_hook(self,hook:Callable[...,None])->RemovableHandle
torch.distributed.nn.api.remote_module._RemoteModule.register_parameter(self,name:str,param:Optional[Parameter])->None
torch.distributed.nn.api.remote_module._RemoteModule.remote_parameters(self,recurse:bool=True)->List[rpc.RRef[Parameter]]
torch.distributed.nn.api.remote_module._RemoteModule.requires_grad_(self:T,requires_grad:bool=True)->T
torch.distributed.nn.api.remote_module._RemoteModule.share_memory(self:T)->T
torch.distributed.nn.api.remote_module._RemoteModule.state_dict(self,destination=None,prefix='',keep_vars=False)
torch.distributed.nn.api.remote_module._RemoteModule.to(self,*args,**kwargs)
torch.distributed.nn.api.remote_module._RemoteModule.train(self:T,mode:bool=True)->T
torch.distributed.nn.api.remote_module._RemoteModule.type(self:T,dst_type:Union[dtype,str])->T
torch.distributed.nn.api.remote_module._RemoteModule.zero_grad(self)->None
torch.distributed.nn.api.remote_module._create_module(module_cls,args,kwargs,device='cpu',module_interface_cls=None)
torch.distributed.nn.api.remote_module._instantiate_template(module_interface_cls)
torch.distributed.nn.api.remote_module._param_rrefs(module_rref,recurse)
torch.distributed.nn.api.remote_module._raise_not_supported(name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/api/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/jit/instantiator.py----------------------------------------
A:torch.distributed.nn.jit.instantiator.logger->logging.getLogger(__name__)
A:torch.distributed.nn.jit.instantiator._TEMP_DIR->tempfile.TemporaryDirectory()
A:torch.distributed.nn.jit.instantiator.qualified_name->torch._jit_internal._qualified_name(module_interface)
A:torch.distributed.nn.jit.instantiator.module_interface_c->cu.get_interface(qualified_name)
A:torch.distributed.nn.jit.instantiator.method_schema->cu.get_interface(qualified_name).getMethod('forward')
A:torch.distributed.nn.jit.instantiator.default_value_str->' = {}'.format(argument.default)
A:torch.distributed.nn.jit.instantiator.arg_type_str->'{name}: {type}{default_value}'.format(name=argument.name, type=argument.type, default_value=default_value_str)
A:torch.distributed.nn.jit.instantiator.args_str->', '.join(arg_str_list)
A:torch.distributed.nn.jit.instantiator.arg_types_str->', '.join(arg_type_str_list)
A:torch.distributed.nn.jit.instantiator.return_type_str->str(argument.type)
A:torch.distributed.nn.jit.instantiator.old_text->f.read()
A:torch.distributed.nn.jit.instantiator.generated_code_text->torch.distributed.nn.jit.templates.remote_module_template.REMOTE_MODULE_TEMPLATE.format(**str_dict)
A:torch.distributed.nn.jit.instantiator.out_path->os.path.join(INSTANTIATED_TEMPLATE_DIR_PATH, f'{generated_module_name}.py')
A:torch.distributed.nn.jit.instantiator.generated_module->importlib.import_module(f'{generated_module_name}')
A:torch.distributed.nn.jit.instantiator.module_interface_cls_name->torch._jit_internal._qualified_name(module_interface_cls).replace('.', '_')
A:torch.distributed.nn.jit.instantiator.(args_str, arg_types_str, return_type_str)->get_arg_return_types_from_interface(module_interface_cls)
A:torch.distributed.nn.jit.instantiator.str_dict->dict(assign_module_interface_cls='module_interface_cls = None', args='*args', kwargs='**kwargs', arg_types='*args, **kwargs', arrow_and_return_type='', arrow_and_future_return_type='', jit_script_decorator='')
torch.distributed.nn.jit.instantiator._do_instantiate_remote_module_template(generated_module_name,str_dict)
torch.distributed.nn.jit.instantiator._write(out_path,text)
torch.distributed.nn.jit.instantiator.get_arg_return_types_from_interface(module_interface)
torch.distributed.nn.jit.instantiator.instantiate_non_scriptable_remote_module_template()
torch.distributed.nn.jit.instantiator.instantiate_scriptable_remote_module_template(module_interface_cls)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/jit/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/jit/templates/remote_module_template.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/nn/jit/templates/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/optim/functional_adagrad.py----------------------------------------
A:torch.distributed.optim.functional_adagrad.self.state->torch.jit.annotate(Dict[torch.Tensor, Dict[str, torch.Tensor]], {})
torch.distributed.optim.functional_adagrad._FunctionalAdagrad(self,params:List[Tensor],lr:float=0.01,lr_decay:float=0.0,weight_decay:float=0.0,initial_accumulator_value:float=0.0,warmup_lr_multiplier:float=1.0,warmup_num_iters:float=0.0,eps:float=1e-10,coalesce_grad:bool=True)
torch.distributed.optim.functional_adagrad._FunctionalAdagrad.__init__(self,params:List[Tensor],lr:float=0.01,lr_decay:float=0.0,weight_decay:float=0.0,initial_accumulator_value:float=0.0,warmup_lr_multiplier:float=1.0,warmup_num_iters:float=0.0,eps:float=1e-10,coalesce_grad:bool=True)
torch.distributed.optim.functional_adagrad._FunctionalAdagrad.step(self,gradients:List[Optional[Tensor]])


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/optim/optimizer.py----------------------------------------
A:torch.distributed.optim.optimizer.compile_lock->Lock()
A:torch.distributed.optim.optimizer.self.optim->optim_cls(self._local_params, *args, **kwargs)
A:torch.distributed.optim.optimizer.all_local_grads->torch.distributed.autograd.get_gradients(autograd_ctx_id)
A:torch.distributed.optim.optimizer.global_lock->Lock()
A:torch.distributed.optim.optimizer.local_optim->local_optim_rref.local_value()
A:torch.distributed.optim.optimizer.optim->_ScriptLocalOptimizer(optim_cls, local_params_rref, *args, **kwargs)
A:torch.distributed.optim.optimizer.script_optim->torch.jit.script(optim)
A:torch.distributed.optim.optimizer.per_worker_params_rref->defaultdict(list)
A:torch.distributed.optim.optimizer.optim_ctor->DistributedOptimizer.functional_optim_map.get(optimizer_class, optimizer_class)
A:torch.distributed.optim.optimizer.remote_optim_rref_fut->torch.distributed.rpc.rpc_async(worker, optimizer_new_func, args=(optim_ctor, param_rrefs) + args, kwargs=kwargs)
A:torch.distributed.optim.optimizer.self.remote_optimizers->_wait_for_all(remote_optim_futs)
torch.distributed.optim.DistributedOptimizer(self,optimizer_class,params_rref,*args,**kwargs)
torch.distributed.optim.DistributedOptimizer.step(self,context_id)
torch.distributed.optim.optimizer.DistributedOptimizer(self,optimizer_class,params_rref,*args,**kwargs)
torch.distributed.optim.optimizer.DistributedOptimizer.__init__(self,optimizer_class,params_rref,*args,**kwargs)
torch.distributed.optim.optimizer.DistributedOptimizer.step(self,context_id)
torch.distributed.optim.optimizer._LocalOptimizer(self,optim_cls,local_params_rref,*args,**kwargs)
torch.distributed.optim.optimizer._LocalOptimizer.__init__(self,optim_cls,local_params_rref,*args,**kwargs)
torch.distributed.optim.optimizer._LocalOptimizer.step(self,autograd_ctx_id)
torch.distributed.optim.optimizer._ScriptLocalOptimizer(self,optim_cls,local_params_rref,*args,**kwargs)
torch.distributed.optim.optimizer._ScriptLocalOptimizer.__init__(self,optim_cls,local_params_rref,*args,**kwargs)
torch.distributed.optim.optimizer._ScriptLocalOptimizer.step(self,autograd_ctx_id:int)
torch.distributed.optim.optimizer._ScriptLocalOptimizerInterface(object)
torch.distributed.optim.optimizer._ScriptLocalOptimizerInterface.step(self,autograd_ctx_id:int)->None
torch.distributed.optim.optimizer._local_optimizer_step(local_optim_rref,autograd_ctx_id)
torch.distributed.optim.optimizer._new_local_optimizer(optim_cls,local_params_rref,*args,**kwargs)
torch.distributed.optim.optimizer._new_script_local_optimizer(optim_cls,local_params_rref,*args,**kwargs)
torch.distributed.optim.optimizer._script_local_optimizer_step(local_optim_rref:RRef[_ScriptLocalOptimizerInterface],autograd_ctx_id:int)->None
torch.distributed.optim.optimizer._wait_for_all(rpc_futs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributed/optim/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/_equalize.py----------------------------------------
A:torch.quantization._equalize.(input, _)->input.min(axis, keepdim)
A:torch.quantization._equalize.axis_list->list(range(size_of_tensor_dim))
A:torch.quantization._equalize.mins->min_over_ndim(input, axis_list)
A:torch.quantization._equalize.maxs->max_over_ndim(input, axis_list)
A:torch.quantization._equalize.weight1_range->channel_range(weight1, output_axis)
A:torch.quantization._equalize.weight2_range->channel_range(weight2, input_axis)
A:torch.quantization._equalize.scaling_factors->torch.reshape(scaling_factors, size2)
A:torch.quantization._equalize.inverse_scaling_factors->torch.reshape(inverse_scaling_factors, size1)
A:torch.quantization._equalize.size1[output_axis]->weight1.size(output_axis)
A:torch.quantization._equalize.size2[input_axis]->weight2.size(input_axis)
A:torch.quantization._equalize.module1.weight->torch.nn.Parameter(weight1)
A:torch.quantization._equalize.module1.bias->torch.nn.Parameter(bias)
A:torch.quantization._equalize.module2.weight->torch.nn.Parameter(weight2)
A:torch.quantization._equalize.model->copy.deepcopy(model)
A:torch.quantization._equalize.previous_name_to_module[pair[0]]->copy.deepcopy(name_to_module[pair[0]])
A:torch.quantization._equalize.previous_name_to_module[pair[1]]->copy.deepcopy(name_to_module[pair[1]])
A:torch.quantization._equalize.summed_norms->torch.tensor(0.0)
A:torch.quantization._equalize.difference->curr_modules[name].weight.sub(prev_modules[name].weight)
torch.quantization._equalize.channel_range(input,axis=0)
torch.quantization._equalize.converged(curr_modules,prev_modules,threshold=0.0001)
torch.quantization._equalize.cross_layer_equalization(module1,module2,output_axis=0,input_axis=1)
torch.quantization._equalize.equalize(model,paired_modules_list,threshold=0.0001,inplace=True)
torch.quantization._equalize.max_over_ndim(input,axis_list,keepdim=False)
torch.quantization._equalize.min_over_ndim(input,axis_list,keepdim=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/quantization_mappings.py----------------------------------------
A:torch.quantization.quantization_mappings.static_quant_module_class->STATIC_QUANT_MODULE_MAPPINGS.get(float_module_class, None)
A:torch.quantization.quantization_mappings.quantized_op->FLOAT_TO_QUANTIZED_OPERATOR_MAPPINGS.get(float_op, None)
torch.quantization.get_compare_output_module_list()
torch.quantization.get_dynamic_quant_module_mappings()
torch.quantization.get_qat_module_mappings()
torch.quantization.get_qconfig_propagation_list()
torch.quantization.get_quantized_operator(float_op)
torch.quantization.get_static_quant_module_class(float_module_class)
torch.quantization.get_static_quant_module_mappings()
torch.quantization.quantization_mappings.get_compare_output_module_list()
torch.quantization.quantization_mappings.get_dynamic_quant_module_mappings()
torch.quantization.quantization_mappings.get_qat_module_mappings()
torch.quantization.quantization_mappings.get_qconfig_propagation_list()
torch.quantization.quantization_mappings.get_quantized_operator(float_op)
torch.quantization.quantization_mappings.get_static_quant_module_class(float_module_class)
torch.quantization.quantization_mappings.get_static_quant_module_mappings()
torch.quantization.quantization_mappings.register_dynamic_quant_module_class(float_source_module_class,dynamic_quant_target_module_class)
torch.quantization.quantization_mappings.register_qat_module_mapping(float_source_module_class,qat_target_module_class)
torch.quantization.quantization_mappings.register_quantized_operator_mapping(float_op,quantized_op)
torch.quantization.quantization_mappings.register_static_quant_module_mapping(float_source_module_class,static_quant_target_module_class)
torch.quantization.register_dynamic_quant_module_class(float_source_module_class,dynamic_quant_target_module_class)
torch.quantization.register_qat_module_mapping(float_source_module_class,qat_target_module_class)
torch.quantization.register_quantized_operator_mapping(float_op,quantized_op)
torch.quantization.register_static_quant_module_mapping(float_source_module_class,static_quant_target_module_class)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/_numeric_suite.py----------------------------------------
A:torch.quantization._numeric_suite.split_str->key.split('.')
A:torch.quantization._numeric_suite.match_string->''.join(key_str.split('.')[0:-2])
A:torch.quantization._numeric_suite.pattern1->''.join(s2.split('.')[0:-1])
A:torch.quantization._numeric_suite.pattern2->''.join(s2.split('.')[0:-2])
A:torch.quantization._numeric_suite.match_key->_find_match(sorted(float_dict, reverse=True), key, 'stats')
A:torch.quantization._numeric_suite.module_name->'.'.join(split_str[:-3])
A:torch.quantization._numeric_suite.self.stats['quantized']->torch.cat((self.stats['quantized'], x.detach()))
A:torch.quantization._numeric_suite.self.stats['float']->torch.cat((self.stats['float'], y.detach()))
A:torch.quantization._numeric_suite.self.stats['tensor_val']->torch.cat((self.stats['tensor_val'], x))
A:torch.quantization._numeric_suite.self.dequant->torch.nn.quantized.DeQuantize()
A:torch.quantization._numeric_suite.self.logger->Logger()
A:torch.quantization._numeric_suite.xl->_convert_tuple_to_list(x)
A:torch.quantization._numeric_suite.output->self.orig_module.add_relu(x, y)
A:torch.quantization._numeric_suite.xl_float->_dequantize_tensor_list(xl)
A:torch.quantization._numeric_suite.shadow_output->self.shadow_module.add_relu(x, y)
A:torch.quantization._numeric_suite.x->x.dequantize().dequantize()
A:torch.quantization._numeric_suite.y->y.dequantize().dequantize()
A:torch.quantization._numeric_suite.reassign[name]->Shadow(mod, float_mod, Logger)
A:torch.quantization._numeric_suite.ob_dict->get_logger_dict(q_model)
A:torch.quantization._numeric_suite.float_dict->get_logger_dict(float_module)
A:torch.quantization._numeric_suite.quantized_dict->get_logger_dict(q_module)
A:torch.quantization._numeric_suite.allow_list->get_compare_output_module_list()
A:torch.quantization._numeric_suite.qconfig_debug->torch.quantization.QConfig(activation=Logger, weight=None)
A:torch.quantization._numeric_suite.act_compare_dict->get_matching_activations(float_model, q_model)
torch.quantization._numeric_suite.Logger(self)
torch.quantization._numeric_suite.Logger.__init__(self)
torch.quantization._numeric_suite.Logger.forward(self,x)
torch.quantization._numeric_suite.OutputLogger(self)
torch.quantization._numeric_suite.OutputLogger.__init__(self)
torch.quantization._numeric_suite.OutputLogger.forward(self,x)
torch.quantization._numeric_suite.Shadow(self,q_module,float_module,Logger)
torch.quantization._numeric_suite.Shadow.__init__(self,q_module,float_module,Logger)
torch.quantization._numeric_suite.Shadow.add(self,x,y)
torch.quantization._numeric_suite.Shadow.add_relu(self,x,y)
torch.quantization._numeric_suite.Shadow.add_scalar(self,x,y)
torch.quantization._numeric_suite.Shadow.cat(self,x,dim=0)
torch.quantization._numeric_suite.Shadow.forward(self,*x)
torch.quantization._numeric_suite.Shadow.mul(self,x,y)
torch.quantization._numeric_suite.Shadow.mul_scalar(self,x,y)
torch.quantization._numeric_suite.ShadowLogger(self)
torch.quantization._numeric_suite.ShadowLogger.__init__(self)
torch.quantization._numeric_suite.ShadowLogger.forward(self,x,y)
torch.quantization._numeric_suite._convert_tuple_to_list(t)
torch.quantization._numeric_suite._dequantize_tensor_list(t)
torch.quantization._numeric_suite._find_match(str_list,key_str,postfix)
torch.quantization._numeric_suite._get_logger_dict_helper(mod,target_dict,prefix='')
torch.quantization._numeric_suite.compare_model_outputs(float_model,q_model,*data,Logger=OutputLogger,allow_list=None)
torch.quantization._numeric_suite.compare_model_stub(float_model,q_model,module_swap_list,*data,Logger=ShadowLogger)
torch.quantization._numeric_suite.compare_weights(float_dict,quantized_dict)
torch.quantization._numeric_suite.get_logger_dict(mod,prefix='')
torch.quantization._numeric_suite.get_matching_activations(float_module,q_module)
torch.quantization._numeric_suite.prepare_model_outputs(float_module,q_module,Logger=OutputLogger,allow_list=None)
torch.quantization._numeric_suite.prepare_model_with_stubs(float_module,q_module,module_swap_list,Logger)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/custom_module_class_mappings.py----------------------------------------
A:torch.quantization.custom_module_class_mappings.OBSERVED_CUSTOM_MODULE_CLASS_MAPPINGS->dict()
A:torch.quantization.custom_module_class_mappings.observed_custom_module_class->dict().get(float_custom_module_class, None)
A:torch.quantization.custom_module_class_mappings.QUANTIZED_CUSTOM_MODULE_CLASS_MAPPINGS->dict()
A:torch.quantization.custom_module_class_mappings.quantized_custom_module_class->dict().get(float_custom_module_class, None)
torch.quantization.custom_module_class_mappings.get_observed_custom_module_class(float_custom_module_class)
torch.quantization.custom_module_class_mappings.get_quantized_custom_module_class(float_custom_module_class)
torch.quantization.custom_module_class_mappings.is_custom_module_class(module_class)
torch.quantization.custom_module_class_mappings.is_observed_custom_module(module)
torch.quantization.custom_module_class_mappings.mark_observed_custom_module(module,custom_module_class)
torch.quantization.custom_module_class_mappings.register_observed_custom_module_mapping(float_custom_module_class,observed_custom_module_class)
torch.quantization.custom_module_class_mappings.register_quantized_custom_module_mapping(float_custom_module_class,quantized_custom_module_class)
torch.quantization.get_observed_custom_module_class(float_custom_module_class)
torch.quantization.get_quantized_custom_module_class(float_custom_module_class)
torch.quantization.is_custom_module_class(module_class)
torch.quantization.is_observed_custom_module(module)
torch.quantization.mark_observed_custom_module(module,custom_module_class)
torch.quantization.register_observed_custom_module_mapping(float_custom_module_class,observed_custom_module_class)
torch.quantization.register_quantized_custom_module_mapping(float_custom_module_class,quantized_custom_module_class)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fuse_modules.py----------------------------------------
A:torch.quantization.fuse_modules.tokens->submodule_key.split('.')
A:torch.quantization.fuse_modules.cur_mod->getattr(cur_mod, s)
A:torch.quantization.fuse_modules.types->tuple((type(m) for m in mod_list))
A:torch.quantization.fuse_modules.fuser_method->get_fuser_method(types)
A:torch.quantization.fuse_modules.fused->fuser_method(*mod_list)
A:torch.quantization.fuse_modules.identity->torch.nn.Identity()
A:torch.quantization.fuse_modules.new_mod_list->fuser_func(mod_list)
A:torch.quantization.fuse_modules.model->copy.deepcopy(model)
torch.quantization.fuse_modules(model,modules_to_fuse,inplace=False,fuser_func=fuse_known_modules)
torch.quantization.fuse_modules._fuse_modules(model,modules_to_fuse,fuser_func=fuse_known_modules)
torch.quantization.fuse_modules._get_module(model,submodule_key)
torch.quantization.fuse_modules._set_module(model,submodule_key,module)
torch.quantization.fuse_modules.fuse_known_modules(mod_list)
torch.quantization.fuse_modules.fuse_modules(model,modules_to_fuse,inplace=False,fuser_func=fuse_known_modules)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/default_mappings.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/observer.py----------------------------------------
A:torch.quantization.observer.r->_PartialWrapper(partial(cls_or_self, **kwargs))
A:torch.quantization.observer.ABC->ABCMeta(str('ABC'), (object,), {})
A:torch.quantization.observer.with_args->classmethod(_with_args)
A:torch.quantization.observer.version->local_metadata.get('version', None)
A:torch.quantization.observer.eps->torch.tensor([torch.finfo(torch.float32).eps])
A:torch.quantization.observer.(quant_min, quant_max)->self._calculate_qmin_qmax()
A:torch.quantization.observer.min_val_neg->torch.min(min_val, torch.zeros_like(min_val))
A:torch.quantization.observer.max_val_pos->torch.max(-min_val_neg, max_val_pos)
A:torch.quantization.observer.scale->torch.tensor(0.1).to(dtype=torch.float)
A:torch.quantization.observer.zero_point->torch.tensor([float(zero_point)], dtype=zero_point.dtype, device=device)
A:torch.quantization.observer.x->x_orig.detach()
A:torch.quantization.observer.(min_val_cur, max_val_cur)->torch._aminmax(x)
A:torch.quantization.observer.min_val->torch.min(min_val, torch.tensor(0.0).to(dtype=torch.float))
A:torch.quantization.observer.max_val->torch.max(max_val, torch.tensor(0.0).to(dtype=torch.float))
A:torch.quantization.observer.(min_val, max_val)->torch._aminmax(x)
A:torch.quantization.observer.nudged_zero_point->int(initial_zero_point.round())
A:torch.quantization.observer.x_dim->x_orig.detach().size()
A:torch.quantization.observer.y->torch.flatten(y, start_dim=1)
A:torch.quantization.observer.(min_vals, max_vals)->torch._aminmax(y, 1)
A:torch.quantization.observer.(min_vals_cur, max_vals_cur)->torch._aminmax(y, 1)
A:torch.quantization.observer.min_vals->torch.min(min_vals_cur, min_vals)
A:torch.quantization.observer.max_vals->torch.max(max_vals_cur, max_vals)
A:torch.quantization.observer.src_bin->torch.arange(self.bins)
A:torch.quantization.observer.dst_bin_of_begin->torch.clamp(src_bin_begin // dst_bin_width, 0, self.dst_nbins - 1)
A:torch.quantization.observer.dst_bin_of_end->torch.clamp(src_bin_end // dst_bin_width, 0, self.dst_nbins - 1)
A:torch.quantization.observer.norm->_compute_quantization_error(next_start_bin, next_end_bin, 'L2')
A:torch.quantization.observer.total->sum(self.histogram)
A:torch.quantization.observer.cSum->torch.cumsum(self.histogram, dim=0)
A:torch.quantization.observer.norm_min->float('inf')
A:torch.quantization.observer.downsample_rate->torch.ceil((combined_max - combined_min) / (self.bins * hist_bin_width)).to(torch.int).item()
A:torch.quantization.observer.start_idx->torch.round((self.min_val - combined_min) / hist_bin_width).to(torch.int).item()
A:torch.quantization.observer.upsampled_histogram->new_hist.repeat_interleave(upsample_rate)
A:torch.quantization.observer.histogram_with_output_range->torch.zeros(Nbins * downsample_rate, device=orig_hist.device)
A:torch.quantization.observer.shifted_integral_histogram->torch.zeros(Nbins, device=orig_hist.device)
A:torch.quantization.observer.(new_min, new_max)->self._non_linear_param_search()
A:torch.quantization.observer.combined_min->torch.min(new_min, min_val)
A:torch.quantization.observer.combined_max->torch.max(new_max, max_val)
A:torch.quantization.observer.(combined_min, combined_max, downsample_rate, start_idx)->self._adjust_min_max(combined_min, combined_max, self.upsample_rate)
A:torch.quantization.observer.combined_histogram->self._combine_histograms(combined_histogram, self.histogram, self.upsample_rate, downsample_rate, start_idx, self.bins)
A:torch.quantization.observer.state_dict[min_val_name]->torch.tensor(float('inf'))
A:torch.quantization.observer.state_dict[max_val_name]->torch.tensor(float('-inf'))
A:torch.quantization.observer.name->re.sub('\\.___torch_mangle_\\d+', '', suffix)
A:torch.quantization.observer.od->OrderedDict()
A:torch.quantization.observer.default_observer->MinMaxObserver.with_args(reduce_range=True)
A:torch.quantization.observer.default_weight_observer->MinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_tensor_symmetric)
A:torch.quantization.observer.default_histogram_observer->HistogramObserver.with_args(reduce_range=True)
A:torch.quantization.observer.default_per_channel_weight_observer->PerChannelMinMaxObserver.with_args(dtype=torch.qint8, qscheme=torch.per_channel_symmetric)
A:torch.quantization.observer.default_float_qparams_observer->PerChannelMinMaxObserver.with_args(dtype=torch.quint8, qscheme=torch.per_channel_affine_float_qparams, ch_axis=0)
torch.quantization.HistogramObserver(self,bins=2048,upsample_rate=128,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)
torch.quantization.HistogramObserver._adjust_min_max(self,combined_min,combined_max,upsample_rate)
torch.quantization.HistogramObserver._combine_histograms(self,orig_hist,new_hist,upsample_rate,downsample_rate,start_idx,Nbins)
torch.quantization.HistogramObserver._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization.HistogramObserver._non_linear_param_search(self)
torch.quantization.HistogramObserver._save_to_state_dict(self,destination,prefix,keep_vars)
torch.quantization.HistogramObserver.calculate_qparams(self)
torch.quantization.HistogramObserver.forward(self,x_orig)
torch.quantization.MinMaxDynamicQuantObserver(MinMaxObserver)
torch.quantization.MinMaxDynamicQuantObserver.calculate_qparams(self)
torch.quantization.MinMaxObserver(self,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.MinMaxObserver.calculate_qparams(self)
torch.quantization.MinMaxObserver.extra_repr(self)
torch.quantization.MinMaxObserver.forward(self,x_orig)
torch.quantization.MovingAverageMinMaxObserver(self,averaging_constant=0.01,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.MovingAverageMinMaxObserver.forward(self,x_orig)
torch.quantization.MovingAveragePerChannelMinMaxObserver(self,averaging_constant=0.01,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.MovingAveragePerChannelMinMaxObserver.forward(self,x_orig)
torch.quantization.NoopObserver(self,dtype=torch.float16,custom_op_name='')
torch.quantization.NoopObserver.calculate_qparams(self)
torch.quantization.NoopObserver.forward(self,x)
torch.quantization.ObserverBase(self,dtype)
torch.quantization.ObserverBase.calculate_qparams(self,**kwargs)
torch.quantization.ObserverBase.forward(self,x)
torch.quantization.PerChannelMinMaxObserver(self,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.PerChannelMinMaxObserver._forward(self,x_orig)
torch.quantization.PerChannelMinMaxObserver._load_from_state_dict(self,state_dict:Union[Dict[str,torch.Tensor],Dict[str,torch.Tensor]],prefix:str,local_metadata:Dict[str,torch.Tensor],strict:bool,missing_keys:List[str],unexpected_keys:List[str],error_msgs:List[str])
torch.quantization.PerChannelMinMaxObserver._load_from_state_dict_script(self,state_dict:Union[Dict[str,torch.Tensor],Dict[str,torch.Tensor]],prefix:str,local_metadata:Dict[str,torch.Tensor],strict:bool,missing_keys:List[str],unexpected_keys:List[str],error_msgs:List[str])
torch.quantization.PerChannelMinMaxObserver.calculate_qparams(self)
torch.quantization.PerChannelMinMaxObserver.extra_repr(self)
torch.quantization.PerChannelMinMaxObserver.forward(self,x_orig)
torch.quantization.PlaceholderObserver(self,dtype=torch.float16,custom_op_name='')
torch.quantization.PlaceholderObserver.calculate_qparams(self)
torch.quantization.PlaceholderObserver.forward(self,x)
torch.quantization.RecordingObserver(self,**kwargs)
torch.quantization.RecordingObserver.calculate_qparams(self)
torch.quantization.RecordingObserver.forward(self,x)
torch.quantization.RecordingObserver.get_tensor_value(self)
torch.quantization._ObserverBase(self,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization._ObserverBase._calculate_qmin_qmax(self)
torch.quantization._ObserverBase._calculate_qparams(self,min_val,max_val)
torch.quantization._ObserverBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization._ObserverBase._validate_qmin_qmax(self,quant_min,quant_max)
torch.quantization._is_activation_post_process(module)
torch.quantization._is_observer_script_module(mod,obs_type_name)
torch.quantization._is_per_channel_script_obs_instance(module)
torch.quantization._with_args(cls_or_self,**kwargs)
torch.quantization.get_observer_state_dict(mod)
torch.quantization.load_observer_state_dict(mod,obs_dict)
torch.quantization.observer.HistogramObserver(self,bins=2048,upsample_rate=128,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)
torch.quantization.observer.HistogramObserver.__init__(self,bins=2048,upsample_rate=128,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False)
torch.quantization.observer.HistogramObserver._adjust_min_max(self,combined_min,combined_max,upsample_rate)
torch.quantization.observer.HistogramObserver._combine_histograms(self,orig_hist,new_hist,upsample_rate,downsample_rate,start_idx,Nbins)
torch.quantization.observer.HistogramObserver._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization.observer.HistogramObserver._non_linear_param_search(self)
torch.quantization.observer.HistogramObserver._save_to_state_dict(self,destination,prefix,keep_vars)
torch.quantization.observer.HistogramObserver.calculate_qparams(self)
torch.quantization.observer.HistogramObserver.forward(self,x_orig)
torch.quantization.observer.MinMaxDynamicQuantObserver(MinMaxObserver)
torch.quantization.observer.MinMaxDynamicQuantObserver.calculate_qparams(self)
torch.quantization.observer.MinMaxObserver(self,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.MinMaxObserver.__init__(self,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.MinMaxObserver.calculate_qparams(self)
torch.quantization.observer.MinMaxObserver.extra_repr(self)
torch.quantization.observer.MinMaxObserver.forward(self,x_orig)
torch.quantization.observer.MovingAverageMinMaxObserver(self,averaging_constant=0.01,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.MovingAverageMinMaxObserver.__init__(self,averaging_constant=0.01,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.MovingAverageMinMaxObserver.forward(self,x_orig)
torch.quantization.observer.MovingAveragePerChannelMinMaxObserver(self,averaging_constant=0.01,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.MovingAveragePerChannelMinMaxObserver.__init__(self,averaging_constant=0.01,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.MovingAveragePerChannelMinMaxObserver.forward(self,x_orig)
torch.quantization.observer.NoopObserver(self,dtype=torch.float16,custom_op_name='')
torch.quantization.observer.NoopObserver.__init__(self,dtype=torch.float16,custom_op_name='')
torch.quantization.observer.NoopObserver.calculate_qparams(self)
torch.quantization.observer.NoopObserver.forward(self,x)
torch.quantization.observer.ObserverBase(self,dtype)
torch.quantization.observer.ObserverBase.__init__(self,dtype)
torch.quantization.observer.ObserverBase.calculate_qparams(self,**kwargs)
torch.quantization.observer.ObserverBase.forward(self,x)
torch.quantization.observer.PerChannelMinMaxObserver(self,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.PerChannelMinMaxObserver.__init__(self,ch_axis=0,dtype=torch.quint8,qscheme=torch.per_channel_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer.PerChannelMinMaxObserver._forward(self,x_orig)
torch.quantization.observer.PerChannelMinMaxObserver._load_from_state_dict(self,state_dict:Union[Dict[str,torch.Tensor],Dict[str,torch.Tensor]],prefix:str,local_metadata:Dict[str,torch.Tensor],strict:bool,missing_keys:List[str],unexpected_keys:List[str],error_msgs:List[str])
torch.quantization.observer.PerChannelMinMaxObserver._load_from_state_dict_script(self,state_dict:Union[Dict[str,torch.Tensor],Dict[str,torch.Tensor]],prefix:str,local_metadata:Dict[str,torch.Tensor],strict:bool,missing_keys:List[str],unexpected_keys:List[str],error_msgs:List[str])
torch.quantization.observer.PerChannelMinMaxObserver.calculate_qparams(self)
torch.quantization.observer.PerChannelMinMaxObserver.extra_repr(self)
torch.quantization.observer.PerChannelMinMaxObserver.forward(self,x_orig)
torch.quantization.observer.PlaceholderObserver(self,dtype=torch.float16,custom_op_name='')
torch.quantization.observer.PlaceholderObserver.__init__(self,dtype=torch.float16,custom_op_name='')
torch.quantization.observer.PlaceholderObserver.calculate_qparams(self)
torch.quantization.observer.PlaceholderObserver.forward(self,x)
torch.quantization.observer.RecordingObserver(self,**kwargs)
torch.quantization.observer.RecordingObserver.__init__(self,**kwargs)
torch.quantization.observer.RecordingObserver.calculate_qparams(self)
torch.quantization.observer.RecordingObserver.forward(self,x)
torch.quantization.observer.RecordingObserver.get_tensor_value(self)
torch.quantization.observer._ObserverBase(self,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer._ObserverBase.__init__(self,dtype=torch.quint8,qscheme=torch.per_tensor_affine,reduce_range=False,quant_min=None,quant_max=None)
torch.quantization.observer._ObserverBase._calculate_qmin_qmax(self)
torch.quantization.observer._ObserverBase._calculate_qparams(self,min_val,max_val)
torch.quantization.observer._ObserverBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization.observer._ObserverBase._validate_qmin_qmax(self,quant_min,quant_max)
torch.quantization.observer._is_activation_post_process(module)
torch.quantization.observer._is_observer_script_module(mod,obs_type_name)
torch.quantization.observer._is_per_channel_script_obs_instance(module)
torch.quantization.observer._with_args(cls_or_self,**kwargs)
torch.quantization.observer.get_observer_state_dict(mod)
torch.quantization.observer.load_observer_state_dict(mod,obs_dict)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/quantize_jit.py----------------------------------------
A:torch.quantization.quantize_jit.model_c->torch._C._jit_pass_quant_finalize(model_c, quant_type, preserved_attrs)
A:torch.quantization.quantize_jit.model->convert_jit(model, True, debug)
A:torch.quantization.quantize_jit.scripted_qconfig_dict->script_qconfig_dict(qconfig_dict)
torch.quantization._check_forward_method(model)
torch.quantization._check_is_script_module(model)
torch.quantization._convert_jit(model,inplace=False,debug=False,quant_type=QuantType.STATIC,preserved_attrs=None)
torch.quantization._prepare_jit(model,qconfig_dict,inplace=False,quant_type=QuantType.STATIC)
torch.quantization._quantize_jit(model,qconfig_dict,run_fn=None,run_args=None,inplace=False,debug=False,quant_type=QuantType.STATIC)
torch.quantization.convert_dynamic_jit(model,inplace=False,debug=False,preserved_attrs=None)
torch.quantization.convert_jit(model,inplace=False,debug=False,preserved_attrs=None)
torch.quantization.fuse_conv_bn_jit(model,inplace=False)
torch.quantization.prepare_dynamic_jit(model,qconfig_dict,inplace=False)
torch.quantization.prepare_jit(model,qconfig_dict,inplace=False)
torch.quantization.quantize_dynamic_jit(model,qconfig_dict,inplace=False,debug=False)
torch.quantization.quantize_jit(model,qconfig_dict,run_fn,run_args,inplace=False,debug=False)
torch.quantization.quantize_jit._check_forward_method(model)
torch.quantization.quantize_jit._check_is_script_module(model)
torch.quantization.quantize_jit._convert_jit(model,inplace=False,debug=False,quant_type=QuantType.STATIC,preserved_attrs=None)
torch.quantization.quantize_jit._prepare_jit(model,qconfig_dict,inplace=False,quant_type=QuantType.STATIC)
torch.quantization.quantize_jit._quantize_jit(model,qconfig_dict,run_fn=None,run_args=None,inplace=False,debug=False,quant_type=QuantType.STATIC)
torch.quantization.quantize_jit.convert_dynamic_jit(model,inplace=False,debug=False,preserved_attrs=None)
torch.quantization.quantize_jit.convert_jit(model,inplace=False,debug=False,preserved_attrs=None)
torch.quantization.quantize_jit.fuse_conv_bn_jit(model,inplace=False)
torch.quantization.quantize_jit.prepare_dynamic_jit(model,qconfig_dict,inplace=False)
torch.quantization.quantize_jit.prepare_jit(model,qconfig_dict,inplace=False)
torch.quantization.quantize_jit.quantize_dynamic_jit(model,qconfig_dict,inplace=False,debug=False)
torch.quantization.quantize_jit.quantize_jit(model,qconfig_dict,run_fn,run_args,inplace=False,debug=False)
torch.quantization.quantize_jit.script_qconfig(qconfig)
torch.quantization.quantize_jit.script_qconfig_dict(qconfig_dict)
torch.quantization.script_qconfig(qconfig)
torch.quantization.script_qconfig_dict(qconfig_dict)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/qconfig.py----------------------------------------
A:torch.quantization.qconfig.default_qconfig->QConfig(activation=default_observer, weight=default_weight_observer)
A:torch.quantization.qconfig.default_debug_qconfig->QConfig(weight=default_weight_observer, activation=default_debug_observer)
A:torch.quantization.qconfig.default_per_channel_qconfig->QConfig(activation=default_observer, weight=default_per_channel_weight_observer)
A:torch.quantization.qconfig.default_dynamic_qconfig->QConfigDynamic(activation=default_dynamic_quant_observer, weight=default_weight_observer)
A:torch.quantization.qconfig.float16_dynamic_qconfig->QConfigDynamic(activation=PlaceholderObserver.with_args(dtype=torch.float16), weight=PlaceholderObserver.with_args(dtype=torch.float16))
A:torch.quantization.qconfig.per_channel_dynamic_qconfig->QConfigDynamic(activation=default_dynamic_quant_observer, weight=default_per_channel_weight_observer)
A:torch.quantization.qconfig.float_qparams_dynamic_qconfig->QConfigDynamic(activation=default_dynamic_quant_observer, weight=default_float_qparams_observer)
A:torch.quantization.qconfig.default_qat_qconfig->QConfig(activation=default_fake_quant, weight=default_weight_fake_quant)
A:torch.quantization.qconfig.default_weight_only_qconfig->QConfig(activation=torch.nn.Identity, weight=default_weight_fake_quant)
A:torch.quantization.qconfig.default_activation_only_qconfig->QConfig(activation=default_fake_quant, weight=torch.nn.Identity)
A:torch.quantization.qconfig.qconfig->QConfig(activation=FakeQuantize.with_args(observer=MovingAverageMinMaxObserver, quant_min=0, quant_max=255, reduce_range=False), weight=default_weight_fake_quant)
torch.quantization.QConfig(cls,activation,weight)
torch.quantization.QConfigDynamic(cls,activation=torch.nn.Identity,weight=torch.nn.Identity)
torch.quantization.get_default_qat_qconfig(backend='fbgemm')
torch.quantization.get_default_qconfig(backend='fbgemm')
torch.quantization.qconfig.QConfig(cls,activation,weight)
torch.quantization.qconfig.QConfig.__new__(cls,activation,weight)
torch.quantization.qconfig.QConfigDynamic(cls,activation=torch.nn.Identity,weight=torch.nn.Identity)
torch.quantization.qconfig.QConfigDynamic.__new__(cls,activation=torch.nn.Identity,weight=torch.nn.Identity)
torch.quantization.qconfig.get_default_qat_qconfig(backend='fbgemm')
torch.quantization.qconfig.get_default_qconfig(backend='fbgemm')


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/_learnable_fake_quantize.py----------------------------------------
A:torch.quantization._learnable_fake_quantize.scale_remasked->scale.reshape(axis_mask)
A:torch.quantization._learnable_fake_quantize.zp_remasked->zp.reshape(axis_mask)
A:torch.quantization._learnable_fake_quantize.dX->_calculate_X_grad(dY, X_q, q_min, q_max).to(device)
A:torch.quantization._learnable_fake_quantize.indicate_small_scale->(X_q == q_min).float().to(device)
A:torch.quantization._learnable_fake_quantize.indicate_big_scale->(X_q == q_max).float().to(device)
A:torch.quantization._learnable_fake_quantize.indicate_saturate_zp->((X_q == q_min).float() + (X_q == q_max).float()).to(device)
A:torch.quantization._learnable_fake_quantize.scale_val->float(scale.item())
A:torch.quantization._learnable_fake_quantize.zp_val->int((zero_point + 0.5).clamp(q_min, q_max).item())
A:torch.quantization._learnable_fake_quantize.X_fq->torch.fake_quantize_per_channel_affine(X, scale_vec, zp_vec, ch_axis, q_min, q_max)
A:torch.quantization._learnable_fake_quantize.dY->dY.to(device).to(device)
A:torch.quantization._learnable_fake_quantize.zero_point->int((zero_point + 0.5).clamp(q_min, q_max).item())
A:torch.quantization._learnable_fake_quantize.X_q->X_q.clamp(q_min, q_max).clamp(q_min, q_max)
A:torch.quantization._learnable_fake_quantize.dScale->_calculate_scale_grad(dY, X, X_fq, X_q, scale_vec, zp_vec, q_min, q_max, device).sum(axis_for_reduction)
A:torch.quantization._learnable_fake_quantize.dZeroPoint->_calculate_zero_point_grad(dY, X, X_fq, X_q, scale_vec, zp_vec, q_min, q_max, device).sum(axis_for_reduction)
A:torch.quantization._learnable_fake_quantize.scale_vec->scale_vec.reshape(axis_mask).to(device).reshape(axis_mask).to(device)
A:torch.quantization._learnable_fake_quantize.zp_vec->zp_vec.reshape(axis_mask).to(device).reshape(axis_mask).to(device)
A:torch.quantization._learnable_fake_quantize.axis_for_reduction->tuple(axis_for_reduction)
A:torch.quantization._learnable_fake_quantize.self.scale->Parameter(torch.tensor([scale] * channel_len))
A:torch.quantization._learnable_fake_quantize.self.zero_point->Parameter(torch.tensor([zero_point] * channel_len))
A:torch.quantization._learnable_fake_quantize.self.activation_post_process->observer(**observer_kwargs)
A:torch.quantization._learnable_fake_quantize.bitrange->torch.tensor(quant_max - quant_min + 1).double()
A:torch.quantization._learnable_fake_quantize.self.bitwidth->int(torch.log2(bitrange).item())
A:torch.quantization._learnable_fake_quantize.self.static_enabled[0]->int(enabled)
A:torch.quantization._learnable_fake_quantize.self.learning_enabled[0]->int(enabled)
A:torch.quantization._learnable_fake_quantize.self.fake_quant_enabled[0]->int(enabled)
A:torch.quantization._learnable_fake_quantize.(_scale, _zero_point)->self.calculate_qparams()
A:torch.quantization._learnable_fake_quantize._scale->_scale.to(self.scale.device).to(self.scale.device)
A:torch.quantization._learnable_fake_quantize._zero_point->_zero_point.to(self.zero_point.device).to(self.zero_point.device)
A:torch.quantization._learnable_fake_quantize.X->torch.fake_quantize_per_tensor_affine(X, float(self.scale.item()), int(self.zero_point.item()), self.quant_min, self.quant_max)
A:torch.quantization._learnable_fake_quantize.with_args->classmethod(_with_args)
torch.quantization._learnable__LearnableFakeQuantize(self,observer,quant_min=0,quant_max=255,scale=1.0,zero_point=0.0,channel_len=-1,use_grad_scaling=False,**observer_kwargs)
torch.quantization._learnable__LearnableFakeQuantize._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization._learnable__LearnableFakeQuantize._save_to_state_dict(self,destination,prefix,keep_vars)
torch.quantization._learnable__LearnableFakeQuantize.calculate_qparams(self)
torch.quantization._learnable__LearnableFakeQuantize.enable_param_learning(self)
torch.quantization._learnable__LearnableFakeQuantize.enable_static_estimate(self)
torch.quantization._learnable__LearnableFakeQuantize.enable_static_observation(self)
torch.quantization._learnable__LearnableFakeQuantize.forward(self,X)
torch.quantization._learnable__LearnableFakeQuantize.observe_quant_params(self)
torch.quantization._learnable__LearnableFakeQuantize.toggle_fake_quant(self,enabled=True)
torch.quantization._learnable__LearnableFakeQuantize.toggle_observer_update(self,enabled=True)
torch.quantization._learnable__LearnableFakeQuantize.toggle_qparam_learning(self,enabled=True)
torch.quantization._learnable__LearnableFakeQuantizePerChannelOp(torch.autograd.Function)
torch.quantization._learnable__LearnableFakeQuantizePerChannelOp.backward(ctx,dY)
torch.quantization._learnable__LearnableFakeQuantizePerChannelOp.forward(ctx,X,scale,zero_point,ch_axis,q_min,q_max,grad_factor)
torch.quantization._learnable__LearnableFakeQuantizePerTensorOp(torch.autograd.Function)
torch.quantization._learnable__LearnableFakeQuantizePerTensorOp.backward(ctx,dY)
torch.quantization._learnable__LearnableFakeQuantizePerTensorOp.forward(ctx,X,scale,zero_point,q_min,q_max,grad_factor)
torch.quantization._learnable__calculate_X_grad(dY,Xq,q_min,q_max)
torch.quantization._learnable__calculate_scale_grad(dY,X,X_fq,X_q,scale,zero_point,q_min,q_max,device)
torch.quantization._learnable__calculate_zero_point_grad(dY,X,X_fq,X_q,scale,zero_point,q_min,q_max,device)
torch.quantization._learnable__quantize(x,scale,zp)
torch.quantization._learnable__quantize_vectorized(x,ch_axis,scale,zp)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize(self,observer,quant_min=0,quant_max=255,scale=1.0,zero_point=0.0,channel_len=-1,use_grad_scaling=False,**observer_kwargs)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.__init__(self,observer,quant_min=0,quant_max=255,scale=1.0,zero_point=0.0,channel_len=-1,use_grad_scaling=False,**observer_kwargs)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize._save_to_state_dict(self,destination,prefix,keep_vars)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.calculate_qparams(self)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.enable_param_learning(self)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.enable_static_estimate(self)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.enable_static_observation(self)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.forward(self,X)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.observe_quant_params(self)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.toggle_fake_quant(self,enabled=True)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.toggle_observer_update(self,enabled=True)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantize.toggle_qparam_learning(self,enabled=True)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantizePerChannelOp(torch.autograd.Function)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantizePerChannelOp.backward(ctx,dY)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantizePerChannelOp.forward(ctx,X,scale,zero_point,ch_axis,q_min,q_max,grad_factor)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantizePerTensorOp(torch.autograd.Function)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantizePerTensorOp.backward(ctx,dY)
torch.quantization._learnable_fake_quantize._LearnableFakeQuantizePerTensorOp.forward(ctx,X,scale,zero_point,q_min,q_max,grad_factor)
torch.quantization._learnable_fake_quantize._calculate_X_grad(dY,Xq,q_min,q_max)
torch.quantization._learnable_fake_quantize._calculate_scale_grad(dY,X,X_fq,X_q,scale,zero_point,q_min,q_max,device)
torch.quantization._learnable_fake_quantize._calculate_zero_point_grad(dY,X,X_fq,X_q,scale,zero_point,q_min,q_max,device)
torch.quantization._learnable_fake_quantize._quantize(x,scale,zp)
torch.quantization._learnable_fake_quantize._quantize_vectorized(x,ch_axis,scale,zp)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/_correct_bias.py----------------------------------------
A:torch.quantization._correct_bias.split_name->name.rsplit('.', 1)
A:torch.quantization._correct_bias.param->getattr(module, attr, None)
A:torch.quantization._correct_bias.x->x.dequantize().dequantize()
A:torch.quantization._correct_bias.quantized_submodule->get_module(quantized_model, uncorrected_module)
A:torch.quantization._correct_bias.bias->get_param(quantized_submodule, 'bias')
A:torch.quantization._correct_bias.ob_dict->torch.quantization._numeric_suite.get_logger_dict(quantized_model)
A:torch.quantization._correct_bias.(parent_name, _)->parent_child_names(uncorrected_module)
A:torch.quantization._correct_bias.dims->list(range(quantization_error.dim()))
A:torch.quantization._correct_bias.expected_error->torch.mean(quantization_error, dims)
torch.quantization._correct_bias.MeanShadowLogger(self)
torch.quantization._correct_bias.MeanShadowLogger.__init__(self)
torch.quantization._correct_bias.MeanShadowLogger.clear(self)
torch.quantization._correct_bias.MeanShadowLogger.forward(self,x,y)
torch.quantization._correct_bias.bias_correction(float_model,quantized_model,img_data,target_modules=_supported_modules_quantized,neval_batches=None)
torch.quantization._correct_bias.get_module(model,name)
torch.quantization._correct_bias.get_param(module,attr)
torch.quantization._correct_bias.parent_child_names(name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fake_quantize.py----------------------------------------
A:torch.quantization.fake_quantize.self.activation_post_process->observer(**observer_kwargs)
A:torch.quantization.fake_quantize.(_scale, _zero_point)->self.calculate_qparams()
A:torch.quantization.fake_quantize.X->torch.fake_quantize_per_tensor_affine(X, float(self.scale), int(self.zero_point), self.quant_min, self.quant_max)
A:torch.quantization.fake_quantize.with_args->classmethod(_with_args)
A:torch.quantization.fake_quantize.default_fake_quant->FakeQuantize.with_args(observer=MovingAverageMinMaxObserver, quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=True)
A:torch.quantization.fake_quantize.default_weight_fake_quant->FakeQuantize.with_args(observer=MovingAverageMinMaxObserver, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_tensor_symmetric, reduce_range=False)
A:torch.quantization.fake_quantize.default_per_channel_weight_fake_quant->FakeQuantize.with_args(observer=MovingAveragePerChannelMinMaxObserver, quant_min=-128, quant_max=127, dtype=torch.qint8, qscheme=torch.per_channel_symmetric, reduce_range=False, ch_axis=0)
A:torch.quantization.fake_quantize.default_histogram_fake_quant->FakeQuantize.with_args(observer=HistogramObserver, quant_min=0, quant_max=255, dtype=torch.quint8, qscheme=torch.per_tensor_affine, reduce_range=True)
A:torch.quantization.fake_quantize.name->re.sub('\\.___torch_mangle_\\d+', '', suffix)
torch.quantization.FakeQuantize(self,observer=MovingAverageMinMaxObserver,quant_min=0,quant_max=255,**observer_kwargs)
torch.quantization.FakeQuantize._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization.FakeQuantize._save_to_state_dict(self,destination,prefix,keep_vars)
torch.quantization.FakeQuantize.calculate_qparams(self)
torch.quantization.FakeQuantize.disable_fake_quant(self)
torch.quantization.FakeQuantize.disable_observer(self)
torch.quantization.FakeQuantize.enable_fake_quant(self,enabled=True)
torch.quantization.FakeQuantize.enable_observer(self,enabled=True)
torch.quantization.FakeQuantize.extra_repr(self)
torch.quantization.FakeQuantize.forward(self,X)
torch.quantization._is_fake_quant_script_module(mod)
torch.quantization.disable_fake_quant(mod)
torch.quantization.disable_observer(mod)
torch.quantization.enable_fake_quant(mod)
torch.quantization.enable_observer(mod)
torch.quantization.fake_quantize.FakeQuantize(self,observer=MovingAverageMinMaxObserver,quant_min=0,quant_max=255,**observer_kwargs)
torch.quantization.fake_quantize.FakeQuantize.__init__(self,observer=MovingAverageMinMaxObserver,quant_min=0,quant_max=255,**observer_kwargs)
torch.quantization.fake_quantize.FakeQuantize._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.quantization.fake_quantize.FakeQuantize._save_to_state_dict(self,destination,prefix,keep_vars)
torch.quantization.fake_quantize.FakeQuantize.calculate_qparams(self)
torch.quantization.fake_quantize.FakeQuantize.disable_fake_quant(self)
torch.quantization.fake_quantize.FakeQuantize.disable_observer(self)
torch.quantization.fake_quantize.FakeQuantize.enable_fake_quant(self,enabled=True)
torch.quantization.fake_quantize.FakeQuantize.enable_observer(self,enabled=True)
torch.quantization.fake_quantize.FakeQuantize.extra_repr(self)
torch.quantization.fake_quantize.FakeQuantize.forward(self,X)
torch.quantization.fake_quantize._is_fake_quant_script_module(mod)
torch.quantization.fake_quantize.disable_fake_quant(mod)
torch.quantization.fake_quantize.disable_observer(mod)
torch.quantization.fake_quantize.enable_fake_quant(mod)
torch.quantization.fake_quantize.enable_observer(mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fuser_method_mappings.py----------------------------------------
A:torch.quantization.fuser_method_mappings.is_3d->isinstance(conv, nn.Conv3d)
A:torch.quantization.fuser_method_mappings.fused_module->map_to_fused_module_train.get(type(conv))
A:torch.quantization.fuser_method_mappings.fused_conv->torch.nn.utils.fusion.fuse_conv_bn_eval(conv, bn)
torch.quantization.fuse_conv_bn(conv,bn)
torch.quantization.fuse_conv_bn_relu(conv,bn,relu)
torch.quantization.fuser_method_mappings.fuse_conv_bn(conv,bn)
torch.quantization.fuser_method_mappings.fuse_conv_bn_relu(conv,bn,relu)
torch.quantization.fuser_method_mappings.get_fuser_method(op_list)
torch.quantization.fuser_method_mappings.register_fuser_method(op_list,fuser_method)
torch.quantization.get_fuser_method(op_list)
torch.quantization.register_fuser_method(op_list,fuser_method)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/quant_type.py----------------------------------------
torch.quantization.QuantType(enum.IntEnum)
torch.quantization.quant_type.QuantType(enum.IntEnum)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/__init__.py----------------------------------------
torch.quantization.__init__.default_eval_fn(model,calib_data)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/stubs.py----------------------------------------
A:torch.quantization.stubs.X->self.module(X)
torch.quantization.DeQuantStub(self)
torch.quantization.DeQuantStub.forward(self,x)
torch.quantization.QuantStub(self,qconfig=None)
torch.quantization.QuantStub.forward(self,x)
torch.quantization.QuantWrapper(self,module)
torch.quantization.QuantWrapper.forward(self,X)
torch.quantization.stubs.DeQuantStub(self)
torch.quantization.stubs.DeQuantStub.__init__(self)
torch.quantization.stubs.DeQuantStub.forward(self,x)
torch.quantization.stubs.QuantStub(self,qconfig=None)
torch.quantization.stubs.QuantStub.__init__(self,qconfig=None)
torch.quantization.stubs.QuantStub.forward(self,x)
torch.quantization.stubs.QuantWrapper(self,module)
torch.quantization.stubs.QuantWrapper.__init__(self,module)
torch.quantization.stubs.QuantWrapper.forward(self,X)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/quantize.py----------------------------------------
A:torch.quantization.quantize.allow_list->get_qconfig_propagation_list()
A:torch.quantization.quantize.module_qconfig->getattr(module, 'qconfig', module_qconfig)
A:torch.quantization.quantize.qconfig_propagation_list->get_qconfig_propagation_list()
A:torch.quantization.quantize.devices->get_unique_devices_(mod)
A:torch.quantization.quantize.activation->qconfig.activation()
A:torch.quantization.quantize.handle->register_activation_post_process_hook(m)
A:torch.quantization.quantize.child.activation_post_process->get_activation_post_process(child.qconfig, device)
A:torch.quantization.quantize.observed_child->get_observed_custom_module_class(type(child)).from_float(child)
A:torch.quantization.quantize.module._modules[name]->add_quant_dequant(child)
A:torch.quantization.quantize.model->copy.deepcopy(model)
A:torch.quantization.quantize.mapping->get_static_quant_module_mappings()
A:torch.quantization.quantize.qconfig_spec->dict(zip(qconfig_spec, itertools.repeat(default_qconfig)))
A:torch.quantization.quantize.module->copy.deepcopy(module)
A:torch.quantization.quantize.reassign[name]->swap_module(mod, mapping)
A:torch.quantization.quantize.new_mod->mapping[type(mod)].from_float(mod)
torch.quantization._convert(module,mapping=None,inplace=False)
torch.quantization._observer_forward_hook(self,input,output)
torch.quantization._observer_forward_pre_hook(self,input)
torch.quantization._propagate_qconfig_helper(module,qconfig_dict,allow_list=None,qconfig_parent=None,prefix='')
torch.quantization._remove_qconfig(module)
torch.quantization.add_observer_(module,qconfig_propagation_list=None,non_leaf_module_list=None,device=None,prehook=None)
torch.quantization.add_quant_dequant(module)
torch.quantization.convert(module,mapping=None,inplace=False,remove_qconfig=True)
torch.quantization.get_observer_dict(mod,target_dict,prefix='')
torch.quantization.get_unique_devices_(module)
torch.quantization.prepare(model,inplace=False,allow_list=None,observer_non_leaf_module_list=None,prehook=None)
torch.quantization.prepare_qat(model,mapping=None,inplace=False)
torch.quantization.propagate_qconfig_(module,qconfig_dict=None,allow_list=None)
torch.quantization.quantize(model,run_fn,run_args,mapping=None,inplace=False)
torch.quantization.quantize._convert(module,mapping=None,inplace=False)
torch.quantization.quantize._observer_forward_hook(self,input,output)
torch.quantization.quantize._observer_forward_pre_hook(self,input)
torch.quantization.quantize._propagate_qconfig_helper(module,qconfig_dict,allow_list=None,qconfig_parent=None,prefix='')
torch.quantization.quantize._remove_qconfig(module)
torch.quantization.quantize.add_observer_(module,qconfig_propagation_list=None,non_leaf_module_list=None,device=None,prehook=None)
torch.quantization.quantize.add_quant_dequant(module)
torch.quantization.quantize.convert(module,mapping=None,inplace=False,remove_qconfig=True)
torch.quantization.quantize.get_observer_dict(mod,target_dict,prefix='')
torch.quantization.quantize.get_unique_devices_(module)
torch.quantization.quantize.prepare(model,inplace=False,allow_list=None,observer_non_leaf_module_list=None,prehook=None)
torch.quantization.quantize.prepare_qat(model,mapping=None,inplace=False)
torch.quantization.quantize.propagate_qconfig_(module,qconfig_dict=None,allow_list=None)
torch.quantization.quantize.quantize(model,run_fn,run_args,mapping=None,inplace=False)
torch.quantization.quantize.quantize_dynamic(model,qconfig_spec=None,dtype=torch.qint8,mapping=None,inplace=False)
torch.quantization.quantize.quantize_qat(model,run_fn,run_args,inplace=False)
torch.quantization.quantize.register_activation_post_process_hook(module)
torch.quantization.quantize.swap_module(mod,mapping)
torch.quantization.quantize_dynamic(model,qconfig_spec=None,dtype=torch.qint8,mapping=None,inplace=False)
torch.quantization.quantize_qat(model,run_fn,run_args,inplace=False)
torch.quantization.register_activation_post_process_hook(module)
torch.quantization.swap_module(mod,mapping)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/quantize_fx.py----------------------------------------
A:torch.quantization.quantize_fx.fuser->Fuser()
A:torch.quantization.quantize_fx.graph_module->fuse_fx(graph_module, inplace)
A:torch.quantization.quantize_fx.quantizer->Quantizer()
A:torch.quantization.quantize_fx.prepared->prepare(graph_module, qconfig_dict, inplace=True)
A:torch.quantization.quantize_fx.model->convert_fx(model, inplace=True, debug=debug)
torch.quantization._check_is_graph_module(model)
torch.quantization._convert_fx(graph_module,inplace,debug,is_dynamic_quant)
torch.quantization._prepare_fx(graph_module,qconfig_dict,inplace,is_dynamic_quant)
torch.quantization._quantize_fx(model,qconfig_dict,run_fn=None,run_args=None,inplace=False,debug=False,is_dynamic_quant=False)
torch.quantization.convert_dynamic_fx(graph_module,inplace=False,debug=False)
torch.quantization.convert_fx(graph_module,inplace=False,debug=False)
torch.quantization.fuse_fx(graph_module,inplace=False)
torch.quantization.prepare_dynamic_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.prepare_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.prepare_qat_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.prepare_static_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.quantize_dynamic_fx(model,qconfig_dict,inplace=False,debug=False)
torch.quantization.quantize_fx._check_is_graph_module(model)
torch.quantization.quantize_fx._convert_fx(graph_module,inplace,debug,is_dynamic_quant)
torch.quantization.quantize_fx._prepare_fx(graph_module,qconfig_dict,inplace,is_dynamic_quant)
torch.quantization.quantize_fx._quantize_fx(model,qconfig_dict,run_fn=None,run_args=None,inplace=False,debug=False,is_dynamic_quant=False)
torch.quantization.quantize_fx.convert_dynamic_fx(graph_module,inplace=False,debug=False)
torch.quantization.quantize_fx.convert_fx(graph_module,inplace=False,debug=False)
torch.quantization.quantize_fx.fuse_fx(graph_module,inplace=False)
torch.quantization.quantize_fx.prepare_dynamic_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.quantize_fx.prepare_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.quantize_fx.prepare_qat_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.quantize_fx.prepare_static_fx(graph_module,qconfig_dict,inplace=False)
torch.quantization.quantize_fx.quantize_dynamic_fx(model,qconfig_dict,inplace=False,debug=False)
torch.quantization.quantize_fx.quantize_static_fx(model,qconfig_dict,run_fn,run_args,inplace=False,debug=False)
torch.quantization.quantize_static_fx(model,qconfig_dict,run_fn,run_args,inplace=False,debug=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/utils.py----------------------------------------
A:torch.quantization.fx.utils.r->target.replace('activation_post_process', 'obs').rsplit('.', 1)
A:torch.quantization.fx.utils.built_in_func_re->re.compile('<built-in function (.*)>')
A:torch.quantization.fx.utils.built_in_meth_re->re.compile('<built-in method (.*) of type.*>')
A:torch.quantization.fx.utils.max_lens[s]->len(s)
A:torch.quantization.fx.utils.name->name.replace('activation_post_process', 'obs').replace('activation_post_process', 'obs')
A:torch.quantization.fx.utils.op->str(n.op)
A:torch.quantization.fx.utils.target->target.replace('activation_post_process', 'obs').replace('activation_post_process', 'obs')
A:torch.quantization.fx.utils.built_in_func->re.compile('<built-in function (.*)>').search(target)
A:torch.quantization.fx.utils.built_in_meth->re.compile('<built-in method (.*) of type.*>').search(target)
A:torch.quantization.fx.utils.args->args.replace('activation_post_process', 'obs').replace('activation_post_process', 'obs')
A:torch.quantization.fx.utils.kwargs->str(n.kwargs)
A:torch.quantization.fx.utils.max_lens[k]->max(max_lens[k], len(v))
A:torch.quantization.fx.utils.(scale, zero_point)->activation_post_process.calculate_qparams()
A:torch.quantization.fx.utils.scale->float(scale)
A:torch.quantization.fx.utils.zero_point->int(zero_point)
A:torch.quantization.fx.utils.ch_axis->int(activation_post_process.ch_axis)
A:torch.quantization.fx.utils.(quantize_op, qparams)->get_quantize_op_and_qparams(activation_post_process)
A:torch.quantization.fx.utils.idx->get_next_qparams_idx(root_module, qparams)
torch.quantization.fx.utils._parent_name(target)
torch.quantization.fx.utils.get_per_tensor_qparams(activation_post_process)
torch.quantization.fx.utils.get_quantize_op_and_qparams(activation_post_process)
torch.quantization.fx.utils.graph_pretty_str(g,shorten=True)->str
torch.quantization.fx.utils.is_per_channel(qscheme)
torch.quantization.fx.utils.is_per_tensor(qscheme)
torch.quantization.fx.utils.quantize_node(root_module,graph,node,activation_post_process)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/fuse.py----------------------------------------
A:torch.quantization.fx.fuse.model->GraphModule(input_root, self.fused_graph)
A:torch.quantization.fx.fuse.self.modules->dict(input_root.named_modules())
A:torch.quantization.fx.fuse.fusion_patterns->get_fusion_patterns()
A:torch.quantization.fx.fuse.fusion_pairs->self._find_matches(input_root, input_graph, fusion_patterns)
A:torch.quantization.fx.fuse.self.fused_graph->Graph()
A:torch.quantization.fx.fuse.(root_node, obj)->self._find_matches(input_root, input_graph, fusion_patterns).get(node.name, (None, None))
A:torch.quantization.fx.fuse.env[node.name]->self.fused_graph.node_copy(node, load_arg)
A:torch.quantization.fx.fuse.modules->dict(root.named_modules())
torch.quantization.fx.Fuser
torch.quantization.fx.Fuser._find_matches(self,root,graph,patterns)
torch.quantization.fx.Fuser.fuse(self,model,inplace=False)
torch.quantization.fx.fuse.Fuser
torch.quantization.fx.fuse.Fuser._find_matches(self,root,graph,patterns)
torch.quantization.fx.fuse.Fuser.fuse(self,model,inplace=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/quantization_patterns.py----------------------------------------
A:torch.quantization.fx.quantization_patterns.self.all_nodes->all([isinstance(a, Node) for a in self.mul_node.args[:2]])
A:torch.quantization.fx.quantization_patterns.(scale, zero_point)->activation_post_process.calculate_qparams()
A:torch.quantization.fx.quantization_patterns.scale->float(scale)
A:torch.quantization.fx.quantization_patterns.zero_point->int(zero_point)
A:torch.quantization.fx.quantization_patterns.kwargs->load_arg(quantized=False)(self.linear_node.kwargs)
A:torch.quantization.fx.quantization_patterns.qconv_cls->get_static_quant_module_class(type(self.conv))
A:torch.quantization.fx.quantization_patterns.quantized->torch.nn.quantized.dynamic.Linear.from_float(self.linear)
A:torch.quantization.fx.quantization_patterns.(parent_name, name)->_parent_name(self.linear_node.target)
A:torch.quantization.fx.quantization_patterns.args->load_arg(quantized=False)(self.linear_node.args)
A:torch.quantization.fx.quantization_patterns.conv_out->quantizer.quantized_graph.create_node('call_function', torch.nn.functional.conv2d, args, kwargs)
A:torch.quantization.fx.quantization_patterns.weight->load_arg(quantized=True)(self.linear_node.args[1])
A:torch.quantization.fx.quantization_patterns.other_args->load_arg(quantized=False)(self.linear_node.args[2:])
A:torch.quantization.fx.quantization_patterns.prepack_args->tuple([weight] + list(other_args))
A:torch.quantization.fx.quantization_patterns.packed_weight->quantizer.quantized_graph.create_node('call_function', prepack_op, prepack_args, {})
A:torch.quantization.fx.quantization_patterns.conv_input->load_arg(quantized=True)(self.conv_node.args[0])
A:torch.quantization.fx.quantization_patterns.(scale, zero_point, _)->get_per_tensor_qparams(activation_post_process)
A:torch.quantization.fx.quantization_patterns.linear_out->quantizer.quantized_graph.create_node('call_function', torch.nn.functional.linear, args, kwargs)
A:torch.quantization.fx.quantization_patterns.bias->load_arg(quantized=False)(self.linear_node.args[2])
A:torch.quantization.fx.quantization_patterns.linear_input->load_arg(quantized=True)(self.linear_node.args[0])
A:torch.quantization.fx.quantization_patterns.qbn_cls->get_static_quant_module_class(type(self.bn))
A:torch.quantization.fx.quantization_patterns.quantized_module_cls->get_static_quant_module_class(type(module))
A:torch.quantization.fx.quantization_patterns.quantized_module->get_static_quant_module_class(type(module)).from_float(module)
A:torch.quantization.fx.quantization_patterns.quantized_op->get_quantized_operator(node.target)
A:torch.quantization.fx.quantization_patterns.quantized_custom_module_class->get_quantized_custom_module_class(observed_custom_module._FLOAT_MODULE)
A:torch.quantization.fx.quantization_patterns.quantized_custom_module->get_quantized_custom_module_class(observed_custom_module._FLOAT_MODULE).from_observed(observed_custom_module)
A:torch.quantization.fx.quantization_patterns.linear_weight->load_arg(quantized=True)(self.linear_node.args[1])
A:torch.quantization.fx.quantization_patterns.non_quantized_input->load_arg(quantized=False)(self.linear_node.args[0])
torch.quantization.fx.quantization_patterns.Add(self,quantizer,node)
torch.quantization.fx.quantization_patterns.Add.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.Add.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.BatchNorm(self,quantizer,node)
torch.quantization.fx.quantization_patterns.BatchNorm.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.BatchNorm.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.Cat(QuantizeHandler)
torch.quantization.fx.quantization_patterns.Cat.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.ConvRelu(self,quantizer,node)
torch.quantization.fx.quantization_patterns.ConvRelu.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.ConvRelu.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.CopyNode(QuantizeHandler)
torch.quantization.fx.quantization_patterns.CopyNode.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.CustomModuleQuantizeHandler(QuantizeHandler)
torch.quantization.fx.quantization_patterns.CustomModuleQuantizeHandler.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.DefaultNode(QuantizeHandler)
torch.quantization.fx.quantization_patterns.DefaultNode.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.DefaultQuant(QuantizeHandler)
torch.quantization.fx.quantization_patterns.DefaultQuant.convert(self,quantizer,node)
torch.quantization.fx.quantization_patterns.DynamicLinear(self,quantizer,node)
torch.quantization.fx.quantization_patterns.DynamicLinear.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.DynamicLinear.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.ELU(QuantizeHandler)
torch.quantization.fx.quantization_patterns.ELU.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.LinearReLU(self,quantizer,node)
torch.quantization.fx.quantization_patterns.LinearReLU.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.LinearReLU.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.Mul(self,quantizer,node)
torch.quantization.fx.quantization_patterns.Mul.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.Mul.convert(self,quantizer,node,load_arg,debug=False)
torch.quantization.fx.quantization_patterns.QuantizeHandler(self,quantizer,node)
torch.quantization.fx.quantization_patterns.QuantizeHandler.__init__(self,quantizer,node)
torch.quantization.fx.quantization_patterns.QuantizeHandler.convert(self,quantizer,node,load_arg,debug=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/quantize.py----------------------------------------
A:torch.quantization.fx.quantize.attr_name->get_attr_name(i)
A:torch.quantization.fx.quantize.node->frontier.pop()
A:torch.quantization.fx.quantize.graph->Graph()
A:torch.quantization.fx.quantize.env[producer_node]->Graph().node_copy(producer_node, load_arg)
A:torch.quantization.fx.quantize.graph_module->GraphModule(root, graph)
A:torch.quantization.fx.quantize.(parent_name, _)->_parent_name(name)
A:torch.quantization.fx.quantize.flattened->dict()
A:torch.quantization.fx.quantize.qconfig_dict[key]->OrderedDict(qconfig_dict.get(key, []))
A:torch.quantization.fx.quantize.global_qconfig->qconfig_dict.get('', None)
A:torch.quantization.fx.quantize.(parent, _)->_parent_name(module_name)
A:torch.quantization.fx.quantize.module_type_qconfig->get_module_type_qconfig(type(self.modules[module_name]))
A:torch.quantization.fx.quantize.module_name_regex_qconfig->get_module_name_regex_qconfig(module_name, module_type_qconfig)
A:torch.quantization.fx.quantize.module_name_qconfig->get_module_name_qconfig(module_name, module_name_regex_qconfig)
A:torch.quantization.fx.quantize.self.qconfig_map->dict()
A:torch.quantization.fx.quantize.(module_name, _)->_parent_name(node.target)
A:torch.quantization.fx.quantize.self.qconfig_map[node.name]->get_qconfig(module_name)
A:torch.quantization.fx.quantize.function_qconfig->get_function_qconfig(node.target)
A:torch.quantization.fx.quantize.module_qconfig->get_qconfig(node.target)
A:torch.quantization.fx.quantize.model->GraphModule(model, act_post_process_removed_graph)
A:torch.quantization.fx.quantize.self.patterns->get_quant_patterns()
A:torch.quantization.fx.quantize.flattened_qconfig_dict->get_flattened_qconfig_dict(qconfig_dict)
A:torch.quantization.fx.quantize.self.modules->dict(model.named_modules())
A:torch.quantization.fx.quantize.matches->self._find_matches(model.graph, self.modules, self.patterns)
A:torch.quantization.fx.quantize.quants->self._find_quants(model.graph, matches)
A:torch.quantization.fx.quantize.self.activation_post_process_map->dict()
A:torch.quantization.fx.quantize.observed_graph->Graph()
A:torch.quantization.fx.quantize.observed_node_names_set->set()
A:torch.quantization.fx.quantize.(root_node, _, obj, qconfig)->self._find_matches(model.graph, self.modules, self.patterns).get(node.name, (None, None, None, None))
A:torch.quantization.fx.quantize.env[node.name]->Graph().node_copy(node, load_arg)
A:torch.quantization.fx.quantize.get_new_observer_name->get_new_attr_name_with_prefix(prefix)
A:torch.quantization.fx.quantize.observer_name->get_new_observer_name(model)
A:torch.quantization.fx.quantize.observed_custom_module_class->get_observed_custom_module_class(type(custom_module))
A:torch.quantization.fx.quantize.observed_custom_module->get_observed_custom_module_class(type(custom_module)).from_float(custom_module)
A:torch.quantization.fx.quantize.(parent_name, name)->_parent_name(node.target)
A:torch.quantization.fx.quantize.new_observer->qconfig.activation()
A:torch.quantization.fx.quantize.device->assert_and_get_unique_device(model)
A:torch.quantization.fx.quantize.weight_observer_nodes->collect_producer_nodes(node_arg)
A:torch.quantization.fx.quantize.weight_observer_module->graph_module_from_producer_nodes(observed, weight_observer_nodes)
A:torch.quantization.fx.quantize.self.quantized_graph->Graph()
A:torch.quantization.fx.quantize.quant_env[n.name]->quant.convert(self, env[n.name])
A:torch.quantization.fx.quantize.quantized->self._fold_weight(quantized)
A:torch.quantization.fx.quantize.(root_node, matched, obj, qconfig)->self._find_matches(model.graph, self.modules, self.patterns).get(node.name, (None, None, None, None))
A:torch.quantization.fx.quantize.result->obj.convert(self, node, load_arg)
A:torch.quantization.fx.quantize.quant_env[node.name]->quantize_node(root_module, self.quantized_graph, load_non_quantized(node.args[0]), observer_module)
A:torch.quantization.fx.quantize.act_post_process_removed_graph->Graph()
A:torch.quantization.fx.quantize.module_dict->dict(model.named_modules())
A:torch.quantization.fx.quantize.packed_weights->dict()
A:torch.quantization.fx.quantize.folded_nodes->dict()
A:torch.quantization.fx.quantize.nodes_to_fold->collect_producer_nodes(node)
A:torch.quantization.fx.quantize.prepacking_module->graph_module_from_producer_nodes(quantized, nodes_to_fold)
A:torch.quantization.fx.quantize.packed_weight->prepacking_module()
A:torch.quantization.fx.quantize.folded_graph->Graph()
A:torch.quantization.fx.quantize.get_new_packed_weight_name->get_new_attr_name_with_prefix('_fx_pass_packed_weight_')
A:torch.quantization.fx.quantize.prepack_node->dict().get(node.name, None)
A:torch.quantization.fx.quantize.packed_weight_name->get_new_packed_weight_name(quantized_root)
A:torch.quantization.fx.quantize.all_matched->set()
torch.quantization.fx.Quantizer(self)
torch.quantization.fx.Quantizer._convert(self,model,inplace=False,debug=False,is_dynamic_quant=False)
torch.quantization.fx.Quantizer._find_matches(self,graph,modules,patterns)
torch.quantization.fx.Quantizer._find_quants(self,graph,matches)
torch.quantization.fx.Quantizer._fold_weight(self,quantized)
torch.quantization.fx.Quantizer._generate_qconfig_map(self,root,input_graph,qconfig_dict)
torch.quantization.fx.Quantizer._prepare(self,model,qconfig_dict,inplace,is_dynamic_quant)
torch.quantization.fx.Quantizer._qat_swap_modules(self,root)
torch.quantization.fx.Quantizer._run_weight_observers(self,observed)
torch.quantization.fx.Quantizer.convert(self,model,inplace=False,debug=False,is_dynamic=False)
torch.quantization.fx.Quantizer.prepare(self,model,qconfig_dict,inplace=False)
torch.quantization.fx.Quantizer.prepare_dynamic(self,model,qconfig_dict,inplace=False)
torch.quantization.fx.Quantizer.restore_state(self,observed)
torch.quantization.fx.Quantizer.save_state(self,observed)
torch.quantization.fx.assert_and_get_unique_device(module)
torch.quantization.fx.collect_producer_nodes(node)
torch.quantization.fx.convert_dict_to_ordered_dict(qconfig_dict)
torch.quantization.fx.get_flattened_qconfig_dict(qconfig_dict)
torch.quantization.fx.get_new_attr_name_with_prefix(prefix)
torch.quantization.fx.graph_module_from_producer_nodes(root,producer_nodes)
torch.quantization.fx.is_activation_post_process(module)
torch.quantization.fx.is_submodule_of_fake_quant(name,module,named_modules)
torch.quantization.fx.quantize.Quantizer(self)
torch.quantization.fx.quantize.Quantizer.__init__(self)
torch.quantization.fx.quantize.Quantizer._convert(self,model,inplace=False,debug=False,is_dynamic_quant=False)
torch.quantization.fx.quantize.Quantizer._find_matches(self,graph,modules,patterns)
torch.quantization.fx.quantize.Quantizer._find_quants(self,graph,matches)
torch.quantization.fx.quantize.Quantizer._fold_weight(self,quantized)
torch.quantization.fx.quantize.Quantizer._generate_qconfig_map(self,root,input_graph,qconfig_dict)
torch.quantization.fx.quantize.Quantizer._prepare(self,model,qconfig_dict,inplace,is_dynamic_quant)
torch.quantization.fx.quantize.Quantizer._qat_swap_modules(self,root)
torch.quantization.fx.quantize.Quantizer._run_weight_observers(self,observed)
torch.quantization.fx.quantize.Quantizer.convert(self,model,inplace=False,debug=False,is_dynamic=False)
torch.quantization.fx.quantize.Quantizer.prepare(self,model,qconfig_dict,inplace=False)
torch.quantization.fx.quantize.Quantizer.prepare_dynamic(self,model,qconfig_dict,inplace=False)
torch.quantization.fx.quantize.Quantizer.restore_state(self,observed)
torch.quantization.fx.quantize.Quantizer.save_state(self,observed)
torch.quantization.fx.quantize.assert_and_get_unique_device(module)
torch.quantization.fx.quantize.collect_producer_nodes(node)
torch.quantization.fx.quantize.convert_dict_to_ordered_dict(qconfig_dict)
torch.quantization.fx.quantize.get_flattened_qconfig_dict(qconfig_dict)
torch.quantization.fx.quantize.get_new_attr_name_with_prefix(prefix)
torch.quantization.fx.quantize.graph_module_from_producer_nodes(root,producer_nodes)
torch.quantization.fx.quantize.is_activation_post_process(module)
torch.quantization.fx.quantize.is_submodule_of_fake_quant(name,module,named_modules)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/pattern_utils.py----------------------------------------
A:torch.quantization.fx.pattern_utils.FUSION_PATTERNS->OrderedDict()
A:torch.quantization.fx.pattern_utils.QUANTIZATION_PATTERNS->OrderedDict()
A:torch.quantization.fx.pattern_utils.DYNAMIC_QUANTIZATION_PATTERNS->OrderedDict()
torch.quantization.fx.pattern_utils.get_dynamic_quant_patterns()
torch.quantization.fx.pattern_utils.get_fusion_patterns()
torch.quantization.fx.pattern_utils.get_quant_patterns()
torch.quantization.fx.pattern_utils.is_match(modules,node,pattern,max_uses=sys.maxsize)
torch.quantization.fx.pattern_utils.register_dynamic_quant_pattern(pattern)
torch.quantization.fx.pattern_utils.register_fusion_pattern(pattern)
torch.quantization.fx.pattern_utils.register_quant_pattern(pattern)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/quantization/fx/fusion_patterns.py----------------------------------------
A:torch.quantization.fx.fusion_patterns.relu->torch.nn.ReLU()
A:torch.quantization.fx.fusion_patterns.op_type_list->tuple((type(m) for m in op_list))
A:torch.quantization.fx.fusion_patterns.(conv_parent_name, conv_name)->_parent_name(self.conv_node.target)
A:torch.quantization.fx.fusion_patterns.fuser_method->get_fuser_method(op_type_list)
A:torch.quantization.fx.fusion_patterns.(parent_name, name)->_parent_name(self.bn_node.target)
A:torch.quantization.fx.fusion_patterns.(module_parent_name, module_name)->_parent_name(self.module_node.target)
torch.quantization.fx.fusion_patterns.ConvBNReLUFusion(self,quantizer,node)
torch.quantization.fx.fusion_patterns.ConvBNReLUFusion.__init__(self,quantizer,node)
torch.quantization.fx.fusion_patterns.ConvBNReLUFusion.fuse(self,quantizer,load_arg)
torch.quantization.fx.fusion_patterns.ModuleReLUFusion(self,quantizer,node)
torch.quantization.fx.fusion_patterns.ModuleReLUFusion.__init__(self,quantizer,node)
torch.quantization.fx.fusion_patterns.ModuleReLUFusion.fuse(self,quantizer,load_arg)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_cudnn.pyi----------------------------------------
torch._C._cudnn.RNNMode(int,Enum)
torch._C._cudnn.getCompileVersion()->Tuple[int, int, int]
torch._C._cudnn.getRuntimeVersion()->Tuple[int, int, int]
torch._C._cudnn.getVersionInt()->int
torch._cudnn.RNNMode(int,Enum)
torch._cudnn.getCompileVersion()->Tuple[int, int, int]
torch._cudnn.getRuntimeVersion()->Tuple[int, int, int]
torch._cudnn.getVersionInt()->int


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_nn.pyi----------------------------------------
torch._C._nn.mkldnn_linear(input:Tensor,weight:Tensor,bias:Optional[Tensor])->Tensor
torch._C._nn.mkldnn_reorder_conv2d_weight(self:Tensor,padding:List,stride:List,dilatation:List,groups:int)->Tensor
torch._C._nn.mkldnn_reorder_conv3d_weight(self:Tensor,padding:List,stride:List,dilatation:List,groups:int)->Tensor
torch._nn.mkldnn_linear(input:Tensor,weight:Tensor,bias:Optional[Tensor])->Tensor
torch._nn.mkldnn_reorder_conv2d_weight(self:Tensor,padding:List,stride:List,dilatation:List,groups:int)->Tensor
torch._nn.mkldnn_reorder_conv3d_weight(self:Tensor,padding:List,stride:List,dilatation:List,groups:int)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/__init__.pyi----------------------------------------
torch._C.__init__.AggregationType(Enum)
torch._C.__init__.AnyType(JitType)
torch._C.__init__.AnyType.get()->AnyType
torch._C.__init__.BFloat16StorageBase(object)
torch._C.__init__.BenchmarkConfig(object)
torch._C.__init__.BenchmarkExecutionStats(object)
torch._C.__init__.BoolStorageBase(object)
torch._C.__init__.BoolTensor(Tensor)
torch._C.__init__.BoolType(JitType)
torch._C.__init__.BoolType.get()->BoolType
torch._C.__init__.BufferDict(self,mod:ScriptModule)
torch._C.__init__.BufferDict.__init__(self,mod:ScriptModule)
torch._C.__init__.ByteStorageBase(object)
torch._C.__init__.ByteTensor(Tensor)
torch._C.__init__.CallStack(self,name:str,range:SourceRange)
torch._C.__init__.CallStack.__init__(self,name:str,range:SourceRange)
torch._C.__init__.CharStorageBase(object)
torch._C.__init__.CharTensor(Tensor)
torch._C.__init__.ClassDef(TreeView)
torch._C.__init__.ClassType(self,qualified_name:str)
torch._C.__init__.ClassType.__init__(self,qualified_name:str)
torch._C.__init__.CompilationUnit(self)
torch._C.__init__.CompilationUnit.__init__(self)
torch._C.__init__.CompilationUnit.define(self,script:str,rcb:ResolutionCallback)
torch._C.__init__.CompilationUnit.find_function(self,name:str)->ScriptFunction
torch._C.__init__.ComplexDoubleStorageBase(object)
torch._C.__init__.ComplexFloatStorageBase(object)
torch._C.__init__.ConcreteModuleType
torch._C.__init__.ConcreteModuleType.equals(self,other:'ConcreteModuleType')->_bool
torch._C.__init__.ConcreteModuleType.from_jit_type(ty:JitType)->ConcreteModuleType
torch._C.__init__.ConcreteModuleType.get_constants(self)->Dict[str, Any]
torch._C.__init__.ConcreteModuleTypeBuilder(self,obj:Any)
torch._C.__init__.ConcreteModuleTypeBuilder.__init__(self,obj:Any)
torch._C.__init__.ConcreteModuleTypeBuilder.add_attribute(self,name:str,ty:JitType,is_param:_bool,is_buffer:_bool)
torch._C.__init__.ConcreteModuleTypeBuilder.add_builtin_function(self,name:str,symbol_name:str)
torch._C.__init__.ConcreteModuleTypeBuilder.add_constant(self,name:str,value:Any)
torch._C.__init__.ConcreteModuleTypeBuilder.add_failed_attribute(self,name:str,failure_reason:str)
torch._C.__init__.ConcreteModuleTypeBuilder.add_function_attribute(self,name:str,ty:JitType,func:Callable[...,Any])
torch._C.__init__.ConcreteModuleTypeBuilder.add_module(self,name:str,meta:ConcreteModuleType)
torch._C.__init__.ConcreteModuleTypeBuilder.add_overload(self,method_name:str,overloaded_method_names:List[str])
torch._C.__init__.ConcreteModuleTypeBuilder.set_module_dict(self)
torch._C.__init__.ConcreteModuleTypeBuilder.set_module_list(self)
torch._C.__init__.Decl(TreeView)
torch._C.__init__.Def(TreeView)
torch._C.__init__.Def.name(self)->Ident
torch._C.__init__.DeviceObjType(JitType)
torch._C.__init__.DeviceObjType.get()->DeviceObjType
torch._C.__init__.DictType(self,key:JitType,value:JitType)
torch._C.__init__.DictType.__init__(self,key:JitType,value:JitType)
torch._C.__init__.DictType.getKeyType(self)->JitType
torch._C.__init__.DictType.getValueType(self)->JitType
torch._C.__init__.DisableTorchFunction()
torch._C.__init__.DoubleStorageBase(object)
torch._C.__init__.DoubleTensor(Tensor)
torch._C.__init__.EnumType(self,qualified_name:str,value_type:JitType,enum_names_values:List[Any])
torch._C.__init__.EnumType.__init__(self,qualified_name:str,value_type:JitType,enum_names_values:List[Any])
torch._C.__init__.ErrorReport(self,range:SourceRange)
torch._C.__init__.ErrorReport.__init__(self,range:SourceRange)
torch._C.__init__.ErrorReport.call_stack()->str
torch._C.__init__.ErrorReport.what(self)->str
torch._C.__init__.FileCheck(object)
torch._C.__init__.FileCheck.check_source_highlighted(self,highlight:str)->'FileCheck'
torch._C.__init__.FileCheck.run(self,test_string:str)->None
torch._C.__init__.FloatStorageBase(object)
torch._C.__init__.FloatTensor(Tensor)
torch._C.__init__.FloatType(JitType)
torch._C.__init__.FloatType.get()->FloatType
torch._C.__init__.FunctionSchema
torch._C.__init__.Future(self)
torch._C.__init__.Future.__init__(self)
torch._C.__init__.Future.done(self)->_bool
torch._C.__init__.Future.set_result(self,result:Any)->None
torch._C.__init__.Future.then(self,callback:Callable)->Future
torch._C.__init__.Future.wait(self)->Any
torch._C.__init__.FutureType(self,a:JitType)
torch._C.__init__.FutureType.__init__(self,a:JitType)
torch._C.__init__.FutureType.getElementType(self)->JitType
torch._C.__init__.Generator(self,device:Union[_device,str,None]=None)
torch._C.__init__.Generator.__init__(self,device:Union[_device,str,None]=None)
torch._C.__init__.Generator.get_state(self)->Tensor
torch._C.__init__.Generator.initial_seed(self)->_int
torch._C.__init__.Generator.manual_seed(self,seed:_int)->Generator
torch._C.__init__.Generator.seed(self)->_int
torch._C.__init__.Generator.set_state(self,_new_state:Tensor)->Generator
torch._C.__init__.Graph
torch._C.__init__.HalfStorageBase(object)
torch._C.__init__.HalfTensor(Tensor)
torch._C.__init__.IODescriptor
torch._C.__init__.IValue
torch._C.__init__.Ident(TreeView)
torch._C.__init__.Ident.name(self)->str
torch._C.__init__.IntStorageBase(object)
torch._C.__init__.IntTensor(Tensor)
torch._C.__init__.IntType(JitType)
torch._C.__init__.IntType.get()->IntType
torch._C.__init__.InterfaceType(self,qualified_name:str)
torch._C.__init__.InterfaceType.__init__(self,qualified_name:str)
torch._C.__init__.InterfaceType.getMethod(self,name:str)->Optional[FunctionSchema]
torch._C.__init__.InterfaceType.getMethodNames(self)->List[str]
torch._C.__init__.JITException
torch._C.__init__.JitType
torch._C.__init__.ListType(self,a:JitType)
torch._C.__init__.ListType.__init__(self,a:JitType)
torch._C.__init__.ListType.getElementType(self)->JitType
torch._C.__init__.ListType.ofBools()->ListType
torch._C.__init__.ListType.ofFloats()->ListType
torch._C.__init__.ListType.ofInts()->ListType
torch._C.__init__.ListType.ofTensors()->ListType
torch._C.__init__.LockingLogger(LoggerBase)
torch._C.__init__.LoggerBase(object)
torch._C.__init__.LongStorageBase(object)
torch._C.__init__.LongTensor(Tensor)
torch._C.__init__.MobileOptimizerType
torch._C.__init__.ModuleDict(self,mod:ScriptModule)
torch._C.__init__.ModuleDict.__init__(self,mod:ScriptModule)
torch._C.__init__.ModuleDict.items(self)->List[Tuple[str, Any]]
torch._C.__init__.NoneType(JitType)
torch._C.__init__.NoneType.get()->NoneType
torch._C.__init__.NoopLogger(LoggerBase)
torch._C.__init__.OptionalType(self,a:JitType)
torch._C.__init__.OptionalType.__init__(self,a:JitType)
torch._C.__init__.OptionalType.getElementType(self)->JitType
torch._C.__init__.OptionalType.ofTensor()->OptionalType
torch._C.__init__.ParameterDict(self,mod:ScriptModule)
torch._C.__init__.ParameterDict.__init__(self,mod:ScriptModule)
torch._C.__init__.PyTorchFileReader(self,buffer:BinaryIO)
torch._C.__init__.PyTorchFileReader.__init__(self,buffer:BinaryIO)
torch._C.__init__.PyTorchFileReader.get_record(self,name:str)->bytes
torch._C.__init__.PyTorchFileWriter(self,buffer:BinaryIO)
torch._C.__init__.PyTorchFileWriter.__init__(self,buffer:BinaryIO)
torch._C.__init__.PyTorchFileWriter.write_end_of_file(self)->None
torch._C.__init__.PyTorchFileWriter.write_record(self,name:str,data:bytes,size:_int)->None
torch._C.__init__.QInt32StorageBase(object)
torch._C.__init__.QInt8StorageBase(object)
torch._C.__init__.QUInt8StorageBase(object)
torch._C.__init__.RRefType(self,a:JitType)
torch._C.__init__.RRefType.__init__(self,a:JitType)
torch._C.__init__.ScriptFunction(self,*args,**kwargs)
torch._C.__init__.ScriptFunction.__call__(self,*args,**kwargs)
torch._C.__init__.ScriptFunction.code(self)->str
torch._C.__init__.ScriptFunction.graph(self)->Graph
torch._C.__init__.ScriptFunction.inlined_graph(self)->Graph
torch._C.__init__.ScriptFunction.name(self)->str
torch._C.__init__.ScriptFunction.qualified_name(self)->str
torch._C.__init__.ScriptFunction.save(self,filename:str,_extra_files:Dict[str,bytes])->None
torch._C.__init__.ScriptFunction.save_to_buffer(self,_extra_files:Dict[str,bytes])->bytes
torch._C.__init__.ScriptFunction.schema(self)->FunctionSchema
torch._C.__init__.ScriptMethod
torch._C.__init__.ScriptModule
torch._C.__init__.ScriptModule._get_method(self,name:str)->ScriptMethod
torch._C.__init__.ScriptModule._method_names(self)->List[str]
torch._C.__init__.ScriptModule.setattr(self,name:str,value:Any)
torch._C.__init__.ShortStorageBase(object)
torch._C.__init__.ShortTensor(Tensor)
torch._C.__init__.Size(Tuple[_int,...])
torch._C.__init__.Size.__getitem__(self:Size,key:_int)->_int
torch._C.__init__.Size.__getitem__(self:Size,key:slice)->Size
torch._C.__init__.Size.numel(self:Size)->_int
torch._C.__init__.SourceRange
torch._C.__init__.StringType(JitType)
torch._C.__init__.StringType.get()->StringType
torch._C.__init__.TensorType(JitType)
torch._C.__init__.TensorType.get(cls)->TensorType
torch._C.__init__.ThroughputBenchmark(self,module:Any)
torch._C.__init__.ThroughputBenchmark.__init__(self,module:Any)
torch._C.__init__.ThroughputBenchmark.add_input(self,*args:Any,**kwargs:Any)->None
torch._C.__init__.ThroughputBenchmark.benchmark(self,config:BenchmarkConfig)->BenchmarkExecutionStats
torch._C.__init__.ThroughputBenchmark.run_once(self,*args:Any,**kwargs:Any)->Any
torch._C.__init__.TracingState
torch._C.__init__.TreeView
torch._C.__init__.TupleType(self,a:List[JitType])
torch._C.__init__.TupleType.__init__(self,a:List[JitType])
torch._C.__init__.Value
torch._C.__init__._CudaDeviceProperties
torch._C.__init__._CudaEventBase(cls,enable_timing:_bool=False,blocking:_bool=False,interprocess:_bool=False)
torch._C.__init__._CudaEventBase.__new__(cls,enable_timing:_bool=False,blocking:_bool=False,interprocess:_bool=False)
torch._C.__init__._CudaEventBase.elapsed_time(self,other:_CudaEventBase)->_float
torch._C.__init__._CudaEventBase.from_ipc_handle(cls,device:_device,ipc_handle:bytes)->_CudaEventBase
torch._C.__init__._CudaEventBase.ipc_handle(self)->bytes
torch._C.__init__._CudaEventBase.query(self)->_bool
torch._C.__init__._CudaEventBase.record(self,stream:_CudaStreamBase)->None
torch._C.__init__._CudaEventBase.synchronize(self)->None
torch._C.__init__._CudaEventBase.wait(self,stream:_CudaStreamBase)->None
torch._C.__init__._CudaStreamBase(self,priority:_int=0,_cdata:_int=0)
torch._C.__init__._CudaStreamBase.__new__(self,priority:_int=0,_cdata:_int=0)
torch._C.__init__._CudaStreamBase.priority_range(self)->Tuple[_int, _int]
torch._C.__init__._CudaStreamBase.query(self)->_bool
torch._C.__init__._CudaStreamBase.synchronize(self)->None
torch._C.__init__._FunctionBase(object)
torch._C.__init__._ImperativeEngine
torch._C.__init__._LegacyVariableBase(self,data:Optional[Tensor]=...,requires_grad:Optional[_bool]=...,volatile:Optional[_bool]=...,_grad_fn:Optional[_FunctionBase]=...)
torch._C.__init__._LegacyVariableBase.__init__(self,data:Optional[Tensor]=...,requires_grad:Optional[_bool]=...,volatile:Optional[_bool]=...,_grad_fn:Optional[_FunctionBase]=...)
torch._C.__init__._TensorBase(self,size:_size,*,device:Union[_device,str,None]=None)
torch._C.__init__._TensorBase.__abs__(self)->Tensor
torch._C.__init__._TensorBase.__add__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__and__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__and__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__and__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__bool__(self)->builtins.bool
torch._C.__init__._TensorBase.__complex__(self)->builtins.complex
torch._C.__init__._TensorBase.__div__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__eq__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__float__(self)->builtins.float
torch._C.__init__._TensorBase.__floordiv__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ge__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__getitem__(self,indices:Union[None,_int,slice,Tensor,List,Tuple])->Tensor
torch._C.__init__._TensorBase.__gt__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__iadd__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__iand__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__iand__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__iand__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__idiv__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ilshift__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ilshift__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__ilshift__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__imul__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__index__(self)->builtins.int
torch._C.__init__._TensorBase.__init__(self,size:_size,*,device:Union[_device,str,None]=None)
torch._C.__init__._TensorBase.__int__(self)->builtins.int
torch._C.__init__._TensorBase.__invert__(self)->Tensor
torch._C.__init__._TensorBase.__ior__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ior__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__ior__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__irshift__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__irshift__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__irshift__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__isub__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ixor__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ixor__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__ixor__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__le__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__long__(self)->builtins.int
torch._C.__init__._TensorBase.__lshift__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__lshift__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__lshift__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__lt__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__matmul__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__mod__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__mul__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__ne__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__neg__(self)->Tensor
torch._C.__init__._TensorBase.__nonzero__(self)->builtins.bool
torch._C.__init__._TensorBase.__or__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__or__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__or__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__pow__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__radd__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__rfloordiv__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__rmul__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__rpow__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__rshift__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__rshift__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__rshift__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.__rsub__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__rtruediv__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__setitem__(self,indices:Union[None,_int,slice,Tensor,List,Tuple],val:Union[Tensor,Number])->None
torch._C.__init__._TensorBase.__sub__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__truediv__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__xor__(self,other:Any)->Tensor
torch._C.__init__._TensorBase.__xor__(self,other:Number)->Tensor
torch._C.__init__._TensorBase.__xor__(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase._coalesced_(self,coalesced:_bool)->Tensor
torch._C.__init__._TensorBase._dimI(self)->_int
torch._C.__init__._TensorBase._dimV(self)->_int
torch._C.__init__._TensorBase._indices(self)->Tensor
torch._C.__init__._TensorBase._nnz(self)->_int
torch._C.__init__._TensorBase._values(self)->Tensor
torch._C.__init__._TensorBase.abs(self)->Tensor
torch._C.__init__._TensorBase.abs_(self)->Tensor
torch._C.__init__._TensorBase.absolute(self)->Tensor
torch._C.__init__._TensorBase.absolute_(self)->Tensor
torch._C.__init__._TensorBase.acos(self)->Tensor
torch._C.__init__._TensorBase.acos_(self)->Tensor
torch._C.__init__._TensorBase.acosh(self)->Tensor
torch._C.__init__._TensorBase.acosh_(self)->Tensor
torch._C.__init__._TensorBase.add(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.add_(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1)->Tensor
torch._C.__init__._TensorBase.addbmm(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addbmm_(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addcdiv(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch._C.__init__._TensorBase.addcdiv_(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch._C.__init__._TensorBase.addcmul(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch._C.__init__._TensorBase.addcmul_(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch._C.__init__._TensorBase.addmm(self,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addmm_(self,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addmv(self,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addmv_(self,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addr(self,vec1:Tensor,vec2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.addr_(self,vec1:Tensor,vec2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.align_as(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.align_to(self,names:Sequence[Union[str,ellipsis,None]])->Tensor
torch._C.__init__._TensorBase.align_to(self,order:Sequence[Union[str,ellipsis,None]],ellipsis_idx:_int)->Tensor
torch._C.__init__._TensorBase.all(self)->Tensor
torch._C.__init__._TensorBase.all(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.all(self,dim:_int,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.allclose(self,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->_bool
torch._C.__init__._TensorBase.amax(self,dim:Union[_int,_size]=(),keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.amin(self,dim:Union[_int,_size]=(),keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.angle(self)->Tensor
torch._C.__init__._TensorBase.any(self)->Tensor
torch._C.__init__._TensorBase.any(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.any(self,dim:_int,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.apply_(self,callable:Callable)->Tensor
torch._C.__init__._TensorBase.arccos(self)->Tensor
torch._C.__init__._TensorBase.arccos_(self)->Tensor
torch._C.__init__._TensorBase.arccosh(self)->Tensor
torch._C.__init__._TensorBase.arccosh_(self)->Tensor
torch._C.__init__._TensorBase.arcsin(self)->Tensor
torch._C.__init__._TensorBase.arcsin_(self)->Tensor
torch._C.__init__._TensorBase.arcsinh(self)->Tensor
torch._C.__init__._TensorBase.arcsinh_(self)->Tensor
torch._C.__init__._TensorBase.arctan(self)->Tensor
torch._C.__init__._TensorBase.arctan_(self)->Tensor
torch._C.__init__._TensorBase.arctanh(self)->Tensor
torch._C.__init__._TensorBase.arctanh_(self)->Tensor
torch._C.__init__._TensorBase.argmax(self,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.argmin(self,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.argsort(self,dim:Union[str,ellipsis,None],descending:_bool=False)->Tensor
torch._C.__init__._TensorBase.argsort(self,dim:_int=-1,descending:_bool=False)->Tensor
torch._C.__init__._TensorBase.as_strided(self,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch._C.__init__._TensorBase.as_strided_(self,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch._C.__init__._TensorBase.as_subclass(self,cls:Tensor)->Tensor
torch._C.__init__._TensorBase.asin(self)->Tensor
torch._C.__init__._TensorBase.asin_(self)->Tensor
torch._C.__init__._TensorBase.asinh(self)->Tensor
torch._C.__init__._TensorBase.asinh_(self)->Tensor
torch._C.__init__._TensorBase.atan(self)->Tensor
torch._C.__init__._TensorBase.atan2(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.atan2_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.atan_(self)->Tensor
torch._C.__init__._TensorBase.atanh(self)->Tensor
torch._C.__init__._TensorBase.atanh_(self)->Tensor
torch._C.__init__._TensorBase.backward(self,gradient:Optional[Tensor]=None,retain_graph:Optional[_bool]=None,create_graph:_bool=False)->None
torch._C.__init__._TensorBase.baddbmm(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.baddbmm_(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.bernoulli(self,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.bernoulli(self,p:_float,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.bernoulli_(self,p:Tensor,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.bernoulli_(self,p:_float=0.5,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.bfloat16(self)->Tensor
torch._C.__init__._TensorBase.bincount(self,weights:Optional[Tensor]=None,minlength:_int=0)->Tensor
torch._C.__init__._TensorBase.bitwise_and(self,other:Number)->Tensor
torch._C.__init__._TensorBase.bitwise_and(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.bitwise_and_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.bitwise_and_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.bitwise_not(self)->Tensor
torch._C.__init__._TensorBase.bitwise_not_(self)->Tensor
torch._C.__init__._TensorBase.bitwise_or(self,other:Number)->Tensor
torch._C.__init__._TensorBase.bitwise_or(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.bitwise_or_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.bitwise_or_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.bitwise_xor(self,other:Number)->Tensor
torch._C.__init__._TensorBase.bitwise_xor(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.bitwise_xor_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.bitwise_xor_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.bmm(self,mat2:Tensor)->Tensor
torch._C.__init__._TensorBase.bool(self)->Tensor
torch._C.__init__._TensorBase.byte(self)->Tensor
torch._C.__init__._TensorBase.cauchy_(self,median:_float=0,sigma:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.ceil(self)->Tensor
torch._C.__init__._TensorBase.ceil_(self)->Tensor
torch._C.__init__._TensorBase.char(self)->Tensor
torch._C.__init__._TensorBase.cholesky(self,upper:_bool=False)->Tensor
torch._C.__init__._TensorBase.cholesky_inverse(self,upper:_bool=False)->Tensor
torch._C.__init__._TensorBase.cholesky_solve(self,input2:Tensor,upper:_bool=False)->Tensor
torch._C.__init__._TensorBase.chunk(self,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.clamp(self,min:_float=-inf,max:_float=inf,*,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.clamp_(self,min:_float=-inf,max:_float=inf)->Tensor
torch._C.__init__._TensorBase.clamp_max(self,max:Number)->Tensor
torch._C.__init__._TensorBase.clamp_max_(self,max:Number)->Tensor
torch._C.__init__._TensorBase.clamp_min(self,min:Number)->Tensor
torch._C.__init__._TensorBase.clamp_min_(self,min:Number)->Tensor
torch._C.__init__._TensorBase.clip(self,min:Optional[Number]=None,max:Optional[Number]=None)->Tensor
torch._C.__init__._TensorBase.clip_(self,min:Optional[Number]=None,max:Optional[Number]=None)->Tensor
torch._C.__init__._TensorBase.clone(self,*,memory_format:Optional[memory_format]=None)->Tensor
torch._C.__init__._TensorBase.coalesce(self)->Tensor
torch._C.__init__._TensorBase.conj(self)->Tensor
torch._C.__init__._TensorBase.contiguous(self,memory_format=torch.contiguous_format)->Tensor
torch._C.__init__._TensorBase.copy_(self,src:Tensor,non_blocking:_bool=False)->Tensor
torch._C.__init__._TensorBase.cos(self)->Tensor
torch._C.__init__._TensorBase.cos_(self)->Tensor
torch._C.__init__._TensorBase.cosh(self)->Tensor
torch._C.__init__._TensorBase.cosh_(self)->Tensor
torch._C.__init__._TensorBase.count_nonzero(self,*dim:_int)->Tensor
torch._C.__init__._TensorBase.count_nonzero(self,dim:Optional[_int]=None)->Tensor
torch._C.__init__._TensorBase.count_nonzero(self,dim:_size)->Tensor
torch._C.__init__._TensorBase.cpu(self)->Tensor
torch._C.__init__._TensorBase.cross(self,other:Tensor,dim:Optional[_int]=None)->Tensor
torch._C.__init__._TensorBase.cuda(self,device:Optional[Union[_device,_int,str]]=None,non_blocking:_bool=False)->Tensor
torch._C.__init__._TensorBase.cummax(self,dim:Union[str,ellipsis,None])->namedtuple_values_indices
torch._C.__init__._TensorBase.cummax(self,dim:_int)->namedtuple_values_indices
torch._C.__init__._TensorBase.cummin(self,dim:Union[str,ellipsis,None])->namedtuple_values_indices
torch._C.__init__._TensorBase.cummin(self,dim:_int)->namedtuple_values_indices
torch._C.__init__._TensorBase.cumprod(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.cumprod(self,dim:_int,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.cumsum(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.cumsum(self,dim:_int,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.data_ptr(self)->_int
torch._C.__init__._TensorBase.deg2rad(self)->Tensor
torch._C.__init__._TensorBase.deg2rad_(self)->Tensor
torch._C.__init__._TensorBase.dense_dim(self)->_int
torch._C.__init__._TensorBase.dequantize(self)->Tensor
torch._C.__init__._TensorBase.det(self)->Tensor
torch._C.__init__._TensorBase.detach(self)->Tensor
torch._C.__init__._TensorBase.detach_(self)->Tensor
torch._C.__init__._TensorBase.diag(self,diagonal:_int=0)->Tensor
torch._C.__init__._TensorBase.diag_embed(self,offset:_int=0,dim1:_int=-2,dim2:_int=-1)->Tensor
torch._C.__init__._TensorBase.diagflat(self,offset:_int=0)->Tensor
torch._C.__init__._TensorBase.diagonal(self,*,outdim:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None],dim2:Union[str,ellipsis,None],offset:_int=0)->Tensor
torch._C.__init__._TensorBase.diagonal(self,offset:_int=0,dim1:_int=0,dim2:_int=1)->Tensor
torch._C.__init__._TensorBase.digamma(self)->Tensor
torch._C.__init__._TensorBase.digamma_(self)->Tensor
torch._C.__init__._TensorBase.dim(self)->_int
torch._C.__init__._TensorBase.dist(self,other:Tensor,p:Number=2)->Tensor
torch._C.__init__._TensorBase.div(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.div_(self,other:Union[Tensor,Number])->Tensor
torch._C.__init__._TensorBase.divide(self,other:Number)->Tensor
torch._C.__init__._TensorBase.divide(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.divide_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.divide_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.dot(self,tensor:Tensor)->Tensor
torch._C.__init__._TensorBase.double(self)->Tensor
torch._C.__init__._TensorBase.eig(self,eigenvectors:_bool=False)->namedtuple_eigenvalues_eigenvectors
torch._C.__init__._TensorBase.element_size(self)->_int
torch._C.__init__._TensorBase.eq(self,other:Number)->Tensor
torch._C.__init__._TensorBase.eq(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.eq_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.eq_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.equal(self,other:Tensor)->_bool
torch._C.__init__._TensorBase.erf(self)->Tensor
torch._C.__init__._TensorBase.erf_(self)->Tensor
torch._C.__init__._TensorBase.erfc(self)->Tensor
torch._C.__init__._TensorBase.erfc_(self)->Tensor
torch._C.__init__._TensorBase.erfinv(self)->Tensor
torch._C.__init__._TensorBase.erfinv_(self)->Tensor
torch._C.__init__._TensorBase.exp(self)->Tensor
torch._C.__init__._TensorBase.exp2(self)->Tensor
torch._C.__init__._TensorBase.exp2_(self)->Tensor
torch._C.__init__._TensorBase.exp_(self)->Tensor
torch._C.__init__._TensorBase.expand(self,*size:_int,implicit:_bool=False)->Tensor
torch._C.__init__._TensorBase.expand(self,size:_size,*,implicit:_bool=False)->Tensor
torch._C.__init__._TensorBase.expand_as(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.expm1(self)->Tensor
torch._C.__init__._TensorBase.expm1_(self)->Tensor
torch._C.__init__._TensorBase.exponential_(self,lambd:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.fft(self,signal_ndim:_int,normalized:_bool=False)->Tensor
torch._C.__init__._TensorBase.fill_(self,value:Number)->Tensor
torch._C.__init__._TensorBase.fill_(self,value:Tensor)->Tensor
torch._C.__init__._TensorBase.fill_diagonal_(self,fill_value:Number,wrap:_bool=False)->Tensor
torch._C.__init__._TensorBase.fix(self)->Tensor
torch._C.__init__._TensorBase.fix_(self)->Tensor
torch._C.__init__._TensorBase.flatten(self,dims:Sequence[Union[str,ellipsis,None]],out_dim:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.flatten(self,start_dim:Union[str,ellipsis,None],end_dim:Union[str,ellipsis,None],out_dim:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.flatten(self,start_dim:_int,end_dim:_int,out_dim:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.flatten(self,start_dim:_int=0,end_dim:_int=-1)->Tensor
torch._C.__init__._TensorBase.flip(self,*dims:_int)->Tensor
torch._C.__init__._TensorBase.flip(self,dims:_size)->Tensor
torch._C.__init__._TensorBase.fliplr(self)->Tensor
torch._C.__init__._TensorBase.flipud(self)->Tensor
torch._C.__init__._TensorBase.float(self)->Tensor
torch._C.__init__._TensorBase.floor(self)->Tensor
torch._C.__init__._TensorBase.floor_(self)->Tensor
torch._C.__init__._TensorBase.floor_divide(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.floor_divide_(self,other:Union[Tensor,Number])->Tensor
torch._C.__init__._TensorBase.fmod(self,other:Number)->Tensor
torch._C.__init__._TensorBase.fmod(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.fmod_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.fmod_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.frac(self)->Tensor
torch._C.__init__._TensorBase.frac_(self)->Tensor
torch._C.__init__._TensorBase.gather(self,dim:Union[str,ellipsis,None],index:Tensor,*,sparse_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.gather(self,dim:_int,index:Tensor,*,sparse_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.gcd(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.gcd_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.ge(self,other:Number)->Tensor
torch._C.__init__._TensorBase.ge(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.ge_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.ge_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.geometric_(self,p:_float,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.geqrf(self)->namedtuple_a_tau
torch._C.__init__._TensorBase.ger(self,vec2:Tensor)->Tensor
torch._C.__init__._TensorBase.get_device(self)->_int
torch._C.__init__._TensorBase.greater(self,other:Number)->Tensor
torch._C.__init__._TensorBase.greater(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.greater_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.greater_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.greater_equal(self,other:Number)->Tensor
torch._C.__init__._TensorBase.greater_equal(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.greater_equal_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.greater_equal_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.gt(self,other:Number)->Tensor
torch._C.__init__._TensorBase.gt(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.gt_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.gt_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.half(self)->Tensor
torch._C.__init__._TensorBase.hardshrink(self,lambd:Number=0.5)->Tensor
torch._C.__init__._TensorBase.heaviside(self,values:Tensor)->Tensor
torch._C.__init__._TensorBase.heaviside_(self,values:Tensor)->Tensor
torch._C.__init__._TensorBase.histc(self,bins:_int=100,min:Number=0,max:Number=0)->Tensor
torch._C.__init__._TensorBase.hypot(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.hypot_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.i0(self)->Tensor
torch._C.__init__._TensorBase.i0_(self)->Tensor
torch._C.__init__._TensorBase.ifft(self,signal_ndim:_int,normalized:_bool=False)->Tensor
torch._C.__init__._TensorBase.index_add(self,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_add(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_add_(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_copy(self,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_copy(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_copy_(self,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_copy_(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.index_fill(self,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.index_fill(self,dim:Union[str,ellipsis,None],index:Tensor,value:Tensor)->Tensor
torch._C.__init__._TensorBase.index_fill(self,dim:_int,index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.index_fill(self,dim:_int,index:Tensor,value:Tensor)->Tensor
torch._C.__init__._TensorBase.index_fill_(self,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.index_fill_(self,dim:Union[str,ellipsis,None],index:Tensor,value:Tensor)->Tensor
torch._C.__init__._TensorBase.index_fill_(self,dim:_int,index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.index_fill_(self,dim:_int,index:Tensor,value:Tensor)->Tensor
torch._C.__init__._TensorBase.index_put(self,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch._C.__init__._TensorBase.index_put_(self,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch._C.__init__._TensorBase.index_select(self,dim:Union[str,ellipsis,None],index:Tensor)->Tensor
torch._C.__init__._TensorBase.index_select(self,dim:_int,index:Tensor)->Tensor
torch._C.__init__._TensorBase.indices(self)->Tensor
torch._C.__init__._TensorBase.int(self)->Tensor
torch._C.__init__._TensorBase.int_repr(self)->Tensor
torch._C.__init__._TensorBase.inverse(self)->Tensor
torch._C.__init__._TensorBase.irfft(self,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True,signal_sizes:_size=())->Tensor
torch._C.__init__._TensorBase.is_coalesced(self)->_bool
torch._C.__init__._TensorBase.is_complex(self)->_bool
torch._C.__init__._TensorBase.is_contiguous(self,memory_format=torch.contiguous_format)->_bool
torch._C.__init__._TensorBase.is_distributed(self)->_bool
torch._C.__init__._TensorBase.is_floating_point(self)->_bool
torch._C.__init__._TensorBase.is_nonzero(self)->_bool
torch._C.__init__._TensorBase.is_pinned(self)->_bool
torch._C.__init__._TensorBase.is_same_size(self,other:Tensor)->_bool
torch._C.__init__._TensorBase.is_set_to(self,tensor:Tensor)->_bool
torch._C.__init__._TensorBase.is_signed(self)->_bool
torch._C.__init__._TensorBase.isclose(self,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->Tensor
torch._C.__init__._TensorBase.isfinite(self)->Tensor
torch._C.__init__._TensorBase.isinf(self)->Tensor
torch._C.__init__._TensorBase.isnan(self)->Tensor
torch._C.__init__._TensorBase.isneginf(self)->Tensor
torch._C.__init__._TensorBase.isposinf(self)->Tensor
torch._C.__init__._TensorBase.isreal(self)->Tensor
torch._C.__init__._TensorBase.item(self)->Number
torch._C.__init__._TensorBase.kthvalue(self,k:_int,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.kthvalue(self,k:_int,dim:_int=-1,keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.lcm(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.lcm_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.le(self,other:Number)->Tensor
torch._C.__init__._TensorBase.le(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.le_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.le_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.lerp(self,end:Tensor,weight:Number)->Tensor
torch._C.__init__._TensorBase.lerp(self,end:Tensor,weight:Tensor)->Tensor
torch._C.__init__._TensorBase.lerp_(self,end:Tensor,weight:Number)->Tensor
torch._C.__init__._TensorBase.lerp_(self,end:Tensor,weight:Tensor)->Tensor
torch._C.__init__._TensorBase.less(self,other:Number)->Tensor
torch._C.__init__._TensorBase.less(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.less_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.less_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.less_equal(self,other:Number)->Tensor
torch._C.__init__._TensorBase.less_equal(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.less_equal_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.less_equal_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.lgamma(self)->Tensor
torch._C.__init__._TensorBase.lgamma_(self)->Tensor
torch._C.__init__._TensorBase.log(self)->Tensor
torch._C.__init__._TensorBase.log10(self)->Tensor
torch._C.__init__._TensorBase.log10_(self)->Tensor
torch._C.__init__._TensorBase.log1p(self)->Tensor
torch._C.__init__._TensorBase.log1p_(self)->Tensor
torch._C.__init__._TensorBase.log2(self)->Tensor
torch._C.__init__._TensorBase.log2_(self)->Tensor
torch._C.__init__._TensorBase.log_(self)->Tensor
torch._C.__init__._TensorBase.log_normal_(self,mean:_float=1,std:_float=2,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.log_softmax(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.log_softmax(self,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.logaddexp(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logaddexp2(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logcumsumexp(self,dim:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.logcumsumexp(self,dim:_int)->Tensor
torch._C.__init__._TensorBase.logdet(self)->Tensor
torch._C.__init__._TensorBase.logical_and(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logical_and_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logical_not(self)->Tensor
torch._C.__init__._TensorBase.logical_not_(self)->Tensor
torch._C.__init__._TensorBase.logical_or(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logical_or_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logical_xor(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logical_xor_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.logit(self,eps:Optional[_float]=None)->Tensor
torch._C.__init__._TensorBase.logit_(self,eps:Optional[_float]=None)->Tensor
torch._C.__init__._TensorBase.logsumexp(self,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.logsumexp(self,dim:Union[_int,_size],keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.long(self)->Tensor
torch._C.__init__._TensorBase.lstsq(self,A:Tensor)->namedtuple_solution_QR
torch._C.__init__._TensorBase.lt(self,other:Number)->Tensor
torch._C.__init__._TensorBase.lt(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.lt_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.lt_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.lu_solve(self,LU_data:Tensor,LU_pivots:Tensor)->Tensor
torch._C.__init__._TensorBase.map_(self,tensor:Tensor,callable:Callable)->Tensor
torch._C.__init__._TensorBase.masked_fill(self,mask:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.masked_fill(self,mask:Tensor,value:Tensor)->Tensor
torch._C.__init__._TensorBase.masked_fill_(self,mask:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.masked_fill_(self,mask:Tensor,value:Tensor)->Tensor
torch._C.__init__._TensorBase.masked_scatter(self,mask:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.masked_scatter_(self,mask:Tensor,source:Tensor)->Tensor
torch._C.__init__._TensorBase.masked_select(self,mask:Tensor)->Tensor
torch._C.__init__._TensorBase.matmul(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.matrix_exp(self)->Tensor
torch._C.__init__._TensorBase.matrix_power(self,n:_int)->Tensor
torch._C.__init__._TensorBase.max(self)->Tensor
torch._C.__init__._TensorBase.max(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.max(self,dim:_int,keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.max(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.maximum(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.mean(self,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.mean(self,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.mean(self,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.median(self)->Tensor
torch._C.__init__._TensorBase.median(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.median(self,dim:_int,keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.min(self)->Tensor
torch._C.__init__._TensorBase.min(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.min(self,dim:_int,keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.min(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.minimum(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.mm(self,mat2:Tensor)->Tensor
torch._C.__init__._TensorBase.mode(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.mode(self,dim:_int=-1,keepdim:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.movedim(self,source:_int,destination:_int)->Tensor
torch._C.__init__._TensorBase.movedim(self,source:_size,destination:_size)->Tensor
torch._C.__init__._TensorBase.mul(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.mul_(self,other:Union[Tensor,Number])->Tensor
torch._C.__init__._TensorBase.multinomial(self,num_samples:_int,replacement:_bool=False,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.multiply(self,other:Number)->Tensor
torch._C.__init__._TensorBase.multiply(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.multiply_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.multiply_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.mv(self,vec:Tensor)->Tensor
torch._C.__init__._TensorBase.mvlgamma(self,p:_int)->Tensor
torch._C.__init__._TensorBase.mvlgamma_(self,p:_int)->Tensor
torch._C.__init__._TensorBase.nanquantile(self,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.nanquantile(self,q:_float,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.nansum(self,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.nansum(self,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.narrow(self,dim:_int,start:Tensor,length:_int)->Tensor
torch._C.__init__._TensorBase.narrow(self,dim:_int,start:_int,length:_int)->Tensor
torch._C.__init__._TensorBase.narrow_copy(self,dim:_int,start:_int,length:_int)->Tensor
torch._C.__init__._TensorBase.ndimension(self)->_int
torch._C.__init__._TensorBase.ne(self,other:Number)->Tensor
torch._C.__init__._TensorBase.ne(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.ne_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.ne_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.neg(self)->Tensor
torch._C.__init__._TensorBase.neg_(self)->Tensor
torch._C.__init__._TensorBase.negative(self)->Tensor
torch._C.__init__._TensorBase.negative_(self)->Tensor
torch._C.__init__._TensorBase.nelement(self)->_int
torch._C.__init__._TensorBase.new(self,*args:Any,device:Union[_device,str,None]=None)->Tensor
torch._C.__init__._TensorBase.new(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.new(self,size:_size,*,device:Union[_device,str,None]=None)->Tensor
torch._C.__init__._TensorBase.new(self,storage:Storage)->Tensor
torch._C.__init__._TensorBase.new_empty(self,*size:_int,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.new_empty(self,size:_size,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.new_full(self,size:_size,fill_value:Number,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.new_ones(self,size:_size,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.new_tensor(self,data:Any,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.new_zeros(self,*size:_int,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.new_zeros(self,size:_size,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C.__init__._TensorBase.nextafter(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.nextafter_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.nonzero(self,*,as_tuple:_bool=...)->Tensor
torch._C.__init__._TensorBase.normal_(self,mean:_float=0,std:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.not_equal(self,other:Number)->Tensor
torch._C.__init__._TensorBase.not_equal(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.not_equal_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.not_equal_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.numel(self)->_int
torch._C.__init__._TensorBase.numpy(self)->Any
torch._C.__init__._TensorBase.orgqr(self,input2:Tensor)->Tensor
torch._C.__init__._TensorBase.ormqr(self,input2:Tensor,input3:Tensor,left:_bool=True,transpose:_bool=False)->Tensor
torch._C.__init__._TensorBase.outer(self,vec2:Tensor)->Tensor
torch._C.__init__._TensorBase.permute(self,*dims:_int)->Tensor
torch._C.__init__._TensorBase.permute(self,dims:_size)->Tensor
torch._C.__init__._TensorBase.pin_memory(self)->Tensor
torch._C.__init__._TensorBase.pinverse(self,rcond:_float=1e-15)->Tensor
torch._C.__init__._TensorBase.polygamma(self,n:_int)->Tensor
torch._C.__init__._TensorBase.polygamma_(self,n:_int)->Tensor
torch._C.__init__._TensorBase.pow(self,exponent:Number)->Tensor
torch._C.__init__._TensorBase.pow(self,exponent:Tensor)->Tensor
torch._C.__init__._TensorBase.pow_(self,exponent:Number)->Tensor
torch._C.__init__._TensorBase.pow_(self,exponent:Tensor)->Tensor
torch._C.__init__._TensorBase.prelu(self,weight:Tensor)->Tensor
torch._C.__init__._TensorBase.prod(self,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.prod(self,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.prod(self,dim:_int,keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.put_(self,index:Tensor,source:Tensor,accumulate:_bool=False)->Tensor
torch._C.__init__._TensorBase.q_per_channel_axis(self)->_int
torch._C.__init__._TensorBase.q_per_channel_scales(self)->Tensor
torch._C.__init__._TensorBase.q_per_channel_zero_points(self)->Tensor
torch._C.__init__._TensorBase.q_scale(self)->_float
torch._C.__init__._TensorBase.q_zero_point(self)->_int
torch._C.__init__._TensorBase.qr(self,some:_bool=True)->namedtuple_Q_R
torch._C.__init__._TensorBase.qscheme(self)->_qscheme
torch._C.__init__._TensorBase.quantile(self,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.quantile(self,q:_float,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.rad2deg(self)->Tensor
torch._C.__init__._TensorBase.rad2deg_(self)->Tensor
torch._C.__init__._TensorBase.random_(self,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.random_(self,from_:_int,to:Optional[_int],*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.random_(self,to:_int,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.reciprocal(self)->Tensor
torch._C.__init__._TensorBase.reciprocal_(self)->Tensor
torch._C.__init__._TensorBase.refine_names(self,names:Sequence[Union[str,ellipsis,None]])->Tensor
torch._C.__init__._TensorBase.relu(self)->Tensor
torch._C.__init__._TensorBase.relu_(self)->Tensor
torch._C.__init__._TensorBase.remainder(self,other:Number)->Tensor
torch._C.__init__._TensorBase.remainder(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.remainder_(self,other:Number)->Tensor
torch._C.__init__._TensorBase.remainder_(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.rename(self,names:Optional[Sequence[Union[str,ellipsis,None]]])->Tensor
torch._C.__init__._TensorBase.rename_(self,names:Optional[Sequence[Union[str,ellipsis,None]]])->Tensor
torch._C.__init__._TensorBase.renorm(self,p:Number,dim:_int,maxnorm:Number)->Tensor
torch._C.__init__._TensorBase.renorm_(self,p:Number,dim:_int,maxnorm:Number)->Tensor
torch._C.__init__._TensorBase.repeat(self,*repeats:_int)->Tensor
torch._C.__init__._TensorBase.repeat(self,repeats:_size)->Tensor
torch._C.__init__._TensorBase.repeat_interleave(self,repeats:Tensor,dim:Optional[_int]=None)->Tensor
torch._C.__init__._TensorBase.repeat_interleave(self,repeats:_int,dim:Optional[_int]=None)->Tensor
torch._C.__init__._TensorBase.requires_grad_(self,mode:_bool=True)->Tensor
torch._C.__init__._TensorBase.reshape(self,*shape:_int)->Tensor
torch._C.__init__._TensorBase.reshape(self,shape:_size)->Tensor
torch._C.__init__._TensorBase.reshape_as(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.resize_(self,*size:_int,memory_format:Optional[memory_format]=None)->Tensor
torch._C.__init__._TensorBase.resize_(self,size:_size,*,memory_format:Optional[memory_format]=None)->Tensor
torch._C.__init__._TensorBase.resize_as_(self,the_template:Tensor,*,memory_format:Optional[memory_format]=None)->Tensor
torch._C.__init__._TensorBase.rfft(self,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True)->Tensor
torch._C.__init__._TensorBase.roll(self,shifts:Union[_int,_size],dims:Union[_int,_size]=())->Tensor
torch._C.__init__._TensorBase.rot90(self,k:_int=1,dims:_size=(0,1))->Tensor
torch._C.__init__._TensorBase.round(self)->Tensor
torch._C.__init__._TensorBase.round_(self)->Tensor
torch._C.__init__._TensorBase.rsqrt(self)->Tensor
torch._C.__init__._TensorBase.rsqrt_(self)->Tensor
torch._C.__init__._TensorBase.scatter(self,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch._C.__init__._TensorBase.scatter(self,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.scatter(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch._C.__init__._TensorBase.scatter(self,dim:_int,index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch._C.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,src:Tensor,*,reduce:str)->Tensor
torch._C.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,value:Number)->Tensor
torch._C.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,value:Number,*,reduce:str)->Tensor
torch._C.__init__._TensorBase.scatter_add(self,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch._C.__init__._TensorBase.scatter_add(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch._C.__init__._TensorBase.scatter_add_(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch._C.__init__._TensorBase.select(self,dim:Union[str,ellipsis,None],index:_int)->Tensor
torch._C.__init__._TensorBase.select(self,dim:_int,index:_int)->Tensor
torch._C.__init__._TensorBase.set_(self,storage:Storage)->Tensor
torch._C.__init__._TensorBase.set_(self,storage:Storage,offset:_int,size:_size,stride:_size)->Tensor
torch._C.__init__._TensorBase.sgn(self)->Tensor
torch._C.__init__._TensorBase.sgn_(self)->Tensor
torch._C.__init__._TensorBase.short(self)->Tensor
torch._C.__init__._TensorBase.sigmoid(self)->Tensor
torch._C.__init__._TensorBase.sigmoid_(self)->Tensor
torch._C.__init__._TensorBase.sign(self)->Tensor
torch._C.__init__._TensorBase.sign_(self)->Tensor
torch._C.__init__._TensorBase.signbit(self)->Tensor
torch._C.__init__._TensorBase.sin(self)->Tensor
torch._C.__init__._TensorBase.sin_(self)->Tensor
torch._C.__init__._TensorBase.sinh(self)->Tensor
torch._C.__init__._TensorBase.sinh_(self)->Tensor
torch._C.__init__._TensorBase.size(self)->Size
torch._C.__init__._TensorBase.size(self,_int)->_int
torch._C.__init__._TensorBase.slogdet(self)->namedtuple_sign_logabsdet
torch._C.__init__._TensorBase.smm(self,mat2:Tensor)->Tensor
torch._C.__init__._TensorBase.softmax(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.softmax(self,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.solve(self,A:Tensor)->namedtuple_solution_LU
torch._C.__init__._TensorBase.sort(self,dim:Union[str,ellipsis,None],descending:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.sort(self,dim:_int=-1,descending:_bool=False)->namedtuple_values_indices
torch._C.__init__._TensorBase.sparse_dim(self)->_int
torch._C.__init__._TensorBase.sparse_mask(self,mask:Tensor)->Tensor
torch._C.__init__._TensorBase.sparse_resize_(self,size:_size,sparse_dim:_int,dense_dim:_int)->Tensor
torch._C.__init__._TensorBase.sparse_resize_and_clear_(self,size:_size,sparse_dim:_int,dense_dim:_int)->Tensor
torch._C.__init__._TensorBase.split(self,split_size:Tuple[_int,...],dim:_int=0)->Sequence[Tensor]
torch._C.__init__._TensorBase.split(self,split_size:_int,dim:_int=0)->Sequence[Tensor]
torch._C.__init__._TensorBase.split_with_sizes(self,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.sqrt(self)->Tensor
torch._C.__init__._TensorBase.sqrt_(self)->Tensor
torch._C.__init__._TensorBase.square(self)->Tensor
torch._C.__init__._TensorBase.square_(self)->Tensor
torch._C.__init__._TensorBase.squeeze(self)->Tensor
torch._C.__init__._TensorBase.squeeze(self,dim:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.squeeze(self,dim:_int)->Tensor
torch._C.__init__._TensorBase.squeeze_(self)->Tensor
torch._C.__init__._TensorBase.squeeze_(self,dim:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.squeeze_(self,dim:_int)->Tensor
torch._C.__init__._TensorBase.sspaddmm(self,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.std(self,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.std(self,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.std(self,unbiased:_bool=True)->Tensor
torch._C.__init__._TensorBase.storage(self)->Storage
torch._C.__init__._TensorBase.storage_offset(self)->_int
torch._C.__init__._TensorBase.stride(self)->Tuple[_int]
torch._C.__init__._TensorBase.stride(self,_int)->_int
torch._C.__init__._TensorBase.sub(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.sub_(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1)->Tensor
torch._C.__init__._TensorBase.subtract(self,other:Number,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.subtract(self,other:Tensor,*,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.subtract_(self,other:Number,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.subtract_(self,other:Tensor,*,alpha:Number=1)->Tensor
torch._C.__init__._TensorBase.sum(self,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.sum(self,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.sum(self,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch._C.__init__._TensorBase.sum_to_size(self,*size:_int)->Tensor
torch._C.__init__._TensorBase.sum_to_size(self,size:_size)->Tensor
torch._C.__init__._TensorBase.svd(self,some:_bool=True,compute_uv:_bool=True)->namedtuple_U_S_V
torch._C.__init__._TensorBase.symeig(self,eigenvectors:_bool=False,upper:_bool=True)->namedtuple_eigenvalues_eigenvectors
torch._C.__init__._TensorBase.t(self)->Tensor
torch._C.__init__._TensorBase.t_(self)->Tensor
torch._C.__init__._TensorBase.take(self,index:Tensor)->Tensor
torch._C.__init__._TensorBase.tan(self)->Tensor
torch._C.__init__._TensorBase.tan_(self)->Tensor
torch._C.__init__._TensorBase.tanh(self)->Tensor
torch._C.__init__._TensorBase.tanh_(self)->Tensor
torch._C.__init__._TensorBase.to(self,device:Optional[Union[_device,str]]=None,dtype:Optional[_dtype]=None,non_blocking:_bool=False,copy:_bool=False)->Tensor
torch._C.__init__._TensorBase.to(self,dtype:_dtype,non_blocking:_bool=False,copy:_bool=False)->Tensor
torch._C.__init__._TensorBase.to(self,other:Tensor,non_blocking:_bool=False,copy:_bool=False)->Tensor
torch._C.__init__._TensorBase.to_dense(self)->Tensor
torch._C.__init__._TensorBase.to_mkldnn(self)->Tensor
torch._C.__init__._TensorBase.to_sparse(self)->Tensor
torch._C.__init__._TensorBase.to_sparse(self,sparse_dim:_int)->Tensor
torch._C.__init__._TensorBase.tolist(self)->List
torch._C.__init__._TensorBase.topk(self,k:_int,dim:_int=-1,largest:_bool=True,sorted:_bool=True)->namedtuple_values_indices
torch._C.__init__._TensorBase.trace(self)->Tensor
torch._C.__init__._TensorBase.transpose(self,dim0:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None])->Tensor
torch._C.__init__._TensorBase.transpose(self,dim0:_int,dim1:_int)->Tensor
torch._C.__init__._TensorBase.transpose_(self,dim0:_int,dim1:_int)->Tensor
torch._C.__init__._TensorBase.triangular_solve(self,A:Tensor,upper:_bool=True,transpose:_bool=False,unitriangular:_bool=False)->namedtuple_solution_cloned_coefficient
torch._C.__init__._TensorBase.tril(self,diagonal:_int=0)->Tensor
torch._C.__init__._TensorBase.tril_(self,diagonal:_int=0)->Tensor
torch._C.__init__._TensorBase.triu(self,diagonal:_int=0)->Tensor
torch._C.__init__._TensorBase.triu_(self,diagonal:_int=0)->Tensor
torch._C.__init__._TensorBase.true_divide(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C.__init__._TensorBase.true_divide_(self,other:Union[Tensor,Number])->Tensor
torch._C.__init__._TensorBase.trunc(self)->Tensor
torch._C.__init__._TensorBase.trunc_(self)->Tensor
torch._C.__init__._TensorBase.type(self,dtype:None=None,non_blocking:_bool=False)->str
torch._C.__init__._TensorBase.type(self,dtype:Union[str,_dtype],non_blocking:_bool=False)->Tensor
torch._C.__init__._TensorBase.type_as(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.unbind(self,dim:Union[str,ellipsis,None])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.unbind(self,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.unflatten(self,dim:Union[str,ellipsis,None],sizes:_size,names:Sequence[Union[str,ellipsis,None]])->Tensor
torch._C.__init__._TensorBase.unflatten(self,dim:_int,sizes:_size,names:Optional[Sequence[Union[str,ellipsis,None]]]=None)->Tensor
torch._C.__init__._TensorBase.unfold(self,dimension:_int,size:_int,step:_int)->Tensor
torch._C.__init__._TensorBase.uniform_(self,from_:_float=0,to:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch._C.__init__._TensorBase.unsafe_chunk(self,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.unsafe_split(self,split_size:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.unsafe_split_with_sizes(self,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C.__init__._TensorBase.unsqueeze(self,dim:_int)->Tensor
torch._C.__init__._TensorBase.unsqueeze_(self,dim:_int)->Tensor
torch._C.__init__._TensorBase.values(self)->Tensor
torch._C.__init__._TensorBase.var(self,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.var(self,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch._C.__init__._TensorBase.var(self,unbiased:_bool=True)->Tensor
torch._C.__init__._TensorBase.vdot(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.view(self,*size:_int)->Tensor
torch._C.__init__._TensorBase.view(self,size:_size)->Tensor
torch._C.__init__._TensorBase.view_as(self,other:Tensor)->Tensor
torch._C.__init__._TensorBase.where(self,condition:Tensor,other:Tensor)->Tensor
torch._C.__init__._TensorBase.zero_(self)->Tensor
torch._C.__init__._add_docstr(obj:T,doc_obj:str)->T
torch._C.__init__._autograd_init()->_bool
torch._C.__init__._collect_all(futures:List[Future])->Future
torch._C.__init__._crash_if_aten_asan()->_int
torch._C.__init__._crash_if_csrc_asan()->_int
torch._C.__init__._crash_if_csrc_ubsan()->_int
torch._C.__init__._create_function_from_graph(qualname:str,graph:Graph)->Graph
torch._C.__init__._create_function_from_trace(qualname:str,func:Callable[...,Any],input_tuple:Tuple[Any,...],var_lookup_fn:Callable[[Tensor],str],strict:_bool,force_outplace:_bool)->Tuple[Graph, Stack]
torch._C.__init__._create_graph_by_tracing(func:Callable[...,Any],inputs:Any,var_name_lookup_fn:Callable[[Tensor],str],strict:Any,force_outplace:Any,self:Any=None)->Tuple[Graph, Stack]
torch._C.__init__._create_module_with_type(ty:JitType)->ScriptModule
torch._C.__init__._cuda_cudaCachingAllocator_raw_alloc(size:_int,cuda_stream:_int)->_int
torch._C.__init__._cuda_cudaCachingAllocator_raw_delete(ptr:_int)->None
torch._C.__init__._cuda_cudaHostAllocator()->_int
torch._C.__init__._cuda_emptyCache()->None
torch._C.__init__._cuda_getCompiledVersion()->_int
torch._C.__init__._cuda_getCurrentBlasHandle()->_int
torch._C.__init__._cuda_getCurrentStream(device:_int)->_int
torch._C.__init__._cuda_getDefaultStream(device:_int)->_int
torch._C.__init__._cuda_lock_mutex()->None
torch._C.__init__._cuda_memorySnapshot()->List[Dict[str, Any]]
torch._C.__init__._cuda_memoryStats(device:_int)->Dict[str, Any]
torch._C.__init__._cuda_resetAccumulatedMemoryStats(device:_int)->None
torch._C.__init__._cuda_resetPeakMemoryStats(device:_int)->None
torch._C.__init__._cuda_setDevice(device:_int)->None
torch._C.__init__._cuda_setStream(cuda_stream:_int)->None
torch._C.__init__._cuda_unlock_mutex()->None
torch._C.__init__._debug_set_autodiff_subgraph_inlining(disabled:_bool)->None
torch._C.__init__._demangle(str)->str
torch._C.__init__._error_if_any_worker_fails()->None
torch._C.__init__._export_opnames(module:ScriptModule)->List[str]
torch._C.__init__._freeze_module(module:ScriptModule,preserved_attrs:List[str],freeze_interfaces:_bool=True)->ScriptModule
torch._C.__init__._from_dlpack(data:Any)->Tensor
torch._C.__init__._get_backcompat_broadcast_warn()->_bool
torch._C.__init__._get_backcompat_keepdim_warn()->_bool
torch._C.__init__._get_cublas_allow_tf32()->_bool
torch._C.__init__._get_cudnn_allow_tf32()->_bool
torch._C.__init__._get_cudnn_benchmark()->_bool
torch._C.__init__._get_cudnn_deterministic()->_bool
torch._C.__init__._get_cudnn_enabled()->_bool
torch._C.__init__._get_custom_class_python_wrapper(name:str,attr:str)->Any
torch._C.__init__._get_default_device()->str
torch._C.__init__._get_deterministic()->_bool
torch._C.__init__._get_graph_executor_optimize()->_bool
torch._C.__init__._get_mkldnn_enabled()->_bool
torch._C.__init__._get_qengine()->_int
torch._C.__init__._get_tracing_state()->TracingState
torch._C.__init__._has_distributed()->_bool
torch._C.__init__._infer_size(arg1:Size,arg2:Size)->Size
torch._C.__init__._initExtension(shm_manager_path:str)->None
torch._C.__init__._init_names(arg:Sequence[Type])->None
torch._C.__init__._is_tracing()->_bool
torch._C.__init__._is_xnnpack_enabled()->_bool
torch._C.__init__._ivalue_tags_match(lhs:ScriptModule,rhs:ScriptModule)->_bool
torch._C.__init__._jit_can_fuse_on_cpu()->_bool
torch._C.__init__._jit_can_fuse_on_gpu()->_bool
torch._C.__init__._jit_clear_class_registry()->None
torch._C.__init__._jit_flatten(arg:Any)->Tuple[List[Tensor], IODescriptor]
torch._C.__init__._jit_get_emit_hooks()->Tuple[Callable, Callable]
torch._C.__init__._jit_get_inline_everything_mode()->_bool
torch._C.__init__._jit_get_operation(op_name:str)->Callable
torch._C.__init__._jit_get_schemas_for_operator(name:str)->List[FunctionSchema]
torch._C.__init__._jit_get_trigger_value(trigger_name:str)->_int
torch._C.__init__._jit_init()->_bool
torch._C.__init__._jit_is_script_object(obj:Any)->_bool
torch._C.__init__._jit_nvfuser_enabled()->_bool
torch._C.__init__._jit_override_can_fuse_on_cpu(override:_bool)
torch._C.__init__._jit_override_can_fuse_on_gpu(override:_bool)
torch._C.__init__._jit_pass_canonicalize(graph:Graph)
torch._C.__init__._jit_pass_dce(Graph)->None
torch._C.__init__._jit_pass_erase_shape_information(graph:Graph)
torch._C.__init__._jit_pass_inline(Graph)->None
torch._C.__init__._jit_pass_lint(Graph)->None
torch._C.__init__._jit_pass_optimize_for_mobile(module:'torch.jit.ScriptModule',optimization_blocklist:Set[MobileOptimizerType],preserved_methods:List[AnyStr])->'torch.jit.ScriptModule'
torch._C.__init__._jit_pass_vulkan_optimize_for_mobile(module:'torch.jit.ScriptModule',preserved_methods:List[AnyStr])->'torch.jit.ScriptModule'
torch._C.__init__._jit_script_class_compile(qual_name:str,definition:ClassDef,defaults:Dict[str,Dict[str,Any]],rcb:ResolutionCallback)
torch._C.__init__._jit_script_compile(qual_name:str,definition:Def,rcb:ResolutionCallback,defaults:Dict[str,Any])
torch._C.__init__._jit_script_compile_overload(qualname:str,overload_decl:Decl,implementation_def:Def,rcb:ResolutionCallback,implementation_defaults:Dict[str,Any],signature:Any)
torch._C.__init__._jit_script_interface_compile(name:str,class_def:ClassDef,rcb:ResolutionCallback,is_module:_bool)
torch._C.__init__._jit_set_emit_hooks(ModuleHook:Optional[Callable],FunctionHook:Optional[Callable])->None
torch._C.__init__._jit_set_inline_everything_mode(enabled:_bool)->None
torch._C.__init__._jit_set_num_profiled_runs(num:_size)->_size
torch._C.__init__._jit_set_nvfuser_enabled(enable:_bool)->_bool
torch._C.__init__._jit_set_profiling_executor(profiling_flag:_bool)->_bool
torch._C.__init__._jit_set_profiling_mode(profiling_flag:_bool)->_bool
torch._C.__init__._jit_set_texpr_fuser_enabled(enable:_bool)
torch._C.__init__._jit_texpr_fuser_enabled()->_bool
torch._C.__init__._jit_try_infer_type(obj:Any)->JitType
torch._C.__init__._jit_unflatten(vars:List[Tensor],desc:IODescriptor)->Any
torch._C.__init__._last_executed_optimized_graph()->Graph
torch._C.__init__._load_for_lite_interpreter(filename:Union[str,Path],map_location:Union[_device,str,None])
torch._C.__init__._load_for_lite_interpreter_from_buffer(buffer:BinaryIO,map_location:Union[_device,str,None])
torch._C.__init__._log_api_usage_once(str)->None
torch._C.__init__._logging_set_logger(logger:LoggerBase)->LoggerBase
torch._C.__init__._nccl_all_gather(input:Sequence[Tensor],output:Sequence[Tensor],streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch._C.__init__._nccl_all_reduce(input:Sequence[Tensor],output:Sequence[Tensor],op:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch._C.__init__._nccl_broadcast(input:Sequence[Tensor],root:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch._C.__init__._nccl_init_rank(nranks:_int,comm_id:bytes,rank:_int)->object
torch._C.__init__._nccl_reduce(input:Sequence[Tensor],output:Tensor,root:_int,op:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch._C.__init__._nccl_reduce_scatter(input:Sequence[Tensor],output:Sequence[Tensor],op:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch._C.__init__._nccl_unique_id()->bytes
torch._C.__init__._nccl_version()->_int
torch._C.__init__._parallel_info()->str
torch._C.__init__._parse_source_def(src:str)->Def
torch._C.__init__._remove_worker_pids(loader_id:_int)->None
torch._C.__init__._replace_overloaded_method_decl(overload_decl:Decl,implementation_def:Def,new_name:str)->Def
torch._C.__init__._resolve_type_from_object(obj:Any,range:SourceRange,rcb:ResolutionCallback)->JitType
torch._C.__init__._run_emit_module_hook(m:ScriptModule)
torch._C.__init__._set_backcompat_broadcast_warn(arg:_bool)->None
torch._C.__init__._set_backcompat_keepdim_warn(arg:_bool)->None
torch._C.__init__._set_cublas_allow_tf32(arg:_bool)->None
torch._C.__init__._set_cudnn_allow_tf32(arg:_bool)->None
torch._C.__init__._set_cudnn_benchmark(arg:_bool)->None
torch._C.__init__._set_cudnn_deterministic(arg:_bool)->None
torch._C.__init__._set_cudnn_enabled(arg:_bool)->None
torch._C.__init__._set_default_dtype(d:_dtype)->None
torch._C.__init__._set_default_tensor_type(type)->None
torch._C.__init__._set_deterministic(arg:_bool)->None
torch._C.__init__._set_grad_enabled(enabled:_bool)->None
torch._C.__init__._set_graph_executor_optimize(optimize:_bool)
torch._C.__init__._set_mkldnn_enabled(arg:_bool)->None
torch._C.__init__._set_qengine(qegine:_int)->None
torch._C.__init__._set_worker_pids(key:_int,child_pids:Tuple[_int,...])->None
torch._C.__init__._set_worker_signal_handlers(*arg:Any)->None
torch._C.__init__._show_config()->str
torch._C.__init__._supported_qengines()->List[_int]
torch._C.__init__._to_dlpack(data:Tensor)->Any
torch._C.__init__._tracer_warn_use_python()
torch._C.__init__._valgrind_supported_platform()->_bool
torch._C.__init__._valgrind_toggle()->None
torch._C.__init__._vmapmode_decrement_nesting()->_int
torch._C.__init__._vmapmode_increment_nesting()->_int
torch._C.__init__.autocast_decrement_nesting()->_int
torch._C.__init__.autocast_increment_nesting()->_int
torch._C.__init__.clear_autocast_cache()->None
torch._C.__init__.device(self,type:str,index:_int)
torch._C.__init__.device.__init__(self,type:str,index:_int)
torch._C.__init__.device.__reduce__(self)->Tuple[Any, ...]
torch._C.__init__.dtype
torch._C.__init__.finfo(self)
torch._C.__init__.finfo.__init__(self)
torch._C.__init__.fork(*args:Any,**kwargs:Any)->Future
torch._C.__init__.get_default_dtype()->_dtype
torch._C.__init__.get_num_interop_threads()->_int
torch._C.__init__.get_num_thread()->_int
torch._C.__init__.iinfo(self,dtype:_dtype)
torch._C.__init__.iinfo.__init__(self,dtype:_dtype)
torch._C.__init__.import_ir_module(cu:CompilationUnit,filename:Union[str,Path],map_location:Union[_device,str,None],extra_files:Dict[str,Any])->ScriptModule
torch._C.__init__.import_ir_module_from_buffer(cu:CompilationUnit,buffer:BinaryIO,map_location:Union[_device,str,None],extra_files:Dict[str,Any])->ScriptModule
torch._C.__init__.is_anomaly_enabled()->_bool
torch._C.__init__.is_autocast_enabled()->_bool
torch._C.__init__.is_grad_enabled()->_bool
torch._C.__init__.layout
torch._C.__init__.memory_format
torch._C.__init__.merge_type_from_type_comment(decl:Decl,type_annotation_decl:Decl,is_method:_bool)->Decl
torch._C.__init__.parse_type_comment(comment:str)->Decl
torch._C.__init__.qscheme
torch._C.__init__.set_anomaly_enabled(enabled:_bool)->None
torch._C.__init__.set_autocast_enabled(enabled:_bool)->None
torch._C.__init__.set_flush_denormal(arg:_bool)->_bool
torch._C.__init__.set_num_interop_threads(nthreads:_int)->None
torch._C.__init__.set_num_threads(nthreads:_int)->None
torch._C.__init__.unify_type_list(types:List[JitType])->JitType
torch._C.__init__.wait(fut:Future)->Any
torch.__init__.BFloat16StorageBase(object)
torch.__init__.BenchmarkConfig(object)
torch.__init__.BenchmarkExecutionStats(object)
torch.__init__.BoolStorageBase(object)
torch.__init__.BoolTensor(Tensor)
torch.__init__.BufferDict(self,mod:ScriptModule)
torch.__init__.ByteStorageBase(object)
torch.__init__.ByteTensor(Tensor)
torch.__init__.CallStack(self,name:str,range:SourceRange)
torch.__init__.CharStorageBase(object)
torch.__init__.CharTensor(Tensor)
torch.__init__.ClassDef(TreeView)
torch.__init__.CompilationUnit(self)
torch.__init__.CompilationUnit.define(self,script:str,rcb:ResolutionCallback)
torch.__init__.CompilationUnit.find_function(self,name:str)->ScriptFunction
torch.__init__.ComplexDoubleStorageBase(object)
torch.__init__.ComplexFloatStorageBase(object)
torch.__init__.Decl(TreeView)
torch.__init__.Def(TreeView)
torch.__init__.Def.name(self)->Ident
torch.__init__.DisableTorchFunction()
torch.__init__.DoubleStorageBase(object)
torch.__init__.DoubleTensor(Tensor)
torch.__init__.ErrorReport(self,range:SourceRange)
torch.__init__.ErrorReport.call_stack()->str
torch.__init__.ErrorReport.what(self)->str
torch.__init__.FileCheck(object)
torch.__init__.FileCheck.check_source_highlighted(self,highlight:str)->'FileCheck'
torch.__init__.FileCheck.run(self,test_string:str)->None
torch.__init__.FloatStorageBase(object)
torch.__init__.FloatTensor(Tensor)
torch.__init__.FunctionSchema
torch.__init__.Future(self)
torch.__init__.Future.done(self)->_bool
torch.__init__.Future.set_result(self,result:Any)->None
torch.__init__.Future.then(self,callback:Callable)->Future
torch.__init__.Future.wait(self)->Any
torch.__init__.Generator(self,device:Union[_device,str,None]=None)
torch.__init__.Generator.get_state(self)->Tensor
torch.__init__.Generator.initial_seed(self)->_int
torch.__init__.Generator.manual_seed(self,seed:_int)->Generator
torch.__init__.Generator.seed(self)->_int
torch.__init__.Generator.set_state(self,_new_state:Tensor)->Generator
torch.__init__.Graph
torch.__init__.HalfStorageBase(object)
torch.__init__.HalfTensor(Tensor)
torch.__init__.IODescriptor
torch.__init__.IValue
torch.__init__.Ident(TreeView)
torch.__init__.Ident.name(self)->str
torch.__init__.IntStorageBase(object)
torch.__init__.IntTensor(Tensor)
torch.__init__.JITException
torch.__init__.LockingLogger(LoggerBase)
torch.__init__.LoggerBase(object)
torch.__init__.LongStorageBase(object)
torch.__init__.LongTensor(Tensor)
torch.__init__.ModuleDict(self,mod:ScriptModule)
torch.__init__.ModuleDict.items(self)->List[Tuple[str, Any]]
torch.__init__.NoopLogger(LoggerBase)
torch.__init__.ParameterDict(self,mod:ScriptModule)
torch.__init__.PyTorchFileReader(self,buffer:BinaryIO)
torch.__init__.PyTorchFileReader.get_record(self,name:str)->bytes
torch.__init__.PyTorchFileWriter(self,buffer:BinaryIO)
torch.__init__.PyTorchFileWriter.write_end_of_file(self)->None
torch.__init__.PyTorchFileWriter.write_record(self,name:str,data:bytes,size:_int)->None
torch.__init__.QInt32StorageBase(object)
torch.__init__.QInt8StorageBase(object)
torch.__init__.QUInt8StorageBase(object)
torch.__init__.ScriptFunction(self,*args,**kwargs)
torch.__init__.ScriptFunction.code(self)->str
torch.__init__.ScriptFunction.graph(self)->Graph
torch.__init__.ScriptFunction.inlined_graph(self)->Graph
torch.__init__.ScriptFunction.name(self)->str
torch.__init__.ScriptFunction.qualified_name(self)->str
torch.__init__.ScriptFunction.save(self,filename:str,_extra_files:Dict[str,bytes])->None
torch.__init__.ScriptFunction.save_to_buffer(self,_extra_files:Dict[str,bytes])->bytes
torch.__init__.ScriptFunction.schema(self)->FunctionSchema
torch.__init__.ScriptMethod
torch.__init__.ScriptModule
torch.__init__.ScriptModule._get_method(self,name:str)->ScriptMethod
torch.__init__.ScriptModule._method_names(self)->List[str]
torch.__init__.ScriptModule.setattr(self,name:str,value:Any)
torch.__init__.ShortStorageBase(object)
torch.__init__.ShortTensor(Tensor)
torch.__init__.Size(Tuple[_int,...])
torch.__init__.Size.__getitem__(self:Size,key:_int)->_int
torch.__init__.Size.__getitem__(self:Size,key:slice)->Size
torch.__init__.Size.numel(self:Size)->_int
torch.__init__.SourceRange
torch.__init__.ThroughputBenchmark(self,module:Any)
torch.__init__.ThroughputBenchmark.add_input(self,*args:Any,**kwargs:Any)->None
torch.__init__.ThroughputBenchmark.benchmark(self,config:BenchmarkConfig)->BenchmarkExecutionStats
torch.__init__.ThroughputBenchmark.run_once(self,*args:Any,**kwargs:Any)->Any
torch.__init__.TracingState
torch.__init__.TreeView
torch.__init__.Value
torch.__init__._CudaDeviceProperties
torch.__init__._CudaEventBase(cls,enable_timing:_bool=False,blocking:_bool=False,interprocess:_bool=False)
torch.__init__._CudaEventBase.elapsed_time(self,other:_CudaEventBase)->_float
torch.__init__._CudaEventBase.from_ipc_handle(cls,device:_device,ipc_handle:bytes)->_CudaEventBase
torch.__init__._CudaEventBase.ipc_handle(self)->bytes
torch.__init__._CudaEventBase.query(self)->_bool
torch.__init__._CudaEventBase.record(self,stream:_CudaStreamBase)->None
torch.__init__._CudaEventBase.synchronize(self)->None
torch.__init__._CudaEventBase.wait(self,stream:_CudaStreamBase)->None
torch.__init__._CudaStreamBase(self,priority:_int=0,_cdata:_int=0)
torch.__init__._CudaStreamBase.priority_range(self)->Tuple[_int, _int]
torch.__init__._CudaStreamBase.query(self)->_bool
torch.__init__._CudaStreamBase.synchronize(self)->None
torch.__init__._FunctionBase(object)
torch.__init__._ImperativeEngine
torch.__init__._LegacyVariableBase(self,data:Optional[Tensor]=...,requires_grad:Optional[_bool]=...,volatile:Optional[_bool]=...,_grad_fn:Optional[_FunctionBase]=...)
torch.__init__._TensorBase(self,size:_size,*,device:Union[_device,str,None]=None)
torch.__init__._TensorBase.__abs__(self)->Tensor
torch.__init__._TensorBase.__add__(self,other:Any)->Tensor
torch.__init__._TensorBase.__and__(self,other:Any)->Tensor
torch.__init__._TensorBase.__and__(self,other:Number)->Tensor
torch.__init__._TensorBase.__and__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__bool__(self)->builtins.bool
torch.__init__._TensorBase.__complex__(self)->builtins.complex
torch.__init__._TensorBase.__div__(self,other:Any)->Tensor
torch.__init__._TensorBase.__eq__(self,other:Any)->Tensor
torch.__init__._TensorBase.__float__(self)->builtins.float
torch.__init__._TensorBase.__floordiv__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ge__(self,other:Any)->Tensor
torch.__init__._TensorBase.__getitem__(self,indices:Union[None,_int,slice,Tensor,List,Tuple])->Tensor
torch.__init__._TensorBase.__gt__(self,other:Any)->Tensor
torch.__init__._TensorBase.__iadd__(self,other:Any)->Tensor
torch.__init__._TensorBase.__iand__(self,other:Any)->Tensor
torch.__init__._TensorBase.__iand__(self,other:Number)->Tensor
torch.__init__._TensorBase.__iand__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__idiv__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ilshift__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ilshift__(self,other:Number)->Tensor
torch.__init__._TensorBase.__ilshift__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__imul__(self,other:Any)->Tensor
torch.__init__._TensorBase.__index__(self)->builtins.int
torch.__init__._TensorBase.__int__(self)->builtins.int
torch.__init__._TensorBase.__invert__(self)->Tensor
torch.__init__._TensorBase.__ior__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ior__(self,other:Number)->Tensor
torch.__init__._TensorBase.__ior__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__irshift__(self,other:Any)->Tensor
torch.__init__._TensorBase.__irshift__(self,other:Number)->Tensor
torch.__init__._TensorBase.__irshift__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__isub__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ixor__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ixor__(self,other:Number)->Tensor
torch.__init__._TensorBase.__ixor__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__le__(self,other:Any)->Tensor
torch.__init__._TensorBase.__long__(self)->builtins.int
torch.__init__._TensorBase.__lshift__(self,other:Any)->Tensor
torch.__init__._TensorBase.__lshift__(self,other:Number)->Tensor
torch.__init__._TensorBase.__lshift__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__lt__(self,other:Any)->Tensor
torch.__init__._TensorBase.__matmul__(self,other:Any)->Tensor
torch.__init__._TensorBase.__mod__(self,other:Any)->Tensor
torch.__init__._TensorBase.__mul__(self,other:Any)->Tensor
torch.__init__._TensorBase.__ne__(self,other:Any)->Tensor
torch.__init__._TensorBase.__neg__(self)->Tensor
torch.__init__._TensorBase.__nonzero__(self)->builtins.bool
torch.__init__._TensorBase.__or__(self,other:Any)->Tensor
torch.__init__._TensorBase.__or__(self,other:Number)->Tensor
torch.__init__._TensorBase.__or__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__pow__(self,other:Any)->Tensor
torch.__init__._TensorBase.__radd__(self,other:Any)->Tensor
torch.__init__._TensorBase.__rfloordiv__(self,other:Any)->Tensor
torch.__init__._TensorBase.__rmul__(self,other:Any)->Tensor
torch.__init__._TensorBase.__rpow__(self,other:Any)->Tensor
torch.__init__._TensorBase.__rshift__(self,other:Any)->Tensor
torch.__init__._TensorBase.__rshift__(self,other:Number)->Tensor
torch.__init__._TensorBase.__rshift__(self,other:Tensor)->Tensor
torch.__init__._TensorBase.__rsub__(self,other:Any)->Tensor
torch.__init__._TensorBase.__rtruediv__(self,other:Any)->Tensor
torch.__init__._TensorBase.__setitem__(self,indices:Union[None,_int,slice,Tensor,List,Tuple],val:Union[Tensor,Number])->None
torch.__init__._TensorBase.__sub__(self,other:Any)->Tensor
torch.__init__._TensorBase.__truediv__(self,other:Any)->Tensor
torch.__init__._TensorBase.__xor__(self,other:Any)->Tensor
torch.__init__._TensorBase.__xor__(self,other:Number)->Tensor
torch.__init__._TensorBase.__xor__(self,other:Tensor)->Tensor
torch.__init__._TensorBase._coalesced_(self,coalesced:_bool)->Tensor
torch.__init__._TensorBase._dimI(self)->_int
torch.__init__._TensorBase._dimV(self)->_int
torch.__init__._TensorBase._indices(self)->Tensor
torch.__init__._TensorBase._nnz(self)->_int
torch.__init__._TensorBase._values(self)->Tensor
torch.__init__._TensorBase.abs(self)->Tensor
torch.__init__._TensorBase.abs_(self)->Tensor
torch.__init__._TensorBase.absolute(self)->Tensor
torch.__init__._TensorBase.absolute_(self)->Tensor
torch.__init__._TensorBase.acos(self)->Tensor
torch.__init__._TensorBase.acos_(self)->Tensor
torch.__init__._TensorBase.acosh(self)->Tensor
torch.__init__._TensorBase.acosh_(self)->Tensor
torch.__init__._TensorBase.add(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.add_(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1)->Tensor
torch.__init__._TensorBase.addbmm(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addbmm_(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addcdiv(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch.__init__._TensorBase.addcdiv_(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch.__init__._TensorBase.addcmul(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch.__init__._TensorBase.addcmul_(self,tensor1:Tensor,tensor2:Tensor,*,value:Number=1)->Tensor
torch.__init__._TensorBase.addmm(self,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addmm_(self,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addmv(self,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addmv_(self,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addr(self,vec1:Tensor,vec2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.addr_(self,vec1:Tensor,vec2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.align_as(self,other:Tensor)->Tensor
torch.__init__._TensorBase.align_to(self,names:Sequence[Union[str,ellipsis,None]])->Tensor
torch.__init__._TensorBase.align_to(self,order:Sequence[Union[str,ellipsis,None]],ellipsis_idx:_int)->Tensor
torch.__init__._TensorBase.all(self)->Tensor
torch.__init__._TensorBase.all(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.all(self,dim:_int,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.allclose(self,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->_bool
torch.__init__._TensorBase.amax(self,dim:Union[_int,_size]=(),keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.amin(self,dim:Union[_int,_size]=(),keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.angle(self)->Tensor
torch.__init__._TensorBase.any(self)->Tensor
torch.__init__._TensorBase.any(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.any(self,dim:_int,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.apply_(self,callable:Callable)->Tensor
torch.__init__._TensorBase.arccos(self)->Tensor
torch.__init__._TensorBase.arccos_(self)->Tensor
torch.__init__._TensorBase.arccosh(self)->Tensor
torch.__init__._TensorBase.arccosh_(self)->Tensor
torch.__init__._TensorBase.arcsin(self)->Tensor
torch.__init__._TensorBase.arcsin_(self)->Tensor
torch.__init__._TensorBase.arcsinh(self)->Tensor
torch.__init__._TensorBase.arcsinh_(self)->Tensor
torch.__init__._TensorBase.arctan(self)->Tensor
torch.__init__._TensorBase.arctan_(self)->Tensor
torch.__init__._TensorBase.arctanh(self)->Tensor
torch.__init__._TensorBase.arctanh_(self)->Tensor
torch.__init__._TensorBase.argmax(self,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.argmin(self,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.argsort(self,dim:Union[str,ellipsis,None],descending:_bool=False)->Tensor
torch.__init__._TensorBase.argsort(self,dim:_int=-1,descending:_bool=False)->Tensor
torch.__init__._TensorBase.as_strided(self,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch.__init__._TensorBase.as_strided_(self,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch.__init__._TensorBase.as_subclass(self,cls:Tensor)->Tensor
torch.__init__._TensorBase.asin(self)->Tensor
torch.__init__._TensorBase.asin_(self)->Tensor
torch.__init__._TensorBase.asinh(self)->Tensor
torch.__init__._TensorBase.asinh_(self)->Tensor
torch.__init__._TensorBase.atan(self)->Tensor
torch.__init__._TensorBase.atan2(self,other:Tensor)->Tensor
torch.__init__._TensorBase.atan2_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.atan_(self)->Tensor
torch.__init__._TensorBase.atanh(self)->Tensor
torch.__init__._TensorBase.atanh_(self)->Tensor
torch.__init__._TensorBase.backward(self,gradient:Optional[Tensor]=None,retain_graph:Optional[_bool]=None,create_graph:_bool=False)->None
torch.__init__._TensorBase.baddbmm(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.baddbmm_(self,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.bernoulli(self,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.bernoulli(self,p:_float,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.bernoulli_(self,p:Tensor,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.bernoulli_(self,p:_float=0.5,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.bfloat16(self)->Tensor
torch.__init__._TensorBase.bincount(self,weights:Optional[Tensor]=None,minlength:_int=0)->Tensor
torch.__init__._TensorBase.bitwise_and(self,other:Number)->Tensor
torch.__init__._TensorBase.bitwise_and(self,other:Tensor)->Tensor
torch.__init__._TensorBase.bitwise_and_(self,other:Number)->Tensor
torch.__init__._TensorBase.bitwise_and_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.bitwise_not(self)->Tensor
torch.__init__._TensorBase.bitwise_not_(self)->Tensor
torch.__init__._TensorBase.bitwise_or(self,other:Number)->Tensor
torch.__init__._TensorBase.bitwise_or(self,other:Tensor)->Tensor
torch.__init__._TensorBase.bitwise_or_(self,other:Number)->Tensor
torch.__init__._TensorBase.bitwise_or_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.bitwise_xor(self,other:Number)->Tensor
torch.__init__._TensorBase.bitwise_xor(self,other:Tensor)->Tensor
torch.__init__._TensorBase.bitwise_xor_(self,other:Number)->Tensor
torch.__init__._TensorBase.bitwise_xor_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.bmm(self,mat2:Tensor)->Tensor
torch.__init__._TensorBase.bool(self)->Tensor
torch.__init__._TensorBase.byte(self)->Tensor
torch.__init__._TensorBase.cauchy_(self,median:_float=0,sigma:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.ceil(self)->Tensor
torch.__init__._TensorBase.ceil_(self)->Tensor
torch.__init__._TensorBase.char(self)->Tensor
torch.__init__._TensorBase.cholesky(self,upper:_bool=False)->Tensor
torch.__init__._TensorBase.cholesky_inverse(self,upper:_bool=False)->Tensor
torch.__init__._TensorBase.cholesky_solve(self,input2:Tensor,upper:_bool=False)->Tensor
torch.__init__._TensorBase.chunk(self,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.clamp(self,min:_float=-inf,max:_float=inf,*,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.clamp_(self,min:_float=-inf,max:_float=inf)->Tensor
torch.__init__._TensorBase.clamp_max(self,max:Number)->Tensor
torch.__init__._TensorBase.clamp_max_(self,max:Number)->Tensor
torch.__init__._TensorBase.clamp_min(self,min:Number)->Tensor
torch.__init__._TensorBase.clamp_min_(self,min:Number)->Tensor
torch.__init__._TensorBase.clip(self,min:Optional[Number]=None,max:Optional[Number]=None)->Tensor
torch.__init__._TensorBase.clip_(self,min:Optional[Number]=None,max:Optional[Number]=None)->Tensor
torch.__init__._TensorBase.clone(self,*,memory_format:Optional[memory_format]=None)->Tensor
torch.__init__._TensorBase.coalesce(self)->Tensor
torch.__init__._TensorBase.conj(self)->Tensor
torch.__init__._TensorBase.contiguous(self,memory_format=torch.contiguous_format)->Tensor
torch.__init__._TensorBase.copy_(self,src:Tensor,non_blocking:_bool=False)->Tensor
torch.__init__._TensorBase.cos(self)->Tensor
torch.__init__._TensorBase.cos_(self)->Tensor
torch.__init__._TensorBase.cosh(self)->Tensor
torch.__init__._TensorBase.cosh_(self)->Tensor
torch.__init__._TensorBase.count_nonzero(self,*dim:_int)->Tensor
torch.__init__._TensorBase.count_nonzero(self,dim:Optional[_int]=None)->Tensor
torch.__init__._TensorBase.count_nonzero(self,dim:_size)->Tensor
torch.__init__._TensorBase.cpu(self)->Tensor
torch.__init__._TensorBase.cross(self,other:Tensor,dim:Optional[_int]=None)->Tensor
torch.__init__._TensorBase.cuda(self,device:Optional[Union[_device,_int,str]]=None,non_blocking:_bool=False)->Tensor
torch.__init__._TensorBase.cummax(self,dim:Union[str,ellipsis,None])->namedtuple_values_indices
torch.__init__._TensorBase.cummax(self,dim:_int)->namedtuple_values_indices
torch.__init__._TensorBase.cummin(self,dim:Union[str,ellipsis,None])->namedtuple_values_indices
torch.__init__._TensorBase.cummin(self,dim:_int)->namedtuple_values_indices
torch.__init__._TensorBase.cumprod(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.cumprod(self,dim:_int,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.cumsum(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.cumsum(self,dim:_int,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.data_ptr(self)->_int
torch.__init__._TensorBase.deg2rad(self)->Tensor
torch.__init__._TensorBase.deg2rad_(self)->Tensor
torch.__init__._TensorBase.dense_dim(self)->_int
torch.__init__._TensorBase.dequantize(self)->Tensor
torch.__init__._TensorBase.det(self)->Tensor
torch.__init__._TensorBase.detach(self)->Tensor
torch.__init__._TensorBase.detach_(self)->Tensor
torch.__init__._TensorBase.diag(self,diagonal:_int=0)->Tensor
torch.__init__._TensorBase.diag_embed(self,offset:_int=0,dim1:_int=-2,dim2:_int=-1)->Tensor
torch.__init__._TensorBase.diagflat(self,offset:_int=0)->Tensor
torch.__init__._TensorBase.diagonal(self,*,outdim:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None],dim2:Union[str,ellipsis,None],offset:_int=0)->Tensor
torch.__init__._TensorBase.diagonal(self,offset:_int=0,dim1:_int=0,dim2:_int=1)->Tensor
torch.__init__._TensorBase.digamma(self)->Tensor
torch.__init__._TensorBase.digamma_(self)->Tensor
torch.__init__._TensorBase.dim(self)->_int
torch.__init__._TensorBase.dist(self,other:Tensor,p:Number=2)->Tensor
torch.__init__._TensorBase.div(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.div_(self,other:Union[Tensor,Number])->Tensor
torch.__init__._TensorBase.divide(self,other:Number)->Tensor
torch.__init__._TensorBase.divide(self,other:Tensor)->Tensor
torch.__init__._TensorBase.divide_(self,other:Number)->Tensor
torch.__init__._TensorBase.divide_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.dot(self,tensor:Tensor)->Tensor
torch.__init__._TensorBase.double(self)->Tensor
torch.__init__._TensorBase.eig(self,eigenvectors:_bool=False)->namedtuple_eigenvalues_eigenvectors
torch.__init__._TensorBase.element_size(self)->_int
torch.__init__._TensorBase.eq(self,other:Number)->Tensor
torch.__init__._TensorBase.eq(self,other:Tensor)->Tensor
torch.__init__._TensorBase.eq_(self,other:Number)->Tensor
torch.__init__._TensorBase.eq_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.equal(self,other:Tensor)->_bool
torch.__init__._TensorBase.erf(self)->Tensor
torch.__init__._TensorBase.erf_(self)->Tensor
torch.__init__._TensorBase.erfc(self)->Tensor
torch.__init__._TensorBase.erfc_(self)->Tensor
torch.__init__._TensorBase.erfinv(self)->Tensor
torch.__init__._TensorBase.erfinv_(self)->Tensor
torch.__init__._TensorBase.exp(self)->Tensor
torch.__init__._TensorBase.exp2(self)->Tensor
torch.__init__._TensorBase.exp2_(self)->Tensor
torch.__init__._TensorBase.exp_(self)->Tensor
torch.__init__._TensorBase.expand(self,*size:_int,implicit:_bool=False)->Tensor
torch.__init__._TensorBase.expand(self,size:_size,*,implicit:_bool=False)->Tensor
torch.__init__._TensorBase.expand_as(self,other:Tensor)->Tensor
torch.__init__._TensorBase.expm1(self)->Tensor
torch.__init__._TensorBase.expm1_(self)->Tensor
torch.__init__._TensorBase.exponential_(self,lambd:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.fft(self,signal_ndim:_int,normalized:_bool=False)->Tensor
torch.__init__._TensorBase.fill_(self,value:Number)->Tensor
torch.__init__._TensorBase.fill_(self,value:Tensor)->Tensor
torch.__init__._TensorBase.fill_diagonal_(self,fill_value:Number,wrap:_bool=False)->Tensor
torch.__init__._TensorBase.fix(self)->Tensor
torch.__init__._TensorBase.fix_(self)->Tensor
torch.__init__._TensorBase.flatten(self,dims:Sequence[Union[str,ellipsis,None]],out_dim:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.flatten(self,start_dim:Union[str,ellipsis,None],end_dim:Union[str,ellipsis,None],out_dim:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.flatten(self,start_dim:_int,end_dim:_int,out_dim:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.flatten(self,start_dim:_int=0,end_dim:_int=-1)->Tensor
torch.__init__._TensorBase.flip(self,*dims:_int)->Tensor
torch.__init__._TensorBase.flip(self,dims:_size)->Tensor
torch.__init__._TensorBase.fliplr(self)->Tensor
torch.__init__._TensorBase.flipud(self)->Tensor
torch.__init__._TensorBase.float(self)->Tensor
torch.__init__._TensorBase.floor(self)->Tensor
torch.__init__._TensorBase.floor_(self)->Tensor
torch.__init__._TensorBase.floor_divide(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.floor_divide_(self,other:Union[Tensor,Number])->Tensor
torch.__init__._TensorBase.fmod(self,other:Number)->Tensor
torch.__init__._TensorBase.fmod(self,other:Tensor)->Tensor
torch.__init__._TensorBase.fmod_(self,other:Number)->Tensor
torch.__init__._TensorBase.fmod_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.frac(self)->Tensor
torch.__init__._TensorBase.frac_(self)->Tensor
torch.__init__._TensorBase.gather(self,dim:Union[str,ellipsis,None],index:Tensor,*,sparse_grad:_bool=False)->Tensor
torch.__init__._TensorBase.gather(self,dim:_int,index:Tensor,*,sparse_grad:_bool=False)->Tensor
torch.__init__._TensorBase.gcd(self,other:Tensor)->Tensor
torch.__init__._TensorBase.gcd_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.ge(self,other:Number)->Tensor
torch.__init__._TensorBase.ge(self,other:Tensor)->Tensor
torch.__init__._TensorBase.ge_(self,other:Number)->Tensor
torch.__init__._TensorBase.ge_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.geometric_(self,p:_float,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.geqrf(self)->namedtuple_a_tau
torch.__init__._TensorBase.ger(self,vec2:Tensor)->Tensor
torch.__init__._TensorBase.get_device(self)->_int
torch.__init__._TensorBase.greater(self,other:Number)->Tensor
torch.__init__._TensorBase.greater(self,other:Tensor)->Tensor
torch.__init__._TensorBase.greater_(self,other:Number)->Tensor
torch.__init__._TensorBase.greater_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.greater_equal(self,other:Number)->Tensor
torch.__init__._TensorBase.greater_equal(self,other:Tensor)->Tensor
torch.__init__._TensorBase.greater_equal_(self,other:Number)->Tensor
torch.__init__._TensorBase.greater_equal_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.gt(self,other:Number)->Tensor
torch.__init__._TensorBase.gt(self,other:Tensor)->Tensor
torch.__init__._TensorBase.gt_(self,other:Number)->Tensor
torch.__init__._TensorBase.gt_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.half(self)->Tensor
torch.__init__._TensorBase.hardshrink(self,lambd:Number=0.5)->Tensor
torch.__init__._TensorBase.heaviside(self,values:Tensor)->Tensor
torch.__init__._TensorBase.heaviside_(self,values:Tensor)->Tensor
torch.__init__._TensorBase.histc(self,bins:_int=100,min:Number=0,max:Number=0)->Tensor
torch.__init__._TensorBase.hypot(self,other:Tensor)->Tensor
torch.__init__._TensorBase.hypot_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.i0(self)->Tensor
torch.__init__._TensorBase.i0_(self)->Tensor
torch.__init__._TensorBase.ifft(self,signal_ndim:_int,normalized:_bool=False)->Tensor
torch.__init__._TensorBase.index_add(self,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_add(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_add_(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_copy(self,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_copy(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_copy_(self,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_copy_(self,dim:_int,index:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.index_fill(self,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.index_fill(self,dim:Union[str,ellipsis,None],index:Tensor,value:Tensor)->Tensor
torch.__init__._TensorBase.index_fill(self,dim:_int,index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.index_fill(self,dim:_int,index:Tensor,value:Tensor)->Tensor
torch.__init__._TensorBase.index_fill_(self,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.index_fill_(self,dim:Union[str,ellipsis,None],index:Tensor,value:Tensor)->Tensor
torch.__init__._TensorBase.index_fill_(self,dim:_int,index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.index_fill_(self,dim:_int,index:Tensor,value:Tensor)->Tensor
torch.__init__._TensorBase.index_put(self,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch.__init__._TensorBase.index_put_(self,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch.__init__._TensorBase.index_select(self,dim:Union[str,ellipsis,None],index:Tensor)->Tensor
torch.__init__._TensorBase.index_select(self,dim:_int,index:Tensor)->Tensor
torch.__init__._TensorBase.indices(self)->Tensor
torch.__init__._TensorBase.int(self)->Tensor
torch.__init__._TensorBase.int_repr(self)->Tensor
torch.__init__._TensorBase.inverse(self)->Tensor
torch.__init__._TensorBase.irfft(self,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True,signal_sizes:_size=())->Tensor
torch.__init__._TensorBase.is_coalesced(self)->_bool
torch.__init__._TensorBase.is_complex(self)->_bool
torch.__init__._TensorBase.is_contiguous(self,memory_format=torch.contiguous_format)->_bool
torch.__init__._TensorBase.is_distributed(self)->_bool
torch.__init__._TensorBase.is_floating_point(self)->_bool
torch.__init__._TensorBase.is_nonzero(self)->_bool
torch.__init__._TensorBase.is_pinned(self)->_bool
torch.__init__._TensorBase.is_same_size(self,other:Tensor)->_bool
torch.__init__._TensorBase.is_set_to(self,tensor:Tensor)->_bool
torch.__init__._TensorBase.is_signed(self)->_bool
torch.__init__._TensorBase.isclose(self,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->Tensor
torch.__init__._TensorBase.isfinite(self)->Tensor
torch.__init__._TensorBase.isinf(self)->Tensor
torch.__init__._TensorBase.isnan(self)->Tensor
torch.__init__._TensorBase.isneginf(self)->Tensor
torch.__init__._TensorBase.isposinf(self)->Tensor
torch.__init__._TensorBase.isreal(self)->Tensor
torch.__init__._TensorBase.item(self)->Number
torch.__init__._TensorBase.kthvalue(self,k:_int,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.kthvalue(self,k:_int,dim:_int=-1,keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.lcm(self,other:Tensor)->Tensor
torch.__init__._TensorBase.lcm_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.le(self,other:Number)->Tensor
torch.__init__._TensorBase.le(self,other:Tensor)->Tensor
torch.__init__._TensorBase.le_(self,other:Number)->Tensor
torch.__init__._TensorBase.le_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.lerp(self,end:Tensor,weight:Number)->Tensor
torch.__init__._TensorBase.lerp(self,end:Tensor,weight:Tensor)->Tensor
torch.__init__._TensorBase.lerp_(self,end:Tensor,weight:Number)->Tensor
torch.__init__._TensorBase.lerp_(self,end:Tensor,weight:Tensor)->Tensor
torch.__init__._TensorBase.less(self,other:Number)->Tensor
torch.__init__._TensorBase.less(self,other:Tensor)->Tensor
torch.__init__._TensorBase.less_(self,other:Number)->Tensor
torch.__init__._TensorBase.less_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.less_equal(self,other:Number)->Tensor
torch.__init__._TensorBase.less_equal(self,other:Tensor)->Tensor
torch.__init__._TensorBase.less_equal_(self,other:Number)->Tensor
torch.__init__._TensorBase.less_equal_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.lgamma(self)->Tensor
torch.__init__._TensorBase.lgamma_(self)->Tensor
torch.__init__._TensorBase.log(self)->Tensor
torch.__init__._TensorBase.log10(self)->Tensor
torch.__init__._TensorBase.log10_(self)->Tensor
torch.__init__._TensorBase.log1p(self)->Tensor
torch.__init__._TensorBase.log1p_(self)->Tensor
torch.__init__._TensorBase.log2(self)->Tensor
torch.__init__._TensorBase.log2_(self)->Tensor
torch.__init__._TensorBase.log_(self)->Tensor
torch.__init__._TensorBase.log_normal_(self,mean:_float=1,std:_float=2,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.log_softmax(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.log_softmax(self,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.logaddexp(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logaddexp2(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logcumsumexp(self,dim:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.logcumsumexp(self,dim:_int)->Tensor
torch.__init__._TensorBase.logdet(self)->Tensor
torch.__init__._TensorBase.logical_and(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logical_and_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logical_not(self)->Tensor
torch.__init__._TensorBase.logical_not_(self)->Tensor
torch.__init__._TensorBase.logical_or(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logical_or_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logical_xor(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logical_xor_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.logit(self,eps:Optional[_float]=None)->Tensor
torch.__init__._TensorBase.logit_(self,eps:Optional[_float]=None)->Tensor
torch.__init__._TensorBase.logsumexp(self,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.logsumexp(self,dim:Union[_int,_size],keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.long(self)->Tensor
torch.__init__._TensorBase.lstsq(self,A:Tensor)->namedtuple_solution_QR
torch.__init__._TensorBase.lt(self,other:Number)->Tensor
torch.__init__._TensorBase.lt(self,other:Tensor)->Tensor
torch.__init__._TensorBase.lt_(self,other:Number)->Tensor
torch.__init__._TensorBase.lt_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.lu_solve(self,LU_data:Tensor,LU_pivots:Tensor)->Tensor
torch.__init__._TensorBase.map_(self,tensor:Tensor,callable:Callable)->Tensor
torch.__init__._TensorBase.masked_fill(self,mask:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.masked_fill(self,mask:Tensor,value:Tensor)->Tensor
torch.__init__._TensorBase.masked_fill_(self,mask:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.masked_fill_(self,mask:Tensor,value:Tensor)->Tensor
torch.__init__._TensorBase.masked_scatter(self,mask:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.masked_scatter_(self,mask:Tensor,source:Tensor)->Tensor
torch.__init__._TensorBase.masked_select(self,mask:Tensor)->Tensor
torch.__init__._TensorBase.matmul(self,other:Tensor)->Tensor
torch.__init__._TensorBase.matrix_exp(self)->Tensor
torch.__init__._TensorBase.matrix_power(self,n:_int)->Tensor
torch.__init__._TensorBase.max(self)->Tensor
torch.__init__._TensorBase.max(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.max(self,dim:_int,keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.max(self,other:Tensor)->Tensor
torch.__init__._TensorBase.maximum(self,other:Tensor)->Tensor
torch.__init__._TensorBase.mean(self,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.mean(self,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.mean(self,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.median(self)->Tensor
torch.__init__._TensorBase.median(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.median(self,dim:_int,keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.min(self)->Tensor
torch.__init__._TensorBase.min(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.min(self,dim:_int,keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.min(self,other:Tensor)->Tensor
torch.__init__._TensorBase.minimum(self,other:Tensor)->Tensor
torch.__init__._TensorBase.mm(self,mat2:Tensor)->Tensor
torch.__init__._TensorBase.mode(self,dim:Union[str,ellipsis,None],keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.mode(self,dim:_int=-1,keepdim:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.movedim(self,source:_int,destination:_int)->Tensor
torch.__init__._TensorBase.movedim(self,source:_size,destination:_size)->Tensor
torch.__init__._TensorBase.mul(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.mul_(self,other:Union[Tensor,Number])->Tensor
torch.__init__._TensorBase.multinomial(self,num_samples:_int,replacement:_bool=False,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.multiply(self,other:Number)->Tensor
torch.__init__._TensorBase.multiply(self,other:Tensor)->Tensor
torch.__init__._TensorBase.multiply_(self,other:Number)->Tensor
torch.__init__._TensorBase.multiply_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.mv(self,vec:Tensor)->Tensor
torch.__init__._TensorBase.mvlgamma(self,p:_int)->Tensor
torch.__init__._TensorBase.mvlgamma_(self,p:_int)->Tensor
torch.__init__._TensorBase.nanquantile(self,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.nanquantile(self,q:_float,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.nansum(self,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.nansum(self,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.narrow(self,dim:_int,start:Tensor,length:_int)->Tensor
torch.__init__._TensorBase.narrow(self,dim:_int,start:_int,length:_int)->Tensor
torch.__init__._TensorBase.narrow_copy(self,dim:_int,start:_int,length:_int)->Tensor
torch.__init__._TensorBase.ndimension(self)->_int
torch.__init__._TensorBase.ne(self,other:Number)->Tensor
torch.__init__._TensorBase.ne(self,other:Tensor)->Tensor
torch.__init__._TensorBase.ne_(self,other:Number)->Tensor
torch.__init__._TensorBase.ne_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.neg(self)->Tensor
torch.__init__._TensorBase.neg_(self)->Tensor
torch.__init__._TensorBase.negative(self)->Tensor
torch.__init__._TensorBase.negative_(self)->Tensor
torch.__init__._TensorBase.nelement(self)->_int
torch.__init__._TensorBase.new(self,*args:Any,device:Union[_device,str,None]=None)->Tensor
torch.__init__._TensorBase.new(self,other:Tensor)->Tensor
torch.__init__._TensorBase.new(self,size:_size,*,device:Union[_device,str,None]=None)->Tensor
torch.__init__._TensorBase.new(self,storage:Storage)->Tensor
torch.__init__._TensorBase.new_empty(self,*size:_int,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.new_empty(self,size:_size,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.new_full(self,size:_size,fill_value:Number,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.new_ones(self,size:_size,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.new_tensor(self,data:Any,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.new_zeros(self,*size:_int,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.new_zeros(self,size:_size,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__init__._TensorBase.nextafter(self,other:Tensor)->Tensor
torch.__init__._TensorBase.nextafter_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.nonzero(self,*,as_tuple:_bool=...)->Tensor
torch.__init__._TensorBase.normal_(self,mean:_float=0,std:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.not_equal(self,other:Number)->Tensor
torch.__init__._TensorBase.not_equal(self,other:Tensor)->Tensor
torch.__init__._TensorBase.not_equal_(self,other:Number)->Tensor
torch.__init__._TensorBase.not_equal_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.numel(self)->_int
torch.__init__._TensorBase.numpy(self)->Any
torch.__init__._TensorBase.orgqr(self,input2:Tensor)->Tensor
torch.__init__._TensorBase.ormqr(self,input2:Tensor,input3:Tensor,left:_bool=True,transpose:_bool=False)->Tensor
torch.__init__._TensorBase.outer(self,vec2:Tensor)->Tensor
torch.__init__._TensorBase.permute(self,*dims:_int)->Tensor
torch.__init__._TensorBase.permute(self,dims:_size)->Tensor
torch.__init__._TensorBase.pin_memory(self)->Tensor
torch.__init__._TensorBase.pinverse(self,rcond:_float=1e-15)->Tensor
torch.__init__._TensorBase.polygamma(self,n:_int)->Tensor
torch.__init__._TensorBase.polygamma_(self,n:_int)->Tensor
torch.__init__._TensorBase.pow(self,exponent:Number)->Tensor
torch.__init__._TensorBase.pow(self,exponent:Tensor)->Tensor
torch.__init__._TensorBase.pow_(self,exponent:Number)->Tensor
torch.__init__._TensorBase.pow_(self,exponent:Tensor)->Tensor
torch.__init__._TensorBase.prelu(self,weight:Tensor)->Tensor
torch.__init__._TensorBase.prod(self,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.prod(self,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.prod(self,dim:_int,keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.put_(self,index:Tensor,source:Tensor,accumulate:_bool=False)->Tensor
torch.__init__._TensorBase.q_per_channel_axis(self)->_int
torch.__init__._TensorBase.q_per_channel_scales(self)->Tensor
torch.__init__._TensorBase.q_per_channel_zero_points(self)->Tensor
torch.__init__._TensorBase.q_scale(self)->_float
torch.__init__._TensorBase.q_zero_point(self)->_int
torch.__init__._TensorBase.qr(self,some:_bool=True)->namedtuple_Q_R
torch.__init__._TensorBase.qscheme(self)->_qscheme
torch.__init__._TensorBase.quantile(self,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.quantile(self,q:_float,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.rad2deg(self)->Tensor
torch.__init__._TensorBase.rad2deg_(self)->Tensor
torch.__init__._TensorBase.random_(self,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.random_(self,from_:_int,to:Optional[_int],*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.random_(self,to:_int,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.reciprocal(self)->Tensor
torch.__init__._TensorBase.reciprocal_(self)->Tensor
torch.__init__._TensorBase.refine_names(self,names:Sequence[Union[str,ellipsis,None]])->Tensor
torch.__init__._TensorBase.relu(self)->Tensor
torch.__init__._TensorBase.relu_(self)->Tensor
torch.__init__._TensorBase.remainder(self,other:Number)->Tensor
torch.__init__._TensorBase.remainder(self,other:Tensor)->Tensor
torch.__init__._TensorBase.remainder_(self,other:Number)->Tensor
torch.__init__._TensorBase.remainder_(self,other:Tensor)->Tensor
torch.__init__._TensorBase.rename(self,names:Optional[Sequence[Union[str,ellipsis,None]]])->Tensor
torch.__init__._TensorBase.rename_(self,names:Optional[Sequence[Union[str,ellipsis,None]]])->Tensor
torch.__init__._TensorBase.renorm(self,p:Number,dim:_int,maxnorm:Number)->Tensor
torch.__init__._TensorBase.renorm_(self,p:Number,dim:_int,maxnorm:Number)->Tensor
torch.__init__._TensorBase.repeat(self,*repeats:_int)->Tensor
torch.__init__._TensorBase.repeat(self,repeats:_size)->Tensor
torch.__init__._TensorBase.repeat_interleave(self,repeats:Tensor,dim:Optional[_int]=None)->Tensor
torch.__init__._TensorBase.repeat_interleave(self,repeats:_int,dim:Optional[_int]=None)->Tensor
torch.__init__._TensorBase.requires_grad_(self,mode:_bool=True)->Tensor
torch.__init__._TensorBase.reshape(self,*shape:_int)->Tensor
torch.__init__._TensorBase.reshape(self,shape:_size)->Tensor
torch.__init__._TensorBase.reshape_as(self,other:Tensor)->Tensor
torch.__init__._TensorBase.resize_(self,*size:_int,memory_format:Optional[memory_format]=None)->Tensor
torch.__init__._TensorBase.resize_(self,size:_size,*,memory_format:Optional[memory_format]=None)->Tensor
torch.__init__._TensorBase.resize_as_(self,the_template:Tensor,*,memory_format:Optional[memory_format]=None)->Tensor
torch.__init__._TensorBase.rfft(self,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True)->Tensor
torch.__init__._TensorBase.roll(self,shifts:Union[_int,_size],dims:Union[_int,_size]=())->Tensor
torch.__init__._TensorBase.rot90(self,k:_int=1,dims:_size=(0,1))->Tensor
torch.__init__._TensorBase.round(self)->Tensor
torch.__init__._TensorBase.round_(self)->Tensor
torch.__init__._TensorBase.rsqrt(self)->Tensor
torch.__init__._TensorBase.rsqrt_(self)->Tensor
torch.__init__._TensorBase.scatter(self,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch.__init__._TensorBase.scatter(self,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.scatter(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch.__init__._TensorBase.scatter(self,dim:_int,index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,src:Tensor,*,reduce:str)->Tensor
torch.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,value:Number)->Tensor
torch.__init__._TensorBase.scatter_(self,dim:_int,index:Tensor,value:Number,*,reduce:str)->Tensor
torch.__init__._TensorBase.scatter_add(self,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch.__init__._TensorBase.scatter_add(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch.__init__._TensorBase.scatter_add_(self,dim:_int,index:Tensor,src:Tensor)->Tensor
torch.__init__._TensorBase.select(self,dim:Union[str,ellipsis,None],index:_int)->Tensor
torch.__init__._TensorBase.select(self,dim:_int,index:_int)->Tensor
torch.__init__._TensorBase.set_(self,storage:Storage)->Tensor
torch.__init__._TensorBase.set_(self,storage:Storage,offset:_int,size:_size,stride:_size)->Tensor
torch.__init__._TensorBase.sgn(self)->Tensor
torch.__init__._TensorBase.sgn_(self)->Tensor
torch.__init__._TensorBase.short(self)->Tensor
torch.__init__._TensorBase.sigmoid(self)->Tensor
torch.__init__._TensorBase.sigmoid_(self)->Tensor
torch.__init__._TensorBase.sign(self)->Tensor
torch.__init__._TensorBase.sign_(self)->Tensor
torch.__init__._TensorBase.signbit(self)->Tensor
torch.__init__._TensorBase.sin(self)->Tensor
torch.__init__._TensorBase.sin_(self)->Tensor
torch.__init__._TensorBase.sinh(self)->Tensor
torch.__init__._TensorBase.sinh_(self)->Tensor
torch.__init__._TensorBase.size(self)->Size
torch.__init__._TensorBase.size(self,_int)->_int
torch.__init__._TensorBase.slogdet(self)->namedtuple_sign_logabsdet
torch.__init__._TensorBase.smm(self,mat2:Tensor)->Tensor
torch.__init__._TensorBase.softmax(self,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.softmax(self,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.solve(self,A:Tensor)->namedtuple_solution_LU
torch.__init__._TensorBase.sort(self,dim:Union[str,ellipsis,None],descending:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.sort(self,dim:_int=-1,descending:_bool=False)->namedtuple_values_indices
torch.__init__._TensorBase.sparse_dim(self)->_int
torch.__init__._TensorBase.sparse_mask(self,mask:Tensor)->Tensor
torch.__init__._TensorBase.sparse_resize_(self,size:_size,sparse_dim:_int,dense_dim:_int)->Tensor
torch.__init__._TensorBase.sparse_resize_and_clear_(self,size:_size,sparse_dim:_int,dense_dim:_int)->Tensor
torch.__init__._TensorBase.split(self,split_size:Tuple[_int,...],dim:_int=0)->Sequence[Tensor]
torch.__init__._TensorBase.split(self,split_size:_int,dim:_int=0)->Sequence[Tensor]
torch.__init__._TensorBase.split_with_sizes(self,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.sqrt(self)->Tensor
torch.__init__._TensorBase.sqrt_(self)->Tensor
torch.__init__._TensorBase.square(self)->Tensor
torch.__init__._TensorBase.square_(self)->Tensor
torch.__init__._TensorBase.squeeze(self)->Tensor
torch.__init__._TensorBase.squeeze(self,dim:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.squeeze(self,dim:_int)->Tensor
torch.__init__._TensorBase.squeeze_(self)->Tensor
torch.__init__._TensorBase.squeeze_(self,dim:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.squeeze_(self,dim:_int)->Tensor
torch.__init__._TensorBase.sspaddmm(self,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.__init__._TensorBase.std(self,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.std(self,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.std(self,unbiased:_bool=True)->Tensor
torch.__init__._TensorBase.storage(self)->Storage
torch.__init__._TensorBase.storage_offset(self)->_int
torch.__init__._TensorBase.stride(self)->Tuple[_int]
torch.__init__._TensorBase.stride(self,_int)->_int
torch.__init__._TensorBase.sub(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.sub_(self,other:Union[Tensor,Number],*,alpha:Optional[Number]=1)->Tensor
torch.__init__._TensorBase.subtract(self,other:Number,alpha:Number=1)->Tensor
torch.__init__._TensorBase.subtract(self,other:Tensor,*,alpha:Number=1)->Tensor
torch.__init__._TensorBase.subtract_(self,other:Number,alpha:Number=1)->Tensor
torch.__init__._TensorBase.subtract_(self,other:Tensor,*,alpha:Number=1)->Tensor
torch.__init__._TensorBase.sum(self,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.sum(self,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.sum(self,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None)->Tensor
torch.__init__._TensorBase.sum_to_size(self,*size:_int)->Tensor
torch.__init__._TensorBase.sum_to_size(self,size:_size)->Tensor
torch.__init__._TensorBase.svd(self,some:_bool=True,compute_uv:_bool=True)->namedtuple_U_S_V
torch.__init__._TensorBase.symeig(self,eigenvectors:_bool=False,upper:_bool=True)->namedtuple_eigenvalues_eigenvectors
torch.__init__._TensorBase.t(self)->Tensor
torch.__init__._TensorBase.t_(self)->Tensor
torch.__init__._TensorBase.take(self,index:Tensor)->Tensor
torch.__init__._TensorBase.tan(self)->Tensor
torch.__init__._TensorBase.tan_(self)->Tensor
torch.__init__._TensorBase.tanh(self)->Tensor
torch.__init__._TensorBase.tanh_(self)->Tensor
torch.__init__._TensorBase.to(self,device:Optional[Union[_device,str]]=None,dtype:Optional[_dtype]=None,non_blocking:_bool=False,copy:_bool=False)->Tensor
torch.__init__._TensorBase.to(self,dtype:_dtype,non_blocking:_bool=False,copy:_bool=False)->Tensor
torch.__init__._TensorBase.to(self,other:Tensor,non_blocking:_bool=False,copy:_bool=False)->Tensor
torch.__init__._TensorBase.to_dense(self)->Tensor
torch.__init__._TensorBase.to_mkldnn(self)->Tensor
torch.__init__._TensorBase.to_sparse(self)->Tensor
torch.__init__._TensorBase.to_sparse(self,sparse_dim:_int)->Tensor
torch.__init__._TensorBase.tolist(self)->List
torch.__init__._TensorBase.topk(self,k:_int,dim:_int=-1,largest:_bool=True,sorted:_bool=True)->namedtuple_values_indices
torch.__init__._TensorBase.trace(self)->Tensor
torch.__init__._TensorBase.transpose(self,dim0:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None])->Tensor
torch.__init__._TensorBase.transpose(self,dim0:_int,dim1:_int)->Tensor
torch.__init__._TensorBase.transpose_(self,dim0:_int,dim1:_int)->Tensor
torch.__init__._TensorBase.triangular_solve(self,A:Tensor,upper:_bool=True,transpose:_bool=False,unitriangular:_bool=False)->namedtuple_solution_cloned_coefficient
torch.__init__._TensorBase.tril(self,diagonal:_int=0)->Tensor
torch.__init__._TensorBase.tril_(self,diagonal:_int=0)->Tensor
torch.__init__._TensorBase.triu(self,diagonal:_int=0)->Tensor
torch.__init__._TensorBase.triu_(self,diagonal:_int=0)->Tensor
torch.__init__._TensorBase.true_divide(self,other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.__init__._TensorBase.true_divide_(self,other:Union[Tensor,Number])->Tensor
torch.__init__._TensorBase.trunc(self)->Tensor
torch.__init__._TensorBase.trunc_(self)->Tensor
torch.__init__._TensorBase.type(self,dtype:None=None,non_blocking:_bool=False)->str
torch.__init__._TensorBase.type(self,dtype:Union[str,_dtype],non_blocking:_bool=False)->Tensor
torch.__init__._TensorBase.type_as(self,other:Tensor)->Tensor
torch.__init__._TensorBase.unbind(self,dim:Union[str,ellipsis,None])->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.unbind(self,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.unflatten(self,dim:Union[str,ellipsis,None],sizes:_size,names:Sequence[Union[str,ellipsis,None]])->Tensor
torch.__init__._TensorBase.unflatten(self,dim:_int,sizes:_size,names:Optional[Sequence[Union[str,ellipsis,None]]]=None)->Tensor
torch.__init__._TensorBase.unfold(self,dimension:_int,size:_int,step:_int)->Tensor
torch.__init__._TensorBase.uniform_(self,from_:_float=0,to:_float=1,*,generator:Optional[Generator]=None)->Tensor
torch.__init__._TensorBase.unsafe_chunk(self,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.unsafe_split(self,split_size:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.unsafe_split_with_sizes(self,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.__init__._TensorBase.unsqueeze(self,dim:_int)->Tensor
torch.__init__._TensorBase.unsqueeze_(self,dim:_int)->Tensor
torch.__init__._TensorBase.values(self)->Tensor
torch.__init__._TensorBase.var(self,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.var(self,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tensor
torch.__init__._TensorBase.var(self,unbiased:_bool=True)->Tensor
torch.__init__._TensorBase.vdot(self,other:Tensor)->Tensor
torch.__init__._TensorBase.view(self,*size:_int)->Tensor
torch.__init__._TensorBase.view(self,size:_size)->Tensor
torch.__init__._TensorBase.view_as(self,other:Tensor)->Tensor
torch.__init__._TensorBase.where(self,condition:Tensor,other:Tensor)->Tensor
torch.__init__._TensorBase.zero_(self)->Tensor
torch.__init__._add_docstr(obj:T,doc_obj:str)->T
torch.__init__._autograd_init()->_bool
torch.__init__._collect_all(futures:List[Future])->Future
torch.__init__._crash_if_aten_asan()->_int
torch.__init__._crash_if_csrc_asan()->_int
torch.__init__._crash_if_csrc_ubsan()->_int
torch.__init__._create_function_from_graph(qualname:str,graph:Graph)->Graph
torch.__init__._create_function_from_trace(qualname:str,func:Callable[...,Any],input_tuple:Tuple[Any,...],var_lookup_fn:Callable[[Tensor],str],strict:_bool,force_outplace:_bool)->Tuple[Graph, Stack]
torch.__init__._create_graph_by_tracing(func:Callable[...,Any],inputs:Any,var_name_lookup_fn:Callable[[Tensor],str],strict:Any,force_outplace:Any,self:Any=None)->Tuple[Graph, Stack]
torch.__init__._create_module_with_type(ty:JitType)->ScriptModule
torch.__init__._cuda_cudaCachingAllocator_raw_alloc(size:_int,cuda_stream:_int)->_int
torch.__init__._cuda_cudaCachingAllocator_raw_delete(ptr:_int)->None
torch.__init__._cuda_cudaHostAllocator()->_int
torch.__init__._cuda_emptyCache()->None
torch.__init__._cuda_getCompiledVersion()->_int
torch.__init__._cuda_getCurrentBlasHandle()->_int
torch.__init__._cuda_getCurrentStream(device:_int)->_int
torch.__init__._cuda_getDefaultStream(device:_int)->_int
torch.__init__._cuda_lock_mutex()->None
torch.__init__._cuda_memorySnapshot()->List[Dict[str, Any]]
torch.__init__._cuda_memoryStats(device:_int)->Dict[str, Any]
torch.__init__._cuda_resetAccumulatedMemoryStats(device:_int)->None
torch.__init__._cuda_resetPeakMemoryStats(device:_int)->None
torch.__init__._cuda_setDevice(device:_int)->None
torch.__init__._cuda_setStream(cuda_stream:_int)->None
torch.__init__._cuda_unlock_mutex()->None
torch.__init__._debug_set_autodiff_subgraph_inlining(disabled:_bool)->None
torch.__init__._demangle(str)->str
torch.__init__._error_if_any_worker_fails()->None
torch.__init__._export_opnames(module:ScriptModule)->List[str]
torch.__init__._freeze_module(module:ScriptModule,preserved_attrs:List[str],freeze_interfaces:_bool=True)->ScriptModule
torch.__init__._from_dlpack(data:Any)->Tensor
torch.__init__._get_backcompat_broadcast_warn()->_bool
torch.__init__._get_backcompat_keepdim_warn()->_bool
torch.__init__._get_cublas_allow_tf32()->_bool
torch.__init__._get_cudnn_allow_tf32()->_bool
torch.__init__._get_cudnn_benchmark()->_bool
torch.__init__._get_cudnn_deterministic()->_bool
torch.__init__._get_cudnn_enabled()->_bool
torch.__init__._get_custom_class_python_wrapper(name:str,attr:str)->Any
torch.__init__._get_default_device()->str
torch.__init__._get_deterministic()->_bool
torch.__init__._get_graph_executor_optimize()->_bool
torch.__init__._get_mkldnn_enabled()->_bool
torch.__init__._get_qengine()->_int
torch.__init__._get_tracing_state()->TracingState
torch.__init__._has_distributed()->_bool
torch.__init__._infer_size(arg1:Size,arg2:Size)->Size
torch.__init__._initExtension(shm_manager_path:str)->None
torch.__init__._init_names(arg:Sequence[Type])->None
torch.__init__._is_tracing()->_bool
torch.__init__._is_xnnpack_enabled()->_bool
torch.__init__._ivalue_tags_match(lhs:ScriptModule,rhs:ScriptModule)->_bool
torch.__init__._jit_can_fuse_on_cpu()->_bool
torch.__init__._jit_can_fuse_on_gpu()->_bool
torch.__init__._jit_clear_class_registry()->None
torch.__init__._jit_flatten(arg:Any)->Tuple[List[Tensor], IODescriptor]
torch.__init__._jit_get_emit_hooks()->Tuple[Callable, Callable]
torch.__init__._jit_get_inline_everything_mode()->_bool
torch.__init__._jit_get_operation(op_name:str)->Callable
torch.__init__._jit_get_schemas_for_operator(name:str)->List[FunctionSchema]
torch.__init__._jit_get_trigger_value(trigger_name:str)->_int
torch.__init__._jit_init()->_bool
torch.__init__._jit_is_script_object(obj:Any)->_bool
torch.__init__._jit_nvfuser_enabled()->_bool
torch.__init__._jit_override_can_fuse_on_cpu(override:_bool)
torch.__init__._jit_override_can_fuse_on_gpu(override:_bool)
torch.__init__._jit_pass_canonicalize(graph:Graph)
torch.__init__._jit_pass_dce(Graph)->None
torch.__init__._jit_pass_erase_shape_information(graph:Graph)
torch.__init__._jit_pass_inline(Graph)->None
torch.__init__._jit_pass_lint(Graph)->None
torch.__init__._jit_pass_optimize_for_mobile(module:'torch.jit.ScriptModule',optimization_blocklist:Set[MobileOptimizerType],preserved_methods:List[AnyStr])->'torch.jit.ScriptModule'
torch.__init__._jit_pass_vulkan_optimize_for_mobile(module:'torch.jit.ScriptModule',preserved_methods:List[AnyStr])->'torch.jit.ScriptModule'
torch.__init__._jit_script_class_compile(qual_name:str,definition:ClassDef,defaults:Dict[str,Dict[str,Any]],rcb:ResolutionCallback)
torch.__init__._jit_script_compile(qual_name:str,definition:Def,rcb:ResolutionCallback,defaults:Dict[str,Any])
torch.__init__._jit_script_compile_overload(qualname:str,overload_decl:Decl,implementation_def:Def,rcb:ResolutionCallback,implementation_defaults:Dict[str,Any],signature:Any)
torch.__init__._jit_script_interface_compile(name:str,class_def:ClassDef,rcb:ResolutionCallback,is_module:_bool)
torch.__init__._jit_set_emit_hooks(ModuleHook:Optional[Callable],FunctionHook:Optional[Callable])->None
torch.__init__._jit_set_inline_everything_mode(enabled:_bool)->None
torch.__init__._jit_set_num_profiled_runs(num:_size)->_size
torch.__init__._jit_set_nvfuser_enabled(enable:_bool)->_bool
torch.__init__._jit_set_profiling_executor(profiling_flag:_bool)->_bool
torch.__init__._jit_set_profiling_mode(profiling_flag:_bool)->_bool
torch.__init__._jit_set_texpr_fuser_enabled(enable:_bool)
torch.__init__._jit_texpr_fuser_enabled()->_bool
torch.__init__._jit_try_infer_type(obj:Any)->JitType
torch.__init__._jit_unflatten(vars:List[Tensor],desc:IODescriptor)->Any
torch.__init__._last_executed_optimized_graph()->Graph
torch.__init__._load_for_lite_interpreter(filename:Union[str,Path],map_location:Union[_device,str,None])
torch.__init__._load_for_lite_interpreter_from_buffer(buffer:BinaryIO,map_location:Union[_device,str,None])
torch.__init__._log_api_usage_once(str)->None
torch.__init__._logging_set_logger(logger:LoggerBase)->LoggerBase
torch.__init__._nccl_all_gather(input:Sequence[Tensor],output:Sequence[Tensor],streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch.__init__._nccl_all_reduce(input:Sequence[Tensor],output:Sequence[Tensor],op:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch.__init__._nccl_broadcast(input:Sequence[Tensor],root:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch.__init__._nccl_init_rank(nranks:_int,comm_id:bytes,rank:_int)->object
torch.__init__._nccl_reduce(input:Sequence[Tensor],output:Tensor,root:_int,op:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch.__init__._nccl_reduce_scatter(input:Sequence[Tensor],output:Sequence[Tensor],op:_int,streams:Optional[Sequence[_CudaStreamBase]],comms:Optional[Sequence[object]])->None
torch.__init__._nccl_unique_id()->bytes
torch.__init__._nccl_version()->_int
torch.__init__._parallel_info()->str
torch.__init__._parse_source_def(src:str)->Def
torch.__init__._remove_worker_pids(loader_id:_int)->None
torch.__init__._replace_overloaded_method_decl(overload_decl:Decl,implementation_def:Def,new_name:str)->Def
torch.__init__._resolve_type_from_object(obj:Any,range:SourceRange,rcb:ResolutionCallback)->JitType
torch.__init__._run_emit_module_hook(m:ScriptModule)
torch.__init__._set_backcompat_broadcast_warn(arg:_bool)->None
torch.__init__._set_backcompat_keepdim_warn(arg:_bool)->None
torch.__init__._set_cublas_allow_tf32(arg:_bool)->None
torch.__init__._set_cudnn_allow_tf32(arg:_bool)->None
torch.__init__._set_cudnn_benchmark(arg:_bool)->None
torch.__init__._set_cudnn_deterministic(arg:_bool)->None
torch.__init__._set_cudnn_enabled(arg:_bool)->None
torch.__init__._set_default_dtype(d:_dtype)->None
torch.__init__._set_default_tensor_type(type)->None
torch.__init__._set_deterministic(arg:_bool)->None
torch.__init__._set_grad_enabled(enabled:_bool)->None
torch.__init__._set_graph_executor_optimize(optimize:_bool)
torch.__init__._set_mkldnn_enabled(arg:_bool)->None
torch.__init__._set_qengine(qegine:_int)->None
torch.__init__._set_worker_pids(key:_int,child_pids:Tuple[_int,...])->None
torch.__init__._set_worker_signal_handlers(*arg:Any)->None
torch.__init__._show_config()->str
torch.__init__._supported_qengines()->List[_int]
torch.__init__._to_dlpack(data:Tensor)->Any
torch.__init__._tracer_warn_use_python()
torch.__init__._valgrind_supported_platform()->_bool
torch.__init__._valgrind_toggle()->None
torch.__init__._vmapmode_decrement_nesting()->_int
torch.__init__._vmapmode_increment_nesting()->_int
torch.__init__.autocast_decrement_nesting()->_int
torch.__init__.autocast_increment_nesting()->_int
torch.__init__.clear_autocast_cache()->None
torch.__init__.device(self,type:str,index:_int)
torch.__init__.device.__reduce__(self)->Tuple[Any, ...]
torch.__init__.dtype
torch.__init__.finfo(self)
torch.__init__.fork(*args:Any,**kwargs:Any)->Future
torch.__init__.get_default_dtype()->_dtype
torch.__init__.get_num_interop_threads()->_int
torch.__init__.get_num_thread()->_int
torch.__init__.iinfo(self,dtype:_dtype)
torch.__init__.import_ir_module(cu:CompilationUnit,filename:Union[str,Path],map_location:Union[_device,str,None],extra_files:Dict[str,Any])->ScriptModule
torch.__init__.import_ir_module_from_buffer(cu:CompilationUnit,buffer:BinaryIO,map_location:Union[_device,str,None],extra_files:Dict[str,Any])->ScriptModule
torch.__init__.is_anomaly_enabled()->_bool
torch.__init__.is_autocast_enabled()->_bool
torch.__init__.is_grad_enabled()->_bool
torch.__init__.layout
torch.__init__.memory_format
torch.__init__.merge_type_from_type_comment(decl:Decl,type_annotation_decl:Decl,is_method:_bool)->Decl
torch.__init__.parse_type_comment(comment:str)->Decl
torch.__init__.qscheme
torch.__init__.set_anomaly_enabled(enabled:_bool)->None
torch.__init__.set_autocast_enabled(enabled:_bool)->None
torch.__init__.set_flush_denormal(arg:_bool)->_bool
torch.__init__.set_num_interop_threads(nthreads:_int)->None
torch.__init__.set_num_threads(nthreads:_int)->None
torch.__init__.unify_type_list(types:List[JitType])->JitType
torch.__init__.wait(fut:Future)->Any


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_VariableFunctions.pyi----------------------------------------
torch._C._VariableFunctions.__and__(input:Tensor,other:Number)->Tensor
torch._C._VariableFunctions.__and__(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.__lshift__(input:Tensor,other:Number)->Tensor
torch._C._VariableFunctions.__lshift__(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.__or__(input:Tensor,other:Number)->Tensor
torch._C._VariableFunctions.__or__(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.__rshift__(input:Tensor,other:Number)->Tensor
torch._C._VariableFunctions.__rshift__(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.__xor__(input:Tensor,other:Number)->Tensor
torch._C._VariableFunctions.__xor__(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions._adaptive_avg_pool2d(input:Tensor,output_size:Union[_int,_size])->Tensor
torch._C._VariableFunctions._add_batch_dim(input:Tensor,batch_dim:_int,level:_int)->Tensor
torch._C._VariableFunctions._add_relu(input:Tensor,other:Tensor,*,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions._add_relu_(input:Tensor,other:Tensor,*,alpha:Number=1)->Tensor
torch._C._VariableFunctions._addmv_impl_(input:Tensor,self2:Tensor,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C._VariableFunctions._aminmax(input:Tensor)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._aminmax(input:Tensor,dim:_int,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._amp_non_finite_check_and_unscale_(input:Tensor,found_inf:Tensor,inv_scale:Tensor)->None
torch._C._VariableFunctions._amp_update_scale(growth_tracker:Tensor,current_scale:Tensor,found_inf:Tensor,scale_growth_factor:_float,scale_backoff_factor:_float,growth_interval:_int)->Tensor
torch._C._VariableFunctions._baddbmm_mkl_(input:Tensor,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C._VariableFunctions._batch_norm_impl_index(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,momentum:_float,eps:_float,cudnn_enabled:_bool)->Tuple[Tensor, Tensor, Tensor, Tensor, _int]
torch._C._VariableFunctions._bmm(input:Tensor,mat2:Tensor,*,deterministic:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions._cast_Byte(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Char(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Double(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Float(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Half(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Int(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Long(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cast_Short(input:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._cat(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions._choose_qparams_per_tensor(input:Tensor,reduce_range:_bool=False)->Tuple[_float, _int]
torch._C._VariableFunctions._compute_linear_combination(input:Tensor,coefficients:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions._conj(input:Tensor)->Tensor
torch._C._VariableFunctions._convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size,groups:_int,benchmark:_bool,deterministic:_bool,cudnn_enabled:_bool)->Tensor
torch._C._VariableFunctions._convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size,groups:_int,benchmark:_bool,deterministic:_bool,cudnn_enabled:_bool,allow_tf32:_bool)->Tensor
torch._C._VariableFunctions._convolution_nogroup(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size)->Tensor
torch._C._VariableFunctions._copy_from(input:Tensor,dst:Tensor,non_blocking:_bool=False)->Tensor
torch._C._VariableFunctions._ctc_loss(log_probs:Tensor,targets:Tensor,input_lengths:_size,target_lengths:_size,blank:_int=0,zero_infinity:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._cudnn_ctc_loss(log_probs:Tensor,targets:Tensor,input_lengths:_size,target_lengths:_size,blank:_int,deterministic:_bool,zero_infinity:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._cudnn_init_dropout_state(dropout:_float,train:_bool,dropout_seed:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions._cudnn_rnn(input:Tensor,weight:Union[Tuple[Tensor,...],List[Tensor]],weight_stride0:_int,weight_buf:Optional[Tensor],hx:Tensor,cx:Optional[Tensor],mode:_int,hidden_size:_int,num_layers:_int,batch_first:_bool,dropout:_float,train:_bool,bidirectional:_bool,batch_sizes:_size,dropout_state:Optional[Tensor])->Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions._cudnn_rnn_flatten_weight(weight_arr:Union[Tuple[Tensor,...],List[Tensor]],weight_stride0:_int,input_size:_int,mode:_int,hidden_size:_int,num_layers:_int,batch_first:_bool,bidirectional:_bool)->Tensor
torch._C._VariableFunctions._cufft_clear_plan_cache(device_index:_int)->None
torch._C._VariableFunctions._cufft_get_plan_cache_max_size(device_index:_int)->_int
torch._C._VariableFunctions._cufft_get_plan_cache_size(device_index:_int)->_int
torch._C._VariableFunctions._cufft_set_plan_cache_max_size(device_index:_int,max_size:_int)->None
torch._C._VariableFunctions._cummax_helper(input:Tensor,values:Tensor,indices:Tensor,dim:_int)->None
torch._C._VariableFunctions._cummin_helper(input:Tensor,values:Tensor,indices:Tensor,dim:_int)->None
torch._C._VariableFunctions._debug_has_internal_overlap(input:Tensor)->_int
torch._C._VariableFunctions._dim_arange(like:Tensor,dim:_int)->Tensor
torch._C._VariableFunctions._dirichlet_grad(x:Tensor,alpha:Tensor,total:Tensor)->Tensor
torch._C._VariableFunctions._embedding_bag(weight:Tensor,indices:Tensor,offsets:Tensor,scale_grad_by_freq:_bool=False,mode:_int=0,sparse:_bool=False,per_sample_weights:Optional[Tensor]=None,include_last_offset:_bool=False)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions._embedding_bag_forward_only(weight:Tensor,indices:Tensor,offsets:Tensor,scale_grad_by_freq:_bool=False,mode:_int=0,sparse:_bool=False,per_sample_weights:Optional[Tensor]=None,include_last_offset:_bool=False)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions._empty_affine_quantized(*size:_int,scale:_float=1,zero_point:_int=0,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions._empty_affine_quantized(size:_size,*,scale:_float=1,zero_point:_int=0,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions._empty_per_channel_affine_quantized(*size:_int,scales:Tensor,zero_points:Tensor,axis:_int,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions._empty_per_channel_affine_quantized(size:_size,*,scales:Tensor,zero_points:Tensor,axis:_int,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions._euclidean_dist(x1:Tensor,x2:Tensor)->Tensor
torch._C._VariableFunctions._fake_quantize_learnable_per_channel_affine(input:Tensor,scale:Tensor,zero_point:Tensor,axis:_int,quant_min:_int,quant_max:_int)->Tensor
torch._C._VariableFunctions._fake_quantize_learnable_per_tensor_affine(input:Tensor,scale:Tensor,zero_point:Tensor,quant_min:_int,quant_max:_int)->Tensor
torch._C._VariableFunctions._fft_with_size(input:Tensor,signal_ndim:_int,complex_input:_bool,complex_output:_bool,inverse:_bool,checked_signal_sizes:_size,normalization:_int,onesided:_bool,output_sizes:_size)->Tensor
torch._C._VariableFunctions._fft_with_size(input:Tensor,signal_ndim:_int,complex_input:_bool,complex_output:_bool,inverse:_bool,checked_signal_sizes:_size,normalized:_bool,onesided:_bool,output_sizes:_size)->Tensor
torch._C._VariableFunctions._foreach_add(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_add(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_add_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->None
torch._C._VariableFunctions._foreach_add_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._C._VariableFunctions._foreach_add_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_add_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._C._VariableFunctions._foreach_addcdiv(input:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_addcdiv_(self:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->None
torch._C._VariableFunctions._foreach_addcmul(input:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_addcmul_(self:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->None
torch._C._VariableFunctions._foreach_div(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_div(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_div_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._C._VariableFunctions._foreach_div_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._C._VariableFunctions._foreach_div_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_div_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._C._VariableFunctions._foreach_exp(tensors:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_exp_(self:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._C._VariableFunctions._foreach_mul(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_mul(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_mul_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._C._VariableFunctions._foreach_mul_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._C._VariableFunctions._foreach_mul_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_mul_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._C._VariableFunctions._foreach_sqrt(tensors:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_sqrt_(self:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._C._VariableFunctions._foreach_sub(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_sub(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_sub_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->None
torch._C._VariableFunctions._foreach_sub_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._C._VariableFunctions._foreach_sub_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions._foreach_sub_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._C._VariableFunctions._fused_dropout(input:Tensor,p:_float,generator:Optional[Generator]=None)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._grid_sampler_2d_cpu_fallback(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch._C._VariableFunctions._has_compatible_shallow_copy_type(input:Tensor,from_:Tensor)->_bool
torch._C._VariableFunctions._index_copy_(input:Tensor,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C._VariableFunctions._index_put_impl_(input:Tensor,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False,unsafe:_bool=False)->Tensor
torch._C._VariableFunctions._log_softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._C._VariableFunctions._log_softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._C._VariableFunctions._logcumsumexp(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions._lu_solve_helper(input:Tensor,LU_data:Tensor,LU_pivots:Tensor)->Tensor
torch._C._VariableFunctions._lu_with_info(input:Tensor,pivot:_bool=True,check_errors:_bool=True)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions._make_per_channel_quantized_tensor(input:Tensor,scale:Tensor,zero_point:Tensor,axis:_int)->Tensor
torch._C._VariableFunctions._make_per_tensor_quantized_tensor(input:Tensor,scale:_float,zero_point:_int)->Tensor
torch._C._VariableFunctions._masked_scale(input:Tensor,mask:Tensor,scale:_float)->Tensor
torch._C._VariableFunctions._mkldnn_reshape(input:Tensor,shape:_size)->Tensor
torch._C._VariableFunctions._mkldnn_transpose(input:Tensor,dim0:_int,dim1:_int)->Tensor
torch._C._VariableFunctions._mkldnn_transpose_(input:Tensor,dim0:_int,dim1:_int)->Tensor
torch._C._VariableFunctions._mode(input:Tensor,dim:_int=-1,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._multinomial_alias_draw(J:Tensor,q:Tensor,num_samples:_int,*,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions._multinomial_alias_setup(probs:Tensor)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._nnpack_available()->_bool
torch._C._VariableFunctions._nnpack_spatial_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:Union[_int,_size],stride:Union[_int,_size]=1)->Tensor
torch._C._VariableFunctions._pack_padded_sequence(input:Tensor,lengths:Tensor,batch_first:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._pad_packed_sequence(data:Tensor,batch_sizes:Tensor,batch_first:_bool,padding_value:Number,total_length:_int)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._remove_batch_dim(input:Tensor,level:_int,batch_size:_int,out_dim:_int)->Tensor
torch._C._VariableFunctions._reshape_from_tensor(input:Tensor,shape:Tensor)->Tensor
torch._C._VariableFunctions._s_where(condition:Tensor,input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions._sample_dirichlet(input:Tensor,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions._saturate_weight_to_fp16(weight:Tensor)->Tensor
torch._C._VariableFunctions._shape_as_tensor(input:Tensor)->Tensor
torch._C._VariableFunctions._sobol_engine_draw(quasi:Tensor,n:_int,sobolstate:Tensor,dimension:_int,num_generated:_int,dtype:Optional[_dtype])->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._sobol_engine_ff_(input:Tensor,n:_int,sobolstate:Tensor,dimension:_int,num_generated:_int)->Tensor
torch._C._VariableFunctions._sobol_engine_initialize_state_(input:Tensor,dimension:_int)->Tensor
torch._C._VariableFunctions._sobol_engine_scramble_(input:Tensor,ltm:Tensor,dimension:_int)->Tensor
torch._C._VariableFunctions._softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._C._VariableFunctions._softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._C._VariableFunctions._sparse_addmm(input:Tensor,sparse:Tensor,dense:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C._VariableFunctions._sparse_log_softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions._sparse_log_softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions._sparse_log_softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._C._VariableFunctions._sparse_log_softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._C._VariableFunctions._sparse_mm(sparse:Tensor,dense:Tensor)->Tensor
torch._C._VariableFunctions._sparse_softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions._sparse_softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions._sparse_softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._C._VariableFunctions._sparse_softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._C._VariableFunctions._sparse_sum(input:Tensor)->Tensor
torch._C._VariableFunctions._sparse_sum(input:Tensor,*,dtype:_dtype)->Tensor
torch._C._VariableFunctions._sparse_sum(input:Tensor,dim:Union[_int,_size])->Tensor
torch._C._VariableFunctions._sparse_sum(input:Tensor,dim:Union[_int,_size],*,dtype:_dtype)->Tensor
torch._C._VariableFunctions._standard_gamma(input:Tensor,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions._standard_gamma_grad(input:Tensor,output:Tensor)->Tensor
torch._C._VariableFunctions._std(input:Tensor,unbiased:_bool=True)->Tensor
torch._C._VariableFunctions._test_serialization_subcmul(input:Tensor,other:Tensor,alpha:Number=1)->Tensor
torch._C._VariableFunctions._trilinear(i1:Tensor,i2:Tensor,i3:Tensor,expand1:_size,expand2:_size,expand3:_size,sumdim:_size,unroll_dim:_int=1)->Tensor
torch._C._VariableFunctions._unique(input:Tensor,sorted:_bool=True,return_inverse:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions._unique2(input:Tensor,sorted:_bool=True,return_inverse:_bool=False,return_counts:_bool=False)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions._use_cudnn_ctc_loss(log_probs:Tensor,targets:Tensor,input_lengths:_size,target_lengths:_size,blank:_int)->_bool
torch._C._VariableFunctions._use_cudnn_rnn_flatten_weight()->_bool
torch._C._VariableFunctions._validate_sparse_coo_tensor_args(indices:Tensor,values:Tensor,size:_size)->None
torch._C._VariableFunctions._var(input:Tensor,unbiased:_bool=True)->Tensor
torch._C._VariableFunctions._weight_norm(v:Tensor,g:Tensor,dim:_int=0)->Tensor
torch._C._VariableFunctions._weight_norm_cuda_interface(v:Tensor,g:Tensor,dim:_int=0)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.abs(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.abs_(input:Tensor)->Tensor
torch._C._VariableFunctions.absolute(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.acos(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.acos_(input:Tensor)->Tensor
torch._C._VariableFunctions.acosh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.acosh_(input:Tensor)->Tensor
torch._C._VariableFunctions.adaptive_avg_pool1d(input:Tensor,output_size:Union[_int,_size])->Tensor
torch._C._VariableFunctions.adaptive_max_pool1d(input:Tensor,output_size:Union[_int,_size])->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.add(input:Union[Tensor,Number],other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.add(self:Tensor,alpha:Number,other:Tensor)->Tensor
torch._C._VariableFunctions.add(self:Tensor,alpha:Number,other:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor)->Tensor
torch._C._VariableFunctions.addbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor)->Tensor
torch._C._VariableFunctions.addbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addbmm(input:Tensor,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.addcdiv(input:Tensor,tensor1:Tensor,tensor2:Tensor,*,value:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.addcdiv(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor)->Tensor
torch._C._VariableFunctions.addcdiv(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addcmul(input:Tensor,tensor1:Tensor,tensor2:Tensor,*,value:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.addcmul(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor)->Tensor
torch._C._VariableFunctions.addcmul(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addmm(beta:Number,self:Tensor,alpha:Number,mat1:Tensor,mat2:Tensor)->Tensor
torch._C._VariableFunctions.addmm(beta:Number,self:Tensor,alpha:Number,mat1:Tensor,mat2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addmm(beta:Number,self:Tensor,mat1:Tensor,mat2:Tensor)->Tensor
torch._C._VariableFunctions.addmm(beta:Number,self:Tensor,mat1:Tensor,mat2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addmm(input:Tensor,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.addmv(beta:Number,self:Tensor,alpha:Number,mat:Tensor,vec:Tensor)->Tensor
torch._C._VariableFunctions.addmv(beta:Number,self:Tensor,alpha:Number,mat:Tensor,vec:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addmv(beta:Number,self:Tensor,mat:Tensor,vec:Tensor)->Tensor
torch._C._VariableFunctions.addmv(beta:Number,self:Tensor,mat:Tensor,vec:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addmv(input:Tensor,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.addmv_(input:Tensor,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._C._VariableFunctions.addr(beta:Number,self:Tensor,alpha:Number,vec1:Tensor,vec2:Tensor)->Tensor
torch._C._VariableFunctions.addr(beta:Number,self:Tensor,alpha:Number,vec1:Tensor,vec2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addr(beta:Number,self:Tensor,vec1:Tensor,vec2:Tensor)->Tensor
torch._C._VariableFunctions.addr(beta:Number,self:Tensor,vec1:Tensor,vec2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.addr(input:Tensor,vec1:Tensor,vec2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.affine_grid_generator(theta:Tensor,size:_size,align_corners:_bool)->Tensor
torch._C._VariableFunctions.all(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.all(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.all(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.allclose(input:Tensor,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->_bool
torch._C._VariableFunctions.alpha_dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.alpha_dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.amax(input:Tensor,dim:Union[_int,_size]=(),keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.amin(input:Tensor,dim:Union[_int,_size]=(),keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.angle(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.any(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.any(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.any(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arange(end:Number,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.arange(start:Number,end:Number,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.arange(start:Number,end:Number,step:Number,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.arccos(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arccos_(input:Tensor)->Tensor
torch._C._VariableFunctions.arccosh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arccosh_(input:Tensor)->Tensor
torch._C._VariableFunctions.arcsin(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arcsin_(input:Tensor)->Tensor
torch._C._VariableFunctions.arcsinh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arcsinh_(input:Tensor)->Tensor
torch._C._VariableFunctions.arctan(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arctan_(input:Tensor)->Tensor
torch._C._VariableFunctions.arctanh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.arctanh_(input:Tensor)->Tensor
torch._C._VariableFunctions.argmax(input:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C._VariableFunctions.argmin(input:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch._C._VariableFunctions.argsort(input:Tensor,dim:Union[str,ellipsis,None],descending:_bool=False)->Tensor
torch._C._VariableFunctions.argsort(input:Tensor,dim:_int=-1,descending:_bool=False)->Tensor
torch._C._VariableFunctions.as_strided(input:Tensor,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch._C._VariableFunctions.as_strided_(input:Tensor,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch._C._VariableFunctions.as_tensor(data:Any,dtype:_dtype=None,device:Optional[_device]=None)->Tensor
torch._C._VariableFunctions.asin(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.asin_(input:Tensor)->Tensor
torch._C._VariableFunctions.asinh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.asinh_(input:Tensor)->Tensor
torch._C._VariableFunctions.atan(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.atan2(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.atan_(input:Tensor)->Tensor
torch._C._VariableFunctions.atanh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.atanh_(input:Tensor)->Tensor
torch._C._VariableFunctions.avg_pool1d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,ceil_mode:_bool=False,count_include_pad:_bool=True)->Tensor
torch._C._VariableFunctions.baddbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor)->Tensor
torch._C._VariableFunctions.baddbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.baddbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor)->Tensor
torch._C._VariableFunctions.baddbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.baddbmm(input:Tensor,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bartlett_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.bartlett_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.batch_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,momentum:_float,eps:_float,cudnn_enabled:_bool)->Tensor
torch._C._VariableFunctions.batch_norm_backward_elemt(grad_out:Tensor,input:Tensor,mean:Tensor,invstd:Tensor,weight:Optional[Tensor],mean_dy:Tensor,mean_dy_xmu:Tensor)->Tensor
torch._C._VariableFunctions.batch_norm_backward_reduce(grad_out:Tensor,input:Tensor,mean:Tensor,invstd:Tensor,weight:Optional[Tensor],input_g:_bool,weight_g:_bool,bias_g:_bool)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions.batch_norm_elemt(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],mean:Tensor,invstd:Tensor,eps:_float,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.batch_norm_gather_stats(input:Tensor,mean:Tensor,invstd:Tensor,running_mean:Optional[Tensor],running_var:Optional[Tensor],momentum:_float,eps:_float,count:_int)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.batch_norm_gather_stats_with_counts(input:Tensor,mean:Tensor,invstd:Tensor,running_mean:Optional[Tensor],running_var:Optional[Tensor],momentum:_float,eps:_float,counts:Tensor)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.batch_norm_stats(input:Tensor,eps:_float)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.batch_norm_update_stats(input:Tensor,running_mean:Optional[Tensor],running_var:Optional[Tensor],momentum:_float)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.bernoulli(input:Tensor,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bernoulli(input:Tensor,p:_float,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bilinear(input1:Tensor,input2:Tensor,weight:Tensor,bias:Optional[Tensor])->Tensor
torch._C._VariableFunctions.bincount(input:Tensor,weights:Optional[Tensor]=None,minlength:_int=0)->Tensor
torch._C._VariableFunctions.binomial(count:Tensor,prob:Tensor,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions.bitwise_and(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bitwise_and(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bitwise_not(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bitwise_or(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bitwise_or(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bitwise_xor(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bitwise_xor(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.blackman_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.blackman_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.bmm(input:Tensor,mat2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bucketize(input:Tensor,boundaries:Tensor,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.bucketize(self:Number,boundaries:Tensor,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.can_cast(from_:_dtype,to:_dtype)->_bool
torch._C._VariableFunctions.cat(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cat(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.ceil(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.ceil_(input:Tensor)->Tensor
torch._C._VariableFunctions.celu(input:Tensor,alpha:Number=1.0)->Tensor
torch._C._VariableFunctions.celu_(input:Tensor,alpha:Number=1.0)->Tensor
torch._C._VariableFunctions.channel_shuffle(input:Tensor,groups:_int)->Tensor
torch._C._VariableFunctions.cholesky(input:Tensor,upper:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cholesky_inverse(input:Tensor,upper:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cholesky_solve(input:Tensor,input2:Tensor,upper:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.choose_qparams_optimized(input:Tensor,numel:_int,n_bins:_int,ratio:_float,bit_width:_int)->Tuple[_float, _float]
torch._C._VariableFunctions.chunk(input:Tensor,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.clamp(self,min:_float=-inf,max:_float=inf,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.clamp_max(input:Tensor,max:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.clamp_max_(input:Tensor,max:Number)->Tensor
torch._C._VariableFunctions.clamp_min(input:Tensor,min:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.clamp_min_(input:Tensor,min:Number)->Tensor
torch._C._VariableFunctions.clip(input:Tensor,min:Optional[Number]=None,max:Optional[Number]=None,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.clip_(input:Tensor,min:Optional[Number]=None,max:Optional[Number]=None)->Tensor
torch._C._VariableFunctions.clone(input:Tensor,*,memory_format:Optional[memory_format]=None)->Tensor
torch._C._VariableFunctions.combinations(input:Tensor,r:_int=2,with_replacement:_bool=False)->Tensor
torch._C._VariableFunctions.complex(real:Tensor,imag:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.conj(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.constant_pad_nd(input:Tensor,pad:_size,value:Number=0)->Tensor
torch._C._VariableFunctions.conv1d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,groups:_int=1)->Tensor
torch._C._VariableFunctions.conv2d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,groups:_int=1)->Tensor
torch._C._VariableFunctions.conv3d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,groups:_int=1)->Tensor
torch._C._VariableFunctions.conv_tbc(input:Tensor,weight:Tensor,bias:Tensor,pad:_int=0)->Tensor
torch._C._VariableFunctions.conv_transpose1d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,output_padding:Union[_int,_size]=0,groups:_int=1,dilation:Union[_int,_size]=1)->Tensor
torch._C._VariableFunctions.conv_transpose2d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,output_padding:Union[_int,_size]=0,groups:_int=1,dilation:Union[_int,_size]=1)->Tensor
torch._C._VariableFunctions.conv_transpose3d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,output_padding:Union[_int,_size]=0,groups:_int=1,dilation:Union[_int,_size]=1)->Tensor
torch._C._VariableFunctions.convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size,groups:_int)->Tensor
torch._C._VariableFunctions.cos(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cos_(input:Tensor)->Tensor
torch._C._VariableFunctions.cosh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cosh_(input:Tensor)->Tensor
torch._C._VariableFunctions.cosine_similarity(x1:Tensor,x2:Tensor,dim:_int=1,eps:_float=1e-08)->Tensor
torch._C._VariableFunctions.count_nonzero(input:Tensor,dim:Optional[_int]=None)->Tensor
torch._C._VariableFunctions.count_nonzero(input:Tensor,dim:_size)->Tensor
torch._C._VariableFunctions.cross(input:Tensor,other:Tensor,dim:Optional[_int]=None,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cudnn_affine_grid_generator(theta:Tensor,N:_int,C:_int,H:_int,W:_int)->Tensor
torch._C._VariableFunctions.cudnn_batch_norm(input:Tensor,weight:Tensor,bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,exponential_average_factor:_float,epsilon:_float)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions.cudnn_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.cudnn_convolution(input:Tensor,weight:Tensor,padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.cudnn_convolution(input:Tensor,weight:Tensor,padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool,allow_tf32:_bool)->Tensor
torch._C._VariableFunctions.cudnn_convolution_transpose(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.cudnn_convolution_transpose(input:Tensor,weight:Tensor,padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.cudnn_convolution_transpose(input:Tensor,weight:Tensor,padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool,allow_tf32:_bool)->Tensor
torch._C._VariableFunctions.cudnn_grid_sampler(input:Tensor,grid:Tensor)->Tensor
torch._C._VariableFunctions.cudnn_is_acceptable(input:Tensor)->_bool
torch._C._VariableFunctions.cummax(input:Tensor,dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.cummax(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.cummin(input:Tensor,dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.cummin(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.cumprod(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cumprod(input:Tensor,dim:_int,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cumsum(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.cumsum(input:Tensor,dim:_int,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.deg2rad(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.deg2rad_(input:Tensor)->Tensor
torch._C._VariableFunctions.dequantize(input:Tensor)->Tensor
torch._C._VariableFunctions.dequantize(tensors:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.det(input:Tensor)->Tensor
torch._C._VariableFunctions.detach(input:Tensor)->Tensor
torch._C._VariableFunctions.detach_(input:Tensor)->Tensor
torch._C._VariableFunctions.diag(input:Tensor,diagonal:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.diag_embed(input:Tensor,offset:_int=0,dim1:_int=-2,dim2:_int=-1)->Tensor
torch._C._VariableFunctions.diagflat(input:Tensor,offset:_int=0)->Tensor
torch._C._VariableFunctions.diagonal(input:Tensor,*,outdim:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None],dim2:Union[str,ellipsis,None],offset:_int=0)->Tensor
torch._C._VariableFunctions.diagonal(input:Tensor,offset:_int=0,dim1:_int=0,dim2:_int=1)->Tensor
torch._C._VariableFunctions.digamma(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.dist(input:Tensor,other:Tensor,p:Number=2)->Tensor
torch._C._VariableFunctions.div(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.divide(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.divide(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.dot(input:Tensor,tensor:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.dstack(tensors:Union[Tuple[Tensor,...],List[Tensor]],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.eig(input:Tensor,eigenvectors:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_eigenvalues_eigenvectors
torch._C._VariableFunctions.embedding(weight:Tensor,indices:Tensor,padding_idx:_int=-1,scale_grad_by_freq:_bool=False,sparse:_bool=False)->Tensor
torch._C._VariableFunctions.embedding_bag(weight:Tensor,indices:Tensor,offsets:Tensor,scale_grad_by_freq:_bool=False,mode:_int=0,sparse:_bool=False,per_sample_weights:Optional[Tensor]=None,include_last_offset:_bool=False)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions.embedding_renorm_(input:Tensor,indices:Tensor,max_norm:_float,norm_type:_float)->Tensor
torch._C._VariableFunctions.empty(*size:_int,memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty(size:_size,*,memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty_meta(*size:_int,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty_meta(size:_size,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.empty_quantized(size:_size,qtensor:Tensor)->Tensor
torch._C._VariableFunctions.empty_strided(size:_size,stride:_size,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.eq(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.eq(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.equal(input:Tensor,other:Tensor)->_bool
torch._C._VariableFunctions.erf(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.erf_(input:Tensor)->Tensor
torch._C._VariableFunctions.erfc(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.erfc_(input:Tensor)->Tensor
torch._C._VariableFunctions.erfinv(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.exp(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.exp2(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.exp2_(input:Tensor)->Tensor
torch._C._VariableFunctions.exp_(input:Tensor)->Tensor
torch._C._VariableFunctions.expm1(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.expm1_(input:Tensor)->Tensor
torch._C._VariableFunctions.eye(n:_int,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.eye(n:_int,m:_int,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.fake_quantize_per_channel_affine(input:Tensor,scale:Tensor,zero_point:Tensor,axis:_int,quant_min:_int,quant_max:_int)->Tensor
torch._C._VariableFunctions.fake_quantize_per_tensor_affine(input:Tensor,scale:_float,zero_point:_int,quant_min:_int,quant_max:_int)->Tensor
torch._C._VariableFunctions.fbgemm_linear_fp16_weight(input:Tensor,packed_weight:Tensor,bias:Tensor)->Tensor
torch._C._VariableFunctions.fbgemm_linear_fp16_weight_fp32_activation(input:Tensor,packed_weight:Tensor,bias:Tensor)->Tensor
torch._C._VariableFunctions.fbgemm_linear_int8_weight(input:Tensor,weight:Tensor,packed:Tensor,col_offsets:Tensor,weight_scale:Number,weight_zero_point:Number,bias:Tensor)->Tensor
torch._C._VariableFunctions.fbgemm_linear_int8_weight_fp32_activation(input:Tensor,weight:Tensor,packed:Tensor,col_offsets:Tensor,weight_scale:Number,weight_zero_point:Number,bias:Tensor)->Tensor
torch._C._VariableFunctions.fbgemm_linear_quantize_weight(input:Tensor)->Tuple[Tensor, Tensor, _float, _int]
torch._C._VariableFunctions.fbgemm_pack_gemm_matrix_fp16(input:Tensor)->Tensor
torch._C._VariableFunctions.fbgemm_pack_quantized_matrix(input:Tensor)->Tensor
torch._C._VariableFunctions.fbgemm_pack_quantized_matrix(input:Tensor,K:_int,N:_int)->Tensor
torch._C._VariableFunctions.feature_alpha_dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.feature_alpha_dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.feature_dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.feature_dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch._C._VariableFunctions.fft(input:Tensor,signal_ndim:_int,normalized:_bool=False)->Tensor
torch._C._VariableFunctions.fill_(input:Tensor,value:Number)->Tensor
torch._C._VariableFunctions.fill_(input:Tensor,value:Tensor)->Tensor
torch._C._VariableFunctions.fix(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.fix_(input:Tensor)->Tensor
torch._C._VariableFunctions.flatten(input:Tensor,dims:Sequence[Union[str,ellipsis,None]],out_dim:Union[str,ellipsis,None])->Tensor
torch._C._VariableFunctions.flatten(input:Tensor,start_dim:Union[str,ellipsis,None],end_dim:Union[str,ellipsis,None],out_dim:Union[str,ellipsis,None])->Tensor
torch._C._VariableFunctions.flatten(input:Tensor,start_dim:_int,end_dim:_int,out_dim:Union[str,ellipsis,None])->Tensor
torch._C._VariableFunctions.flatten(input:Tensor,start_dim:_int=0,end_dim:_int=-1)->Tensor
torch._C._VariableFunctions.flip(input:Tensor,dims:_size)->Tensor
torch._C._VariableFunctions.fliplr(input:Tensor)->Tensor
torch._C._VariableFunctions.flipud(input:Tensor)->Tensor
torch._C._VariableFunctions.floor(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.floor_(input:Tensor)->Tensor
torch._C._VariableFunctions.floor_divide(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.fmod(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.fmod(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.frac(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.frac_(input:Tensor)->Tensor
torch._C._VariableFunctions.frobenius_norm(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.frobenius_norm(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.from_file(filename:str,shared:Optional[_bool]=None,size:Optional[_int]=0,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.from_numpy(ndarray)->Tensor
torch._C._VariableFunctions.full(size:_size,fill_value:Number,*,names:List[Union[str,None]],layout:_layout=strided,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.full(size:_size,fill_value:Number,*,out:Optional[Tensor]=None,layout:_layout=strided,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.full_like(input:Tensor,fill_value:Number,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.gather(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,*,sparse_grad:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.gather(input:Tensor,dim:_int,index:Tensor,*,sparse_grad:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.gcd(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.gcd_(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.ge(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.ge(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.geqrf(input:Tensor,*,out:Optional[Tensor]=None)->namedtuple_a_tau
torch._C._VariableFunctions.ger(input:Tensor,vec2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.get_default_dtype()->_dtype
torch._C._VariableFunctions.get_num_interop_threads()->_int
torch._C._VariableFunctions.get_num_threads()->_int
torch._C._VariableFunctions.greater(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.greater(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.greater_equal(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.greater_equal(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.grid_sampler(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch._C._VariableFunctions.grid_sampler_2d(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch._C._VariableFunctions.grid_sampler_3d(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch._C._VariableFunctions.group_norm(input:Tensor,num_groups:_int,weight:Optional[Tensor]=None,bias:Optional[Tensor]=None,eps:_float=1e-05,cudnn_enabled:_bool=True)->Tensor
torch._C._VariableFunctions.gru(data:Tensor,batch_sizes:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.gru(input:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.gru_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.gt(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.gt(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.hamming_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.hamming_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.hamming_window(window_length:_int,periodic:_bool,alpha:_float,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.hamming_window(window_length:_int,periodic:_bool,alpha:_float,beta:_float,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.hann_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.hann_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.hardshrink(input:Tensor,lambd:Number=0.5)->Tensor
torch._C._VariableFunctions.heaviside(input:Tensor,values:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.histc(input:Tensor,bins:_int=100,min:Number=0,max:Number=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.hspmm(mat1:Tensor,mat2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.hstack(tensors:Union[Tuple[Tensor,...],List[Tensor]],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.hypot(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.i0(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.i0_(input:Tensor)->Tensor
torch._C._VariableFunctions.ifft(input:Tensor,signal_ndim:_int,normalized:_bool=False)->Tensor
torch._C._VariableFunctions.imag(input:Tensor)->Tensor
torch._C._VariableFunctions.index_add(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch._C._VariableFunctions.index_add(input:Tensor,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C._VariableFunctions.index_copy(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch._C._VariableFunctions.index_copy(input:Tensor,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._C._VariableFunctions.index_fill(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch._C._VariableFunctions.index_fill(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,value:Tensor)->Tensor
torch._C._VariableFunctions.index_fill(input:Tensor,dim:_int,index:Tensor,value:Number)->Tensor
torch._C._VariableFunctions.index_fill(input:Tensor,dim:_int,index:Tensor,value:Tensor)->Tensor
torch._C._VariableFunctions.index_put(input:Tensor,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch._C._VariableFunctions.index_put_(input:Tensor,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch._C._VariableFunctions.index_select(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.index_select(input:Tensor,dim:_int,index:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.init_num_threads()->None
torch._C._VariableFunctions.instance_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],use_input_stats:_bool,momentum:_float,eps:_float,cudnn_enabled:_bool)->Tensor
torch._C._VariableFunctions.int_repr(input:Tensor)->Tensor
torch._C._VariableFunctions.inverse(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.irfft(input:Tensor,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True,signal_sizes:_size=())->Tensor
torch._C._VariableFunctions.is_complex(input:Tensor)->_bool
torch._C._VariableFunctions.is_distributed(input:Tensor)->_bool
torch._C._VariableFunctions.is_floating_point(input:Tensor)->_bool
torch._C._VariableFunctions.is_grad_enabled()->_bool
torch._C._VariableFunctions.is_nonzero(input:Tensor)->_bool
torch._C._VariableFunctions.is_same_size(input:Tensor,other:Tensor)->_bool
torch._C._VariableFunctions.is_signed(input:Tensor)->_bool
torch._C._VariableFunctions.is_vulkan_available()->_bool
torch._C._VariableFunctions.isclose(input:Tensor,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->Tensor
torch._C._VariableFunctions.isfinite(input:Tensor)->Tensor
torch._C._VariableFunctions.isinf(input:Tensor)->Tensor
torch._C._VariableFunctions.isnan(input:Tensor)->Tensor
torch._C._VariableFunctions.isneginf(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.isposinf(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.isreal(input:Tensor)->Tensor
torch._C._VariableFunctions.kaiser_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.kaiser_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.kaiser_window(window_length:_int,periodic:_bool,beta:_float,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.kthvalue(input:Tensor,k:_int,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.kthvalue(input:Tensor,k:_int,dim:_int=-1,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.layer_norm(input:Tensor,normalized_shape:_size,weight:Optional[Tensor]=None,bias:Optional[Tensor]=None,eps:_float=1e-05,cudnn_enable:_bool=True)->Tensor
torch._C._VariableFunctions.lcm(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lcm_(input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.le(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.le(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lerp(input:Tensor,end:Tensor,weight:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lerp(input:Tensor,end:Tensor,weight:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.less(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.less(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.less_equal(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.less_equal(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lgamma(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.linspace(start:Number,end:Number,steps:Optional[_int]=None,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.log(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.log10(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.log10_(input:Tensor)->Tensor
torch._C._VariableFunctions.log1p(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.log1p_(input:Tensor)->Tensor
torch._C._VariableFunctions.log2(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.log2_(input:Tensor)->Tensor
torch._C._VariableFunctions.log_(input:Tensor)->Tensor
torch._C._VariableFunctions.log_softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions.log_softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions.logaddexp(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logaddexp2(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logcumsumexp(input:Tensor,dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logcumsumexp(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logdet(input:Tensor)->Tensor
torch._C._VariableFunctions.logical_and(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logical_not(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logical_or(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logical_xor(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logit(input:Tensor,eps:Optional[_float]=None,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logit_(input:Tensor,eps:Optional[_float]=None)->Tensor
torch._C._VariableFunctions.logspace(start:Number,end:Number,steps:Optional[_int]=None,base:_float=10.0,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.logsumexp(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.logsumexp(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lstm(data:Tensor,batch_sizes:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.lstm(input:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.lstm_cell(input:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.lstsq(input:Tensor,A:Tensor,*,out:Optional[Tensor]=None)->namedtuple_solution_QR
torch._C._VariableFunctions.lt(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lt(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.lu_solve(input:Tensor,LU_data:Tensor,LU_pivots:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.masked_fill(input:Tensor,mask:Tensor,value:Number)->Tensor
torch._C._VariableFunctions.masked_fill(input:Tensor,mask:Tensor,value:Tensor)->Tensor
torch._C._VariableFunctions.masked_scatter(input:Tensor,mask:Tensor,source:Tensor)->Tensor
torch._C._VariableFunctions.masked_select(input:Tensor,mask:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.matmul(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.matrix_exp(input:Tensor)->Tensor
torch._C._VariableFunctions.matrix_power(input:Tensor,n:_int)->Tensor
torch._C._VariableFunctions.matrix_rank(input:Tensor,symmetric:_bool=False)->Tensor
torch._C._VariableFunctions.matrix_rank(input:Tensor,tol:_float,symmetric:_bool=False)->Tensor
torch._C._VariableFunctions.max(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.max(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.max(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.max(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.max_pool1d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.max_pool1d_with_indices(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.max_pool2d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.max_pool3d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.maximum(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.mean(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.mean(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.mean(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.median(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.median(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.median(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.min(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.min(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.min(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.min(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.minimum(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.miopen_batch_norm(input:Tensor,weight:Tensor,bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,exponential_average_factor:_float,epsilon:_float)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.miopen_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.miopen_convolution_transpose(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.miopen_depthwise_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch._C._VariableFunctions.miopen_rnn(input:Tensor,weight:Union[Tuple[Tensor,...],List[Tensor]],weight_stride0:_int,hx:Tensor,cx:Optional[Tensor],mode:_int,hidden_size:_int,num_layers:_int,batch_first:_bool,dropout:_float,train:_bool,bidirectional:_bool,batch_sizes:_size,dropout_state:Optional[Tensor])->Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]
torch._C._VariableFunctions.mkldnn_adaptive_avg_pool2d(input:Tensor,output_size:Union[_int,_size])->Tensor
torch._C._VariableFunctions.mkldnn_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int)->Tensor
torch._C._VariableFunctions.mkldnn_convolution_backward_weights(weight_size:_size,grad_output:Tensor,input:Tensor,padding:_size,stride:_size,dilation:_size,groups:_int,bias_defined:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.mkldnn_max_pool2d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.mkldnn_max_pool3d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.mm(input:Tensor,mat2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.mode(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.mode(input:Tensor,dim:_int=-1,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.movedim(input:Tensor,source:_int,destination:_int)->Tensor
torch._C._VariableFunctions.movedim(input:Tensor,source:_size,destination:_size)->Tensor
torch._C._VariableFunctions.mul(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.multinomial(input:Tensor,num_samples:_int,replacement:_bool=False,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.multiply(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.multiply(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.mv(input:Tensor,vec:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.mvlgamma(input:Tensor,p:_int)->Tensor
torch._C._VariableFunctions.nanquantile(input:Tensor,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.nanquantile(input:Tensor,q:_float,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.nansum(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.nansum(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.narrow(input:Tensor,dim:_int,start:Tensor,length:_int)->Tensor
torch._C._VariableFunctions.narrow(input:Tensor,dim:_int,start:_int,length:_int)->Tensor
torch._C._VariableFunctions.native_batch_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,momentum:_float,eps:_float,*,out:Optional[Tensor]=None)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.native_group_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],N:_int,C:_int,HxW:_int,group:_int,eps:_float)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.native_layer_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],M:_int,N:_int,eps:_float)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.native_norm(input:Tensor,p:Number=2)->Tensor
torch._C._VariableFunctions.native_norm(input:Tensor,p:Optional[Number],dim:Union[_int,_size],keepdim:_bool,dtype:Optional[_dtype])->Tensor
torch._C._VariableFunctions.ne(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.ne(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.neg(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.neg_(input:Tensor)->Tensor
torch._C._VariableFunctions.negative(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.negative_(input:Tensor)->Tensor
torch._C._VariableFunctions.nextafter(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.nonzero(input:Tensor,*,as_tuple:bool=...)->Tensor
torch._C._VariableFunctions.nonzero(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.norm_except_dim(v:Tensor,pow:_int=2,dim:_int=0)->Tensor
torch._C._VariableFunctions.normal(mean:Tensor,std:Tensor,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.normal(mean:Tensor,std:_float=1,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.normal(mean:_float,std:Tensor,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.normal(mean:_float,std:_float,size:_size,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.not_equal(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.not_equal(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.nuclear_norm(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.nuclear_norm(input:Tensor,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.numel(self:Tensor)->_int
torch._C._VariableFunctions.ones(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.ones(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.ones(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.ones(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.ones_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.orgqr(input:Tensor,input2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.ormqr(input:Tensor,input2:Tensor,input3:Tensor,left:_bool=True,transpose:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.outer(input:Tensor,vec2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.pairwise_distance(x1:Tensor,x2:Tensor,p:_float=2,eps:_float=1e-06,keepdim:_bool=False)->Tensor
torch._C._VariableFunctions.pdist(input:Tensor,p:_float=2)->Tensor
torch._C._VariableFunctions.pinverse(input:Tensor,rcond:_float=1e-15)->Tensor
torch._C._VariableFunctions.pixel_shuffle(input:Tensor,upscale_factor:_int)->Tensor
torch._C._VariableFunctions.poisson(input:Tensor,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions.poisson_nll_loss(input:Tensor,target:Tensor,log_input:_bool,full:_bool,eps:_float,reduction:_int)->Tensor
torch._C._VariableFunctions.polar(abs:Tensor,angle:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.polygamma(n:_int,input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.pow(input:Tensor,exponent:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.pow(input:Tensor,exponent:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.pow(self:Number,exponent:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.prelu(input:Tensor,weight:Tensor)->Tensor
torch._C._VariableFunctions.prod(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.prod(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.prod(input:Tensor,dim:_int,keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.promote_types(type1:_dtype,type2:_dtype)->_dtype
torch._C._VariableFunctions.q_per_channel_axis(input:Tensor)->_int
torch._C._VariableFunctions.q_per_channel_scales(input:Tensor)->Tensor
torch._C._VariableFunctions.q_per_channel_zero_points(input:Tensor)->Tensor
torch._C._VariableFunctions.q_scale(input:Tensor)->_float
torch._C._VariableFunctions.q_zero_point(input:Tensor)->_int
torch._C._VariableFunctions.qr(input:Tensor,some:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_Q_R
torch._C._VariableFunctions.quantile(input:Tensor,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.quantile(input:Tensor,q:_float,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.quantize_per_channel(input:Tensor,scales:Tensor,zero_points:Tensor,axis:_int,dtype:_dtype)->Tensor
torch._C._VariableFunctions.quantize_per_tensor(input:Tensor,scale:_float,zero_point:_int,dtype:_dtype)->Tensor
torch._C._VariableFunctions.quantize_per_tensor(tensors:Union[Tuple[Tensor,...],List[Tensor]],scales:Tensor,zero_points:Tensor,dtype:_dtype)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.quantized_batch_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],mean:Tensor,var:Tensor,eps:_float,output_scale:_float,output_zero_point:_int)->Tensor
torch._C._VariableFunctions.quantized_gru_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tensor
torch._C._VariableFunctions.quantized_lstm_cell(input:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.quantized_max_pool1d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.quantized_max_pool2d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch._C._VariableFunctions.quantized_rnn_relu_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tensor
torch._C._VariableFunctions.quantized_rnn_tanh_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tensor
torch._C._VariableFunctions.rad2deg(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.rad2deg_(input:Tensor)->Tensor
torch._C._VariableFunctions.rand(*size:_int,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(*size:_int,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(size:_size,*,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(size:_size,*,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.rand_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randint(high:_int,size:_size,*,generator:Optional[Generator]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randint(low:_int,high:_int,size:_size,*,generator:Optional[Generator]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randint_like(input:Tensor,high:_int,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randint_like(input:Tensor,low:_int,high:_int,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(*size:_int,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(*size:_int,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(size:_size,*,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(size:_size,*,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randn_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randperm(n:_int,*,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.randperm(n:_int,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.range(start:Number,end:Number,step:Number=1,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.real(input:Tensor)->Tensor
torch._C._VariableFunctions.reciprocal(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.reciprocal_(input:Tensor)->Tensor
torch._C._VariableFunctions.relu(input:Tensor)->Tensor
torch._C._VariableFunctions.relu_(input:Tensor)->Tensor
torch._C._VariableFunctions.remainder(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.remainder(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.renorm(input:Tensor,p:Number,dim:_int,maxnorm:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.repeat_interleave(input:Tensor,repeats:Tensor,dim:Optional[_int]=None)->Tensor
torch._C._VariableFunctions.repeat_interleave(input:Tensor,repeats:_int,dim:Optional[_int]=None)->Tensor
torch._C._VariableFunctions.repeat_interleave(repeats:Tensor)->Tensor
torch._C._VariableFunctions.reshape(input:Tensor,shape:_size)->Tensor
torch._C._VariableFunctions.resize_as_(input:Tensor,the_template:Tensor,*,memory_format:Optional[memory_format]=None)->Tensor
torch._C._VariableFunctions.result_type(scalar1:Number,scalar2:Number)->_dtype
torch._C._VariableFunctions.result_type(scalar:Number,tensor:Tensor)->_dtype
torch._C._VariableFunctions.result_type(tensor:Tensor,other:Number)->_dtype
torch._C._VariableFunctions.result_type(tensor:Tensor,other:Tensor)->_dtype
torch._C._VariableFunctions.rfft(input:Tensor,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True)->Tensor
torch._C._VariableFunctions.rnn_relu(data:Tensor,batch_sizes:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.rnn_relu(input:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.rnn_relu_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.rnn_tanh(data:Tensor,batch_sizes:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.rnn_tanh(input:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.rnn_tanh_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.roll(input:Tensor,shifts:Union[_int,_size],dims:Union[_int,_size]=())->Tensor
torch._C._VariableFunctions.rot90(input:Tensor,k:_int=1,dims:_size=(0,1))->Tensor
torch._C._VariableFunctions.round(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.round_(input:Tensor)->Tensor
torch._C._VariableFunctions.rrelu(input:Tensor,lower:Number=0.125,upper:Number=0.3333333333333333,training:_bool=False,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions.rrelu_(input:Tensor,lower:Number=0.125,upper:Number=0.3333333333333333,training:_bool=False,generator:Optional[Generator]=None)->Tensor
torch._C._VariableFunctions.rsqrt(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.rsqrt_(input:Tensor)->Tensor
torch._C._VariableFunctions.rsub(input:Tensor,other:Number,alpha:Number=1)->Tensor
torch._C._VariableFunctions.rsub(input:Tensor,other:Tensor,*,alpha:Number=1)->Tensor
torch._C._VariableFunctions.scalar_tensor(s:Number,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.scatter(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch._C._VariableFunctions.scatter(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch._C._VariableFunctions.scatter(input:Tensor,dim:_int,index:Tensor,src:Tensor)->Tensor
torch._C._VariableFunctions.scatter(input:Tensor,dim:_int,index:Tensor,value:Number)->Tensor
torch._C._VariableFunctions.scatter_add(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch._C._VariableFunctions.scatter_add(input:Tensor,dim:_int,index:Tensor,src:Tensor)->Tensor
torch._C._VariableFunctions.searchsorted(sorted_sequence:Tensor,input:Tensor,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.searchsorted(sorted_sequence:Tensor,self:Number,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.select(input:Tensor,dim:Union[str,ellipsis,None],index:_int)->Tensor
torch._C._VariableFunctions.select(input:Tensor,dim:_int,index:_int)->Tensor
torch._C._VariableFunctions.selu(input:Tensor)->Tensor
torch._C._VariableFunctions.selu_(input:Tensor)->Tensor
torch._C._VariableFunctions.set_flush_denormal(mode:_bool)->_bool
torch._C._VariableFunctions.set_num_interop_threads(num:_int)->None
torch._C._VariableFunctions.set_num_threads(num:_int)->None
torch._C._VariableFunctions.sgn(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sigmoid(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sigmoid_(input:Tensor)->Tensor
torch._C._VariableFunctions.sign(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.signbit(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sin(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sin_(input:Tensor)->Tensor
torch._C._VariableFunctions.sinh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sinh_(input:Tensor)->Tensor
torch._C._VariableFunctions.slogdet(input:Tensor)->namedtuple_sign_logabsdet
torch._C._VariableFunctions.smm(input:Tensor,mat2:Tensor)->Tensor
torch._C._VariableFunctions.softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions.softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._C._VariableFunctions.solve(input:Tensor,A:Tensor,*,out:Optional[Tensor]=None)->namedtuple_solution_LU
torch._C._VariableFunctions.sort(input:Tensor,dim:Union[str,ellipsis,None],descending:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.sort(input:Tensor,dim:_int=-1,descending:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.sparse_coo_tensor(indices:Tensor,values:Union[Tensor,List],size:Optional[_size]=None,*,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.split_with_sizes(input:Tensor,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.sqrt(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sqrt_(input:Tensor)->Tensor
torch._C._VariableFunctions.square(input:Tensor)->Tensor
torch._C._VariableFunctions.square_(input:Tensor)->Tensor
torch._C._VariableFunctions.squeeze(input:Tensor)->Tensor
torch._C._VariableFunctions.squeeze(input:Tensor,dim:Union[str,ellipsis,None])->Tensor
torch._C._VariableFunctions.squeeze(input:Tensor,dim:_int)->Tensor
torch._C._VariableFunctions.sspaddmm(beta:Number,self:Tensor,alpha:Number,mat1:Tensor,mat2:Tensor)->Tensor
torch._C._VariableFunctions.sspaddmm(beta:Number,self:Tensor,mat1:Tensor,mat2:Tensor)->Tensor
torch._C._VariableFunctions.sspaddmm(input:Tensor,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.stack(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.std(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.std(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.std(input:Tensor,unbiased:_bool=True,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.std_mean(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.std_mean(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.std_mean(input:Tensor,unbiased:_bool=True)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.sub(input:Union[Tensor,Number],other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sub(self:Tensor,alpha:Number,other:Tensor)->Tensor
torch._C._VariableFunctions.sub(self:Tensor,alpha:Number,other:Tensor,*,out:Tensor)->Tensor
torch._C._VariableFunctions.subtract(input:Tensor,other:Number,alpha:Number=1,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.subtract(input:Tensor,other:Tensor,*,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sum(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sum(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.sum(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.svd(input:Tensor,some:_bool=True,compute_uv:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_U_S_V
torch._C._VariableFunctions.symeig(input:Tensor,eigenvectors:_bool=False,upper:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_eigenvalues_eigenvectors
torch._C._VariableFunctions.t(input:Tensor)->Tensor
torch._C._VariableFunctions.take(input:Tensor,index:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.tan(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.tan_(input:Tensor)->Tensor
torch._C._VariableFunctions.tanh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.tanh_(input:Tensor)->Tensor
torch._C._VariableFunctions.tensor(data:Any,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.threshold(input:Tensor,threshold:Number,value:Number,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.threshold_(input:Tensor,threshold:Number,value:Number)->Tensor
torch._C._VariableFunctions.topk(input:Tensor,k:_int,dim:_int=-1,largest:_bool=True,sorted:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch._C._VariableFunctions.trace(input:Tensor)->Tensor
torch._C._VariableFunctions.transpose(input:Tensor,dim0:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None])->Tensor
torch._C._VariableFunctions.transpose(input:Tensor,dim0:_int,dim1:_int)->Tensor
torch._C._VariableFunctions.trapz(y:Tensor,*,dx:_float=1,dim:_int=-1)->Tensor
torch._C._VariableFunctions.trapz(y:Tensor,x:Tensor,*,dim:_int=-1)->Tensor
torch._C._VariableFunctions.triangular_solve(input:Tensor,A:Tensor,upper:_bool=True,transpose:_bool=False,unitriangular:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_solution_cloned_coefficient
torch._C._VariableFunctions.tril(input:Tensor,diagonal:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.tril_indices(row:_int,col:_int,offset:_int=0,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.triu(input:Tensor,diagonal:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.triu_indices(row:_int,col:_int,offset:_int=0,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.true_divide(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.trunc(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.trunc_(input:Tensor)->Tensor
torch._C._VariableFunctions.unbind(input:Tensor,dim:Union[str,ellipsis,None])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.unbind(input:Tensor,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.unique_dim(input:Tensor,dim:_int,sorted:_bool=True,return_inverse:_bool=False,return_counts:_bool=False)->Tuple[Tensor, Tensor, Tensor]
torch._C._VariableFunctions.unsafe_chunk(input:Tensor,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.unsafe_split(input:Tensor,split_size:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.unsafe_split_with_sizes(input:Tensor,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.unsqueeze(input:Tensor,dim:_int)->Tensor
torch._C._VariableFunctions.vander(x:Tensor,N:Optional[_int]=None,increasing:_bool=False)->Tensor
torch._C._VariableFunctions.var(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.var(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.var(input:Tensor,unbiased:_bool=True,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.var_mean(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.var_mean(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.var_mean(input:Tensor,unbiased:_bool=True)->Tuple[Tensor, Tensor]
torch._C._VariableFunctions.vdot(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.view_as_complex(input:Tensor)->Tensor
torch._C._VariableFunctions.view_as_real(input:Tensor)->Tensor
torch._C._VariableFunctions.vstack(tensors:Union[Tuple[Tensor,...],List[Tensor]],*,out:Optional[Tensor]=None)->Tensor
torch._C._VariableFunctions.where(condition:Tensor)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._C._VariableFunctions.where(condition:Tensor,input:Tensor,other:Number)->Tensor
torch._C._VariableFunctions.where(condition:Tensor,input:Tensor,other:Tensor)->Tensor
torch._C._VariableFunctions.where(condition:Tensor,self:Number,other:Number)->Tensor
torch._C._VariableFunctions.where(condition:Tensor,self:Number,other:Tensor)->Tensor
torch._C._VariableFunctions.zero_(input:Tensor)->Tensor
torch._C._VariableFunctions.zeros(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.zeros(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.zeros(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.zeros(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._C._VariableFunctions.zeros_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.__and__(input:Tensor,other:Number)->Tensor
torch.__and__(input:Tensor,other:Tensor)->Tensor
torch.__lshift__(input:Tensor,other:Number)->Tensor
torch.__lshift__(input:Tensor,other:Tensor)->Tensor
torch.__or__(input:Tensor,other:Number)->Tensor
torch.__or__(input:Tensor,other:Tensor)->Tensor
torch.__rshift__(input:Tensor,other:Number)->Tensor
torch.__rshift__(input:Tensor,other:Tensor)->Tensor
torch.__xor__(input:Tensor,other:Number)->Tensor
torch.__xor__(input:Tensor,other:Tensor)->Tensor
torch._adaptive_avg_pool2d(input:Tensor,output_size:Union[_int,_size])->Tensor
torch._add_batch_dim(input:Tensor,batch_dim:_int,level:_int)->Tensor
torch._add_relu(input:Tensor,other:Tensor,*,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch._add_relu_(input:Tensor,other:Tensor,*,alpha:Number=1)->Tensor
torch._addmv_impl_(input:Tensor,self2:Tensor,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._aminmax(input:Tensor)->Tuple[Tensor, Tensor]
torch._aminmax(input:Tensor,dim:_int,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch._amp_non_finite_check_and_unscale_(input:Tensor,found_inf:Tensor,inv_scale:Tensor)->None
torch._amp_update_scale(growth_tracker:Tensor,current_scale:Tensor,found_inf:Tensor,scale_growth_factor:_float,scale_backoff_factor:_float,growth_interval:_int)->Tensor
torch._baddbmm_mkl_(input:Tensor,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._batch_norm_impl_index(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,momentum:_float,eps:_float,cudnn_enabled:_bool)->Tuple[Tensor, Tensor, Tensor, Tensor, _int]
torch._bmm(input:Tensor,mat2:Tensor,*,deterministic:_bool=False,out:Optional[Tensor]=None)->Tensor
torch._cast_Byte(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Char(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Double(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Float(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Half(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Int(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Long(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cast_Short(input:Tensor,non_blocking:_bool=False)->Tensor
torch._cat(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch._choose_qparams_per_tensor(input:Tensor,reduce_range:_bool=False)->Tuple[_float, _int]
torch._compute_linear_combination(input:Tensor,coefficients:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch._conj(input:Tensor)->Tensor
torch._convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size,groups:_int,benchmark:_bool,deterministic:_bool,cudnn_enabled:_bool)->Tensor
torch._convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size,groups:_int,benchmark:_bool,deterministic:_bool,cudnn_enabled:_bool,allow_tf32:_bool)->Tensor
torch._convolution_nogroup(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size)->Tensor
torch._copy_from(input:Tensor,dst:Tensor,non_blocking:_bool=False)->Tensor
torch._ctc_loss(log_probs:Tensor,targets:Tensor,input_lengths:_size,target_lengths:_size,blank:_int=0,zero_infinity:_bool=False)->Tuple[Tensor, Tensor]
torch._cudnn_ctc_loss(log_probs:Tensor,targets:Tensor,input_lengths:_size,target_lengths:_size,blank:_int,deterministic:_bool,zero_infinity:_bool)->Tuple[Tensor, Tensor]
torch._cudnn_init_dropout_state(dropout:_float,train:_bool,dropout_seed:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._cudnn_rnn(input:Tensor,weight:Union[Tuple[Tensor,...],List[Tensor]],weight_stride0:_int,weight_buf:Optional[Tensor],hx:Tensor,cx:Optional[Tensor],mode:_int,hidden_size:_int,num_layers:_int,batch_first:_bool,dropout:_float,train:_bool,bidirectional:_bool,batch_sizes:_size,dropout_state:Optional[Tensor])->Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]
torch._cudnn_rnn_flatten_weight(weight_arr:Union[Tuple[Tensor,...],List[Tensor]],weight_stride0:_int,input_size:_int,mode:_int,hidden_size:_int,num_layers:_int,batch_first:_bool,bidirectional:_bool)->Tensor
torch._cufft_clear_plan_cache(device_index:_int)->None
torch._cufft_get_plan_cache_max_size(device_index:_int)->_int
torch._cufft_get_plan_cache_size(device_index:_int)->_int
torch._cufft_set_plan_cache_max_size(device_index:_int,max_size:_int)->None
torch._cummax_helper(input:Tensor,values:Tensor,indices:Tensor,dim:_int)->None
torch._cummin_helper(input:Tensor,values:Tensor,indices:Tensor,dim:_int)->None
torch._debug_has_internal_overlap(input:Tensor)->_int
torch._dim_arange(like:Tensor,dim:_int)->Tensor
torch._dirichlet_grad(x:Tensor,alpha:Tensor,total:Tensor)->Tensor
torch._embedding_bag(weight:Tensor,indices:Tensor,offsets:Tensor,scale_grad_by_freq:_bool=False,mode:_int=0,sparse:_bool=False,per_sample_weights:Optional[Tensor]=None,include_last_offset:_bool=False)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._embedding_bag_forward_only(weight:Tensor,indices:Tensor,offsets:Tensor,scale_grad_by_freq:_bool=False,mode:_int=0,sparse:_bool=False,per_sample_weights:Optional[Tensor]=None,include_last_offset:_bool=False)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch._empty_affine_quantized(*size:_int,scale:_float=1,zero_point:_int=0,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._empty_affine_quantized(size:_size,*,scale:_float=1,zero_point:_int=0,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._empty_per_channel_affine_quantized(*size:_int,scales:Tensor,zero_points:Tensor,axis:_int,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._empty_per_channel_affine_quantized(size:_size,*,scales:Tensor,zero_points:Tensor,axis:_int,memory_format:Optional[memory_format]=contiguous_format,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch._euclidean_dist(x1:Tensor,x2:Tensor)->Tensor
torch._fake_quantize_learnable_per_channel_affine(input:Tensor,scale:Tensor,zero_point:Tensor,axis:_int,quant_min:_int,quant_max:_int)->Tensor
torch._fake_quantize_learnable_per_tensor_affine(input:Tensor,scale:Tensor,zero_point:Tensor,quant_min:_int,quant_max:_int)->Tensor
torch._fft_with_size(input:Tensor,signal_ndim:_int,complex_input:_bool,complex_output:_bool,inverse:_bool,checked_signal_sizes:_size,normalization:_int,onesided:_bool,output_sizes:_size)->Tensor
torch._fft_with_size(input:Tensor,signal_ndim:_int,complex_input:_bool,complex_output:_bool,inverse:_bool,checked_signal_sizes:_size,normalized:_bool,onesided:_bool,output_sizes:_size)->Tensor
torch._foreach_add(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_add(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_add_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->None
torch._foreach_add_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._foreach_add_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_add_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._foreach_addcdiv(input:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_addcdiv_(self:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->None
torch._foreach_addcmul(input:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_addcmul_(self:Union[Tuple[Tensor,...],List[Tensor]],tensor1:Union[Tuple[Tensor,...],List[Tensor]],tensor2:Union[Tuple[Tensor,...],List[Tensor]],value:Number=1)->None
torch._foreach_div(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_div(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_div_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._foreach_div_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._foreach_div_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_div_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._foreach_exp(tensors:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_exp_(self:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._foreach_mul(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_mul(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_mul_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._foreach_mul_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._foreach_mul_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_mul_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._foreach_sqrt(tensors:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_sqrt_(self:Union[Tuple[Tensor,...],List[Tensor]])->None
torch._foreach_sub(tensors1:Union[Tuple[Tensor,...],List[Tensor]],tensors2:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_sub(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_sub_(self:Union[Tuple[Tensor,...],List[Tensor]],other:Union[Tuple[Tensor,...],List[Tensor]],*,alpha:Number=1)->None
torch._foreach_sub_(self:Union[Tuple[Tensor,...],List[Tensor]],scalar:Number)->None
torch._foreach_sub_scalar_list(tensors:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->Union[Tuple[Tensor, ...], List[Tensor]]
torch._foreach_sub_scalar_list_(self:Union[Tuple[Tensor,...],List[Tensor]],scalars:Sequence[float])->None
torch._fused_dropout(input:Tensor,p:_float,generator:Optional[Generator]=None)->Tuple[Tensor, Tensor]
torch._grid_sampler_2d_cpu_fallback(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch._has_compatible_shallow_copy_type(input:Tensor,from_:Tensor)->_bool
torch._index_copy_(input:Tensor,dim:_int,index:Tensor,source:Tensor)->Tensor
torch._index_put_impl_(input:Tensor,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False,unsafe:_bool=False)->Tensor
torch._log_softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._log_softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._logcumsumexp(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->Tensor
torch._lu_solve_helper(input:Tensor,LU_data:Tensor,LU_pivots:Tensor)->Tensor
torch._lu_with_info(input:Tensor,pivot:_bool=True,check_errors:_bool=True)->Tuple[Tensor, Tensor, Tensor]
torch._make_per_channel_quantized_tensor(input:Tensor,scale:Tensor,zero_point:Tensor,axis:_int)->Tensor
torch._make_per_tensor_quantized_tensor(input:Tensor,scale:_float,zero_point:_int)->Tensor
torch._masked_scale(input:Tensor,mask:Tensor,scale:_float)->Tensor
torch._mkldnn_reshape(input:Tensor,shape:_size)->Tensor
torch._mkldnn_transpose(input:Tensor,dim0:_int,dim1:_int)->Tensor
torch._mkldnn_transpose_(input:Tensor,dim0:_int,dim1:_int)->Tensor
torch._mode(input:Tensor,dim:_int=-1,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tuple[Tensor, Tensor]
torch._multinomial_alias_draw(J:Tensor,q:Tensor,num_samples:_int,*,generator:Optional[Generator]=None)->Tensor
torch._multinomial_alias_setup(probs:Tensor)->Tuple[Tensor, Tensor]
torch._nnpack_available()->_bool
torch._nnpack_spatial_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:Union[_int,_size],stride:Union[_int,_size]=1)->Tensor
torch._pack_padded_sequence(input:Tensor,lengths:Tensor,batch_first:_bool)->Tuple[Tensor, Tensor]
torch._pad_packed_sequence(data:Tensor,batch_sizes:Tensor,batch_first:_bool,padding_value:Number,total_length:_int)->Tuple[Tensor, Tensor]
torch._remove_batch_dim(input:Tensor,level:_int,batch_size:_int,out_dim:_int)->Tensor
torch._reshape_from_tensor(input:Tensor,shape:Tensor)->Tensor
torch._s_where(condition:Tensor,input:Tensor,other:Tensor)->Tensor
torch._sample_dirichlet(input:Tensor,generator:Optional[Generator]=None)->Tensor
torch._saturate_weight_to_fp16(weight:Tensor)->Tensor
torch._shape_as_tensor(input:Tensor)->Tensor
torch._sobol_engine_draw(quasi:Tensor,n:_int,sobolstate:Tensor,dimension:_int,num_generated:_int,dtype:Optional[_dtype])->Tuple[Tensor, Tensor]
torch._sobol_engine_ff_(input:Tensor,n:_int,sobolstate:Tensor,dimension:_int,num_generated:_int)->Tensor
torch._sobol_engine_initialize_state_(input:Tensor,dimension:_int)->Tensor
torch._sobol_engine_scramble_(input:Tensor,ltm:Tensor,dimension:_int)->Tensor
torch._softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._sparse_addmm(input:Tensor,sparse:Tensor,dense:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch._sparse_log_softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._sparse_log_softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._sparse_log_softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._sparse_log_softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._sparse_mm(sparse:Tensor,dense:Tensor)->Tensor
torch._sparse_softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch._sparse_softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch._sparse_softmax(input:Tensor,dim:_int,half_to_float:_bool)->Tensor
torch._sparse_softmax_backward_data(grad_output:Tensor,output:Tensor,dim:_int,input:Tensor)->Tensor
torch._sparse_sum(input:Tensor)->Tensor
torch._sparse_sum(input:Tensor,*,dtype:_dtype)->Tensor
torch._sparse_sum(input:Tensor,dim:Union[_int,_size])->Tensor
torch._sparse_sum(input:Tensor,dim:Union[_int,_size],*,dtype:_dtype)->Tensor
torch._standard_gamma(input:Tensor,generator:Optional[Generator]=None)->Tensor
torch._standard_gamma_grad(input:Tensor,output:Tensor)->Tensor
torch._std(input:Tensor,unbiased:_bool=True)->Tensor
torch._test_serialization_subcmul(input:Tensor,other:Tensor,alpha:Number=1)->Tensor
torch._trilinear(i1:Tensor,i2:Tensor,i3:Tensor,expand1:_size,expand2:_size,expand3:_size,sumdim:_size,unroll_dim:_int=1)->Tensor
torch._unique(input:Tensor,sorted:_bool=True,return_inverse:_bool=False)->Tuple[Tensor, Tensor]
torch._unique2(input:Tensor,sorted:_bool=True,return_inverse:_bool=False,return_counts:_bool=False)->Tuple[Tensor, Tensor, Tensor]
torch._use_cudnn_ctc_loss(log_probs:Tensor,targets:Tensor,input_lengths:_size,target_lengths:_size,blank:_int)->_bool
torch._use_cudnn_rnn_flatten_weight()->_bool
torch._validate_sparse_coo_tensor_args(indices:Tensor,values:Tensor,size:_size)->None
torch._var(input:Tensor,unbiased:_bool=True)->Tensor
torch._weight_norm(v:Tensor,g:Tensor,dim:_int=0)->Tensor
torch._weight_norm_cuda_interface(v:Tensor,g:Tensor,dim:_int=0)->Tuple[Tensor, Tensor]
torch.abs(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.abs_(input:Tensor)->Tensor
torch.absolute(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.acos(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.acos_(input:Tensor)->Tensor
torch.acosh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.acosh_(input:Tensor)->Tensor
torch.adaptive_avg_pool1d(input:Tensor,output_size:Union[_int,_size])->Tensor
torch.adaptive_max_pool1d(input:Tensor,output_size:Union[_int,_size])->Tuple[Tensor, Tensor]
torch.add(input:Union[Tensor,Number],other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch.add(self:Tensor,alpha:Number,other:Tensor)->Tensor
torch.add(self:Tensor,alpha:Number,other:Tensor,*,out:Tensor)->Tensor
torch.addbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor)->Tensor
torch.addbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch.addbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor)->Tensor
torch.addbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch.addbmm(input:Tensor,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.addcdiv(input:Tensor,tensor1:Tensor,tensor2:Tensor,*,value:Number=1,out:Optional[Tensor]=None)->Tensor
torch.addcdiv(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor)->Tensor
torch.addcdiv(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor,*,out:Tensor)->Tensor
torch.addcmul(input:Tensor,tensor1:Tensor,tensor2:Tensor,*,value:Number=1,out:Optional[Tensor]=None)->Tensor
torch.addcmul(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor)->Tensor
torch.addcmul(self:Tensor,value:Number,tensor1:Tensor,tensor2:Tensor,*,out:Tensor)->Tensor
torch.addmm(beta:Number,self:Tensor,alpha:Number,mat1:Tensor,mat2:Tensor)->Tensor
torch.addmm(beta:Number,self:Tensor,alpha:Number,mat1:Tensor,mat2:Tensor,*,out:Tensor)->Tensor
torch.addmm(beta:Number,self:Tensor,mat1:Tensor,mat2:Tensor)->Tensor
torch.addmm(beta:Number,self:Tensor,mat1:Tensor,mat2:Tensor,*,out:Tensor)->Tensor
torch.addmm(input:Tensor,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.addmv(beta:Number,self:Tensor,alpha:Number,mat:Tensor,vec:Tensor)->Tensor
torch.addmv(beta:Number,self:Tensor,alpha:Number,mat:Tensor,vec:Tensor,*,out:Tensor)->Tensor
torch.addmv(beta:Number,self:Tensor,mat:Tensor,vec:Tensor)->Tensor
torch.addmv(beta:Number,self:Tensor,mat:Tensor,vec:Tensor,*,out:Tensor)->Tensor
torch.addmv(input:Tensor,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.addmv_(input:Tensor,mat:Tensor,vec:Tensor,*,beta:Number=1,alpha:Number=1)->Tensor
torch.addr(beta:Number,self:Tensor,alpha:Number,vec1:Tensor,vec2:Tensor)->Tensor
torch.addr(beta:Number,self:Tensor,alpha:Number,vec1:Tensor,vec2:Tensor,*,out:Tensor)->Tensor
torch.addr(beta:Number,self:Tensor,vec1:Tensor,vec2:Tensor)->Tensor
torch.addr(beta:Number,self:Tensor,vec1:Tensor,vec2:Tensor,*,out:Tensor)->Tensor
torch.addr(input:Tensor,vec1:Tensor,vec2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.affine_grid_generator(theta:Tensor,size:_size,align_corners:_bool)->Tensor
torch.all(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.all(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.all(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.allclose(input:Tensor,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->_bool
torch.alpha_dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch.alpha_dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch.amax(input:Tensor,dim:Union[_int,_size]=(),keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.amin(input:Tensor,dim:Union[_int,_size]=(),keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.angle(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.any(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.any(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.any(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.arange(end:Number,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.arange(start:Number,end:Number,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.arange(start:Number,end:Number,step:Number,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.arccos(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.arccos_(input:Tensor)->Tensor
torch.arccosh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.arccosh_(input:Tensor)->Tensor
torch.arcsin(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.arcsin_(input:Tensor)->Tensor
torch.arcsinh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.arcsinh_(input:Tensor)->Tensor
torch.arctan(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.arctan_(input:Tensor)->Tensor
torch.arctanh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.arctanh_(input:Tensor)->Tensor
torch.argmax(input:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.argmin(input:Tensor,dim:Optional[_int]=None,keepdim:_bool=False)->Tensor
torch.argsort(input:Tensor,dim:Union[str,ellipsis,None],descending:_bool=False)->Tensor
torch.argsort(input:Tensor,dim:_int=-1,descending:_bool=False)->Tensor
torch.as_strided(input:Tensor,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch.as_strided_(input:Tensor,size:_size,stride:_size,storage_offset:Optional[_int]=None)->Tensor
torch.as_tensor(data:Any,dtype:_dtype=None,device:Optional[_device]=None)->Tensor
torch.asin(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.asin_(input:Tensor)->Tensor
torch.asinh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.asinh_(input:Tensor)->Tensor
torch.atan(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.atan2(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.atan_(input:Tensor)->Tensor
torch.atanh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.atanh_(input:Tensor)->Tensor
torch.avg_pool1d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,ceil_mode:_bool=False,count_include_pad:_bool=True)->Tensor
torch.baddbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor)->Tensor
torch.baddbmm(beta:Number,self:Tensor,alpha:Number,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch.baddbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor)->Tensor
torch.baddbmm(beta:Number,self:Tensor,batch1:Tensor,batch2:Tensor,*,out:Tensor)->Tensor
torch.baddbmm(input:Tensor,batch1:Tensor,batch2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.bartlett_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.bartlett_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.batch_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,momentum:_float,eps:_float,cudnn_enabled:_bool)->Tensor
torch.batch_norm_backward_elemt(grad_out:Tensor,input:Tensor,mean:Tensor,invstd:Tensor,weight:Optional[Tensor],mean_dy:Tensor,mean_dy_xmu:Tensor)->Tensor
torch.batch_norm_backward_reduce(grad_out:Tensor,input:Tensor,mean:Tensor,invstd:Tensor,weight:Optional[Tensor],input_g:_bool,weight_g:_bool,bias_g:_bool)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch.batch_norm_elemt(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],mean:Tensor,invstd:Tensor,eps:_float,*,out:Optional[Tensor]=None)->Tensor
torch.batch_norm_gather_stats(input:Tensor,mean:Tensor,invstd:Tensor,running_mean:Optional[Tensor],running_var:Optional[Tensor],momentum:_float,eps:_float,count:_int)->Tuple[Tensor, Tensor]
torch.batch_norm_gather_stats_with_counts(input:Tensor,mean:Tensor,invstd:Tensor,running_mean:Optional[Tensor],running_var:Optional[Tensor],momentum:_float,eps:_float,counts:Tensor)->Tuple[Tensor, Tensor]
torch.batch_norm_stats(input:Tensor,eps:_float)->Tuple[Tensor, Tensor]
torch.batch_norm_update_stats(input:Tensor,running_mean:Optional[Tensor],running_var:Optional[Tensor],momentum:_float)->Tuple[Tensor, Tensor]
torch.bernoulli(input:Tensor,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch.bernoulli(input:Tensor,p:_float,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch.bilinear(input1:Tensor,input2:Tensor,weight:Tensor,bias:Optional[Tensor])->Tensor
torch.bincount(input:Tensor,weights:Optional[Tensor]=None,minlength:_int=0)->Tensor
torch.binomial(count:Tensor,prob:Tensor,generator:Optional[Generator]=None)->Tensor
torch.bitwise_and(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.bitwise_and(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.bitwise_not(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.bitwise_or(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.bitwise_or(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.bitwise_xor(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.bitwise_xor(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.blackman_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.blackman_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.bmm(input:Tensor,mat2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.bucketize(input:Tensor,boundaries:Tensor,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch.bucketize(self:Number,boundaries:Tensor,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch.can_cast(from_:_dtype,to:_dtype)->_bool
torch.cat(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->Tensor
torch.cat(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch.ceil(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.ceil_(input:Tensor)->Tensor
torch.celu(input:Tensor,alpha:Number=1.0)->Tensor
torch.celu_(input:Tensor,alpha:Number=1.0)->Tensor
torch.channel_shuffle(input:Tensor,groups:_int)->Tensor
torch.cholesky(input:Tensor,upper:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.cholesky_inverse(input:Tensor,upper:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.cholesky_solve(input:Tensor,input2:Tensor,upper:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.choose_qparams_optimized(input:Tensor,numel:_int,n_bins:_int,ratio:_float,bit_width:_int)->Tuple[_float, _float]
torch.chunk(input:Tensor,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.clamp(self,min:_float=-inf,max:_float=inf,*,out:Optional[Tensor]=None)->Tensor
torch.clamp_max(input:Tensor,max:Number,*,out:Optional[Tensor]=None)->Tensor
torch.clamp_max_(input:Tensor,max:Number)->Tensor
torch.clamp_min(input:Tensor,min:Number,*,out:Optional[Tensor]=None)->Tensor
torch.clamp_min_(input:Tensor,min:Number)->Tensor
torch.clip(input:Tensor,min:Optional[Number]=None,max:Optional[Number]=None,*,out:Optional[Tensor]=None)->Tensor
torch.clip_(input:Tensor,min:Optional[Number]=None,max:Optional[Number]=None)->Tensor
torch.clone(input:Tensor,*,memory_format:Optional[memory_format]=None)->Tensor
torch.combinations(input:Tensor,r:_int=2,with_replacement:_bool=False)->Tensor
torch.complex(real:Tensor,imag:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.conj(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.constant_pad_nd(input:Tensor,pad:_size,value:Number=0)->Tensor
torch.conv1d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,groups:_int=1)->Tensor
torch.conv2d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,groups:_int=1)->Tensor
torch.conv3d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,groups:_int=1)->Tensor
torch.conv_tbc(input:Tensor,weight:Tensor,bias:Tensor,pad:_int=0)->Tensor
torch.conv_transpose1d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,output_padding:Union[_int,_size]=0,groups:_int=1,dilation:Union[_int,_size]=1)->Tensor
torch.conv_transpose2d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,output_padding:Union[_int,_size]=0,groups:_int=1,dilation:Union[_int,_size]=1)->Tensor
torch.conv_transpose3d(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,stride:Union[_int,_size]=1,padding:Union[_int,_size]=0,output_padding:Union[_int,_size]=0,groups:_int=1,dilation:Union[_int,_size]=1)->Tensor
torch.convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],stride:_size,padding:_size,dilation:_size,transposed:_bool,output_padding:_size,groups:_int)->Tensor
torch.cos(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.cos_(input:Tensor)->Tensor
torch.cosh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.cosh_(input:Tensor)->Tensor
torch.cosine_similarity(x1:Tensor,x2:Tensor,dim:_int=1,eps:_float=1e-08)->Tensor
torch.count_nonzero(input:Tensor,dim:Optional[_int]=None)->Tensor
torch.count_nonzero(input:Tensor,dim:_size)->Tensor
torch.cross(input:Tensor,other:Tensor,dim:Optional[_int]=None,*,out:Optional[Tensor]=None)->Tensor
torch.cudnn_affine_grid_generator(theta:Tensor,N:_int,C:_int,H:_int,W:_int)->Tensor
torch.cudnn_batch_norm(input:Tensor,weight:Tensor,bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,exponential_average_factor:_float,epsilon:_float)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch.cudnn_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.cudnn_convolution(input:Tensor,weight:Tensor,padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.cudnn_convolution(input:Tensor,weight:Tensor,padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool,allow_tf32:_bool)->Tensor
torch.cudnn_convolution_transpose(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.cudnn_convolution_transpose(input:Tensor,weight:Tensor,padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.cudnn_convolution_transpose(input:Tensor,weight:Tensor,padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool,allow_tf32:_bool)->Tensor
torch.cudnn_grid_sampler(input:Tensor,grid:Tensor)->Tensor
torch.cudnn_is_acceptable(input:Tensor)->_bool
torch.cummax(input:Tensor,dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.cummax(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.cummin(input:Tensor,dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.cummin(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.cumprod(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.cumprod(input:Tensor,dim:_int,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.cumsum(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.cumsum(input:Tensor,dim:_int,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.deg2rad(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.deg2rad_(input:Tensor)->Tensor
torch.dequantize(input:Tensor)->Tensor
torch.dequantize(tensors:Union[Tuple[Tensor,...],List[Tensor]])->Union[Tuple[Tensor, ...], List[Tensor]]
torch.det(input:Tensor)->Tensor
torch.detach(input:Tensor)->Tensor
torch.detach_(input:Tensor)->Tensor
torch.diag(input:Tensor,diagonal:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch.diag_embed(input:Tensor,offset:_int=0,dim1:_int=-2,dim2:_int=-1)->Tensor
torch.diagflat(input:Tensor,offset:_int=0)->Tensor
torch.diagonal(input:Tensor,*,outdim:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None],dim2:Union[str,ellipsis,None],offset:_int=0)->Tensor
torch.diagonal(input:Tensor,offset:_int=0,dim1:_int=0,dim2:_int=1)->Tensor
torch.digamma(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.dist(input:Tensor,other:Tensor,p:Number=2)->Tensor
torch.div(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.divide(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.divide(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.dot(input:Tensor,tensor:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch.dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch.dstack(tensors:Union[Tuple[Tensor,...],List[Tensor]],*,out:Optional[Tensor]=None)->Tensor
torch.eig(input:Tensor,eigenvectors:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_eigenvalues_eigenvectors
torch.embedding(weight:Tensor,indices:Tensor,padding_idx:_int=-1,scale_grad_by_freq:_bool=False,sparse:_bool=False)->Tensor
torch.embedding_bag(weight:Tensor,indices:Tensor,offsets:Tensor,scale_grad_by_freq:_bool=False,mode:_int=0,sparse:_bool=False,per_sample_weights:Optional[Tensor]=None,include_last_offset:_bool=False)->Tuple[Tensor, Tensor, Tensor, Tensor]
torch.embedding_renorm_(input:Tensor,indices:Tensor,max_norm:_float,norm_type:_float)->Tensor
torch.empty(*size:_int,memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty(size:_size,*,memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],memory_format:Optional[memory_format]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty_meta(*size:_int,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty_meta(size:_size,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.empty_quantized(size:_size,qtensor:Tensor)->Tensor
torch.empty_strided(size:_size,stride:_size,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.eq(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.eq(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.equal(input:Tensor,other:Tensor)->_bool
torch.erf(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.erf_(input:Tensor)->Tensor
torch.erfc(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.erfc_(input:Tensor)->Tensor
torch.erfinv(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.exp(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.exp2(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.exp2_(input:Tensor)->Tensor
torch.exp_(input:Tensor)->Tensor
torch.expm1(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.expm1_(input:Tensor)->Tensor
torch.eye(n:_int,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.eye(n:_int,m:_int,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.fake_quantize_per_channel_affine(input:Tensor,scale:Tensor,zero_point:Tensor,axis:_int,quant_min:_int,quant_max:_int)->Tensor
torch.fake_quantize_per_tensor_affine(input:Tensor,scale:_float,zero_point:_int,quant_min:_int,quant_max:_int)->Tensor
torch.fbgemm_linear_fp16_weight(input:Tensor,packed_weight:Tensor,bias:Tensor)->Tensor
torch.fbgemm_linear_fp16_weight_fp32_activation(input:Tensor,packed_weight:Tensor,bias:Tensor)->Tensor
torch.fbgemm_linear_int8_weight(input:Tensor,weight:Tensor,packed:Tensor,col_offsets:Tensor,weight_scale:Number,weight_zero_point:Number,bias:Tensor)->Tensor
torch.fbgemm_linear_int8_weight_fp32_activation(input:Tensor,weight:Tensor,packed:Tensor,col_offsets:Tensor,weight_scale:Number,weight_zero_point:Number,bias:Tensor)->Tensor
torch.fbgemm_linear_quantize_weight(input:Tensor)->Tuple[Tensor, Tensor, _float, _int]
torch.fbgemm_pack_gemm_matrix_fp16(input:Tensor)->Tensor
torch.fbgemm_pack_quantized_matrix(input:Tensor)->Tensor
torch.fbgemm_pack_quantized_matrix(input:Tensor,K:_int,N:_int)->Tensor
torch.feature_alpha_dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch.feature_alpha_dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch.feature_dropout(input:Tensor,p:_float,train:_bool)->Tensor
torch.feature_dropout_(input:Tensor,p:_float,train:_bool)->Tensor
torch.fft(input:Tensor,signal_ndim:_int,normalized:_bool=False)->Tensor
torch.fill_(input:Tensor,value:Number)->Tensor
torch.fill_(input:Tensor,value:Tensor)->Tensor
torch.fix(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.fix_(input:Tensor)->Tensor
torch.flatten(input:Tensor,dims:Sequence[Union[str,ellipsis,None]],out_dim:Union[str,ellipsis,None])->Tensor
torch.flatten(input:Tensor,start_dim:Union[str,ellipsis,None],end_dim:Union[str,ellipsis,None],out_dim:Union[str,ellipsis,None])->Tensor
torch.flatten(input:Tensor,start_dim:_int,end_dim:_int,out_dim:Union[str,ellipsis,None])->Tensor
torch.flatten(input:Tensor,start_dim:_int=0,end_dim:_int=-1)->Tensor
torch.flip(input:Tensor,dims:_size)->Tensor
torch.fliplr(input:Tensor)->Tensor
torch.flipud(input:Tensor)->Tensor
torch.floor(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.floor_(input:Tensor)->Tensor
torch.floor_divide(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.fmod(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.fmod(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.frac(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.frac_(input:Tensor)->Tensor
torch.frobenius_norm(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.frobenius_norm(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.from_file(filename:str,shared:Optional[_bool]=None,size:Optional[_int]=0,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.from_numpy(ndarray)->Tensor
torch.full(size:_size,fill_value:Number,*,names:List[Union[str,None]],layout:_layout=strided,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.full(size:_size,fill_value:Number,*,out:Optional[Tensor]=None,layout:_layout=strided,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.full_like(input:Tensor,fill_value:Number,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.gather(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,*,sparse_grad:_bool=False,out:Optional[Tensor]=None)->Tensor
torch.gather(input:Tensor,dim:_int,index:Tensor,*,sparse_grad:_bool=False,out:Optional[Tensor]=None)->Tensor
torch.gcd(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.gcd_(input:Tensor,other:Tensor)->Tensor
torch.ge(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.ge(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.geqrf(input:Tensor,*,out:Optional[Tensor]=None)->namedtuple_a_tau
torch.ger(input:Tensor,vec2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.get_default_dtype()->_dtype
torch.get_num_interop_threads()->_int
torch.get_num_threads()->_int
torch.greater(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.greater(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.greater_equal(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.greater_equal(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.grid_sampler(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch.grid_sampler_2d(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch.grid_sampler_3d(input:Tensor,grid:Tensor,interpolation_mode:_int,padding_mode:_int,align_corners:_bool)->Tensor
torch.group_norm(input:Tensor,num_groups:_int,weight:Optional[Tensor]=None,bias:Optional[Tensor]=None,eps:_float=1e-05,cudnn_enabled:_bool=True)->Tensor
torch.gru(data:Tensor,batch_sizes:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor]
torch.gru(input:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor]
torch.gru_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tensor
torch.gt(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.gt(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.hamming_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.hamming_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.hamming_window(window_length:_int,periodic:_bool,alpha:_float,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.hamming_window(window_length:_int,periodic:_bool,alpha:_float,beta:_float,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.hann_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.hann_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.hardshrink(input:Tensor,lambd:Number=0.5)->Tensor
torch.heaviside(input:Tensor,values:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.histc(input:Tensor,bins:_int=100,min:Number=0,max:Number=0,*,out:Optional[Tensor]=None)->Tensor
torch.hspmm(mat1:Tensor,mat2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.hstack(tensors:Union[Tuple[Tensor,...],List[Tensor]],*,out:Optional[Tensor]=None)->Tensor
torch.hypot(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.i0(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.i0_(input:Tensor)->Tensor
torch.ifft(input:Tensor,signal_ndim:_int,normalized:_bool=False)->Tensor
torch.imag(input:Tensor)->Tensor
torch.index_add(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch.index_add(input:Tensor,dim:_int,index:Tensor,source:Tensor)->Tensor
torch.index_copy(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,source:Tensor)->Tensor
torch.index_copy(input:Tensor,dim:_int,index:Tensor,source:Tensor)->Tensor
torch.index_fill(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch.index_fill(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,value:Tensor)->Tensor
torch.index_fill(input:Tensor,dim:_int,index:Tensor,value:Number)->Tensor
torch.index_fill(input:Tensor,dim:_int,index:Tensor,value:Tensor)->Tensor
torch.index_put(input:Tensor,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch.index_put_(input:Tensor,indices:Optional[Union[Tuple[Tensor,...],List[Tensor]]],values:Tensor,accumulate:_bool=False)->Tensor
torch.index_select(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.index_select(input:Tensor,dim:_int,index:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.init_num_threads()->None
torch.instance_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],use_input_stats:_bool,momentum:_float,eps:_float,cudnn_enabled:_bool)->Tensor
torch.int_repr(input:Tensor)->Tensor
torch.inverse(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.irfft(input:Tensor,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True,signal_sizes:_size=())->Tensor
torch.is_complex(input:Tensor)->_bool
torch.is_distributed(input:Tensor)->_bool
torch.is_floating_point(input:Tensor)->_bool
torch.is_grad_enabled()->_bool
torch.is_nonzero(input:Tensor)->_bool
torch.is_same_size(input:Tensor,other:Tensor)->_bool
torch.is_signed(input:Tensor)->_bool
torch.is_vulkan_available()->_bool
torch.isclose(input:Tensor,other:Tensor,rtol:_float=1e-05,atol:_float=1e-08,equal_nan:_bool=False)->Tensor
torch.isfinite(input:Tensor)->Tensor
torch.isinf(input:Tensor)->Tensor
torch.isnan(input:Tensor)->Tensor
torch.isneginf(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.isposinf(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.isreal(input:Tensor)->Tensor
torch.kaiser_window(window_length:_int,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.kaiser_window(window_length:_int,periodic:_bool,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.kaiser_window(window_length:_int,periodic:_bool,beta:_float,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.kthvalue(input:Tensor,k:_int,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.kthvalue(input:Tensor,k:_int,dim:_int=-1,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.layer_norm(input:Tensor,normalized_shape:_size,weight:Optional[Tensor]=None,bias:Optional[Tensor]=None,eps:_float=1e-05,cudnn_enable:_bool=True)->Tensor
torch.lcm(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.lcm_(input:Tensor,other:Tensor)->Tensor
torch.le(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.le(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.lerp(input:Tensor,end:Tensor,weight:Number,*,out:Optional[Tensor]=None)->Tensor
torch.lerp(input:Tensor,end:Tensor,weight:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.less(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.less(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.less_equal(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.less_equal(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.lgamma(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.linspace(start:Number,end:Number,steps:Optional[_int]=None,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.log(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.log10(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.log10_(input:Tensor)->Tensor
torch.log1p(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.log1p_(input:Tensor)->Tensor
torch.log2(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.log2_(input:Tensor)->Tensor
torch.log_(input:Tensor)->Tensor
torch.log_softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch.log_softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch.logaddexp(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.logaddexp2(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.logcumsumexp(input:Tensor,dim:Union[str,ellipsis,None],*,out:Optional[Tensor]=None)->Tensor
torch.logcumsumexp(input:Tensor,dim:_int,*,out:Optional[Tensor]=None)->Tensor
torch.logdet(input:Tensor)->Tensor
torch.logical_and(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.logical_not(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.logical_or(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.logical_xor(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.logit(input:Tensor,eps:Optional[_float]=None,*,out:Optional[Tensor]=None)->Tensor
torch.logit_(input:Tensor,eps:Optional[_float]=None)->Tensor
torch.logspace(start:Number,end:Number,steps:Optional[_int]=None,base:_float=10.0,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.logsumexp(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.logsumexp(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.lstm(data:Tensor,batch_sizes:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor, Tensor]
torch.lstm(input:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor, Tensor]
torch.lstm_cell(input:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tuple[Tensor, Tensor]
torch.lstsq(input:Tensor,A:Tensor,*,out:Optional[Tensor]=None)->namedtuple_solution_QR
torch.lt(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.lt(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.lu_solve(input:Tensor,LU_data:Tensor,LU_pivots:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.masked_fill(input:Tensor,mask:Tensor,value:Number)->Tensor
torch.masked_fill(input:Tensor,mask:Tensor,value:Tensor)->Tensor
torch.masked_scatter(input:Tensor,mask:Tensor,source:Tensor)->Tensor
torch.masked_select(input:Tensor,mask:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.matmul(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.matrix_exp(input:Tensor)->Tensor
torch.matrix_power(input:Tensor,n:_int)->Tensor
torch.matrix_rank(input:Tensor,symmetric:_bool=False)->Tensor
torch.matrix_rank(input:Tensor,tol:_float,symmetric:_bool=False)->Tensor
torch.max(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.max(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.max(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.max(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.max_pool1d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.max_pool1d_with_indices(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tuple[Tensor, Tensor]
torch.max_pool2d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.max_pool3d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.maximum(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.mean(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.mean(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.mean(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.median(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.median(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.median(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.min(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.min(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.min(input:Tensor,dim:_int,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.min(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.minimum(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.miopen_batch_norm(input:Tensor,weight:Tensor,bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,exponential_average_factor:_float,epsilon:_float)->Tuple[Tensor, Tensor, Tensor]
torch.miopen_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.miopen_convolution_transpose(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,output_padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.miopen_depthwise_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int,benchmark:_bool,deterministic:_bool)->Tensor
torch.miopen_rnn(input:Tensor,weight:Union[Tuple[Tensor,...],List[Tensor]],weight_stride0:_int,hx:Tensor,cx:Optional[Tensor],mode:_int,hidden_size:_int,num_layers:_int,batch_first:_bool,dropout:_float,train:_bool,bidirectional:_bool,batch_sizes:_size,dropout_state:Optional[Tensor])->Tuple[Tensor, Tensor, Tensor, Tensor, Tensor]
torch.mkldnn_adaptive_avg_pool2d(input:Tensor,output_size:Union[_int,_size])->Tensor
torch.mkldnn_convolution(input:Tensor,weight:Tensor,bias:Optional[Tensor],padding:_size,stride:_size,dilation:_size,groups:_int)->Tensor
torch.mkldnn_convolution_backward_weights(weight_size:_size,grad_output:Tensor,input:Tensor,padding:_size,stride:_size,dilation:_size,groups:_int,bias_defined:_bool)->Tuple[Tensor, Tensor]
torch.mkldnn_max_pool2d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.mkldnn_max_pool3d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.mm(input:Tensor,mat2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.mode(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.mode(input:Tensor,dim:_int=-1,keepdim:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.movedim(input:Tensor,source:_int,destination:_int)->Tensor
torch.movedim(input:Tensor,source:_size,destination:_size)->Tensor
torch.mul(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.multinomial(input:Tensor,num_samples:_int,replacement:_bool=False,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch.multiply(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.multiply(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.mv(input:Tensor,vec:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.mvlgamma(input:Tensor,p:_int)->Tensor
torch.nanquantile(input:Tensor,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.nanquantile(input:Tensor,q:_float,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.nansum(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.nansum(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.narrow(input:Tensor,dim:_int,start:Tensor,length:_int)->Tensor
torch.narrow(input:Tensor,dim:_int,start:_int,length:_int)->Tensor
torch.native_batch_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],running_mean:Optional[Tensor],running_var:Optional[Tensor],training:_bool,momentum:_float,eps:_float,*,out:Optional[Tensor]=None)->Tuple[Tensor, Tensor, Tensor]
torch.native_group_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],N:_int,C:_int,HxW:_int,group:_int,eps:_float)->Tuple[Tensor, Tensor, Tensor]
torch.native_layer_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],M:_int,N:_int,eps:_float)->Tuple[Tensor, Tensor, Tensor]
torch.native_norm(input:Tensor,p:Number=2)->Tensor
torch.native_norm(input:Tensor,p:Optional[Number],dim:Union[_int,_size],keepdim:_bool,dtype:Optional[_dtype])->Tensor
torch.ne(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.ne(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.neg(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.neg_(input:Tensor)->Tensor
torch.negative(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.negative_(input:Tensor)->Tensor
torch.nextafter(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.nonzero(input:Tensor,*,as_tuple:bool=...)->Tensor
torch.nonzero(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.norm_except_dim(v:Tensor,pow:_int=2,dim:_int=0)->Tensor
torch.normal(mean:Tensor,std:Tensor,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch.normal(mean:Tensor,std:_float=1,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch.normal(mean:_float,std:Tensor,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None)->Tensor
torch.normal(mean:_float,std:_float,size:_size,*,generator:Optional[Generator]=None,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.not_equal(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.not_equal(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.nuclear_norm(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.nuclear_norm(input:Tensor,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.numel(self:Tensor)->_int
torch.ones(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.ones(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.ones(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.ones(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.ones_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.orgqr(input:Tensor,input2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.ormqr(input:Tensor,input2:Tensor,input3:Tensor,left:_bool=True,transpose:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.outer(input:Tensor,vec2:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.pairwise_distance(x1:Tensor,x2:Tensor,p:_float=2,eps:_float=1e-06,keepdim:_bool=False)->Tensor
torch.pdist(input:Tensor,p:_float=2)->Tensor
torch.pinverse(input:Tensor,rcond:_float=1e-15)->Tensor
torch.pixel_shuffle(input:Tensor,upscale_factor:_int)->Tensor
torch.poisson(input:Tensor,generator:Optional[Generator]=None)->Tensor
torch.poisson_nll_loss(input:Tensor,target:Tensor,log_input:_bool,full:_bool,eps:_float,reduction:_int)->Tensor
torch.polar(abs:Tensor,angle:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.polygamma(n:_int,input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.pow(input:Tensor,exponent:Number,*,out:Optional[Tensor]=None)->Tensor
torch.pow(input:Tensor,exponent:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.pow(self:Number,exponent:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.prelu(input:Tensor,weight:Tensor)->Tensor
torch.prod(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.prod(input:Tensor,dim:Union[str,ellipsis,None],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.prod(input:Tensor,dim:_int,keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.promote_types(type1:_dtype,type2:_dtype)->_dtype
torch.q_per_channel_axis(input:Tensor)->_int
torch.q_per_channel_scales(input:Tensor)->Tensor
torch.q_per_channel_zero_points(input:Tensor)->Tensor
torch.q_scale(input:Tensor)->_float
torch.q_zero_point(input:Tensor)->_int
torch.qr(input:Tensor,some:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_Q_R
torch.quantile(input:Tensor,q:Tensor,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.quantile(input:Tensor,q:_float,dim:Optional[_int]=None,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.quantize_per_channel(input:Tensor,scales:Tensor,zero_points:Tensor,axis:_int,dtype:_dtype)->Tensor
torch.quantize_per_tensor(input:Tensor,scale:_float,zero_point:_int,dtype:_dtype)->Tensor
torch.quantize_per_tensor(tensors:Union[Tuple[Tensor,...],List[Tensor]],scales:Tensor,zero_points:Tensor,dtype:_dtype)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.quantized_batch_norm(input:Tensor,weight:Optional[Tensor],bias:Optional[Tensor],mean:Tensor,var:Tensor,eps:_float,output_scale:_float,output_zero_point:_int)->Tensor
torch.quantized_gru_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tensor
torch.quantized_lstm_cell(input:Tensor,hx:Union[Tuple[Tensor,...],List[Tensor]],w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tuple[Tensor, Tensor]
torch.quantized_max_pool1d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.quantized_max_pool2d(input:Tensor,kernel_size:Union[_int,_size],stride:Union[_int,_size]=(),padding:Union[_int,_size]=0,dilation:Union[_int,_size]=1,ceil_mode:_bool=False)->Tensor
torch.quantized_rnn_relu_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tensor
torch.quantized_rnn_tanh_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Tensor,b_hh:Tensor,packed_ih:Tensor,packed_hh:Tensor,col_offsets_ih:Tensor,col_offsets_hh:Tensor,scale_ih:Number,scale_hh:Number,zero_point_ih:Number,zero_point_hh:Number)->Tensor
torch.rad2deg(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.rad2deg_(input:Tensor)->Tensor
torch.rand(*size:_int,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(*size:_int,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(size:_size,*,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(size:_size,*,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.rand_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randint(high:_int,size:_size,*,generator:Optional[Generator]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randint(low:_int,high:_int,size:_size,*,generator:Optional[Generator]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randint_like(input:Tensor,high:_int,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randint_like(input:Tensor,low:_int,high:_int,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(*size:_int,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(*size:_int,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(size:_size,*,generator:Optional[Generator],names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(size:_size,*,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randn_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randperm(n:_int,*,generator:Optional[Generator],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.randperm(n:_int,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.range(start:Number,end:Number,step:Number=1,*,out:Optional[Tensor]=None,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.real(input:Tensor)->Tensor
torch.reciprocal(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.reciprocal_(input:Tensor)->Tensor
torch.relu(input:Tensor)->Tensor
torch.relu_(input:Tensor)->Tensor
torch.remainder(input:Tensor,other:Number,*,out:Optional[Tensor]=None)->Tensor
torch.remainder(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.renorm(input:Tensor,p:Number,dim:_int,maxnorm:Number,*,out:Optional[Tensor]=None)->Tensor
torch.repeat_interleave(input:Tensor,repeats:Tensor,dim:Optional[_int]=None)->Tensor
torch.repeat_interleave(input:Tensor,repeats:_int,dim:Optional[_int]=None)->Tensor
torch.repeat_interleave(repeats:Tensor)->Tensor
torch.reshape(input:Tensor,shape:_size)->Tensor
torch.resize_as_(input:Tensor,the_template:Tensor,*,memory_format:Optional[memory_format]=None)->Tensor
torch.result_type(scalar1:Number,scalar2:Number)->_dtype
torch.result_type(scalar:Number,tensor:Tensor)->_dtype
torch.result_type(tensor:Tensor,other:Number)->_dtype
torch.result_type(tensor:Tensor,other:Tensor)->_dtype
torch.rfft(input:Tensor,signal_ndim:_int,normalized:_bool=False,onesided:_bool=True)->Tensor
torch.rnn_relu(data:Tensor,batch_sizes:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor]
torch.rnn_relu(input:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor]
torch.rnn_relu_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tensor
torch.rnn_tanh(data:Tensor,batch_sizes:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool)->Tuple[Tensor, Tensor]
torch.rnn_tanh(input:Tensor,hx:Tensor,params:Union[Tuple[Tensor,...],List[Tensor]],has_biases:_bool,num_layers:_int,dropout:_float,train:_bool,bidirectional:_bool,batch_first:_bool)->Tuple[Tensor, Tensor]
torch.rnn_tanh_cell(input:Tensor,hx:Tensor,w_ih:Tensor,w_hh:Tensor,b_ih:Optional[Tensor]=None,b_hh:Optional[Tensor]=None)->Tensor
torch.roll(input:Tensor,shifts:Union[_int,_size],dims:Union[_int,_size]=())->Tensor
torch.rot90(input:Tensor,k:_int=1,dims:_size=(0,1))->Tensor
torch.round(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.round_(input:Tensor)->Tensor
torch.rrelu(input:Tensor,lower:Number=0.125,upper:Number=0.3333333333333333,training:_bool=False,generator:Optional[Generator]=None)->Tensor
torch.rrelu_(input:Tensor,lower:Number=0.125,upper:Number=0.3333333333333333,training:_bool=False,generator:Optional[Generator]=None)->Tensor
torch.rsqrt(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.rsqrt_(input:Tensor)->Tensor
torch.rsub(input:Tensor,other:Number,alpha:Number=1)->Tensor
torch.rsub(input:Tensor,other:Tensor,*,alpha:Number=1)->Tensor
torch.scalar_tensor(s:Number,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.scatter(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch.scatter(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,value:Number)->Tensor
torch.scatter(input:Tensor,dim:_int,index:Tensor,src:Tensor)->Tensor
torch.scatter(input:Tensor,dim:_int,index:Tensor,value:Number)->Tensor
torch.scatter_add(input:Tensor,dim:Union[str,ellipsis,None],index:Tensor,src:Tensor)->Tensor
torch.scatter_add(input:Tensor,dim:_int,index:Tensor,src:Tensor)->Tensor
torch.searchsorted(sorted_sequence:Tensor,input:Tensor,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch.searchsorted(sorted_sequence:Tensor,self:Number,*,out_int32:_bool=False,right:_bool=False,out:Optional[Tensor]=None)->Tensor
torch.select(input:Tensor,dim:Union[str,ellipsis,None],index:_int)->Tensor
torch.select(input:Tensor,dim:_int,index:_int)->Tensor
torch.selu(input:Tensor)->Tensor
torch.selu_(input:Tensor)->Tensor
torch.set_flush_denormal(mode:_bool)->_bool
torch.set_num_interop_threads(num:_int)->None
torch.set_num_threads(num:_int)->None
torch.sgn(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.sigmoid(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.sigmoid_(input:Tensor)->Tensor
torch.sign(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.signbit(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.sin(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.sin_(input:Tensor)->Tensor
torch.sinh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.sinh_(input:Tensor)->Tensor
torch.slogdet(input:Tensor)->namedtuple_sign_logabsdet
torch.smm(input:Tensor,mat2:Tensor)->Tensor
torch.softmax(input:Tensor,dim:Union[str,ellipsis,None],*,dtype:Optional[_dtype]=None)->Tensor
torch.softmax(input:Tensor,dim:_int,dtype:Optional[_dtype]=None)->Tensor
torch.solve(input:Tensor,A:Tensor,*,out:Optional[Tensor]=None)->namedtuple_solution_LU
torch.sort(input:Tensor,dim:Union[str,ellipsis,None],descending:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.sort(input:Tensor,dim:_int=-1,descending:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.sparse_coo_tensor(indices:Tensor,values:Union[Tensor,List],size:Optional[_size]=None,*,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.split_with_sizes(input:Tensor,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.sqrt(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.sqrt_(input:Tensor)->Tensor
torch.square(input:Tensor)->Tensor
torch.square_(input:Tensor)->Tensor
torch.squeeze(input:Tensor)->Tensor
torch.squeeze(input:Tensor,dim:Union[str,ellipsis,None])->Tensor
torch.squeeze(input:Tensor,dim:_int)->Tensor
torch.sspaddmm(beta:Number,self:Tensor,alpha:Number,mat1:Tensor,mat2:Tensor)->Tensor
torch.sspaddmm(beta:Number,self:Tensor,mat1:Tensor,mat2:Tensor)->Tensor
torch.sspaddmm(input:Tensor,mat1:Tensor,mat2:Tensor,*,beta:Number=1,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.stack(tensors:Union[Tuple[Tensor,...],List[Tensor]],dim:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch.std(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.std(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.std(input:Tensor,unbiased:_bool=True,*,out:Optional[Tensor]=None)->Tensor
torch.std_mean(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch.std_mean(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch.std_mean(input:Tensor,unbiased:_bool=True)->Tuple[Tensor, Tensor]
torch.sub(input:Union[Tensor,Number],other:Union[Tensor,Number],*,alpha:Optional[Number]=1,out:Optional[Tensor]=None)->Tensor
torch.sub(self:Tensor,alpha:Number,other:Tensor)->Tensor
torch.sub(self:Tensor,alpha:Number,other:Tensor,*,out:Tensor)->Tensor
torch.subtract(input:Tensor,other:Number,alpha:Number=1,*,out:Optional[Tensor]=None)->Tensor
torch.subtract(input:Tensor,other:Tensor,*,alpha:Number=1,out:Optional[Tensor]=None)->Tensor
torch.sum(input:Tensor,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.sum(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.sum(input:Tensor,dim:Union[_int,_size],keepdim:_bool=False,*,dtype:Optional[_dtype]=None,out:Optional[Tensor]=None)->Tensor
torch.svd(input:Tensor,some:_bool=True,compute_uv:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_U_S_V
torch.symeig(input:Tensor,eigenvectors:_bool=False,upper:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_eigenvalues_eigenvectors
torch.t(input:Tensor)->Tensor
torch.take(input:Tensor,index:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.tan(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.tan_(input:Tensor)->Tensor
torch.tanh(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.tanh_(input:Tensor)->Tensor
torch.tensor(data:Any,dtype:Optional[_dtype]=None,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.threshold(input:Tensor,threshold:Number,value:Number,*,out:Optional[Tensor]=None)->Tensor
torch.threshold_(input:Tensor,threshold:Number,value:Number)->Tensor
torch.topk(input:Tensor,k:_int,dim:_int=-1,largest:_bool=True,sorted:_bool=True,*,out:Optional[Tensor]=None)->namedtuple_values_indices
torch.trace(input:Tensor)->Tensor
torch.transpose(input:Tensor,dim0:Union[str,ellipsis,None],dim1:Union[str,ellipsis,None])->Tensor
torch.transpose(input:Tensor,dim0:_int,dim1:_int)->Tensor
torch.trapz(y:Tensor,*,dx:_float=1,dim:_int=-1)->Tensor
torch.trapz(y:Tensor,x:Tensor,*,dim:_int=-1)->Tensor
torch.triangular_solve(input:Tensor,A:Tensor,upper:_bool=True,transpose:_bool=False,unitriangular:_bool=False,*,out:Optional[Tensor]=None)->namedtuple_solution_cloned_coefficient
torch.tril(input:Tensor,diagonal:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch.tril_indices(row:_int,col:_int,offset:_int=0,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.triu(input:Tensor,diagonal:_int=0,*,out:Optional[Tensor]=None)->Tensor
torch.triu_indices(row:_int,col:_int,offset:_int=0,*,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.true_divide(input:Union[Tensor,Number],other:Union[Tensor,Number],*,out:Optional[Tensor]=None)->Tensor
torch.trunc(input:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.trunc_(input:Tensor)->Tensor
torch.unbind(input:Tensor,dim:Union[str,ellipsis,None])->Union[Tuple[Tensor, ...], List[Tensor]]
torch.unbind(input:Tensor,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.unique_dim(input:Tensor,dim:_int,sorted:_bool=True,return_inverse:_bool=False,return_counts:_bool=False)->Tuple[Tensor, Tensor, Tensor]
torch.unsafe_chunk(input:Tensor,chunks:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.unsafe_split(input:Tensor,split_size:_int,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.unsafe_split_with_sizes(input:Tensor,split_sizes:_size,dim:_int=0)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.unsqueeze(input:Tensor,dim:_int)->Tensor
torch.vander(x:Tensor,N:Optional[_int]=None,increasing:_bool=False)->Tensor
torch.var(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.var(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False,*,out:Optional[Tensor]=None)->Tensor
torch.var(input:Tensor,unbiased:_bool=True,*,out:Optional[Tensor]=None)->Tensor
torch.var_mean(input:Tensor,dim:Sequence[Union[str,ellipsis,None]],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch.var_mean(input:Tensor,dim:Union[_int,_size],unbiased:_bool=True,keepdim:_bool=False)->Tuple[Tensor, Tensor]
torch.var_mean(input:Tensor,unbiased:_bool=True)->Tuple[Tensor, Tensor]
torch.vdot(input:Tensor,other:Tensor,*,out:Optional[Tensor]=None)->Tensor
torch.view_as_complex(input:Tensor)->Tensor
torch.view_as_real(input:Tensor)->Tensor
torch.vstack(tensors:Union[Tuple[Tensor,...],List[Tensor]],*,out:Optional[Tensor]=None)->Tensor
torch.where(condition:Tensor)->Union[Tuple[Tensor, ...], List[Tensor]]
torch.where(condition:Tensor,input:Tensor,other:Number)->Tensor
torch.where(condition:Tensor,input:Tensor,other:Tensor)->Tensor
torch.where(condition:Tensor,self:Number,other:Number)->Tensor
torch.where(condition:Tensor,self:Number,other:Tensor)->Tensor
torch.zero_(input:Tensor)->Tensor
torch.zeros(*size:_int,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.zeros(*size:_int,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.zeros(size:_size,*,names:Optional[Sequence[Union[str,ellipsis,None]]],out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.zeros(size:_size,*,out:Optional[Tensor]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor
torch.zeros_like(input:Tensor,*,memory_format:Optional[memory_format]=None,dtype:_dtype=None,layout:_layout=strided,device:Union[_device,str,None]=None,requires_grad:_bool=False)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_onnx.pyi----------------------------------------
torch._C._onnx.OperatorExportTypes(Enum)
torch._C._onnx.TensorProtoDataType(Enum)
torch._C._onnx.TrainingMode(Enum)
torch._onnx.TrainingMode(Enum)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_nvtx.pyi----------------------------------------
torch._C._nvtx.markA(message:str)->None
torch._C._nvtx.rangePop()->int
torch._C._nvtx.rangePushA(message:str)->int
torch._nvtx.markA(message:str)->None
torch._nvtx.rangePop()->int
torch._nvtx.rangePushA(message:str)->int


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_functions.pyi----------------------------------------
torch._C._functions.DelayedError(self,msg:AnyStr,num_inputs:int)
torch._C._functions.DelayedError.__init__(self,msg:AnyStr,num_inputs:int)
torch._C._functions.UndefinedGrad(self)
torch._C._functions.UndefinedGrad.__init__(self)
torch._functions.DelayedError(self,msg:AnyStr,num_inputs:int)
torch._functions.UndefinedGrad(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/_C/_autograd.pyi----------------------------------------
torch._C._autograd.ProfilerConfig(self,state:ProfilerState,report_input_shapes:bool,profile_memory:bool,with_stack:bool)
torch._C._autograd.ProfilerConfig.__init__(self,state:ProfilerState,report_input_shapes:bool,profile_memory:bool,with_stack:bool)
torch._C._autograd.ProfilerEvent
torch._C._autograd.ProfilerEvent.cpu_elapsed_us(self,other:ProfilerEvent)->float
torch._C._autograd.ProfilerEvent.cpu_memory_usage(self)->int
torch._C._autograd.ProfilerEvent.cuda_elapsed_us(self,other:ProfilerEvent)->float
torch._C._autograd.ProfilerEvent.cuda_memory_usage(self)->int
torch._C._autograd.ProfilerEvent.device(self)->int
torch._C._autograd.ProfilerEvent.handle(self)->int
torch._C._autograd.ProfilerEvent.has_cuda(self)->bool
torch._C._autograd.ProfilerEvent.is_remote(self)->bool
torch._C._autograd.ProfilerEvent.kind(self)->int
torch._C._autograd.ProfilerEvent.name(self)->str
torch._C._autograd.ProfilerEvent.node_id(self)->int
torch._C._autograd.ProfilerEvent.sequence_nr(self)->int
torch._C._autograd.ProfilerEvent.shapes(self)->List[List[int]]
torch._C._autograd.ProfilerEvent.thread_id(self)->int
torch._C._autograd.ProfilerState(Enum)
torch._C._autograd._disable_profiler()->List[List[ProfilerEvent]]
torch._C._autograd._enable_profiler(config:ProfilerConfig)->None
torch._C._autograd._enable_record_function(enable:bool)->None
torch._C._autograd._profiler_enabled()->bool
torch._C._autograd._set_empty_test_observer(is_global:bool,sampling_prob:float)->None
torch._autograd.ProfilerConfig(self,state:ProfilerState,report_input_shapes:bool,profile_memory:bool,with_stack:bool)
torch._autograd.ProfilerEvent
torch._autograd.ProfilerEvent.cpu_elapsed_us(self,other:ProfilerEvent)->float
torch._autograd.ProfilerEvent.cpu_memory_usage(self)->int
torch._autograd.ProfilerEvent.cuda_elapsed_us(self,other:ProfilerEvent)->float
torch._autograd.ProfilerEvent.cuda_memory_usage(self)->int
torch._autograd.ProfilerEvent.device(self)->int
torch._autograd.ProfilerEvent.handle(self)->int
torch._autograd.ProfilerEvent.has_cuda(self)->bool
torch._autograd.ProfilerEvent.is_remote(self)->bool
torch._autograd.ProfilerEvent.kind(self)->int
torch._autograd.ProfilerEvent.name(self)->str
torch._autograd.ProfilerEvent.node_id(self)->int
torch._autograd.ProfilerEvent.sequence_nr(self)->int
torch._autograd.ProfilerEvent.shapes(self)->List[List[int]]
torch._autograd.ProfilerEvent.thread_id(self)->int
torch._autograd.ProfilerState(Enum)
torch._autograd._disable_profiler()->List[List[ProfilerEvent]]
torch._autograd._enable_profiler(config:ProfilerConfig)->None
torch._autograd._enable_record_function(enable:bool)->None
torch._autograd._profiler_enabled()->bool
torch._autograd._set_empty_test_observer(is_global:bool,sampling_prob:float)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/init.py----------------------------------------
A:torch.nn.init.l->norm_cdf((a - mean) / std)
A:torch.nn.init.u->norm_cdf((b - mean) / std)
A:torch.nn.init.dimensions->tensor.dim()
A:torch.nn.init.sizes->tensor.size()
A:torch.nn.init.min_dim->min(out_chans_per_grp, sizes[1])
A:torch.nn.init.num_input_fmaps->tensor.size(1)
A:torch.nn.init.num_output_fmaps->tensor.size(0)
A:torch.nn.init.receptive_field_size->tensor[0][0].numel()
A:torch.nn.init.(fan_in, fan_out)->_calculate_fan_in_and_fan_out(tensor)
A:torch.nn.init.mode->mode.lower().lower()
A:torch.nn.init.fan->_calculate_correct_fan(tensor, mode)
A:torch.nn.init.gain->calculate_gain(nonlinearity, a)
A:torch.nn.init.rows->tensor.size(0)
A:torch.nn.init.flattened->tensor.new(rows, cols).normal_(0, 1)
A:torch.nn.init.(q, r)->torch.qr(flattened)
A:torch.nn.init.d->torch.diag(r, 0)
A:torch.nn.init.ph->torch.diag(r, 0).sign()
A:torch.nn.init.num_zeros->int(math.ceil(sparsity * rows))
A:torch.nn.init.row_indices->torch.randperm(rows)
A:torch.nn.init.deprecated_init.__doc__->'\n    {old_name}(...)\n\n    .. warning::\n        This method is now deprecated in favor of :func:`torch.nn.init.{new_name}`.\n\n    See :func:`~torch.nn.init.{new_name}` for details.'.format(old_name=old_name, new_name=new_name)
A:torch.nn.init.uniform->_make_deprecate(uniform_)
A:torch.nn.init.normal->_make_deprecate(normal_)
A:torch.nn.init.constant->_make_deprecate(constant_)
A:torch.nn.init.eye->_make_deprecate(eye_)
A:torch.nn.init.dirac->_make_deprecate(dirac_)
A:torch.nn.init.xavier_uniform->_make_deprecate(xavier_uniform_)
A:torch.nn.init.xavier_normal->_make_deprecate(xavier_normal_)
A:torch.nn.init.kaiming_uniform->_make_deprecate(kaiming_uniform_)
A:torch.nn.init.kaiming_normal->_make_deprecate(kaiming_normal_)
A:torch.nn.init.orthogonal->_make_deprecate(orthogonal_)
A:torch.nn.init.sparse->_make_deprecate(sparse_)
torch.nn.init._calculate_correct_fan(tensor,mode)
torch.nn.init._calculate_fan_in_and_fan_out(tensor)
torch.nn.init._make_deprecate(meth)
torch.nn.init._no_grad_fill_(tensor,val)
torch.nn.init._no_grad_normal_(tensor,mean,std)
torch.nn.init._no_grad_trunc_normal_(tensor,mean,std,a,b)
torch.nn.init._no_grad_uniform_(tensor,a,b)
torch.nn.init._no_grad_zero_(tensor)
torch.nn.init.calculate_gain(nonlinearity,param=None)
torch.nn.init.constant_(tensor,val)
torch.nn.init.dirac_(tensor,groups=1)
torch.nn.init.eye_(tensor)
torch.nn.init.kaiming_normal_(tensor,a=0,mode='fan_in',nonlinearity='leaky_relu')
torch.nn.init.kaiming_uniform_(tensor,a=0,mode='fan_in',nonlinearity='leaky_relu')
torch.nn.init.normal_(tensor,mean=0.0,std=1.0)
torch.nn.init.ones_(tensor)
torch.nn.init.orthogonal_(tensor,gain=1)
torch.nn.init.sparse_(tensor,sparsity,std=0.01)
torch.nn.init.trunc_normal_(tensor,mean=0.0,std=1.0,a=-2.0,b=2.0)
torch.nn.init.uniform_(tensor,a=0.0,b=1.0)
torch.nn.init.xavier_normal_(tensor,gain=1.0)
torch.nn.init.xavier_uniform_(tensor,gain=1.0)
torch.nn.init.zeros_(tensor)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/common_types.py----------------------------------------
A:torch.nn.common_types.T->TypeVar('T')


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parameter.py----------------------------------------
A:torch.nn.parameter.data->torch.Tensor()
A:torch.nn.parameter.result->type(self)(self.data.clone(memory_format=torch.preserve_format), self.requires_grad)
torch.nn.Parameter(cls,data=None,requires_grad=True)
torch.nn.Parameter.__deepcopy__(self,memo)
torch.nn.Parameter.__reduce_ex__(self,proto)
torch.nn.Parameter.__repr__(self)
torch.nn.parameter.Parameter(cls,data=None,requires_grad=True)
torch.nn.parameter.Parameter.__deepcopy__(self,memo)
torch.nn.parameter.Parameter.__new__(cls,data=None,requires_grad=True)
torch.nn.parameter.Parameter.__reduce_ex__(self,proto)
torch.nn.parameter.Parameter.__repr__(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parameter.pyi----------------------------------------
torch.nn.parameter.Parameter.__init__(self,data:Tensor=...,requires_grad:builtins.bool=...)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/grad.py----------------------------------------
A:torch.nn.grad.input_size->list(input_size)
A:torch.nn.grad.stride->_triple(stride)
A:torch.nn.grad.padding->_triple(padding)
A:torch.nn.grad.dilation->_triple(dilation)
A:torch.nn.grad.grad_input_padding->_grad_input_padding(grad_output, input_size, stride, padding, kernel_size, dilation)
A:torch.nn.grad.grad_output->grad_output.contiguous().view(grad_output.shape[0] * grad_output.shape[1], 1, grad_output.shape[2], grad_output.shape[3], grad_output.shape[4]).contiguous().view(grad_output.shape[0] * grad_output.shape[1], 1, grad_output.shape[2], grad_output.shape[3], grad_output.shape[4])
A:torch.nn.grad.input->input.contiguous().view(1, input.shape[0] * input.shape[1], input.shape[2], input.shape[3], input.shape[4]).contiguous().view(1, input.shape[0] * input.shape[1], input.shape[2], input.shape[3], input.shape[4])
A:torch.nn.grad.grad_weight->grad_weight.contiguous().view(min_batch, grad_weight.shape[1] // min_batch, grad_weight.shape[2], grad_weight.shape[3], grad_weight.shape[4]).contiguous().view(min_batch, grad_weight.shape[1] // min_batch, grad_weight.shape[2], grad_weight.shape[3], grad_weight.shape[4])
torch.nn.grad._grad_input_padding(grad_output,input_size,stride,padding,kernel_size,dilation=None)
torch.nn.grad.conv1d_input(input_size,weight,grad_output,stride=1,padding=0,dilation=1,groups=1)
torch.nn.grad.conv1d_weight(input,weight_size,grad_output,stride=1,padding=0,dilation=1,groups=1)
torch.nn.grad.conv2d_input(input_size,weight,grad_output,stride=1,padding=0,dilation=1,groups=1)
torch.nn.grad.conv2d_weight(input,weight_size,grad_output,stride=1,padding=0,dilation=1,groups=1)
torch.nn.grad.conv3d_input(input_size,weight,grad_output,stride=1,padding=0,dilation=1,groups=1)
torch.nn.grad.conv3d_weight(input,weight_size,grad_output,stride=1,padding=0,dilation=1,groups=1)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/functional.py----------------------------------------
A:torch.nn.functional.conv1d->_add_docstr(torch.conv1d, '\nconv1d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n\nApplies a 1D convolution over an input signal composed of several input\nplanes.\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nSee :class:`~torch.nn.Conv1d` for details and output shape.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n    weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kW)`\n    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n    stride: the stride of the convolving kernel. Can be a single number or\n      a one-element tuple `(sW,)`. Default: 1\n    padding: implicit paddings on both sides of the input. Can be a\n      single number or a one-element tuple `(padW,)`. Default: 0\n    dilation: the spacing between kernel elements. Can be a single number or\n      a one-element tuple `(dW,)`. Default: 1\n    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by\n      the number of groups. Default: 1\n\nExamples::\n\n    >>> filters = torch.randn(33, 16, 3)\n    >>> inputs = torch.randn(20, 16, 50)\n    >>> F.conv1d(inputs, filters)\n')
A:torch.nn.functional.conv2d->_add_docstr(torch.conv2d, '\nconv2d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n\nApplies a 2D convolution over an input image composed of several input\nplanes.\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nSee :class:`~torch.nn.Conv2d` for details and output shape.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n    weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kH , kW)`\n    bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: ``None``\n    stride: the stride of the convolving kernel. Can be a single number or a\n      tuple `(sH, sW)`. Default: 1\n    padding: implicit paddings on both sides of the input. Can be a\n      single number or a tuple `(padH, padW)`. Default: 0\n    dilation: the spacing between kernel elements. Can be a single number or\n      a tuple `(dH, dW)`. Default: 1\n    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n      number of groups. Default: 1\n\nExamples::\n\n    >>> # With square kernels and equal stride\n    >>> filters = torch.randn(8,4,3,3)\n    >>> inputs = torch.randn(1,4,5,5)\n    >>> F.conv2d(inputs, filters, padding=1)\n')
A:torch.nn.functional.conv3d->_add_docstr(torch.conv3d, '\nconv3d(input, weight, bias=None, stride=1, padding=0, dilation=1, groups=1) -> Tensor\n\nApplies a 3D convolution over an input image composed of several input\nplanes.\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nSee :class:`~torch.nn.Conv3d` for details and output shape.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n    weight: filters of shape :math:`(\\text{out\\_channels} , \\frac{\\text{in\\_channels}}{\\text{groups}} , kT , kH , kW)`\n    bias: optional bias tensor of shape :math:`(\\text{out\\_channels})`. Default: None\n    stride: the stride of the convolving kernel. Can be a single number or a\n      tuple `(sT, sH, sW)`. Default: 1\n    padding: implicit paddings on both sides of the input. Can be a\n      single number or a tuple `(padT, padH, padW)`. Default: 0\n    dilation: the spacing between kernel elements. Can be a single number or\n      a tuple `(dT, dH, dW)`. Default: 1\n    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by\n      the number of groups. Default: 1\n\nExamples::\n\n    >>> filters = torch.randn(33, 16, 3, 3, 3)\n    >>> inputs = torch.randn(20, 16, 50, 10, 20)\n    >>> F.conv3d(inputs, filters)\n')
A:torch.nn.functional.conv_transpose1d->_add_docstr(torch.conv_transpose1d, '\nconv_transpose1d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n\nApplies a 1D transposed convolution operator over an input signal\ncomposed of several input planes, sometimes also called "deconvolution".\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nSee :class:`~torch.nn.ConvTranspose1d` for details and output shape.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kW)`\n    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n    stride: the stride of the convolving kernel. Can be a single number or a\n      tuple ``(sW,)``. Default: 1\n    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n      sides of each dimension in the input. Can be a single number or a tuple\n      ``(padW,)``. Default: 0\n    output_padding: additional size added to one side of each dimension in the\n      output shape. Can be a single number or a tuple ``(out_padW)``. Default: 0\n    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n      number of groups. Default: 1\n    dilation: the spacing between kernel elements. Can be a single number or\n      a tuple ``(dW,)``. Default: 1\n\nExamples::\n\n    >>> inputs = torch.randn(20, 16, 50)\n    >>> weights = torch.randn(16, 33, 5)\n    >>> F.conv_transpose1d(inputs, weights)\n')
A:torch.nn.functional.conv_transpose2d->_add_docstr(torch.conv_transpose2d, '\nconv_transpose2d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n\nApplies a 2D transposed convolution operator over an input image\ncomposed of several input planes, sometimes also called "deconvolution".\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nSee :class:`~torch.nn.ConvTranspose2d` for details and output shape.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kH , kW)`\n    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n    stride: the stride of the convolving kernel. Can be a single number or a\n      tuple ``(sH, sW)``. Default: 1\n    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n      sides of each dimension in the input. Can be a single number or a tuple\n      ``(padH, padW)``. Default: 0\n    output_padding: additional size added to one side of each dimension in the\n      output shape. Can be a single number or a tuple ``(out_padH, out_padW)``.\n      Default: 0\n    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n      number of groups. Default: 1\n    dilation: the spacing between kernel elements. Can be a single number or\n      a tuple ``(dH, dW)``. Default: 1\n\nExamples::\n\n    >>> # With square kernels and equal stride\n    >>> inputs = torch.randn(1, 4, 5, 5)\n    >>> weights = torch.randn(4, 8, 3, 3)\n    >>> F.conv_transpose2d(inputs, weights, padding=1)\n')
A:torch.nn.functional.conv_transpose3d->_add_docstr(torch.conv_transpose3d, '\nconv_transpose3d(input, weight, bias=None, stride=1, padding=0, output_padding=0, groups=1, dilation=1) -> Tensor\n\nApplies a 3D transposed convolution operator over an input image\ncomposed of several input planes, sometimes also called "deconvolution"\n\nThis operator supports :ref:`TensorFloat32<tf32_on_ampere>`.\n\nSee :class:`~torch.nn.ConvTranspose3d` for details and output shape.\n\nNote:\n    In some circumstances when using the CUDA backend with CuDNN, this operator\n    may select a nondeterministic algorithm to increase performance. If this is\n    undesirable, you can try to make the operation deterministic (potentially at\n    a performance cost) by setting ``torch.backends.cudnn.deterministic =\n    True``.\n    Please see the notes on :doc:`/notes/randomness` for background.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iT , iH , iW)`\n    weight: filters of shape :math:`(\\text{in\\_channels} , \\frac{\\text{out\\_channels}}{\\text{groups}} , kT , kH , kW)`\n    bias: optional bias of shape :math:`(\\text{out\\_channels})`. Default: None\n    stride: the stride of the convolving kernel. Can be a single number or a\n      tuple ``(sT, sH, sW)``. Default: 1\n    padding: ``dilation * (kernel_size - 1) - padding`` zero-padding will be added to both\n      sides of each dimension in the input. Can be a single number or a tuple\n      ``(padT, padH, padW)``. Default: 0\n    output_padding: additional size added to one side of each dimension in the\n      output shape. Can be a single number or a tuple\n      ``(out_padT, out_padH, out_padW)``. Default: 0\n    groups: split input into groups, :math:`\\text{in\\_channels}` should be divisible by the\n      number of groups. Default: 1\n    dilation: the spacing between kernel elements. Can be a single number or\n      a tuple `(dT, dH, dW)`. Default: 1\n\nExamples::\n\n    >>> inputs = torch.randn(20, 16, 50, 10, 20)\n    >>> weights = torch.randn(16, 33, 3, 3, 3)\n    >>> F.conv_transpose3d(inputs, weights)\n')
A:torch.nn.functional.conv_tbc->_add_docstr(torch.conv_tbc, '\nApplies a 1-dimensional sequence convolution over an input sequence.\nInput and output dimensions are (Time, Batch, Channels) - hence TBC.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{sequence length} \\times batch \\times \\text{in\\_channels})`\n    weight: filter of shape (:math:`\\text{kernel width} \\times \\text{in\\_channels} \\times \\text{out\\_channels}`)\n    bias: bias of shape (:math:`\\text{out\\_channels}`)\n    pad: number of timesteps to pad. Default: 0\n')
A:torch.nn.functional.avg_pool1d->_add_docstr(torch.avg_pool1d, '\navg_pool1d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True) -> Tensor\n\nApplies a 1D average pooling over an input signal composed of several\ninput planes.\n\nSee :class:`~torch.nn.AvgPool1d` for details and output shape.\n\nArgs:\n    input: input tensor of shape :math:`(\\text{minibatch} , \\text{in\\_channels} , iW)`\n    kernel_size: the size of the window. Can be a single number or a\n      tuple `(kW,)`\n    stride: the stride of the window. Can be a single number or a tuple\n      `(sW,)`. Default: :attr:`kernel_size`\n    padding: implicit zero paddings on both sides of the input. Can be a\n      single number or a tuple `(padW,)`. Default: 0\n    ceil_mode: when True, will use `ceil` instead of `floor` to compute the\n        output shape. Default: ``False``\n    count_include_pad: when True, will include the zero-padding in the\n        averaging calculation. Default: ``True``\n\nExamples::\n\n    >>> # pool of square window of size=3, stride=2\n    >>> input = torch.tensor([[[1, 2, 3, 4, 5, 6, 7]]], dtype=torch.float32)\n    >>> F.avg_pool1d(input, kernel_size=3, stride=2)\n    tensor([[[ 2.,  4.,  6.]]])\n\n')
A:torch.nn.functional.avg_pool2d->_add_docstr(torch._C._nn.avg_pool2d, '\navg_pool2d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor\n\nApplies 2D average-pooling operation in :math:`kH \\times kW` regions by step size\n:math:`sH \\times sW` steps. The number of output features is equal to the number of\ninput planes.\n\nSee :class:`~torch.nn.AvgPool2d` for details and output shape.\n\nArgs:\n    input: input tensor :math:`(\\text{minibatch} , \\text{in\\_channels} , iH , iW)`\n    kernel_size: size of the pooling region. Can be a single number or a\n      tuple `(kH, kW)`\n    stride: stride of the pooling operation. Can be a single number or a\n      tuple `(sH, sW)`. Default: :attr:`kernel_size`\n    padding: implicit zero paddings on both sides of the input. Can be a\n      single number or a tuple `(padH, padW)`. Default: 0\n    ceil_mode: when True, will use `ceil` instead of `floor` in the formula\n        to compute the output shape. Default: ``False``\n    count_include_pad: when True, will include the zero-padding in the\n        averaging calculation. Default: ``True``\n    divisor_override: if specified, it will be used as divisor, otherwise\n         size of the pooling region will be used. Default: None\n')
A:torch.nn.functional.avg_pool3d->_add_docstr(torch._C._nn.avg_pool3d, '\navg_pool3d(input, kernel_size, stride=None, padding=0, ceil_mode=False, count_include_pad=True, divisor_override=None) -> Tensor\n\nApplies 3D average-pooling operation in :math:`kT \\times kH \\times kW` regions by step\nsize :math:`sT \\times sH \\times sW` steps. The number of output features is equal to\n:math:`\\lfloor\\frac{\\text{input planes}}{sT}\\rfloor`.\n\nSee :class:`~torch.nn.AvgPool3d` for details and output shape.\n\nArgs:\n    input: input tensor :math:`(\\text{minibatch} , \\text{in\\_channels} , iT \\times iH , iW)`\n    kernel_size: size of the pooling region. Can be a single number or a\n      tuple `(kT, kH, kW)`\n    stride: stride of the pooling operation. Can be a single number or a\n      tuple `(sT, sH, sW)`. Default: :attr:`kernel_size`\n    padding: implicit zero paddings on both sides of the input. Can be a\n      single number or a tuple `(padT, padH, padW)`, Default: 0\n    ceil_mode: when True, will use `ceil` instead of `floor` in the formula\n        to compute the output shape\n    count_include_pad: when True, will include the zero-padding in the\n        averaging calculation\n    divisor_override: if specified, it will be used as divisor, otherwise\n        size of the pooling region will be used. Default: None\n')
A:torch.nn.functional._output_ratio->_triple(output_ratio)
A:torch.nn.functional._random_samples->torch.rand(input.size(0), input.size(1), 3, dtype=input.dtype, device=input.device)
A:torch.nn.functional.fractional_max_pool2d->boolean_dispatch(arg_name='return_indices', arg_index=4, default=False, if_true=fractional_max_pool2d_with_indices, if_false=_fractional_max_pool2d, module_name=__name__, func_name='fractional_max_pool2d')
A:torch.nn.functional.fractional_max_pool3d->boolean_dispatch(arg_name='return_indices', arg_index=4, default=False, if_true=fractional_max_pool3d_with_indices, if_false=_fractional_max_pool3d, module_name=__name__, func_name='fractional_max_pool3d')
A:torch.nn.functional.stride->torch.jit.annotate(List[int], [])
A:torch.nn.functional.max_pool1d->boolean_dispatch(arg_name='return_indices', arg_index=6, default=False, if_true=max_pool1d_with_indices, if_false=_max_pool1d, module_name=__name__, func_name='max_pool1d')
A:torch.nn.functional.max_pool2d->boolean_dispatch(arg_name='return_indices', arg_index=6, default=False, if_true=max_pool2d_with_indices, if_false=_max_pool2d, module_name=__name__, func_name='max_pool2d')
A:torch.nn.functional.max_pool3d->boolean_dispatch(arg_name='return_indices', arg_index=6, default=False, if_true=max_pool3d_with_indices, if_false=_max_pool3d, module_name=__name__, func_name='max_pool3d')
A:torch.nn.functional.input_size->input.view(n, c, 0, 0).size()
A:torch.nn.functional.default_size->torch.jit.annotate(List[int], [])
A:torch.nn.functional.kernel_size->_triple(kernel_size)
A:torch.nn.functional._stride->_triple(stride)
A:torch.nn.functional.padding->_triple(padding)
A:torch.nn.functional.output_size->_list_with_default(output_size, input.size())
A:torch.nn.functional.(kw, kh)->modules.utils._pair(kernel_size)
A:torch.nn.functional.out->torch.empty(out_shape, dtype=input.dtype, layout=input.layout, device=input.device)
A:torch.nn.functional.adaptive_max_pool1d->boolean_dispatch(arg_name='return_indices', arg_index=2, default=False, if_true=adaptive_max_pool1d_with_indices, if_false=_adaptive_max_pool1d, module_name=__name__, func_name='adaptive_max_pool1d')
A:torch.nn.functional.adaptive_max_pool2d->boolean_dispatch(arg_name='return_indices', arg_index=2, default=False, if_true=adaptive_max_pool2d_with_indices, if_false=_adaptive_max_pool2d, module_name=__name__, func_name='adaptive_max_pool2d')
A:torch.nn.functional.adaptive_max_pool3d->boolean_dispatch(arg_name='return_indices', arg_index=2, default=False, if_true=adaptive_max_pool3d_with_indices, if_false=_adaptive_max_pool3d, module_name=__name__, func_name='adaptive_max_pool3d')
A:torch.nn.functional.adaptive_avg_pool1d->_add_docstr(torch.adaptive_avg_pool1d, '\nadaptive_avg_pool1d(input, output_size) -> Tensor\n\nApplies a 1D adaptive average pooling over an input signal composed of\nseveral input planes.\n\nSee :class:`~torch.nn.AdaptiveAvgPool1d` for details and output shape.\n\nArgs:\n    output_size: the target output size (single integer)\n')
A:torch.nn.functional._output_size->_list_with_default(output_size, input.size())
A:torch.nn.functional.result->torch.rrelu(input, lower, upper, training)
A:torch.nn.functional.threshold_->_add_docstr(_VF.threshold_, '\nthreshold_(input, threshold, value) -> Tensor\n\nIn-place version of :func:`~threshold`.\n')
A:torch.nn.functional.relu_->_add_docstr(torch.relu_, '\nrelu_(input) -> Tensor\n\nIn-place version of :func:`~relu`.\n')
A:torch.nn.functional.hardtanh_->_add_docstr(torch._C._nn.hardtanh_, '\nhardtanh_(input, min_val=-1., max_val=1.) -> Tensor\n\nIn-place version of :func:`~hardtanh`.\n')
A:torch.nn.functional.elu_->_add_docstr(torch._C._nn.elu_, '\nelu_(input, alpha=1.) -> Tensor\n\nIn-place version of :func:`~elu`.\n')
A:torch.nn.functional.selu_->_add_docstr(torch.selu_, '\nselu_(input) -> Tensor\n\nIn-place version of :func:`~selu`.\n')
A:torch.nn.functional.celu_->_add_docstr(torch.celu_, '\ncelu_(input, alpha=1.) -> Tensor\n\nIn-place version of :func:`~celu`.\n')
A:torch.nn.functional.leaky_relu_->_add_docstr(torch._C._nn.leaky_relu_, '\nleaky_relu_(input, negative_slope=0.01) -> Tensor\n\nIn-place version of :func:`~leaky_relu`.\n')
A:torch.nn.functional.rrelu_->_add_docstr(torch.rrelu_, '\nrrelu_(input, lower=1./8, upper=1./3, training=False) -> Tensor\n\nIn-place version of :func:`~rrelu`.\n')
A:torch.nn.functional.logsigmoid->_add_docstr(torch._C._nn.log_sigmoid, '\nlogsigmoid(input) -> Tensor\n\nApplies element-wise :math:`\\text{LogSigmoid}(x_i) = \\log \\left(\\frac{1}{1 + \\exp(-x_i)}\\right)`\n\nSee :class:`~torch.nn.LogSigmoid` for more details.\n')
A:torch.nn.functional.softplus->_add_docstr(torch._C._nn.softplus, '\nsoftplus(input, beta=1, threshold=20) -> Tensor\n\nApplies element-wise, the function :math:`\\text{Softplus}(x) = \\frac{1}{\\beta} * \\log(1 + \\exp(\\beta * x))`.\n\nFor numerical stability the implementation reverts to the linear function\nwhen :math:`input \\times \\beta > threshold`.\n\nSee :class:`~torch.nn.Softplus` for more details.\n')
A:torch.nn.functional.dim->input.view(n, c, 0, 0).dim()
A:torch.nn.functional.ret->loss.sum()
A:torch.nn.functional.y_soft->gumbels.softmax(dim)
A:torch.nn.functional.y_hard->torch.zeros_like(logits, memory_format=torch.legacy_contiguous_format).scatter_(dim, index, 1.0)
A:torch.nn.functional.softshrink->_add_docstr(torch._C._nn.softshrink, '\nsoftshrink(input, lambd=0.5) -> Tensor\n\nApplies the soft shrinkage function elementwise\n\nSee :class:`~torch.nn.Softshrink` for more details.\n')
A:torch.nn.functional.output->torch.clamp(positive_dist - negative_dist + margin, min=0.0)
A:torch.nn.functional.input->input.view(n, c, 0, 0).view(n, c, 0, 0)
A:torch.nn.functional.type_str->str(type(offsets))
A:torch.nn.functional.offsets->torch.arange(0, input.numel(), input.size(1), dtype=torch.long, device=input.device)
A:torch.nn.functional.per_sample_weights->per_sample_weights.reshape(-1).reshape(-1)
A:torch.nn.functional.(ret, _, _, _)->torch.embedding_bag(weight, input, offsets, scale_grad_by_freq, mode_enum, sparse, per_sample_weights, include_last_offset)
A:torch.nn.functional.div->div.mul(alpha).add(k).pow(beta).mul(alpha).add(k).pow(beta)
A:torch.nn.functional.sizes->input.view(n, c, 0, 0).view(n, c, 0, 0).size()
A:torch.nn.functional.reduction->_Reduction.legacy_get_string(size_average, reduce)
A:torch.nn.functional.n->input.view(n, c, 0, 0).view(n, c, 0, 0).size(0)
A:torch.nn.functional.c->input.view(n, c, 0, 0).view(n, c, 0, 0).size(1)
A:torch.nn.functional.target->target.view(n, 0, 0).view(n, 0, 0)
A:torch.nn.functional.reduction_enum->_Reduction.get_enum(reduction)
A:torch.nn.functional.reduced->torch.kl_div(input, target, reduction_enum, log_target=log_target)
A:torch.nn.functional.new_size->_infer_size(target.size(), weight.size())
A:torch.nn.functional.weight->weight.expand(new_size).expand(new_size)
A:torch.nn.functional.(expanded_input, expanded_target)->torch.broadcast_tensors(input, target)
A:torch.nn.functional.pixel_shuffle->_add_docstr(torch.pixel_shuffle, '\nRearranges elements in a tensor of shape :math:`(*, C \\times r^2, H, W)` to a\ntensor of shape :math:`(*, C, H \\times r, W \\times r)`.\n\nSee :class:`~torch.nn.PixelShuffle` for details.\n\nArgs:\n    input (Tensor): the input tensor\n    upscale_factor (int): factor to increase spatial resolution by\n\nExamples::\n\n    >>> input = torch.randn(1, 9, 4, 4)\n    >>> output = torch.nn.functional.pixel_shuffle(input, 3)\n    >>> print(output.size())\n    torch.Size([1, 1, 12, 12])\n')
A:torch.nn.functional.channel_shuffle->_add_docstr(torch.channel_shuffle, '\nDivide the channels in a tensor of shape :math:`(*, C , H, W)`\ninto g groups and rearrange them as :math:`(*, C \\frac g, g, H, W)`,\nwhile keeping the original tensor shape.\n\nSee :class:`~torch.nn.ChannelShuffle` for details.\n\nArgs:\n    input (Tensor): the input tensor\n    groups (int): number of groups to divide channels in and rearrange.\n\nExamples::\n\n    >>> input = torch.randn(1, 4, 2, 2)\n    >>> print(input)\n    [[[[1, 2],\n       [3, 4]],\n      [[5, 6],\n       [7, 8]],\n      [[9, 10],\n       [11, 12]],\n      [[13, 14],\n       [15, 16]],\n     ]]\n    >>> output = torch.nn.functional.channel_shuffle(input, 2)\n    >>> print(output)\n    [[[[1, 2],\n       [3, 4]],\n      [[9, 10],\n       [11, 12]],\n      [[5, 6],\n       [7, 8]],\n      [[13, 14],\n       [15, 16]],\n     ]]\n')
A:torch.nn.functional.pdist->_add_docstr(torch.pdist, "\npdist(input, p=2) -> Tensor\n\nComputes the p-norm distance between every pair of row vectors in the input.\nThis is identical to the upper triangular portion, excluding the diagonal, of\n`torch.norm(input[:, None] - input, dim=2, p=p)`. This function will be faster\nif the rows are contiguous.\n\nIf input has shape :math:`N \\times M` then the output will have shape\n:math:`\\frac{1}{2} N (N - 1)`.\n\nThis function is equivalent to `scipy.spatial.distance.pdist(input,\n'minkowski', p=p)` if :math:`p \\in (0, \\infty)`. When :math:`p = 0` it is\nequivalent to `scipy.spatial.distance.pdist(input, 'hamming') * M`.\nWhen :math:`p = \\infty`, the closest scipy function is\n`scipy.spatial.distance.pdist(xn, lambda x, y: np.abs(x - y).max())`.\n\nArgs:\n    input: input tensor of shape :math:`N \\times M`.\n    p: p value for the p-norm distance to calculate between each vector pair\n        :math:`\\in [0, \\infty]`.\n")
A:torch.nn.functional.cosine_similarity->_add_docstr(torch.cosine_similarity, '\ncosine_similarity(x1, x2, dim=1, eps=1e-8) -> Tensor\n\nReturns cosine similarity between x1 and x2, computed along dim.\n\n.. math ::\n    \\text{similarity} = \\dfrac{x_1 \\cdot x_2}{\\max(\\Vert x_1 \\Vert _2 \\cdot \\Vert x_2 \\Vert _2, \\epsilon)}\n\nArgs:\n    x1 (Tensor): First input.\n    x2 (Tensor): Second input (of size matching x1).\n    dim (int, optional): Dimension of vectors. Default: 1\n    eps (float, optional): Small value to avoid division by zero.\n        Default: 1e-8\n\nShape:\n    - Input: :math:`(\\ast_1, D, \\ast_2)` where D is at position `dim`.\n    - Output: :math:`(\\ast_1, \\ast_2)` where 1 is at position `dim`.\n\nExample::\n\n    >>> input1 = torch.randn(100, 128)\n    >>> input2 = torch.randn(100, 128)\n    >>> output = F.cosine_similarity(input1, input2)\n    >>> print(output)\n')
A:torch.nn.functional.one_hot->_add_docstr(torch._C._nn.one_hot, '\none_hot(tensor, num_classes=-1) -> LongTensor\n\nTakes LongTensor with index values of shape ``(*)`` and returns a tensor\nof shape ``(*, num_classes)`` that have zeros everywhere except where the\nindex of last dimension matches the corresponding value of the input tensor,\nin which case it will be 1.\n\nSee also `One-hot on Wikipedia`_ .\n\n.. _One-hot on Wikipedia:\n    https://en.wikipedia.org/wiki/One-hot\n\nArguments:\n    tensor (LongTensor): class values of any shape.\n    num_classes (int):  Total number of classes. If set to -1, the number\n        of classes will be inferred as one greater than the largest class\n        value in the input tensor.\n\nReturns:\n    LongTensor that has one more dimension with 1 values at the\n    index of last dimension indicated by the input, and 0 everywhere\n    else.\n\nExamples:\n    >>> F.one_hot(torch.arange(0, 5) % 3)\n    tensor([[1, 0, 0],\n            [0, 1, 0],\n            [0, 0, 1],\n            [1, 0, 0],\n            [0, 1, 0]])\n    >>> F.one_hot(torch.arange(0, 5) % 3, num_classes=5)\n    tensor([[1, 0, 0, 0, 0],\n            [0, 1, 0, 0, 0],\n            [0, 0, 1, 0, 0],\n            [1, 0, 0, 0, 0],\n            [0, 1, 0, 0, 0]])\n    >>> F.one_hot(torch.arange(0, 6).view(3,2) % 3)\n    tensor([[[1, 0, 0],\n             [0, 1, 0]],\n            [[0, 0, 1],\n             [1, 0, 0]],\n            [[0, 1, 0],\n             [0, 0, 1]]])\n')
A:torch.nn.functional.positive_dist->distance_function(anchor, positive)
A:torch.nn.functional.negative_dist->torch.min(negative_dist, swap_dist)
A:torch.nn.functional.swap_dist->distance_function(positive, negative)
A:torch.nn.functional.denom->input.view(n, c, 0, 0).view(n, c, 0, 0).norm(p, dim, keepdim=True).clamp_min_(eps).expand_as(input)
A:torch.nn.functional.ndim->len(paddable_shape)
A:torch.nn.functional.out_d0->max(padding[-2], 0)
A:torch.nn.functional.in_d0->max(-padding[-2], 0)
A:torch.nn.functional.out_h0->max(padding[-4], 0)
A:torch.nn.functional.in_h0->max(-padding[-4], 0)
A:torch.nn.functional.out_w0->max(padding[-6], 0)
A:torch.nn.functional.in_w0->max(-padding[-6], 0)
A:torch.nn.functional.i0->max(padding[-6], 0)
A:torch.nn.functional.(tgt_len, bsz, embed_dim)->query.size()
A:torch.nn.functional.(q, k, v)->linear(query, in_proj_weight, in_proj_bias).chunk(3, dim=-1)
A:torch.nn.functional.q->q.contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1).contiguous().view(tgt_len, bsz * num_heads, head_dim).transpose(0, 1)
A:torch.nn.functional.(k, v)->linear(key, _w, _b).chunk(2, dim=-1)
A:torch.nn.functional.k->torch.cat([k, torch.zeros((k.size(0), 1) + k.size()[2:], dtype=k.dtype, device=k.device)], dim=1)
A:torch.nn.functional.v->torch.cat([v, torch.zeros((v.size(0), 1) + v.size()[2:], dtype=v.dtype, device=v.device)], dim=1)
A:torch.nn.functional.q_proj_weight_non_opt->torch.jit._unwrap_optional(q_proj_weight)
A:torch.nn.functional.(len1, len2)->torch.jit._unwrap_optional(v_proj_weight).size()
A:torch.nn.functional.k_proj_weight_non_opt->torch.jit._unwrap_optional(k_proj_weight)
A:torch.nn.functional.v_proj_weight_non_opt->torch.jit._unwrap_optional(v_proj_weight)
A:torch.nn.functional.attn_mask->pad(attn_mask, (0, 1))
A:torch.nn.functional.key_padding_mask->pad(key_padding_mask, (0, 1))
A:torch.nn.functional.src_len->torch.cat([k, torch.zeros((k.size(0), 1) + k.size()[2:], dtype=k.dtype, device=k.device)], dim=1).size(1)
A:torch.nn.functional.attn_output_weights->attn_output_weights.view(bsz, num_heads, tgt_len, src_len).view(bsz, num_heads, tgt_len, src_len)
A:torch.nn.functional.attn_output->linear(attn_output, out_proj_weight, out_proj_bias)
torch.nn._adaptive_max_pool1d(input,output_size,return_indices=False)
torch.nn._adaptive_max_pool2d(input,output_size,return_indices=False)
torch.nn._adaptive_max_pool3d(input,output_size,return_indices=False)
torch.nn._fractional_max_pool2d(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn._fractional_max_pool3d(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn._get_softmax_dim(name,ndim,stacklevel)
torch.nn._max_pool1d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn._max_pool2d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn._max_pool3d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn._no_grad_embedding_renorm_(weight,input,max_norm,norm_type)
torch.nn._pad(input,pad,mode='constant',value=0)
torch.nn._pad_circular(input,padding)
torch.nn._threshold(input,threshold,value,inplace=False)
torch.nn._unpool_output_size(input,kernel_size,stride,padding,output_size)
torch.nn._verify_batch_size(size)
torch.nn.adaptive_avg_pool2d(input,output_size)
torch.nn.adaptive_avg_pool3d(input,output_size)
torch.nn.adaptive_max_pool1d_with_indices(input,output_size,return_indices=False)
torch.nn.adaptive_max_pool2d_with_indices(input,output_size,return_indices=False)
torch.nn.adaptive_max_pool3d_with_indices(input,output_size,return_indices=False)
torch.nn.affine_grid(theta,size,align_corners=None)
torch.nn.alpha_dropout(input,p=0.5,training=False,inplace=False)
torch.nn.assert_int_or_pair(arg,arg_name,message)
torch.nn.batch_norm(input,running_mean,running_var,weight=None,bias=None,training=False,momentum=0.1,eps=1e-05)
torch.nn.bilinear(input1,input2,weight,bias=None)
torch.nn.binary_cross_entropy(input,target,weight=None,size_average=None,reduce=None,reduction='mean')
torch.nn.binary_cross_entropy_with_logits(input,target,weight=None,size_average=None,reduce=None,reduction='mean',pos_weight=None)
torch.nn.celu(input,alpha=1.0,inplace=False)
torch.nn.cosine_embedding_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')
torch.nn.cross_entropy(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')
torch.nn.ctc_loss(log_probs,targets,input_lengths,target_lengths,blank=0,reduction='mean',zero_infinity=False)
torch.nn.dropout(input,p=0.5,training=True,inplace=False)
torch.nn.dropout2d(input,p=0.5,training=True,inplace=False)
torch.nn.dropout3d(input,p=0.5,training=True,inplace=False)
torch.nn.elu(input,alpha=1.0,inplace=False)
torch.nn.embedding(input,weight,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)
torch.nn.embedding_bag(input,weight,offsets=None,max_norm=None,norm_type=2,scale_grad_by_freq=False,mode='mean',sparse=False,per_sample_weights=None,include_last_offset=False)
torch.nn.feature_alpha_dropout(input,p=0.5,training=False,inplace=False)
torch.nn.fold(input,output_size,kernel_size,dilation=1,padding=0,stride=1)
torch.nn.fractional_max_pool2d_with_indices(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn.fractional_max_pool3d_with_indices(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn.functional._adaptive_max_pool1d(input,output_size,return_indices=False)
torch.nn.functional._adaptive_max_pool2d(input,output_size,return_indices=False)
torch.nn.functional._adaptive_max_pool3d(input,output_size,return_indices=False)
torch.nn.functional._fractional_max_pool2d(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn.functional._fractional_max_pool3d(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn.functional._get_softmax_dim(name,ndim,stacklevel)
torch.nn.functional._max_pool1d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.functional._max_pool2d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.functional._max_pool3d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.functional._no_grad_embedding_renorm_(weight,input,max_norm,norm_type)
torch.nn.functional._pad(input,pad,mode='constant',value=0)
torch.nn.functional._pad_circular(input,padding)
torch.nn.functional._threshold(input,threshold,value,inplace=False)
torch.nn.functional._unpool_output_size(input,kernel_size,stride,padding,output_size)
torch.nn.functional._verify_batch_size(size)
torch.nn.functional.adaptive_avg_pool2d(input,output_size)
torch.nn.functional.adaptive_avg_pool3d(input,output_size)
torch.nn.functional.adaptive_max_pool1d_with_indices(input,output_size,return_indices=False)
torch.nn.functional.adaptive_max_pool2d_with_indices(input,output_size,return_indices=False)
torch.nn.functional.adaptive_max_pool3d_with_indices(input,output_size,return_indices=False)
torch.nn.functional.affine_grid(theta,size,align_corners=None)
torch.nn.functional.alpha_dropout(input,p=0.5,training=False,inplace=False)
torch.nn.functional.assert_int_or_pair(arg,arg_name,message)
torch.nn.functional.batch_norm(input,running_mean,running_var,weight=None,bias=None,training=False,momentum=0.1,eps=1e-05)
torch.nn.functional.bilinear(input1,input2,weight,bias=None)
torch.nn.functional.binary_cross_entropy(input,target,weight=None,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.binary_cross_entropy_with_logits(input,target,weight=None,size_average=None,reduce=None,reduction='mean',pos_weight=None)
torch.nn.functional.celu(input,alpha=1.0,inplace=False)
torch.nn.functional.cosine_embedding_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.cross_entropy(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')
torch.nn.functional.ctc_loss(log_probs,targets,input_lengths,target_lengths,blank=0,reduction='mean',zero_infinity=False)
torch.nn.functional.dropout(input,p=0.5,training=True,inplace=False)
torch.nn.functional.dropout2d(input,p=0.5,training=True,inplace=False)
torch.nn.functional.dropout3d(input,p=0.5,training=True,inplace=False)
torch.nn.functional.elu(input,alpha=1.0,inplace=False)
torch.nn.functional.embedding(input,weight,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)
torch.nn.functional.embedding_bag(input,weight,offsets=None,max_norm=None,norm_type=2,scale_grad_by_freq=False,mode='mean',sparse=False,per_sample_weights=None,include_last_offset=False)
torch.nn.functional.feature_alpha_dropout(input,p=0.5,training=False,inplace=False)
torch.nn.functional.fold(input,output_size,kernel_size,dilation=1,padding=0,stride=1)
torch.nn.functional.fractional_max_pool2d_with_indices(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn.functional.fractional_max_pool3d_with_indices(input,kernel_size,output_size=None,output_ratio=None,return_indices=False,_random_samples=None)
torch.nn.functional.gelu(input)
torch.nn.functional.glu(input:Tensor,dim:int=-1)->Tensor
torch.nn.functional.grid_sample(input,grid,mode='bilinear',padding_mode='zeros',align_corners=None)
torch.nn.functional.group_norm(input,num_groups,weight=None,bias=None,eps=1e-05)
torch.nn.functional.gumbel_softmax(logits,tau=1,hard=False,eps=1e-10,dim=-1)
torch.nn.functional.hardshrink(input,lambd=0.5)
torch.nn.functional.hardsigmoid(input,inplace=False)
torch.nn.functional.hardswish(input:Tensor,inplace:bool=False)->Tensor
torch.nn.functional.hardtanh(input:Tensor,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False)->Tensor
torch.nn.functional.hinge_embedding_loss(input,target,margin=1.0,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.instance_norm(input,running_mean=None,running_var=None,weight=None,bias=None,use_input_stats=True,momentum=0.1,eps=1e-05)
torch.nn.functional.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None,recompute_scale_factor=None)
torch.nn.functional.kl_div(input,target,size_average=None,reduce=None,reduction='mean',log_target=False)
torch.nn.functional.l1_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.layer_norm(input,normalized_shape,weight=None,bias=None,eps=1e-05)
torch.nn.functional.leaky_relu(input:Tensor,negative_slope:float=0.01,inplace:bool=False)->Tensor
torch.nn.functional.linear(input,weight,bias=None)
torch.nn.functional.local_response_norm(input,size,alpha=0.0001,beta=0.75,k=1.0)
torch.nn.functional.log_softmax(input,dim=None,_stacklevel=3,dtype=None)
torch.nn.functional.lp_pool1d(input,norm_type,kernel_size,stride=None,ceil_mode=False)
torch.nn.functional.lp_pool2d(input,norm_type,kernel_size,stride=None,ceil_mode=False)
torch.nn.functional.margin_ranking_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.max_pool1d_with_indices(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.functional.max_pool2d_with_indices(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.functional.max_pool3d_with_indices(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.functional.max_unpool1d(input,indices,kernel_size,stride=None,padding=0,output_size=None)
torch.nn.functional.max_unpool2d(input,indices,kernel_size,stride=None,padding=0,output_size=None)
torch.nn.functional.max_unpool3d(input,indices,kernel_size,stride=None,padding=0,output_size=None)
torch.nn.functional.mse_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.multi_head_attention_forward(query:Tensor,key:Tensor,value:Tensor,embed_dim_to_check:int,num_heads:int,in_proj_weight:Tensor,in_proj_bias:Tensor,bias_k:Optional[Tensor],bias_v:Optional[Tensor],add_zero_attn:bool,dropout_p:float,out_proj_weight:Tensor,out_proj_bias:Tensor,training:bool=True,key_padding_mask:Optional[Tensor]=None,need_weights:bool=True,attn_mask:Optional[Tensor]=None,use_separate_proj_weight:bool=False,q_proj_weight:Optional[Tensor]=None,k_proj_weight:Optional[Tensor]=None,v_proj_weight:Optional[Tensor]=None,static_k:Optional[Tensor]=None,static_v:Optional[Tensor]=None)->Tuple[Tensor, Optional[Tensor]]
torch.nn.functional.multi_margin_loss(input,target,p=1,margin=1.0,weight=None,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.multilabel_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.multilabel_soft_margin_loss(input,target,weight=None,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.nll_loss(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')
torch.nn.functional.normalize(input,p=2,dim=1,eps=1e-12,out=None)
torch.nn.functional.pairwise_distance(x1,x2,p=2.0,eps=1e-06,keepdim=False)
torch.nn.functional.poisson_nll_loss(input,target,log_input=True,full=False,size_average=None,eps=1e-08,reduce=None,reduction='mean')
torch.nn.functional.prelu(input,weight)
torch.nn.functional.relu(input:Tensor,inplace:bool=False)->Tensor
torch.nn.functional.relu6(input,inplace=False)
torch.nn.functional.rrelu(input,lower=1.0/8,upper=1.0/3,training=False,inplace=False)
torch.nn.functional.selu(input,inplace=False)
torch.nn.functional.sigmoid(input)
torch.nn.functional.silu(input,inplace=False)
torch.nn.functional.smooth_l1_loss(input,target,size_average=None,reduce=None,reduction='mean',beta=1.0)
torch.nn.functional.soft_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.softmax(input,dim=None,_stacklevel=3,dtype=None)
torch.nn.functional.softmin(input,dim=None,_stacklevel=3,dtype=None)
torch.nn.functional.softsign(input)
torch.nn.functional.tanh(input)
torch.nn.functional.tanhshrink(input)
torch.nn.functional.triplet_margin_loss(anchor,positive,negative,margin=1.0,p=2,eps=1e-06,swap=False,size_average=None,reduce=None,reduction='mean')
torch.nn.functional.triplet_margin_with_distance_loss(anchor,positive,negative,*,distance_function=None,margin=1.0,swap=False,reduction='mean')
torch.nn.functional.unfold(input,kernel_size,dilation=1,padding=0,stride=1)
torch.nn.functional.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)
torch.nn.functional.upsample_bilinear(input,size=None,scale_factor=None)
torch.nn.functional.upsample_nearest(input,size=None,scale_factor=None)
torch.nn.gelu(input)
torch.nn.glu(input:Tensor,dim:int=-1)->Tensor
torch.nn.grid_sample(input,grid,mode='bilinear',padding_mode='zeros',align_corners=None)
torch.nn.group_norm(input,num_groups,weight=None,bias=None,eps=1e-05)
torch.nn.gumbel_softmax(logits,tau=1,hard=False,eps=1e-10,dim=-1)
torch.nn.hardshrink(input,lambd=0.5)
torch.nn.hardsigmoid(input,inplace=False)
torch.nn.hardswish(input:Tensor,inplace:bool=False)->Tensor
torch.nn.hardtanh(input:Tensor,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False)->Tensor
torch.nn.hinge_embedding_loss(input,target,margin=1.0,size_average=None,reduce=None,reduction='mean')
torch.nn.instance_norm(input,running_mean=None,running_var=None,weight=None,bias=None,use_input_stats=True,momentum=0.1,eps=1e-05)
torch.nn.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None,recompute_scale_factor=None)
torch.nn.kl_div(input,target,size_average=None,reduce=None,reduction='mean',log_target=False)
torch.nn.l1_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.layer_norm(input,normalized_shape,weight=None,bias=None,eps=1e-05)
torch.nn.leaky_relu(input:Tensor,negative_slope:float=0.01,inplace:bool=False)->Tensor
torch.nn.linear(input,weight,bias=None)
torch.nn.local_response_norm(input,size,alpha=0.0001,beta=0.75,k=1.0)
torch.nn.log_softmax(input,dim=None,_stacklevel=3,dtype=None)
torch.nn.lp_pool1d(input,norm_type,kernel_size,stride=None,ceil_mode=False)
torch.nn.lp_pool2d(input,norm_type,kernel_size,stride=None,ceil_mode=False)
torch.nn.margin_ranking_loss(input1,input2,target,margin=0,size_average=None,reduce=None,reduction='mean')
torch.nn.max_pool1d_with_indices(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.max_pool2d_with_indices(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.max_pool3d_with_indices(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.max_unpool1d(input,indices,kernel_size,stride=None,padding=0,output_size=None)
torch.nn.max_unpool2d(input,indices,kernel_size,stride=None,padding=0,output_size=None)
torch.nn.max_unpool3d(input,indices,kernel_size,stride=None,padding=0,output_size=None)
torch.nn.mse_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.multi_head_attention_forward(query:Tensor,key:Tensor,value:Tensor,embed_dim_to_check:int,num_heads:int,in_proj_weight:Tensor,in_proj_bias:Tensor,bias_k:Optional[Tensor],bias_v:Optional[Tensor],add_zero_attn:bool,dropout_p:float,out_proj_weight:Tensor,out_proj_bias:Tensor,training:bool=True,key_padding_mask:Optional[Tensor]=None,need_weights:bool=True,attn_mask:Optional[Tensor]=None,use_separate_proj_weight:bool=False,q_proj_weight:Optional[Tensor]=None,k_proj_weight:Optional[Tensor]=None,v_proj_weight:Optional[Tensor]=None,static_k:Optional[Tensor]=None,static_v:Optional[Tensor]=None)->Tuple[Tensor, Optional[Tensor]]
torch.nn.multi_margin_loss(input,target,p=1,margin=1.0,weight=None,size_average=None,reduce=None,reduction='mean')
torch.nn.multilabel_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.multilabel_soft_margin_loss(input,target,weight=None,size_average=None,reduce=None,reduction='mean')
torch.nn.nll_loss(input,target,weight=None,size_average=None,ignore_index=-100,reduce=None,reduction='mean')
torch.nn.normalize(input,p=2,dim=1,eps=1e-12,out=None)
torch.nn.pairwise_distance(x1,x2,p=2.0,eps=1e-06,keepdim=False)
torch.nn.poisson_nll_loss(input,target,log_input=True,full=False,size_average=None,eps=1e-08,reduce=None,reduction='mean')
torch.nn.prelu(input,weight)
torch.nn.relu(input:Tensor,inplace:bool=False)->Tensor
torch.nn.relu6(input,inplace=False)
torch.nn.rrelu(input,lower=1.0/8,upper=1.0/3,training=False,inplace=False)
torch.nn.selu(input,inplace=False)
torch.nn.sigmoid(input)
torch.nn.silu(input,inplace=False)
torch.nn.smooth_l1_loss(input,target,size_average=None,reduce=None,reduction='mean',beta=1.0)
torch.nn.soft_margin_loss(input,target,size_average=None,reduce=None,reduction='mean')
torch.nn.softmax(input,dim=None,_stacklevel=3,dtype=None)
torch.nn.softmin(input,dim=None,_stacklevel=3,dtype=None)
torch.nn.softsign(input)
torch.nn.tanh(input)
torch.nn.tanhshrink(input)
torch.nn.triplet_margin_loss(anchor,positive,negative,margin=1.0,p=2,eps=1e-06,swap=False,size_average=None,reduce=None,reduction='mean')
torch.nn.triplet_margin_with_distance_loss(anchor,positive,negative,*,distance_function=None,margin=1.0,swap=False,reduction='mean')
torch.nn.unfold(input,kernel_size,dilation=1,padding=0,stride=1)
torch.nn.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)
torch.nn.upsample_bilinear(input,size=None,scale_factor=None)
torch.nn.upsample_nearest(input,size=None,scale_factor=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/functional.pyi----------------------------------------
torch.nn.functional.pad(input:Tensor,pad:Sequence[int],mode:str=...,value:float=...)->Tensor
torch.nn.functional.threshold(input:Tensor,threshold:float,value:float,inplace:bool=...)->Tensor
torch.nn.pad(input:Tensor,pad:Sequence[int],mode:str=...,value:float=...)->Tensor
torch.nn.threshold(input:Tensor,threshold:float,value:float,inplace:bool=...)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/_reduction.py----------------------------------------
torch.nn._reduction.get_enum(reduction)
torch.nn._reduction.legacy_get_enum(size_average,reduce,emit_warning=True)
torch.nn._reduction.legacy_get_string(size_average,reduce,emit_warning=True)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/cpp.py----------------------------------------
A:torch.nn.cpp.self._parameters->OrderedDictWrapper(cpp_module, '_parameters')
A:torch.nn.cpp.self._buffers->OrderedDictWrapper(cpp_module, '_buffers')
A:torch.nn.cpp.self._modules->OrderedDictWrapper(cpp_module, '_modules')
A:torch.nn.cpp.param.data->fn(param.data)
A:torch.nn.cpp.param._grad.data->fn(param._grad.data)
A:torch.nn.cpp.buf.data->fn(buf.data)
torch.nn.cpp.ModuleWrapper(self,cpp_module)
torch.nn.cpp.ModuleWrapper.__init__(self,cpp_module)
torch.nn.cpp.ModuleWrapper.__repr__(self)
torch.nn.cpp.ModuleWrapper._apply(self,fn)
torch.nn.cpp.ModuleWrapper.training(self)
torch.nn.cpp.ModuleWrapper.training(self,mode)
torch.nn.cpp.OrderedDictWrapper(self,cpp_module,attr)
torch.nn.cpp.OrderedDictWrapper.__contains__(self,key)
torch.nn.cpp.OrderedDictWrapper.__getitem__(self,key)
torch.nn.cpp.OrderedDictWrapper.__init__(self,cpp_module,attr)
torch.nn.cpp.OrderedDictWrapper.__iter__(self)
torch.nn.cpp.OrderedDictWrapper.__len__(self)
torch.nn.cpp.OrderedDictWrapper.cpp_dict(self)
torch.nn.cpp.OrderedDictWrapper.items(self)
torch.nn.cpp.OrderedDictWrapper.keys(self)
torch.nn.cpp.OrderedDictWrapper.values(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/weight_norm.py----------------------------------------
A:torch.nn.utils.weight_norm.g->getattr(module, self.name + '_g')
A:torch.nn.utils.weight_norm.v->getattr(module, self.name + '_v')
A:torch.nn.utils.weight_norm.fn->WeightNorm(name, dim)
A:torch.nn.utils.weight_norm.weight->self.compute_weight(module)
A:torch.nn.utils.weight_norm.T_module->TypeVar('T_module', bound=Module)
torch.nn.utils.remove_weight_norm(module:T_module,name:str='weight')->T_module
torch.nn.utils.weight_norm(module:T_module,name:str='weight',dim:int=0)->T_module
torch.nn.utils.weight_norm.WeightNorm(self,name:str,dim:int)
torch.nn.utils.weight_norm.WeightNorm.__init__(self,name:str,dim:int)
torch.nn.utils.weight_norm.WeightNorm.apply(module,name:str,dim:int)->'WeightNorm'
torch.nn.utils.weight_norm.WeightNorm.compute_weight(self,module:Module)->Any
torch.nn.utils.weight_norm.WeightNorm.remove(self,module:Module)->None
torch.nn.utils.weight_norm.remove_weight_norm(module:T_module,name:str='weight')->T_module
torch.nn.utils.weight_norm.weight_norm(module:T_module,name:str='weight',dim:int=0)->T_module


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/memory_format.py----------------------------------------
A:torch.nn.utils.memory_format.weight_data->module.weight.detach().clone().contiguous(memory_format=memory_format)
A:torch.nn.utils.memory_format.module.weight.data->module.weight.detach().clone().contiguous(memory_format=memory_format).resize_(weight_data.size(), memory_format=memory_format)
torch.nn.utils.convert_conv2d_weight_memory_format(module,memory_format)
torch.nn.utils.memory_format.convert_conv2d_weight_memory_format(module,memory_format)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/fusion.py----------------------------------------
A:torch.nn.utils.fusion.fused_conv->copy.deepcopy(conv)
A:torch.nn.utils.fusion.(fused_conv.weight, fused_conv.bias)->fuse_conv_bn_weights(fused_conv.weight, fused_conv.bias, bn.running_mean, bn.running_var, bn.eps, bn.weight, bn.bias)
A:torch.nn.utils.fusion.conv_b->bn_rm.new_zeros(bn_rm.shape)
A:torch.nn.utils.fusion.bn_var_rsqrt->torch.rsqrt(bn_rv + bn_eps)
torch.nn.utils.fuse_conv_bn_eval(conv,bn)
torch.nn.utils.fuse_conv_bn_weights(conv_w,conv_b,bn_rm,bn_rv,bn_eps,bn_w,bn_b)
torch.nn.utils.fusion.fuse_conv_bn_eval(conv,bn)
torch.nn.utils.fusion.fuse_conv_bn_weights(conv_w,conv_b,bn_rm,bn_rv,bn_eps,bn_w,bn_b)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/prune.py----------------------------------------
A:torch.nn.utils.prune.mask->make_mask(t, self.dim, topk.indices)
A:torch.nn.utils.prune.orig->getattr(module, name + '_orig')
A:torch.nn.utils.prune.method->pruning_method(**kwargs)
A:torch.nn.utils.prune.container->PruningContainer()
A:torch.nn.utils.prune.default_mask->torch.nn.utils.parameters_to_vector([getattr(module, name + '_mask', torch.ones_like(getattr(module, name))) for (module, name) in parameters])
A:torch.nn.utils.prune.weight->self.apply_mask(module)
A:torch.nn.utils.prune.new_mask->new_mask.to(dtype=t.dtype).to(dtype=t.dtype)
A:torch.nn.utils.prune.n_dims->len(t.shape)
A:torch.nn.utils.prune.partial_mask->pruning_method(**kwargs).compute_mask(t[slc], default_mask=mask[slc])
A:torch.nn.utils.prune.new_mask[slc]->pruning_method(**kwargs).compute_mask(t[slc], default_mask=mask[slc]).to(dtype=new_mask.dtype)
A:torch.nn.utils.prune.tensor_size->torch.nn.utils.parameters_to_vector([getattr(*p) for p in parameters]).nelement()
A:torch.nn.utils.prune.nparams_toprune->_compute_nparams_toprune(self.amount, tensor_size)
A:torch.nn.utils.prune.prob->torch.rand(nchannels)
A:torch.nn.utils.prune.topk->torch.topk(norm, k=nparams_tokeep, largest=True)
A:torch.nn.utils.prune.norm->torch.norm(t, p=n, dim=dims)
A:torch.nn.utils.prune.t->torch.nn.utils.parameters_to_vector([getattr(*p) for p in parameters])
A:torch.nn.utils.prune.final_mask->PruningContainer().compute_mask(t, default_mask)
A:torch.nn.utils.prune.param->getattr(module, name)
A:torch.nn.utils.prune.num_param->getattr(module, name).numel()
A:torch.nn.utils.prune.param_mask->final_mask[pointer:pointer + num_param].view_as(param)
A:torch.nn.utils.prune.dims->list(range(t.dim()))
torch.nn.utils.prune.BasePruningMethod(self)
torch.nn.utils.prune.BasePruningMethod.__init__(self)
torch.nn.utils.prune.BasePruningMethod.apply(cls,module,name,*args,**kwargs)
torch.nn.utils.prune.BasePruningMethod.apply_mask(self,module)
torch.nn.utils.prune.BasePruningMethod.compute_mask(self,t,default_mask)
torch.nn.utils.prune.BasePruningMethod.prune(self,t,default_mask=None)
torch.nn.utils.prune.BasePruningMethod.remove(self,module)
torch.nn.utils.prune.CustomFromMask(self,mask)
torch.nn.utils.prune.CustomFromMask.__init__(self,mask)
torch.nn.utils.prune.CustomFromMask.apply(cls,module,name,mask)
torch.nn.utils.prune.CustomFromMask.compute_mask(self,t,default_mask)
torch.nn.utils.prune.Identity(BasePruningMethod)
torch.nn.utils.prune.Identity.apply(cls,module,name)
torch.nn.utils.prune.Identity.compute_mask(self,t,default_mask)
torch.nn.utils.prune.L1Unstructured(self,amount)
torch.nn.utils.prune.L1Unstructured.__init__(self,amount)
torch.nn.utils.prune.L1Unstructured.apply(cls,module,name,amount)
torch.nn.utils.prune.L1Unstructured.compute_mask(self,t,default_mask)
torch.nn.utils.prune.LnStructured(self,amount,n,dim=-1)
torch.nn.utils.prune.LnStructured.__init__(self,amount,n,dim=-1)
torch.nn.utils.prune.LnStructured.apply(cls,module,name,amount,n,dim)
torch.nn.utils.prune.LnStructured.compute_mask(self,t,default_mask)
torch.nn.utils.prune.PruningContainer(self,*args)
torch.nn.utils.prune.PruningContainer.__getitem__(self,idx)
torch.nn.utils.prune.PruningContainer.__init__(self,*args)
torch.nn.utils.prune.PruningContainer.__iter__(self)
torch.nn.utils.prune.PruningContainer.__len__(self)
torch.nn.utils.prune.PruningContainer.add_pruning_method(self,method)
torch.nn.utils.prune.PruningContainer.compute_mask(self,t,default_mask)
torch.nn.utils.prune.RandomStructured(self,amount,dim=-1)
torch.nn.utils.prune.RandomStructured.__init__(self,amount,dim=-1)
torch.nn.utils.prune.RandomStructured.apply(cls,module,name,amount,dim=-1)
torch.nn.utils.prune.RandomStructured.compute_mask(self,t,default_mask)
torch.nn.utils.prune.RandomUnstructured(self,amount)
torch.nn.utils.prune.RandomUnstructured.__init__(self,amount)
torch.nn.utils.prune.RandomUnstructured.apply(cls,module,name,amount)
torch.nn.utils.prune.RandomUnstructured.compute_mask(self,t,default_mask)
torch.nn.utils.prune._compute_norm(t,n,dim)
torch.nn.utils.prune._compute_nparams_toprune(amount,tensor_size)
torch.nn.utils.prune._validate_pruning_amount(amount,tensor_size)
torch.nn.utils.prune._validate_pruning_amount_init(amount)
torch.nn.utils.prune._validate_pruning_dim(t,dim)
torch.nn.utils.prune._validate_structured_pruning(t)
torch.nn.utils.prune.custom_from_mask(module,name,mask)
torch.nn.utils.prune.global_unstructured(parameters,pruning_method,**kwargs)
torch.nn.utils.prune.identity(module,name)
torch.nn.utils.prune.is_pruned(module)
torch.nn.utils.prune.l1_unstructured(module,name,amount)
torch.nn.utils.prune.ln_structured(module,name,amount,n,dim)
torch.nn.utils.prune.random_structured(module,name,amount,dim)
torch.nn.utils.prune.random_unstructured(module,name,amount)
torch.nn.utils.prune.remove(module,name)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/clip_grad.py----------------------------------------
A:torch.nn.utils.clip_grad.max_norm->float(max_norm)
A:torch.nn.utils.clip_grad.norm_type->float(norm_type)
A:torch.nn.utils.clip_grad.total_norm->torch.norm(torch.stack([torch.norm(p.grad.detach(), norm_type).to(device) for p in parameters]), norm_type)
A:torch.nn.utils.clip_grad.clip_value->float(clip_value)
torch.nn.utils.clip_grad.clip_grad_norm(parameters:_tensor_or_tensors,max_norm:float,norm_type:float=2.0)->torch.Tensor
torch.nn.utils.clip_grad.clip_grad_norm_(parameters:_tensor_or_tensors,max_norm:float,norm_type:float=2.0)->torch.Tensor
torch.nn.utils.clip_grad.clip_grad_value_(parameters:_tensor_or_tensors,clip_value:float)->None
torch.nn.utils.clip_grad_norm(parameters:_tensor_or_tensors,max_norm:float,norm_type:float=2.0)->torch.Tensor
torch.nn.utils.clip_grad_norm_(parameters:_tensor_or_tensors,max_norm:float,norm_type:float=2.0)->torch.Tensor
torch.nn.utils.clip_grad_value_(parameters:_tensor_or_tensors,clip_value:float)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/convert_parameters.py----------------------------------------
A:torch.nn.utils.convert_parameters.param_device->_check_param_device(param, param_device)
A:torch.nn.utils.convert_parameters.num_param->param.numel()
torch.nn.utils.convert_parameters._check_param_device(param:torch.Tensor,old_param_device:Optional[int])->int
torch.nn.utils.convert_parameters.parameters_to_vector(parameters:Iterable[torch.Tensor])->torch.Tensor
torch.nn.utils.convert_parameters.vector_to_parameters(vec:torch.Tensor,parameters:Iterable[torch.Tensor])->None
torch.nn.utils.parameters_to_vector(parameters:Iterable[torch.Tensor])->torch.Tensor
torch.nn.utils.vector_to_parameters(vec:torch.Tensor,parameters:Iterable[torch.Tensor])->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/spectral_norm.py----------------------------------------
A:torch.nn.utils.spectral_norm.weight_mat->SpectralNorm(name, n_power_iterations, dim, eps).reshape_weight_to_matrix(weight_orig)
A:torch.nn.utils.spectral_norm.height->SpectralNorm(name, n_power_iterations, dim, eps).reshape_weight_to_matrix(weight_orig).size(0)
A:torch.nn.utils.spectral_norm.weight->state_dict.pop(weight_key)
A:torch.nn.utils.spectral_norm.u->normalize(weight.new_empty(h).normal_(0, 1), dim=0, eps=fn.eps)
A:torch.nn.utils.spectral_norm.v->SpectralNorm(name, n_power_iterations, dim, eps)._solve_v_and_rescale(weight_mat, u, sigma)
A:torch.nn.utils.spectral_norm.sigma->(weight_orig / weight).mean()
A:torch.nn.utils.spectral_norm.fn->SpectralNorm(name, n_power_iterations, dim, eps)
A:torch.nn.utils.spectral_norm.(h, w)->SpectralNorm(name, n_power_iterations, dim, eps).reshape_weight_to_matrix(weight_orig).size()
A:torch.nn.utils.spectral_norm.version->local_metadata.get('spectral_norm', {}).get(fn.name + '.version', None)
A:torch.nn.utils.spectral_norm.T_module->TypeVar('T_module', bound=Module)
torch.nn.utils.remove_spectral_norm(module:T_module,name:str='weight')->T_module
torch.nn.utils.spectral_norm(module:T_module,name:str='weight',n_power_iterations:int=1,eps:float=1e-12,dim:Optional[int]=None)->T_module
torch.nn.utils.spectral_norm.SpectralNorm(self,name:str='weight',n_power_iterations:int=1,dim:int=0,eps:float=1e-12)
torch.nn.utils.spectral_norm.SpectralNorm.__init__(self,name:str='weight',n_power_iterations:int=1,dim:int=0,eps:float=1e-12)
torch.nn.utils.spectral_norm.SpectralNorm._solve_v_and_rescale(self,weight_mat,u,target_sigma)
torch.nn.utils.spectral_norm.SpectralNorm.apply(module:Module,name:str,n_power_iterations:int,dim:int,eps:float)->'SpectralNorm'
torch.nn.utils.spectral_norm.SpectralNorm.compute_weight(self,module:Module,do_power_iteration:bool)->torch.Tensor
torch.nn.utils.spectral_norm.SpectralNorm.remove(self,module:Module)->None
torch.nn.utils.spectral_norm.SpectralNorm.reshape_weight_to_matrix(self,weight:torch.Tensor)->torch.Tensor
torch.nn.utils.spectral_norm.SpectralNormLoadStateDictPreHook(self,fn)
torch.nn.utils.spectral_norm.SpectralNormLoadStateDictPreHook.__init__(self,fn)
torch.nn.utils.spectral_norm.SpectralNormStateDictHook(self,fn)
torch.nn.utils.spectral_norm.SpectralNormStateDictHook.__init__(self,fn)
torch.nn.utils.spectral_norm.remove_spectral_norm(module:T_module,name:str='weight')->T_module
torch.nn.utils.spectral_norm.spectral_norm(module:T_module,name:str='weight',n_power_iterations:int=1,eps:float=1e-12,dim:Optional[int]=None)->T_module


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/utils/rnn.py----------------------------------------
A:torch.nn.utils.rnn.PackedSequence_->namedtuple('PackedSequence', ['data', 'batch_sizes', 'sorted_indices', 'unsorted_indices'])
A:torch.nn.utils.rnn.ex->torch.tensor((), dtype=self.data.dtype, device=self.data.device).to(*args, **kwargs)
A:torch.nn.utils.rnn.data->self.data.to(*args, **kwargs)
A:torch.nn.utils.rnn.sorted_indices->sorted_indices.to(input.device).to(input.device)
A:torch.nn.utils.rnn.unsorted_indices->invert_permutation(sorted_indices)
A:torch.nn.utils.rnn.(data, batch_sizes, sorted_indices, unsorted_indices)->_packed_sequence_init_args(data, batch_sizes, sorted_indices, unsorted_indices)
A:torch.nn.utils.rnn.output->torch.empty_like(permutation, memory_format=torch.legacy_contiguous_format)
A:torch.nn.utils.rnn.lengths->torch.as_tensor([v.size(0) for v in sequences])
A:torch.nn.utils.rnn.(lengths, sorted_indices)->torch.sort(lengths, descending=True)
A:torch.nn.utils.rnn.input->input.index_select(batch_dim, sorted_indices).index_select(batch_dim, sorted_indices)
A:torch.nn.utils.rnn.(data, batch_sizes)->_VF._pack_padded_sequence(input, lengths, batch_first)
A:torch.nn.utils.rnn.max_seq_length->sequence.batch_sizes.size(0)
A:torch.nn.utils.rnn.(padded_output, lengths)->_VF._pad_packed_sequence(sequence.data, sequence.batch_sizes, batch_first, padding_value, max_seq_length)
A:torch.nn.utils.rnn.max_size->sequences[0].size()
A:torch.nn.utils.rnn.max_len->max([s.size(0) for s in sequences])
A:torch.nn.utils.rnn.out_tensor->sequences[0].new_full(out_dims, padding_value)
A:torch.nn.utils.rnn.length->tensor.size(0)
torch.nn.utils.rnn.PackedSequence(cls,data,batch_sizes=None,sorted_indices=None,unsorted_indices=None)
torch.nn.utils.rnn.PackedSequence.__new__(cls,data,batch_sizes=None,sorted_indices=None,unsorted_indices=None)
torch.nn.utils.rnn.PackedSequence.byte(self)
torch.nn.utils.rnn.PackedSequence.char(self)
torch.nn.utils.rnn.PackedSequence.cpu(self,*args,**kwargs)
torch.nn.utils.rnn.PackedSequence.cuda(self,*args,**kwargs)
torch.nn.utils.rnn.PackedSequence.double(self)
torch.nn.utils.rnn.PackedSequence.float(self)
torch.nn.utils.rnn.PackedSequence.half(self)
torch.nn.utils.rnn.PackedSequence.int(self)
torch.nn.utils.rnn.PackedSequence.is_cuda(self)
torch.nn.utils.rnn.PackedSequence.is_pinned(self)
torch.nn.utils.rnn.PackedSequence.long(self)
torch.nn.utils.rnn.PackedSequence.pin_memory(self)
torch.nn.utils.rnn.PackedSequence.short(self)
torch.nn.utils.rnn.PackedSequence.to(self,*args,**kwargs)
torch.nn.utils.rnn._packed_sequence_init(data,batch_sizes=None,sorted_indices=None,unsorted_indices=None)
torch.nn.utils.rnn._packed_sequence_init_args(data,batch_sizes=None,sorted_indices=None,unsorted_indices=None)
torch.nn.utils.rnn.bind(optional,fn)
torch.nn.utils.rnn.invert_permutation(permutation)
torch.nn.utils.rnn.pack_padded_sequence(input,lengths,batch_first=False,enforce_sorted=True)
torch.nn.utils.rnn.pack_sequence(sequences,enforce_sorted=True)
torch.nn.utils.rnn.pad_packed_sequence(sequence,batch_first=False,padding_value=0.0,total_length=None)
torch.nn.utils.rnn.pad_sequence(sequences,batch_first=False,padding_value=0.0)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/backends/thnn.py----------------------------------------
torch.nn.backends.thnn._get_thnn_function_backend()


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/backends/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/replicate.py----------------------------------------
A:torch.nn.parallel.replicate.gen->module.modules()
A:torch.nn.parallel.replicate.memo->set()
A:torch.nn.parallel.replicate.tensor_copies->_functions.Broadcast.apply(devices, *tensors)
A:torch.nn.parallel.replicate.devices->list(map(lambda x: _get_device_index(x, True), devices))
A:torch.nn.parallel.replicate.num_replicas->len(devices)
A:torch.nn.parallel.replicate.params->list(network.parameters())
A:torch.nn.parallel.replicate.param_copies->_broadcast_coalesced_reshape(params, devices, detach)
A:torch.nn.parallel.replicate.buffers->list(network.buffers())
A:torch.nn.parallel.replicate.buffer_copies_rg->_broadcast_coalesced_reshape(buffers_rg, devices, detach=detach)
A:torch.nn.parallel.replicate.buffer_copies_not_rg->_broadcast_coalesced_reshape(buffers_not_rg, devices, detach=True)
A:torch.nn.parallel.replicate.modules->list(network.modules())
A:torch.nn.parallel.replicate.replica->module._replicate_for_data_parallel()
A:torch.nn.parallel.replicate.replica._former_parameters->OrderedDict()
torch.nn.parallel.replicate(network,devices,detach=False)
torch.nn.parallel.replicate._broadcast_coalesced_reshape(tensors,devices,detach=False)
torch.nn.parallel.replicate._init_script_module()
torch.nn.parallel.replicate._is_jit_enabled()
torch.nn.parallel.replicate._is_script_method(module)
torch.nn.parallel.replicate._is_script_module(module)
torch.nn.parallel.replicate._replicatable_module(module,memo=None)
torch.nn.parallel.replicate.replicate(network,devices,detach=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/replicate.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/parallel_apply.py----------------------------------------
A:torch.nn.parallel.parallel_apply.devices->list(map(lambda x: _get_device_index(x, True), devices))
A:torch.nn.parallel.parallel_apply.lock->threading.Lock()
A:torch.nn.parallel.parallel_apply.device->get_a_var(input).get_device()
A:torch.nn.parallel.parallel_apply.output->module(*input, **kwargs)
A:torch.nn.parallel.parallel_apply.results[i]->ExceptionWrapper(where='in replica {} on device {}'.format(i, device))
torch.nn.parallel.parallel_apply(modules,inputs,kwargs_tup=None,devices=None)
torch.nn.parallel.parallel_apply.get_a_var(obj)
torch.nn.parallel.parallel_apply.parallel_apply(modules,inputs,kwargs_tup=None,devices=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/parallel_apply.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/data_parallel.py----------------------------------------
A:torch.nn.parallel.data_parallel.device_ids->list(map(lambda x: _get_device_index(x, True), device_ids))
A:torch.nn.parallel.data_parallel.dev_props->_get_devices_properties(device_ids)
A:torch.nn.parallel.data_parallel.(min_pos, min_val)->min(enumerate(values), key=operator.itemgetter(1))
A:torch.nn.parallel.data_parallel.(max_pos, max_val)->max(enumerate(values), key=operator.itemgetter(1))
A:torch.nn.parallel.data_parallel.device_type->_get_available_device_type()
A:torch.nn.parallel.data_parallel.self.device_ids->list(map(lambda x: _get_device_index(x, True), device_ids))
A:torch.nn.parallel.data_parallel.self.output_device->_get_device_index(output_device, True)
A:torch.nn.parallel.data_parallel.self.src_device_obj->torch.device(device_type, self.device_ids[0])
A:torch.nn.parallel.data_parallel.(inputs, kwargs)->self.scatter(inputs, kwargs, self.device_ids)
A:torch.nn.parallel.data_parallel.replicas->replicate(module, used_device_ids)
A:torch.nn.parallel.data_parallel.outputs->parallel_apply(replicas, inputs, module_kwargs, used_device_ids)
A:torch.nn.parallel.data_parallel.output_device->_get_device_index(output_device, True)
A:torch.nn.parallel.data_parallel.src_device_obj->torch.device(device_type, device_ids[0])
A:torch.nn.parallel.data_parallel.(inputs, module_kwargs)->scatter_kwargs(inputs, module_kwargs, device_ids, dim)
torch.nn.DataParallel(self,module,device_ids=None,output_device=None,dim=0)
torch.nn.DataParallel.forward(self,*inputs,**kwargs)
torch.nn.DataParallel.gather(self,outputs,output_device)
torch.nn.DataParallel.parallel_apply(self,replicas,inputs,kwargs)
torch.nn.DataParallel.replicate(self,module,device_ids)
torch.nn.DataParallel.scatter(self,inputs,kwargs,device_ids)
torch.nn.parallel.data_parallel(module,inputs,device_ids=None,output_device=None,dim=0,module_kwargs=None)
torch.nn.parallel.data_parallel.DataParallel(self,module,device_ids=None,output_device=None,dim=0)
torch.nn.parallel.data_parallel.DataParallel.__init__(self,module,device_ids=None,output_device=None,dim=0)
torch.nn.parallel.data_parallel.DataParallel.forward(self,*inputs,**kwargs)
torch.nn.parallel.data_parallel.DataParallel.gather(self,outputs,output_device)
torch.nn.parallel.data_parallel.DataParallel.parallel_apply(self,replicas,inputs,kwargs)
torch.nn.parallel.data_parallel.DataParallel.replicate(self,module,device_ids)
torch.nn.parallel.data_parallel.DataParallel.scatter(self,inputs,kwargs,device_ids)
torch.nn.parallel.data_parallel._check_balance(device_ids)
torch.nn.parallel.data_parallel.data_parallel(module,inputs,device_ids=None,output_device=None,dim=0,module_kwargs=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/data_parallel.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/__init__.py----------------------------------------
torch.nn.parallel.__init__.DistributedDataParallelCPU(*args,**kwargs)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/__init__.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/distributed.py----------------------------------------
A:torch.nn.parallel.distributed.device_ids->_get_all_device_indices()
A:torch.nn.parallel.distributed.self.device_ids->list(map(lambda x: _get_device_index(x, True), device_ids))
A:torch.nn.parallel.distributed.self.output_device->_get_device_index(output_device, True)
A:torch.nn.parallel.distributed.self.process_group->_get_default_group()
A:torch.nn.parallel.distributed.self.broadcast_bucket_size->int(250 * 1024 * 1024)
A:torch.nn.parallel.distributed.self.bucket_bytes_cap->int(bucket_cap_mb * 1024 * 1024)
A:torch.nn.parallel.distributed.module_states->list(self.module.state_dict().values())
A:torch.nn.parallel.distributed.self._module_copies->replicate(self.module, self.device_ids, detach=True)
A:torch.nn.parallel.distributed.bucket_indices->torch.distributed._compute_bucket_assignment_by_size(parameters[0], [dist._DEFAULT_FIRST_BUCKET_BYTES, self.bucket_bytes_cap], expect_sparse_gradient[0])
A:torch.nn.parallel.distributed.self.reducer->torch.distributed.Reducer(parameters, list(reversed(bucket_indices)), self.process_group, expect_sparse_gradient, self.bucket_bytes_cap, self.find_unused_parameters, self.gradient_as_bucket_view)
A:torch.nn.parallel.distributed.attrs->copy.copy(self.__dict__)
A:torch.nn.parallel.distributed.ones->torch.ones(1, device=self.device)
A:torch.nn.parallel.distributed.work->self.process_group.allreduce(zero_tensors)
A:torch.nn.parallel.distributed.(inputs, kwargs)->self.scatter(inputs, kwargs, self.device_ids)
A:torch.nn.parallel.distributed.output->self.module(*inputs, **kwargs)
A:torch.nn.parallel.distributed.outputs->self.parallel_apply(self._module_copies[:len(inputs)], inputs, kwargs)
A:torch.nn.parallel.distributed.all_active_procs->torch.zeros(1, device=self.device)
A:torch.nn.parallel.distributed.requires_sync_tensor->torch.zeros(1, device=self.device)
A:torch.nn.parallel.distributed.my_rank->torch.distributed.get_rank(self.process_group)
A:torch.nn.parallel.distributed.authoritative_rank->self._find_common_rank(dist.get_rank(), True)
A:torch.nn.parallel.distributed.self._authoritative_rank->self._find_common_rank(my_rank, is_last_joiner)
A:torch.nn.parallel.distributed.all_bucket_tensors->self.reducer.get_bucket_tensors()
A:torch.nn.parallel.distributed.locally_used_param_maps->self.reducer._get_local_used_maps()
A:torch.nn.parallel.distributed.num_active_procs->self._schedule_shadow_all_reduce_for_fwd_pass()
A:torch.nn.parallel.distributed.(work, should_sync_backwards_tensor)->self._check_global_requires_backward_grad_sync(is_joined_rank=True)
A:torch.nn.parallel.distributed.rank_to_use->torch.tensor([input_rank if rank_cond else -1], device=self.device)
A:torch.nn.parallel.distributed.result->comm.broadcast_coalesced(self.modules_buffers[0], self.device_ids, self.broadcast_bucket_size)
A:torch.nn.parallel.distributed.sig->inspect.signature(hook)
torch.nn.parallel.DistributedDataParallel(self,module,device_ids=None,output_device=None,dim=0,broadcast_buffers=True,process_group=None,bucket_cap_mb=25,find_unused_parameters=False,check_reduction=False,gradient_as_bucket_view=False)
torch.nn.parallel.DistributedDataParallel.__getstate__(self)
torch.nn.parallel.DistributedDataParallel.__setstate__(self,state)
torch.nn.parallel.DistributedDataParallel._check_and_sync_module_buffers(self)
torch.nn.parallel.DistributedDataParallel._check_comm_hook(self,hook)
torch.nn.parallel.DistributedDataParallel._check_default_group(self)
torch.nn.parallel.DistributedDataParallel._check_global_requires_backward_grad_sync(self,is_joined_rank)
torch.nn.parallel.DistributedDataParallel._ddp_init_helper(self)
torch.nn.parallel.DistributedDataParallel._distributed_broadcast_coalesced(self,tensors,buffer_size,authoritative_rank=0)
torch.nn.parallel.DistributedDataParallel._find_common_rank(self,input_rank,rank_cond)
torch.nn.parallel.DistributedDataParallel._match_all_reduce_for_bwd_pass(self)
torch.nn.parallel.DistributedDataParallel._match_unused_params_allreduce(self)
torch.nn.parallel.DistributedDataParallel._passing_sync_batchnorm_handle(self,module_copies)
torch.nn.parallel.DistributedDataParallel._register_comm_hook(self,state:object,hook:callable)
torch.nn.parallel.DistributedDataParallel._schedule_shadow_all_reduce_for_fwd_pass(self)
torch.nn.parallel.DistributedDataParallel._sync_final_model(self,is_last_joiner)
torch.nn.parallel.DistributedDataParallel._sync_params(self)
torch.nn.parallel.DistributedDataParallel._sync_params_and_buffers(self,authoritative_rank=0)
torch.nn.parallel.DistributedDataParallel.forward(self,*inputs,**kwargs)
torch.nn.parallel.DistributedDataParallel.gather(self,outputs,output_device)
torch.nn.parallel.DistributedDataParallel.join(self,divide_by_initial_world_size=True,enable=True)
torch.nn.parallel.DistributedDataParallel.no_sync(self)
torch.nn.parallel.DistributedDataParallel.parallel_apply(self,replicas,inputs,kwargs)
torch.nn.parallel.DistributedDataParallel.scatter(self,inputs,kwargs,device_ids)
torch.nn.parallel.DistributedDataParallel.train(self,mode=True)
torch.nn.parallel.DistributedDataParallel.will_sync_module_buffers(self)
torch.nn.parallel.distributed.DistributedDataParallel(self,module,device_ids=None,output_device=None,dim=0,broadcast_buffers=True,process_group=None,bucket_cap_mb=25,find_unused_parameters=False,check_reduction=False,gradient_as_bucket_view=False)
torch.nn.parallel.distributed.DistributedDataParallel.__getstate__(self)
torch.nn.parallel.distributed.DistributedDataParallel.__init__(self,module,device_ids=None,output_device=None,dim=0,broadcast_buffers=True,process_group=None,bucket_cap_mb=25,find_unused_parameters=False,check_reduction=False,gradient_as_bucket_view=False)
torch.nn.parallel.distributed.DistributedDataParallel.__setstate__(self,state)
torch.nn.parallel.distributed.DistributedDataParallel._check_and_sync_module_buffers(self)
torch.nn.parallel.distributed.DistributedDataParallel._check_comm_hook(self,hook)
torch.nn.parallel.distributed.DistributedDataParallel._check_default_group(self)
torch.nn.parallel.distributed.DistributedDataParallel._check_global_requires_backward_grad_sync(self,is_joined_rank)
torch.nn.parallel.distributed.DistributedDataParallel._ddp_init_helper(self)
torch.nn.parallel.distributed.DistributedDataParallel._distributed_broadcast_coalesced(self,tensors,buffer_size,authoritative_rank=0)
torch.nn.parallel.distributed.DistributedDataParallel._find_common_rank(self,input_rank,rank_cond)
torch.nn.parallel.distributed.DistributedDataParallel._match_all_reduce_for_bwd_pass(self)
torch.nn.parallel.distributed.DistributedDataParallel._match_unused_params_allreduce(self)
torch.nn.parallel.distributed.DistributedDataParallel._passing_sync_batchnorm_handle(self,module_copies)
torch.nn.parallel.distributed.DistributedDataParallel._register_comm_hook(self,state:object,hook:callable)
torch.nn.parallel.distributed.DistributedDataParallel._schedule_shadow_all_reduce_for_fwd_pass(self)
torch.nn.parallel.distributed.DistributedDataParallel._sync_final_model(self,is_last_joiner)
torch.nn.parallel.distributed.DistributedDataParallel._sync_params(self)
torch.nn.parallel.distributed.DistributedDataParallel._sync_params_and_buffers(self,authoritative_rank=0)
torch.nn.parallel.distributed.DistributedDataParallel.forward(self,*inputs,**kwargs)
torch.nn.parallel.distributed.DistributedDataParallel.gather(self,outputs,output_device)
torch.nn.parallel.distributed.DistributedDataParallel.join(self,divide_by_initial_world_size=True,enable=True)
torch.nn.parallel.distributed.DistributedDataParallel.no_sync(self)
torch.nn.parallel.distributed.DistributedDataParallel.parallel_apply(self,replicas,inputs,kwargs)
torch.nn.parallel.distributed.DistributedDataParallel.scatter(self,inputs,kwargs,device_ids)
torch.nn.parallel.distributed.DistributedDataParallel.train(self,mode=True)
torch.nn.parallel.distributed.DistributedDataParallel.will_sync_module_buffers(self)
torch.nn.parallel.distributed._dump_DDP_relevant_env_vars()
torch.nn.parallel.distributed._find_tensors(obj)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/distributed.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/comm.py----------------------------------------
A:torch.nn.parallel.comm.destination->_get_device_index(destination, allow_cpu=True, optional=True)
A:torch.nn.parallel.comm.input_size->inputs[0].size()
A:torch.nn.parallel.comm.got->'x'.join((str(x) for x in inp.size()))
A:torch.nn.parallel.comm.expected->'x'.join((str(x) for x in input_size))
A:torch.nn.parallel.comm.result->reduce_add(tensor_at_gpus, destination)
A:torch.nn.parallel.comm.destination_device->torch.device(inputs[root_index].device.type, destination)
A:torch.nn.parallel.comm.flat_result->reduce_add(flat_tensors, destination)
torch.nn.parallel.comm.broadcast(tensor,devices=None,*,out=None)
torch.nn.parallel.comm.broadcast_coalesced(tensors,devices,buffer_size=10485760)
torch.nn.parallel.comm.gather(tensors,dim=0,destination=None,*,out=None)
torch.nn.parallel.comm.reduce_add(inputs,destination=None)
torch.nn.parallel.comm.reduce_add_coalesced(inputs,destination=None,buffer_size=10485760)
torch.nn.parallel.comm.scatter(tensor,devices=None,chunk_sizes=None,dim=0,streams=None,*,out=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/scatter_gather.py----------------------------------------
A:torch.nn.parallel.scatter_gather.res->gather_map(outputs)
A:torch.nn.parallel.scatter_gather.inputs->tuple(inputs)
A:torch.nn.parallel.scatter_gather.kwargs->tuple(kwargs)
torch.nn.parallel.gather(outputs,target_device,dim=0)
torch.nn.parallel.scatter(inputs,target_gpus,dim=0)
torch.nn.parallel.scatter_gather.gather(outputs,target_device,dim=0)
torch.nn.parallel.scatter_gather.scatter(inputs,target_gpus,dim=0)
torch.nn.parallel.scatter_gather.scatter_kwargs(inputs,kwargs,target_gpus,dim=0)
torch.nn.parallel.scatter_kwargs(inputs,kwargs,target_gpus,dim=0)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/scatter_gather.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/common_types.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/parallel/_functions.py----------------------------------------
A:torch.nn.parallel._functions.target_gpus->list(map(lambda x: _get_device_index(x, True), target_gpus))
A:torch.nn.parallel._functions.ctx.num_inputs->len(inputs)
A:torch.nn.parallel._functions.ctx.input_device->inputs[0].get_device()
A:torch.nn.parallel._functions.outputs->comm.scatter(input, target_gpus, chunk_sizes, ctx.dim, streams)
A:torch.nn.parallel._functions.target_device->_get_device_index(target_device, True)
A:torch.nn.parallel._functions.ctx.input_gpus->tuple(map(lambda i: i.get_device(), inputs))
A:torch.nn.parallel._functions.inputs->tuple((t.view(1) for t in inputs))
A:torch.nn.parallel._functions.ctx.input_sizes->tuple(map(lambda i: i.size(ctx.dim), inputs))
A:torch.nn.parallel._functions.scattered_grads->tuple((g[0] for g in scattered_grads))
A:torch.nn.parallel._functions.main_stream->torch.cuda.current_stream()
A:torch.nn.parallel._functions._streams[device]->torch.cuda.Stream(device)
torch.nn.parallel._functions.Broadcast(Function)
torch.nn.parallel._functions.Broadcast.backward(ctx,*grad_outputs)
torch.nn.parallel._functions.Broadcast.forward(ctx,target_gpus,*inputs)
torch.nn.parallel._functions.Gather(Function)
torch.nn.parallel._functions.Gather.backward(ctx,grad_output)
torch.nn.parallel._functions.Gather.forward(ctx,target_device,dim,*inputs)
torch.nn.parallel._functions.ReduceAddCoalesced(Function)
torch.nn.parallel._functions.ReduceAddCoalesced.backward(ctx,*grad_outputs)
torch.nn.parallel._functions.ReduceAddCoalesced.forward(ctx,destination,num_inputs,*grads)
torch.nn.parallel._functions.Scatter(Function)
torch.nn.parallel._functions.Scatter.backward(ctx,*grad_output)
torch.nn.parallel._functions.Scatter.forward(ctx,target_gpus,chunk_sizes,dim,input)
torch.nn.parallel._functions._get_stream(device)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/container.py----------------------------------------
A:torch.nn.modules.container.T->TypeVar('T')
A:torch.nn.modules.container.size->len(self)
A:torch.nn.modules.container.idx->self._get_abs_string_index(idx)
A:torch.nn.modules.container.key->self._get_item_by_idx(self._modules.keys(), idx)
A:torch.nn.modules.container.keys->super(ParameterList, self).__dir__()
A:torch.nn.modules.container.input->module(input)
A:torch.nn.modules.container.self._modules->OrderedDict(list(zip(str_indices, self._modules.values())))
A:torch.nn.modules.container.offset->len(self)
A:torch.nn.modules.container.size_str->'x'.join((str(size) for size in p.size()))
A:torch.nn.modules.container.parastr->'Parameter containing: [{} of size {}{}]'.format(torch.typename(p), size_str, device_str)
A:torch.nn.modules.container.tmpstr->'\n'.join(child_lines)
torch.nn.Container(self,**kwargs:Any)
torch.nn.ModuleDict(self,modules:Optional[Mapping[str,Module]]=None)
torch.nn.ModuleDict.__contains__(self,key:str)->bool
torch.nn.ModuleDict.__delitem__(self,key:str)->None
torch.nn.ModuleDict.__getitem__(self,key:str)->Module
torch.nn.ModuleDict.__iter__(self)->Iterator[str]
torch.nn.ModuleDict.__len__(self)->int
torch.nn.ModuleDict.__setitem__(self,key:str,module:Module)->None
torch.nn.ModuleDict.clear(self)->None
torch.nn.ModuleDict.forward(self)
torch.nn.ModuleDict.items(self)->Iterable[Tuple[str, Module]]
torch.nn.ModuleDict.keys(self)->Iterable[str]
torch.nn.ModuleDict.pop(self,key:str)->Module
torch.nn.ModuleDict.update(self,modules:Mapping[str,Module])->None
torch.nn.ModuleDict.values(self)->Iterable[Module]
torch.nn.ModuleList(self,modules:Optional[Iterable[Module]]=None)
torch.nn.ModuleList.__delitem__(self,idx:Union[int,slice])->None
torch.nn.ModuleList.__dir__(self)
torch.nn.ModuleList.__getitem__(self,idx:int)->Module
torch.nn.ModuleList.__iadd__(self:T,modules:Iterable[Module])->T
torch.nn.ModuleList.__iter__(self)->Iterator[Module]
torch.nn.ModuleList.__len__(self)->int
torch.nn.ModuleList.__setitem__(self,idx:int,module:Module)->None
torch.nn.ModuleList._get_abs_string_index(self,idx)
torch.nn.ModuleList.append(self:T,module:Module)->T
torch.nn.ModuleList.extend(self:T,modules:Iterable[Module])->T
torch.nn.ModuleList.forward(self)
torch.nn.ModuleList.insert(self,index:int,module:Module)->None
torch.nn.ParameterDict(self,parameters:Optional[Mapping[str,'Parameter']]=None)
torch.nn.ParameterDict.__contains__(self,key:str)->bool
torch.nn.ParameterDict.__delitem__(self,key:str)->None
torch.nn.ParameterDict.__getitem__(self,key:str)->'Parameter'
torch.nn.ParameterDict.__iter__(self)->Iterator[str]
torch.nn.ParameterDict.__len__(self)->int
torch.nn.ParameterDict.__setattr__(self,key:Any,value:Any)->None
torch.nn.ParameterDict.__setitem__(self,key:str,parameter:'Parameter')->None
torch.nn.ParameterDict._replicate_for_data_parallel(self)
torch.nn.ParameterDict.clear(self)->None
torch.nn.ParameterDict.extra_repr(self)->str
torch.nn.ParameterDict.items(self)->Iterable[Tuple[str, 'Parameter']]
torch.nn.ParameterDict.keys(self)->Iterable[str]
torch.nn.ParameterDict.pop(self,key:str)->'Parameter'
torch.nn.ParameterDict.update(self,parameters:Mapping[str,'Parameter'])->None
torch.nn.ParameterDict.values(self)->Iterable['Parameter']
torch.nn.ParameterList(self,parameters:Optional[Iterable['Parameter']]=None)
torch.nn.ParameterList.__dir__(self)
torch.nn.ParameterList.__getitem__(self,idx)
torch.nn.ParameterList.__iadd__(self:T,parameters:Iterable['Parameter'])->T
torch.nn.ParameterList.__iter__(self)->Iterator['Parameter']
torch.nn.ParameterList.__len__(self)->int
torch.nn.ParameterList.__setattr__(self,key:Any,value:Any)->None
torch.nn.ParameterList.__setitem__(self,idx:int,param:'Parameter')->None
torch.nn.ParameterList._get_abs_string_index(self,idx)
torch.nn.ParameterList._replicate_for_data_parallel(self)
torch.nn.ParameterList.append(self:T,parameter:'Parameter')->T
torch.nn.ParameterList.extend(self:T,parameters:Iterable['Parameter'])->T
torch.nn.ParameterList.extra_repr(self)->str
torch.nn.Sequential(self,*args:Any)
torch.nn.Sequential.__delitem__(self,idx:Union[slice,int])->None
torch.nn.Sequential.__dir__(self)
torch.nn.Sequential.__getitem__(self:T,idx)->T
torch.nn.Sequential.__iter__(self)->Iterator[Module]
torch.nn.Sequential.__len__(self)->int
torch.nn.Sequential.__setitem__(self,idx:int,module:Module)->None
torch.nn.Sequential._get_item_by_idx(self,iterator,idx)
torch.nn.Sequential.forward(self,input)
torch.nn.modules.container.Container(self,**kwargs:Any)
torch.nn.modules.container.Container.__init__(self,**kwargs:Any)
torch.nn.modules.container.ModuleDict(self,modules:Optional[Mapping[str,Module]]=None)
torch.nn.modules.container.ModuleDict.__contains__(self,key:str)->bool
torch.nn.modules.container.ModuleDict.__delitem__(self,key:str)->None
torch.nn.modules.container.ModuleDict.__getitem__(self,key:str)->Module
torch.nn.modules.container.ModuleDict.__init__(self,modules:Optional[Mapping[str,Module]]=None)
torch.nn.modules.container.ModuleDict.__iter__(self)->Iterator[str]
torch.nn.modules.container.ModuleDict.__len__(self)->int
torch.nn.modules.container.ModuleDict.__setitem__(self,key:str,module:Module)->None
torch.nn.modules.container.ModuleDict.clear(self)->None
torch.nn.modules.container.ModuleDict.forward(self)
torch.nn.modules.container.ModuleDict.items(self)->Iterable[Tuple[str, Module]]
torch.nn.modules.container.ModuleDict.keys(self)->Iterable[str]
torch.nn.modules.container.ModuleDict.pop(self,key:str)->Module
torch.nn.modules.container.ModuleDict.update(self,modules:Mapping[str,Module])->None
torch.nn.modules.container.ModuleDict.values(self)->Iterable[Module]
torch.nn.modules.container.ModuleList(self,modules:Optional[Iterable[Module]]=None)
torch.nn.modules.container.ModuleList.__delitem__(self,idx:Union[int,slice])->None
torch.nn.modules.container.ModuleList.__dir__(self)
torch.nn.modules.container.ModuleList.__getitem__(self,idx:int)->Module
torch.nn.modules.container.ModuleList.__iadd__(self:T,modules:Iterable[Module])->T
torch.nn.modules.container.ModuleList.__init__(self,modules:Optional[Iterable[Module]]=None)
torch.nn.modules.container.ModuleList.__iter__(self)->Iterator[Module]
torch.nn.modules.container.ModuleList.__len__(self)->int
torch.nn.modules.container.ModuleList.__setitem__(self,idx:int,module:Module)->None
torch.nn.modules.container.ModuleList._get_abs_string_index(self,idx)
torch.nn.modules.container.ModuleList.append(self:T,module:Module)->T
torch.nn.modules.container.ModuleList.extend(self:T,modules:Iterable[Module])->T
torch.nn.modules.container.ModuleList.forward(self)
torch.nn.modules.container.ModuleList.insert(self,index:int,module:Module)->None
torch.nn.modules.container.ParameterDict(self,parameters:Optional[Mapping[str,'Parameter']]=None)
torch.nn.modules.container.ParameterDict.__contains__(self,key:str)->bool
torch.nn.modules.container.ParameterDict.__delitem__(self,key:str)->None
torch.nn.modules.container.ParameterDict.__getitem__(self,key:str)->'Parameter'
torch.nn.modules.container.ParameterDict.__init__(self,parameters:Optional[Mapping[str,'Parameter']]=None)
torch.nn.modules.container.ParameterDict.__iter__(self)->Iterator[str]
torch.nn.modules.container.ParameterDict.__len__(self)->int
torch.nn.modules.container.ParameterDict.__setattr__(self,key:Any,value:Any)->None
torch.nn.modules.container.ParameterDict.__setitem__(self,key:str,parameter:'Parameter')->None
torch.nn.modules.container.ParameterDict._replicate_for_data_parallel(self)
torch.nn.modules.container.ParameterDict.clear(self)->None
torch.nn.modules.container.ParameterDict.extra_repr(self)->str
torch.nn.modules.container.ParameterDict.items(self)->Iterable[Tuple[str, 'Parameter']]
torch.nn.modules.container.ParameterDict.keys(self)->Iterable[str]
torch.nn.modules.container.ParameterDict.pop(self,key:str)->'Parameter'
torch.nn.modules.container.ParameterDict.update(self,parameters:Mapping[str,'Parameter'])->None
torch.nn.modules.container.ParameterDict.values(self)->Iterable['Parameter']
torch.nn.modules.container.ParameterList(self,parameters:Optional[Iterable['Parameter']]=None)
torch.nn.modules.container.ParameterList.__dir__(self)
torch.nn.modules.container.ParameterList.__getitem__(self,idx)
torch.nn.modules.container.ParameterList.__iadd__(self:T,parameters:Iterable['Parameter'])->T
torch.nn.modules.container.ParameterList.__init__(self,parameters:Optional[Iterable['Parameter']]=None)
torch.nn.modules.container.ParameterList.__iter__(self)->Iterator['Parameter']
torch.nn.modules.container.ParameterList.__len__(self)->int
torch.nn.modules.container.ParameterList.__setattr__(self,key:Any,value:Any)->None
torch.nn.modules.container.ParameterList.__setitem__(self,idx:int,param:'Parameter')->None
torch.nn.modules.container.ParameterList._get_abs_string_index(self,idx)
torch.nn.modules.container.ParameterList._replicate_for_data_parallel(self)
torch.nn.modules.container.ParameterList.append(self:T,parameter:'Parameter')->T
torch.nn.modules.container.ParameterList.extend(self:T,parameters:Iterable['Parameter'])->T
torch.nn.modules.container.ParameterList.extra_repr(self)->str
torch.nn.modules.container.Sequential(self,*args:Any)
torch.nn.modules.container.Sequential.__delitem__(self,idx:Union[slice,int])->None
torch.nn.modules.container.Sequential.__dir__(self)
torch.nn.modules.container.Sequential.__getitem__(self:T,idx)->T
torch.nn.modules.container.Sequential.__init__(self,*args:Any)
torch.nn.modules.container.Sequential.__iter__(self)->Iterator[Module]
torch.nn.modules.container.Sequential.__len__(self)->int
torch.nn.modules.container.Sequential.__setitem__(self,idx:int,module:Module)->None
torch.nn.modules.container.Sequential._get_item_by_idx(self,iterator,idx)
torch.nn.modules.container.Sequential.forward(self,input)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/flatten.py----------------------------------------
torch.nn.Flatten(self,start_dim:int=1,end_dim:int=-1)
torch.nn.Flatten.extra_repr(self)->str
torch.nn.Flatten.forward(self,input:Tensor)->Tensor
torch.nn.Unflatten(self,dim:Union[int,str],unflattened_size:Union[Size,NamedShape])
torch.nn.Unflatten._require_tuple_int(self,input)
torch.nn.Unflatten._require_tuple_tuple(self,input)
torch.nn.Unflatten.extra_repr(self)->str
torch.nn.Unflatten.forward(self,input:Tensor)->Tensor
torch.nn.modules.flatten.Flatten(self,start_dim:int=1,end_dim:int=-1)
torch.nn.modules.flatten.Flatten.__init__(self,start_dim:int=1,end_dim:int=-1)
torch.nn.modules.flatten.Flatten.extra_repr(self)->str
torch.nn.modules.flatten.Flatten.forward(self,input:Tensor)->Tensor
torch.nn.modules.flatten.Unflatten(self,dim:Union[int,str],unflattened_size:Union[Size,NamedShape])
torch.nn.modules.flatten.Unflatten.__init__(self,dim:Union[int,str],unflattened_size:Union[Size,NamedShape])
torch.nn.modules.flatten.Unflatten._require_tuple_int(self,input)
torch.nn.modules.flatten.Unflatten._require_tuple_tuple(self,input)
torch.nn.modules.flatten.Unflatten.extra_repr(self)->str
torch.nn.modules.flatten.Unflatten.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/dropout.py----------------------------------------
torch.nn.AlphaDropout(_DropoutNd)
torch.nn.AlphaDropout.forward(self,input:Tensor)->Tensor
torch.nn.Dropout(_DropoutNd)
torch.nn.Dropout.forward(self,input:Tensor)->Tensor
torch.nn.Dropout2d(_DropoutNd)
torch.nn.Dropout2d.forward(self,input:Tensor)->Tensor
torch.nn.Dropout3d(_DropoutNd)
torch.nn.Dropout3d.forward(self,input:Tensor)->Tensor
torch.nn.FeatureAlphaDropout(_DropoutNd)
torch.nn.FeatureAlphaDropout.forward(self,input:Tensor)->Tensor
torch.nn.dropout._DropoutNd(self,p:float=0.5,inplace:bool=False)
torch.nn.dropout._DropoutNd.extra_repr(self)->str
torch.nn.modules.dropout.AlphaDropout(_DropoutNd)
torch.nn.modules.dropout.AlphaDropout.forward(self,input:Tensor)->Tensor
torch.nn.modules.dropout.Dropout(_DropoutNd)
torch.nn.modules.dropout.Dropout.forward(self,input:Tensor)->Tensor
torch.nn.modules.dropout.Dropout2d(_DropoutNd)
torch.nn.modules.dropout.Dropout2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.dropout.Dropout3d(_DropoutNd)
torch.nn.modules.dropout.Dropout3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.dropout.FeatureAlphaDropout(_DropoutNd)
torch.nn.modules.dropout.FeatureAlphaDropout.forward(self,input:Tensor)->Tensor
torch.nn.modules.dropout._DropoutNd(self,p:float=0.5,inplace:bool=False)
torch.nn.modules.dropout._DropoutNd.__init__(self,p:float=0.5,inplace:bool=False)
torch.nn.modules.dropout._DropoutNd.extra_repr(self)->str


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/transformer.py----------------------------------------
A:torch.nn.modules.transformer.encoder_layer->TransformerEncoderLayer(d_model, nhead, dim_feedforward, dropout, activation)
A:torch.nn.modules.transformer.encoder_norm->LayerNorm(d_model)
A:torch.nn.modules.transformer.self.encoder->TransformerEncoder(encoder_layer, num_encoder_layers, encoder_norm)
A:torch.nn.modules.transformer.decoder_layer->TransformerDecoderLayer(d_model, nhead, dim_feedforward, dropout, activation)
A:torch.nn.modules.transformer.decoder_norm->LayerNorm(d_model)
A:torch.nn.modules.transformer.self.decoder->TransformerDecoder(decoder_layer, num_decoder_layers, decoder_norm)
A:torch.nn.modules.transformer.memory->self.encoder(src, mask=src_mask, src_key_padding_mask=src_key_padding_mask)
A:torch.nn.modules.transformer.output->self.norm(output)
A:torch.nn.modules.transformer.mask->mask.float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0)).float().masked_fill(mask == 0, float('-inf')).masked_fill(mask == 1, float(0.0))
A:torch.nn.modules.transformer.self.layers->_get_clones(decoder_layer, num_layers)
A:torch.nn.modules.transformer.self.self_attn->MultiheadAttention(d_model, nhead, dropout=dropout)
A:torch.nn.modules.transformer.self.linear1->Linear(d_model, dim_feedforward)
A:torch.nn.modules.transformer.self.dropout->Dropout(dropout)
A:torch.nn.modules.transformer.self.linear2->Linear(dim_feedforward, d_model)
A:torch.nn.modules.transformer.self.norm1->LayerNorm(d_model)
A:torch.nn.modules.transformer.self.norm2->LayerNorm(d_model)
A:torch.nn.modules.transformer.self.dropout1->Dropout(dropout)
A:torch.nn.modules.transformer.self.dropout2->Dropout(dropout)
A:torch.nn.modules.transformer.self.activation->_get_activation_fn(activation)
A:torch.nn.modules.transformer.src->self.norm2(src)
A:torch.nn.modules.transformer.src2->self.linear2(self.dropout(self.activation(self.linear1(src))))
A:torch.nn.modules.transformer.self.multihead_attn->MultiheadAttention(d_model, nhead, dropout=dropout)
A:torch.nn.modules.transformer.self.norm3->LayerNorm(d_model)
A:torch.nn.modules.transformer.self.dropout3->Dropout(dropout)
A:torch.nn.modules.transformer.tgt->self.norm3(tgt)
A:torch.nn.modules.transformer.tgt2->self.linear2(self.dropout(self.activation(self.linear1(tgt))))
torch.nn.Transformer(self,d_model:int=512,nhead:int=8,num_encoder_layers:int=6,num_decoder_layers:int=6,dim_feedforward:int=2048,dropout:float=0.1,activation:str='relu',custom_encoder:Optional[Any]=None,custom_decoder:Optional[Any]=None)
torch.nn.Transformer._reset_parameters(self)
torch.nn.Transformer.forward(self,src:Tensor,tgt:Tensor,src_mask:Optional[Tensor]=None,tgt_mask:Optional[Tensor]=None,memory_mask:Optional[Tensor]=None,src_key_padding_mask:Optional[Tensor]=None,tgt_key_padding_mask:Optional[Tensor]=None,memory_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.Transformer.generate_square_subsequent_mask(self,sz:int)->Tensor
torch.nn.TransformerDecoder(self,decoder_layer,num_layers,norm=None)
torch.nn.TransformerDecoder.forward(self,tgt:Tensor,memory:Tensor,tgt_mask:Optional[Tensor]=None,memory_mask:Optional[Tensor]=None,tgt_key_padding_mask:Optional[Tensor]=None,memory_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.TransformerDecoderLayer(self,d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')
torch.nn.TransformerDecoderLayer.__setstate__(self,state)
torch.nn.TransformerDecoderLayer.forward(self,tgt:Tensor,memory:Tensor,tgt_mask:Optional[Tensor]=None,memory_mask:Optional[Tensor]=None,tgt_key_padding_mask:Optional[Tensor]=None,memory_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.TransformerEncoder(self,encoder_layer,num_layers,norm=None)
torch.nn.TransformerEncoder.forward(self,src:Tensor,mask:Optional[Tensor]=None,src_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.TransformerEncoderLayer(self,d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')
torch.nn.TransformerEncoderLayer.__setstate__(self,state)
torch.nn.TransformerEncoderLayer.forward(self,src:Tensor,src_mask:Optional[Tensor]=None,src_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.modules.transformer.Transformer(self,d_model:int=512,nhead:int=8,num_encoder_layers:int=6,num_decoder_layers:int=6,dim_feedforward:int=2048,dropout:float=0.1,activation:str='relu',custom_encoder:Optional[Any]=None,custom_decoder:Optional[Any]=None)
torch.nn.modules.transformer.Transformer.__init__(self,d_model:int=512,nhead:int=8,num_encoder_layers:int=6,num_decoder_layers:int=6,dim_feedforward:int=2048,dropout:float=0.1,activation:str='relu',custom_encoder:Optional[Any]=None,custom_decoder:Optional[Any]=None)
torch.nn.modules.transformer.Transformer._reset_parameters(self)
torch.nn.modules.transformer.Transformer.forward(self,src:Tensor,tgt:Tensor,src_mask:Optional[Tensor]=None,tgt_mask:Optional[Tensor]=None,memory_mask:Optional[Tensor]=None,src_key_padding_mask:Optional[Tensor]=None,tgt_key_padding_mask:Optional[Tensor]=None,memory_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.modules.transformer.Transformer.generate_square_subsequent_mask(self,sz:int)->Tensor
torch.nn.modules.transformer.TransformerDecoder(self,decoder_layer,num_layers,norm=None)
torch.nn.modules.transformer.TransformerDecoder.__init__(self,decoder_layer,num_layers,norm=None)
torch.nn.modules.transformer.TransformerDecoder.forward(self,tgt:Tensor,memory:Tensor,tgt_mask:Optional[Tensor]=None,memory_mask:Optional[Tensor]=None,tgt_key_padding_mask:Optional[Tensor]=None,memory_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.modules.transformer.TransformerDecoderLayer(self,d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')
torch.nn.modules.transformer.TransformerDecoderLayer.__init__(self,d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')
torch.nn.modules.transformer.TransformerDecoderLayer.__setstate__(self,state)
torch.nn.modules.transformer.TransformerDecoderLayer.forward(self,tgt:Tensor,memory:Tensor,tgt_mask:Optional[Tensor]=None,memory_mask:Optional[Tensor]=None,tgt_key_padding_mask:Optional[Tensor]=None,memory_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.modules.transformer.TransformerEncoder(self,encoder_layer,num_layers,norm=None)
torch.nn.modules.transformer.TransformerEncoder.__init__(self,encoder_layer,num_layers,norm=None)
torch.nn.modules.transformer.TransformerEncoder.forward(self,src:Tensor,mask:Optional[Tensor]=None,src_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.modules.transformer.TransformerEncoderLayer(self,d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')
torch.nn.modules.transformer.TransformerEncoderLayer.__init__(self,d_model,nhead,dim_feedforward=2048,dropout=0.1,activation='relu')
torch.nn.modules.transformer.TransformerEncoderLayer.__setstate__(self,state)
torch.nn.modules.transformer.TransformerEncoderLayer.forward(self,src:Tensor,src_mask:Optional[Tensor]=None,src_key_padding_mask:Optional[Tensor]=None)->Tensor
torch.nn.modules.transformer._get_activation_fn(activation)
torch.nn.modules.transformer._get_clones(module,N)
torch.nn.transformer._get_activation_fn(activation)
torch.nn.transformer._get_clones(module,N)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/upsampling.py----------------------------------------
A:torch.nn.modules.upsampling.self.scale_factor->tuple((float(factor) for factor in scale_factor))
torch.nn.Upsample(self,size:Optional[_size_any_t]=None,scale_factor:Optional[_ratio_any_t]=None,mode:str='nearest',align_corners:Optional[bool]=None)
torch.nn.Upsample.extra_repr(self)->str
torch.nn.Upsample.forward(self,input:Tensor)->Tensor
torch.nn.UpsamplingBilinear2d(self,size:Optional[_size_2_t]=None,scale_factor:Optional[_ratio_2_t]=None)
torch.nn.UpsamplingNearest2d(self,size:Optional[_size_2_t]=None,scale_factor:Optional[_ratio_2_t]=None)
torch.nn.modules.upsampling.Upsample(self,size:Optional[_size_any_t]=None,scale_factor:Optional[_ratio_any_t]=None,mode:str='nearest',align_corners:Optional[bool]=None)
torch.nn.modules.upsampling.Upsample.__init__(self,size:Optional[_size_any_t]=None,scale_factor:Optional[_ratio_any_t]=None,mode:str='nearest',align_corners:Optional[bool]=None)
torch.nn.modules.upsampling.Upsample.extra_repr(self)->str
torch.nn.modules.upsampling.Upsample.forward(self,input:Tensor)->Tensor
torch.nn.modules.upsampling.UpsamplingBilinear2d(self,size:Optional[_size_2_t]=None,scale_factor:Optional[_ratio_2_t]=None)
torch.nn.modules.upsampling.UpsamplingBilinear2d.__init__(self,size:Optional[_size_2_t]=None,scale_factor:Optional[_ratio_2_t]=None)
torch.nn.modules.upsampling.UpsamplingNearest2d(self,size:Optional[_size_2_t]=None,scale_factor:Optional[_ratio_2_t]=None)
torch.nn.modules.upsampling.UpsamplingNearest2d.__init__(self,size:Optional[_size_2_t]=None,scale_factor:Optional[_ratio_2_t]=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/activation.py----------------------------------------
A:torch.nn.modules.activation.self.q_proj_weight->Parameter(torch.Tensor(embed_dim, embed_dim))
A:torch.nn.modules.activation.self.k_proj_weight->Parameter(torch.Tensor(embed_dim, self.kdim))
A:torch.nn.modules.activation.self.v_proj_weight->Parameter(torch.Tensor(embed_dim, self.vdim))
A:torch.nn.modules.activation.self.in_proj_weight->Parameter(torch.empty(3 * embed_dim, embed_dim))
A:torch.nn.modules.activation.self.in_proj_bias->Parameter(torch.empty(3 * embed_dim))
A:torch.nn.modules.activation.self.out_proj->_LinearWithBias(embed_dim, embed_dim)
A:torch.nn.modules.activation.self.bias_k->Parameter(torch.empty(1, 1, embed_dim))
A:torch.nn.modules.activation.self.bias_v->Parameter(torch.empty(1, 1, embed_dim))
A:torch.nn.modules.activation.self.weight->Parameter(torch.Tensor(num_parameters).fill_(init))
torch.nn.CELU(self,alpha:float=1.0,inplace:bool=False)
torch.nn.CELU.extra_repr(self)->str
torch.nn.CELU.forward(self,input:Tensor)->Tensor
torch.nn.ELU(self,alpha:float=1.0,inplace:bool=False)
torch.nn.ELU.extra_repr(self)->str
torch.nn.ELU.forward(self,input:Tensor)->Tensor
torch.nn.GELU(Module)
torch.nn.GELU.forward(self,input:Tensor)->Tensor
torch.nn.GLU(self,dim:int=-1)
torch.nn.GLU.extra_repr(self)->str
torch.nn.GLU.forward(self,input:Tensor)->Tensor
torch.nn.Hardshrink(self,lambd:float=0.5)
torch.nn.Hardshrink.extra_repr(self)->str
torch.nn.Hardshrink.forward(self,input:Tensor)->Tensor
torch.nn.Hardsigmoid(self,inplace:bool=False)
torch.nn.Hardsigmoid.forward(self,input:Tensor)->Tensor
torch.nn.Hardswish(self,inplace:bool=False)
torch.nn.Hardswish.forward(self,input:Tensor)->Tensor
torch.nn.Hardtanh(self,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False,min_value:Optional[float]=None,max_value:Optional[float]=None)
torch.nn.Hardtanh.extra_repr(self)->str
torch.nn.Hardtanh.forward(self,input:Tensor)->Tensor
torch.nn.LeakyReLU(self,negative_slope:float=0.01,inplace:bool=False)
torch.nn.LeakyReLU.extra_repr(self)->str
torch.nn.LeakyReLU.forward(self,input:Tensor)->Tensor
torch.nn.LogSigmoid(Module)
torch.nn.LogSigmoid.forward(self,input:Tensor)->Tensor
torch.nn.LogSoftmax(self,dim:Optional[int]=None)
torch.nn.LogSoftmax.__setstate__(self,state)
torch.nn.LogSoftmax.extra_repr(self)
torch.nn.LogSoftmax.forward(self,input:Tensor)->Tensor
torch.nn.MultiheadAttention(self,embed_dim,num_heads,dropout=0.0,bias=True,add_bias_kv=False,add_zero_attn=False,kdim=None,vdim=None)
torch.nn.MultiheadAttention.__setstate__(self,state)
torch.nn.MultiheadAttention._reset_parameters(self)
torch.nn.MultiheadAttention.forward(self,query,key,value,key_padding_mask=None,need_weights=True,attn_mask=None)
torch.nn.PReLU(self,num_parameters:int=1,init:float=0.25)
torch.nn.PReLU.extra_repr(self)->str
torch.nn.PReLU.forward(self,input:Tensor)->Tensor
torch.nn.RReLU(self,lower:float=1.0/8,upper:float=1.0/3,inplace:bool=False)
torch.nn.RReLU.extra_repr(self)
torch.nn.RReLU.forward(self,input:Tensor)->Tensor
torch.nn.ReLU(self,inplace:bool=False)
torch.nn.ReLU.extra_repr(self)->str
torch.nn.ReLU.forward(self,input:Tensor)->Tensor
torch.nn.ReLU6(self,inplace:bool=False)
torch.nn.ReLU6.extra_repr(self)->str
torch.nn.SELU(self,inplace:bool=False)
torch.nn.SELU.extra_repr(self)->str
torch.nn.SELU.forward(self,input:Tensor)->Tensor
torch.nn.SiLU(self,inplace:bool=False)
torch.nn.SiLU.extra_repr(self)->str
torch.nn.SiLU.forward(self,input:Tensor)->Tensor
torch.nn.Sigmoid(Module)
torch.nn.Sigmoid.forward(self,input:Tensor)->Tensor
torch.nn.Softmax(self,dim:Optional[int]=None)
torch.nn.Softmax.__setstate__(self,state)
torch.nn.Softmax.extra_repr(self)->str
torch.nn.Softmax.forward(self,input:Tensor)->Tensor
torch.nn.Softmax2d(Module)
torch.nn.Softmax2d.forward(self,input:Tensor)->Tensor
torch.nn.Softmin(self,dim:Optional[int]=None)
torch.nn.Softmin.__setstate__(self,state)
torch.nn.Softmin.extra_repr(self)
torch.nn.Softmin.forward(self,input:Tensor)->Tensor
torch.nn.Softplus(self,beta:int=1,threshold:int=20)
torch.nn.Softplus.extra_repr(self)->str
torch.nn.Softplus.forward(self,input:Tensor)->Tensor
torch.nn.Softshrink(self,lambd:float=0.5)
torch.nn.Softshrink.extra_repr(self)->str
torch.nn.Softshrink.forward(self,input:Tensor)->Tensor
torch.nn.Softsign(Module)
torch.nn.Softsign.forward(self,input:Tensor)->Tensor
torch.nn.Tanh(Module)
torch.nn.Tanh.forward(self,input:Tensor)->Tensor
torch.nn.Tanhshrink(Module)
torch.nn.Tanhshrink.forward(self,input:Tensor)->Tensor
torch.nn.Threshold(self,threshold:float,value:float,inplace:bool=False)
torch.nn.Threshold.extra_repr(self)
torch.nn.Threshold.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.CELU(self,alpha:float=1.0,inplace:bool=False)
torch.nn.modules.activation.CELU.__init__(self,alpha:float=1.0,inplace:bool=False)
torch.nn.modules.activation.CELU.extra_repr(self)->str
torch.nn.modules.activation.CELU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.ELU(self,alpha:float=1.0,inplace:bool=False)
torch.nn.modules.activation.ELU.__init__(self,alpha:float=1.0,inplace:bool=False)
torch.nn.modules.activation.ELU.extra_repr(self)->str
torch.nn.modules.activation.ELU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.GELU(Module)
torch.nn.modules.activation.GELU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.GLU(self,dim:int=-1)
torch.nn.modules.activation.GLU.__init__(self,dim:int=-1)
torch.nn.modules.activation.GLU.extra_repr(self)->str
torch.nn.modules.activation.GLU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Hardshrink(self,lambd:float=0.5)
torch.nn.modules.activation.Hardshrink.__init__(self,lambd:float=0.5)
torch.nn.modules.activation.Hardshrink.extra_repr(self)->str
torch.nn.modules.activation.Hardshrink.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Hardsigmoid(self,inplace:bool=False)
torch.nn.modules.activation.Hardsigmoid.__init__(self,inplace:bool=False)
torch.nn.modules.activation.Hardsigmoid.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Hardswish(self,inplace:bool=False)
torch.nn.modules.activation.Hardswish.__init__(self,inplace:bool=False)
torch.nn.modules.activation.Hardswish.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Hardtanh(self,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False,min_value:Optional[float]=None,max_value:Optional[float]=None)
torch.nn.modules.activation.Hardtanh.__init__(self,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False,min_value:Optional[float]=None,max_value:Optional[float]=None)
torch.nn.modules.activation.Hardtanh.extra_repr(self)->str
torch.nn.modules.activation.Hardtanh.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.LeakyReLU(self,negative_slope:float=0.01,inplace:bool=False)
torch.nn.modules.activation.LeakyReLU.__init__(self,negative_slope:float=0.01,inplace:bool=False)
torch.nn.modules.activation.LeakyReLU.extra_repr(self)->str
torch.nn.modules.activation.LeakyReLU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.LogSigmoid(Module)
torch.nn.modules.activation.LogSigmoid.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.LogSoftmax(self,dim:Optional[int]=None)
torch.nn.modules.activation.LogSoftmax.__init__(self,dim:Optional[int]=None)
torch.nn.modules.activation.LogSoftmax.__setstate__(self,state)
torch.nn.modules.activation.LogSoftmax.extra_repr(self)
torch.nn.modules.activation.LogSoftmax.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.MultiheadAttention(self,embed_dim,num_heads,dropout=0.0,bias=True,add_bias_kv=False,add_zero_attn=False,kdim=None,vdim=None)
torch.nn.modules.activation.MultiheadAttention.__init__(self,embed_dim,num_heads,dropout=0.0,bias=True,add_bias_kv=False,add_zero_attn=False,kdim=None,vdim=None)
torch.nn.modules.activation.MultiheadAttention.__setstate__(self,state)
torch.nn.modules.activation.MultiheadAttention._reset_parameters(self)
torch.nn.modules.activation.MultiheadAttention.forward(self,query,key,value,key_padding_mask=None,need_weights=True,attn_mask=None)
torch.nn.modules.activation.PReLU(self,num_parameters:int=1,init:float=0.25)
torch.nn.modules.activation.PReLU.__init__(self,num_parameters:int=1,init:float=0.25)
torch.nn.modules.activation.PReLU.extra_repr(self)->str
torch.nn.modules.activation.PReLU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.RReLU(self,lower:float=1.0/8,upper:float=1.0/3,inplace:bool=False)
torch.nn.modules.activation.RReLU.__init__(self,lower:float=1.0/8,upper:float=1.0/3,inplace:bool=False)
torch.nn.modules.activation.RReLU.extra_repr(self)
torch.nn.modules.activation.RReLU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.ReLU(self,inplace:bool=False)
torch.nn.modules.activation.ReLU.__init__(self,inplace:bool=False)
torch.nn.modules.activation.ReLU.extra_repr(self)->str
torch.nn.modules.activation.ReLU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.ReLU6(self,inplace:bool=False)
torch.nn.modules.activation.ReLU6.__init__(self,inplace:bool=False)
torch.nn.modules.activation.ReLU6.extra_repr(self)->str
torch.nn.modules.activation.SELU(self,inplace:bool=False)
torch.nn.modules.activation.SELU.__init__(self,inplace:bool=False)
torch.nn.modules.activation.SELU.extra_repr(self)->str
torch.nn.modules.activation.SELU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.SiLU(self,inplace:bool=False)
torch.nn.modules.activation.SiLU.__init__(self,inplace:bool=False)
torch.nn.modules.activation.SiLU.extra_repr(self)->str
torch.nn.modules.activation.SiLU.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Sigmoid(Module)
torch.nn.modules.activation.Sigmoid.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Softmax(self,dim:Optional[int]=None)
torch.nn.modules.activation.Softmax.__init__(self,dim:Optional[int]=None)
torch.nn.modules.activation.Softmax.__setstate__(self,state)
torch.nn.modules.activation.Softmax.extra_repr(self)->str
torch.nn.modules.activation.Softmax.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Softmax2d(Module)
torch.nn.modules.activation.Softmax2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Softmin(self,dim:Optional[int]=None)
torch.nn.modules.activation.Softmin.__init__(self,dim:Optional[int]=None)
torch.nn.modules.activation.Softmin.__setstate__(self,state)
torch.nn.modules.activation.Softmin.extra_repr(self)
torch.nn.modules.activation.Softmin.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Softplus(self,beta:int=1,threshold:int=20)
torch.nn.modules.activation.Softplus.__init__(self,beta:int=1,threshold:int=20)
torch.nn.modules.activation.Softplus.extra_repr(self)->str
torch.nn.modules.activation.Softplus.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Softshrink(self,lambd:float=0.5)
torch.nn.modules.activation.Softshrink.__init__(self,lambd:float=0.5)
torch.nn.modules.activation.Softshrink.extra_repr(self)->str
torch.nn.modules.activation.Softshrink.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Softsign(Module)
torch.nn.modules.activation.Softsign.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Tanh(Module)
torch.nn.modules.activation.Tanh.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Tanhshrink(Module)
torch.nn.modules.activation.Tanhshrink.forward(self,input:Tensor)->Tensor
torch.nn.modules.activation.Threshold(self,threshold:float,value:float,inplace:bool=False)
torch.nn.modules.activation.Threshold.__init__(self,threshold:float,value:float,inplace:bool=False)
torch.nn.modules.activation.Threshold.extra_repr(self)
torch.nn.modules.activation.Threshold.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/distance.py----------------------------------------
torch.nn.CosineSimilarity(self,dim:int=1,eps:float=1e-08)
torch.nn.CosineSimilarity.forward(self,x1:Tensor,x2:Tensor)->Tensor
torch.nn.PairwiseDistance(self,p:float=2.0,eps:float=1e-06,keepdim:bool=False)
torch.nn.PairwiseDistance.forward(self,x1:Tensor,x2:Tensor)->Tensor
torch.nn.modules.distance.CosineSimilarity(self,dim:int=1,eps:float=1e-08)
torch.nn.modules.distance.CosineSimilarity.__init__(self,dim:int=1,eps:float=1e-08)
torch.nn.modules.distance.CosineSimilarity.forward(self,x1:Tensor,x2:Tensor)->Tensor
torch.nn.modules.distance.PairwiseDistance(self,p:float=2.0,eps:float=1e-06,keepdim:bool=False)
torch.nn.modules.distance.PairwiseDistance.__init__(self,p:float=2.0,eps:float=1e-06,keepdim:bool=False)
torch.nn.modules.distance.PairwiseDistance.forward(self,x1:Tensor,x2:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/module.py----------------------------------------
A:torch.nn.modules.module.T->TypeVar('T', bound='Module')
A:torch.nn.modules.module.s->'\n'.join(s)
A:torch.nn.modules.module.first->'\n'.join(s).pop(0)
A:torch.nn.modules.module._global_backward_hooks->OrderedDict()
A:torch.nn.modules.module._global_forward_pre_hooks->OrderedDict()
A:torch.nn.modules.module._global_forward_hooks->OrderedDict()
A:torch.nn.modules.module.handle->torch.utils.hooks.RemovableHandle(self._load_state_dict_pre_hooks)
A:torch.nn.modules.module.self._parameters->OrderedDict()
A:torch.nn.modules.module.self._buffers->OrderedDict()
A:torch.nn.modules.module.self._non_persistent_buffers_set->set()
A:torch.nn.modules.module.self._backward_hooks->OrderedDict()
A:torch.nn.modules.module.self._forward_hooks->OrderedDict()
A:torch.nn.modules.module.self._forward_pre_hooks->OrderedDict()
A:torch.nn.modules.module.self._state_dict_hooks->OrderedDict()
A:torch.nn.modules.module.self._load_state_dict_pre_hooks->OrderedDict()
A:torch.nn.modules.module.self._modules->OrderedDict()
A:torch.nn.modules.module.param_applied->fn(param)
A:torch.nn.modules.module.should_use_set_data->compute_should_use_set_data(param.grad, grad_applied)
A:torch.nn.modules.module.self._parameters[key]->Parameter(param_applied, param.requires_grad)
A:torch.nn.modules.module.grad_applied->fn(param.grad)
A:torch.nn.modules.module.self._parameters[key].grad->fn(param.grad).requires_grad_(param.grad.requires_grad)
A:torch.nn.modules.module.self._buffers[key]->fn(buf)
A:torch.nn.modules.module.(device, dtype, non_blocking, convert_to_format)->torch._C._nn._parse_to(*args, **kwargs)
A:torch.nn.modules.module.tracing_state->torch._C._get_tracing_state()
A:torch.nn.modules.module.cur_scope_name->torch._C._get_tracing_state().current_scope()
A:torch.nn.modules.module.result->self.forward(*input, **kwargs)
A:torch.nn.modules.module.hook_result->hook(self, destination, prefix, local_metadata)
A:torch.nn.modules.module.var->next((v for v in var.values() if isinstance(v, torch.Tensor)))
A:torch.nn.modules.module.wrapper->functools.partial(hook, self)
A:torch.nn.modules.module.params->self.__dict__.get('_parameters')
A:torch.nn.modules.module.modules->list(self._modules.keys())
A:torch.nn.modules.module.buffers->list(self._buffers.keys())
A:torch.nn.modules.module.T_destination->TypeVar('T_destination', bound=Mapping[str, Tensor])
A:torch.nn.modules.module.destination->OrderedDict()
A:torch.nn.modules.module.destination._metadata->OrderedDict()
A:torch.nn.modules.module.destination._metadata[prefix[:-1]]local_metadata->dict(version=self._version)
A:torch.nn.modules.module.local_name_params->itertools.chain(self._parameters.items(), persistent_buffers.items())
A:torch.nn.modules.module.metadata->getattr(state_dict, '_metadata', None)
A:torch.nn.modules.module.state_dict->state_dict.copy().copy()
A:torch.nn.modules.module.memo->set()
A:torch.nn.modules.module.members->get_members_fn(module)
A:torch.nn.modules.module.gen->self._named_members(lambda module: module._buffers.items(), prefix=prefix, recurse=recurse)
A:torch.nn.modules.module.extra_repr->self.extra_repr()
A:torch.nn.modules.module.extra_lines->self.extra_repr().split('\n')
A:torch.nn.modules.module.mod_str->_addindent(mod_str, 2)
A:torch.nn.modules.module.module_attrs->dir(self.__class__)
A:torch.nn.modules.module.attrs->list(self.__dict__.keys())
A:torch.nn.modules.module.parameters->list(self._parameters.keys())
A:torch.nn.modules.module.replica->self.__new__(type(self))
A:torch.nn.modules.module.replica.__dict__->self.__dict__.copy()
A:torch.nn.modules.module.replica._parameters->OrderedDict()
A:torch.nn.modules.module.replica._buffers->self.__new__(type(self))._buffers.copy()
A:torch.nn.modules.module.replica._modules->self.__new__(type(self))._modules.copy()
torch.nn.Module(self)
torch.nn.Module.__delattr__(self,name)
torch.nn.Module.__dir__(self)
torch.nn.Module.__getattr__(self,name:str)->Union[Tensor, 'Module']
torch.nn.Module.__repr__(self)
torch.nn.Module.__setattr__(self,name:str,value:Union[Tensor,'Module'])->None
torch.nn.Module.__setstate__(self,state)
torch.nn.Module._apply(self,fn)
torch.nn.Module._call_impl(self,*input,**kwargs)
torch.nn.Module._get_name(self)
torch.nn.Module._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.Module._named_members(self,get_members_fn,prefix='',recurse=True)
torch.nn.Module._register_load_state_dict_pre_hook(self,hook)
torch.nn.Module._register_state_dict_hook(self,hook)
torch.nn.Module._replicate_for_data_parallel(self)
torch.nn.Module._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.Module._slow_forward(self,*input,**kwargs)
torch.nn.Module.add_module(self,name:str,module:Optional['Module'])->None
torch.nn.Module.apply(self:T,fn:Callable[['Module'],None])->T
torch.nn.Module.bfloat16(self:T)->T
torch.nn.Module.buffers(self,recurse:bool=True)->Iterator[Tensor]
torch.nn.Module.children(self)->Iterator['Module']
torch.nn.Module.cpu(self:T)->T
torch.nn.Module.cuda(self:T,device:Optional[Union[int,device]]=None)->T
torch.nn.Module.double(self:T)->T
torch.nn.Module.eval(self:T)->T
torch.nn.Module.extra_repr(self)->str
torch.nn.Module.float(self:T)->T
torch.nn.Module.half(self:T)->T
torch.nn.Module.load_state_dict(self,state_dict:Union[Dict[str,Tensor],Dict[str,Tensor]],strict:bool=True)
torch.nn.Module.modules(self)->Iterator['Module']
torch.nn.Module.named_buffers(self,prefix:str='',recurse:bool=True)->Iterator[Tuple[str, Tensor]]
torch.nn.Module.named_children(self)->Iterator[Tuple[str, 'Module']]
torch.nn.Module.named_modules(self,memo:Optional[Set['Module']]=None,prefix:str='')
torch.nn.Module.named_parameters(self,prefix:str='',recurse:bool=True)->Iterator[Tuple[str, Tensor]]
torch.nn.Module.parameters(self,recurse:bool=True)->Iterator[Parameter]
torch.nn.Module.register_backward_hook(self,hook:Callable[['Module',_grad_t,_grad_t],Union[None,Tensor]])->RemovableHandle
torch.nn.Module.register_buffer(self,name:str,tensor:Optional[Tensor],persistent:bool=True)->None
torch.nn.Module.register_forward_hook(self,hook:Callable[...,None])->RemovableHandle
torch.nn.Module.register_forward_pre_hook(self,hook:Callable[...,None])->RemovableHandle
torch.nn.Module.register_parameter(self,name:str,param:Optional[Parameter])->None
torch.nn.Module.requires_grad_(self:T,requires_grad:bool=True)->T
torch.nn.Module.share_memory(self:T)->T
torch.nn.Module.state_dict(self,destination=None,prefix='',keep_vars=False)
torch.nn.Module.to(self,*args,**kwargs)
torch.nn.Module.train(self:T,mode:bool=True)->T
torch.nn.Module.type(self:T,dst_type:Union[dtype,str])->T
torch.nn.Module.zero_grad(self,set_to_none:bool=False)->None
torch.nn.ModuleAttributeError(AttributeError)
torch.nn.module._IncompatibleKeys(namedtuple('IncompatibleKeys',['missing_keys','unexpected_keys']))
torch.nn.module._IncompatibleKeys.__repr__(self)
torch.nn.module._addindent(s_,numSpaces)
torch.nn.module._forward_unimplemented(self,*input:Any)->None
torch.nn.module.register_module_backward_hook(hook:Callable[['Module',_grad_t,_grad_t],Union[None,Tensor]])->RemovableHandle
torch.nn.module.register_module_forward_hook(hook:Callable[...,None])->RemovableHandle
torch.nn.module.register_module_forward_pre_hook(hook:Callable[...,None])->RemovableHandle
torch.nn.modules.module.Module(self)
torch.nn.modules.module.Module.__delattr__(self,name)
torch.nn.modules.module.Module.__dir__(self)
torch.nn.modules.module.Module.__getattr__(self,name:str)->Union[Tensor, 'Module']
torch.nn.modules.module.Module.__init__(self)
torch.nn.modules.module.Module.__repr__(self)
torch.nn.modules.module.Module.__setattr__(self,name:str,value:Union[Tensor,'Module'])->None
torch.nn.modules.module.Module.__setstate__(self,state)
torch.nn.modules.module.Module._apply(self,fn)
torch.nn.modules.module.Module._call_impl(self,*input,**kwargs)
torch.nn.modules.module.Module._get_name(self)
torch.nn.modules.module.Module._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.modules.module.Module._named_members(self,get_members_fn,prefix='',recurse=True)
torch.nn.modules.module.Module._register_load_state_dict_pre_hook(self,hook)
torch.nn.modules.module.Module._register_state_dict_hook(self,hook)
torch.nn.modules.module.Module._replicate_for_data_parallel(self)
torch.nn.modules.module.Module._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.modules.module.Module._slow_forward(self,*input,**kwargs)
torch.nn.modules.module.Module.add_module(self,name:str,module:Optional['Module'])->None
torch.nn.modules.module.Module.apply(self:T,fn:Callable[['Module'],None])->T
torch.nn.modules.module.Module.bfloat16(self:T)->T
torch.nn.modules.module.Module.buffers(self,recurse:bool=True)->Iterator[Tensor]
torch.nn.modules.module.Module.children(self)->Iterator['Module']
torch.nn.modules.module.Module.cpu(self:T)->T
torch.nn.modules.module.Module.cuda(self:T,device:Optional[Union[int,device]]=None)->T
torch.nn.modules.module.Module.double(self:T)->T
torch.nn.modules.module.Module.eval(self:T)->T
torch.nn.modules.module.Module.extra_repr(self)->str
torch.nn.modules.module.Module.float(self:T)->T
torch.nn.modules.module.Module.half(self:T)->T
torch.nn.modules.module.Module.load_state_dict(self,state_dict:Union[Dict[str,Tensor],Dict[str,Tensor]],strict:bool=True)
torch.nn.modules.module.Module.modules(self)->Iterator['Module']
torch.nn.modules.module.Module.named_buffers(self,prefix:str='',recurse:bool=True)->Iterator[Tuple[str, Tensor]]
torch.nn.modules.module.Module.named_children(self)->Iterator[Tuple[str, 'Module']]
torch.nn.modules.module.Module.named_modules(self,memo:Optional[Set['Module']]=None,prefix:str='')
torch.nn.modules.module.Module.named_parameters(self,prefix:str='',recurse:bool=True)->Iterator[Tuple[str, Tensor]]
torch.nn.modules.module.Module.parameters(self,recurse:bool=True)->Iterator[Parameter]
torch.nn.modules.module.Module.register_backward_hook(self,hook:Callable[['Module',_grad_t,_grad_t],Union[None,Tensor]])->RemovableHandle
torch.nn.modules.module.Module.register_buffer(self,name:str,tensor:Optional[Tensor],persistent:bool=True)->None
torch.nn.modules.module.Module.register_forward_hook(self,hook:Callable[...,None])->RemovableHandle
torch.nn.modules.module.Module.register_forward_pre_hook(self,hook:Callable[...,None])->RemovableHandle
torch.nn.modules.module.Module.register_parameter(self,name:str,param:Optional[Parameter])->None
torch.nn.modules.module.Module.requires_grad_(self:T,requires_grad:bool=True)->T
torch.nn.modules.module.Module.share_memory(self:T)->T
torch.nn.modules.module.Module.state_dict(self,destination=None,prefix='',keep_vars=False)
torch.nn.modules.module.Module.to(self,*args,**kwargs)
torch.nn.modules.module.Module.train(self:T,mode:bool=True)->T
torch.nn.modules.module.Module.type(self:T,dst_type:Union[dtype,str])->T
torch.nn.modules.module.Module.zero_grad(self,set_to_none:bool=False)->None
torch.nn.modules.module.ModuleAttributeError(AttributeError)
torch.nn.modules.module._IncompatibleKeys(namedtuple('IncompatibleKeys',['missing_keys','unexpected_keys']))
torch.nn.modules.module._IncompatibleKeys.__repr__(self)
torch.nn.modules.module._addindent(s_,numSpaces)
torch.nn.modules.module._forward_unimplemented(self,*input:Any)->None
torch.nn.modules.module.register_module_backward_hook(hook:Callable[['Module',_grad_t,_grad_t],Union[None,Tensor]])->RemovableHandle
torch.nn.modules.module.register_module_forward_hook(hook:Callable[...,None])->RemovableHandle
torch.nn.modules.module.register_module_forward_pre_hook(hook:Callable[...,None])->RemovableHandle


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/sparse.py----------------------------------------
A:torch.nn.modules.sparse.self.weight->Parameter(_weight)
A:torch.nn.modules.sparse.embedding->cls(num_embeddings=rows, embedding_dim=cols, _weight=embeddings, padding_idx=padding_idx, max_norm=max_norm, norm_type=norm_type, scale_grad_by_freq=scale_grad_by_freq, sparse=sparse)
A:torch.nn.modules.sparse.embeddingbag->cls(num_embeddings=rows, embedding_dim=cols, _weight=embeddings, max_norm=max_norm, norm_type=norm_type, scale_grad_by_freq=scale_grad_by_freq, mode=mode, sparse=sparse, include_last_offset=include_last_offset)
torch.nn.Embedding(self,num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[Tensor]=None)
torch.nn.Embedding.extra_repr(self)->str
torch.nn.Embedding.forward(self,input:Tensor)->Tensor
torch.nn.Embedding.from_pretrained(cls,embeddings,freeze=True,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)
torch.nn.Embedding.reset_parameters(self)->None
torch.nn.EmbeddingBag(self,num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,_weight:Optional[Tensor]=None,include_last_offset:bool=False)
torch.nn.EmbeddingBag.extra_repr(self)->str
torch.nn.EmbeddingBag.forward(self,input:Tensor,offsets:Optional[Tensor]=None,per_sample_weights:Optional[Tensor]=None)->Tensor
torch.nn.EmbeddingBag.from_pretrained(cls,embeddings:Tensor,freeze:bool=True,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,include_last_offset:bool=False)->'EmbeddingBag'
torch.nn.EmbeddingBag.reset_parameters(self)->None
torch.nn.modules.sparse.Embedding(self,num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[Tensor]=None)
torch.nn.modules.sparse.Embedding.__init__(self,num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[Tensor]=None)
torch.nn.modules.sparse.Embedding.extra_repr(self)->str
torch.nn.modules.sparse.Embedding.forward(self,input:Tensor)->Tensor
torch.nn.modules.sparse.Embedding.from_pretrained(cls,embeddings,freeze=True,padding_idx=None,max_norm=None,norm_type=2.0,scale_grad_by_freq=False,sparse=False)
torch.nn.modules.sparse.Embedding.reset_parameters(self)->None
torch.nn.modules.sparse.EmbeddingBag(self,num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,_weight:Optional[Tensor]=None,include_last_offset:bool=False)
torch.nn.modules.sparse.EmbeddingBag.__init__(self,num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,_weight:Optional[Tensor]=None,include_last_offset:bool=False)
torch.nn.modules.sparse.EmbeddingBag.extra_repr(self)->str
torch.nn.modules.sparse.EmbeddingBag.forward(self,input:Tensor,offsets:Optional[Tensor]=None,per_sample_weights:Optional[Tensor]=None)->Tensor
torch.nn.modules.sparse.EmbeddingBag.from_pretrained(cls,embeddings:Tensor,freeze:bool=True,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='mean',sparse:bool=False,include_last_offset:bool=False)->'EmbeddingBag'
torch.nn.modules.sparse.EmbeddingBag.reset_parameters(self)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/utils.py----------------------------------------
A:torch.nn.modules.utils._single->_ntuple(1)
A:torch.nn.modules.utils._pair->_ntuple(2)
A:torch.nn.modules.utils._triple->_ntuple(3)
A:torch.nn.modules.utils._quadruple->_ntuple(4)
torch.nn.modules.utils._list_with_default(out_size,defaults)
torch.nn.modules.utils._ntuple(n)
torch.nn.modules.utils._reverse_repeat_tuple(t,n)
torch.nn.utils._list_with_default(out_size,defaults)
torch.nn.utils._ntuple(n)
torch.nn.utils._reverse_repeat_tuple(t,n)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/linear.py----------------------------------------
A:torch.nn.modules.linear.self.weight->Parameter(torch.Tensor(out_features, in1_features, in2_features))
A:torch.nn.modules.linear.self.bias->Parameter(torch.Tensor(out_features))
A:torch.nn.modules.linear.(fan_in, _)->init._calculate_fan_in_and_fan_out(self.weight)
torch.nn.Bilinear(self,in1_features:int,in2_features:int,out_features:int,bias:bool=True)
torch.nn.Bilinear.extra_repr(self)->str
torch.nn.Bilinear.forward(self,input1:Tensor,input2:Tensor)->Tensor
torch.nn.Bilinear.reset_parameters(self)->None
torch.nn.Identity(self,*args,**kwargs)
torch.nn.Identity.forward(self,input:Tensor)->Tensor
torch.nn.Linear(self,in_features:int,out_features:int,bias:bool=True)
torch.nn.Linear.extra_repr(self)->str
torch.nn.Linear.forward(self,input:Tensor)->Tensor
torch.nn.Linear.reset_parameters(self)->None
torch.nn.linear._LinearWithBias(self,in_features:int,out_features:int)
torch.nn.modules.linear.Bilinear(self,in1_features:int,in2_features:int,out_features:int,bias:bool=True)
torch.nn.modules.linear.Bilinear.__init__(self,in1_features:int,in2_features:int,out_features:int,bias:bool=True)
torch.nn.modules.linear.Bilinear.extra_repr(self)->str
torch.nn.modules.linear.Bilinear.forward(self,input1:Tensor,input2:Tensor)->Tensor
torch.nn.modules.linear.Bilinear.reset_parameters(self)->None
torch.nn.modules.linear.Identity(self,*args,**kwargs)
torch.nn.modules.linear.Identity.__init__(self,*args,**kwargs)
torch.nn.modules.linear.Identity.forward(self,input:Tensor)->Tensor
torch.nn.modules.linear.Linear(self,in_features:int,out_features:int,bias:bool=True)
torch.nn.modules.linear.Linear.__init__(self,in_features:int,out_features:int,bias:bool=True)
torch.nn.modules.linear.Linear.extra_repr(self)->str
torch.nn.modules.linear.Linear.forward(self,input:Tensor)->Tensor
torch.nn.modules.linear.Linear.reset_parameters(self)->None
torch.nn.modules.linear._LinearWithBias(self,in_features:int,out_features:int)
torch.nn.modules.linear._LinearWithBias.__init__(self,in_features:int,out_features:int)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/pixelshuffle.py----------------------------------------
torch.nn.PixelShuffle(self,upscale_factor:int)
torch.nn.PixelShuffle.extra_repr(self)->str
torch.nn.PixelShuffle.forward(self,input:Tensor)->Tensor
torch.nn.modules.pixelshuffle.PixelShuffle(self,upscale_factor:int)
torch.nn.modules.pixelshuffle.PixelShuffle.__init__(self,upscale_factor:int)
torch.nn.modules.pixelshuffle.PixelShuffle.extra_repr(self)->str
torch.nn.modules.pixelshuffle.PixelShuffle.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/adaptive.py----------------------------------------
A:torch.nn.modules.adaptive._ASMoutput->namedtuple('ASMoutput', ['output', 'loss'])
A:torch.nn.modules.adaptive.cutoffs->list(cutoffs)
A:torch.nn.modules.adaptive.self.head->Linear(self.in_features, self.head_size, bias=self.head_bias)
A:torch.nn.modules.adaptive.self.tail->ModuleList()
A:torch.nn.modules.adaptive.hsz->int(self.in_features // self.div_value ** (i + 1))
A:torch.nn.modules.adaptive.projection->Sequential(Linear(self.in_features, hsz, bias=False), Linear(hsz, osz, bias=False))
A:torch.nn.modules.adaptive.batch_size->target.size(0)
A:torch.nn.modules.adaptive.output->torch.argmax(head_output, dim=1)
A:torch.nn.modules.adaptive.gather_inds->target.new_empty(batch_size)
A:torch.nn.modules.adaptive.row_indices->target_mask.nonzero().squeeze()
A:torch.nn.modules.adaptive.input_subset->input.index_select(0, row_indices)
A:torch.nn.modules.adaptive.cluster_output->self.tail[i](input)
A:torch.nn.modules.adaptive.cluster_logprob->log_softmax(cluster_output, dim=1)
A:torch.nn.modules.adaptive.local_logprob->log_softmax(cluster_output, dim=1).gather(1, relative_target.unsqueeze(1))
A:torch.nn.modules.adaptive.head_output->self.head(input)
A:torch.nn.modules.adaptive.head_logprob->log_softmax(head_output, dim=1)
A:torch.nn.modules.adaptive.loss->(-output).mean()
A:torch.nn.modules.adaptive.out->input.new_empty((head_output.size(0), self.n_classes))
A:torch.nn.modules.adaptive.log_prob->self._get_full_log_prob(input[not_in_shortlist], head_output[not_in_shortlist])
A:torch.nn.modules.adaptive.output[not_in_shortlist]->torch.argmax(log_prob, dim=1)
torch.nn.AdaptiveLogSoftmaxWithLoss(self,in_features:int,n_classes:int,cutoffs:Sequence[int],div_value:float=4.0,head_bias:bool=False)
torch.nn.AdaptiveLogSoftmaxWithLoss._get_full_log_prob(self,input,head_output)
torch.nn.AdaptiveLogSoftmaxWithLoss.forward(self,input:Tensor,target:Tensor)->_ASMoutput
torch.nn.AdaptiveLogSoftmaxWithLoss.log_prob(self,input:Tensor)->Tensor
torch.nn.AdaptiveLogSoftmaxWithLoss.predict(self,input:Tensor)->Tensor
torch.nn.AdaptiveLogSoftmaxWithLoss.reset_parameters(self)->None
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss(self,in_features:int,n_classes:int,cutoffs:Sequence[int],div_value:float=4.0,head_bias:bool=False)
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss.__init__(self,in_features:int,n_classes:int,cutoffs:Sequence[int],div_value:float=4.0,head_bias:bool=False)
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss._get_full_log_prob(self,input,head_output)
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss.forward(self,input:Tensor,target:Tensor)->_ASMoutput
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss.log_prob(self,input:Tensor)->Tensor
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss.predict(self,input:Tensor)->Tensor
torch.nn.modules.adaptive.AdaptiveLogSoftmaxWithLoss.reset_parameters(self)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/batchnorm.py----------------------------------------
A:torch.nn.modules.batchnorm.self.weight->Parameter(torch.Tensor(num_features))
A:torch.nn.modules.batchnorm.self.bias->Parameter(torch.Tensor(num_features))
A:torch.nn.modules.batchnorm.version->local_metadata.get('version', None)
A:torch.nn.modules.batchnorm.state_dict[num_batches_tracked_key]->torch.tensor(0, dtype=torch.long)
A:torch.nn.modules.batchnorm.world_size->torch.distributed.get_world_size(process_group)
A:torch.nn.modules.batchnorm.module_output->torch.nn.SyncBatchNorm(module.num_features, module.eps, module.momentum, module.affine, module.track_running_stats, process_group)
torch.nn.BatchNorm1d(_BatchNorm)
torch.nn.BatchNorm1d._check_input_dim(self,input)
torch.nn.BatchNorm2d(_BatchNorm)
torch.nn.BatchNorm2d._check_input_dim(self,input)
torch.nn.BatchNorm3d(_BatchNorm)
torch.nn.BatchNorm3d._check_input_dim(self,input)
torch.nn.SyncBatchNorm(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True,process_group:Optional[Any]=None)
torch.nn.SyncBatchNorm._check_input_dim(self,input)
torch.nn.SyncBatchNorm._specify_ddp_gpu_num(self,gpu_size)
torch.nn.SyncBatchNorm.convert_sync_batchnorm(cls,module,process_group=None)
torch.nn.SyncBatchNorm.forward(self,input:Tensor)->Tensor
torch.nn.batchnorm._BatchNorm(self,num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)
torch.nn.batchnorm._BatchNorm.forward(self,input:Tensor)->Tensor
torch.nn.batchnorm._NormBase(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True)
torch.nn.batchnorm._NormBase._check_input_dim(self,input)
torch.nn.batchnorm._NormBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.batchnorm._NormBase.extra_repr(self)
torch.nn.batchnorm._NormBase.reset_parameters(self)->None
torch.nn.batchnorm._NormBase.reset_running_stats(self)->None
torch.nn.modules.batchnorm.BatchNorm1d(_BatchNorm)
torch.nn.modules.batchnorm.BatchNorm1d._check_input_dim(self,input)
torch.nn.modules.batchnorm.BatchNorm2d(_BatchNorm)
torch.nn.modules.batchnorm.BatchNorm2d._check_input_dim(self,input)
torch.nn.modules.batchnorm.BatchNorm3d(_BatchNorm)
torch.nn.modules.batchnorm.BatchNorm3d._check_input_dim(self,input)
torch.nn.modules.batchnorm.SyncBatchNorm(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True,process_group:Optional[Any]=None)
torch.nn.modules.batchnorm.SyncBatchNorm.__init__(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True,process_group:Optional[Any]=None)
torch.nn.modules.batchnorm.SyncBatchNorm._check_input_dim(self,input)
torch.nn.modules.batchnorm.SyncBatchNorm._specify_ddp_gpu_num(self,gpu_size)
torch.nn.modules.batchnorm.SyncBatchNorm.convert_sync_batchnorm(cls,module,process_group=None)
torch.nn.modules.batchnorm.SyncBatchNorm.forward(self,input:Tensor)->Tensor
torch.nn.modules.batchnorm._BatchNorm(self,num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)
torch.nn.modules.batchnorm._BatchNorm.__init__(self,num_features,eps=1e-05,momentum=0.1,affine=True,track_running_stats=True)
torch.nn.modules.batchnorm._BatchNorm.forward(self,input:Tensor)->Tensor
torch.nn.modules.batchnorm._NormBase(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True)
torch.nn.modules.batchnorm._NormBase.__init__(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=True,track_running_stats:bool=True)
torch.nn.modules.batchnorm._NormBase._check_input_dim(self,input)
torch.nn.modules.batchnorm._NormBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.modules.batchnorm._NormBase.extra_repr(self)
torch.nn.modules.batchnorm._NormBase.reset_parameters(self)->None
torch.nn.modules.batchnorm._NormBase.reset_running_stats(self)->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/padding.py----------------------------------------
A:torch.nn.modules.padding.self.padding->_ntuple(6)(padding)
torch.nn.ConstantPad1d(self,padding:_size_2_t,value:float)
torch.nn.ConstantPad2d(self,padding:_size_4_t,value:float)
torch.nn.ConstantPad3d(self,padding:_size_6_t,value:float)
torch.nn.ReflectionPad1d(self,padding:_size_2_t)
torch.nn.ReflectionPad2d(self,padding:_size_4_t)
torch.nn.ReplicationPad1d(self,padding:_size_2_t)
torch.nn.ReplicationPad2d(self,padding:_size_4_t)
torch.nn.ReplicationPad3d(self,padding:_size_6_t)
torch.nn.ZeroPad2d(self,padding:_size_4_t)
torch.nn.modules.padding.ConstantPad1d(self,padding:_size_2_t,value:float)
torch.nn.modules.padding.ConstantPad1d.__init__(self,padding:_size_2_t,value:float)
torch.nn.modules.padding.ConstantPad2d(self,padding:_size_4_t,value:float)
torch.nn.modules.padding.ConstantPad2d.__init__(self,padding:_size_4_t,value:float)
torch.nn.modules.padding.ConstantPad3d(self,padding:_size_6_t,value:float)
torch.nn.modules.padding.ConstantPad3d.__init__(self,padding:_size_6_t,value:float)
torch.nn.modules.padding.ReflectionPad1d(self,padding:_size_2_t)
torch.nn.modules.padding.ReflectionPad1d.__init__(self,padding:_size_2_t)
torch.nn.modules.padding.ReflectionPad2d(self,padding:_size_4_t)
torch.nn.modules.padding.ReflectionPad2d.__init__(self,padding:_size_4_t)
torch.nn.modules.padding.ReplicationPad1d(self,padding:_size_2_t)
torch.nn.modules.padding.ReplicationPad1d.__init__(self,padding:_size_2_t)
torch.nn.modules.padding.ReplicationPad2d(self,padding:_size_4_t)
torch.nn.modules.padding.ReplicationPad2d.__init__(self,padding:_size_4_t)
torch.nn.modules.padding.ReplicationPad3d(self,padding:_size_6_t)
torch.nn.modules.padding.ReplicationPad3d.__init__(self,padding:_size_6_t)
torch.nn.modules.padding.ZeroPad2d(self,padding:_size_4_t)
torch.nn.modules.padding.ZeroPad2d.__init__(self,padding:_size_4_t)
torch.nn.modules.padding._ConstantPadNd(self,value:float)
torch.nn.modules.padding._ConstantPadNd.__init__(self,value:float)
torch.nn.modules.padding._ConstantPadNd.extra_repr(self)->str
torch.nn.modules.padding._ConstantPadNd.forward(self,input:Tensor)->Tensor
torch.nn.modules.padding._ReflectionPadNd(Module)
torch.nn.modules.padding._ReflectionPadNd.extra_repr(self)->str
torch.nn.modules.padding._ReflectionPadNd.forward(self,input:Tensor)->Tensor
torch.nn.modules.padding._ReplicationPadNd(Module)
torch.nn.modules.padding._ReplicationPadNd.extra_repr(self)->str
torch.nn.modules.padding._ReplicationPadNd.forward(self,input:Tensor)->Tensor
torch.nn.padding._ConstantPadNd(self,value:float)
torch.nn.padding._ConstantPadNd.extra_repr(self)->str
torch.nn.padding._ConstantPadNd.forward(self,input:Tensor)->Tensor
torch.nn.padding._ReflectionPadNd(Module)
torch.nn.padding._ReflectionPadNd.extra_repr(self)->str
torch.nn.padding._ReflectionPadNd.forward(self,input:Tensor)->Tensor
torch.nn.padding._ReplicationPadNd(Module)
torch.nn.padding._ReplicationPadNd.extra_repr(self)->str
torch.nn.padding._ReplicationPadNd.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/fold.py----------------------------------------
torch.nn.Fold(self,output_size:_size_any_t,kernel_size:_size_any_t,dilation:_size_any_t=1,padding:_size_any_t=0,stride:_size_any_t=1)
torch.nn.Fold.extra_repr(self)->str
torch.nn.Fold.forward(self,input:Tensor)->Tensor
torch.nn.Unfold(self,kernel_size:_size_any_t,dilation:_size_any_t=1,padding:_size_any_t=0,stride:_size_any_t=1)
torch.nn.Unfold.extra_repr(self)->str
torch.nn.Unfold.forward(self,input:Tensor)->Tensor
torch.nn.modules.fold.Fold(self,output_size:_size_any_t,kernel_size:_size_any_t,dilation:_size_any_t=1,padding:_size_any_t=0,stride:_size_any_t=1)
torch.nn.modules.fold.Fold.__init__(self,output_size:_size_any_t,kernel_size:_size_any_t,dilation:_size_any_t=1,padding:_size_any_t=0,stride:_size_any_t=1)
torch.nn.modules.fold.Fold.extra_repr(self)->str
torch.nn.modules.fold.Fold.forward(self,input:Tensor)->Tensor
torch.nn.modules.fold.Unfold(self,kernel_size:_size_any_t,dilation:_size_any_t=1,padding:_size_any_t=0,stride:_size_any_t=1)
torch.nn.modules.fold.Unfold.__init__(self,kernel_size:_size_any_t,dilation:_size_any_t=1,padding:_size_any_t=0,stride:_size_any_t=1)
torch.nn.modules.fold.Unfold.extra_repr(self)->str
torch.nn.modules.fold.Unfold.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/instancenorm.py----------------------------------------
A:torch.nn.modules.instancenorm.version->local_metadata.get('version', None)
torch.nn.InstanceNorm1d(_InstanceNorm)
torch.nn.InstanceNorm1d._check_input_dim(self,input)
torch.nn.InstanceNorm2d(_InstanceNorm)
torch.nn.InstanceNorm2d._check_input_dim(self,input)
torch.nn.InstanceNorm3d(_InstanceNorm)
torch.nn.InstanceNorm3d._check_input_dim(self,input)
torch.nn.instancenorm._InstanceNorm(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=False,track_running_stats:bool=False)
torch.nn.instancenorm._InstanceNorm._check_input_dim(self,input)
torch.nn.instancenorm._InstanceNorm._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.instancenorm._InstanceNorm.forward(self,input:Tensor)->Tensor
torch.nn.modules.instancenorm.InstanceNorm1d(_InstanceNorm)
torch.nn.modules.instancenorm.InstanceNorm1d._check_input_dim(self,input)
torch.nn.modules.instancenorm.InstanceNorm2d(_InstanceNorm)
torch.nn.modules.instancenorm.InstanceNorm2d._check_input_dim(self,input)
torch.nn.modules.instancenorm.InstanceNorm3d(_InstanceNorm)
torch.nn.modules.instancenorm.InstanceNorm3d._check_input_dim(self,input)
torch.nn.modules.instancenorm._InstanceNorm(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=False,track_running_stats:bool=False)
torch.nn.modules.instancenorm._InstanceNorm.__init__(self,num_features:int,eps:float=1e-05,momentum:float=0.1,affine:bool=False,track_running_stats:bool=False)
torch.nn.modules.instancenorm._InstanceNorm._check_input_dim(self,input)
torch.nn.modules.instancenorm._InstanceNorm._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.modules.instancenorm._InstanceNorm.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/channelshuffle.py----------------------------------------
torch.nn.channelshuffle.ChannelShuffle(self,groups)
torch.nn.channelshuffle.ChannelShuffle.extra_repr(self)
torch.nn.channelshuffle.ChannelShuffle.forward(self,input)
torch.nn.modules.channelshuffle.ChannelShuffle(self,groups)
torch.nn.modules.channelshuffle.ChannelShuffle.__init__(self,groups)
torch.nn.modules.channelshuffle.ChannelShuffle.extra_repr(self)
torch.nn.modules.channelshuffle.ChannelShuffle.forward(self,input)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/pooling.py----------------------------------------
A:torch.nn.modules.pooling.self.kernel_size->_triple(kernel_size)
A:torch.nn.modules.pooling.self.stride->_single(stride if stride is not None else kernel_size)
A:torch.nn.modules.pooling.self.padding->_single(padding)
torch.nn.AdaptiveAvgPool1d(_AdaptiveAvgPoolNd)
torch.nn.AdaptiveAvgPool1d.forward(self,input:Tensor)->Tensor
torch.nn.AdaptiveAvgPool2d(_AdaptiveAvgPoolNd)
torch.nn.AdaptiveAvgPool2d.forward(self,input:Tensor)->Tensor
torch.nn.AdaptiveAvgPool3d(_AdaptiveAvgPoolNd)
torch.nn.AdaptiveAvgPool3d.forward(self,input:Tensor)->Tensor
torch.nn.AdaptiveMaxPool1d(_AdaptiveMaxPoolNd)
torch.nn.AdaptiveMaxPool1d.forward(self,input:Tensor)->Tensor
torch.nn.AdaptiveMaxPool2d(_AdaptiveMaxPoolNd)
torch.nn.AdaptiveMaxPool2d.forward(self,input:Tensor)->Tensor
torch.nn.AdaptiveMaxPool3d(_AdaptiveMaxPoolNd)
torch.nn.AdaptiveMaxPool3d.forward(self,input:Tensor)->Tensor
torch.nn.AvgPool1d(self,kernel_size:_size_1_t,stride:_size_1_t=None,padding:_size_1_t=0,ceil_mode:bool=False,count_include_pad:bool=True)
torch.nn.AvgPool1d.forward(self,input:Tensor)->Tensor
torch.nn.AvgPool2d(self,kernel_size:_size_2_t,stride:Optional[_size_2_t]=None,padding:_size_2_t=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override:bool=None)
torch.nn.AvgPool2d.forward(self,input:Tensor)->Tensor
torch.nn.AvgPool3d(self,kernel_size:_size_3_t,stride:Optional[_size_3_t]=None,padding:_size_3_t=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override=None)
torch.nn.AvgPool3d.__setstate__(self,d)
torch.nn.AvgPool3d.forward(self,input:Tensor)->Tensor
torch.nn.FractionalMaxPool2d(self,kernel_size:_size_2_t,output_size:Optional[_size_2_t]=None,output_ratio:Optional[_ratio_2_t]=None,return_indices:bool=False,_random_samples=None)
torch.nn.FractionalMaxPool2d.forward(self,input:Tensor)->Tensor
torch.nn.FractionalMaxPool3d(self,kernel_size:_size_3_t,output_size:Optional[_size_3_t]=None,output_ratio:Optional[_ratio_3_t]=None,return_indices:bool=False,_random_samples=None)
torch.nn.FractionalMaxPool3d.forward(self,input:Tensor)->Tensor
torch.nn.LPPool1d(_LPPoolNd)
torch.nn.LPPool1d.forward(self,input:Tensor)->Tensor
torch.nn.LPPool2d(_LPPoolNd)
torch.nn.LPPool2d.forward(self,input:Tensor)->Tensor
torch.nn.MaxPool1d(_MaxPoolNd)
torch.nn.MaxPool1d.forward(self,input:Tensor)->Tensor
torch.nn.MaxPool2d(_MaxPoolNd)
torch.nn.MaxPool2d.forward(self,input:Tensor)->Tensor
torch.nn.MaxPool3d(_MaxPoolNd)
torch.nn.MaxPool3d.forward(self,input:Tensor)->Tensor
torch.nn.MaxUnpool1d(self,kernel_size:_size_1_t,stride:Optional[_size_1_t]=None,padding:_size_1_t=0)
torch.nn.MaxUnpool1d.forward(self,input:Tensor,indices:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.MaxUnpool2d(self,kernel_size:_size_2_t,stride:Optional[_size_2_t]=None,padding:_size_2_t=0)
torch.nn.MaxUnpool2d.forward(self,input:Tensor,indices:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.MaxUnpool3d(self,kernel_size:_size_3_t,stride:Optional[_size_3_t]=None,padding:_size_3_t=0)
torch.nn.MaxUnpool3d.forward(self,input:Tensor,indices:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.pooling.AdaptiveAvgPool1d(_AdaptiveAvgPoolNd)
torch.nn.modules.pooling.AdaptiveAvgPool1d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AdaptiveAvgPool2d(_AdaptiveAvgPoolNd)
torch.nn.modules.pooling.AdaptiveAvgPool2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AdaptiveAvgPool3d(_AdaptiveAvgPoolNd)
torch.nn.modules.pooling.AdaptiveAvgPool3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AdaptiveMaxPool1d(_AdaptiveMaxPoolNd)
torch.nn.modules.pooling.AdaptiveMaxPool1d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AdaptiveMaxPool2d(_AdaptiveMaxPoolNd)
torch.nn.modules.pooling.AdaptiveMaxPool2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AdaptiveMaxPool3d(_AdaptiveMaxPoolNd)
torch.nn.modules.pooling.AdaptiveMaxPool3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AvgPool1d(self,kernel_size:_size_1_t,stride:_size_1_t=None,padding:_size_1_t=0,ceil_mode:bool=False,count_include_pad:bool=True)
torch.nn.modules.pooling.AvgPool1d.__init__(self,kernel_size:_size_1_t,stride:_size_1_t=None,padding:_size_1_t=0,ceil_mode:bool=False,count_include_pad:bool=True)
torch.nn.modules.pooling.AvgPool1d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AvgPool2d(self,kernel_size:_size_2_t,stride:Optional[_size_2_t]=None,padding:_size_2_t=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override:bool=None)
torch.nn.modules.pooling.AvgPool2d.__init__(self,kernel_size:_size_2_t,stride:Optional[_size_2_t]=None,padding:_size_2_t=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override:bool=None)
torch.nn.modules.pooling.AvgPool2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.AvgPool3d(self,kernel_size:_size_3_t,stride:Optional[_size_3_t]=None,padding:_size_3_t=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override=None)
torch.nn.modules.pooling.AvgPool3d.__init__(self,kernel_size:_size_3_t,stride:Optional[_size_3_t]=None,padding:_size_3_t=0,ceil_mode:bool=False,count_include_pad:bool=True,divisor_override=None)
torch.nn.modules.pooling.AvgPool3d.__setstate__(self,d)
torch.nn.modules.pooling.AvgPool3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.FractionalMaxPool2d(self,kernel_size:_size_2_t,output_size:Optional[_size_2_t]=None,output_ratio:Optional[_ratio_2_t]=None,return_indices:bool=False,_random_samples=None)
torch.nn.modules.pooling.FractionalMaxPool2d.__init__(self,kernel_size:_size_2_t,output_size:Optional[_size_2_t]=None,output_ratio:Optional[_ratio_2_t]=None,return_indices:bool=False,_random_samples=None)
torch.nn.modules.pooling.FractionalMaxPool2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.FractionalMaxPool3d(self,kernel_size:_size_3_t,output_size:Optional[_size_3_t]=None,output_ratio:Optional[_ratio_3_t]=None,return_indices:bool=False,_random_samples=None)
torch.nn.modules.pooling.FractionalMaxPool3d.__init__(self,kernel_size:_size_3_t,output_size:Optional[_size_3_t]=None,output_ratio:Optional[_ratio_3_t]=None,return_indices:bool=False,_random_samples=None)
torch.nn.modules.pooling.FractionalMaxPool3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.LPPool1d(_LPPoolNd)
torch.nn.modules.pooling.LPPool1d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.LPPool2d(_LPPoolNd)
torch.nn.modules.pooling.LPPool2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.MaxPool1d(_MaxPoolNd)
torch.nn.modules.pooling.MaxPool1d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.MaxPool2d(_MaxPoolNd)
torch.nn.modules.pooling.MaxPool2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.MaxPool3d(_MaxPoolNd)
torch.nn.modules.pooling.MaxPool3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.pooling.MaxUnpool1d(self,kernel_size:_size_1_t,stride:Optional[_size_1_t]=None,padding:_size_1_t=0)
torch.nn.modules.pooling.MaxUnpool1d.__init__(self,kernel_size:_size_1_t,stride:Optional[_size_1_t]=None,padding:_size_1_t=0)
torch.nn.modules.pooling.MaxUnpool1d.forward(self,input:Tensor,indices:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.pooling.MaxUnpool2d(self,kernel_size:_size_2_t,stride:Optional[_size_2_t]=None,padding:_size_2_t=0)
torch.nn.modules.pooling.MaxUnpool2d.__init__(self,kernel_size:_size_2_t,stride:Optional[_size_2_t]=None,padding:_size_2_t=0)
torch.nn.modules.pooling.MaxUnpool2d.forward(self,input:Tensor,indices:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.pooling.MaxUnpool3d(self,kernel_size:_size_3_t,stride:Optional[_size_3_t]=None,padding:_size_3_t=0)
torch.nn.modules.pooling.MaxUnpool3d.__init__(self,kernel_size:_size_3_t,stride:Optional[_size_3_t]=None,padding:_size_3_t=0)
torch.nn.modules.pooling.MaxUnpool3d.forward(self,input:Tensor,indices:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.pooling._AdaptiveAvgPoolNd(self,output_size:_size_any_t)
torch.nn.modules.pooling._AdaptiveAvgPoolNd.__init__(self,output_size:_size_any_t)
torch.nn.modules.pooling._AdaptiveAvgPoolNd.extra_repr(self)->str
torch.nn.modules.pooling._AdaptiveMaxPoolNd(self,output_size:_size_any_t,return_indices:bool=False)
torch.nn.modules.pooling._AdaptiveMaxPoolNd.__init__(self,output_size:_size_any_t,return_indices:bool=False)
torch.nn.modules.pooling._AdaptiveMaxPoolNd.extra_repr(self)->str
torch.nn.modules.pooling._AvgPoolNd(Module)
torch.nn.modules.pooling._AvgPoolNd.extra_repr(self)->str
torch.nn.modules.pooling._LPPoolNd(self,norm_type:float,kernel_size:_size_any_t,stride:Optional[_size_any_t]=None,ceil_mode:bool=False)
torch.nn.modules.pooling._LPPoolNd.__init__(self,norm_type:float,kernel_size:_size_any_t,stride:Optional[_size_any_t]=None,ceil_mode:bool=False)
torch.nn.modules.pooling._LPPoolNd.extra_repr(self)->str
torch.nn.modules.pooling._MaxPoolNd(self,kernel_size:_size_any_t,stride:Optional[_size_any_t]=None,padding:_size_any_t=0,dilation:_size_any_t=1,return_indices:bool=False,ceil_mode:bool=False)
torch.nn.modules.pooling._MaxPoolNd.__init__(self,kernel_size:_size_any_t,stride:Optional[_size_any_t]=None,padding:_size_any_t=0,dilation:_size_any_t=1,return_indices:bool=False,ceil_mode:bool=False)
torch.nn.modules.pooling._MaxPoolNd.extra_repr(self)->str
torch.nn.modules.pooling._MaxUnpoolNd(Module)
torch.nn.modules.pooling._MaxUnpoolNd.extra_repr(self)->str
torch.nn.pooling._AdaptiveAvgPoolNd(self,output_size:_size_any_t)
torch.nn.pooling._AdaptiveAvgPoolNd.extra_repr(self)->str
torch.nn.pooling._AdaptiveMaxPoolNd(self,output_size:_size_any_t,return_indices:bool=False)
torch.nn.pooling._AdaptiveMaxPoolNd.extra_repr(self)->str
torch.nn.pooling._AvgPoolNd(Module)
torch.nn.pooling._AvgPoolNd.extra_repr(self)->str
torch.nn.pooling._LPPoolNd(self,norm_type:float,kernel_size:_size_any_t,stride:Optional[_size_any_t]=None,ceil_mode:bool=False)
torch.nn.pooling._LPPoolNd.extra_repr(self)->str
torch.nn.pooling._MaxPoolNd(self,kernel_size:_size_any_t,stride:Optional[_size_any_t]=None,padding:_size_any_t=0,dilation:_size_any_t=1,return_indices:bool=False,ceil_mode:bool=False)
torch.nn.pooling._MaxPoolNd.extra_repr(self)->str
torch.nn.pooling._MaxUnpoolNd(Module)
torch.nn.pooling._MaxUnpoolNd.extra_repr(self)->str


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/_functions.py----------------------------------------
A:torch.nn.modules._functions.input->input.contiguous().contiguous()
A:torch.nn.modules._functions.count->torch.empty(1, dtype=running_mean.dtype, device=input.device).fill_(input.numel() // input.size(1))
A:torch.nn.modules._functions.(mean, invstd)->torch.batch_norm_gather_stats_with_counts(input, mean_all, invstd_all, running_mean, running_var, momentum, eps, count_all.view(-1))
A:torch.nn.modules._functions.combined->torch.cat([sum_dy, sum_dy_xmu], dim=0)
A:torch.nn.modules._functions.(mean_all, invstd_all, count_all)->torch.split(combined, num_channels, dim=1)
A:torch.nn.modules._functions.size->count_all.view(-1).long().sum()
A:torch.nn.modules._functions.out->torch.batch_norm_elemt(input, weight, bias, mean, invstd, eps)
A:torch.nn.modules._functions.grad_output->grad_output.contiguous().contiguous()
A:torch.nn.modules._functions.(sum_dy, sum_dy_xmu, grad_weight, grad_bias)->torch.batch_norm_backward_reduce(grad_output, saved_input, mean, invstd, weight, self.needs_input_grad[0], self.needs_input_grad[1], self.needs_input_grad[2])
A:torch.nn.modules._functions.(sum_dy, sum_dy_xmu)->torch.split(combined, num_channels)
A:torch.nn.modules._functions.divisor->count_tensor.sum()
A:torch.nn.modules._functions.grad_input->grad_output.contiguous().contiguous().new()
A:torch.nn.modules._functions.output->input.contiguous().contiguous().new()
A:torch.nn.modules._functions.batch_size->input.contiguous().contiguous().size(0)
A:torch.nn.modules._functions.channels->input.contiguous().contiguous().size(1)
A:torch.nn.modules._functions.input_height->input.contiguous().contiguous().size(2)
A:torch.nn.modules._functions.input_width->input.contiguous().contiguous().size(3)
A:torch.nn.modules._functions.pre_pad->int((ctx.size - 1) / 2 + 1)
A:torch.nn.modules._functions.scale_first->ctx.scale.select(1, 0)
A:torch.nn.modules._functions.scale_previous->ctx.scale.select(1, c - 1)
A:torch.nn.modules._functions.scale_current->ctx.scale.select(1, c)
A:torch.nn.modules._functions.square_next->input_square.select(1, c + pre_pad - 1)
A:torch.nn.modules._functions.square_previous->input_square.select(1, c - pre_pad)
A:torch.nn.modules._functions.paddded_ratio->input.contiguous().contiguous().new(channels + ctx.size - 1, input_height, input_width)
A:torch.nn.modules._functions.accum_ratio->input.contiguous().contiguous().new(input_height, input_width)
A:torch.nn.modules._functions.inversePrePad->int(ctx.size - (ctx.size - 1) / 2)
A:torch.nn.modules._functions.padded_ratio_center->input.contiguous().contiguous().new(channels + ctx.size - 1, input_height, input_width).narrow(0, inversePrePad, channels)
torch.nn._functions.CrossMapLRN2d(Function)
torch.nn._functions.CrossMapLRN2d.backward(ctx,grad_output)
torch.nn._functions.CrossMapLRN2d.forward(ctx,input,size,alpha=0.0001,beta=0.75,k=1)
torch.nn._functions.SyncBatchNorm(Function)
torch.nn._functions.SyncBatchNorm.backward(self,grad_output)
torch.nn._functions.SyncBatchNorm.forward(self,input,weight,bias,running_mean,running_var,eps,momentum,process_group,world_size)
torch.nn.modules._functions.CrossMapLRN2d(Function)
torch.nn.modules._functions.CrossMapLRN2d.backward(ctx,grad_output)
torch.nn.modules._functions.CrossMapLRN2d.forward(ctx,input,size,alpha=0.0001,beta=0.75,k=1)
torch.nn.modules._functions.SyncBatchNorm(Function)
torch.nn.modules._functions.SyncBatchNorm.backward(self,grad_output)
torch.nn.modules._functions.SyncBatchNorm.forward(self,input,weight,bias,running_mean,running_var,eps,momentum,process_group,world_size)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/rnn.py----------------------------------------
A:torch.nn.modules.rnn.self.dropout->float(dropout)
A:torch.nn.modules.rnn.w_ih->Parameter(torch.Tensor(gate_size, layer_input_size))
A:torch.nn.modules.rnn.w_hh->Parameter(torch.Tensor(gate_size, hidden_size))
A:torch.nn.modules.rnn.b_ih->Parameter(torch.Tensor(gate_size))
A:torch.nn.modules.rnn.b_hh->Parameter(torch.Tensor(gate_size))
A:torch.nn.modules.rnn.idx->self._flat_weights_names.index(attr)
A:torch.nn.modules.rnn.unique_data_ptrs->set((p.data_ptr() for p in self._flat_weights))
A:torch.nn.modules.rnn.ret->_VF.rnn_relu_cell(input, hx, self.weight_ih, self.weight_hh, self.bias_ih, self.bias_hh)
A:torch.nn.modules.rnn.mini_batch->int(mini_batch)
A:torch.nn.modules.rnn.expected_hidden_size->self.get_expected_hidden_size(input, batch_sizes)
A:torch.nn.modules.rnn.is_packed->isinstance(input, PackedSequence)
A:torch.nn.modules.rnn.max_batch_size->int(max_batch_size)
A:torch.nn.modules.rnn.hx->torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)
A:torch.nn.modules.rnn.result->_VF.gru(input, batch_sizes, hx, self._flat_weights, self.bias, self.num_layers, self.dropout, self.training, self.bidirectional)
A:torch.nn.modules.rnn.output->PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)
A:torch.nn.modules.rnn.replica->super(RNNBase, self)._replicate_for_data_parallel()
A:torch.nn.modules.rnn.self.nonlinearity->kwargs.pop('nonlinearity', 'tanh')
A:torch.nn.modules.rnn.zeros->torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)
A:torch.nn.modules.rnn.output_packed->PackedSequence(output, batch_sizes, sorted_indices, unsorted_indices)
A:torch.nn.modules.rnn.self.weight_ih->Parameter(torch.Tensor(num_chunks * hidden_size, input_size))
A:torch.nn.modules.rnn.self.weight_hh->Parameter(torch.Tensor(num_chunks * hidden_size, hidden_size))
A:torch.nn.modules.rnn.self.bias_ih->Parameter(torch.Tensor(num_chunks * hidden_size))
A:torch.nn.modules.rnn.self.bias_hh->Parameter(torch.Tensor(num_chunks * hidden_size))
torch.nn.GRU(self,*args,**kwargs)
torch.nn.GRU.forward(self,input,hx=None)
torch.nn.GRUCell(self,input_size:int,hidden_size:int,bias:bool=True)
torch.nn.GRUCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.LSTM(self,*args,**kwargs)
torch.nn.LSTM.check_forward_args(self,input:Tensor,hidden:Tuple[Tensor,Tensor],batch_sizes:Optional[Tensor])
torch.nn.LSTM.forward(self,input,hx=None)
torch.nn.LSTM.permute_hidden(self,hx:Tuple[Tensor,Tensor],permutation:Optional[Tensor])->Tuple[Tensor, Tensor]
torch.nn.LSTMCell(self,input_size:int,hidden_size:int,bias:bool=True)
torch.nn.LSTMCell.forward(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[Tensor, Tensor]
torch.nn.RNN(self,*args,**kwargs)
torch.nn.RNNBase(self,mode:str,input_size:int,hidden_size:int,num_layers:int=1,bias:bool=True,batch_first:bool=False,dropout:float=0.0,bidirectional:bool=False)
torch.nn.RNNBase.__setattr__(self,attr,value)
torch.nn.RNNBase.__setstate__(self,d)
torch.nn.RNNBase._apply(self,fn)
torch.nn.RNNBase._replicate_for_data_parallel(self)
torch.nn.RNNBase.all_weights(self)->List[Parameter]
torch.nn.RNNBase.check_forward_args(self,input:Tensor,hidden:Tensor,batch_sizes:Optional[Tensor])
torch.nn.RNNBase.check_hidden_size(self,hx:Tensor,expected_hidden_size:Tuple[int,int,int],msg:str='Expectedhiddensize{},got{}')->None
torch.nn.RNNBase.check_input(self,input:Tensor,batch_sizes:Optional[Tensor])->None
torch.nn.RNNBase.extra_repr(self)->str
torch.nn.RNNBase.flatten_parameters(self)->None
torch.nn.RNNBase.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tuple[Tensor, Tensor]
torch.nn.RNNBase.get_expected_hidden_size(self,input:Tensor,batch_sizes:Optional[Tensor])->Tuple[int, int, int]
torch.nn.RNNBase.permute_hidden(self,hx:Tensor,permutation:Optional[Tensor])
torch.nn.RNNBase.reset_parameters(self)->None
torch.nn.RNNCell(self,input_size:int,hidden_size:int,bias:bool=True,nonlinearity:str='tanh')
torch.nn.RNNCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.RNNCellBase(self,input_size:int,hidden_size:int,bias:bool,num_chunks:int)
torch.nn.RNNCellBase.check_forward_hidden(self,input:Tensor,hx:Tensor,hidden_label:str='')->None
torch.nn.RNNCellBase.check_forward_input(self,input:Tensor)->None
torch.nn.RNNCellBase.extra_repr(self)->str
torch.nn.RNNCellBase.reset_parameters(self)->None
torch.nn.modules.rnn.GRU(self,*args,**kwargs)
torch.nn.modules.rnn.GRU.__init__(self,*args,**kwargs)
torch.nn.modules.rnn.GRU.forward(self,input,hx=None)
torch.nn.modules.rnn.GRUCell(self,input_size:int,hidden_size:int,bias:bool=True)
torch.nn.modules.rnn.GRUCell.__init__(self,input_size:int,hidden_size:int,bias:bool=True)
torch.nn.modules.rnn.GRUCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.modules.rnn.LSTM(self,*args,**kwargs)
torch.nn.modules.rnn.LSTM.__init__(self,*args,**kwargs)
torch.nn.modules.rnn.LSTM.check_forward_args(self,input:Tensor,hidden:Tuple[Tensor,Tensor],batch_sizes:Optional[Tensor])
torch.nn.modules.rnn.LSTM.forward(self,input,hx=None)
torch.nn.modules.rnn.LSTM.permute_hidden(self,hx:Tuple[Tensor,Tensor],permutation:Optional[Tensor])->Tuple[Tensor, Tensor]
torch.nn.modules.rnn.LSTMCell(self,input_size:int,hidden_size:int,bias:bool=True)
torch.nn.modules.rnn.LSTMCell.__init__(self,input_size:int,hidden_size:int,bias:bool=True)
torch.nn.modules.rnn.LSTMCell.forward(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[Tensor, Tensor]
torch.nn.modules.rnn.RNN(self,*args,**kwargs)
torch.nn.modules.rnn.RNN.__init__(self,*args,**kwargs)
torch.nn.modules.rnn.RNNBase(self,mode:str,input_size:int,hidden_size:int,num_layers:int=1,bias:bool=True,batch_first:bool=False,dropout:float=0.0,bidirectional:bool=False)
torch.nn.modules.rnn.RNNBase.__init__(self,mode:str,input_size:int,hidden_size:int,num_layers:int=1,bias:bool=True,batch_first:bool=False,dropout:float=0.0,bidirectional:bool=False)
torch.nn.modules.rnn.RNNBase.__setattr__(self,attr,value)
torch.nn.modules.rnn.RNNBase.__setstate__(self,d)
torch.nn.modules.rnn.RNNBase._apply(self,fn)
torch.nn.modules.rnn.RNNBase._replicate_for_data_parallel(self)
torch.nn.modules.rnn.RNNBase.all_weights(self)->List[Parameter]
torch.nn.modules.rnn.RNNBase.check_forward_args(self,input:Tensor,hidden:Tensor,batch_sizes:Optional[Tensor])
torch.nn.modules.rnn.RNNBase.check_hidden_size(self,hx:Tensor,expected_hidden_size:Tuple[int,int,int],msg:str='Expectedhiddensize{},got{}')->None
torch.nn.modules.rnn.RNNBase.check_input(self,input:Tensor,batch_sizes:Optional[Tensor])->None
torch.nn.modules.rnn.RNNBase.extra_repr(self)->str
torch.nn.modules.rnn.RNNBase.flatten_parameters(self)->None
torch.nn.modules.rnn.RNNBase.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tuple[Tensor, Tensor]
torch.nn.modules.rnn.RNNBase.get_expected_hidden_size(self,input:Tensor,batch_sizes:Optional[Tensor])->Tuple[int, int, int]
torch.nn.modules.rnn.RNNBase.permute_hidden(self,hx:Tensor,permutation:Optional[Tensor])
torch.nn.modules.rnn.RNNBase.reset_parameters(self)->None
torch.nn.modules.rnn.RNNCell(self,input_size:int,hidden_size:int,bias:bool=True,nonlinearity:str='tanh')
torch.nn.modules.rnn.RNNCell.__init__(self,input_size:int,hidden_size:int,bias:bool=True,nonlinearity:str='tanh')
torch.nn.modules.rnn.RNNCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.modules.rnn.RNNCellBase(self,input_size:int,hidden_size:int,bias:bool,num_chunks:int)
torch.nn.modules.rnn.RNNCellBase.__init__(self,input_size:int,hidden_size:int,bias:bool,num_chunks:int)
torch.nn.modules.rnn.RNNCellBase.check_forward_hidden(self,input:Tensor,hx:Tensor,hidden_label:str='')->None
torch.nn.modules.rnn.RNNCellBase.check_forward_input(self,input:Tensor)->None
torch.nn.modules.rnn.RNNCellBase.extra_repr(self)->str
torch.nn.modules.rnn.RNNCellBase.reset_parameters(self)->None
torch.nn.modules.rnn.apply_permutation(tensor:Tensor,permutation:Tensor,dim:int=1)->Tensor
torch.nn.rnn.apply_permutation(tensor:Tensor,permutation:Tensor,dim:int=1)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/loss.py----------------------------------------
A:torch.nn.modules.loss.self.reduction->_Reduction.legacy_get_string(size_average, reduce)
torch.nn.BCELoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.BCELoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.BCEWithLogitsLoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean',pos_weight:Optional[Tensor]=None)
torch.nn.BCEWithLogitsLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.CTCLoss(self,blank:int=0,reduction:str='mean',zero_infinity:bool=False)
torch.nn.CTCLoss.forward(self,log_probs:Tensor,targets:Tensor,input_lengths:Tensor,target_lengths:Tensor)->Tensor
torch.nn.CosineEmbeddingLoss(self,margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.CosineEmbeddingLoss.forward(self,input1:Tensor,input2:Tensor,target:Tensor)->Tensor
torch.nn.CrossEntropyLoss(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.CrossEntropyLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.HingeEmbeddingLoss(self,margin:float=1.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.HingeEmbeddingLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.KLDivLoss(self,size_average=None,reduce=None,reduction:str='mean',log_target:bool=False)
torch.nn.KLDivLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.L1Loss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.L1Loss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.MSELoss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.MSELoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.MarginRankingLoss(self,margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.MarginRankingLoss.forward(self,input1:Tensor,input2:Tensor,target:Tensor)->Tensor
torch.nn.MultiLabelMarginLoss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.MultiLabelMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.MultiLabelSoftMarginLoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.MultiLabelSoftMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.MultiMarginLoss(self,p:int=1,margin:float=1.0,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.MultiMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.NLLLoss(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.NLLLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.NLLLoss2d(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.PoissonNLLLoss(self,log_input:bool=True,full:bool=False,size_average=None,eps:float=1e-08,reduce=None,reduction:str='mean')
torch.nn.PoissonNLLLoss.forward(self,log_input:Tensor,target:Tensor)->Tensor
torch.nn.SmoothL1Loss(self,size_average=None,reduce=None,reduction:str='mean',beta:float=1.0)
torch.nn.SmoothL1Loss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.SoftMarginLoss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.SoftMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.TripletMarginLoss(self,margin:float=1.0,p:float=2.0,eps:float=1e-06,swap:bool=False,size_average=None,reduce=None,reduction:str='mean')
torch.nn.TripletMarginLoss.forward(self,anchor:Tensor,positive:Tensor,negative:Tensor)->Tensor
torch.nn.TripletMarginWithDistanceLoss(self,*,distance_function:Optional[Callable[[Tensor,Tensor],Tensor]]=None,margin:float=1.0,swap:bool=False,reduction:str='mean')
torch.nn.TripletMarginWithDistanceLoss.forward(self,anchor:Tensor,positive:Tensor,negative:Tensor)->Tensor
torch.nn.loss._Loss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.loss._WeightedLoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.BCELoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.BCELoss.__init__(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.BCELoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.BCEWithLogitsLoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean',pos_weight:Optional[Tensor]=None)
torch.nn.modules.loss.BCEWithLogitsLoss.__init__(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean',pos_weight:Optional[Tensor]=None)
torch.nn.modules.loss.BCEWithLogitsLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.CTCLoss(self,blank:int=0,reduction:str='mean',zero_infinity:bool=False)
torch.nn.modules.loss.CTCLoss.__init__(self,blank:int=0,reduction:str='mean',zero_infinity:bool=False)
torch.nn.modules.loss.CTCLoss.forward(self,log_probs:Tensor,targets:Tensor,input_lengths:Tensor,target_lengths:Tensor)->Tensor
torch.nn.modules.loss.CosineEmbeddingLoss(self,margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.CosineEmbeddingLoss.__init__(self,margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.CosineEmbeddingLoss.forward(self,input1:Tensor,input2:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.CrossEntropyLoss(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.modules.loss.CrossEntropyLoss.__init__(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.modules.loss.CrossEntropyLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.HingeEmbeddingLoss(self,margin:float=1.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.HingeEmbeddingLoss.__init__(self,margin:float=1.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.HingeEmbeddingLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.KLDivLoss(self,size_average=None,reduce=None,reduction:str='mean',log_target:bool=False)
torch.nn.modules.loss.KLDivLoss.__init__(self,size_average=None,reduce=None,reduction:str='mean',log_target:bool=False)
torch.nn.modules.loss.KLDivLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.L1Loss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.L1Loss.__init__(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.L1Loss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.MSELoss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MSELoss.__init__(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MSELoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.MarginRankingLoss(self,margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MarginRankingLoss.__init__(self,margin:float=0.0,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MarginRankingLoss.forward(self,input1:Tensor,input2:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.MultiLabelMarginLoss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MultiLabelMarginLoss.__init__(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MultiLabelMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.MultiLabelSoftMarginLoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MultiLabelSoftMarginLoss.__init__(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MultiLabelSoftMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.MultiMarginLoss(self,p:int=1,margin:float=1.0,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MultiMarginLoss.__init__(self,p:int=1,margin:float=1.0,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.MultiMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.NLLLoss(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.modules.loss.NLLLoss.__init__(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.modules.loss.NLLLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.NLLLoss2d(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.modules.loss.NLLLoss2d.__init__(self,weight:Optional[Tensor]=None,size_average=None,ignore_index:int=-100,reduce=None,reduction:str='mean')
torch.nn.modules.loss.PoissonNLLLoss(self,log_input:bool=True,full:bool=False,size_average=None,eps:float=1e-08,reduce=None,reduction:str='mean')
torch.nn.modules.loss.PoissonNLLLoss.__init__(self,log_input:bool=True,full:bool=False,size_average=None,eps:float=1e-08,reduce=None,reduction:str='mean')
torch.nn.modules.loss.PoissonNLLLoss.forward(self,log_input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.SmoothL1Loss(self,size_average=None,reduce=None,reduction:str='mean',beta:float=1.0)
torch.nn.modules.loss.SmoothL1Loss.__init__(self,size_average=None,reduce=None,reduction:str='mean',beta:float=1.0)
torch.nn.modules.loss.SmoothL1Loss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.SoftMarginLoss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.SoftMarginLoss.__init__(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.SoftMarginLoss.forward(self,input:Tensor,target:Tensor)->Tensor
torch.nn.modules.loss.TripletMarginLoss(self,margin:float=1.0,p:float=2.0,eps:float=1e-06,swap:bool=False,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.TripletMarginLoss.__init__(self,margin:float=1.0,p:float=2.0,eps:float=1e-06,swap:bool=False,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss.TripletMarginLoss.forward(self,anchor:Tensor,positive:Tensor,negative:Tensor)->Tensor
torch.nn.modules.loss.TripletMarginWithDistanceLoss(self,*,distance_function:Optional[Callable[[Tensor,Tensor],Tensor]]=None,margin:float=1.0,swap:bool=False,reduction:str='mean')
torch.nn.modules.loss.TripletMarginWithDistanceLoss.__init__(self,*,distance_function:Optional[Callable[[Tensor,Tensor],Tensor]]=None,margin:float=1.0,swap:bool=False,reduction:str='mean')
torch.nn.modules.loss.TripletMarginWithDistanceLoss.forward(self,anchor:Tensor,positive:Tensor,negative:Tensor)->Tensor
torch.nn.modules.loss._Loss(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss._Loss.__init__(self,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss._WeightedLoss(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')
torch.nn.modules.loss._WeightedLoss.__init__(self,weight:Optional[Tensor]=None,size_average=None,reduce=None,reduction:str='mean')


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/normalization.py----------------------------------------
A:torch.nn.modules.normalization.self.normalized_shape->tuple(normalized_shape)
A:torch.nn.modules.normalization.self.weight->Parameter(torch.Tensor(num_channels))
A:torch.nn.modules.normalization.self.bias->Parameter(torch.Tensor(num_channels))
torch.nn.CrossMapLRN2d(self,size:int,alpha:float=0.0001,beta:float=0.75,k:float=1)
torch.nn.CrossMapLRN2d.extra_repr(self)->str
torch.nn.CrossMapLRN2d.forward(self,input:Tensor)->Tensor
torch.nn.GroupNorm(self,num_groups:int,num_channels:int,eps:float=1e-05,affine:bool=True)
torch.nn.GroupNorm.extra_repr(self)->str
torch.nn.GroupNorm.forward(self,input:Tensor)->Tensor
torch.nn.GroupNorm.reset_parameters(self)->None
torch.nn.LayerNorm(self,normalized_shape:_shape_t,eps:float=1e-05,elementwise_affine:bool=True)
torch.nn.LayerNorm.extra_repr(self)->Tensor
torch.nn.LayerNorm.forward(self,input:Tensor)->Tensor
torch.nn.LayerNorm.reset_parameters(self)->None
torch.nn.LocalResponseNorm(self,size:int,alpha:float=0.0001,beta:float=0.75,k:float=1.0)
torch.nn.LocalResponseNorm.extra_repr(self)
torch.nn.LocalResponseNorm.forward(self,input:Tensor)->Tensor
torch.nn.modules.normalization.CrossMapLRN2d(self,size:int,alpha:float=0.0001,beta:float=0.75,k:float=1)
torch.nn.modules.normalization.CrossMapLRN2d.__init__(self,size:int,alpha:float=0.0001,beta:float=0.75,k:float=1)
torch.nn.modules.normalization.CrossMapLRN2d.extra_repr(self)->str
torch.nn.modules.normalization.CrossMapLRN2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.normalization.GroupNorm(self,num_groups:int,num_channels:int,eps:float=1e-05,affine:bool=True)
torch.nn.modules.normalization.GroupNorm.__init__(self,num_groups:int,num_channels:int,eps:float=1e-05,affine:bool=True)
torch.nn.modules.normalization.GroupNorm.extra_repr(self)->str
torch.nn.modules.normalization.GroupNorm.forward(self,input:Tensor)->Tensor
torch.nn.modules.normalization.GroupNorm.reset_parameters(self)->None
torch.nn.modules.normalization.LayerNorm(self,normalized_shape:_shape_t,eps:float=1e-05,elementwise_affine:bool=True)
torch.nn.modules.normalization.LayerNorm.__init__(self,normalized_shape:_shape_t,eps:float=1e-05,elementwise_affine:bool=True)
torch.nn.modules.normalization.LayerNorm.extra_repr(self)->Tensor
torch.nn.modules.normalization.LayerNorm.forward(self,input:Tensor)->Tensor
torch.nn.modules.normalization.LayerNorm.reset_parameters(self)->None
torch.nn.modules.normalization.LocalResponseNorm(self,size:int,alpha:float=0.0001,beta:float=0.75,k:float=1.0)
torch.nn.modules.normalization.LocalResponseNorm.__init__(self,size:int,alpha:float=0.0001,beta:float=0.75,k:float=1.0)
torch.nn.modules.normalization.LocalResponseNorm.extra_repr(self)
torch.nn.modules.normalization.LocalResponseNorm.forward(self,input:Tensor)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/modules/conv.py----------------------------------------
A:torch.nn.modules.conv.self._reversed_padding_repeated_twice->_reverse_repeat_tuple(self.padding, 2)
A:torch.nn.modules.conv.self.weight->Parameter(torch.Tensor(out_channels, in_channels // groups, *kernel_size))
A:torch.nn.modules.conv.self.bias->Parameter(torch.Tensor(out_channels))
A:torch.nn.modules.conv.(fan_in, _)->init._calculate_fan_in_and_fan_out(self.weight)
A:torch.nn.modules.conv.kernel_size->_triple(kernel_size)
A:torch.nn.modules.conv.stride->_triple(stride)
A:torch.nn.modules.conv.padding->_triple(padding)
A:torch.nn.modules.conv.dilation->_triple(dilation)
A:torch.nn.modules.conv.ret->_single(self.output_padding)
A:torch.nn.modules.conv.min_sizes->torch.jit.annotate(List[int], [])
A:torch.nn.modules.conv.max_sizes->torch.jit.annotate(List[int], [])
A:torch.nn.modules.conv.res->torch.jit.annotate(List[int], [])
A:torch.nn.modules.conv.output_padding->self._output_padding(input, output_size, self.stride, self.padding, self.kernel_size, self.dilation)
torch.nn.Conv1d(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t=1,padding:_size_1_t=0,dilation:_size_1_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.Conv1d.forward(self,input:Tensor)->Tensor
torch.nn.Conv2d(self,in_channels:int,out_channels:int,kernel_size:_size_2_t,stride:_size_2_t=1,padding:_size_2_t=0,dilation:_size_2_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.Conv2d._conv_forward(self,input,weight)
torch.nn.Conv2d.forward(self,input:Tensor)->Tensor
torch.nn.Conv3d(self,in_channels:int,out_channels:int,kernel_size:_size_3_t,stride:_size_3_t=1,padding:_size_3_t=0,dilation:_size_3_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.Conv3d.forward(self,input:Tensor)->Tensor
torch.nn.ConvTranspose1d(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t=1,padding:_size_1_t=0,output_padding:_size_1_t=0,groups:int=1,bias:bool=True,dilation:_size_1_t=1,padding_mode:str='zeros')
torch.nn.ConvTranspose1d.forward(self,input:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.ConvTranspose2d(self,in_channels:int,out_channels:int,kernel_size:_size_2_t,stride:_size_2_t=1,padding:_size_2_t=0,output_padding:_size_2_t=0,groups:int=1,bias:bool=True,dilation:int=1,padding_mode:str='zeros')
torch.nn.ConvTranspose2d.forward(self,input:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.ConvTranspose3d(self,in_channels:int,out_channels:int,kernel_size:_size_3_t,stride:_size_3_t=1,padding:_size_3_t=0,output_padding:_size_3_t=0,groups:int=1,bias:bool=True,dilation:_size_3_t=1,padding_mode:str='zeros')
torch.nn.ConvTranspose3d.forward(self,input:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.conv._ConvNd(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t,padding:_size_1_t,dilation:_size_1_t,transposed:bool,output_padding:_size_1_t,groups:int,bias:Optional[Tensor],padding_mode:str)
torch.nn.conv._ConvNd.__setstate__(self,state)
torch.nn.conv._ConvNd.extra_repr(self)
torch.nn.conv._ConvNd.reset_parameters(self)->None
torch.nn.conv._ConvTransposeMixin(self,*args,**kwargs)
torch.nn.conv._ConvTransposeNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode)
torch.nn.conv._ConvTransposeNd._output_padding(self,input,output_size,stride,padding,kernel_size,dilation=None)
torch.nn.modules.conv.Conv1d(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t=1,padding:_size_1_t=0,dilation:_size_1_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.modules.conv.Conv1d.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t=1,padding:_size_1_t=0,dilation:_size_1_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.modules.conv.Conv1d.forward(self,input:Tensor)->Tensor
torch.nn.modules.conv.Conv2d(self,in_channels:int,out_channels:int,kernel_size:_size_2_t,stride:_size_2_t=1,padding:_size_2_t=0,dilation:_size_2_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.modules.conv.Conv2d.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_2_t,stride:_size_2_t=1,padding:_size_2_t=0,dilation:_size_2_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.modules.conv.Conv2d._conv_forward(self,input,weight)
torch.nn.modules.conv.Conv2d.forward(self,input:Tensor)->Tensor
torch.nn.modules.conv.Conv3d(self,in_channels:int,out_channels:int,kernel_size:_size_3_t,stride:_size_3_t=1,padding:_size_3_t=0,dilation:_size_3_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.modules.conv.Conv3d.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_3_t,stride:_size_3_t=1,padding:_size_3_t=0,dilation:_size_3_t=1,groups:int=1,bias:bool=True,padding_mode:str='zeros')
torch.nn.modules.conv.Conv3d.forward(self,input:Tensor)->Tensor
torch.nn.modules.conv.ConvTranspose1d(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t=1,padding:_size_1_t=0,output_padding:_size_1_t=0,groups:int=1,bias:bool=True,dilation:_size_1_t=1,padding_mode:str='zeros')
torch.nn.modules.conv.ConvTranspose1d.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t=1,padding:_size_1_t=0,output_padding:_size_1_t=0,groups:int=1,bias:bool=True,dilation:_size_1_t=1,padding_mode:str='zeros')
torch.nn.modules.conv.ConvTranspose1d.forward(self,input:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.conv.ConvTranspose2d(self,in_channels:int,out_channels:int,kernel_size:_size_2_t,stride:_size_2_t=1,padding:_size_2_t=0,output_padding:_size_2_t=0,groups:int=1,bias:bool=True,dilation:int=1,padding_mode:str='zeros')
torch.nn.modules.conv.ConvTranspose2d.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_2_t,stride:_size_2_t=1,padding:_size_2_t=0,output_padding:_size_2_t=0,groups:int=1,bias:bool=True,dilation:int=1,padding_mode:str='zeros')
torch.nn.modules.conv.ConvTranspose2d.forward(self,input:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.conv.ConvTranspose3d(self,in_channels:int,out_channels:int,kernel_size:_size_3_t,stride:_size_3_t=1,padding:_size_3_t=0,output_padding:_size_3_t=0,groups:int=1,bias:bool=True,dilation:_size_3_t=1,padding_mode:str='zeros')
torch.nn.modules.conv.ConvTranspose3d.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_3_t,stride:_size_3_t=1,padding:_size_3_t=0,output_padding:_size_3_t=0,groups:int=1,bias:bool=True,dilation:_size_3_t=1,padding_mode:str='zeros')
torch.nn.modules.conv.ConvTranspose3d.forward(self,input:Tensor,output_size:Optional[List[int]]=None)->Tensor
torch.nn.modules.conv._ConvNd(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t,padding:_size_1_t,dilation:_size_1_t,transposed:bool,output_padding:_size_1_t,groups:int,bias:Optional[Tensor],padding_mode:str)
torch.nn.modules.conv._ConvNd.__init__(self,in_channels:int,out_channels:int,kernel_size:_size_1_t,stride:_size_1_t,padding:_size_1_t,dilation:_size_1_t,transposed:bool,output_padding:_size_1_t,groups:int,bias:Optional[Tensor],padding_mode:str)
torch.nn.modules.conv._ConvNd.__setstate__(self,state)
torch.nn.modules.conv._ConvNd.extra_repr(self)
torch.nn.modules.conv._ConvNd.reset_parameters(self)->None
torch.nn.modules.conv._ConvTransposeMixin(self,*args,**kwargs)
torch.nn.modules.conv._ConvTransposeMixin.__init__(self,*args,**kwargs)
torch.nn.modules.conv._ConvTransposeNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode)
torch.nn.modules.conv._ConvTransposeNd.__init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode)
torch.nn.modules.conv._ConvTransposeNd._output_padding(self,input,output_size,stride,padding,kernel_size,dilation=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/qat/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/qat/modules/linear.py----------------------------------------
A:torch.nn.qat.modules.linear.self.weight_fake_quant->qconfig.weight()
A:torch.nn.qat.modules.linear.qat_linear->cls(mod.in_features, mod.out_features, bias=mod.bias is not None, qconfig=qconfig)
torch.nn.qat.Linear(self,in_features,out_features,bias=True,qconfig=None)
torch.nn.qat.Linear.forward(self,input)
torch.nn.qat.Linear.from_float(cls,mod)
torch.nn.qat.modules.linear.Linear(self,in_features,out_features,bias=True,qconfig=None)
torch.nn.qat.modules.linear.Linear.__init__(self,in_features,out_features,bias=True,qconfig=None)
torch.nn.qat.modules.linear.Linear.forward(self,input)
torch.nn.qat.modules.linear.Linear.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/qat/modules/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/qat/modules/conv.py----------------------------------------
A:torch.nn.qat.modules.conv.self.weight_fake_quant->qconfig.weight()
A:torch.nn.qat.modules.conv.qat_conv->cls(mod.in_channels, mod.out_channels, mod.kernel_size, stride=mod.stride, padding=mod.padding, dilation=mod.dilation, groups=mod.groups, bias=mod.bias is not None, padding_mode=mod.padding_mode, qconfig=qconfig)
torch.nn.qat.Conv2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)
torch.nn.qat.Conv2d.forward(self,input)
torch.nn.qat.Conv2d.from_float(cls,mod)
torch.nn.qat.modules.conv.Conv2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)
torch.nn.qat.modules.conv.Conv2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)
torch.nn.qat.modules.conv.Conv2d.forward(self,input)
torch.nn.qat.modules.conv.Conv2d.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/functional.py----------------------------------------
A:torch.nn.quantized.functional.stride->torch.jit.annotate(List[int], [])
A:torch.nn.quantized.functional.padding->_triple(padding)
A:torch.nn.quantized.functional.dilation->_triple(dilation)
A:torch.nn.quantized.functional.packed_params->torch.ops.quantized.conv3d_prepack(weight, bias, stride, padding, dilation, groups)
A:torch.nn.quantized.functional.scale->input.q_scale()
A:torch.nn.quantized.functional.zero_point->input.q_zero_point()
A:torch.nn.quantized.functional._packed_params->torch.ops.quantized.linear_prepack(weight, bias)
A:torch.nn.quantized.functional.output->torch._empty_affine_quantized(input.shape, scale=scale, zero_point=int(zero_point), dtype=input.dtype)
A:torch.nn.quantized.functional.result->torch._C._nn.leaky_relu(input, negative_slope)
torch.nn.quantized.adaptive_avg_pool2d(input:Tensor,output_size:BroadcastingList2[int])->Tensor
torch.nn.quantized.adaptive_avg_pool3d(input:Tensor,output_size:BroadcastingList2[int])->Tensor
torch.nn.quantized.avg_pool2d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)
torch.nn.quantized.avg_pool3d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)
torch.nn.quantized.celu(input:Tensor,scale:float,zero_point:int,alpha:Optional[float]=1.0)->Tensor
torch.nn.quantized.clamp(input:Tensor,min_:float,max_:float)->Tensor
torch.nn.quantized.conv1d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)
torch.nn.quantized.conv2d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)
torch.nn.quantized.conv3d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)
torch.nn.quantized.elu(input:Tensor,scale:float,zero_point:int,alpha:float=1.0)->Tensor
torch.nn.quantized.functional.adaptive_avg_pool2d(input:Tensor,output_size:BroadcastingList2[int])->Tensor
torch.nn.quantized.functional.adaptive_avg_pool3d(input:Tensor,output_size:BroadcastingList2[int])->Tensor
torch.nn.quantized.functional.avg_pool2d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)
torch.nn.quantized.functional.avg_pool3d(input,kernel_size,stride=None,padding=0,ceil_mode=False,count_include_pad=True,divisor_override=None)
torch.nn.quantized.functional.celu(input:Tensor,scale:float,zero_point:int,alpha:Optional[float]=1.0)->Tensor
torch.nn.quantized.functional.clamp(input:Tensor,min_:float,max_:float)->Tensor
torch.nn.quantized.functional.conv1d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)
torch.nn.quantized.functional.conv2d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)
torch.nn.quantized.functional.conv3d(input,weight,bias,stride=1,padding=0,dilation=1,groups=1,padding_mode='zeros',scale=1.0,zero_point=0,dtype=torch.quint8)
torch.nn.quantized.functional.elu(input:Tensor,scale:float,zero_point:int,alpha:float=1.0)->Tensor
torch.nn.quantized.functional.hardsigmoid(input:Tensor)->Tensor
torch.nn.quantized.functional.hardswish(input:Tensor,scale:float,zero_point:int)->Tensor
torch.nn.quantized.functional.hardtanh(input:Tensor,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False)->Tensor
torch.nn.quantized.functional.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None)
torch.nn.quantized.functional.leaky_relu(input:Tensor,negative_slope:float=0.01,inplace:bool=False,scale:float=None,zero_point:int=None)
torch.nn.quantized.functional.linear(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,scale:Optional[float]=None,zero_point:Optional[int]=None)->Tensor
torch.nn.quantized.functional.max_pool1d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.quantized.functional.max_pool2d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.quantized.functional.relu(input:Tensor,inplace:bool=False)->Tensor
torch.nn.quantized.functional.threshold(input:Tensor,threshold:float,value:float)->Tensor
torch.nn.quantized.functional.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)
torch.nn.quantized.functional.upsample_bilinear(input,size=None,scale_factor=None)
torch.nn.quantized.functional.upsample_nearest(input,size=None,scale_factor=None)
torch.nn.quantized.hardsigmoid(input:Tensor)->Tensor
torch.nn.quantized.hardswish(input:Tensor,scale:float,zero_point:int)->Tensor
torch.nn.quantized.hardtanh(input:Tensor,min_val:float=-1.0,max_val:float=1.0,inplace:bool=False)->Tensor
torch.nn.quantized.interpolate(input,size=None,scale_factor=None,mode='nearest',align_corners=None)
torch.nn.quantized.leaky_relu(input:Tensor,negative_slope:float=0.01,inplace:bool=False,scale:float=None,zero_point:int=None)
torch.nn.quantized.linear(input:Tensor,weight:Tensor,bias:Optional[Tensor]=None,scale:Optional[float]=None,zero_point:Optional[int]=None)->Tensor
torch.nn.quantized.max_pool1d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.quantized.max_pool2d(input,kernel_size,stride=None,padding=0,dilation=1,ceil_mode=False,return_indices=False)
torch.nn.quantized.relu(input:Tensor,inplace:bool=False)->Tensor
torch.nn.quantized.threshold(input:Tensor,threshold:float,value:float)->Tensor
torch.nn.quantized.upsample(input,size=None,scale_factor=None,mode='nearest',align_corners=None)
torch.nn.quantized.upsample_bilinear(input,size=None,scale_factor=None)
torch.nn.quantized.upsample_nearest(input,size=None,scale_factor=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/embedding_ops.py----------------------------------------
A:torch.nn.quantized.modules.embedding_ops.scales->torch.ones(num_embeddings, dtype=torch.float)
A:torch.nn.quantized.modules.embedding_ops.zero_points->torch.zeros(num_embeddings, dtype=torch.float)
A:torch.nn.quantized.modules.embedding_ops.wq->torch._empty_per_channel_affine_quantized([num_embeddings, embedding_dim], scales=scales, zero_points=zero_points, axis=0, dtype=torch.quint8)
A:torch.nn.quantized.modules.embedding_ops.self._packed_weight->torch.ops.quantized.embedding_bag_prepack(weight)
A:torch.nn.quantized.modules.embedding_ops.destination[prefix + '_packed_weight']->self._weight()
A:torch.nn.quantized.modules.embedding_ops.version->local_metadata.get('version', None)
A:torch.nn.quantized.modules.embedding_ops.self.qweight->torch._empty_per_channel_affine_quantized([num_embeddings, embedding_dim], scales=scales, zero_points=zero_points, axis=0, dtype=torch.quint8)
A:torch.nn.quantized.modules.embedding_ops.self._packed_params->EmbeddingPackedParams(num_embeddings, embedding_dim, dtype)
A:torch.nn.quantized.modules.embedding_ops.extra_repr_str->'num_embeddings={}, embedding_dim={}, dtype={}, qscheme={}'.format(self.num_embeddings, self.embedding_dim, self._packed_params.dtype, self.qweight.qscheme())
A:torch.nn.quantized.modules.embedding_ops.weight_observer->torch.quantization.qconfig.float_qparams_dynamic_qconfig.weight()
A:torch.nn.quantized.modules.embedding_ops.qweight->_quantize_weight(mod.weight.float(), weight_observer)
A:torch.nn.quantized.modules.embedding_ops.qembedding->Embedding(mod.num_embeddings, mod.embedding_dim)
A:torch.nn.quantized.modules.embedding_ops.qembedding_bag->EmbeddingBag(mod.num_embeddings, mod.embedding_dim)
torch.nn.quantized.Embedding(self,num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[Tensor]=None,dtype=torch.quint8)
torch.nn.quantized.Embedding.__repr__(self)
torch.nn.quantized.Embedding._get_name(self)
torch.nn.quantized.Embedding.extra_repr(self)
torch.nn.quantized.Embedding.forward(self,indices:Tensor)->Tensor
torch.nn.quantized.Embedding.from_float(cls,mod)
torch.nn.quantized.Embedding.set_weight(self,w)
torch.nn.quantized.Embedding.weight(self)
torch.nn.quantized.EmbeddingBag(self,num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='sum',sparse:bool=False,_weight:Optional[Tensor]=None,include_last_offset:bool=False,dtype=torch.quint8)
torch.nn.quantized.EmbeddingBag._get_name(self)
torch.nn.quantized.EmbeddingBag.forward(self,indices:Tensor,offsets:Optional[Tensor]=None,per_sample_weights:Optional[Tensor]=None,compressed_indices_mapping:Optional[Tensor]=None)->Tensor
torch.nn.quantized.EmbeddingBag.from_float(cls,mod)
torch.nn.quantized.EmbeddingPackedParams(self,num_embeddings,embedding_dim,dtype=torch.quint8)
torch.nn.quantized.EmbeddingPackedParams.__repr__(self)
torch.nn.quantized.EmbeddingPackedParams._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.EmbeddingPackedParams._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.EmbeddingPackedParams._weight(self)
torch.nn.quantized.EmbeddingPackedParams.forward(self,x)
torch.nn.quantized.EmbeddingPackedParams.set_weight(self,weight)
torch.nn.quantized.modules.embedding_ops.Embedding(self,num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[Tensor]=None,dtype=torch.quint8)
torch.nn.quantized.modules.embedding_ops.Embedding.__init__(self,num_embeddings:int,embedding_dim:int,padding_idx:Optional[int]=None,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,sparse:bool=False,_weight:Optional[Tensor]=None,dtype=torch.quint8)
torch.nn.quantized.modules.embedding_ops.Embedding.__repr__(self)
torch.nn.quantized.modules.embedding_ops.Embedding._get_name(self)
torch.nn.quantized.modules.embedding_ops.Embedding.extra_repr(self)
torch.nn.quantized.modules.embedding_ops.Embedding.forward(self,indices:Tensor)->Tensor
torch.nn.quantized.modules.embedding_ops.Embedding.from_float(cls,mod)
torch.nn.quantized.modules.embedding_ops.Embedding.set_weight(self,w)
torch.nn.quantized.modules.embedding_ops.Embedding.weight(self)
torch.nn.quantized.modules.embedding_ops.EmbeddingBag(self,num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='sum',sparse:bool=False,_weight:Optional[Tensor]=None,include_last_offset:bool=False,dtype=torch.quint8)
torch.nn.quantized.modules.embedding_ops.EmbeddingBag.__init__(self,num_embeddings:int,embedding_dim:int,max_norm:Optional[float]=None,norm_type:float=2.0,scale_grad_by_freq:bool=False,mode:str='sum',sparse:bool=False,_weight:Optional[Tensor]=None,include_last_offset:bool=False,dtype=torch.quint8)
torch.nn.quantized.modules.embedding_ops.EmbeddingBag._get_name(self)
torch.nn.quantized.modules.embedding_ops.EmbeddingBag.forward(self,indices:Tensor,offsets:Optional[Tensor]=None,per_sample_weights:Optional[Tensor]=None,compressed_indices_mapping:Optional[Tensor]=None)->Tensor
torch.nn.quantized.modules.embedding_ops.EmbeddingBag.from_float(cls,mod)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams(self,num_embeddings,embedding_dim,dtype=torch.quint8)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams.__init__(self,num_embeddings,embedding_dim,dtype=torch.quint8)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams.__repr__(self)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams._weight(self)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams.forward(self,x)
torch.nn.quantized.modules.embedding_ops.EmbeddingPackedParams.set_weight(self,weight)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/activation.py----------------------------------------
A:torch.nn.quantized.modules.activation.(scale, zero_point)->mod.activation_post_process.calculate_qparams()
torch.nn.quantized.ELU(self,scale,zero_point,alpha=1.0)
torch.nn.quantized.ELU._get_name(self)
torch.nn.quantized.ELU.forward(self,input)
torch.nn.quantized.ELU.from_float(mod)
torch.nn.quantized.Hardswish(self,scale,zero_point)
torch.nn.quantized.Hardswish._get_name(self)
torch.nn.quantized.Hardswish.forward(self,input)
torch.nn.quantized.Hardswish.from_float(mod)
torch.nn.quantized.ReLU(self,inplace=False)
torch.nn.quantized.ReLU._get_name(self)
torch.nn.quantized.ReLU.forward(self,input)
torch.nn.quantized.ReLU.from_float(mod)
torch.nn.quantized.ReLU6(self,inplace=False)
torch.nn.quantized.ReLU6._get_name(self)
torch.nn.quantized.ReLU6.forward(self,input)
torch.nn.quantized.ReLU6.from_float(mod)
torch.nn.quantized.modules.activation.ELU(self,scale,zero_point,alpha=1.0)
torch.nn.quantized.modules.activation.ELU.__init__(self,scale,zero_point,alpha=1.0)
torch.nn.quantized.modules.activation.ELU._get_name(self)
torch.nn.quantized.modules.activation.ELU.forward(self,input)
torch.nn.quantized.modules.activation.ELU.from_float(mod)
torch.nn.quantized.modules.activation.Hardswish(self,scale,zero_point)
torch.nn.quantized.modules.activation.Hardswish.__init__(self,scale,zero_point)
torch.nn.quantized.modules.activation.Hardswish._get_name(self)
torch.nn.quantized.modules.activation.Hardswish.forward(self,input)
torch.nn.quantized.modules.activation.Hardswish.from_float(mod)
torch.nn.quantized.modules.activation.ReLU(self,inplace=False)
torch.nn.quantized.modules.activation.ReLU.__init__(self,inplace=False)
torch.nn.quantized.modules.activation.ReLU._get_name(self)
torch.nn.quantized.modules.activation.ReLU.forward(self,input)
torch.nn.quantized.modules.activation.ReLU.from_float(mod)
torch.nn.quantized.modules.activation.ReLU6(self,inplace=False)
torch.nn.quantized.modules.activation.ReLU6.__init__(self,inplace=False)
torch.nn.quantized.modules.activation.ReLU6._get_name(self)
torch.nn.quantized.modules.activation.ReLU6.forward(self,input)
torch.nn.quantized.modules.activation.ReLU6.from_float(mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/utils.py----------------------------------------
A:torch.nn.quantized.modules.utils.(wt_scale, wt_zp)->observer.calculate_qparams()
A:torch.nn.quantized.modules.utils.qweight->torch.quantize_per_channel(float_wt, wt_scale.to(torch.float), wt_zp.to(torch.float), observer.ch_axis, torch.quint8)
A:torch.nn.quantized.modules.utils.extra_repr->self.extra_repr()
A:torch.nn.quantized.modules.utils.extra_lines->self.extra_repr().split('\n')
A:torch.nn.quantized.modules.utils.mod_str->_addindent(mod_str, 2)
A:torch.nn.quantized.modules.utils._pair_from_first->_ntuple_from_first(2)
torch.nn.quantized.modules.utils._ntuple_from_first(n)
torch.nn.quantized.modules.utils._quantize_weight(float_wt,observer)
torch.nn.quantized.modules.utils.hide_packed_params_repr(self,params)
torch.nn.quantized.utils._ntuple_from_first(n)
torch.nn.quantized.utils._quantize_weight(float_wt,observer)
torch.nn.quantized.utils.hide_packed_params_repr(self,params)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/linear.py----------------------------------------
A:torch.nn.quantized.modules.linear.wq->torch.zeros([1, 1], dtype=torch.float)
A:torch.nn.quantized.modules.linear.self._packed_params->LinearPackedParams(dtype)
A:torch.nn.quantized.modules.linear.destination[prefix + '_packed_params']->self._weight_bias()
A:torch.nn.quantized.modules.linear.version->local_metadata.get('version', None)
A:torch.nn.quantized.modules.linear.(qweight, bias)->self._weight_bias()
A:torch.nn.quantized.modules.linear.bias->state_dict.pop(prefix + 'bias')
A:torch.nn.quantized.modules.linear.qweight->_quantize_weight(mod.weight.float(), weight_post_process)
A:torch.nn.quantized.modules.linear.destination[prefix + 'scale']->torch.tensor(self.scale)
A:torch.nn.quantized.modules.linear.destination[prefix + 'zero_point']->torch.tensor(self.zero_point)
A:torch.nn.quantized.modules.linear.self.scale->float(state_dict[prefix + 'scale'])
A:torch.nn.quantized.modules.linear.self.zero_point->int(state_dict[prefix + 'zero_point'])
A:torch.nn.quantized.modules.linear.weight->state_dict.pop(prefix + 'weight')
A:torch.nn.quantized.modules.linear.weight_post_process->mod.qconfig.weight()
A:torch.nn.quantized.modules.linear.(act_scale, act_zp)->activation_post_process.calculate_qparams()
A:torch.nn.quantized.modules.linear.qlinear->cls(mod.in_features, mod.out_features, dtype=dtype)
A:torch.nn.quantized.modules.linear.qlinear.scale->float(act_scale)
A:torch.nn.quantized.modules.linear.qlinear.zero_point->int(act_zp)
torch.nn.quantized.Linear(self,in_features,out_features,bias_=True,dtype=torch.qint8)
torch.nn.quantized.Linear.__repr__(self)
torch.nn.quantized.Linear._get_name(self)
torch.nn.quantized.Linear._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.Linear._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.Linear._weight_bias(self)
torch.nn.quantized.Linear.bias(self)
torch.nn.quantized.Linear.extra_repr(self)
torch.nn.quantized.Linear.forward(self,x)
torch.nn.quantized.Linear.from_float(cls,mod)
torch.nn.quantized.Linear.set_weight_bias(self,w:torch.Tensor,b:Optional[torch.Tensor])->None
torch.nn.quantized.Linear.weight(self)
torch.nn.quantized.LinearPackedParams(self,dtype=torch.qint8)
torch.nn.quantized.LinearPackedParams.__getstate__(self)
torch.nn.quantized.LinearPackedParams.__repr__(self)
torch.nn.quantized.LinearPackedParams.__setstate__(self,state)
torch.nn.quantized.LinearPackedParams._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.LinearPackedParams._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.LinearPackedParams._weight_bias(self)
torch.nn.quantized.LinearPackedParams.forward(self,x)
torch.nn.quantized.LinearPackedParams.set_weight_bias(self,weight:torch.Tensor,bias:Optional[torch.Tensor])->None
torch.nn.quantized.modules.linear.Linear(self,in_features,out_features,bias_=True,dtype=torch.qint8)
torch.nn.quantized.modules.linear.Linear.__init__(self,in_features,out_features,bias_=True,dtype=torch.qint8)
torch.nn.quantized.modules.linear.Linear.__repr__(self)
torch.nn.quantized.modules.linear.Linear._get_name(self)
torch.nn.quantized.modules.linear.Linear._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.modules.linear.Linear._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.modules.linear.Linear._weight_bias(self)
torch.nn.quantized.modules.linear.Linear.bias(self)
torch.nn.quantized.modules.linear.Linear.extra_repr(self)
torch.nn.quantized.modules.linear.Linear.forward(self,x)
torch.nn.quantized.modules.linear.Linear.from_float(cls,mod)
torch.nn.quantized.modules.linear.Linear.set_weight_bias(self,w:torch.Tensor,b:Optional[torch.Tensor])->None
torch.nn.quantized.modules.linear.Linear.weight(self)
torch.nn.quantized.modules.linear.LinearPackedParams(self,dtype=torch.qint8)
torch.nn.quantized.modules.linear.LinearPackedParams.__getstate__(self)
torch.nn.quantized.modules.linear.LinearPackedParams.__init__(self,dtype=torch.qint8)
torch.nn.quantized.modules.linear.LinearPackedParams.__repr__(self)
torch.nn.quantized.modules.linear.LinearPackedParams.__setstate__(self,state)
torch.nn.quantized.modules.linear.LinearPackedParams._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.modules.linear.LinearPackedParams._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.modules.linear.LinearPackedParams._weight_bias(self)
torch.nn.quantized.modules.linear.LinearPackedParams.forward(self,x)
torch.nn.quantized.modules.linear.LinearPackedParams.set_weight_bias(self,weight:torch.Tensor,bias:Optional[torch.Tensor])->None


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/functional_modules.py----------------------------------------
A:torch.nn.quantized.modules.functional_modules.self.activation_post_process->torch.nn.Identity()
A:torch.nn.quantized.modules.functional_modules.r->self.activation_post_process(r)
A:torch.nn.quantized.modules.functional_modules.destination[prefix + 'scale']->torch.tensor(self.scale)
A:torch.nn.quantized.modules.functional_modules.destination[prefix + 'zero_point']->torch.tensor(self.zero_point)
A:torch.nn.quantized.modules.functional_modules.self.scale->float(state_dict.pop(prefix + 'scale'))
A:torch.nn.quantized.modules.functional_modules.self.zero_point->int(state_dict.pop(prefix + 'zero_point'))
A:torch.nn.quantized.modules.functional_modules.(scale, zero_point)->mod.activation_post_process.calculate_qparams()
A:torch.nn.quantized.modules.functional_modules.new_mod->QFunctional()
A:torch.nn.quantized.modules.functional_modules.new_mod.scale->float(scale)
A:torch.nn.quantized.modules.functional_modules.new_mod.zero_point->int(zero_point)
torch.nn.quantized.FloatFunctional(self)
torch.nn.quantized.FloatFunctional.add(self,x,y)
torch.nn.quantized.FloatFunctional.add_relu(self,x,y)
torch.nn.quantized.FloatFunctional.add_scalar(self,x,y)
torch.nn.quantized.FloatFunctional.cat(self,x,dim=0)
torch.nn.quantized.FloatFunctional.forward(self,x)
torch.nn.quantized.FloatFunctional.mul(self,x,y)
torch.nn.quantized.FloatFunctional.mul_scalar(self,x,y)
torch.nn.quantized.QFunctional(self)
torch.nn.quantized.QFunctional._get_name(self)
torch.nn.quantized.QFunctional._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.QFunctional._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.QFunctional.add(self,x,y)
torch.nn.quantized.QFunctional.add_relu(self,x,y)
torch.nn.quantized.QFunctional.add_scalar(self,x,y)
torch.nn.quantized.QFunctional.cat(self,x,dim=0)
torch.nn.quantized.QFunctional.extra_repr(self)
torch.nn.quantized.QFunctional.forward(self,x)
torch.nn.quantized.QFunctional.from_float(cls,mod)
torch.nn.quantized.QFunctional.mul(self,x,y)
torch.nn.quantized.QFunctional.mul_scalar(self,x,y)
torch.nn.quantized.modules.functional_modules.FloatFunctional(self)
torch.nn.quantized.modules.functional_modules.FloatFunctional.__init__(self)
torch.nn.quantized.modules.functional_modules.FloatFunctional.add(self,x,y)
torch.nn.quantized.modules.functional_modules.FloatFunctional.add_relu(self,x,y)
torch.nn.quantized.modules.functional_modules.FloatFunctional.add_scalar(self,x,y)
torch.nn.quantized.modules.functional_modules.FloatFunctional.cat(self,x,dim=0)
torch.nn.quantized.modules.functional_modules.FloatFunctional.forward(self,x)
torch.nn.quantized.modules.functional_modules.FloatFunctional.mul(self,x,y)
torch.nn.quantized.modules.functional_modules.FloatFunctional.mul_scalar(self,x,y)
torch.nn.quantized.modules.functional_modules.QFunctional(self)
torch.nn.quantized.modules.functional_modules.QFunctional.__init__(self)
torch.nn.quantized.modules.functional_modules.QFunctional._get_name(self)
torch.nn.quantized.modules.functional_modules.QFunctional._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.modules.functional_modules.QFunctional._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.modules.functional_modules.QFunctional.add(self,x,y)
torch.nn.quantized.modules.functional_modules.QFunctional.add_relu(self,x,y)
torch.nn.quantized.modules.functional_modules.QFunctional.add_scalar(self,x,y)
torch.nn.quantized.modules.functional_modules.QFunctional.cat(self,x,dim=0)
torch.nn.quantized.modules.functional_modules.QFunctional.extra_repr(self)
torch.nn.quantized.modules.functional_modules.QFunctional.forward(self,x)
torch.nn.quantized.modules.functional_modules.QFunctional.from_float(cls,mod)
torch.nn.quantized.modules.functional_modules.QFunctional.mul(self,x,y)
torch.nn.quantized.modules.functional_modules.QFunctional.mul_scalar(self,x,y)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/batchnorm.py----------------------------------------
A:torch.nn.quantized.modules.batchnorm.(scale, zero_point)->activation_post_process.calculate_qparams()
A:torch.nn.quantized.modules.batchnorm.new_mod->cls(mod.num_features, mod.eps)
A:torch.nn.quantized.modules.batchnorm.new_mod.scale->float(scale)
A:torch.nn.quantized.modules.batchnorm.new_mod.zero_point->int(zero_point)
torch.nn.quantized.BatchNorm2d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.quantized.BatchNorm2d._get_name(self)
torch.nn.quantized.BatchNorm2d.forward(self,input)
torch.nn.quantized.BatchNorm2d.from_float(cls,mod)
torch.nn.quantized.BatchNorm3d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.quantized.BatchNorm3d._get_name(self)
torch.nn.quantized.BatchNorm3d.forward(self,input)
torch.nn.quantized.BatchNorm3d.from_float(cls,mod)
torch.nn.quantized.modules.batchnorm.BatchNorm2d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.quantized.modules.batchnorm.BatchNorm2d.__init__(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.quantized.modules.batchnorm.BatchNorm2d._get_name(self)
torch.nn.quantized.modules.batchnorm.BatchNorm2d.forward(self,input)
torch.nn.quantized.modules.batchnorm.BatchNorm2d.from_float(cls,mod)
torch.nn.quantized.modules.batchnorm.BatchNorm3d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.quantized.modules.batchnorm.BatchNorm3d.__init__(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.quantized.modules.batchnorm.BatchNorm3d._get_name(self)
torch.nn.quantized.modules.batchnorm.BatchNorm3d.forward(self,input)
torch.nn.quantized.modules.batchnorm.BatchNorm3d.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/__init__.py----------------------------------------
A:torch.nn.quantized.modules.__init__.(scale, zero_point)->mod.activation_post_process.calculate_qparams()
torch.nn.quantized.__init__.DeQuantize(self)
torch.nn.quantized.__init__.DeQuantize.forward(self,Xq)
torch.nn.quantized.__init__.DeQuantize.from_float(mod)
torch.nn.quantized.__init__.Quantize(self,scale,zero_point,dtype)
torch.nn.quantized.__init__.Quantize.extra_repr(self)
torch.nn.quantized.__init__.Quantize.forward(self,X)
torch.nn.quantized.__init__.Quantize.from_float(mod)
torch.nn.quantized.modules.__init__.DeQuantize(self)
torch.nn.quantized.modules.__init__.DeQuantize.__init__(self)
torch.nn.quantized.modules.__init__.DeQuantize.forward(self,Xq)
torch.nn.quantized.modules.__init__.DeQuantize.from_float(mod)
torch.nn.quantized.modules.__init__.Quantize(self,scale,zero_point,dtype)
torch.nn.quantized.modules.__init__.Quantize.__init__(self,scale,zero_point,dtype)
torch.nn.quantized.modules.__init__.Quantize.extra_repr(self)
torch.nn.quantized.modules.__init__.Quantize.forward(self,X)
torch.nn.quantized.modules.__init__.Quantize.from_float(mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/normalization.py----------------------------------------
A:torch.nn.quantized.modules.normalization.(scale, zero_point)->mod.activation_post_process.calculate_qparams()
A:torch.nn.quantized.modules.normalization.new_mod->cls(mod.num_features, mod.weight, mod.bias, float(scale), int(zero_point), mod.eps, mod.affine)
torch.nn.quantized.GroupNorm(self,num_groups,num_channels,weight,bias,scale,zero_point,eps=1e-05,affine=True)
torch.nn.quantized.GroupNorm._get_name(self)
torch.nn.quantized.GroupNorm.forward(self,input)
torch.nn.quantized.GroupNorm.from_float(cls,mod)
torch.nn.quantized.InstanceNorm1d(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.InstanceNorm1d._get_name(self)
torch.nn.quantized.InstanceNorm1d.forward(self,input)
torch.nn.quantized.InstanceNorm1d.from_float(cls,mod)
torch.nn.quantized.InstanceNorm2d(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.InstanceNorm2d._get_name(self)
torch.nn.quantized.InstanceNorm2d.forward(self,input)
torch.nn.quantized.InstanceNorm2d.from_float(cls,mod)
torch.nn.quantized.InstanceNorm3d(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.InstanceNorm3d._get_name(self)
torch.nn.quantized.InstanceNorm3d.forward(self,input)
torch.nn.quantized.InstanceNorm3d.from_float(cls,mod)
torch.nn.quantized.LayerNorm(self,normalized_shape,weight,bias,scale,zero_point,eps=1e-05,elementwise_affine=True)
torch.nn.quantized.LayerNorm._get_name(self)
torch.nn.quantized.LayerNorm.forward(self,input)
torch.nn.quantized.LayerNorm.from_float(cls,mod)
torch.nn.quantized.modules.normalization.GroupNorm(self,num_groups,num_channels,weight,bias,scale,zero_point,eps=1e-05,affine=True)
torch.nn.quantized.modules.normalization.GroupNorm.__init__(self,num_groups,num_channels,weight,bias,scale,zero_point,eps=1e-05,affine=True)
torch.nn.quantized.modules.normalization.GroupNorm._get_name(self)
torch.nn.quantized.modules.normalization.GroupNorm.forward(self,input)
torch.nn.quantized.modules.normalization.GroupNorm.from_float(cls,mod)
torch.nn.quantized.modules.normalization.InstanceNorm1d(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.modules.normalization.InstanceNorm1d.__init__(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.modules.normalization.InstanceNorm1d._get_name(self)
torch.nn.quantized.modules.normalization.InstanceNorm1d.forward(self,input)
torch.nn.quantized.modules.normalization.InstanceNorm1d.from_float(cls,mod)
torch.nn.quantized.modules.normalization.InstanceNorm2d(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.modules.normalization.InstanceNorm2d.__init__(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.modules.normalization.InstanceNorm2d._get_name(self)
torch.nn.quantized.modules.normalization.InstanceNorm2d.forward(self,input)
torch.nn.quantized.modules.normalization.InstanceNorm2d.from_float(cls,mod)
torch.nn.quantized.modules.normalization.InstanceNorm3d(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.modules.normalization.InstanceNorm3d.__init__(self,num_features,weight,bias,scale,zero_point,eps=1e-05,momentum=0.1,affine=False,track_running_stats=False)
torch.nn.quantized.modules.normalization.InstanceNorm3d._get_name(self)
torch.nn.quantized.modules.normalization.InstanceNorm3d.forward(self,input)
torch.nn.quantized.modules.normalization.InstanceNorm3d.from_float(cls,mod)
torch.nn.quantized.modules.normalization.LayerNorm(self,normalized_shape,weight,bias,scale,zero_point,eps=1e-05,elementwise_affine=True)
torch.nn.quantized.modules.normalization.LayerNorm.__init__(self,normalized_shape,weight,bias,scale,zero_point,eps=1e-05,elementwise_affine=True)
torch.nn.quantized.modules.normalization.LayerNorm._get_name(self)
torch.nn.quantized.modules.normalization.LayerNorm.forward(self,input)
torch.nn.quantized.modules.normalization.LayerNorm.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/modules/conv.py----------------------------------------
A:torch.nn.quantized.modules.conv.qweight->_quantize_weight(mod.weight.float(), weight_post_process)
A:torch.nn.quantized.modules.conv.(w, b)->torch.ops.quantized.conv2d_unpack(self._packed_params)
A:torch.nn.quantized.modules.conv.destination[prefix + 'scale']->torch.tensor(self.scale)
A:torch.nn.quantized.modules.conv.destination[prefix + 'zero_point']->torch.tensor(self.zero_point)
A:torch.nn.quantized.modules.conv.self.scale->float(state_dict[prefix + 'scale'])
A:torch.nn.quantized.modules.conv.self.zero_point->int(state_dict[prefix + 'zero_point'])
A:torch.nn.quantized.modules.conv.weight_post_process->mod.qconfig.weight()
A:torch.nn.quantized.modules.conv.(act_scale, act_zp)->mod.activation_post_process.calculate_qparams()
A:torch.nn.quantized.modules.conv.qconv->cls(mod.in_channels, mod.out_channels, mod.kernel_size, mod.stride, mod.padding, mod.output_padding, mod.groups, mod.bias is not None, mod.dilation, mod.padding_mode)
A:torch.nn.quantized.modules.conv.qconv.scale->float(act_scale)
A:torch.nn.quantized.modules.conv.qconv.zero_point->int(act_zp)
A:torch.nn.quantized.modules.conv.kernel_size->_pair(kernel_size)
A:torch.nn.quantized.modules.conv.stride->_pair(stride)
A:torch.nn.quantized.modules.conv.padding->_pair(padding)
A:torch.nn.quantized.modules.conv.dilation->_pair(dilation)
A:torch.nn.quantized.modules.conv.self._packed_params->torch.ops.quantized.conv_transpose2d_prepack(w, b, self.stride, self.padding, self.output_padding, self.dilation, self.groups)
A:torch.nn.quantized.modules.conv.(mod.weight, mod.bias)->fuse_conv_bn_weights(mod.weight, mod.bias, mod.bn.running_mean, mod.bn.running_var, mod.bn.eps, mod.bn.weight, mod.bn.bias)
A:torch.nn.quantized.modules.conv.res->torch.jit.annotate(List[int], [])
A:torch.nn.quantized.modules.conv.output_padding->_pair(output_padding)
A:torch.nn.quantized.modules.conv.(w, _)->self._weight_bias()
A:torch.nn.quantized.modules.conv.(_, b)->self._weight_bias()
torch.nn.quantized.Conv1d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.Conv1d._get_name(self)
torch.nn.quantized.Conv1d._weight_bias(self)
torch.nn.quantized.Conv1d.bias(self)
torch.nn.quantized.Conv1d.forward(self,input)
torch.nn.quantized.Conv1d.from_float(cls,mod)
torch.nn.quantized.Conv1d.set_weight_bias(self,w,b)
torch.nn.quantized.Conv1d.weight(self)
torch.nn.quantized.Conv2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.Conv2d._get_name(self)
torch.nn.quantized.Conv2d._weight_bias(self)
torch.nn.quantized.Conv2d.bias(self)
torch.nn.quantized.Conv2d.forward(self,input)
torch.nn.quantized.Conv2d.from_float(cls,mod)
torch.nn.quantized.Conv2d.set_weight_bias(self,w,b)
torch.nn.quantized.Conv2d.weight(self)
torch.nn.quantized.Conv3d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.Conv3d._get_name(self)
torch.nn.quantized.Conv3d._weight_bias(self)
torch.nn.quantized.Conv3d.bias(self)
torch.nn.quantized.Conv3d.forward(self,input)
torch.nn.quantized.Conv3d.from_float(cls,mod)
torch.nn.quantized.Conv3d.set_weight_bias(self,w,b)
torch.nn.quantized.Conv3d.weight(self)
torch.nn.quantized.ConvTranspose1d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')
torch.nn.quantized.ConvTranspose1d._get_name(self)
torch.nn.quantized.ConvTranspose1d._weight_bias(self)
torch.nn.quantized.ConvTranspose1d.bias(self)
torch.nn.quantized.ConvTranspose1d.forward(self,input)
torch.nn.quantized.ConvTranspose1d.set_weight_bias(self,w,b)
torch.nn.quantized.ConvTranspose1d.weight(self)
torch.nn.quantized.ConvTranspose2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')
torch.nn.quantized.ConvTranspose2d._get_name(self)
torch.nn.quantized.ConvTranspose2d._weight_bias(self)
torch.nn.quantized.ConvTranspose2d.bias(self)
torch.nn.quantized.ConvTranspose2d.forward(self,input)
torch.nn.quantized.ConvTranspose2d.set_weight_bias(self,w,b)
torch.nn.quantized.ConvTranspose2d.weight(self)
torch.nn.quantized.conv._ConvNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode='zeros')
torch.nn.quantized.conv._ConvNd.__getstate__(self)
torch.nn.quantized.conv._ConvNd.__setstate__(self,state)
torch.nn.quantized.conv._ConvNd._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.conv._ConvNd._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.conv._ConvNd.extra_repr(self)
torch.nn.quantized.conv._ConvNd.get_qconv(cls,mod,activation_post_process,weight_post_process=None)
torch.nn.quantized.conv._ConvTransposeNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode)
torch.nn.quantized.conv._ConvTransposeNd._input_padding(self,kernel_size,dilation,padding)
torch.nn.quantized.conv._ConvTransposeNd.from_float(cls,mod)
torch.nn.quantized.modules.conv.Conv1d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.modules.conv.Conv1d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.modules.conv.Conv1d._get_name(self)
torch.nn.quantized.modules.conv.Conv1d._weight_bias(self)
torch.nn.quantized.modules.conv.Conv1d.bias(self)
torch.nn.quantized.modules.conv.Conv1d.forward(self,input)
torch.nn.quantized.modules.conv.Conv1d.from_float(cls,mod)
torch.nn.quantized.modules.conv.Conv1d.set_weight_bias(self,w,b)
torch.nn.quantized.modules.conv.Conv1d.weight(self)
torch.nn.quantized.modules.conv.Conv2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.modules.conv.Conv2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.modules.conv.Conv2d._get_name(self)
torch.nn.quantized.modules.conv.Conv2d._weight_bias(self)
torch.nn.quantized.modules.conv.Conv2d.bias(self)
torch.nn.quantized.modules.conv.Conv2d.forward(self,input)
torch.nn.quantized.modules.conv.Conv2d.from_float(cls,mod)
torch.nn.quantized.modules.conv.Conv2d.set_weight_bias(self,w,b)
torch.nn.quantized.modules.conv.Conv2d.weight(self)
torch.nn.quantized.modules.conv.Conv3d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.modules.conv.Conv3d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.quantized.modules.conv.Conv3d._get_name(self)
torch.nn.quantized.modules.conv.Conv3d._weight_bias(self)
torch.nn.quantized.modules.conv.Conv3d.bias(self)
torch.nn.quantized.modules.conv.Conv3d.forward(self,input)
torch.nn.quantized.modules.conv.Conv3d.from_float(cls,mod)
torch.nn.quantized.modules.conv.Conv3d.set_weight_bias(self,w,b)
torch.nn.quantized.modules.conv.Conv3d.weight(self)
torch.nn.quantized.modules.conv.ConvTranspose1d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')
torch.nn.quantized.modules.conv.ConvTranspose1d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')
torch.nn.quantized.modules.conv.ConvTranspose1d._get_name(self)
torch.nn.quantized.modules.conv.ConvTranspose1d._weight_bias(self)
torch.nn.quantized.modules.conv.ConvTranspose1d.bias(self)
torch.nn.quantized.modules.conv.ConvTranspose1d.forward(self,input)
torch.nn.quantized.modules.conv.ConvTranspose1d.set_weight_bias(self,w,b)
torch.nn.quantized.modules.conv.ConvTranspose1d.weight(self)
torch.nn.quantized.modules.conv.ConvTranspose2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')
torch.nn.quantized.modules.conv.ConvTranspose2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,output_padding=0,groups=1,bias=True,dilation=1,padding_mode='zeros')
torch.nn.quantized.modules.conv.ConvTranspose2d._get_name(self)
torch.nn.quantized.modules.conv.ConvTranspose2d._weight_bias(self)
torch.nn.quantized.modules.conv.ConvTranspose2d.bias(self)
torch.nn.quantized.modules.conv.ConvTranspose2d.forward(self,input)
torch.nn.quantized.modules.conv.ConvTranspose2d.set_weight_bias(self,w,b)
torch.nn.quantized.modules.conv.ConvTranspose2d.weight(self)
torch.nn.quantized.modules.conv._ConvNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode='zeros')
torch.nn.quantized.modules.conv._ConvNd.__getstate__(self)
torch.nn.quantized.modules.conv._ConvNd.__init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode='zeros')
torch.nn.quantized.modules.conv._ConvNd.__setstate__(self,state)
torch.nn.quantized.modules.conv._ConvNd._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.modules.conv._ConvNd._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.modules.conv._ConvNd.extra_repr(self)
torch.nn.quantized.modules.conv._ConvNd.get_qconv(cls,mod,activation_post_process,weight_post_process=None)
torch.nn.quantized.modules.conv._ConvTransposeNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode)
torch.nn.quantized.modules.conv._ConvTransposeNd.__init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode)
torch.nn.quantized.modules.conv._ConvTransposeNd._input_padding(self,kernel_size,dilation,padding)
torch.nn.quantized.modules.conv._ConvTransposeNd.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/dynamic/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/dynamic/modules/linear.py----------------------------------------
A:torch.nn.quantized.dynamic.modules.linear.Y->torch.ops.quantized.linear_dynamic_fp16(x, self._packed_params._packed_params)
A:torch.nn.quantized.dynamic.modules.linear.extra_repr_str->'in_features={}, out_features={}, dtype={}'.format(self.in_features, self.out_features, self._packed_params.dtype)
A:torch.nn.quantized.dynamic.modules.linear.version->local_metadata.get('version', None)
A:torch.nn.quantized.dynamic.modules.linear.weight_observer->torch.quantization.qconfig.default_dynamic_qconfig.weight()
A:torch.nn.quantized.dynamic.modules.linear.qweight->mod.weight.float()
A:torch.nn.quantized.dynamic.modules.linear.qlinear->Linear(mod.in_features, mod.out_features, dtype=dtype)
torch.nn.quantized.dynamic.Linear(self,in_features,out_features,bias_=True,dtype=torch.qint8)
torch.nn.quantized.dynamic.Linear._get_name(self)
torch.nn.quantized.dynamic.Linear._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.Linear.extra_repr(self)
torch.nn.quantized.dynamic.Linear.forward(self,x)
torch.nn.quantized.dynamic.Linear.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.linear.Linear(self,in_features,out_features,bias_=True,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.linear.Linear.__init__(self,in_features,out_features,bias_=True,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.linear.Linear._get_name(self)
torch.nn.quantized.dynamic.modules.linear.Linear._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.modules.linear.Linear.extra_repr(self)
torch.nn.quantized.dynamic.modules.linear.Linear.forward(self,x)
torch.nn.quantized.dynamic.modules.linear.Linear.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/dynamic/modules/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/quantized/dynamic/modules/rnn.py----------------------------------------
A:torch.nn.quantized.dynamic.modules.rnn.self.dropout->float(dropout)
A:torch.nn.quantized.dynamic.modules.rnn.w_ih->torch.quantize_per_tensor(w_ih, scale=0.1, zero_point=0, dtype=torch.qint8)
A:torch.nn.quantized.dynamic.modules.rnn.w_hh->torch.quantize_per_tensor(w_hh, scale=0.1, zero_point=0, dtype=torch.qint8)
A:torch.nn.quantized.dynamic.modules.rnn.b_ih->torch.randn(gate_size).to(torch.float)
A:torch.nn.quantized.dynamic.modules.rnn.b_hh->torch.randn(gate_size).to(torch.float)
A:torch.nn.quantized.dynamic.modules.rnn.packed_ih->torch.ops.quantized.linear_prepack_fp16(weight_ih.float(), bias_ih)
A:torch.nn.quantized.dynamic.modules.rnn.packed_hh->torch.ops.quantized.linear_prepack_fp16(weight_hh.float(), bias_hh)
A:torch.nn.quantized.dynamic.modules.rnn.cell_params->torch.ops.quantized.make_quantized_cell_params_fp16(packed_ih, packed_hh)
A:torch.nn.quantized.dynamic.modules.rnn.self._all_weight_values->torch.nn.ModuleList(_all_weight_values)
A:torch.nn.quantized.dynamic.modules.rnn.extra_repr->self.extra_repr()
A:torch.nn.quantized.dynamic.modules.rnn.extra_lines->self.extra_repr().split('\n')
A:torch.nn.quantized.dynamic.modules.rnn.mod_str->torch.nn.modules.module._addindent(mod_str, 2)
A:torch.nn.quantized.dynamic.modules.rnn.mini_batch->int(batch_sizes[0])
A:torch.nn.quantized.dynamic.modules.rnn.expected_hidden_size->self.get_expected_hidden_size(input, batch_sizes)
A:torch.nn.quantized.dynamic.modules.rnn.version->local_metadata.get('version', None)
A:torch.nn.quantized.dynamic.modules.rnn.qRNNBase->LSTM(mod.input_size, mod.hidden_size, mod.num_layers, mod.bias, mod.batch_first, mod.dropout, mod.bidirectional, dtype)
A:torch.nn.quantized.dynamic.modules.rnn.weight_name->'weight_{}_l{}{}'.format(ihhh, layer, suffix)
A:torch.nn.quantized.dynamic.modules.rnn.bias_name->'bias_{}_l{}{}'.format(ihhh, layer, suffix)
A:torch.nn.quantized.dynamic.modules.rnn.weight->getattr(mod, weight_name)
A:torch.nn.quantized.dynamic.modules.rnn.bias->getattr(mod, bias_name)
A:torch.nn.quantized.dynamic.modules.rnn.(weight_ih, bias_ih)->retrieve_weight_bias('ih')
A:torch.nn.quantized.dynamic.modules.rnn.(weight_hh, bias_hh)->retrieve_weight_bias('hh')
A:torch.nn.quantized.dynamic.modules.rnn.weight_observer->weight_observer_method()
A:torch.nn.quantized.dynamic.modules.rnn.qweight->_quantize_weight(weight.float(), weight_observer)
A:torch.nn.quantized.dynamic.modules.rnn.packed_weight->torch.ops.quantized.linear_prepack_fp16(weight.float(), bias)
A:torch.nn.quantized.dynamic.modules.rnn.qRNNBase._all_weight_values->torch.nn.ModuleList(_all_weight_values)
A:torch.nn.quantized.dynamic.modules.rnn.key_name1->'bias_ih_l{layer_idx}{suffix}'.format(layer_idx=layer, suffix=suffix)
A:torch.nn.quantized.dynamic.modules.rnn.key_name2->'bias_hh_l{layer_idx}{suffix}'.format(layer_idx=layer, suffix=suffix)
A:torch.nn.quantized.dynamic.modules.rnn.zeros->torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)
A:torch.nn.quantized.dynamic.modules.rnn.hx->torch.zeros(input.size(0), self.hidden_size, dtype=input.dtype, device=input.device)
A:torch.nn.quantized.dynamic.modules.rnn.result->torch.quantized_lstm(input, batch_sizes, hx, _all_params, self.bias, self.num_layers, float(self.dropout), self.training, self.bidirectional, dtype=self.dtype, use_dynamic=True)
A:torch.nn.quantized.dynamic.modules.rnn.(output, hidden)->self.forward_impl(input, hx, batch_sizes, max_batch_size, sorted_indices)
A:torch.nn.quantized.dynamic.modules.rnn.max_batch_size->int(max_batch_size)
A:torch.nn.quantized.dynamic.modules.rnn.(output_, hidden)->self.forward_impl(input_, hx, batch_sizes, max_batch_size, sorted_indices)
A:torch.nn.quantized.dynamic.modules.rnn.output->PackedSequence(output_, batch_sizes, sorted_indices, unsorted_indices)
A:torch.nn.quantized.dynamic.modules.rnn.self.bias_ih->torch.randn(num_chunks * hidden_size).to(dtype=torch.float)
A:torch.nn.quantized.dynamic.modules.rnn.self.bias_hh->torch.randn(num_chunks * hidden_size).to(dtype=torch.float)
A:torch.nn.quantized.dynamic.modules.rnn.weight_ih->torch.quantize_per_tensor(weight_ih, scale=1, zero_point=0, dtype=torch.qint8)
A:torch.nn.quantized.dynamic.modules.rnn.weight_hh->torch.quantize_per_tensor(weight_hh, scale=1, zero_point=0, dtype=torch.qint8)
A:torch.nn.quantized.dynamic.modules.rnn.packed_weight_ih->torch.ops.quantized.linear_prepack_fp16(weight_ih, self.bias_ih)
A:torch.nn.quantized.dynamic.modules.rnn.packed_weight_hh->torch.ops.quantized.linear_prepack_fp16(weight_hh, self.bias_hh)
A:torch.nn.quantized.dynamic.modules.rnn.qRNNCellBase->RNNCell(mod.input_size, mod.hidden_size, bias=mod.bias, nonlinearity=mod.nonlinearity, dtype=dtype)
A:torch.nn.quantized.dynamic.modules.rnn.qRNNCellBase._packed_weight_ih->process_weights(mod.weight_ih, mod.bias_ih, dtype)
A:torch.nn.quantized.dynamic.modules.rnn.qRNNCellBase._packed_weight_hh->process_weights(mod.weight_hh, mod.bias_hh, dtype)
A:torch.nn.quantized.dynamic.modules.rnn.self._packed_weight_ih->state_dict.pop(prefix + '_packed_weight_ih')
A:torch.nn.quantized.dynamic.modules.rnn.self._packed_weight_hh->state_dict.pop(prefix + '_packed_weight_hh')
A:torch.nn.quantized.dynamic.modules.rnn.ret->torch.ops.quantized.quantized_rnn_relu_cell_dynamic(input, hx, self._packed_weight_ih, self._packed_weight_hh, self.bias_ih, self.bias_hh)
torch.nn.quantized.dynamic.GRUCell(self,input_size,hidden_size,bias=True,dtype=torch.qint8)
torch.nn.quantized.dynamic.GRUCell._get_name(self)
torch.nn.quantized.dynamic.GRUCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.quantized.dynamic.GRUCell.from_float(cls,mod)
torch.nn.quantized.dynamic.LSTM(self,*args,**kwargs)
torch.nn.quantized.dynamic.LSTM._get_name(self)
torch.nn.quantized.dynamic.LSTM.check_forward_args(self,input:Tensor,hidden:Tuple[Tensor,Tensor],batch_sizes:Optional[Tensor])->None
torch.nn.quantized.dynamic.LSTM.forward(self,input,hx=None)
torch.nn.quantized.dynamic.LSTM.forward_impl(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]],batch_sizes:Optional[Tensor],max_batch_size:int,sorted_indices:Optional[Tensor])->Tuple[Tensor, Tuple[Tensor, Tensor]]
torch.nn.quantized.dynamic.LSTM.forward_packed(self,input:PackedSequence,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[PackedSequence, Tuple[Tensor, Tensor]]
torch.nn.quantized.dynamic.LSTM.forward_tensor(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[Tensor, Tuple[Tensor, Tensor]]
torch.nn.quantized.dynamic.LSTM.from_float(cls,mod)
torch.nn.quantized.dynamic.LSTM.permute_hidden(self,hx:Tuple[Tensor,Tensor],permutation:Optional[Tensor])->Tuple[Tensor, Tensor]
torch.nn.quantized.dynamic.LSTMCell(self,*args,**kwargs)
torch.nn.quantized.dynamic.LSTMCell._get_name(self)
torch.nn.quantized.dynamic.LSTMCell.forward(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[Tensor, Tensor]
torch.nn.quantized.dynamic.LSTMCell.from_float(cls,mod)
torch.nn.quantized.dynamic.RNNCell(self,input_size,hidden_size,bias=True,nonlinearity='tanh',dtype=torch.qint8)
torch.nn.quantized.dynamic.RNNCell._get_name(self)
torch.nn.quantized.dynamic.RNNCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.quantized.dynamic.RNNCell.from_float(cls,mod)
torch.nn.quantized.dynamic.RNNCellBase(self,input_size,hidden_size,bias=True,num_chunks=4,dtype=torch.qint8)
torch.nn.quantized.dynamic.RNNCellBase._get_name(self)
torch.nn.quantized.dynamic.RNNCellBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.RNNCellBase._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.dynamic.RNNCellBase._weight_bias(self)
torch.nn.quantized.dynamic.RNNCellBase.check_forward_hidden(self,input:Tensor,hx:Tensor,hidden_label:str='')->None
torch.nn.quantized.dynamic.RNNCellBase.check_forward_input(self,input)
torch.nn.quantized.dynamic.RNNCellBase.extra_repr(self)
torch.nn.quantized.dynamic.RNNCellBase.from_float(cls,mod)
torch.nn.quantized.dynamic.RNNCellBase.get_bias(self)
torch.nn.quantized.dynamic.RNNCellBase.get_weight(self)
torch.nn.quantized.dynamic.modules.rnn.GRUCell(self,input_size,hidden_size,bias=True,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.GRUCell.__init__(self,input_size,hidden_size,bias=True,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.GRUCell._get_name(self)
torch.nn.quantized.dynamic.modules.rnn.GRUCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.quantized.dynamic.modules.rnn.GRUCell.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.rnn.LSTM(self,*args,**kwargs)
torch.nn.quantized.dynamic.modules.rnn.LSTM.__init__(self,*args,**kwargs)
torch.nn.quantized.dynamic.modules.rnn.LSTM._get_name(self)
torch.nn.quantized.dynamic.modules.rnn.LSTM.check_forward_args(self,input:Tensor,hidden:Tuple[Tensor,Tensor],batch_sizes:Optional[Tensor])->None
torch.nn.quantized.dynamic.modules.rnn.LSTM.forward(self,input,hx=None)
torch.nn.quantized.dynamic.modules.rnn.LSTM.forward_impl(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]],batch_sizes:Optional[Tensor],max_batch_size:int,sorted_indices:Optional[Tensor])->Tuple[Tensor, Tuple[Tensor, Tensor]]
torch.nn.quantized.dynamic.modules.rnn.LSTM.forward_packed(self,input:PackedSequence,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[PackedSequence, Tuple[Tensor, Tensor]]
torch.nn.quantized.dynamic.modules.rnn.LSTM.forward_tensor(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[Tensor, Tuple[Tensor, Tensor]]
torch.nn.quantized.dynamic.modules.rnn.LSTM.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.rnn.LSTM.permute_hidden(self,hx:Tuple[Tensor,Tensor],permutation:Optional[Tensor])->Tuple[Tensor, Tensor]
torch.nn.quantized.dynamic.modules.rnn.LSTMCell(self,*args,**kwargs)
torch.nn.quantized.dynamic.modules.rnn.LSTMCell.__init__(self,*args,**kwargs)
torch.nn.quantized.dynamic.modules.rnn.LSTMCell._get_name(self)
torch.nn.quantized.dynamic.modules.rnn.LSTMCell.forward(self,input:Tensor,hx:Optional[Tuple[Tensor,Tensor]]=None)->Tuple[Tensor, Tensor]
torch.nn.quantized.dynamic.modules.rnn.LSTMCell.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.rnn.PackedParameter(self,param)
torch.nn.quantized.dynamic.modules.rnn.PackedParameter.__init__(self,param)
torch.nn.quantized.dynamic.modules.rnn.PackedParameter._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.modules.rnn.PackedParameter._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.dynamic.modules.rnn.RNNBase(self,mode,input_size,hidden_size,num_layers=1,bias=True,batch_first=False,dropout=0.0,bidirectional=False,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.__init__(self,mode,input_size,hidden_size,num_layers=1,bias=True,batch_first=False,dropout=0.0,bidirectional=False,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.__repr__(self)
torch.nn.quantized.dynamic.modules.rnn.RNNBase._get_name(self)
torch.nn.quantized.dynamic.modules.rnn.RNNBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.modules.rnn.RNNBase._weight_bias(self)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.check_forward_args(self,input:Tensor,hidden:Tensor,batch_sizes:Optional[Tensor])->None
torch.nn.quantized.dynamic.modules.rnn.RNNBase.check_hidden_size(self,hx:Tensor,expected_hidden_size:Tuple[int,int,int],msg:str='Expectedhiddensize{},got{}')->None
torch.nn.quantized.dynamic.modules.rnn.RNNBase.check_input(self,input:Tensor,batch_sizes:Optional[Tensor])->None
torch.nn.quantized.dynamic.modules.rnn.RNNBase.extra_repr(self)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.get_bias(self)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.get_expected_hidden_size(self,input:Tensor,batch_sizes:Optional[Tensor])->Tuple[int, int, int]
torch.nn.quantized.dynamic.modules.rnn.RNNBase.get_weight(self)
torch.nn.quantized.dynamic.modules.rnn.RNNBase.permute_hidden(self,hx:Tensor,permutation:Optional[Tensor])->Tensor
torch.nn.quantized.dynamic.modules.rnn.RNNCell(self,input_size,hidden_size,bias=True,nonlinearity='tanh',dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNCell.__init__(self,input_size,hidden_size,bias=True,nonlinearity='tanh',dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNCell._get_name(self)
torch.nn.quantized.dynamic.modules.rnn.RNNCell.forward(self,input:Tensor,hx:Optional[Tensor]=None)->Tensor
torch.nn.quantized.dynamic.modules.rnn.RNNCell.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase(self,input_size,hidden_size,bias=True,num_chunks=4,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.__init__(self,input_size,hidden_size,bias=True,num_chunks=4,dtype=torch.qint8)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase._get_name(self)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase._weight_bias(self)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.check_forward_hidden(self,input:Tensor,hx:Tensor,hidden_label:str='')->None
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.check_forward_input(self,input)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.extra_repr(self)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.from_float(cls,mod)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.get_bias(self)
torch.nn.quantized.dynamic.modules.rnn.RNNCellBase.get_weight(self)
torch.nn.quantized.dynamic.modules.rnn.apply_permutation(tensor:Tensor,permutation:Tensor,dim:int=1)->Tensor
torch.nn.quantized.dynamic.rnn.PackedParameter(self,param)
torch.nn.quantized.dynamic.rnn.PackedParameter._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.rnn.PackedParameter._save_to_state_dict(self,destination,prefix,keep_vars)
torch.nn.quantized.dynamic.rnn.RNNBase(self,mode,input_size,hidden_size,num_layers=1,bias=True,batch_first=False,dropout=0.0,bidirectional=False,dtype=torch.qint8)
torch.nn.quantized.dynamic.rnn.RNNBase.__repr__(self)
torch.nn.quantized.dynamic.rnn.RNNBase._get_name(self)
torch.nn.quantized.dynamic.rnn.RNNBase._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.quantized.dynamic.rnn.RNNBase._weight_bias(self)
torch.nn.quantized.dynamic.rnn.RNNBase.check_forward_args(self,input:Tensor,hidden:Tensor,batch_sizes:Optional[Tensor])->None
torch.nn.quantized.dynamic.rnn.RNNBase.check_hidden_size(self,hx:Tensor,expected_hidden_size:Tuple[int,int,int],msg:str='Expectedhiddensize{},got{}')->None
torch.nn.quantized.dynamic.rnn.RNNBase.check_input(self,input:Tensor,batch_sizes:Optional[Tensor])->None
torch.nn.quantized.dynamic.rnn.RNNBase.extra_repr(self)
torch.nn.quantized.dynamic.rnn.RNNBase.from_float(cls,mod)
torch.nn.quantized.dynamic.rnn.RNNBase.get_bias(self)
torch.nn.quantized.dynamic.rnn.RNNBase.get_expected_hidden_size(self,input:Tensor,batch_sizes:Optional[Tensor])->Tuple[int, int, int]
torch.nn.quantized.dynamic.rnn.RNNBase.get_weight(self)
torch.nn.quantized.dynamic.rnn.RNNBase.permute_hidden(self,hx:Tensor,permutation:Optional[Tensor])->Tensor
torch.nn.quantized.dynamic.rnn.apply_permutation(tensor:Tensor,permutation:Tensor,dim:int=1)->Tensor


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/modules/fused.py----------------------------------------
torch.nn.intrinsic.BNReLU2d(self,batch_norm,relu)
torch.nn.intrinsic.BNReLU3d(self,batch_norm,relu)
torch.nn.intrinsic.ConvBn1d(self,conv,bn)
torch.nn.intrinsic.ConvBn2d(self,conv,bn)
torch.nn.intrinsic.ConvBn3d(self,conv,bn)
torch.nn.intrinsic.ConvBnReLU1d(self,conv,bn,relu)
torch.nn.intrinsic.ConvBnReLU2d(self,conv,bn,relu)
torch.nn.intrinsic.ConvBnReLU3d(self,conv,bn,relu)
torch.nn.intrinsic.ConvReLU1d(self,conv,relu)
torch.nn.intrinsic.ConvReLU2d(self,conv,relu)
torch.nn.intrinsic.ConvReLU3d(self,conv,relu)
torch.nn.intrinsic.LinearReLU(self,linear,relu)
torch.nn.intrinsic.modules.fused.BNReLU2d(self,batch_norm,relu)
torch.nn.intrinsic.modules.fused.BNReLU2d.__init__(self,batch_norm,relu)
torch.nn.intrinsic.modules.fused.BNReLU3d(self,batch_norm,relu)
torch.nn.intrinsic.modules.fused.BNReLU3d.__init__(self,batch_norm,relu)
torch.nn.intrinsic.modules.fused.ConvBn1d(self,conv,bn)
torch.nn.intrinsic.modules.fused.ConvBn1d.__init__(self,conv,bn)
torch.nn.intrinsic.modules.fused.ConvBn2d(self,conv,bn)
torch.nn.intrinsic.modules.fused.ConvBn2d.__init__(self,conv,bn)
torch.nn.intrinsic.modules.fused.ConvBn3d(self,conv,bn)
torch.nn.intrinsic.modules.fused.ConvBn3d.__init__(self,conv,bn)
torch.nn.intrinsic.modules.fused.ConvBnReLU1d(self,conv,bn,relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU1d.__init__(self,conv,bn,relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU2d(self,conv,bn,relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU2d.__init__(self,conv,bn,relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU3d(self,conv,bn,relu)
torch.nn.intrinsic.modules.fused.ConvBnReLU3d.__init__(self,conv,bn,relu)
torch.nn.intrinsic.modules.fused.ConvReLU1d(self,conv,relu)
torch.nn.intrinsic.modules.fused.ConvReLU1d.__init__(self,conv,relu)
torch.nn.intrinsic.modules.fused.ConvReLU2d(self,conv,relu)
torch.nn.intrinsic.modules.fused.ConvReLU2d.__init__(self,conv,relu)
torch.nn.intrinsic.modules.fused.ConvReLU3d(self,conv,relu)
torch.nn.intrinsic.modules.fused.ConvReLU3d.__init__(self,conv,relu)
torch.nn.intrinsic.modules.fused.LinearReLU(self,linear,relu)
torch.nn.intrinsic.modules.fused.LinearReLU.__init__(self,linear,relu)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/modules/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/qat/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/qat/modules/conv_fused.py----------------------------------------
A:torch.nn.intrinsic.qat.modules.conv_fused.self.bn->torch.nn.BatchNorm2d(out_channels, eps, momentum, True, True)
A:torch.nn.intrinsic.qat.modules.conv_fused.self.weight_fake_quant->self.qconfig.weight()
A:torch.nn.intrinsic.qat.modules.conv_fused.self.bias->Parameter(torch.Tensor(out_channels))
A:torch.nn.intrinsic.qat.modules.conv_fused.(fan_in, _)->torch.nn.init._calculate_fan_in_and_fan_out(self.weight)
A:torch.nn.intrinsic.qat.modules.conv_fused.running_std->torch.sqrt(self.bn.running_var + self.bn.eps)
A:torch.nn.intrinsic.qat.modules.conv_fused.scaled_weight->self.weight_fake_quant(self.weight * scale_factor.reshape([-1, 1, 1, 1]))
A:torch.nn.intrinsic.qat.modules.conv_fused.conv->self.bn(conv_orig)
A:torch.nn.intrinsic.qat.modules.conv_fused.version->local_metadata.get('version', None)
A:torch.nn.intrinsic.qat.modules.conv_fused.qat_convbn->cls(conv.in_channels, conv.out_channels, conv.kernel_size, conv.stride, conv.padding, conv.dilation, conv.groups, conv.bias is not None, conv.padding_mode, bn.eps, bn.momentum, False, qconfig)
A:torch.nn.intrinsic.qat.modules.conv_fused.kernel_size->_pair(kernel_size)
A:torch.nn.intrinsic.qat.modules.conv_fused.stride->_pair(stride)
A:torch.nn.intrinsic.qat.modules.conv_fused.padding->_pair(padding)
A:torch.nn.intrinsic.qat.modules.conv_fused.dilation->_pair(dilation)
torch.nn.intrinsic.qat.ConvBn2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=None,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.ConvBnReLU2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=None,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.ConvBnReLU2d.forward(self,input)
torch.nn.intrinsic.qat.ConvBnReLU2d.from_float(cls,mod)
torch.nn.intrinsic.qat.ConvReLU2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)
torch.nn.intrinsic.qat.ConvReLU2d.forward(self,input)
torch.nn.intrinsic.qat.ConvReLU2d.from_float(cls,mod)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode,eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd._forward(self,input)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.extra_repr(self)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.forward(self,input)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.freeze_bn_stats(self)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.from_float(cls,mod)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.reset_bn_parameters(self)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.reset_parameters(self)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.reset_running_stats(self)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.train(self,mode=True)
torch.nn.intrinsic.qat.conv_fused._ConvBnNd.update_bn_stats(self)
torch.nn.intrinsic.qat.freeze_bn_stats(mod)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBn2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=None,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBn2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=None,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=None,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=None,padding_mode='zeros',eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d.forward(self,input)
torch.nn.intrinsic.qat.modules.conv_fused.ConvBnReLU2d.from_float(cls,mod)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros',qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d.forward(self,input)
torch.nn.intrinsic.qat.modules.conv_fused.ConvReLU2d.from_float(cls,mod)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode,eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.__init__(self,in_channels,out_channels,kernel_size,stride,padding,dilation,transposed,output_padding,groups,bias,padding_mode,eps=1e-05,momentum=0.1,freeze_bn=False,qconfig=None)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd._forward(self,input)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd._load_from_state_dict(self,state_dict,prefix,local_metadata,strict,missing_keys,unexpected_keys,error_msgs)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.extra_repr(self)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.forward(self,input)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.freeze_bn_stats(self)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.from_float(cls,mod)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.reset_bn_parameters(self)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.reset_parameters(self)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.reset_running_stats(self)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.train(self,mode=True)
torch.nn.intrinsic.qat.modules.conv_fused._ConvBnNd.update_bn_stats(self)
torch.nn.intrinsic.qat.modules.conv_fused.freeze_bn_stats(mod)
torch.nn.intrinsic.qat.modules.conv_fused.update_bn_stats(mod)
torch.nn.intrinsic.qat.update_bn_stats(mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/qat/modules/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/qat/modules/linear_relu.py----------------------------------------
torch.nn.intrinsic.qat.LinearReLU(self,in_features,out_features,bias=True,qconfig=None)
torch.nn.intrinsic.qat.LinearReLU.forward(self,input)
torch.nn.intrinsic.qat.LinearReLU.from_float(cls,mod)
torch.nn.intrinsic.qat.modules.linear_relu.LinearReLU(self,in_features,out_features,bias=True,qconfig=None)
torch.nn.intrinsic.qat.modules.linear_relu.LinearReLU.__init__(self,in_features,out_features,bias=True,qconfig=None)
torch.nn.intrinsic.qat.modules.linear_relu.LinearReLU.forward(self,input)
torch.nn.intrinsic.qat.modules.linear_relu.LinearReLU.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/quantized/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/quantized/modules/conv_relu.py----------------------------------------
A:torch.nn.intrinsic.quantized.modules.conv_relu.(mod.weight, mod.bias)->fuse_conv_bn_weights(mod.weight, mod.bias, mod.bn.running_mean, mod.bn.running_var, mod.bn.eps, mod.bn.weight, mod.bn.bias)
torch.nn.intrinsic.quantized.ConvReLU1d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.ConvReLU1d._get_name(self)
torch.nn.intrinsic.quantized.ConvReLU1d.forward(self,input)
torch.nn.intrinsic.quantized.ConvReLU1d.from_float(cls,mod)
torch.nn.intrinsic.quantized.ConvReLU2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.ConvReLU2d._get_name(self)
torch.nn.intrinsic.quantized.ConvReLU2d.forward(self,input)
torch.nn.intrinsic.quantized.ConvReLU2d.from_float(cls,mod)
torch.nn.intrinsic.quantized.ConvReLU3d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.ConvReLU3d._get_name(self)
torch.nn.intrinsic.quantized.ConvReLU3d.forward(self,input)
torch.nn.intrinsic.quantized.ConvReLU3d.from_float(cls,mod)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d._get_name(self)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d.forward(self,input)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU1d.from_float(cls,mod)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d._get_name(self)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d.forward(self,input)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU2d.from_float(cls,mod)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d.__init__(self,in_channels,out_channels,kernel_size,stride=1,padding=0,dilation=1,groups=1,bias=True,padding_mode='zeros')
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d._get_name(self)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d.forward(self,input)
torch.nn.intrinsic.quantized.modules.conv_relu.ConvReLU3d.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/quantized/modules/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/quantized/modules/linear_relu.py----------------------------------------
A:torch.nn.intrinsic.quantized.modules.linear_relu.Y_q->torch.ops.quantized.linear_relu(input, self._packed_params._packed_params, float(self.scale), int(self.zero_point))
torch.nn.intrinsic.quantized.LinearReLU(self,in_features,out_features,bias=True,dtype=torch.qint8)
torch.nn.intrinsic.quantized.LinearReLU._get_name(self)
torch.nn.intrinsic.quantized.LinearReLU.forward(self,input)
torch.nn.intrinsic.quantized.LinearReLU.from_float(cls,mod)
torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU(self,in_features,out_features,bias=True,dtype=torch.qint8)
torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU.__init__(self,in_features,out_features,bias=True,dtype=torch.qint8)
torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU._get_name(self)
torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU.forward(self,input)
torch.nn.intrinsic.quantized.modules.linear_relu.LinearReLU.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/nn/intrinsic/quantized/modules/bn_relu.py----------------------------------------
torch.nn.intrinsic.quantized.BNReLU2d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.intrinsic.quantized.BNReLU2d._get_name(self)
torch.nn.intrinsic.quantized.BNReLU2d.forward(self,input)
torch.nn.intrinsic.quantized.BNReLU2d.from_float(cls,mod)
torch.nn.intrinsic.quantized.BNReLU3d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.intrinsic.quantized.BNReLU3d._get_name(self)
torch.nn.intrinsic.quantized.BNReLU3d.forward(self,input)
torch.nn.intrinsic.quantized.BNReLU3d.from_float(cls,mod)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d.__init__(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d._get_name(self)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d.forward(self,input)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU2d.from_float(cls,mod)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d.__init__(self,num_features,eps=1e-05,momentum=0.1)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d._get_name(self)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d.forward(self,input)
torch.nn.intrinsic.quantized.modules.bn_relu.BNReLU3d.from_float(cls,mod)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/poisson.py----------------------------------------
A:torch.distributions.poisson.(self.rate,)->broadcast_all(rate)
A:torch.distributions.poisson.batch_shape->torch.Size(batch_shape)
A:torch.distributions.poisson.new->self._get_checked_instance(Poisson, _instance)
A:torch.distributions.poisson.new.rate->self.rate.expand(batch_shape)
A:torch.distributions.poisson.shape->self._extended_shape(sample_shape)
A:torch.distributions.poisson.(rate, value)->broadcast_all(self.rate, value)
torch.distributions.Poisson(self,rate,validate_args=None)
torch.distributions.Poisson._log_normalizer(self,x)
torch.distributions.Poisson._natural_params(self)
torch.distributions.Poisson.expand(self,batch_shape,_instance=None)
torch.distributions.Poisson.log_prob(self,value)
torch.distributions.Poisson.mean(self)
torch.distributions.Poisson.sample(self,sample_shape=torch.Size())
torch.distributions.Poisson.variance(self)
torch.distributions.poisson.Poisson(self,rate,validate_args=None)
torch.distributions.poisson.Poisson.__init__(self,rate,validate_args=None)
torch.distributions.poisson.Poisson._log_normalizer(self,x)
torch.distributions.poisson.Poisson._natural_params(self)
torch.distributions.poisson.Poisson.expand(self,batch_shape,_instance=None)
torch.distributions.poisson.Poisson.log_prob(self,value)
torch.distributions.poisson.Poisson.mean(self)
torch.distributions.poisson.Poisson.sample(self,sample_shape=torch.Size())
torch.distributions.poisson.Poisson.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/pareto.py----------------------------------------
A:torch.distributions.pareto.(self.scale, self.alpha)->broadcast_all(scale, alpha)
A:torch.distributions.pareto.base_dist->Exponential(self.alpha)
A:torch.distributions.pareto.new->self._get_checked_instance(Pareto, _instance)
A:torch.distributions.pareto.new.scale->self.scale.expand(batch_shape)
A:torch.distributions.pareto.new.alpha->self.alpha.expand(batch_shape)
A:torch.distributions.pareto.a->self.alpha.clamp(min=2)
torch.distributions.Pareto(self,scale,alpha,validate_args=None)
torch.distributions.Pareto.entropy(self)
torch.distributions.Pareto.expand(self,batch_shape,_instance=None)
torch.distributions.Pareto.mean(self)
torch.distributions.Pareto.support(self)
torch.distributions.Pareto.variance(self)
torch.distributions.pareto.Pareto(self,scale,alpha,validate_args=None)
torch.distributions.pareto.Pareto.__init__(self,scale,alpha,validate_args=None)
torch.distributions.pareto.Pareto.entropy(self)
torch.distributions.pareto.Pareto.expand(self,batch_shape,_instance=None)
torch.distributions.pareto.Pareto.mean(self)
torch.distributions.pareto.Pareto.support(self)
torch.distributions.pareto.Pareto.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/cauchy.py----------------------------------------
A:torch.distributions.cauchy.(self.loc, self.scale)->broadcast_all(loc, scale)
A:torch.distributions.cauchy.batch_shape->torch.Size(batch_shape)
A:torch.distributions.cauchy.new->self._get_checked_instance(Cauchy, _instance)
A:torch.distributions.cauchy.new.loc->self.loc.expand(batch_shape)
A:torch.distributions.cauchy.new.scale->self.scale.expand(batch_shape)
A:torch.distributions.cauchy.shape->self._extended_shape(sample_shape)
A:torch.distributions.cauchy.eps->self.loc.new(shape).cauchy_()
torch.distributions.Cauchy(self,loc,scale,validate_args=None)
torch.distributions.Cauchy.cdf(self,value)
torch.distributions.Cauchy.entropy(self)
torch.distributions.Cauchy.expand(self,batch_shape,_instance=None)
torch.distributions.Cauchy.icdf(self,value)
torch.distributions.Cauchy.log_prob(self,value)
torch.distributions.Cauchy.mean(self)
torch.distributions.Cauchy.rsample(self,sample_shape=torch.Size())
torch.distributions.Cauchy.variance(self)
torch.distributions.cauchy.Cauchy(self,loc,scale,validate_args=None)
torch.distributions.cauchy.Cauchy.__init__(self,loc,scale,validate_args=None)
torch.distributions.cauchy.Cauchy.cdf(self,value)
torch.distributions.cauchy.Cauchy.entropy(self)
torch.distributions.cauchy.Cauchy.expand(self,batch_shape,_instance=None)
torch.distributions.cauchy.Cauchy.icdf(self,value)
torch.distributions.cauchy.Cauchy.log_prob(self,value)
torch.distributions.cauchy.Cauchy.mean(self)
torch.distributions.cauchy.Cauchy.rsample(self,sample_shape=torch.Size())
torch.distributions.cauchy.Cauchy.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/geometric.py----------------------------------------
A:torch.distributions.geometric.(self.probs,)->broadcast_all(probs)
A:torch.distributions.geometric.(self.logits,)->broadcast_all(logits)
A:torch.distributions.geometric.batch_shape->torch.Size(batch_shape)
A:torch.distributions.geometric.new->self._get_checked_instance(Geometric, _instance)
A:torch.distributions.geometric.new.probs->self.probs.expand(batch_shape)
A:torch.distributions.geometric.new.logits->self.logits.expand(batch_shape)
A:torch.distributions.geometric.shape->self._extended_shape(sample_shape)
A:torch.distributions.geometric.u->self.probs.new(shape).uniform_(tiny, 1)
A:torch.distributions.geometric.(value, probs)->broadcast_all(value, self.probs)
A:torch.distributions.geometric.probs->probs.clone(memory_format=torch.contiguous_format).clone(memory_format=torch.contiguous_format)
torch.distributions.Geometric(self,probs=None,logits=None,validate_args=None)
torch.distributions.Geometric.entropy(self)
torch.distributions.Geometric.expand(self,batch_shape,_instance=None)
torch.distributions.Geometric.log_prob(self,value)
torch.distributions.Geometric.logits(self)
torch.distributions.Geometric.mean(self)
torch.distributions.Geometric.probs(self)
torch.distributions.Geometric.sample(self,sample_shape=torch.Size())
torch.distributions.Geometric.variance(self)
torch.distributions.geometric.Geometric(self,probs=None,logits=None,validate_args=None)
torch.distributions.geometric.Geometric.__init__(self,probs=None,logits=None,validate_args=None)
torch.distributions.geometric.Geometric.entropy(self)
torch.distributions.geometric.Geometric.expand(self,batch_shape,_instance=None)
torch.distributions.geometric.Geometric.log_prob(self,value)
torch.distributions.geometric.Geometric.logits(self)
torch.distributions.geometric.Geometric.mean(self)
torch.distributions.geometric.Geometric.probs(self)
torch.distributions.geometric.Geometric.sample(self,sample_shape=torch.Size())
torch.distributions.geometric.Geometric.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/half_normal.py----------------------------------------
A:torch.distributions.half_normal.base_dist->Normal(0, scale)
A:torch.distributions.half_normal.new->self._get_checked_instance(HalfNormal, _instance)
torch.distributions.HalfNormal(self,scale,validate_args=None)
torch.distributions.HalfNormal.cdf(self,value)
torch.distributions.HalfNormal.entropy(self)
torch.distributions.HalfNormal.expand(self,batch_shape,_instance=None)
torch.distributions.HalfNormal.icdf(self,prob)
torch.distributions.HalfNormal.log_prob(self,value)
torch.distributions.HalfNormal.mean(self)
torch.distributions.HalfNormal.scale(self)
torch.distributions.HalfNormal.variance(self)
torch.distributions.half_normal.HalfNormal(self,scale,validate_args=None)
torch.distributions.half_normal.HalfNormal.__init__(self,scale,validate_args=None)
torch.distributions.half_normal.HalfNormal.cdf(self,value)
torch.distributions.half_normal.HalfNormal.entropy(self)
torch.distributions.half_normal.HalfNormal.expand(self,batch_shape,_instance=None)
torch.distributions.half_normal.HalfNormal.icdf(self,prob)
torch.distributions.half_normal.HalfNormal.log_prob(self,value)
torch.distributions.half_normal.HalfNormal.mean(self)
torch.distributions.half_normal.HalfNormal.scale(self)
torch.distributions.half_normal.HalfNormal.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/one_hot_categorical.py----------------------------------------
A:torch.distributions.one_hot_categorical.self._categorical->Categorical(probs, logits)
A:torch.distributions.one_hot_categorical.new->self._get_checked_instance(OneHotCategorical, _instance)
A:torch.distributions.one_hot_categorical.batch_shape->torch.Size(batch_shape)
A:torch.distributions.one_hot_categorical.new._categorical->self._categorical.expand(batch_shape)
A:torch.distributions.one_hot_categorical.sample_shape->torch.Size(sample_shape)
A:torch.distributions.one_hot_categorical.indices->self._categorical.sample(sample_shape)
A:torch.distributions.one_hot_categorical.values->values.expand((n,) + self.batch_shape + (n,)).expand((n,) + self.batch_shape + (n,))
torch.distributions.OneHotCategorical(self,probs=None,logits=None,validate_args=None)
torch.distributions.OneHotCategorical._new(self,*args,**kwargs)
torch.distributions.OneHotCategorical._param(self)
torch.distributions.OneHotCategorical.entropy(self)
torch.distributions.OneHotCategorical.enumerate_support(self,expand=True)
torch.distributions.OneHotCategorical.expand(self,batch_shape,_instance=None)
torch.distributions.OneHotCategorical.log_prob(self,value)
torch.distributions.OneHotCategorical.logits(self)
torch.distributions.OneHotCategorical.mean(self)
torch.distributions.OneHotCategorical.param_shape(self)
torch.distributions.OneHotCategorical.probs(self)
torch.distributions.OneHotCategorical.sample(self,sample_shape=torch.Size())
torch.distributions.OneHotCategorical.variance(self)
torch.distributions.one_hot_categorical.OneHotCategorical(self,probs=None,logits=None,validate_args=None)
torch.distributions.one_hot_categorical.OneHotCategorical.__init__(self,probs=None,logits=None,validate_args=None)
torch.distributions.one_hot_categorical.OneHotCategorical._new(self,*args,**kwargs)
torch.distributions.one_hot_categorical.OneHotCategorical._param(self)
torch.distributions.one_hot_categorical.OneHotCategorical.entropy(self)
torch.distributions.one_hot_categorical.OneHotCategorical.enumerate_support(self,expand=True)
torch.distributions.one_hot_categorical.OneHotCategorical.expand(self,batch_shape,_instance=None)
torch.distributions.one_hot_categorical.OneHotCategorical.log_prob(self,value)
torch.distributions.one_hot_categorical.OneHotCategorical.logits(self)
torch.distributions.one_hot_categorical.OneHotCategorical.mean(self)
torch.distributions.one_hot_categorical.OneHotCategorical.param_shape(self)
torch.distributions.one_hot_categorical.OneHotCategorical.probs(self)
torch.distributions.one_hot_categorical.OneHotCategorical.sample(self,sample_shape=torch.Size())
torch.distributions.one_hot_categorical.OneHotCategorical.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/logistic_normal.py----------------------------------------
A:torch.distributions.logistic_normal.base_dist->Normal(loc, scale)
A:torch.distributions.logistic_normal.self._event_shape->torch.Size([s + 1 for s in self._event_shape])
A:torch.distributions.logistic_normal.new->self._get_checked_instance(LogisticNormal, _instance)
torch.distributions.LogisticNormal(self,loc,scale,validate_args=None)
torch.distributions.LogisticNormal.expand(self,batch_shape,_instance=None)
torch.distributions.LogisticNormal.loc(self)
torch.distributions.LogisticNormal.scale(self)
torch.distributions.logistic_normal.LogisticNormal(self,loc,scale,validate_args=None)
torch.distributions.logistic_normal.LogisticNormal.__init__(self,loc,scale,validate_args=None)
torch.distributions.logistic_normal.LogisticNormal.expand(self,batch_shape,_instance=None)
torch.distributions.logistic_normal.LogisticNormal.loc(self)
torch.distributions.logistic_normal.LogisticNormal.scale(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/utils.py----------------------------------------
A:torch.distributions.utils.options->dict(dtype=value.dtype, device=value.device)
A:torch.distributions.utils.ps_clamped->clamp_probs(probs)
A:torch.distributions.utils.value->self.wrapped(instance)
torch.distributions.utils._standard_normal(shape,dtype,device)
torch.distributions.utils._sum_rightmost(value,dim)
torch.distributions.utils.broadcast_all(*values)
torch.distributions.utils.clamp_probs(probs)
torch.distributions.utils.lazy_property(self,wrapped)
torch.distributions.utils.lazy_property.__get__(self,instance,obj_type=None)
torch.distributions.utils.lazy_property.__init__(self,wrapped)
torch.distributions.utils.logits_to_probs(logits,is_binary=False)
torch.distributions.utils.probs_to_logits(probs,is_binary=False)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/weibull.py----------------------------------------
A:torch.distributions.weibull.(self.scale, self.concentration)->broadcast_all(scale, concentration)
A:torch.distributions.weibull.self.concentration_reciprocal->self.concentration.reciprocal()
A:torch.distributions.weibull.base_dist->self.base_dist.expand(batch_shape)
A:torch.distributions.weibull.new->self._get_checked_instance(Weibull, _instance)
A:torch.distributions.weibull.new.scale->self.scale.expand(batch_shape)
A:torch.distributions.weibull.new.concentration->self.concentration.expand(batch_shape)
A:torch.distributions.weibull.new.concentration_reciprocal->self._get_checked_instance(Weibull, _instance).concentration.reciprocal()
torch.distributions.Weibull(self,scale,concentration,validate_args=None)
torch.distributions.Weibull.entropy(self)
torch.distributions.Weibull.expand(self,batch_shape,_instance=None)
torch.distributions.Weibull.mean(self)
torch.distributions.Weibull.variance(self)
torch.distributions.weibull.Weibull(self,scale,concentration,validate_args=None)
torch.distributions.weibull.Weibull.__init__(self,scale,concentration,validate_args=None)
torch.distributions.weibull.Weibull.entropy(self)
torch.distributions.weibull.Weibull.expand(self,batch_shape,_instance=None)
torch.distributions.weibull.Weibull.mean(self)
torch.distributions.weibull.Weibull.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/log_normal.py----------------------------------------
A:torch.distributions.log_normal.base_dist->Normal(loc, scale)
A:torch.distributions.log_normal.new->self._get_checked_instance(LogNormal, _instance)
torch.distributions.LogNormal(self,loc,scale,validate_args=None)
torch.distributions.LogNormal.entropy(self)
torch.distributions.LogNormal.expand(self,batch_shape,_instance=None)
torch.distributions.LogNormal.loc(self)
torch.distributions.LogNormal.mean(self)
torch.distributions.LogNormal.scale(self)
torch.distributions.LogNormal.variance(self)
torch.distributions.log_normal.LogNormal(self,loc,scale,validate_args=None)
torch.distributions.log_normal.LogNormal.__init__(self,loc,scale,validate_args=None)
torch.distributions.log_normal.LogNormal.entropy(self)
torch.distributions.log_normal.LogNormal.expand(self,batch_shape,_instance=None)
torch.distributions.log_normal.LogNormal.loc(self)
torch.distributions.log_normal.LogNormal.mean(self)
torch.distributions.log_normal.LogNormal.scale(self)
torch.distributions.log_normal.LogNormal.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/lowrank_multivariate_normal.py----------------------------------------
A:torch.distributions.lowrank_multivariate_normal.m->W.size(-1)
A:torch.distributions.lowrank_multivariate_normal.K->torch.matmul(Dinvsqrt_W, Dinvsqrt_W.transpose(-1, -2)).contiguous()
A:torch.distributions.lowrank_multivariate_normal.Wt_Dinv_x->_batch_mv(Wt_Dinv, x)
A:torch.distributions.lowrank_multivariate_normal.mahalanobis_term1->(x.pow(2) / D).sum(-1)
A:torch.distributions.lowrank_multivariate_normal.mahalanobis_term2->_batch_mahalanobis(capacitance_tril, Wt_Dinv_x)
A:torch.distributions.lowrank_multivariate_normal.loc_->loc.unsqueeze(-1)
A:torch.distributions.lowrank_multivariate_normal.cov_diag_->cov_diag.unsqueeze(-1)
A:torch.distributions.lowrank_multivariate_normal.(loc_, self.cov_factor, cov_diag_)->torch.broadcast_tensors(loc_, cov_factor, cov_diag_)
A:torch.distributions.lowrank_multivariate_normal.self._capacitance_tril->_batch_capacitance_tril(cov_factor, cov_diag)
A:torch.distributions.lowrank_multivariate_normal.new->self._get_checked_instance(LowRankMultivariateNormal, _instance)
A:torch.distributions.lowrank_multivariate_normal.batch_shape->torch.Size(batch_shape)
A:torch.distributions.lowrank_multivariate_normal.new.loc->self.loc.expand(loc_shape)
A:torch.distributions.lowrank_multivariate_normal.new.cov_diag->self.cov_diag.expand(loc_shape)
A:torch.distributions.lowrank_multivariate_normal.new.cov_factor->self.cov_factor.expand(loc_shape + self.cov_factor.shape[-1:])
A:torch.distributions.lowrank_multivariate_normal.cov_diag_sqrt_unsqueeze->self._unbroadcasted_cov_diag.sqrt().unsqueeze(-1)
A:torch.distributions.lowrank_multivariate_normal.shape->self._extended_shape(sample_shape)
A:torch.distributions.lowrank_multivariate_normal.eps_W->_standard_normal(W_shape, dtype=self.loc.dtype, device=self.loc.device)
A:torch.distributions.lowrank_multivariate_normal.eps_D->_standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)
A:torch.distributions.lowrank_multivariate_normal.M->_batch_lowrank_mahalanobis(self._unbroadcasted_cov_factor, self._unbroadcasted_cov_diag, diff, self._capacitance_tril)
A:torch.distributions.lowrank_multivariate_normal.log_det->_batch_lowrank_logdet(self._unbroadcasted_cov_factor, self._unbroadcasted_cov_diag, self._capacitance_tril)
torch.distributions.LowRankMultivariateNormal(self,loc,cov_factor,cov_diag,validate_args=None)
torch.distributions.LowRankMultivariateNormal.covariance_matrix(self)
torch.distributions.LowRankMultivariateNormal.entropy(self)
torch.distributions.LowRankMultivariateNormal.expand(self,batch_shape,_instance=None)
torch.distributions.LowRankMultivariateNormal.log_prob(self,value)
torch.distributions.LowRankMultivariateNormal.mean(self)
torch.distributions.LowRankMultivariateNormal.precision_matrix(self)
torch.distributions.LowRankMultivariateNormal.rsample(self,sample_shape=torch.Size())
torch.distributions.LowRankMultivariateNormal.scale_tril(self)
torch.distributions.LowRankMultivariateNormal.variance(self)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal(self,loc,cov_factor,cov_diag,validate_args=None)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.__init__(self,loc,cov_factor,cov_diag,validate_args=None)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.covariance_matrix(self)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.entropy(self)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.expand(self,batch_shape,_instance=None)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.log_prob(self,value)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.mean(self)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.precision_matrix(self)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.rsample(self,sample_shape=torch.Size())
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.scale_tril(self)
torch.distributions.lowrank_multivariate_normal.LowRankMultivariateNormal.variance(self)
torch.distributions.lowrank_multivariate_normal._batch_capacitance_tril(W,D)
torch.distributions.lowrank_multivariate_normal._batch_lowrank_logdet(W,D,capacitance_tril)
torch.distributions.lowrank_multivariate_normal._batch_lowrank_mahalanobis(W,D,x,capacitance_tril)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/transformed_distribution.py----------------------------------------
A:torch.distributions.transformed_distribution.event_dim->len(self.event_shape)
A:torch.distributions.transformed_distribution.new->self._get_checked_instance(TransformedDistribution, _instance)
A:torch.distributions.transformed_distribution.batch_shape->torch.Size(batch_shape)
A:torch.distributions.transformed_distribution.new.base_dist->self.base_dist.expand(base_dist_batch_shape)
A:torch.distributions.transformed_distribution.x->transform.inv(y)
A:torch.distributions.transformed_distribution.value->transform(value)
torch.distributions.TransformedDistribution(self,base_distribution,transforms,validate_args=None)
torch.distributions.TransformedDistribution._monotonize_cdf(self,value)
torch.distributions.TransformedDistribution.cdf(self,value)
torch.distributions.TransformedDistribution.expand(self,batch_shape,_instance=None)
torch.distributions.TransformedDistribution.has_rsample(self)
torch.distributions.TransformedDistribution.icdf(self,value)
torch.distributions.TransformedDistribution.log_prob(self,value)
torch.distributions.TransformedDistribution.rsample(self,sample_shape=torch.Size())
torch.distributions.TransformedDistribution.sample(self,sample_shape=torch.Size())
torch.distributions.TransformedDistribution.support(self)
torch.distributions.transformed_distribution.TransformedDistribution(self,base_distribution,transforms,validate_args=None)
torch.distributions.transformed_distribution.TransformedDistribution.__init__(self,base_distribution,transforms,validate_args=None)
torch.distributions.transformed_distribution.TransformedDistribution._monotonize_cdf(self,value)
torch.distributions.transformed_distribution.TransformedDistribution.cdf(self,value)
torch.distributions.transformed_distribution.TransformedDistribution.expand(self,batch_shape,_instance=None)
torch.distributions.transformed_distribution.TransformedDistribution.has_rsample(self)
torch.distributions.transformed_distribution.TransformedDistribution.icdf(self,value)
torch.distributions.transformed_distribution.TransformedDistribution.log_prob(self,value)
torch.distributions.transformed_distribution.TransformedDistribution.rsample(self,sample_shape=torch.Size())
torch.distributions.transformed_distribution.TransformedDistribution.sample(self,sample_shape=torch.Size())
torch.distributions.transformed_distribution.TransformedDistribution.support(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/exp_family.py----------------------------------------
A:torch.distributions.exp_family.lg_normal->self._log_normalizer(*nparams)
A:torch.distributions.exp_family.gradients->torch.autograd.grad(lg_normal.sum(), nparams, create_graph=True)
torch.distributions.ExponentialFamily(Distribution)
torch.distributions.ExponentialFamily._log_normalizer(self,*natural_params)
torch.distributions.ExponentialFamily._mean_carrier_measure(self)
torch.distributions.ExponentialFamily._natural_params(self)
torch.distributions.ExponentialFamily.entropy(self)
torch.distributions.exp_family.ExponentialFamily(Distribution)
torch.distributions.exp_family.ExponentialFamily._log_normalizer(self,*natural_params)
torch.distributions.exp_family.ExponentialFamily._mean_carrier_measure(self)
torch.distributions.exp_family.ExponentialFamily._natural_params(self)
torch.distributions.exp_family.ExponentialFamily.entropy(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/laplace.py----------------------------------------
A:torch.distributions.laplace.(self.loc, self.scale)->broadcast_all(loc, scale)
A:torch.distributions.laplace.batch_shape->torch.Size(batch_shape)
A:torch.distributions.laplace.new->self._get_checked_instance(Laplace, _instance)
A:torch.distributions.laplace.new.loc->self.loc.expand(batch_shape)
A:torch.distributions.laplace.new.scale->self.scale.expand(batch_shape)
A:torch.distributions.laplace.shape->self._extended_shape(sample_shape)
A:torch.distributions.laplace.finfo->torch.finfo(self.loc.dtype)
A:torch.distributions.laplace.u->self.loc.new(shape).uniform_(finfo.eps - 1, 1)
torch.distributions.Laplace(self,loc,scale,validate_args=None)
torch.distributions.Laplace.cdf(self,value)
torch.distributions.Laplace.entropy(self)
torch.distributions.Laplace.expand(self,batch_shape,_instance=None)
torch.distributions.Laplace.icdf(self,value)
torch.distributions.Laplace.log_prob(self,value)
torch.distributions.Laplace.mean(self)
torch.distributions.Laplace.rsample(self,sample_shape=torch.Size())
torch.distributions.Laplace.stddev(self)
torch.distributions.Laplace.variance(self)
torch.distributions.laplace.Laplace(self,loc,scale,validate_args=None)
torch.distributions.laplace.Laplace.__init__(self,loc,scale,validate_args=None)
torch.distributions.laplace.Laplace.cdf(self,value)
torch.distributions.laplace.Laplace.entropy(self)
torch.distributions.laplace.Laplace.expand(self,batch_shape,_instance=None)
torch.distributions.laplace.Laplace.icdf(self,value)
torch.distributions.laplace.Laplace.log_prob(self,value)
torch.distributions.laplace.Laplace.mean(self)
torch.distributions.laplace.Laplace.rsample(self,sample_shape=torch.Size())
torch.distributions.laplace.Laplace.stddev(self)
torch.distributions.laplace.Laplace.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/multivariate_normal.py----------------------------------------
A:torch.distributions.multivariate_normal.n->bx.permute(permute_dims).size(-1)
A:torch.distributions.multivariate_normal.bx_batch_dims->len(bx_batch_shape)
A:torch.distributions.multivariate_normal.bx->bx.permute(permute_dims).permute(permute_dims)
A:torch.distributions.multivariate_normal.flat_L->bL.reshape(-1, n, n)
A:torch.distributions.multivariate_normal.flat_x->bx.permute(permute_dims).permute(permute_dims).reshape(-1, flat_L.size(0), n)
A:torch.distributions.multivariate_normal.flat_x_swap->bx.permute(permute_dims).permute(permute_dims).reshape(-1, flat_L.size(0), n).permute(1, 2, 0)
A:torch.distributions.multivariate_normal.M_swap->torch.triangular_solve(flat_x_swap, flat_L, upper=False)[0].pow(2).sum(-2)
A:torch.distributions.multivariate_normal.M->_batch_mahalanobis(self._unbroadcasted_scale_tril, diff)
A:torch.distributions.multivariate_normal.permuted_M->_batch_mahalanobis(self._unbroadcasted_scale_tril, diff).reshape(bx.shape[:-1])
A:torch.distributions.multivariate_normal.permute_inv_dims->list(range(outer_batch_dims))
A:torch.distributions.multivariate_normal.reshaped_M->_batch_mahalanobis(self._unbroadcasted_scale_tril, diff).reshape(bx.shape[:-1]).permute(permute_inv_dims)
A:torch.distributions.multivariate_normal.Lf->torch.cholesky(torch.flip(P, (-2, -1)))
A:torch.distributions.multivariate_normal.L_inv->torch.transpose(torch.flip(Lf, (-2, -1)), -2, -1)
A:torch.distributions.multivariate_normal.loc_->loc.unsqueeze(-1)
A:torch.distributions.multivariate_normal.(self.scale_tril, loc_)->torch.broadcast_tensors(scale_tril, loc_)
A:torch.distributions.multivariate_normal.(self.covariance_matrix, loc_)->torch.broadcast_tensors(covariance_matrix, loc_)
A:torch.distributions.multivariate_normal.(self.precision_matrix, loc_)->torch.broadcast_tensors(precision_matrix, loc_)
A:torch.distributions.multivariate_normal.self._unbroadcasted_scale_tril->_precision_to_scale_tril(precision_matrix)
A:torch.distributions.multivariate_normal.new->self._get_checked_instance(MultivariateNormal, _instance)
A:torch.distributions.multivariate_normal.batch_shape->torch.Size(batch_shape)
A:torch.distributions.multivariate_normal.new.loc->self.loc.expand(loc_shape)
A:torch.distributions.multivariate_normal.new.covariance_matrix->self.covariance_matrix.expand(cov_shape)
A:torch.distributions.multivariate_normal.new.scale_tril->self.scale_tril.expand(cov_shape)
A:torch.distributions.multivariate_normal.new.precision_matrix->self.precision_matrix.expand(cov_shape)
A:torch.distributions.multivariate_normal.identity->torch.eye(self.loc.size(-1), device=self.loc.device, dtype=self.loc.dtype)
A:torch.distributions.multivariate_normal.shape->self._extended_shape(sample_shape)
A:torch.distributions.multivariate_normal.eps->_standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)
A:torch.distributions.multivariate_normal.half_log_det->self._unbroadcasted_scale_tril.diagonal(dim1=-2, dim2=-1).log().sum(-1)
torch.distributions.MultivariateNormal(self,loc,covariance_matrix=None,precision_matrix=None,scale_tril=None,validate_args=None)
torch.distributions.MultivariateNormal.covariance_matrix(self)
torch.distributions.MultivariateNormal.entropy(self)
torch.distributions.MultivariateNormal.expand(self,batch_shape,_instance=None)
torch.distributions.MultivariateNormal.log_prob(self,value)
torch.distributions.MultivariateNormal.mean(self)
torch.distributions.MultivariateNormal.precision_matrix(self)
torch.distributions.MultivariateNormal.rsample(self,sample_shape=torch.Size())
torch.distributions.MultivariateNormal.scale_tril(self)
torch.distributions.MultivariateNormal.variance(self)
torch.distributions.multivariate_normal.MultivariateNormal(self,loc,covariance_matrix=None,precision_matrix=None,scale_tril=None,validate_args=None)
torch.distributions.multivariate_normal.MultivariateNormal.__init__(self,loc,covariance_matrix=None,precision_matrix=None,scale_tril=None,validate_args=None)
torch.distributions.multivariate_normal.MultivariateNormal.covariance_matrix(self)
torch.distributions.multivariate_normal.MultivariateNormal.entropy(self)
torch.distributions.multivariate_normal.MultivariateNormal.expand(self,batch_shape,_instance=None)
torch.distributions.multivariate_normal.MultivariateNormal.log_prob(self,value)
torch.distributions.multivariate_normal.MultivariateNormal.mean(self)
torch.distributions.multivariate_normal.MultivariateNormal.precision_matrix(self)
torch.distributions.multivariate_normal.MultivariateNormal.rsample(self,sample_shape=torch.Size())
torch.distributions.multivariate_normal.MultivariateNormal.scale_tril(self)
torch.distributions.multivariate_normal.MultivariateNormal.variance(self)
torch.distributions.multivariate_normal._batch_mahalanobis(bL,bx)
torch.distributions.multivariate_normal._batch_mv(bmat,bvec)
torch.distributions.multivariate_normal._precision_to_scale_tril(P)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/gamma.py----------------------------------------
A:torch.distributions.gamma.(self.concentration, self.rate)->broadcast_all(concentration, rate)
A:torch.distributions.gamma.batch_shape->torch.Size(batch_shape)
A:torch.distributions.gamma.new->self._get_checked_instance(Gamma, _instance)
A:torch.distributions.gamma.new.concentration->self.concentration.expand(batch_shape)
A:torch.distributions.gamma.new.rate->self.rate.expand(batch_shape)
A:torch.distributions.gamma.shape->self._extended_shape(sample_shape)
A:torch.distributions.gamma.value->torch.as_tensor(value, dtype=self.rate.dtype, device=self.rate.device)
torch.distributions.Gamma(self,concentration,rate,validate_args=None)
torch.distributions.Gamma._log_normalizer(self,x,y)
torch.distributions.Gamma._natural_params(self)
torch.distributions.Gamma.entropy(self)
torch.distributions.Gamma.expand(self,batch_shape,_instance=None)
torch.distributions.Gamma.log_prob(self,value)
torch.distributions.Gamma.mean(self)
torch.distributions.Gamma.rsample(self,sample_shape=torch.Size())
torch.distributions.Gamma.variance(self)
torch.distributions.gamma.Gamma(self,concentration,rate,validate_args=None)
torch.distributions.gamma.Gamma.__init__(self,concentration,rate,validate_args=None)
torch.distributions.gamma.Gamma._log_normalizer(self,x,y)
torch.distributions.gamma.Gamma._natural_params(self)
torch.distributions.gamma.Gamma.entropy(self)
torch.distributions.gamma.Gamma.expand(self,batch_shape,_instance=None)
torch.distributions.gamma.Gamma.log_prob(self,value)
torch.distributions.gamma.Gamma.mean(self)
torch.distributions.gamma.Gamma.rsample(self,sample_shape=torch.Size())
torch.distributions.gamma.Gamma.variance(self)
torch.distributions.gamma._standard_gamma(concentration)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/mixture_same_family.py----------------------------------------
A:torch.distributions.mixture_same_family.self._event_ndims->len(event_shape)
A:torch.distributions.mixture_same_family.batch_shape->torch.Size(batch_shape)
A:torch.distributions.mixture_same_family.new->self._get_checked_instance(MixtureSameFamily, _instance)
A:torch.distributions.mixture_same_family.new._component_distribution->self._component_distribution.expand(batch_shape_comp)
A:torch.distributions.mixture_same_family.new._mixture_distribution->self._mixture_distribution.expand(batch_shape)
A:torch.distributions.mixture_same_family.probs->self._pad_mixture_dimensions(self.mixture_distribution.probs)
A:torch.distributions.mixture_same_family.mean_cond_var->torch.sum(probs * self.component_distribution.variance, dim=-1 - self._event_ndims)
A:torch.distributions.mixture_same_family.var_cond_mean->torch.sum(probs * (self.component_distribution.mean - self._pad(self.mean)).pow(2.0), dim=-1 - self._event_ndims)
A:torch.distributions.mixture_same_family.x->x.reshape(xs[:-1] + torch.Size(pad_ndims * [1]) + xs[-1:] + torch.Size(self._event_ndims * [1])).reshape(xs[:-1] + torch.Size(pad_ndims * [1]) + xs[-1:] + torch.Size(self._event_ndims * [1]))
A:torch.distributions.mixture_same_family.cdf_x->self.component_distribution.cdf(x)
A:torch.distributions.mixture_same_family.log_prob_x->self.component_distribution.log_prob(x)
A:torch.distributions.mixture_same_family.log_mix_prob->torch.log_softmax(self.mixture_distribution.logits, dim=-1)
A:torch.distributions.mixture_same_family.sample_len->len(sample_shape)
A:torch.distributions.mixture_same_family.batch_len->len(self.batch_shape)
A:torch.distributions.mixture_same_family.mix_sample->self.mixture_distribution.sample(sample_shape)
A:torch.distributions.mixture_same_family.comp_samples->self.component_distribution.sample(sample_shape)
A:torch.distributions.mixture_same_family.mix_sample_r->mix_sample_r.repeat(torch.Size([1] * len(mix_shape)) + torch.Size([1]) + es).repeat(torch.Size([1] * len(mix_shape)) + torch.Size([1]) + es)
A:torch.distributions.mixture_same_family.samples->torch.gather(comp_samples, gather_dim, mix_sample_r)
A:torch.distributions.mixture_same_family.dist_batch_ndims->self.batch_shape.numel()
A:torch.distributions.mixture_same_family.cat_batch_ndims->self.mixture_distribution.batch_shape.numel()
A:torch.distributions.mixture_same_family.args_string->'\n  {},\n  {}'.format(self.mixture_distribution, self.component_distribution)
torch.distributions.MixtureSameFamily(self,mixture_distribution,component_distribution,validate_args=None)
torch.distributions.MixtureSameFamily.__repr__(self)
torch.distributions.MixtureSameFamily._pad(self,x)
torch.distributions.MixtureSameFamily._pad_mixture_dimensions(self,x)
torch.distributions.MixtureSameFamily.cdf(self,x)
torch.distributions.MixtureSameFamily.component_distribution(self)
torch.distributions.MixtureSameFamily.expand(self,batch_shape,_instance=None)
torch.distributions.MixtureSameFamily.log_prob(self,x)
torch.distributions.MixtureSameFamily.mean(self)
torch.distributions.MixtureSameFamily.mixture_distribution(self)
torch.distributions.MixtureSameFamily.sample(self,sample_shape=torch.Size())
torch.distributions.MixtureSameFamily.support(self)
torch.distributions.MixtureSameFamily.variance(self)
torch.distributions.mixture_same_family.MixtureSameFamily(self,mixture_distribution,component_distribution,validate_args=None)
torch.distributions.mixture_same_family.MixtureSameFamily.__init__(self,mixture_distribution,component_distribution,validate_args=None)
torch.distributions.mixture_same_family.MixtureSameFamily.__repr__(self)
torch.distributions.mixture_same_family.MixtureSameFamily._pad(self,x)
torch.distributions.mixture_same_family.MixtureSameFamily._pad_mixture_dimensions(self,x)
torch.distributions.mixture_same_family.MixtureSameFamily.cdf(self,x)
torch.distributions.mixture_same_family.MixtureSameFamily.component_distribution(self)
torch.distributions.mixture_same_family.MixtureSameFamily.expand(self,batch_shape,_instance=None)
torch.distributions.mixture_same_family.MixtureSameFamily.log_prob(self,x)
torch.distributions.mixture_same_family.MixtureSameFamily.mean(self)
torch.distributions.mixture_same_family.MixtureSameFamily.mixture_distribution(self)
torch.distributions.mixture_same_family.MixtureSameFamily.sample(self,sample_shape=torch.Size())
torch.distributions.mixture_same_family.MixtureSameFamily.support(self)
torch.distributions.mixture_same_family.MixtureSameFamily.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/distribution.py----------------------------------------
A:torch.distributions.distribution.sample_shape->torch.Size(sample_shape)
A:torch.distributions.distribution.actual_shape->value.size()
A:torch.distributions.distribution.args_string->', '.join(['{}: {}'.format(p, self.__dict__[p] if self.__dict__[p].numel() == 1 else self.__dict__[p].size()) for p in param_names])
torch.distributions.Distribution(self,batch_shape=torch.Size(),event_shape=torch.Size(),validate_args=None)
torch.distributions.Distribution.__repr__(self)
torch.distributions.Distribution._extended_shape(self,sample_shape=torch.Size())
torch.distributions.Distribution._get_checked_instance(self,cls,_instance=None)
torch.distributions.Distribution._validate_sample(self,value)
torch.distributions.Distribution.arg_constraints(self)
torch.distributions.Distribution.batch_shape(self)
torch.distributions.Distribution.cdf(self,value)
torch.distributions.Distribution.entropy(self)
torch.distributions.Distribution.enumerate_support(self,expand=True)
torch.distributions.Distribution.event_shape(self)
torch.distributions.Distribution.expand(self,batch_shape,_instance=None)
torch.distributions.Distribution.icdf(self,value)
torch.distributions.Distribution.log_prob(self,value)
torch.distributions.Distribution.mean(self)
torch.distributions.Distribution.perplexity(self)
torch.distributions.Distribution.rsample(self,sample_shape=torch.Size())
torch.distributions.Distribution.sample(self,sample_shape=torch.Size())
torch.distributions.Distribution.sample_n(self,n)
torch.distributions.Distribution.set_default_validate_args(value)
torch.distributions.Distribution.stddev(self)
torch.distributions.Distribution.support(self)
torch.distributions.Distribution.variance(self)
torch.distributions.distribution.Distribution(self,batch_shape=torch.Size(),event_shape=torch.Size(),validate_args=None)
torch.distributions.distribution.Distribution.__init__(self,batch_shape=torch.Size(),event_shape=torch.Size(),validate_args=None)
torch.distributions.distribution.Distribution.__repr__(self)
torch.distributions.distribution.Distribution._extended_shape(self,sample_shape=torch.Size())
torch.distributions.distribution.Distribution._get_checked_instance(self,cls,_instance=None)
torch.distributions.distribution.Distribution._validate_sample(self,value)
torch.distributions.distribution.Distribution.arg_constraints(self)
torch.distributions.distribution.Distribution.batch_shape(self)
torch.distributions.distribution.Distribution.cdf(self,value)
torch.distributions.distribution.Distribution.entropy(self)
torch.distributions.distribution.Distribution.enumerate_support(self,expand=True)
torch.distributions.distribution.Distribution.event_shape(self)
torch.distributions.distribution.Distribution.expand(self,batch_shape,_instance=None)
torch.distributions.distribution.Distribution.icdf(self,value)
torch.distributions.distribution.Distribution.log_prob(self,value)
torch.distributions.distribution.Distribution.mean(self)
torch.distributions.distribution.Distribution.perplexity(self)
torch.distributions.distribution.Distribution.rsample(self,sample_shape=torch.Size())
torch.distributions.distribution.Distribution.sample(self,sample_shape=torch.Size())
torch.distributions.distribution.Distribution.sample_n(self,n)
torch.distributions.distribution.Distribution.set_default_validate_args(value)
torch.distributions.distribution.Distribution.stddev(self)
torch.distributions.distribution.Distribution.support(self)
torch.distributions.distribution.Distribution.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/transforms.py----------------------------------------
A:torch.distributions.transforms.inv->ComposeTransform([p.inv for p in reversed(self.parts)])
A:torch.distributions.transforms.self._inv->weakref.ref(inv)
A:torch.distributions.transforms.y->y.clamp(min=finfo.tiny, max=1.0 - finfo.eps).clamp(min=finfo.tiny, max=1.0 - finfo.eps)
A:torch.distributions.transforms.x->part(x)
A:torch.distributions.transforms.inv._inv->weakref.ref(self)
A:torch.distributions.transforms.y_tmp->part(x)
A:torch.distributions.transforms.identity_transform->ComposeTransform([])
A:torch.distributions.transforms.(self.exponent,)->broadcast_all(exponent)
A:torch.distributions.transforms.finfo->torch.finfo(y.dtype)
A:torch.distributions.transforms.codomain->torch.distributions.constraints.interval(-1.0, 1.0)
A:torch.distributions.transforms.result->result.view(result_size).sum(-1).view(result_size).sum(-1)
A:torch.distributions.transforms.probs->(logprobs - logprobs.max(-1, True)[0]).exp()
A:torch.distributions.transforms.z->_clipped_sigmoid(x - offset.log())
A:torch.distributions.transforms.z_cumprod->(1 - z).cumprod(-1)
A:torch.distributions.transforms.sf->torch.clamp(sf, min=torch.finfo(y.dtype).tiny)
A:torch.distributions.transforms.detJ->(-x + F.logsigmoid(x) + y[..., :-1].log()).sum(-1)
A:torch.distributions.transforms.self.transforms->list(tseq)
A:torch.distributions.transforms.self.lengths->list(lengths)
A:torch.distributions.transforms.xslice->part(x).narrow(self.dim, start, length)
A:torch.distributions.transforms.yslice->y.clamp(min=finfo.tiny, max=1.0 - finfo.eps).clamp(min=finfo.tiny, max=1.0 - finfo.eps).narrow(self.dim, start, length)
A:torch.distributions.transforms.yslices->self._slice(y)
A:torch.distributions.transforms.xslices->self._slice(x)
torch.distributions.AbsTransform(Transform)
torch.distributions.AbsTransform.__eq__(self,other)
torch.distributions.AbsTransform._call(self,x)
torch.distributions.AbsTransform._inverse(self,y)
torch.distributions.AffineTransform(self,loc,scale,event_dim=0,cache_size=0)
torch.distributions.AffineTransform.__eq__(self,other)
torch.distributions.AffineTransform._call(self,x)
torch.distributions.AffineTransform._inverse(self,y)
torch.distributions.AffineTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.AffineTransform.sign(self)
torch.distributions.AffineTransform.with_cache(self,cache_size=1)
torch.distributions.CatTransform(self,tseq,dim=0,lengths=None,cache_size=0)
torch.distributions.CatTransform._call(self,x)
torch.distributions.CatTransform._inverse(self,y)
torch.distributions.CatTransform.bijective(self)
torch.distributions.CatTransform.codomain(self)
torch.distributions.CatTransform.domain(self)
torch.distributions.CatTransform.length(self)
torch.distributions.CatTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.CatTransform.with_cache(self,cache_size=1)
torch.distributions.ComposeTransform(self,parts,cache_size=0)
torch.distributions.ComposeTransform.__eq__(self,other)
torch.distributions.ComposeTransform.__repr__(self)
torch.distributions.ComposeTransform.bijective(self)
torch.distributions.ComposeTransform.codomain(self)
torch.distributions.ComposeTransform.domain(self)
torch.distributions.ComposeTransform.event_dim(self)
torch.distributions.ComposeTransform.inv(self)
torch.distributions.ComposeTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.ComposeTransform.sign(self)
torch.distributions.ComposeTransform.with_cache(self,cache_size=1)
torch.distributions.ExpTransform(Transform)
torch.distributions.ExpTransform.__eq__(self,other)
torch.distributions.ExpTransform._call(self,x)
torch.distributions.ExpTransform._inverse(self,y)
torch.distributions.ExpTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.LowerCholeskyTransform(Transform)
torch.distributions.LowerCholeskyTransform.__eq__(self,other)
torch.distributions.LowerCholeskyTransform._call(self,x)
torch.distributions.LowerCholeskyTransform._inverse(self,y)
torch.distributions.PowerTransform(self,exponent,cache_size=0)
torch.distributions.PowerTransform.__eq__(self,other)
torch.distributions.PowerTransform._call(self,x)
torch.distributions.PowerTransform._inverse(self,y)
torch.distributions.PowerTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.PowerTransform.with_cache(self,cache_size=1)
torch.distributions.SigmoidTransform(Transform)
torch.distributions.SigmoidTransform.__eq__(self,other)
torch.distributions.SigmoidTransform._call(self,x)
torch.distributions.SigmoidTransform._inverse(self,y)
torch.distributions.SigmoidTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.SoftmaxTransform(Transform)
torch.distributions.SoftmaxTransform.__eq__(self,other)
torch.distributions.SoftmaxTransform._call(self,x)
torch.distributions.SoftmaxTransform._inverse(self,y)
torch.distributions.StackTransform(self,tseq,dim=0,cache_size=0)
torch.distributions.StackTransform._call(self,x)
torch.distributions.StackTransform._inverse(self,y)
torch.distributions.StackTransform._slice(self,z)
torch.distributions.StackTransform.bijective(self)
torch.distributions.StackTransform.codomain(self)
torch.distributions.StackTransform.domain(self)
torch.distributions.StackTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.StackTransform.with_cache(self,cache_size=1)
torch.distributions.StickBreakingTransform(Transform)
torch.distributions.StickBreakingTransform.__eq__(self,other)
torch.distributions.StickBreakingTransform._call(self,x)
torch.distributions.StickBreakingTransform._inverse(self,y)
torch.distributions.StickBreakingTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.TanhTransform(Transform)
torch.distributions.TanhTransform.__eq__(self,other)
torch.distributions.TanhTransform._call(self,x)
torch.distributions.TanhTransform._inverse(self,y)
torch.distributions.TanhTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.Transform(self,cache_size=0)
torch.distributions.Transform.__eq__(self,other)
torch.distributions.Transform.__ne__(self,other)
torch.distributions.Transform.__repr__(self)
torch.distributions.Transform._call(self,x)
torch.distributions.Transform._inv_call(self,y)
torch.distributions.Transform._inverse(self,y)
torch.distributions.Transform.inv(self)
torch.distributions.Transform.log_abs_det_jacobian(self,x,y)
torch.distributions.Transform.sign(self)
torch.distributions.Transform.with_cache(self,cache_size=1)
torch.distributions._InverseTransform(self,transform)
torch.distributions._InverseTransform.__eq__(self,other)
torch.distributions._InverseTransform.bijective(self)
torch.distributions._InverseTransform.codomain(self)
torch.distributions._InverseTransform.domain(self)
torch.distributions._InverseTransform.event_dim(self)
torch.distributions._InverseTransform.inv(self)
torch.distributions._InverseTransform.log_abs_det_jacobian(self,x,y)
torch.distributions._InverseTransform.sign(self)
torch.distributions._InverseTransform.with_cache(self,cache_size=1)
torch.distributions._clipped_sigmoid(x)
torch.distributions.transforms.AbsTransform(Transform)
torch.distributions.transforms.AbsTransform.__eq__(self,other)
torch.distributions.transforms.AbsTransform._call(self,x)
torch.distributions.transforms.AbsTransform._inverse(self,y)
torch.distributions.transforms.AffineTransform(self,loc,scale,event_dim=0,cache_size=0)
torch.distributions.transforms.AffineTransform.__eq__(self,other)
torch.distributions.transforms.AffineTransform.__init__(self,loc,scale,event_dim=0,cache_size=0)
torch.distributions.transforms.AffineTransform._call(self,x)
torch.distributions.transforms.AffineTransform._inverse(self,y)
torch.distributions.transforms.AffineTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.AffineTransform.sign(self)
torch.distributions.transforms.AffineTransform.with_cache(self,cache_size=1)
torch.distributions.transforms.CatTransform(self,tseq,dim=0,lengths=None,cache_size=0)
torch.distributions.transforms.CatTransform.__init__(self,tseq,dim=0,lengths=None,cache_size=0)
torch.distributions.transforms.CatTransform._call(self,x)
torch.distributions.transforms.CatTransform._inverse(self,y)
torch.distributions.transforms.CatTransform.bijective(self)
torch.distributions.transforms.CatTransform.codomain(self)
torch.distributions.transforms.CatTransform.domain(self)
torch.distributions.transforms.CatTransform.length(self)
torch.distributions.transforms.CatTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.CatTransform.with_cache(self,cache_size=1)
torch.distributions.transforms.ComposeTransform(self,parts,cache_size=0)
torch.distributions.transforms.ComposeTransform.__eq__(self,other)
torch.distributions.transforms.ComposeTransform.__init__(self,parts,cache_size=0)
torch.distributions.transforms.ComposeTransform.__repr__(self)
torch.distributions.transforms.ComposeTransform.bijective(self)
torch.distributions.transforms.ComposeTransform.codomain(self)
torch.distributions.transforms.ComposeTransform.domain(self)
torch.distributions.transforms.ComposeTransform.event_dim(self)
torch.distributions.transforms.ComposeTransform.inv(self)
torch.distributions.transforms.ComposeTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.ComposeTransform.sign(self)
torch.distributions.transforms.ComposeTransform.with_cache(self,cache_size=1)
torch.distributions.transforms.ExpTransform(Transform)
torch.distributions.transforms.ExpTransform.__eq__(self,other)
torch.distributions.transforms.ExpTransform._call(self,x)
torch.distributions.transforms.ExpTransform._inverse(self,y)
torch.distributions.transforms.ExpTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.LowerCholeskyTransform(Transform)
torch.distributions.transforms.LowerCholeskyTransform.__eq__(self,other)
torch.distributions.transforms.LowerCholeskyTransform._call(self,x)
torch.distributions.transforms.LowerCholeskyTransform._inverse(self,y)
torch.distributions.transforms.PowerTransform(self,exponent,cache_size=0)
torch.distributions.transforms.PowerTransform.__eq__(self,other)
torch.distributions.transforms.PowerTransform.__init__(self,exponent,cache_size=0)
torch.distributions.transforms.PowerTransform._call(self,x)
torch.distributions.transforms.PowerTransform._inverse(self,y)
torch.distributions.transforms.PowerTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.PowerTransform.with_cache(self,cache_size=1)
torch.distributions.transforms.SigmoidTransform(Transform)
torch.distributions.transforms.SigmoidTransform.__eq__(self,other)
torch.distributions.transforms.SigmoidTransform._call(self,x)
torch.distributions.transforms.SigmoidTransform._inverse(self,y)
torch.distributions.transforms.SigmoidTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.SoftmaxTransform(Transform)
torch.distributions.transforms.SoftmaxTransform.__eq__(self,other)
torch.distributions.transforms.SoftmaxTransform._call(self,x)
torch.distributions.transforms.SoftmaxTransform._inverse(self,y)
torch.distributions.transforms.StackTransform(self,tseq,dim=0,cache_size=0)
torch.distributions.transforms.StackTransform.__init__(self,tseq,dim=0,cache_size=0)
torch.distributions.transforms.StackTransform._call(self,x)
torch.distributions.transforms.StackTransform._inverse(self,y)
torch.distributions.transforms.StackTransform._slice(self,z)
torch.distributions.transforms.StackTransform.bijective(self)
torch.distributions.transforms.StackTransform.codomain(self)
torch.distributions.transforms.StackTransform.domain(self)
torch.distributions.transforms.StackTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.StackTransform.with_cache(self,cache_size=1)
torch.distributions.transforms.StickBreakingTransform(Transform)
torch.distributions.transforms.StickBreakingTransform.__eq__(self,other)
torch.distributions.transforms.StickBreakingTransform._call(self,x)
torch.distributions.transforms.StickBreakingTransform._inverse(self,y)
torch.distributions.transforms.StickBreakingTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.TanhTransform(Transform)
torch.distributions.transforms.TanhTransform.__eq__(self,other)
torch.distributions.transforms.TanhTransform._call(self,x)
torch.distributions.transforms.TanhTransform._inverse(self,y)
torch.distributions.transforms.TanhTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.Transform(self,cache_size=0)
torch.distributions.transforms.Transform.__eq__(self,other)
torch.distributions.transforms.Transform.__init__(self,cache_size=0)
torch.distributions.transforms.Transform.__ne__(self,other)
torch.distributions.transforms.Transform.__repr__(self)
torch.distributions.transforms.Transform._call(self,x)
torch.distributions.transforms.Transform._inv_call(self,y)
torch.distributions.transforms.Transform._inverse(self,y)
torch.distributions.transforms.Transform.inv(self)
torch.distributions.transforms.Transform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms.Transform.sign(self)
torch.distributions.transforms.Transform.with_cache(self,cache_size=1)
torch.distributions.transforms._InverseTransform(self,transform)
torch.distributions.transforms._InverseTransform.__eq__(self,other)
torch.distributions.transforms._InverseTransform.__init__(self,transform)
torch.distributions.transforms._InverseTransform.bijective(self)
torch.distributions.transforms._InverseTransform.codomain(self)
torch.distributions.transforms._InverseTransform.domain(self)
torch.distributions.transforms._InverseTransform.event_dim(self)
torch.distributions.transforms._InverseTransform.inv(self)
torch.distributions.transforms._InverseTransform.log_abs_det_jacobian(self,x,y)
torch.distributions.transforms._InverseTransform.sign(self)
torch.distributions.transforms._InverseTransform.with_cache(self,cache_size=1)
torch.distributions.transforms._clipped_sigmoid(x)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/constraint_registry.py----------------------------------------
A:torch.distributions.constraint_registry.constraint->type(constraint)
A:torch.distributions.constraint_registry.biject_to->ConstraintRegistry()
A:torch.distributions.constraint_registry.transform_to->ConstraintRegistry()
torch.distributions.constraint_registry.ConstraintRegistry(self)
torch.distributions.constraint_registry.ConstraintRegistry.__init__(self)
torch.distributions.constraint_registry.ConstraintRegistry.register(self,constraint,factory=None)
torch.distributions.constraint_registry._biject_to_cat(constraint)
torch.distributions.constraint_registry._biject_to_simplex(constraint)
torch.distributions.constraint_registry._biject_to_stack(constraint)
torch.distributions.constraint_registry._transform_to_cat(constraint)
torch.distributions.constraint_registry._transform_to_greater_than(constraint)
torch.distributions.constraint_registry._transform_to_interval(constraint)
torch.distributions.constraint_registry._transform_to_less_than(constraint)
torch.distributions.constraint_registry._transform_to_lower_cholesky(constraint)
torch.distributions.constraint_registry._transform_to_positive(constraint)
torch.distributions.constraint_registry._transform_to_real(constraint)
torch.distributions.constraint_registry._transform_to_simplex(constraint)
torch.distributions.constraint_registry._transform_to_stack(constraint)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/relaxed_categorical.py----------------------------------------
A:torch.distributions.relaxed_categorical.self._categorical->Categorical(probs, logits)
A:torch.distributions.relaxed_categorical.new->self._get_checked_instance(RelaxedOneHotCategorical, _instance)
A:torch.distributions.relaxed_categorical.batch_shape->torch.Size(batch_shape)
A:torch.distributions.relaxed_categorical.new._categorical->self._categorical.expand(batch_shape)
A:torch.distributions.relaxed_categorical.shape->self._extended_shape(sample_shape)
A:torch.distributions.relaxed_categorical.uniforms->clamp_probs(torch.rand(shape, dtype=self.logits.dtype, device=self.logits.device))
A:torch.distributions.relaxed_categorical.(logits, value)->broadcast_all(self.logits, value)
A:torch.distributions.relaxed_categorical.score->(score - score.logsumexp(dim=-1, keepdim=True)).sum(-1)
A:torch.distributions.relaxed_categorical.base_dist->ExpRelaxedCategorical(temperature, probs, logits)
torch.distributions.RelaxedOneHotCategorical(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.RelaxedOneHotCategorical.expand(self,batch_shape,_instance=None)
torch.distributions.RelaxedOneHotCategorical.logits(self)
torch.distributions.RelaxedOneHotCategorical.probs(self)
torch.distributions.RelaxedOneHotCategorical.temperature(self)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.__init__(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical._new(self,*args,**kwargs)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.expand(self,batch_shape,_instance=None)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.log_prob(self,value)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.logits(self)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.param_shape(self)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.probs(self)
torch.distributions.relaxed_categorical.ExpRelaxedCategorical.rsample(self,sample_shape=torch.Size())
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.__init__(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.expand(self,batch_shape,_instance=None)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.logits(self)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.probs(self)
torch.distributions.relaxed_categorical.RelaxedOneHotCategorical.temperature(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/von_mises.py----------------------------------------
A:torch.distributions.von_mises.coef->list(coef)
A:torch.distributions.von_mises.result->torch.where(x < 3.75, small, large)
A:torch.distributions.von_mises.small->small.log().log()
A:torch.distributions.von_mises.done->torch.zeros(x.shape, dtype=torch.bool, device=loc.device)
A:torch.distributions.von_mises.u->torch.rand((3,) + x.shape, dtype=loc.dtype, device=loc.device)
A:torch.distributions.von_mises.(u1, u2, u3)->torch.rand((3,) + x.shape, dtype=loc.dtype, device=loc.device).unbind()
A:torch.distributions.von_mises.z->torch.cos(math.pi * u1)
A:torch.distributions.von_mises.x->torch.empty(shape, dtype=self.loc.dtype, device=self.loc.device)
A:torch.distributions.von_mises.(self.loc, self.concentration)->broadcast_all(loc, concentration)
A:torch.distributions.von_mises.event_shape->torch.Size()
A:torch.distributions.von_mises.shape->self._extended_shape(sample_shape)
A:torch.distributions.von_mises.validate_args->self.__dict__.get('_validate_args')
A:torch.distributions.von_mises.loc->self.loc.expand(batch_shape)
A:torch.distributions.von_mises.concentration->self.concentration.expand(batch_shape)
torch.distributions.VonMises(self,loc,concentration,validate_args=None)
torch.distributions.VonMises.expand(self,batch_shape)
torch.distributions.VonMises.log_prob(self,value)
torch.distributions.VonMises.mean(self)
torch.distributions.VonMises.sample(self,sample_shape=torch.Size())
torch.distributions.VonMises.variance(self)
torch.distributions.von_mises.VonMises(self,loc,concentration,validate_args=None)
torch.distributions.von_mises.VonMises.__init__(self,loc,concentration,validate_args=None)
torch.distributions.von_mises.VonMises.expand(self,batch_shape)
torch.distributions.von_mises.VonMises.log_prob(self,value)
torch.distributions.von_mises.VonMises.mean(self)
torch.distributions.von_mises.VonMises.sample(self,sample_shape=torch.Size())
torch.distributions.von_mises.VonMises.variance(self)
torch.distributions.von_mises._eval_poly(y,coef)
torch.distributions.von_mises._log_modified_bessel_fn(x,order=0)
torch.distributions.von_mises._rejection_sample(loc,concentration,proposal_r,x)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/normal.py----------------------------------------
A:torch.distributions.normal.(self.loc, self.scale)->broadcast_all(loc, scale)
A:torch.distributions.normal.batch_shape->torch.Size(batch_shape)
A:torch.distributions.normal.new->self._get_checked_instance(Normal, _instance)
A:torch.distributions.normal.new.loc->self.loc.expand(batch_shape)
A:torch.distributions.normal.new.scale->self.scale.expand(batch_shape)
A:torch.distributions.normal.shape->self._extended_shape(sample_shape)
A:torch.distributions.normal.eps->_standard_normal(shape, dtype=self.loc.dtype, device=self.loc.device)
torch.distributions.Normal(self,loc,scale,validate_args=None)
torch.distributions.Normal._log_normalizer(self,x,y)
torch.distributions.Normal._natural_params(self)
torch.distributions.Normal.cdf(self,value)
torch.distributions.Normal.entropy(self)
torch.distributions.Normal.expand(self,batch_shape,_instance=None)
torch.distributions.Normal.icdf(self,value)
torch.distributions.Normal.log_prob(self,value)
torch.distributions.Normal.mean(self)
torch.distributions.Normal.rsample(self,sample_shape=torch.Size())
torch.distributions.Normal.sample(self,sample_shape=torch.Size())
torch.distributions.Normal.stddev(self)
torch.distributions.Normal.variance(self)
torch.distributions.normal.Normal(self,loc,scale,validate_args=None)
torch.distributions.normal.Normal.__init__(self,loc,scale,validate_args=None)
torch.distributions.normal.Normal._log_normalizer(self,x,y)
torch.distributions.normal.Normal._natural_params(self)
torch.distributions.normal.Normal.cdf(self,value)
torch.distributions.normal.Normal.entropy(self)
torch.distributions.normal.Normal.expand(self,batch_shape,_instance=None)
torch.distributions.normal.Normal.icdf(self,value)
torch.distributions.normal.Normal.log_prob(self,value)
torch.distributions.normal.Normal.mean(self)
torch.distributions.normal.Normal.rsample(self,sample_shape=torch.Size())
torch.distributions.normal.Normal.sample(self,sample_shape=torch.Size())
torch.distributions.normal.Normal.stddev(self)
torch.distributions.normal.Normal.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/multinomial.py----------------------------------------
A:torch.distributions.multinomial.self._categorical->Categorical(probs=probs, logits=logits)
A:torch.distributions.multinomial.new->self._get_checked_instance(Multinomial, _instance)
A:torch.distributions.multinomial.batch_shape->torch.Size(batch_shape)
A:torch.distributions.multinomial.new._categorical->self._categorical.expand(batch_shape)
A:torch.distributions.multinomial.sample_shape->torch.Size(sample_shape)
A:torch.distributions.multinomial.samples->samples.permute(*shifted_idx).permute(*shifted_idx)
A:torch.distributions.multinomial.shifted_idx->list(range(samples.dim()))
A:torch.distributions.multinomial.counts->samples.permute(*shifted_idx).permute(*shifted_idx).new(self._extended_shape(sample_shape)).zero_()
A:torch.distributions.multinomial.(logits, value)->broadcast_all(self.logits, value)
A:torch.distributions.multinomial.logits->logits.clone(memory_format=torch.contiguous_format).clone(memory_format=torch.contiguous_format)
A:torch.distributions.multinomial.log_factorial_n->torch.lgamma(value.sum(-1) + 1)
A:torch.distributions.multinomial.log_factorial_xs->torch.lgamma(value + 1).sum(-1)
A:torch.distributions.multinomial.log_powers->(logits * value).sum(-1)
torch.distributions.Multinomial(self,total_count=1,probs=None,logits=None,validate_args=None)
torch.distributions.Multinomial._new(self,*args,**kwargs)
torch.distributions.Multinomial.expand(self,batch_shape,_instance=None)
torch.distributions.Multinomial.log_prob(self,value)
torch.distributions.Multinomial.logits(self)
torch.distributions.Multinomial.mean(self)
torch.distributions.Multinomial.param_shape(self)
torch.distributions.Multinomial.probs(self)
torch.distributions.Multinomial.sample(self,sample_shape=torch.Size())
torch.distributions.Multinomial.support(self)
torch.distributions.Multinomial.variance(self)
torch.distributions.multinomial.Multinomial(self,total_count=1,probs=None,logits=None,validate_args=None)
torch.distributions.multinomial.Multinomial.__init__(self,total_count=1,probs=None,logits=None,validate_args=None)
torch.distributions.multinomial.Multinomial._new(self,*args,**kwargs)
torch.distributions.multinomial.Multinomial.expand(self,batch_shape,_instance=None)
torch.distributions.multinomial.Multinomial.log_prob(self,value)
torch.distributions.multinomial.Multinomial.logits(self)
torch.distributions.multinomial.Multinomial.mean(self)
torch.distributions.multinomial.Multinomial.param_shape(self)
torch.distributions.multinomial.Multinomial.probs(self)
torch.distributions.multinomial.Multinomial.sample(self,sample_shape=torch.Size())
torch.distributions.multinomial.Multinomial.support(self)
torch.distributions.multinomial.Multinomial.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/negative_binomial.py----------------------------------------
A:torch.distributions.negative_binomial.(self.total_count, self.probs)->broadcast_all(total_count, probs)
A:torch.distributions.negative_binomial.self.total_count->self.total_count.type_as(self.logits)
A:torch.distributions.negative_binomial.(self.total_count, self.logits)->broadcast_all(total_count, logits)
A:torch.distributions.negative_binomial.batch_shape->torch.Size(batch_shape)
A:torch.distributions.negative_binomial.new->self._get_checked_instance(NegativeBinomial, _instance)
A:torch.distributions.negative_binomial.new.total_count->self.total_count.expand(batch_shape)
A:torch.distributions.negative_binomial.new.probs->self.probs.expand(batch_shape)
A:torch.distributions.negative_binomial.new.logits->self.logits.expand(batch_shape)
A:torch.distributions.negative_binomial.rate->self._gamma.sample(sample_shape=sample_shape)
torch.distributions.NegativeBinomial(self,total_count,probs=None,logits=None,validate_args=None)
torch.distributions.NegativeBinomial._gamma(self)
torch.distributions.NegativeBinomial._new(self,*args,**kwargs)
torch.distributions.NegativeBinomial.expand(self,batch_shape,_instance=None)
torch.distributions.NegativeBinomial.log_prob(self,value)
torch.distributions.NegativeBinomial.logits(self)
torch.distributions.NegativeBinomial.mean(self)
torch.distributions.NegativeBinomial.param_shape(self)
torch.distributions.NegativeBinomial.probs(self)
torch.distributions.NegativeBinomial.sample(self,sample_shape=torch.Size())
torch.distributions.NegativeBinomial.variance(self)
torch.distributions.negative_binomial.NegativeBinomial(self,total_count,probs=None,logits=None,validate_args=None)
torch.distributions.negative_binomial.NegativeBinomial.__init__(self,total_count,probs=None,logits=None,validate_args=None)
torch.distributions.negative_binomial.NegativeBinomial._gamma(self)
torch.distributions.negative_binomial.NegativeBinomial._new(self,*args,**kwargs)
torch.distributions.negative_binomial.NegativeBinomial.expand(self,batch_shape,_instance=None)
torch.distributions.negative_binomial.NegativeBinomial.log_prob(self,value)
torch.distributions.negative_binomial.NegativeBinomial.logits(self)
torch.distributions.negative_binomial.NegativeBinomial.mean(self)
torch.distributions.negative_binomial.NegativeBinomial.param_shape(self)
torch.distributions.negative_binomial.NegativeBinomial.probs(self)
torch.distributions.negative_binomial.NegativeBinomial.sample(self,sample_shape=torch.Size())
torch.distributions.negative_binomial.NegativeBinomial.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/chi2.py----------------------------------------
A:torch.distributions.chi2.new->self._get_checked_instance(Chi2, _instance)
torch.distributions.Chi2(self,df,validate_args=None)
torch.distributions.Chi2.df(self)
torch.distributions.Chi2.expand(self,batch_shape,_instance=None)
torch.distributions.chi2.Chi2(self,df,validate_args=None)
torch.distributions.chi2.Chi2.__init__(self,df,validate_args=None)
torch.distributions.chi2.Chi2.df(self)
torch.distributions.chi2.Chi2.expand(self,batch_shape,_instance=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/kl.py----------------------------------------
A:torch.distributions.kl.n->bmat.size(-1)
A:torch.distributions.kl.m->bmat.size(-2)
A:torch.distributions.kl.flat_trace->bmat.reshape(-1, m * n).pow(2).sum(-1)
A:torch.distributions.kl.fun->_dispatch_kl(type(p), type(q))
A:torch.distributions.kl.kl[inf_idxs]->_infinite_like(kl[inf_idxs])
A:torch.distributions.kl.sum_p_concentration->p.concentration.sum(-1)
A:torch.distributions.kl.sum_q_concentration->q.concentration.sum(-1)
A:torch.distributions.kl.t2->(4 * p.scale * q.scale).log()
A:torch.distributions.kl.lg_normal->p._log_normalizer(*p_nparams)
A:torch.distributions.kl.gradients->torch.autograd.grad(lg_normal.sum(), p_nparams, create_graph=True)
A:torch.distributions.kl.t3->((p.high + p.low - 2 * q.loc) / 2).pow(2)
A:torch.distributions.kl.loc_abs_diff->(p.loc - q.loc).abs()
A:torch.distributions.kl.term3->_batch_mahalanobis(q._unbroadcasted_scale_tril, q.loc - p.loc)
A:torch.distributions.kl.term21->_batch_trace_XXT(torch.triangular_solve(p_cov_factor, q_scale_tril, upper=False)[0])
A:torch.distributions.kl.term22->_batch_trace_XXT(torch.triangular_solve(p_cov_diag, q_scale_tril, upper=False)[0])
A:torch.distributions.kl.term23->_batch_trace_XXT(A * p._unbroadcasted_cov_diag.sqrt().unsqueeze(-2))
A:torch.distributions.kl.term24->_batch_trace_XXT(A.matmul(p._unbroadcasted_cov_factor))
A:torch.distributions.kl.combined_batch_shape->torch._C._infer_size(q._unbroadcasted_scale_tril.shape[:-2], p._unbroadcasted_scale_tril.shape[:-2])
A:torch.distributions.kl.q_scale_tril->q._unbroadcasted_scale_tril.expand(combined_batch_shape + (n, n))
A:torch.distributions.kl.p_cov_factor->p._unbroadcasted_cov_factor.expand(combined_batch_shape + (n, p.cov_factor.size(-1)))
A:torch.distributions.kl.p_cov_diag->torch.diag_embed(p._unbroadcasted_cov_diag.sqrt()).expand(combined_batch_shape + (n, n))
A:torch.distributions.kl.p_scale_tril->p._unbroadcasted_scale_tril.expand(combined_batch_shape + (n, n))
A:torch.distributions.kl.term2->_batch_trace_XXT(torch.triangular_solve(p_scale_tril, q_scale_tril, upper=False)[0])
A:torch.distributions.kl.var_ratio->(p.scale / q.scale).pow(2)
A:torch.distributions.kl.t1->((p.scale + q.scale).pow(2) + (p.loc - q.loc).pow(2)).log()
A:torch.distributions.kl.extra_event_dim->len(p.event_shape)
A:torch.distributions.kl.base_kl_divergence->kl_divergence(p.base_dist, q.base_dist)
A:torch.distributions.kl.result->kl_divergence(p.base_dist, q.base_dist)
A:torch.distributions.kl.var_normal->q.scale.pow(2)
A:torch.distributions.kl.rate_sqr->p.rate.pow(2)
A:torch.distributions.kl.beta_sqr->p.rate.pow(2)
A:torch.distributions.kl.var_scale_sqr_ratio->(p.scale / q.scale).pow(2)
A:torch.distributions.kl.t4->(p.alpha * common_term - q.loc).pow(2)
torch.distributions.kl._Match(self,*types)
torch.distributions.kl._Match.__eq__(self,other)
torch.distributions.kl._Match.__init__(self,*types)
torch.distributions.kl._Match.__le__(self,other)
torch.distributions.kl._batch_trace_XXT(bmat)
torch.distributions.kl._dispatch_kl(type_p,type_q)
torch.distributions.kl._infinite_like(tensor)
torch.distributions.kl._kl_bernoulli_bernoulli(p,q)
torch.distributions.kl._kl_bernoulli_poisson(p,q)
torch.distributions.kl._kl_beta_beta(p,q)
torch.distributions.kl._kl_beta_continuous_bernoulli(p,q)
torch.distributions.kl._kl_beta_exponential(p,q)
torch.distributions.kl._kl_beta_gamma(p,q)
torch.distributions.kl._kl_beta_infinity(p,q)
torch.distributions.kl._kl_beta_normal(p,q)
torch.distributions.kl._kl_beta_uniform(p,q)
torch.distributions.kl._kl_binomial_binomial(p,q)
torch.distributions.kl._kl_categorical_categorical(p,q)
torch.distributions.kl._kl_cauchy_cauchy(p,q)
torch.distributions.kl._kl_continuous_bernoulli_continuous_bernoulli(p,q)
torch.distributions.kl._kl_continuous_bernoulli_exponential(p,q)
torch.distributions.kl._kl_continuous_bernoulli_infinity(p,q)
torch.distributions.kl._kl_continuous_bernoulli_normal(p,q)
torch.distributions.kl._kl_continuous_bernoulli_uniform(p,q)
torch.distributions.kl._kl_dirichlet_dirichlet(p,q)
torch.distributions.kl._kl_expfamily_expfamily(p,q)
torch.distributions.kl._kl_exponential_exponential(p,q)
torch.distributions.kl._kl_exponential_gamma(p,q)
torch.distributions.kl._kl_exponential_gumbel(p,q)
torch.distributions.kl._kl_exponential_infinity(p,q)
torch.distributions.kl._kl_exponential_normal(p,q)
torch.distributions.kl._kl_gamma_exponential(p,q)
torch.distributions.kl._kl_gamma_gamma(p,q)
torch.distributions.kl._kl_gamma_gumbel(p,q)
torch.distributions.kl._kl_gamma_infinity(p,q)
torch.distributions.kl._kl_gamma_normal(p,q)
torch.distributions.kl._kl_geometric_geometric(p,q)
torch.distributions.kl._kl_gumbel_gumbel(p,q)
torch.distributions.kl._kl_gumbel_infinity(p,q)
torch.distributions.kl._kl_gumbel_normal(p,q)
torch.distributions.kl._kl_halfnormal_halfnormal(p,q)
torch.distributions.kl._kl_independent_independent(p,q)
torch.distributions.kl._kl_laplace_infinity(p,q)
torch.distributions.kl._kl_laplace_laplace(p,q)
torch.distributions.kl._kl_laplace_normal(p,q)
torch.distributions.kl._kl_lowrankmultivariatenormal_lowrankmultivariatenormal(p,q)
torch.distributions.kl._kl_lowrankmultivariatenormal_multivariatenormal(p,q)
torch.distributions.kl._kl_multivariatenormal_lowrankmultivariatenormal(p,q)
torch.distributions.kl._kl_multivariatenormal_multivariatenormal(p,q)
torch.distributions.kl._kl_normal_gumbel(p,q)
torch.distributions.kl._kl_normal_infinity(p,q)
torch.distributions.kl._kl_normal_normal(p,q)
torch.distributions.kl._kl_onehotcategorical_onehotcategorical(p,q)
torch.distributions.kl._kl_pareto_exponential(p,q)
torch.distributions.kl._kl_pareto_gamma(p,q)
torch.distributions.kl._kl_pareto_infinity(p,q)
torch.distributions.kl._kl_pareto_normal(p,q)
torch.distributions.kl._kl_pareto_pareto(p,q)
torch.distributions.kl._kl_poisson_infinity(p,q)
torch.distributions.kl._kl_poisson_poisson(p,q)
torch.distributions.kl._kl_transformed_transformed(p,q)
torch.distributions.kl._kl_uniform_beta(p,q)
torch.distributions.kl._kl_uniform_continuous_bernoulli(p,q)
torch.distributions.kl._kl_uniform_exponetial(p,q)
torch.distributions.kl._kl_uniform_gamma(p,q)
torch.distributions.kl._kl_uniform_gumbel(p,q)
torch.distributions.kl._kl_uniform_normal(p,q)
torch.distributions.kl._kl_uniform_pareto(p,q)
torch.distributions.kl._kl_uniform_uniform(p,q)
torch.distributions.kl._x_log_x(tensor)
torch.distributions.kl.kl_divergence(p,q)
torch.distributions.kl.register_kl(type_p,type_q)
torch.distributions.kl_divergence(p,q)
torch.distributions.register_kl(type_p,type_q)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/bernoulli.py----------------------------------------
A:torch.distributions.bernoulli.is_scalar->isinstance(logits, Number)
A:torch.distributions.bernoulli.(self.probs,)->broadcast_all(probs)
A:torch.distributions.bernoulli.(self.logits,)->broadcast_all(logits)
A:torch.distributions.bernoulli.batch_shape->torch.Size(batch_shape)
A:torch.distributions.bernoulli.new->self._get_checked_instance(Bernoulli, _instance)
A:torch.distributions.bernoulli.new.probs->self.probs.expand(batch_shape)
A:torch.distributions.bernoulli.new.logits->self.logits.expand(batch_shape)
A:torch.distributions.bernoulli.shape->self._extended_shape(sample_shape)
A:torch.distributions.bernoulli.(logits, value)->broadcast_all(self.logits, value)
A:torch.distributions.bernoulli.values->values.expand((-1,) + self._batch_shape).expand((-1,) + self._batch_shape)
torch.distributions.Bernoulli(self,probs=None,logits=None,validate_args=None)
torch.distributions.Bernoulli._log_normalizer(self,x)
torch.distributions.Bernoulli._natural_params(self)
torch.distributions.Bernoulli._new(self,*args,**kwargs)
torch.distributions.Bernoulli.entropy(self)
torch.distributions.Bernoulli.enumerate_support(self,expand=True)
torch.distributions.Bernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.Bernoulli.log_prob(self,value)
torch.distributions.Bernoulli.logits(self)
torch.distributions.Bernoulli.mean(self)
torch.distributions.Bernoulli.param_shape(self)
torch.distributions.Bernoulli.probs(self)
torch.distributions.Bernoulli.sample(self,sample_shape=torch.Size())
torch.distributions.Bernoulli.variance(self)
torch.distributions.bernoulli.Bernoulli(self,probs=None,logits=None,validate_args=None)
torch.distributions.bernoulli.Bernoulli.__init__(self,probs=None,logits=None,validate_args=None)
torch.distributions.bernoulli.Bernoulli._log_normalizer(self,x)
torch.distributions.bernoulli.Bernoulli._natural_params(self)
torch.distributions.bernoulli.Bernoulli._new(self,*args,**kwargs)
torch.distributions.bernoulli.Bernoulli.entropy(self)
torch.distributions.bernoulli.Bernoulli.enumerate_support(self,expand=True)
torch.distributions.bernoulli.Bernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.bernoulli.Bernoulli.log_prob(self,value)
torch.distributions.bernoulli.Bernoulli.logits(self)
torch.distributions.bernoulli.Bernoulli.mean(self)
torch.distributions.bernoulli.Bernoulli.param_shape(self)
torch.distributions.bernoulli.Bernoulli.probs(self)
torch.distributions.bernoulli.Bernoulli.sample(self,sample_shape=torch.Size())
torch.distributions.bernoulli.Bernoulli.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/gumbel.py----------------------------------------
A:torch.distributions.gumbel.(self.loc, self.scale)->broadcast_all(loc, scale)
A:torch.distributions.gumbel.finfo->torch.finfo(self.loc.dtype)
A:torch.distributions.gumbel.base_dist->Uniform(torch.full_like(self.loc, finfo.tiny), torch.full_like(self.loc, 1 - finfo.eps))
A:torch.distributions.gumbel.new->self._get_checked_instance(Gumbel, _instance)
A:torch.distributions.gumbel.new.loc->self.loc.expand(batch_shape)
A:torch.distributions.gumbel.new.scale->self.scale.expand(batch_shape)
torch.distributions.Gumbel(self,loc,scale,validate_args=None)
torch.distributions.Gumbel.entropy(self)
torch.distributions.Gumbel.expand(self,batch_shape,_instance=None)
torch.distributions.Gumbel.log_prob(self,value)
torch.distributions.Gumbel.mean(self)
torch.distributions.Gumbel.stddev(self)
torch.distributions.Gumbel.variance(self)
torch.distributions.gumbel.Gumbel(self,loc,scale,validate_args=None)
torch.distributions.gumbel.Gumbel.__init__(self,loc,scale,validate_args=None)
torch.distributions.gumbel.Gumbel.entropy(self)
torch.distributions.gumbel.Gumbel.expand(self,batch_shape,_instance=None)
torch.distributions.gumbel.Gumbel.log_prob(self,value)
torch.distributions.gumbel.Gumbel.mean(self)
torch.distributions.gumbel.Gumbel.stddev(self)
torch.distributions.gumbel.Gumbel.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/dirichlet.py----------------------------------------
A:torch.distributions.dirichlet.total->self.concentration.expand(shape).sum(-1, True).expand_as(concentration)
A:torch.distributions.dirichlet.grad->torch._dirichlet_grad(x, concentration, total)
A:torch.distributions.dirichlet.x->torch._sample_dirichlet(concentration)
A:torch.distributions.dirichlet.new->self._get_checked_instance(Dirichlet, _instance)
A:torch.distributions.dirichlet.batch_shape->torch.Size(batch_shape)
A:torch.distributions.dirichlet.new.concentration->self.concentration.expand(batch_shape + self.event_shape)
A:torch.distributions.dirichlet.shape->self._extended_shape(sample_shape)
A:torch.distributions.dirichlet.concentration->self.concentration.expand(shape)
A:torch.distributions.dirichlet.con0->self.concentration.sum(-1, True)
A:torch.distributions.dirichlet.k->self.concentration.size(-1)
A:torch.distributions.dirichlet.a0->self.concentration.sum(-1)
torch.distributions.Dirichlet(self,concentration,validate_args=None)
torch.distributions.Dirichlet._log_normalizer(self,x)
torch.distributions.Dirichlet._natural_params(self)
torch.distributions.Dirichlet.entropy(self)
torch.distributions.Dirichlet.expand(self,batch_shape,_instance=None)
torch.distributions.Dirichlet.log_prob(self,value)
torch.distributions.Dirichlet.mean(self)
torch.distributions.Dirichlet.rsample(self,sample_shape=())
torch.distributions.Dirichlet.variance(self)
torch.distributions.dirichlet.Dirichlet(self,concentration,validate_args=None)
torch.distributions.dirichlet.Dirichlet.__init__(self,concentration,validate_args=None)
torch.distributions.dirichlet.Dirichlet._log_normalizer(self,x)
torch.distributions.dirichlet.Dirichlet._natural_params(self)
torch.distributions.dirichlet.Dirichlet.entropy(self)
torch.distributions.dirichlet.Dirichlet.expand(self,batch_shape,_instance=None)
torch.distributions.dirichlet.Dirichlet.log_prob(self,value)
torch.distributions.dirichlet.Dirichlet.mean(self)
torch.distributions.dirichlet.Dirichlet.rsample(self,sample_shape=())
torch.distributions.dirichlet.Dirichlet.variance(self)
torch.distributions.dirichlet._Dirichlet(Function)
torch.distributions.dirichlet._Dirichlet.backward(ctx,grad_output)
torch.distributions.dirichlet._Dirichlet.forward(ctx,concentration)
torch.distributions.dirichlet._Dirichlet_backward(x,concentration,grad_output)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/relaxed_bernoulli.py----------------------------------------
A:torch.distributions.relaxed_bernoulli.is_scalar->isinstance(logits, Number)
A:torch.distributions.relaxed_bernoulli.(self.probs,)->broadcast_all(probs)
A:torch.distributions.relaxed_bernoulli.(self.logits,)->broadcast_all(logits)
A:torch.distributions.relaxed_bernoulli.batch_shape->torch.Size(batch_shape)
A:torch.distributions.relaxed_bernoulli.new->self._get_checked_instance(RelaxedBernoulli, _instance)
A:torch.distributions.relaxed_bernoulli.new.probs->self.probs.expand(batch_shape)
A:torch.distributions.relaxed_bernoulli.new.logits->self.logits.expand(batch_shape)
A:torch.distributions.relaxed_bernoulli.shape->self._extended_shape(sample_shape)
A:torch.distributions.relaxed_bernoulli.probs->clamp_probs(self.probs.expand(shape))
A:torch.distributions.relaxed_bernoulli.uniforms->clamp_probs(torch.rand(shape, dtype=probs.dtype, device=probs.device))
A:torch.distributions.relaxed_bernoulli.(logits, value)->broadcast_all(self.logits, value)
A:torch.distributions.relaxed_bernoulli.base_dist->LogitRelaxedBernoulli(temperature, probs, logits)
torch.distributions.RelaxedBernoulli(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.RelaxedBernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.RelaxedBernoulli.logits(self)
torch.distributions.RelaxedBernoulli.probs(self)
torch.distributions.RelaxedBernoulli.temperature(self)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.__init__(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli._new(self,*args,**kwargs)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.log_prob(self,value)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.logits(self)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.param_shape(self)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.probs(self)
torch.distributions.relaxed_bernoulli.LogitRelaxedBernoulli.rsample(self,sample_shape=torch.Size())
torch.distributions.relaxed_bernoulli.RelaxedBernoulli(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_bernoulli.RelaxedBernoulli.__init__(self,temperature,probs=None,logits=None,validate_args=None)
torch.distributions.relaxed_bernoulli.RelaxedBernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.relaxed_bernoulli.RelaxedBernoulli.logits(self)
torch.distributions.relaxed_bernoulli.RelaxedBernoulli.probs(self)
torch.distributions.relaxed_bernoulli.RelaxedBernoulli.temperature(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/independent.py----------------------------------------
A:torch.distributions.independent.new->self._get_checked_instance(Independent, _instance)
A:torch.distributions.independent.batch_shape->torch.Size(batch_shape)
A:torch.distributions.independent.new.base_dist->self.base_dist.expand(batch_shape + self.event_shape[:self.reinterpreted_batch_ndims])
A:torch.distributions.independent.log_prob->self.base_dist.log_prob(value)
A:torch.distributions.independent.entropy->self.base_dist.entropy()
torch.distributions.Independent(self,base_distribution,reinterpreted_batch_ndims,validate_args=None)
torch.distributions.Independent.__repr__(self)
torch.distributions.Independent.entropy(self)
torch.distributions.Independent.enumerate_support(self,expand=True)
torch.distributions.Independent.expand(self,batch_shape,_instance=None)
torch.distributions.Independent.has_enumerate_support(self)
torch.distributions.Independent.has_rsample(self)
torch.distributions.Independent.log_prob(self,value)
torch.distributions.Independent.mean(self)
torch.distributions.Independent.rsample(self,sample_shape=torch.Size())
torch.distributions.Independent.sample(self,sample_shape=torch.Size())
torch.distributions.Independent.support(self)
torch.distributions.Independent.variance(self)
torch.distributions.independent.Independent(self,base_distribution,reinterpreted_batch_ndims,validate_args=None)
torch.distributions.independent.Independent.__init__(self,base_distribution,reinterpreted_batch_ndims,validate_args=None)
torch.distributions.independent.Independent.__repr__(self)
torch.distributions.independent.Independent.entropy(self)
torch.distributions.independent.Independent.enumerate_support(self,expand=True)
torch.distributions.independent.Independent.expand(self,batch_shape,_instance=None)
torch.distributions.independent.Independent.has_enumerate_support(self)
torch.distributions.independent.Independent.has_rsample(self)
torch.distributions.independent.Independent.log_prob(self,value)
torch.distributions.independent.Independent.mean(self)
torch.distributions.independent.Independent.rsample(self,sample_shape=torch.Size())
torch.distributions.independent.Independent.sample(self,sample_shape=torch.Size())
torch.distributions.independent.Independent.support(self)
torch.distributions.independent.Independent.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/uniform.py----------------------------------------
A:torch.distributions.uniform.(self.low, self.high)->broadcast_all(low, high)
A:torch.distributions.uniform.batch_shape->torch.Size(batch_shape)
A:torch.distributions.uniform.new->self._get_checked_instance(Uniform, _instance)
A:torch.distributions.uniform.new.low->self.low.expand(batch_shape)
A:torch.distributions.uniform.new.high->self.high.expand(batch_shape)
A:torch.distributions.uniform.shape->self._extended_shape(sample_shape)
A:torch.distributions.uniform.rand->torch.rand(shape, dtype=self.low.dtype, device=self.low.device)
A:torch.distributions.uniform.lb->self.low.le(value).type_as(self.low)
A:torch.distributions.uniform.ub->self.high.gt(value).type_as(self.low)
torch.distributions.Uniform(self,low,high,validate_args=None)
torch.distributions.Uniform.cdf(self,value)
torch.distributions.Uniform.entropy(self)
torch.distributions.Uniform.expand(self,batch_shape,_instance=None)
torch.distributions.Uniform.icdf(self,value)
torch.distributions.Uniform.log_prob(self,value)
torch.distributions.Uniform.mean(self)
torch.distributions.Uniform.rsample(self,sample_shape=torch.Size())
torch.distributions.Uniform.stddev(self)
torch.distributions.Uniform.support(self)
torch.distributions.Uniform.variance(self)
torch.distributions.uniform.Uniform(self,low,high,validate_args=None)
torch.distributions.uniform.Uniform.__init__(self,low,high,validate_args=None)
torch.distributions.uniform.Uniform.cdf(self,value)
torch.distributions.uniform.Uniform.entropy(self)
torch.distributions.uniform.Uniform.expand(self,batch_shape,_instance=None)
torch.distributions.uniform.Uniform.icdf(self,value)
torch.distributions.uniform.Uniform.log_prob(self,value)
torch.distributions.uniform.Uniform.mean(self)
torch.distributions.uniform.Uniform.rsample(self,sample_shape=torch.Size())
torch.distributions.uniform.Uniform.stddev(self)
torch.distributions.uniform.Uniform.support(self)
torch.distributions.uniform.Uniform.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/categorical.py----------------------------------------
A:torch.distributions.categorical.new->self._get_checked_instance(Categorical, _instance)
A:torch.distributions.categorical.batch_shape->torch.Size(batch_shape)
A:torch.distributions.categorical.new.probs->self.probs.expand(param_shape)
A:torch.distributions.categorical.new.logits->self.logits.expand(param_shape)
A:torch.distributions.categorical.sample_shape->torch.Size(sample_shape)
A:torch.distributions.categorical.probs_2d->self.probs.reshape(-1, self._num_events)
A:torch.distributions.categorical.value->value.long().unsqueeze(-1).long().unsqueeze(-1)
A:torch.distributions.categorical.(value, log_pmf)->torch.broadcast_tensors(value, self.logits)
A:torch.distributions.categorical.logits->torch.clamp(self.logits, min=min_real)
A:torch.distributions.categorical.values->values.expand((-1,) + self._batch_shape).expand((-1,) + self._batch_shape)
torch.distributions.Categorical(self,probs=None,logits=None,validate_args=None)
torch.distributions.Categorical._new(self,*args,**kwargs)
torch.distributions.Categorical.entropy(self)
torch.distributions.Categorical.enumerate_support(self,expand=True)
torch.distributions.Categorical.expand(self,batch_shape,_instance=None)
torch.distributions.Categorical.log_prob(self,value)
torch.distributions.Categorical.logits(self)
torch.distributions.Categorical.mean(self)
torch.distributions.Categorical.param_shape(self)
torch.distributions.Categorical.probs(self)
torch.distributions.Categorical.sample(self,sample_shape=torch.Size())
torch.distributions.Categorical.support(self)
torch.distributions.Categorical.variance(self)
torch.distributions.categorical.Categorical(self,probs=None,logits=None,validate_args=None)
torch.distributions.categorical.Categorical.__init__(self,probs=None,logits=None,validate_args=None)
torch.distributions.categorical.Categorical._new(self,*args,**kwargs)
torch.distributions.categorical.Categorical.entropy(self)
torch.distributions.categorical.Categorical.enumerate_support(self,expand=True)
torch.distributions.categorical.Categorical.expand(self,batch_shape,_instance=None)
torch.distributions.categorical.Categorical.log_prob(self,value)
torch.distributions.categorical.Categorical.logits(self)
torch.distributions.categorical.Categorical.mean(self)
torch.distributions.categorical.Categorical.param_shape(self)
torch.distributions.categorical.Categorical.probs(self)
torch.distributions.categorical.Categorical.sample(self,sample_shape=torch.Size())
torch.distributions.categorical.Categorical.support(self)
torch.distributions.categorical.Categorical.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/continuous_bernoulli.py----------------------------------------
A:torch.distributions.continuous_bernoulli.is_scalar->isinstance(logits, Number)
A:torch.distributions.continuous_bernoulli.(self.probs,)->broadcast_all(probs)
A:torch.distributions.continuous_bernoulli.self.probs->clamp_probs(self.probs)
A:torch.distributions.continuous_bernoulli.(self.logits,)->broadcast_all(logits)
A:torch.distributions.continuous_bernoulli.batch_shape->torch.Size(batch_shape)
A:torch.distributions.continuous_bernoulli.new->self._get_checked_instance(ContinuousBernoulli, _instance)
A:torch.distributions.continuous_bernoulli.new.probs->self.probs.expand(batch_shape)
A:torch.distributions.continuous_bernoulli.new.logits->self.logits.expand(batch_shape)
A:torch.distributions.continuous_bernoulli.cut_probs->self._cut_probs()
A:torch.distributions.continuous_bernoulli.cut_probs_below_half->torch.where(torch.le(cut_probs, 0.5), cut_probs, torch.zeros_like(cut_probs))
A:torch.distributions.continuous_bernoulli.cut_probs_above_half->torch.where(torch.ge(cut_probs, 0.5), cut_probs, torch.ones_like(cut_probs))
A:torch.distributions.continuous_bernoulli.x->torch.pow(self.probs - 0.5, 2)
A:torch.distributions.continuous_bernoulli.shape->self._extended_shape(sample_shape)
A:torch.distributions.continuous_bernoulli.u->torch.rand(shape, dtype=self.probs.dtype, device=self.probs.device)
A:torch.distributions.continuous_bernoulli.(logits, value)->broadcast_all(self.logits, value)
A:torch.distributions.continuous_bernoulli.unbounded_cdfs->torch.where(self._outside_unstable_region(), cdfs, value)
A:torch.distributions.continuous_bernoulli.log_probs0->torch.log1p(-self.probs)
A:torch.distributions.continuous_bernoulli.log_probs1->torch.log(self.probs)
A:torch.distributions.continuous_bernoulli.out_unst_reg->torch.max(torch.le(x, self._lims[0] - 0.5), torch.gt(x, self._lims[1] - 0.5))
A:torch.distributions.continuous_bernoulli.cut_nat_params->torch.where(out_unst_reg, x, (self._lims[0] - 0.5) * torch.ones_like(x))
torch.distributions.ContinuousBernoulli(self,probs=None,logits=None,lims=(0.499,0.501),validate_args=None)
torch.distributions.ContinuousBernoulli._cont_bern_log_norm(self)
torch.distributions.ContinuousBernoulli._cut_probs(self)
torch.distributions.ContinuousBernoulli._log_normalizer(self,x)
torch.distributions.ContinuousBernoulli._natural_params(self)
torch.distributions.ContinuousBernoulli._new(self,*args,**kwargs)
torch.distributions.ContinuousBernoulli._outside_unstable_region(self)
torch.distributions.ContinuousBernoulli.cdf(self,value)
torch.distributions.ContinuousBernoulli.entropy(self)
torch.distributions.ContinuousBernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.ContinuousBernoulli.icdf(self,value)
torch.distributions.ContinuousBernoulli.log_prob(self,value)
torch.distributions.ContinuousBernoulli.logits(self)
torch.distributions.ContinuousBernoulli.mean(self)
torch.distributions.ContinuousBernoulli.param_shape(self)
torch.distributions.ContinuousBernoulli.probs(self)
torch.distributions.ContinuousBernoulli.rsample(self,sample_shape=torch.Size())
torch.distributions.ContinuousBernoulli.sample(self,sample_shape=torch.Size())
torch.distributions.ContinuousBernoulli.stddev(self)
torch.distributions.ContinuousBernoulli.variance(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli(self,probs=None,logits=None,lims=(0.499,0.501),validate_args=None)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.__init__(self,probs=None,logits=None,lims=(0.499,0.501),validate_args=None)
torch.distributions.continuous_bernoulli.ContinuousBernoulli._cont_bern_log_norm(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli._cut_probs(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli._log_normalizer(self,x)
torch.distributions.continuous_bernoulli.ContinuousBernoulli._natural_params(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli._new(self,*args,**kwargs)
torch.distributions.continuous_bernoulli.ContinuousBernoulli._outside_unstable_region(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.cdf(self,value)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.entropy(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.expand(self,batch_shape,_instance=None)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.icdf(self,value)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.log_prob(self,value)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.logits(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.mean(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.param_shape(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.probs(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.rsample(self,sample_shape=torch.Size())
torch.distributions.continuous_bernoulli.ContinuousBernoulli.sample(self,sample_shape=torch.Size())
torch.distributions.continuous_bernoulli.ContinuousBernoulli.stddev(self)
torch.distributions.continuous_bernoulli.ContinuousBernoulli.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/studentT.py----------------------------------------
A:torch.distributions.studentT.m->self.df.clone(memory_format=torch.contiguous_format)
A:torch.distributions.studentT.(self.df, self.loc, self.scale)->broadcast_all(df, loc, scale)
A:torch.distributions.studentT.self._chi2->Chi2(self.df)
A:torch.distributions.studentT.batch_shape->torch.Size(batch_shape)
A:torch.distributions.studentT.new->self._get_checked_instance(StudentT, _instance)
A:torch.distributions.studentT.new.df->self.df.expand(batch_shape)
A:torch.distributions.studentT.new.loc->self.loc.expand(batch_shape)
A:torch.distributions.studentT.new.scale->self.scale.expand(batch_shape)
A:torch.distributions.studentT.new._chi2->self._chi2.expand(batch_shape)
A:torch.distributions.studentT.shape->self._extended_shape(sample_shape)
A:torch.distributions.studentT.X->_standard_normal(shape, dtype=self.df.dtype, device=self.df.device)
A:torch.distributions.studentT.Z->self._chi2.rsample(sample_shape)
torch.distributions.StudentT(self,df,loc=0.0,scale=1.0,validate_args=None)
torch.distributions.StudentT.entropy(self)
torch.distributions.StudentT.expand(self,batch_shape,_instance=None)
torch.distributions.StudentT.log_prob(self,value)
torch.distributions.StudentT.mean(self)
torch.distributions.StudentT.rsample(self,sample_shape=torch.Size())
torch.distributions.StudentT.variance(self)
torch.distributions.studentT.StudentT(self,df,loc=0.0,scale=1.0,validate_args=None)
torch.distributions.studentT.StudentT.__init__(self,df,loc=0.0,scale=1.0,validate_args=None)
torch.distributions.studentT.StudentT.entropy(self)
torch.distributions.studentT.StudentT.expand(self,batch_shape,_instance=None)
torch.distributions.studentT.StudentT.log_prob(self,value)
torch.distributions.studentT.StudentT.mean(self)
torch.distributions.studentT.StudentT.rsample(self,sample_shape=torch.Size())
torch.distributions.studentT.StudentT.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/binomial.py----------------------------------------
A:torch.distributions.binomial.(self.total_count, self.probs)->broadcast_all(total_count, probs)
A:torch.distributions.binomial.self.total_count->self.total_count.type_as(self.logits)
A:torch.distributions.binomial.is_scalar->isinstance(self.logits, Number)
A:torch.distributions.binomial.(self.total_count, self.logits)->broadcast_all(total_count, logits)
A:torch.distributions.binomial.batch_shape->torch.Size(batch_shape)
A:torch.distributions.binomial.new->self._get_checked_instance(Binomial, _instance)
A:torch.distributions.binomial.new.total_count->self.total_count.expand(batch_shape)
A:torch.distributions.binomial.new.probs->self.probs.expand(batch_shape)
A:torch.distributions.binomial.new.logits->self.logits.expand(batch_shape)
A:torch.distributions.binomial.shape->self._extended_shape(sample_shape)
A:torch.distributions.binomial.log_factorial_n->torch.lgamma(self.total_count + 1)
A:torch.distributions.binomial.log_factorial_k->torch.lgamma(value + 1)
A:torch.distributions.binomial.log_factorial_nmk->torch.lgamma(self.total_count - value + 1)
A:torch.distributions.binomial.total_count->int(self.total_count.max())
A:torch.distributions.binomial.values->values.expand((-1,) + self._batch_shape).expand((-1,) + self._batch_shape)
torch.distributions.Binomial(self,total_count=1,probs=None,logits=None,validate_args=None)
torch.distributions.Binomial._new(self,*args,**kwargs)
torch.distributions.Binomial.enumerate_support(self,expand=True)
torch.distributions.Binomial.expand(self,batch_shape,_instance=None)
torch.distributions.Binomial.log_prob(self,value)
torch.distributions.Binomial.logits(self)
torch.distributions.Binomial.mean(self)
torch.distributions.Binomial.param_shape(self)
torch.distributions.Binomial.probs(self)
torch.distributions.Binomial.sample(self,sample_shape=torch.Size())
torch.distributions.Binomial.support(self)
torch.distributions.Binomial.variance(self)
torch.distributions.binomial.Binomial(self,total_count=1,probs=None,logits=None,validate_args=None)
torch.distributions.binomial.Binomial.__init__(self,total_count=1,probs=None,logits=None,validate_args=None)
torch.distributions.binomial.Binomial._new(self,*args,**kwargs)
torch.distributions.binomial.Binomial.enumerate_support(self,expand=True)
torch.distributions.binomial.Binomial.expand(self,batch_shape,_instance=None)
torch.distributions.binomial.Binomial.log_prob(self,value)
torch.distributions.binomial.Binomial.logits(self)
torch.distributions.binomial.Binomial.mean(self)
torch.distributions.binomial.Binomial.param_shape(self)
torch.distributions.binomial.Binomial.probs(self)
torch.distributions.binomial.Binomial.sample(self,sample_shape=torch.Size())
torch.distributions.binomial.Binomial.support(self)
torch.distributions.binomial.Binomial.variance(self)
torch.distributions.binomial._clamp_by_zero(x)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/half_cauchy.py----------------------------------------
A:torch.distributions.half_cauchy.base_dist->Cauchy(0, scale)
A:torch.distributions.half_cauchy.new->self._get_checked_instance(HalfCauchy, _instance)
A:torch.distributions.half_cauchy.value->torch.as_tensor(value, dtype=self.base_dist.scale.dtype, device=self.base_dist.scale.device)
torch.distributions.HalfCauchy(self,scale,validate_args=None)
torch.distributions.HalfCauchy.cdf(self,value)
torch.distributions.HalfCauchy.entropy(self)
torch.distributions.HalfCauchy.expand(self,batch_shape,_instance=None)
torch.distributions.HalfCauchy.icdf(self,prob)
torch.distributions.HalfCauchy.log_prob(self,value)
torch.distributions.HalfCauchy.mean(self)
torch.distributions.HalfCauchy.scale(self)
torch.distributions.HalfCauchy.variance(self)
torch.distributions.half_cauchy.HalfCauchy(self,scale,validate_args=None)
torch.distributions.half_cauchy.HalfCauchy.__init__(self,scale,validate_args=None)
torch.distributions.half_cauchy.HalfCauchy.cdf(self,value)
torch.distributions.half_cauchy.HalfCauchy.entropy(self)
torch.distributions.half_cauchy.HalfCauchy.expand(self,batch_shape,_instance=None)
torch.distributions.half_cauchy.HalfCauchy.icdf(self,prob)
torch.distributions.half_cauchy.HalfCauchy.log_prob(self,value)
torch.distributions.half_cauchy.HalfCauchy.mean(self)
torch.distributions.half_cauchy.HalfCauchy.scale(self)
torch.distributions.half_cauchy.HalfCauchy.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/exponential.py----------------------------------------
A:torch.distributions.exponential.(self.rate,)->broadcast_all(rate)
A:torch.distributions.exponential.new->self._get_checked_instance(Exponential, _instance)
A:torch.distributions.exponential.batch_shape->torch.Size(batch_shape)
A:torch.distributions.exponential.new.rate->self.rate.expand(batch_shape)
A:torch.distributions.exponential.shape->self._extended_shape(sample_shape)
A:torch.distributions.exponential.u->torch.rand(shape, dtype=self.rate.dtype, device=self.rate.device)
torch.distributions.Exponential(self,rate,validate_args=None)
torch.distributions.Exponential._log_normalizer(self,x)
torch.distributions.Exponential._natural_params(self)
torch.distributions.Exponential.cdf(self,value)
torch.distributions.Exponential.entropy(self)
torch.distributions.Exponential.expand(self,batch_shape,_instance=None)
torch.distributions.Exponential.icdf(self,value)
torch.distributions.Exponential.log_prob(self,value)
torch.distributions.Exponential.mean(self)
torch.distributions.Exponential.rsample(self,sample_shape=torch.Size())
torch.distributions.Exponential.stddev(self)
torch.distributions.Exponential.variance(self)
torch.distributions.exponential.Exponential(self,rate,validate_args=None)
torch.distributions.exponential.Exponential.__init__(self,rate,validate_args=None)
torch.distributions.exponential.Exponential._log_normalizer(self,x)
torch.distributions.exponential.Exponential._natural_params(self)
torch.distributions.exponential.Exponential.cdf(self,value)
torch.distributions.exponential.Exponential.entropy(self)
torch.distributions.exponential.Exponential.expand(self,batch_shape,_instance=None)
torch.distributions.exponential.Exponential.icdf(self,value)
torch.distributions.exponential.Exponential.log_prob(self,value)
torch.distributions.exponential.Exponential.mean(self)
torch.distributions.exponential.Exponential.rsample(self,sample_shape=torch.Size())
torch.distributions.exponential.Exponential.stddev(self)
torch.distributions.exponential.Exponential.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/beta.py----------------------------------------
A:torch.distributions.beta.concentration1_concentration0->torch.stack([concentration1, concentration0], -1)
A:torch.distributions.beta.(concentration1, concentration0)->broadcast_all(concentration1, concentration0)
A:torch.distributions.beta.self._dirichlet->Dirichlet(concentration1_concentration0)
A:torch.distributions.beta.new->self._get_checked_instance(Beta, _instance)
A:torch.distributions.beta.batch_shape->torch.Size(batch_shape)
A:torch.distributions.beta.new._dirichlet->self._dirichlet.expand(batch_shape)
A:torch.distributions.beta.heads_tails->torch.stack([value, 1.0 - value], -1)
torch.distributions.Beta(self,concentration1,concentration0,validate_args=None)
torch.distributions.Beta._log_normalizer(self,x,y)
torch.distributions.Beta._natural_params(self)
torch.distributions.Beta.concentration0(self)
torch.distributions.Beta.concentration1(self)
torch.distributions.Beta.entropy(self)
torch.distributions.Beta.expand(self,batch_shape,_instance=None)
torch.distributions.Beta.log_prob(self,value)
torch.distributions.Beta.mean(self)
torch.distributions.Beta.rsample(self,sample_shape=())
torch.distributions.Beta.variance(self)
torch.distributions.beta.Beta(self,concentration1,concentration0,validate_args=None)
torch.distributions.beta.Beta.__init__(self,concentration1,concentration0,validate_args=None)
torch.distributions.beta.Beta._log_normalizer(self,x,y)
torch.distributions.beta.Beta._natural_params(self)
torch.distributions.beta.Beta.concentration0(self)
torch.distributions.beta.Beta.concentration1(self)
torch.distributions.beta.Beta.entropy(self)
torch.distributions.beta.Beta.expand(self,batch_shape,_instance=None)
torch.distributions.beta.Beta.log_prob(self,value)
torch.distributions.beta.Beta.mean(self)
torch.distributions.beta.Beta.rsample(self,sample_shape=())
torch.distributions.beta.Beta.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/constraints.py----------------------------------------
A:torch.distributions.constraints.value_tril->value.tril()
A:torch.distributions.constraints.flattened_value->value.reshape((-1,) + matrix_shape)
A:torch.distributions.constraints.self.cseq->list(cseq)
A:torch.distributions.constraints.self.lengths->list(lengths)
A:torch.distributions.constraints.v->value.narrow(self.dim, start, length)
A:torch.distributions.constraints.dependent->_Dependent()
A:torch.distributions.constraints.boolean->_Boolean()
A:torch.distributions.constraints.nonnegative_integer->_IntegerGreaterThan(0)
A:torch.distributions.constraints.positive_integer->_IntegerGreaterThan(1)
A:torch.distributions.constraints.real->_Real()
A:torch.distributions.constraints.real_vector->_RealVector()
A:torch.distributions.constraints.positive->_GreaterThan(0.0)
A:torch.distributions.constraints.unit_interval->_Interval(0.0, 1.0)
A:torch.distributions.constraints.simplex->_Simplex()
A:torch.distributions.constraints.lower_triangular->_LowerTriangular()
A:torch.distributions.constraints.lower_cholesky->_LowerCholesky()
A:torch.distributions.constraints.positive_definite->_PositiveDefinite()
torch.distributions.constraints.Constraint(object)
torch.distributions.constraints.Constraint.__repr__(self)
torch.distributions.constraints.Constraint.check(self,value)
torch.distributions.constraints._Boolean(Constraint)
torch.distributions.constraints._Boolean.check(self,value)
torch.distributions.constraints._Cat(self,cseq,dim=0,lengths=None)
torch.distributions.constraints._Cat.__init__(self,cseq,dim=0,lengths=None)
torch.distributions.constraints._Cat.check(self,value)
torch.distributions.constraints._Dependent(Constraint)
torch.distributions.constraints._Dependent.check(self,x)
torch.distributions.constraints._DependentProperty(property,_Dependent)
torch.distributions.constraints._GreaterThan(self,lower_bound)
torch.distributions.constraints._GreaterThan.__init__(self,lower_bound)
torch.distributions.constraints._GreaterThan.__repr__(self)
torch.distributions.constraints._GreaterThan.check(self,value)
torch.distributions.constraints._GreaterThanEq(self,lower_bound)
torch.distributions.constraints._GreaterThanEq.__init__(self,lower_bound)
torch.distributions.constraints._GreaterThanEq.__repr__(self)
torch.distributions.constraints._GreaterThanEq.check(self,value)
torch.distributions.constraints._HalfOpenInterval(self,lower_bound,upper_bound)
torch.distributions.constraints._HalfOpenInterval.__init__(self,lower_bound,upper_bound)
torch.distributions.constraints._HalfOpenInterval.__repr__(self)
torch.distributions.constraints._HalfOpenInterval.check(self,value)
torch.distributions.constraints._IntegerGreaterThan(self,lower_bound)
torch.distributions.constraints._IntegerGreaterThan.__init__(self,lower_bound)
torch.distributions.constraints._IntegerGreaterThan.__repr__(self)
torch.distributions.constraints._IntegerGreaterThan.check(self,value)
torch.distributions.constraints._IntegerInterval(self,lower_bound,upper_bound)
torch.distributions.constraints._IntegerInterval.__init__(self,lower_bound,upper_bound)
torch.distributions.constraints._IntegerInterval.__repr__(self)
torch.distributions.constraints._IntegerInterval.check(self,value)
torch.distributions.constraints._IntegerLessThan(self,upper_bound)
torch.distributions.constraints._IntegerLessThan.__init__(self,upper_bound)
torch.distributions.constraints._IntegerLessThan.__repr__(self)
torch.distributions.constraints._IntegerLessThan.check(self,value)
torch.distributions.constraints._Interval(self,lower_bound,upper_bound)
torch.distributions.constraints._Interval.__init__(self,lower_bound,upper_bound)
torch.distributions.constraints._Interval.__repr__(self)
torch.distributions.constraints._Interval.check(self,value)
torch.distributions.constraints._LessThan(self,upper_bound)
torch.distributions.constraints._LessThan.__init__(self,upper_bound)
torch.distributions.constraints._LessThan.__repr__(self)
torch.distributions.constraints._LessThan.check(self,value)
torch.distributions.constraints._LowerCholesky(Constraint)
torch.distributions.constraints._LowerCholesky.check(self,value)
torch.distributions.constraints._LowerTriangular(Constraint)
torch.distributions.constraints._LowerTriangular.check(self,value)
torch.distributions.constraints._PositiveDefinite(Constraint)
torch.distributions.constraints._PositiveDefinite.check(self,value)
torch.distributions.constraints._Real(Constraint)
torch.distributions.constraints._Real.check(self,value)
torch.distributions.constraints._RealVector(Constraint)
torch.distributions.constraints._RealVector.check(self,value)
torch.distributions.constraints._Simplex(Constraint)
torch.distributions.constraints._Simplex.check(self,value)
torch.distributions.constraints._Stack(self,cseq,dim=0)
torch.distributions.constraints._Stack.__init__(self,cseq,dim=0)
torch.distributions.constraints._Stack.check(self,value)
torch.distributions.constraints.is_dependent(constraint)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/distributions/fishersnedecor.py----------------------------------------
A:torch.distributions.fishersnedecor.(self.df1, self.df2)->broadcast_all(df1, df2)
A:torch.distributions.fishersnedecor.self._gamma1->Gamma(self.df1 * 0.5, self.df1)
A:torch.distributions.fishersnedecor.self._gamma2->Gamma(self.df2 * 0.5, self.df2)
A:torch.distributions.fishersnedecor.batch_shape->torch.Size(batch_shape)
A:torch.distributions.fishersnedecor.new->self._get_checked_instance(FisherSnedecor, _instance)
A:torch.distributions.fishersnedecor.new.df1->self.df1.expand(batch_shape)
A:torch.distributions.fishersnedecor.new.df2->self.df2.expand(batch_shape)
A:torch.distributions.fishersnedecor.new._gamma1->self._gamma1.expand(batch_shape)
A:torch.distributions.fishersnedecor.new._gamma2->self._gamma2.expand(batch_shape)
A:torch.distributions.fishersnedecor.df2->self.df2.clone(memory_format=torch.contiguous_format)
A:torch.distributions.fishersnedecor.shape->self._extended_shape(sample_shape)
A:torch.distributions.fishersnedecor.X1->self._gamma1.rsample(sample_shape).view(shape)
A:torch.distributions.fishersnedecor.X2->self._gamma2.rsample(sample_shape).view(shape)
torch.distributions.FisherSnedecor(self,df1,df2,validate_args=None)
torch.distributions.FisherSnedecor.expand(self,batch_shape,_instance=None)
torch.distributions.FisherSnedecor.log_prob(self,value)
torch.distributions.FisherSnedecor.mean(self)
torch.distributions.FisherSnedecor.rsample(self,sample_shape=torch.Size(()))
torch.distributions.FisherSnedecor.variance(self)
torch.distributions.fishersnedecor.FisherSnedecor(self,df1,df2,validate_args=None)
torch.distributions.fishersnedecor.FisherSnedecor.__init__(self,df1,df2,validate_args=None)
torch.distributions.fishersnedecor.FisherSnedecor.expand(self,batch_shape,_instance=None)
torch.distributions.fishersnedecor.FisherSnedecor.log_prob(self,value)
torch.distributions.fishersnedecor.FisherSnedecor.mean(self)
torch.distributions.fishersnedecor.FisherSnedecor.rsample(self,sample_shape=torch.Size(()))
torch.distributions.fishersnedecor.FisherSnedecor.variance(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/linalg/__init__.py----------------------------------------
A:torch.linalg.__init__.det->_add_docstr(_linalg.linalg_det, '\nlinalg.det(input) -> Tensor\n\nAlias of :func:`torch.det`.\n')
A:torch.linalg.__init__.norm->_add_docstr(_linalg.linalg_norm, "\nlinalg.norm(input, ord=None, dim=None, keepdim=False, *, out=None, dtype=None) -> Tensor\n\nReturns the matrix norm or vector norm of a given tensor.\n\nThis function can calculate one of eight different types of matrix norms, or one\nof an infinite number of vector norms, depending on both the number of reduction\ndimensions and the value of the `ord` parameter.\n\nArgs:\n    input (Tensor): The input tensor. If dim is None, x must be 1-D or 2-D, unless :attr:`ord`\n        is None. If both :attr:`dim` and :attr:`ord` are None, the 2-norm of the input flattened to 1-D\n        will be returned.\n\n    ord (int, float, inf, -inf, 'fro', 'nuc', optional): The order of norm.\n        inf refers to :attr:`float('inf')`, numpy's :attr:`inf` object, or any equivalent object.\n        The following norms can be calculated:\n\n        =====  ============================  ==========================\n        ord    norm for matrices             norm for vectors\n        =====  ============================  ==========================\n        None   Frobenius norm                2-norm\n        'fro'  Frobenius norm                -- not supported --\n        'nuc'  nuclear norm                  -- not supported --\n        inf    max(sum(abs(x), dim=1))       max(abs(x))\n        -inf   min(sum(abs(x), dim=1))       min(abs(x))\n        0      -- not supported --           sum(x != 0)\n        1      max(sum(abs(x), dim=0))       as below\n        -1     min(sum(abs(x), dim=0))       as below\n        2      2-norm (largest sing. value)  as below\n        -2     smallest singular value       as below\n        other  -- not supported --           sum(abs(x)**ord)**(1./ord)\n        =====  ============================  ==========================\n\n        Default: ``None``\n\n    dim (int, 2-tuple of ints, 2-list of ints, optional): If :attr:`dim` is an int,\n        vector norm will be calculated over the specified dimension. If :attr:`dim`\n        is a 2-tuple of ints, matrix norm will be calculated over the specified\n        dimensions. If :attr:`dim` is None, matrix norm will be calculated\n        when the input tensor has two dimensions, and vector norm will be\n        calculated when the input tensor has one dimension. Default: ``None``\n\n    keepdim (bool, optional): If set to True, the reduced dimensions are retained\n        in the result as dimensions with size one. Default: ``False``\n\nKeyword args:\n\n    out (Tensor, optional): The output tensor. Ignored if ``None``. Default: ``None``\n\n    dtype (:class:`torch.dtype`, optional): If specified, the input tensor is cast to\n        :attr:`dtype` before performing the operation, and the returned tensor's type\n        will be :attr:`dtype`. If this argument is used in conjunction with the\n        :attr:`out` argument, the output tensor's type must match this argument or a\n        RuntimeError will be raised. This argument is not currently supported for\n        :attr:`ord='nuc'` or :attr:`ord='fro'`. Default: ``None``\n\nExamples::\n\n    >>> import torch\n    >>> from torch import linalg as LA\n    >>> a = torch.arange(9, dtype=torch.float) - 4\n    >>> a\n    tensor([-4., -3., -2., -1.,  0.,  1.,  2.,  3.,  4.])\n    >>> b = a.reshape((3, 3))\n    >>> b\n    tensor([[-4., -3., -2.],\n            [-1.,  0.,  1.],\n            [ 2.,  3.,  4.]])\n\n    >>> LA.norm(a)\n    tensor(7.7460)\n    >>> LA.norm(b)\n    tensor(7.7460)\n    >>> LA.norm(b, 'fro')\n    tensor(7.7460)\n    >>> LA.norm(a, float('inf'))\n    tensor(4.)\n    >>> LA.norm(b, float('inf'))\n    tensor(9.)\n    >>> LA.norm(a, -float('inf'))\n    tensor(0.)\n    >>> LA.norm(b, -float('inf'))\n    tensor(2.)\n\n    >>> LA.norm(a, 1)\n    tensor(20.)\n    >>> LA.norm(b, 1)\n    tensor(7.)\n    >>> LA.norm(a, -1)\n    tensor(0.)\n    >>> LA.norm(b, -1)\n    tensor(6.)\n    >>> LA.norm(a, 2)\n    tensor(7.7460)\n    >>> LA.norm(b, 2)\n    tensor(7.3485)\n\n    >>> LA.norm(a, -2)\n    tensor(0.)\n    >>> LA.norm(b.double(), -2)\n    tensor(1.8570e-16, dtype=torch.float64)\n    >>> LA.norm(a, 3)\n    tensor(5.8480)\n    >>> LA.norm(a, -3)\n    tensor(0.)\n\nUsing the :attr:`dim` argument to compute vector norms::\n\n    >>> c = torch.tensor([[1., 2., 3.],\n    ...                   [-1, 1, 4]])\n    >>> LA.norm(c, dim=0)\n    tensor([1.4142, 2.2361, 5.0000])\n    >>> LA.norm(c, dim=1)\n    tensor([3.7417, 4.2426])\n    >>> LA.norm(c, ord=1, dim=1)\n    tensor([6., 6.])\n\nUsing the :attr:`dim` argument to compute matrix norms::\n\n    >>> m = torch.arange(8, dtype=torch.float).reshape(2, 2, 2)\n    >>> LA.norm(m, dim=(1,2))\n    tensor([ 3.7417, 11.2250])\n    >>> LA.norm(m[0, :, :]), LA.norm(m[1, :, :])\n    (tensor(3.7417), tensor(11.2250))\n")


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/swa_utils.py----------------------------------------
A:torch.optim.swa_utils.self.module->self.module.to(device)
A:torch.optim.swa_utils.p_model_->p_model.detach().to(device)
A:torch.optim.swa_utils.module.running_mean->torch.zeros_like(module.running_mean)
A:torch.optim.swa_utils.module.running_var->torch.ones_like(module.running_var)
A:torch.optim.swa_utils.input->input.to(device).to(device)
A:torch.optim.swa_utils.swa_lrs->self._format_param(optimizer, swa_lr)
A:torch.optim.swa_utils.prev_t->max(0, min(1, (step - 1) / self.anneal_epochs))
A:torch.optim.swa_utils.prev_alpha->self.anneal_func(prev_t)
A:torch.optim.swa_utils.t->max(0, min(1, step / self.anneal_epochs))
A:torch.optim.swa_utils.alpha->self.anneal_func(t)
torch.optim.swa_utils.AveragedModel(self,model,device=None,avg_fn=None)
torch.optim.swa_utils.AveragedModel.__init__(self,model,device=None,avg_fn=None)
torch.optim.swa_utils.AveragedModel.forward(self,*args,**kwargs)
torch.optim.swa_utils.AveragedModel.update_parameters(self,model)
torch.optim.swa_utils.SWALR(self,optimizer,swa_lr,anneal_epochs=10,anneal_strategy='cos',last_epoch=-1)
torch.optim.swa_utils.SWALR.__init__(self,optimizer,swa_lr,anneal_epochs=10,anneal_strategy='cos',last_epoch=-1)
torch.optim.swa_utils.SWALR._cosine_anneal(t)
torch.optim.swa_utils.SWALR._format_param(optimizer,swa_lrs)
torch.optim.swa_utils.SWALR._get_initial_lr(lr,swa_lr,alpha)
torch.optim.swa_utils.SWALR._linear_anneal(t)
torch.optim.swa_utils.SWALR.get_lr(self)
torch.optim.swa_utils.update_bn(loader,model,device=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/swa_utils.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/sgd.py----------------------------------------
A:torch.optim.sgd.defaults->dict(lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay, nesterov=nesterov)
A:torch.optim.sgd.loss->closure()
A:torch.optim.sgd.d_p->d_p.add(buf, alpha=momentum).add(buf, alpha=momentum)
A:torch.optim.sgd.bufparam_state['momentum_buffer']->torch.clone(d_p).detach()
torch.optim.SGD(self,params,lr=required,momentum=0,dampening=0,weight_decay=0,nesterov=False)
torch.optim.SGD.__setstate__(self,state)
torch.optim.SGD.step(self,closure=None)
torch.optim.sgd.SGD(self,params,lr=required,momentum=0,dampening=0,weight_decay=0,nesterov=False)
torch.optim.sgd.SGD.__init__(self,params,lr=required,momentum=0,dampening=0,weight_decay=0,nesterov=False)
torch.optim.sgd.SGD.__setstate__(self,state)
torch.optim.sgd.SGD.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/sgd.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/rprop.py----------------------------------------
A:torch.optim.rprop.defaults->dict(lr=lr, etas=etas, step_sizes=step_sizes)
A:torch.optim.rprop.loss->closure()
A:torch.optim.rprop.state['prev']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.rprop.state['step_size']->grad.clone(memory_format=torch.preserve_format).new().resize_as_(grad).fill_(group['lr'])
A:torch.optim.rprop.sign->grad.clone(memory_format=torch.preserve_format).mul(state['prev']).sign()
A:torch.optim.rprop.grad->grad.clone(memory_format=torch.preserve_format).clone(memory_format=torch.preserve_format)
torch.optim.Rprop(self,params,lr=0.01,etas=(0.5,1.2),step_sizes=(1e-06,50))
torch.optim.Rprop.step(self,closure=None)
torch.optim.rprop.Rprop(self,params,lr=0.01,etas=(0.5,1.2),step_sizes=(1e-06,50))
torch.optim.rprop.Rprop.__init__(self,params,lr=0.01,etas=(0.5,1.2),step_sizes=(1e-06,50))
torch.optim.rprop.Rprop.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/rprop.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/lbfgs.py----------------------------------------
A:torch.optim.lbfgs.d2->d2_square.sqrt()
A:torch.optim.lbfgs.d_norm->flat_grad.neg().abs().max()
A:torch.optim.lbfgs.g->g.clone(memory_format=torch.contiguous_format).clone(memory_format=torch.contiguous_format)
A:torch.optim.lbfgs.(f_new, g_new)->obj_func(x, t, d)
A:torch.optim.lbfgs.gtd_new->g_new.dot(d)
A:torch.optim.lbfgs.t->state.get('t')
A:torch.optim.lbfgs.g_prev->g_new.clone(memory_format=torch.contiguous_format)
A:torch.optim.lbfgs.bracket_g[high_pos]->g_new.clone(memory_format=torch.contiguous_format)
A:torch.optim.lbfgs.bracket_g[low_pos]->g_new.clone(memory_format=torch.contiguous_format)
A:torch.optim.lbfgs.defaults->dict(lr=lr, max_iter=max_iter, max_eval=max_eval, tolerance_grad=tolerance_grad, tolerance_change=tolerance_change, history_size=history_size, line_search_fn=line_search_fn)
A:torch.optim.lbfgs.self._numel_cache->reduce(lambda total, p: total + p.numel(), self._params, 0)
A:torch.optim.lbfgs.view->p.grad.view(-1)
A:torch.optim.lbfgs.numel->p.numel()
A:torch.optim.lbfgs.loss->float(closure())
A:torch.optim.lbfgs.flat_grad->self._gather_flat_grad()
A:torch.optim.lbfgs.closure->torch.enable_grad()(closure)
A:torch.optim.lbfgs.orig_loss->closure()
A:torch.optim.lbfgs.d->self._gather_flat_grad().neg()
A:torch.optim.lbfgs.old_dirs->state.get('old_dirs')
A:torch.optim.lbfgs.old_stps->state.get('old_stps')
A:torch.optim.lbfgs.ro->state.get('ro')
A:torch.optim.lbfgs.H_diag->state.get('H_diag')
A:torch.optim.lbfgs.prev_flat_grad->self._gather_flat_grad().clone(memory_format=torch.contiguous_format)
A:torch.optim.lbfgs.prev_loss->state.get('prev_loss')
A:torch.optim.lbfgs.y->self._gather_flat_grad().sub(prev_flat_grad)
A:torch.optim.lbfgs.s->self._gather_flat_grad().neg().mul(t)
A:torch.optim.lbfgs.ys->self._gather_flat_grad().sub(prev_flat_grad).dot(s)
A:torch.optim.lbfgs.num_old->len(old_dirs)
A:torch.optim.lbfgs.q->self._gather_flat_grad().neg()
A:torch.optim.lbfgs.dr->torch.mul(q, H_diag)
A:torch.optim.lbfgs.gtd->self._gather_flat_grad().dot(d)
A:torch.optim.lbfgs.x_init->self._clone_param()
A:torch.optim.lbfgs.(loss, flat_grad, t, ls_func_evals)->_strong_wolfe(obj_func, x_init, t, d, loss, flat_grad, gtd)
torch.optim.LBFGS(self,params,lr=1,max_iter=20,max_eval=None,tolerance_grad=1e-07,tolerance_change=1e-09,history_size=100,line_search_fn=None)
torch.optim.LBFGS._add_grad(self,step_size,update)
torch.optim.LBFGS._clone_param(self)
torch.optim.LBFGS._directional_evaluate(self,closure,x,t,d)
torch.optim.LBFGS._gather_flat_grad(self)
torch.optim.LBFGS._numel(self)
torch.optim.LBFGS._set_param(self,params_data)
torch.optim.LBFGS.step(self,closure)
torch.optim.lbfgs.LBFGS(self,params,lr=1,max_iter=20,max_eval=None,tolerance_grad=1e-07,tolerance_change=1e-09,history_size=100,line_search_fn=None)
torch.optim.lbfgs.LBFGS.__init__(self,params,lr=1,max_iter=20,max_eval=None,tolerance_grad=1e-07,tolerance_change=1e-09,history_size=100,line_search_fn=None)
torch.optim.lbfgs.LBFGS._add_grad(self,step_size,update)
torch.optim.lbfgs.LBFGS._clone_param(self)
torch.optim.lbfgs.LBFGS._directional_evaluate(self,closure,x,t,d)
torch.optim.lbfgs.LBFGS._gather_flat_grad(self)
torch.optim.lbfgs.LBFGS._numel(self)
torch.optim.lbfgs.LBFGS._set_param(self,params_data)
torch.optim.lbfgs.LBFGS.step(self,closure)
torch.optim.lbfgs._cubic_interpolate(x1,f1,g1,x2,f2,g2,bounds=None)
torch.optim.lbfgs._strong_wolfe(obj_func,x,t,d,f,g,gtd,c1=0.0001,c2=0.9,tolerance_change=1e-09,max_ls=25)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/lbfgs.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adadelta.py----------------------------------------
A:torch.optim.adadelta.defaults->dict(lr=lr, rho=rho, eps=eps, weight_decay=weight_decay)
A:torch.optim.adadelta.loss->closure()
A:torch.optim.adadelta.state['square_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adadelta.state['acc_delta']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adadelta.grad->grad.add(p, alpha=group['weight_decay']).add(p, alpha=group['weight_decay'])
A:torch.optim.adadelta.std->square_avg.add(eps).sqrt_()
A:torch.optim.adadelta.delta->acc_delta.add(eps).sqrt_().div_(std).mul_(grad)
torch.optim.Adadelta(self,params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)
torch.optim.Adadelta.step(self,closure=None)
torch.optim.adadelta.Adadelta(self,params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)
torch.optim.adadelta.Adadelta.__init__(self,params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)
torch.optim.adadelta.Adadelta.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adadelta.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adamax.py----------------------------------------
A:torch.optim.adamax.defaults->dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)
A:torch.optim.adamax.loss->closure()
A:torch.optim.adamax.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adamax.state['exp_inf']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adamax.grad->grad.add(p, alpha=group['weight_decay']).add(p, alpha=group['weight_decay'])
A:torch.optim.adamax.norm_buf->torch.cat([exp_inf.mul_(beta2).unsqueeze(0), grad.abs().add_(eps).unsqueeze_(0)], 0)
torch.optim.Adamax(self,params,lr=0.002,betas=(0.9,0.999),eps=1e-08,weight_decay=0)
torch.optim.Adamax.step(self,closure=None)
torch.optim.adamax.Adamax(self,params,lr=0.002,betas=(0.9,0.999),eps=1e-08,weight_decay=0)
torch.optim.adamax.Adamax.__init__(self,params,lr=0.002,betas=(0.9,0.999),eps=1e-08,weight_decay=0)
torch.optim.adamax.Adamax.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adamax.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/rmsprop.py----------------------------------------
A:torch.optim.rmsprop.defaults->dict(lr=lr, momentum=momentum, alpha=alpha, eps=eps, centered=centered, weight_decay=weight_decay)
A:torch.optim.rmsprop.loss->closure()
A:torch.optim.rmsprop.state['square_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.rmsprop.state['momentum_buffer']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.rmsprop.state['grad_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.rmsprop.grad->grad.add(p, alpha=group['weight_decay']).add(p, alpha=group['weight_decay'])
A:torch.optim.rmsprop.avg->square_avg.sqrt().add_(group['eps'])
torch.optim.RMSprop(self,params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)
torch.optim.RMSprop.__setstate__(self,state)
torch.optim.RMSprop.step(self,closure=None)
torch.optim.rmsprop.RMSprop(self,params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)
torch.optim.rmsprop.RMSprop.__init__(self,params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)
torch.optim.rmsprop.RMSprop.__setstate__(self,state)
torch.optim.rmsprop.RMSprop.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/rmsprop.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/asgd.py----------------------------------------
A:torch.optim.asgd.defaults->dict(lr=lr, lambd=lambd, alpha=alpha, t0=t0, weight_decay=weight_decay)
A:torch.optim.asgd.loss->closure()
A:torch.optim.asgd.state['ax']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.asgd.grad->grad.add(p, alpha=group['weight_decay']).add(p, alpha=group['weight_decay'])
torch.optim.ASGD(self,params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)
torch.optim.ASGD.step(self,closure=None)
torch.optim.asgd.ASGD(self,params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)
torch.optim.asgd.ASGD.__init__(self,params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)
torch.optim.asgd.ASGD.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/asgd.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adagrad.py----------------------------------------
A:torch.optim.adagrad.defaults->dict(lr=lr, lr_decay=lr_decay, eps=eps, weight_decay=weight_decay, initial_accumulator_value=initial_accumulator_value)
A:torch.optim.adagrad.state['sum']->torch.full_like(p, initial_accumulator_value, memory_format=torch.preserve_format)
A:torch.optim.adagrad.loss->closure()
torch.optim.Adagrad(self,params,lr=0.01,lr_decay=0,weight_decay=0,initial_accumulator_value=0,eps=1e-10)
torch.optim.Adagrad.share_memory(self)
torch.optim.Adagrad.step(self,closure=None)
torch.optim.adagrad.Adagrad(self,params,lr=0.01,lr_decay=0,weight_decay=0,initial_accumulator_value=0,eps=1e-10)
torch.optim.adagrad.Adagrad.__init__(self,params,lr=0.01,lr_decay=0,weight_decay=0,initial_accumulator_value=0,eps=1e-10)
torch.optim.adagrad.Adagrad.share_memory(self)
torch.optim.adagrad.Adagrad.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adagrad.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/__init__.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adamw.py----------------------------------------
A:torch.optim.adamw.defaults->dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)
A:torch.optim.adamw.loss->closure()
A:torch.optim.adamw.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adamw.state['exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adamw.state['max_exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adamw.denom->(exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(group['eps'])
torch.optim.AdamW(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)
torch.optim.AdamW.__setstate__(self,state)
torch.optim.AdamW.step(self,closure=None)
torch.optim.adamw.AdamW(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)
torch.optim.adamw.AdamW.__init__(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)
torch.optim.adamw.AdamW.__setstate__(self,state)
torch.optim.adamw.AdamW.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adamw.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/lr_scheduler.py----------------------------------------
A:torch.optim.lr_scheduler.self.base_lrs->list(map(lambda group: group['initial_lr'], optimizer.param_groups))
A:torch.optim.lr_scheduler.instance_ref->weakref.ref(method.__self__)
A:torch.optim.lr_scheduler.instance->instance_ref()
A:torch.optim.lr_scheduler.wrapped->func.__get__(instance, cls)
A:torch.optim.lr_scheduler.self.optimizer.step->with_counter(self.optimizer.step)
A:torch.optim.lr_scheduler.values->self.get_lr()
A:torch.optim.lr_scheduler.self.lr_lambdas->list(lr_lambda)
A:torch.optim.lr_scheduler.state_dict['lr_lambdas'][idx]->fn.__dict__.copy()
A:torch.optim.lr_scheduler.lr_lambdas->state_dict.pop('lr_lambdas')
A:torch.optim.lr_scheduler.self.milestones->Counter(milestones)
A:torch.optim.lr_scheduler.milestones->list(sorted(self.milestones.elements()))
A:torch.optim.lr_scheduler.self.min_lrs->list(min_lr)
A:torch.optim.lr_scheduler.current->float(metrics)
A:torch.optim.lr_scheduler.old_lr->float(param_group['lr'])
A:torch.optim.lr_scheduler.new_lr->max(old_lr * self.factor, self.min_lrs[i])
A:torch.optim.lr_scheduler.base_lrs->self._format_param('base_lr', optimizer, base_lr)
A:torch.optim.lr_scheduler.self.max_lrs->self._format_param('max_lr', optimizer, max_lr)
A:torch.optim.lr_scheduler.step_size_up->float(step_size_up)
A:torch.optim.lr_scheduler.base_momentums->self._format_param('base_momentum', optimizer, base_momentum)
A:torch.optim.lr_scheduler.self.base_momentums->list(map(lambda group: group['momentum'], optimizer.param_groups))
A:torch.optim.lr_scheduler.self.max_momentums->self._format_param('max_momentum', optimizer, max_momentum)
A:torch.optim.lr_scheduler.cycle->math.floor(1 + self.last_epoch / self.total_size)
A:torch.optim.lr_scheduler.n->int(math.log(epoch / self.T_0 * (self.T_mult - 1) + 1, self.T_mult))
A:torch.optim.lr_scheduler.self.last_epoch->math.floor(epoch)
A:torch.optim.lr_scheduler.max_lrs->self._format_param('max_lr', self.optimizer, max_lr)
A:torch.optim.lr_scheduler.max_momentums->self._format_param('max_momentum', optimizer, max_momentum)
A:torch.optim.lr_scheduler.computed_lr->self.anneal_func(group['max_lr'], group['min_lr'], down_step_num / self.step_size_down)
A:torch.optim.lr_scheduler.computed_momentum->self.anneal_func(group['base_momentum'], group['max_momentum'], down_step_num / self.step_size_down)
torch.optim.lr_scheduler.CosineAnnealingLR(self,optimizer,T_max,eta_min=0,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.CosineAnnealingLR.__init__(self,optimizer,T_max,eta_min=0,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.CosineAnnealingLR._get_closed_form_lr(self)
torch.optim.lr_scheduler.CosineAnnealingLR.get_lr(self)
torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(self,optimizer,T_0,T_mult=1,eta_min=0,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.__init__(self,optimizer,T_0,T_mult=1,eta_min=0,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.get_lr(self)
torch.optim.lr_scheduler.CosineAnnealingWarmRestarts.step(self,epoch=None)
torch.optim.lr_scheduler.CyclicLR(self,optimizer,base_lr,max_lr,step_size_up=2000,step_size_down=None,mode='triangular',gamma=1.0,scale_fn=None,scale_mode='cycle',cycle_momentum=True,base_momentum=0.8,max_momentum=0.9,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.CyclicLR.__init__(self,optimizer,base_lr,max_lr,step_size_up=2000,step_size_down=None,mode='triangular',gamma=1.0,scale_fn=None,scale_mode='cycle',cycle_momentum=True,base_momentum=0.8,max_momentum=0.9,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.CyclicLR._exp_range_scale_fn(self,x)
torch.optim.lr_scheduler.CyclicLR._format_param(self,name,optimizer,param)
torch.optim.lr_scheduler.CyclicLR._triangular2_scale_fn(self,x)
torch.optim.lr_scheduler.CyclicLR._triangular_scale_fn(self,x)
torch.optim.lr_scheduler.CyclicLR.get_lr(self)
torch.optim.lr_scheduler.ExponentialLR(self,optimizer,gamma,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.ExponentialLR.__init__(self,optimizer,gamma,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.ExponentialLR._get_closed_form_lr(self)
torch.optim.lr_scheduler.ExponentialLR.get_lr(self)
torch.optim.lr_scheduler.LambdaLR(self,optimizer,lr_lambda,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.LambdaLR.__init__(self,optimizer,lr_lambda,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.LambdaLR.get_lr(self)
torch.optim.lr_scheduler.LambdaLR.load_state_dict(self,state_dict)
torch.optim.lr_scheduler.LambdaLR.state_dict(self)
torch.optim.lr_scheduler.MultiStepLR(self,optimizer,milestones,gamma=0.1,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.MultiStepLR.__init__(self,optimizer,milestones,gamma=0.1,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.MultiStepLR._get_closed_form_lr(self)
torch.optim.lr_scheduler.MultiStepLR.get_lr(self)
torch.optim.lr_scheduler.MultiplicativeLR(self,optimizer,lr_lambda,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.MultiplicativeLR.__init__(self,optimizer,lr_lambda,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.MultiplicativeLR.get_lr(self)
torch.optim.lr_scheduler.MultiplicativeLR.load_state_dict(self,state_dict)
torch.optim.lr_scheduler.MultiplicativeLR.state_dict(self)
torch.optim.lr_scheduler.OneCycleLR(self,optimizer,max_lr,total_steps=None,epochs=None,steps_per_epoch=None,pct_start=0.3,anneal_strategy='cos',cycle_momentum=True,base_momentum=0.85,max_momentum=0.95,div_factor=25.0,final_div_factor=10000.0,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.OneCycleLR.__init__(self,optimizer,max_lr,total_steps=None,epochs=None,steps_per_epoch=None,pct_start=0.3,anneal_strategy='cos',cycle_momentum=True,base_momentum=0.85,max_momentum=0.95,div_factor=25.0,final_div_factor=10000.0,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.OneCycleLR._annealing_cos(self,start,end,pct)
torch.optim.lr_scheduler.OneCycleLR._annealing_linear(self,start,end,pct)
torch.optim.lr_scheduler.OneCycleLR._format_param(self,name,optimizer,param)
torch.optim.lr_scheduler.OneCycleLR.get_lr(self)
torch.optim.lr_scheduler.ReduceLROnPlateau(self,optimizer,mode='min',factor=0.1,patience=10,threshold=0.0001,threshold_mode='rel',cooldown=0,min_lr=0,eps=1e-08,verbose=False)
torch.optim.lr_scheduler.ReduceLROnPlateau.__init__(self,optimizer,mode='min',factor=0.1,patience=10,threshold=0.0001,threshold_mode='rel',cooldown=0,min_lr=0,eps=1e-08,verbose=False)
torch.optim.lr_scheduler.ReduceLROnPlateau._init_is_better(self,mode,threshold,threshold_mode)
torch.optim.lr_scheduler.ReduceLROnPlateau._reduce_lr(self,epoch)
torch.optim.lr_scheduler.ReduceLROnPlateau._reset(self)
torch.optim.lr_scheduler.ReduceLROnPlateau.in_cooldown(self)
torch.optim.lr_scheduler.ReduceLROnPlateau.is_better(self,a,best)
torch.optim.lr_scheduler.ReduceLROnPlateau.load_state_dict(self,state_dict)
torch.optim.lr_scheduler.ReduceLROnPlateau.state_dict(self)
torch.optim.lr_scheduler.ReduceLROnPlateau.step(self,metrics,epoch=None)
torch.optim.lr_scheduler.StepLR(self,optimizer,step_size,gamma=0.1,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.StepLR.__init__(self,optimizer,step_size,gamma=0.1,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler.StepLR._get_closed_form_lr(self)
torch.optim.lr_scheduler.StepLR.get_lr(self)
torch.optim.lr_scheduler._LRScheduler(self,optimizer,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler._LRScheduler.__init__(self,optimizer,last_epoch=-1,verbose=False)
torch.optim.lr_scheduler._LRScheduler.get_last_lr(self)
torch.optim.lr_scheduler._LRScheduler.get_lr(self)
torch.optim.lr_scheduler._LRScheduler.load_state_dict(self,state_dict)
torch.optim.lr_scheduler._LRScheduler.print_lr(self,is_verbose,group,lr,epoch=None)
torch.optim.lr_scheduler._LRScheduler.state_dict(self)
torch.optim.lr_scheduler._LRScheduler.step(self,epoch=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/lr_scheduler.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/sparse_adam.py----------------------------------------
A:torch.optim.sparse_adam.defaults->dict(lr=lr, betas=betas, eps=eps)
A:torch.optim.sparse_adam.loss->closure()
A:torch.optim.sparse_adam.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.sparse_adam.state['exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.sparse_adam.grad->grad.coalesce().coalesce()
A:torch.optim.sparse_adam.grad_indices->grad.coalesce().coalesce()._indices()
A:torch.optim.sparse_adam.grad_values->grad.coalesce().coalesce()._values()
A:torch.optim.sparse_adam.size->grad.coalesce().coalesce().size()
A:torch.optim.sparse_adam.old_exp_avg_values->exp_avg.sparse_mask(grad)._values()
A:torch.optim.sparse_adam.exp_avg_update_values->grad.coalesce().coalesce()._values().sub(old_exp_avg_values).mul_(1 - beta1)
A:torch.optim.sparse_adam.old_exp_avg_sq_values->exp_avg_sq.sparse_mask(grad)._values()
A:torch.optim.sparse_adam.exp_avg_sq_update_values->grad.coalesce().coalesce()._values().pow(2).sub_(old_exp_avg_sq_values).mul_(1 - beta2)
A:torch.optim.sparse_adam.numer->grad.coalesce().coalesce()._values().sub(old_exp_avg_values).mul_(1 - beta1).add_(old_exp_avg_values)
A:torch.optim.sparse_adam.denom->grad.coalesce().coalesce()._values().pow(2).sub_(old_exp_avg_sq_values).mul_(1 - beta2).sqrt_().add_(group['eps'])
torch.optim.SparseAdam(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08)
torch.optim.SparseAdam.step(self,closure=None)
torch.optim.sparse_adam.SparseAdam(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08)
torch.optim.sparse_adam.SparseAdam.__init__(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08)
torch.optim.sparse_adam.SparseAdam.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/sparse_adam.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/functional.py----------------------------------------
A:torch.optim.functional.size->grad.add(param, alpha=weight_decay).size()
A:torch.optim.functional.grad->grad.add(param, alpha=weight_decay).add(param, alpha=weight_decay)
A:torch.optim.functional.grad_indices->grad.add(param, alpha=weight_decay).add(param, alpha=weight_decay)._indices()
A:torch.optim.functional.grad_values->grad.add(param, alpha=weight_decay).add(param, alpha=weight_decay)._values()
A:torch.optim.functional.std->state_sum.sqrt().add_(eps)
A:torch.optim.functional.std_values->state_sum.sqrt().add_(eps)._values().sqrt_().add_(eps)
A:torch.optim.functional.denom->(exp_avg_sq.sqrt() / math.sqrt(bias_correction2)).add_(eps)
torch.optim._make_sparse(grad,grad_indices,values)
torch.optim.adagrad(params:List[Tensor],grads:List[Tensor],state_sums:List[Tensor],state_steps:List[int],lr:float,weight_decay:float,lr_decay:float,eps:float)
torch.optim.adam(params:List[Tensor],grads:List[Tensor],exp_avgs:List[Tensor],exp_avg_sqs:List[Tensor],max_exp_avg_sqs:List[Tensor],state_steps:List[int],amsgrad:bool,beta1:float,beta2:float,lr:float,weight_decay:float,eps:float)
torch.optim.functional._make_sparse(grad,grad_indices,values)
torch.optim.functional.adagrad(params:List[Tensor],grads:List[Tensor],state_sums:List[Tensor],state_steps:List[int],lr:float,weight_decay:float,lr_decay:float,eps:float)
torch.optim.functional.adam(params:List[Tensor],grads:List[Tensor],exp_avgs:List[Tensor],exp_avg_sqs:List[Tensor],max_exp_avg_sqs:List[Tensor],state_steps:List[int],amsgrad:bool,beta1:float,beta2:float,lr:float,weight_decay:float,eps:float)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/optimizer.py----------------------------------------
A:torch.optim.optimizer.required->_RequiredParameter()
A:torch.optim.optimizer.self.state->defaultdict(dict)
A:torch.optim.optimizer.param_groups->list(params)
A:torch.optim.optimizer.state_dict->deepcopy(state_dict)
A:torch.optim.optimizer.value->value.to(param.device).to(param.device)
A:torch.optim.optimizer.state->defaultdict(dict)
A:torch.optim.optimizer.state[param]->cast(param, v)
A:torch.optim.optimizer.param_group['params']->list(params)
A:torch.optim.optimizer.param_set->set()
torch.optim.Optimizer(self,params,defaults)
torch.optim.Optimizer.__getstate__(self)
torch.optim.Optimizer.__repr__(self)
torch.optim.Optimizer.__setstate__(self,state)
torch.optim.Optimizer.add_param_group(self,param_group)
torch.optim.Optimizer.load_state_dict(self,state_dict)
torch.optim.Optimizer.state_dict(self)
torch.optim.Optimizer.step(self,closure)
torch.optim.Optimizer.zero_grad(self,set_to_none:bool=False)
torch.optim.optimizer.Optimizer(self,params,defaults)
torch.optim.optimizer.Optimizer.__getstate__(self)
torch.optim.optimizer.Optimizer.__init__(self,params,defaults)
torch.optim.optimizer.Optimizer.__repr__(self)
torch.optim.optimizer.Optimizer.__setstate__(self,state)
torch.optim.optimizer.Optimizer.add_param_group(self,param_group)
torch.optim.optimizer.Optimizer.load_state_dict(self,state_dict)
torch.optim.optimizer.Optimizer.state_dict(self)
torch.optim.optimizer.Optimizer.step(self,closure)
torch.optim.optimizer.Optimizer.zero_grad(self,set_to_none:bool=False)
torch.optim.optimizer._RequiredParameter(object)
torch.optim.optimizer._RequiredParameter.__repr__(self)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/optimizer.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adam.py----------------------------------------
A:torch.optim.adam.defaults->dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)
A:torch.optim.adam.loss->closure()
A:torch.optim.adam.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adam.state['exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim.adam.state['max_exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
torch.optim.Adam(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
torch.optim.Adam.__setstate__(self,state)
torch.optim.Adam.step(self,closure=None)
torch.optim.adam.Adam(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
torch.optim.adam.Adam.__init__(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
torch.optim.adam.Adam.__setstate__(self,state)
torch.optim.adam.Adam.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/adam.pyi----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/rprop.py----------------------------------------
A:torch.optim._multi_tensor.rprop.defaults->dict(lr=lr, etas=etas, step_sizes=step_sizes)
A:torch.optim._multi_tensor.rprop.loss->closure()
A:torch.optim._multi_tensor.rprop.state['prev']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.rprop.state['step_size']->p.grad.new().resize_as_(p.grad).fill_(group['lr'])
A:torch.optim._multi_tensor.rprop.signs->torch._foreach_mul(grads, [s['prev'] for s in states])
A:torch.optim._multi_tensor.rprop.grads[i]->grads[i].clone(memory_format=torch.preserve_format).clone(memory_format=torch.preserve_format)
torch.optim._multi_tensor.Rprop(self,params,lr=0.01,etas=(0.5,1.2),step_sizes=(1e-06,50))
torch.optim._multi_tensor.Rprop.step(self,closure=None)
torch.optim._multi_tensor.rprop.Rprop(self,params,lr=0.01,etas=(0.5,1.2),step_sizes=(1e-06,50))
torch.optim._multi_tensor.rprop.Rprop.__init__(self,params,lr=0.01,etas=(0.5,1.2),step_sizes=(1e-06,50))
torch.optim._multi_tensor.rprop.Rprop.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/adadelta.py----------------------------------------
A:torch.optim._multi_tensor.adadelta.defaults->dict(lr=lr, rho=rho, eps=eps, weight_decay=weight_decay)
A:torch.optim._multi_tensor.adadelta.loss->closure()
A:torch.optim._multi_tensor.adadelta.state['square_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adadelta.state['acc_delta']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adadelta.std->torch._foreach_add(square_avgs, eps)
A:torch.optim._multi_tensor.adadelta.deltas->torch._foreach_add(acc_deltas, eps)
torch.optim._multi_tensor.Adadelta(self,params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)
torch.optim._multi_tensor.Adadelta.step(self,closure=None)
torch.optim._multi_tensor.adadelta.Adadelta(self,params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)
torch.optim._multi_tensor.adadelta.Adadelta.__init__(self,params,lr=1.0,rho=0.9,eps=1e-06,weight_decay=0)
torch.optim._multi_tensor.adadelta.Adadelta.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/adamax.py----------------------------------------
A:torch.optim._multi_tensor.adamax.defaults->dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay)
A:torch.optim._multi_tensor.adamax.loss->closure()
A:torch.optim._multi_tensor.adamax.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adamax.state['exp_inf']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adamax.norm_buf->torch.cat([exp_inf.unsqueeze(0), grad.abs().add_(eps).unsqueeze_(0)], 0)
torch.optim._multi_tensor.Adamax(self,params,lr=0.002,betas=(0.9,0.999),eps=1e-08,weight_decay=0)
torch.optim._multi_tensor.Adamax.step(self,closure=None)
torch.optim._multi_tensor.adamax.Adamax(self,params,lr=0.002,betas=(0.9,0.999),eps=1e-08,weight_decay=0)
torch.optim._multi_tensor.adamax.Adamax.__init__(self,params,lr=0.002,betas=(0.9,0.999),eps=1e-08,weight_decay=0)
torch.optim._multi_tensor.adamax.Adamax.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/rmsprop.py----------------------------------------
A:torch.optim._multi_tensor.rmsprop.defaults->dict(lr=lr, momentum=momentum, alpha=alpha, eps=eps, centered=centered, weight_decay=weight_decay)
A:torch.optim._multi_tensor.rmsprop.loss->closure()
A:torch.optim._multi_tensor.rmsprop.state['square_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.rmsprop.state['momentum_buffer']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.rmsprop.state['grad_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.rmsprop.avg->torch._foreach_sqrt(square_avg)
torch.optim._multi_tensor.RMSprop(self,params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)
torch.optim._multi_tensor.RMSprop.__setstate__(self,state)
torch.optim._multi_tensor.RMSprop.step(self,closure=None)
torch.optim._multi_tensor.rmsprop.RMSprop(self,params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)
torch.optim._multi_tensor.rmsprop.RMSprop.__init__(self,params,lr=0.01,alpha=0.99,eps=1e-08,weight_decay=0,momentum=0,centered=False)
torch.optim._multi_tensor.rmsprop.RMSprop.__setstate__(self,state)
torch.optim._multi_tensor.rmsprop.RMSprop.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/sgd.py----------------------------------------
A:torch.optim._multi_tensor.sgd.defaults->dict(lr=lr, momentum=momentum, dampening=dampening, weight_decay=weight_decay, nesterov=nesterov)
A:torch.optim._multi_tensor.sgd.loss->closure()
A:torch.optim._multi_tensor.sgd.grads->torch._foreach_add(grads, params_with_grad, alpha=weight_decay)
A:torch.optim._multi_tensor.sgd.bufstates[i]['momentum_buffer']->torch.clone(grads[i]).detach()
torch.optim._multi_tensor.SGD(self,params,lr=required,momentum=0,dampening=0,weight_decay=0,nesterov=False)
torch.optim._multi_tensor.SGD.__setstate__(self,state)
torch.optim._multi_tensor.SGD.step(self,closure=None)
torch.optim._multi_tensor.sgd.SGD(self,params,lr=required,momentum=0,dampening=0,weight_decay=0,nesterov=False)
torch.optim._multi_tensor.sgd.SGD.__init__(self,params,lr=required,momentum=0,dampening=0,weight_decay=0,nesterov=False)
torch.optim._multi_tensor.sgd.SGD.__setstate__(self,state)
torch.optim._multi_tensor.sgd.SGD.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/adamw.py----------------------------------------
A:torch.optim._multi_tensor.adamw.defaults->dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)
A:torch.optim._multi_tensor.adamw.loss->closure()
A:torch.optim._multi_tensor.adamw.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adamw.state['exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adamw.state['max_exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adamw.max_exp_avg_sq_sqrt->torch._foreach_sqrt(max_exp_avg_sq)
A:torch.optim._multi_tensor.adamw.denom->torch._foreach_add(exp_avg_sq_sqrt, group['eps'])
A:torch.optim._multi_tensor.adamw.exp_avg_sq_sqrt->torch._foreach_sqrt(exp_avg_sq)
torch.optim._multi_tensor.AdamW(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)
torch.optim._multi_tensor.AdamW.__setstate__(self,state)
torch.optim._multi_tensor.AdamW.step(self,closure=None)
torch.optim._multi_tensor.adamw.AdamW(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)
torch.optim._multi_tensor.adamw.AdamW.__init__(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0.01,amsgrad=False)
torch.optim._multi_tensor.adamw.AdamW.__setstate__(self,state)
torch.optim._multi_tensor.adamw.AdamW.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/adam.py----------------------------------------
A:torch.optim._multi_tensor.adam.defaults->dict(lr=lr, betas=betas, eps=eps, weight_decay=weight_decay, amsgrad=amsgrad)
A:torch.optim._multi_tensor.adam.loss->closure()
A:torch.optim._multi_tensor.adam.state['exp_avg']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adam.state['exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adam.state['max_exp_avg_sq']->torch.zeros_like(p, memory_format=torch.preserve_format)
A:torch.optim._multi_tensor.adam.grads->torch._foreach_add(grads, params_with_grad, alpha=group['weight_decay'])
A:torch.optim._multi_tensor.adam.max_exp_avg_sq_sqrt->torch._foreach_sqrt(max_exp_avg_sq)
A:torch.optim._multi_tensor.adam.denom->torch._foreach_add(exp_avg_sq_sqrt, group['eps'])
A:torch.optim._multi_tensor.adam.exp_avg_sq_sqrt->torch._foreach_sqrt(exp_avg_sq)
torch.optim._multi_tensor.Adam(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
torch.optim._multi_tensor.Adam.__setstate__(self,state)
torch.optim._multi_tensor.Adam.step(self,closure=None)
torch.optim._multi_tensor.adam.Adam(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
torch.optim._multi_tensor.adam.Adam.__init__(self,params,lr=0.001,betas=(0.9,0.999),eps=1e-08,weight_decay=0,amsgrad=False)
torch.optim._multi_tensor.adam.Adam.__setstate__(self,state)
torch.optim._multi_tensor.adam.Adam.step(self,closure=None)


----------------------------------------/home/zhang/Packages/torch/torch1.7.0/optim/_multi_tensor/asgd.py----------------------------------------
A:torch.optim._multi_tensor.asgd.defaults->dict(lr=lr, lambd=lambd, alpha=alpha, t0=t0, weight_decay=weight_decay)
A:torch.optim._multi_tensor.asgd.loss->closure()
A:torch.optim._multi_tensor.asgd.state['ax']->torch.zeros_like(p, memory_format=torch.preserve_format)
torch.optim._multi_tensor.ASGD(self,params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)
torch.optim._multi_tensor.ASGD.step(self,closure=None)
torch.optim._multi_tensor.asgd.ASGD(self,params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)
torch.optim._multi_tensor.asgd.ASGD.__init__(self,params,lr=0.01,lambd=0.0001,alpha=0.75,t0=1000000.0,weight_decay=0)
torch.optim._multi_tensor.asgd.ASGD.step(self,closure=None)

