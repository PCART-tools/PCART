
----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/downloader.py----------------------------------------
A:gensim.downloader._DEFAULT_BASE_DIR->os.path.expanduser('~/gensim-data')
A:gensim.downloader.BASE_DIR->os.environ.get('GENSIM_DATA_DIR', _DEFAULT_BASE_DIR)
A:gensim.downloader._PARENT_DIR->os.path.abspath(os.path.join(BASE_DIR, '..'))
A:gensim.downloader.logger->logging.getLogger(__name__)
A:gensim.downloader.size_downloaded->float(chunks_downloaded * chunk_size)
A:gensim.downloader.filled_len->int(math.floor(bar_len * size_downloaded / total_size))
A:gensim.downloader.percent_downloaded->round(size_downloaded * 100 / total_size, 1)
A:gensim.downloader.hash_md5->hashlib.md5()
A:gensim.downloader.cache_path->os.path.join(BASE_DIR, 'information.json')
A:gensim.downloader.info_bytes->urlopen(url).read()
A:gensim.downloader.information->info()
A:gensim.downloader.url_load_file->'{base}/{fname}/__init__.py'.format(base=DOWNLOAD_BASE_URL, fname=name)
A:gensim.downloader.data_folder_dir->os.path.join(BASE_DIR, name)
A:gensim.downloader.tmp_dir->tempfile.mkdtemp()
A:gensim.downloader.init_path->os.path.join(tmp_dir, '__init__.py')
A:gensim.downloader.total_parts->_get_parts(name)
A:gensim.downloader.concatenated_folder_name->'{fname}.gz'.format(fname=name)
A:gensim.downloader.concatenated_folder_dir->os.path.join(tmp_dir, concatenated_folder_name)
A:gensim.downloader.url_data->'{base}/{fname}/{fname}.gz'.format(base=DOWNLOAD_BASE_URL, fname=name)
A:gensim.downloader.fname->'{fname}.gz'.format(fname=name)
A:gensim.downloader.dst_path->os.path.join(tmp_dir, fname)
A:gensim.downloader.part_path->os.path.join(tmp_dir, '{fname}.gz_0{part}'.format(fname=name, part=part))
A:gensim.downloader.file_name->_get_filename(name)
A:gensim.downloader.folder_dir->os.path.join(BASE_DIR, name)
A:gensim.downloader.path->os.path.join(folder_dir, file_name)
A:gensim.downloader.module->__import__(name)
A:gensim.downloader.parser->argparse.ArgumentParser(description='Gensim console API', usage='python -m gensim.api.downloader  [-h] [-d data_name | -i data_name]')
A:gensim.downloader.group->argparse.ArgumentParser(description='Gensim console API', usage='python -m gensim.api.downloader  [-h] [-d data_name | -i data_name]').add_mutually_exclusive_group()
A:gensim.downloader.args->argparse.ArgumentParser(description='Gensim console API', usage='python -m gensim.api.downloader  [-h] [-d data_name | -i data_name]').parse_args()
A:gensim.downloader.data_path->load(args.download[0], return_path=True)
gensim.downloader._calculate_md5_checksum(fname)
gensim.downloader._create_base_dir()
gensim.downloader._download(name)
gensim.downloader._get_checksum(name,part=None)
gensim.downloader._get_filename(name)
gensim.downloader._get_parts(name)
gensim.downloader._load_info(url=DATA_LIST_URL,encoding='utf-8')
gensim.downloader._progress(chunks_downloaded,chunk_size,total_size,part=1,total_parts=1)
gensim.downloader.info(name=None,show_only_latest=True,name_only=False)
gensim.downloader.load(name,return_path=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/utils.py----------------------------------------
A:gensim.utils.logger->logging.getLogger(__name__)
A:gensim.utils.PAT_ALPHABETIC->re.compile('(((?![\\d])\\w)+)', re.UNICODE)
A:gensim.utils.RE_HTML_ENTITY->re.compile('&(#?)([xX]?)(\\w{1,8});', re.UNICODE)
A:gensim.utils.NO_CYTHON->RuntimeError("Compiled extensions are unavailable. If you've installed from a package, ask the package maintainer to include compiled extensions. If you're building Gensim from source yourself, install Cython and a C compiler, and then run `python setup.py build_ext --inplace` to retry. ")
A:gensim.utils.default_prng->numpy.random.default_rng()
A:gensim.utils.tlock->getattr(self, tlockname)
A:gensim.utils.result->socket.gethostbyname(socket.gethostname())
A:gensim.utils.mgr->file_or_filename(input)
A:gensim.utils.text->deaccent(text)
A:gensim.utils.norm->unicodedata.normalize('NFD', text)
A:gensim.utils.event_dict->deepcopy(event)
A:gensim.utils.event_dict['datetime']->datetime.datetime.now().isoformat()
A:gensim.utils.event_dict['platform']->platform.platform()
A:gensim.utils.(compress, subname)->SaveLoad._adapt_by_suffix(fname)
A:gensim.utils.obj->itertools.chain([doc1], obj)
A:gensim.utils.cfname->'.'.join((fname, attrib))
A:gensim.utils.val->numpy.load(subname(fname, attrib), mmap_mode=mmap)
A:gensim.utils.sparse->unpickle(subname(fname, attrib))
A:gensim.utils.sparse.data->numpy.load(subname(fname, attrib, 'data'), mmap_mode=mmap)
A:gensim.utils.sparse.indptr->numpy.load(subname(fname, attrib, 'indptr'), mmap_mode=mmap)
A:gensim.utils.sparse.indices->numpy.load(subname(fname, attrib, 'indices'), mmap_mode=mmap)
A:gensim.utils.restores->self._save_specials(fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)
A:gensim.utils.asides[attrib]->getattr(self, attrib)
A:gensim.utils.maxid->max(maxid, max((fieldid for (fieldid, _) in document)))
A:gensim.utils.id2word->FakeDict(num_terms)
A:gensim.utils.doc1->next(iter(obj))
A:gensim.utils.(id1, val1)->next(iter(doc1))
A:gensim.utils.ns->locateNS()
A:gensim.utils.s->socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
A:gensim.utils.(result, port)->socket.socket(socket.AF_INET, socket.SOCK_DGRAM).getsockname()
A:gensim.utils.self.length->sum((1 for x in self))
A:gensim.utils.(start, end, step)->self.slice_.indices(len(self.corpus.index))
A:gensim.utils.ent->match.group(3)
A:gensim.utils.cp->html.entities.name2codepoint.get(ent)
A:gensim.utils.it->iter(self.corpus)
A:gensim.utils.chunk->itertools.islice(it, self.chunksize)
A:gensim.utils.qsize->self.q.qsize()
A:gensim.utils.q->multiprocessing.Queue(maxsize=maxsize)
A:gensim.utils.worker->InputQueue(q, corpus, chunksize, maxsize=maxsize, as_numpy=as_numpy)
A:gensim.utils.(fname, oext)->os.path.splitext(fname)
A:gensim.utils.sims->sorted(enumerate(sims), key=lambda item: -item[1])
A:gensim.utils.doc['tokens']->preprocess(doc['text'])
A:gensim.utils.uri->daemon.register(obj, name)
A:gensim.utils.nnz->numpy.random.uniform(size=(dim,))
A:gensim.utils.old_len->len(vocab)
A:gensim.utils.rule_res->trim_rule(word, count, min_count)
A:gensim.utils.process->subprocess.Popen(*popenargs, stdout=stdout, **kwargs)
A:gensim.utils.(output, unused_err)->subprocess.Popen(*popenargs, stdout=stdout, **kwargs).communicate()
A:gensim.utils.retcode->subprocess.Popen(*popenargs, stdout=stdout, **kwargs).poll()
A:gensim.utils.cmd->kwargs.get('args')
A:gensim.utils.error->subprocess.CalledProcessError(retcode, cmd)
A:gensim.utils.ndarray->numpy.asarray(ndarray)
A:gensim.utils.doc_windows->strided_windows(document, window_size)
A:gensim.utils.line->any2unicode(' '.join(sentence) + '\n')
A:gensim.utils.n_jobs->max(multiprocessing.cpu_count() + 1 + n_jobs, 1)
gensim.utils.ClippedCorpus(self,corpus,max_docs=None)
gensim.utils.ClippedCorpus.__init__(self,corpus,max_docs=None)
gensim.utils.ClippedCorpus.__iter__(self)
gensim.utils.ClippedCorpus.__len__(self)
gensim.utils.FakeDict(self,num_terms)
gensim.utils.FakeDict.__contains__(self,val)
gensim.utils.FakeDict.__getitem__(self,val)
gensim.utils.FakeDict.__init__(self,num_terms)
gensim.utils.FakeDict.__len__(self)
gensim.utils.FakeDict.__str__(self)
gensim.utils.FakeDict.get(self,val,default=None)
gensim.utils.FakeDict.iteritems(self)
gensim.utils.FakeDict.keys(self)
gensim.utils.InputQueue(self,q,corpus,chunksize,maxsize,as_numpy)
gensim.utils.InputQueue.__init__(self,q,corpus,chunksize,maxsize,as_numpy)
gensim.utils.InputQueue.run(self)
gensim.utils.RepeatCorpus(self,corpus,reps)
gensim.utils.RepeatCorpus.__init__(self,corpus,reps)
gensim.utils.RepeatCorpus.__iter__(self)
gensim.utils.RepeatCorpusNTimes(self,corpus,n)
gensim.utils.RepeatCorpusNTimes.__init__(self,corpus,n)
gensim.utils.RepeatCorpusNTimes.__iter__(self)
gensim.utils.SaveLoad
gensim.utils.SaveLoad._adapt_by_suffix(fname)
gensim.utils.SaveLoad._load_specials(self,fname,mmap,compress,subname)
gensim.utils.SaveLoad._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.utils.SaveLoad._smart_save(self,fname,separately=None,sep_limit=10*1024**2,ignore=frozenset(),pickle_protocol=PICKLE_PROTOCOL)
gensim.utils.SaveLoad.add_lifecycle_event(self,event_name,log_level=logging.INFO,**event)
gensim.utils.SaveLoad.load(cls,fname,mmap=None)
gensim.utils.SaveLoad.save(self,fname_or_handle,separately=None,sep_limit=10*1024**2,ignore=frozenset(),pickle_protocol=PICKLE_PROTOCOL)
gensim.utils.SlicedCorpus(self,corpus,slice_)
gensim.utils.SlicedCorpus.__init__(self,corpus,slice_)
gensim.utils.SlicedCorpus.__iter__(self)
gensim.utils.SlicedCorpus.__len__(self)
gensim.utils._iter_windows(document,window_size,copy=False,ignore_below_size=True)
gensim.utils.any2unicode(text,encoding='utf8',errors='strict')
gensim.utils.any2utf8(text,errors='strict',encoding='utf8')
gensim.utils.call_on_class_only(*args,**kwargs)
gensim.utils.check_output(stdout=subprocess.PIPE,*popenargs,**kwargs)
gensim.utils.chunkize_serial(iterable,chunksize,as_numpy=False,dtype=np.float32)
gensim.utils.copytree_hardlink(source,dest)
gensim.utils.deaccent(text)
gensim.utils.decode_htmlentities(text)
gensim.utils.deprecated(reason)
gensim.utils.dict_from_corpus(corpus)
gensim.utils.effective_n_jobs(n_jobs)
gensim.utils.file_or_filename(input)
gensim.utils.flatten(nested_list)
gensim.utils.getNS(host=None,port=None,broadcast=True,hmac_key=None)
gensim.utils.get_max_id(corpus)
gensim.utils.get_my_ip()
gensim.utils.get_random_state(seed)
gensim.utils.identity(p)
gensim.utils.ignore_deprecation_warning()
gensim.utils.is_corpus(obj)
gensim.utils.iter_windows(texts,window_size,copy=False,ignore_below_size=True,include_doc_num=False)
gensim.utils.keep_vocab_item(word,count,min_count,trim_rule=None)
gensim.utils.lazy_flatten(nested_list)
gensim.utils.merge_counts(dict1,dict2)
gensim.utils.mock_data(n_items=1000,dim=1000,prob_nnz=0.5,lam=1.0)
gensim.utils.mock_data_row(dim=1000,prob_nnz=0.5,lam=1.0)
gensim.utils.open_file(input)
gensim.utils.pickle(obj,fname,protocol=PICKLE_PROTOCOL)
gensim.utils.prune_vocab(vocab,min_reduce,trim_rule=None)
gensim.utils.pyro_daemon(name,obj,random_suffix=False,ip=None,port=None,ns_conf=None)
gensim.utils.qsize(queue)
gensim.utils.randfname(prefix='gensim')
gensim.utils.revdict(d)
gensim.utils.safe_unichr(intval)
gensim.utils.sample_dict(d,n=10,use_random=True)
gensim.utils.save_as_line_sentence(corpus,filename)
gensim.utils.simple_preprocess(doc,deacc=False,min_len=2,max_len=15)
gensim.utils.simple_tokenize(text)
gensim.utils.smart_extension(fname,ext)
gensim.utils.strided_windows(ndarray,window_size)
gensim.utils.synchronous(tlockname)
gensim.utils.tokenize(text,lowercase=False,deacc=False,encoding='utf8',errors='strict',to_lower=False,lower=False)
gensim.utils.toptexts(query,texts,index,n=10)
gensim.utils.trim_vocab_by_freq(vocab,topk,trim_rule=None)
gensim.utils.unpickle(fname)
gensim.utils.upload_chunked(server,docs,chunksize=1000,preprocess=None)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/matutils.py----------------------------------------
A:gensim.matutils.logger->logging.getLogger(__name__)
A:gensim.matutils.x->numpy.log(np.sum(np.exp(x - x_max)))
A:gensim.matutils.indices->set(list(vec1.keys()) + list(vec2.keys()))
A:gensim.matutils.data->numpy.asarray(data, dtype=dtype)
A:gensim.matutils.result->sum((value * vec2.get(index, 0.0) for (index, value) in vec1.items()))
A:gensim.matutils.buffer->numpy.zeros(nbytes + align, dtype=np.uint8)
A:gensim.matutils.biggest->nnz.take(argsort(abs(vec).take(nnz), topn, reverse=True))
A:gensim.matutils.matrix_abs->abs(matrix)
A:gensim.matutils.v->matrix.getrow(i)
A:gensim.matutils.v_abs->abs(matrix).getrow(i)
A:gensim.matutils.matrix_indices->numpy.concatenate(matrix_indices).ravel()
A:gensim.matutils.matrix_data->numpy.concatenate(matrix_data).ravel()
A:gensim.matutils.vec->vec.todense().tolist().todense().tolist()
A:gensim.matutils.doc->dict(doc)
A:gensim.matutils.result[list(doc)]->list(doc.values())
A:gensim.matutils.result[:, docno]->sparse2full(doc, num_terms)
A:gensim.matutils.self.sparse->sparse.tocsc()
A:gensim.matutils.max_val->numpy.max(vec, 1)
A:gensim.matutils.tot->numpy.sum(np.exp(vec + log_shift[:, np.newaxis]), 1)
A:gensim.matutils.k->ret_log_normalize_vec(vec.T)
A:gensim.matutils.blas_nrm2->blas('nrm2', np.array([], dtype=float))
A:gensim.matutils.blas_scal->blas('scal', np.array([], dtype=float))
A:gensim.matutils.veclen->numpy.count_nonzero(vec)
A:gensim.matutils.first->next(iter(vec))
A:gensim.matutils.length->float(sum((abs(val) for (_, val) in vec)))
A:gensim.matutils.vec1->set(vec1)
A:gensim.matutils.vec2->set(vec2)
A:gensim.matutils.dense1->sparse2full(vec1, max_len)
A:gensim.matutils.dense2->sparse2full(vec2, max_len)
A:gensim.matutils.max_len->max(len(vec1), len(vec2))
A:gensim.matutils.(vec1, vec2)->_convert_vec(vec1, vec2, num_features=num_features)
A:gensim.matutils.sim->numpy.sqrt(0.5 * ((np.sqrt(vec1) - np.sqrt(vec2)) ** 2).sum())
A:gensim.matutils.union_cardinality->len(set1 | set2)
A:gensim.matutils.x_max->numpy.max(x)
A:gensim.matutils.a->numpy.asfortranarray(la[0])
A:gensim.matutils.(geqrf,)->get_lapack_funcs(('geqrf',), (a,))
A:gensim.matutils.(qr, tau, work, info)->geqrf(a, lwork=work[0], overwrite_a=True)
A:gensim.matutils.r->triu(qr[:n, :n])
A:gensim.matutils.(gorgqr,)->get_lapack_funcs(('orgqr',), (qr,))
A:gensim.matutils.(q, work, info)->gorgqr(qr, tau, lwork=work[0], overwrite_a=True)
A:gensim.matutils.self.fout->gensim.utils.open(self.fname, 'wb+')
A:gensim.matutils.vector->sorted(((i, w) for (i, w) in vector if abs(w) > 1e-12))
A:gensim.matutils.mw->MmWriter(fname)
A:gensim.matutils.posnow->MmWriter(fname).fout.tell()
A:gensim.matutils.(max_id, veclen)->MmWriter(fname).write_vector(docno, bow)
A:gensim.matutils._num_terms->max(_num_terms, 1 + max_id)
gensim.matutils.Dense2Corpus(self,dense,documents_columns=True)
gensim.matutils.Dense2Corpus.__init__(self,dense,documents_columns=True)
gensim.matutils.Dense2Corpus.__iter__(self)
gensim.matutils.Dense2Corpus.__len__(self)
gensim.matutils.MmWriter(self,fname)
gensim.matutils.MmWriter.__del__(self)
gensim.matutils.MmWriter.__init__(self,fname)
gensim.matutils.MmWriter.close(self)
gensim.matutils.MmWriter.fake_headers(self,num_docs,num_terms,num_nnz)
gensim.matutils.MmWriter.write_corpus(fname,corpus,progress_cnt=1000,index=False,num_terms=None,metadata=False)
gensim.matutils.MmWriter.write_headers(self,num_docs,num_terms,num_nnz)
gensim.matutils.MmWriter.write_vector(self,docno,vector)
gensim.matutils.Scipy2Corpus(self,vecs)
gensim.matutils.Scipy2Corpus.__init__(self,vecs)
gensim.matutils.Scipy2Corpus.__iter__(self)
gensim.matutils.Scipy2Corpus.__len__(self)
gensim.matutils.Sparse2Corpus(self,sparse,documents_columns=True)
gensim.matutils.Sparse2Corpus.__getitem__(self,document_index)
gensim.matutils.Sparse2Corpus.__init__(self,sparse,documents_columns=True)
gensim.matutils.Sparse2Corpus.__iter__(self)
gensim.matutils.Sparse2Corpus.__len__(self)
gensim.matutils._convert_vec(vec1,vec2,num_features=None)
gensim.matutils.any2sparse(vec,eps=1e-09)
gensim.matutils.argsort(x,topn=None,reverse=False)
gensim.matutils.blas(name,ndarray)
gensim.matutils.corpus2csc(corpus,num_terms=None,dtype=np.float64,num_docs=None,num_nnz=None,printprogress=0)
gensim.matutils.corpus2dense(corpus,num_terms,num_docs=None,dtype=np.float32)
gensim.matutils.cossim(vec1,vec2)
gensim.matutils.full2sparse(vec,eps=1e-09)
gensim.matutils.full2sparse_clipped(vec,topn,eps=1e-09)
gensim.matutils.hellinger(vec1,vec2)
gensim.matutils.isbow(vec)
gensim.matutils.ismatrix(m)
gensim.matutils.jaccard(vec1,vec2)
gensim.matutils.jaccard_distance(set1,set2)
gensim.matutils.jensen_shannon(vec1,vec2,num_features=None)
gensim.matutils.kullback_leibler(vec1,vec2,num_features=None)
gensim.matutils.pad(mat,padrow,padcol)
gensim.matutils.qr_destroy(la)
gensim.matutils.ret_log_normalize_vec(vec,axis=1)
gensim.matutils.ret_normalized_vec(vec,length)
gensim.matutils.scipy2scipy_clipped(matrix,topn,eps=1e-09)
gensim.matutils.scipy2sparse(vec,eps=1e-09)
gensim.matutils.sparse2full(doc,length)
gensim.matutils.unitvec(vec,norm='l2',return_norm=False)
gensim.matutils.veclen(vec)
gensim.matutils.zeros_aligned(shape,dtype,order='C',align=128)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/interfaces.py----------------------------------------
A:gensim.interfaces.logger->logging.getLogger(__name__)
A:gensim.interfaces.(is_corpus, query)->gensim.utils.is_corpus(query)
A:gensim.interfaces.query->gensim.matutils.unitvec(query)
A:gensim.interfaces.result->self.get_similarities(query)
A:gensim.interfaces.chunk_end->min(self.index.shape[0], chunk_start + self.chunksize)
gensim.interfaces.CorpusABC(utils.SaveLoad)
gensim.interfaces.CorpusABC.__iter__(self)
gensim.interfaces.CorpusABC.__len__(self)
gensim.interfaces.CorpusABC.save(self,*args,**kwargs)
gensim.interfaces.CorpusABC.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.interfaces.SimilarityABC(self,corpus)
gensim.interfaces.SimilarityABC.__getitem__(self,query)
gensim.interfaces.SimilarityABC.__init__(self,corpus)
gensim.interfaces.SimilarityABC.__iter__(self)
gensim.interfaces.SimilarityABC.get_similarities(self,doc)
gensim.interfaces.TransformationABC(utils.SaveLoad)
gensim.interfaces.TransformationABC.__getitem__(self,vec)
gensim.interfaces.TransformationABC._apply(self,corpus,chunksize=None,**kwargs)
gensim.interfaces.TransformedCorpus(self,obj,corpus,chunksize=None,**kwargs)
gensim.interfaces.TransformedCorpus.__getitem__(self,docno)
gensim.interfaces.TransformedCorpus.__init__(self,obj,corpus,chunksize=None,**kwargs)
gensim.interfaces.TransformedCorpus.__iter__(self)
gensim.interfaces.TransformedCorpus.__len__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/__init__.py----------------------------------------
A:gensim.__init__.logger->logging.getLogger('gensim')


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/nosy.py----------------------------------------
A:gensim.nosy.stats->os.stat(os.path.join(root, f))
A:gensim.nosy.val->check_sum()
gensim.nosy.check_sum()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/word2vec_standalone.py----------------------------------------
A:gensim.scripts.word2vec_standalone.logger->logging.getLogger(__name__)
A:gensim.scripts.word2vec_standalone.parser->argparse.ArgumentParser()
A:gensim.scripts.word2vec_standalone.args->argparse.ArgumentParser().parse_args()
A:gensim.scripts.word2vec_standalone.corpus->LineSentence(args.train)
A:gensim.scripts.word2vec_standalone.model->Word2Vec(corpus, vector_size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, alpha=args.alpha, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, epochs=args.iter)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/word2vec2tensor.py----------------------------------------
A:gensim.scripts.word2vec2tensor.logger->logging.getLogger(__name__)
A:gensim.scripts.word2vec2tensor.model->gensim.models.KeyedVectors.load_word2vec_format(word2vec_model_path, binary=binary)
A:gensim.scripts.word2vec2tensor.vector_row->'\t'.join((str(x) for x in model[word]))
A:gensim.scripts.word2vec2tensor.parser->argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=__doc__[:-138])
A:gensim.scripts.word2vec2tensor.args->argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=__doc__[:-138]).parse_args()
gensim.scripts.word2vec2tensor.word2vec2tensor(word2vec_model_path,tensor_filename,binary=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/make_wiki_online_nodebug.py----------------------------------------
A:gensim.scripts.make_wiki_online_nodebug.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki_online_nodebug.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki_online_nodebug.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki_online_nodebug.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki_online_nodebug.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki_online_nodebug.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki_online_nodebug.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/benchmark.py----------------------------------------
A:gensim.scripts.benchmark.logger->logging.getLogger(__name__)
A:gensim.scripts.benchmark.corpus->Text8Corpus(sys.argv[1])


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/make_wiki.py----------------------------------------
A:gensim.scripts.make_wiki.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki.wiki->WikiCorpus(inp)
A:gensim.scripts.make_wiki.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/make_wiki_online.py----------------------------------------
A:gensim.scripts.make_wiki_online.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki_online.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki_online.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki_online.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki_online.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki_online.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki_online.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/make_wikicorpus.py----------------------------------------
A:gensim.scripts.make_wikicorpus.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wikicorpus.logger->logging.getLogger(program)
A:gensim.scripts.make_wikicorpus.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wikicorpus.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wikicorpus.wiki->WikiCorpus(inp)
A:gensim.scripts.make_wikicorpus.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wikicorpus.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/glove2word2vec.py----------------------------------------
A:gensim.scripts.glove2word2vec.logger->logging.getLogger(__name__)
A:gensim.scripts.glove2word2vec.num_lines->sum((1 for _ in f))
A:gensim.scripts.glove2word2vec.glovekv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(glove_input_file, binary=False, no_header=True)
A:gensim.scripts.glove2word2vec.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawDescriptionHelpFormatter)
A:gensim.scripts.glove2word2vec.args->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawDescriptionHelpFormatter).parse_args()
A:gensim.scripts.glove2word2vec.(num_lines, num_dims)->glove2word2vec(args.input, args.output)
gensim.scripts.glove2word2vec.get_glove_info(glove_file_name)
gensim.scripts.glove2word2vec.glove2word2vec(glove_input_file,word2vec_output_file)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/segment_wiki.py----------------------------------------
A:gensim.scripts.segment_wiki.logger->logging.getLogger(__name__)
A:gensim.scripts.segment_wiki.wiki_sections_corpus->_WikiSectionsCorpus(xml_fileobj, min_article_character=min_article_character, processes=workers, include_interlinks=include_interlinks)
A:gensim.scripts.segment_wiki.wiki_sections_text->_WikiSectionsCorpus(xml_fileobj, min_article_character=min_article_character, processes=workers, include_interlinks=include_interlinks).get_texts_with_sections()
A:gensim.scripts.segment_wiki.outfile->gensim.utils.open(output_file, 'wb')
A:gensim.scripts.segment_wiki.article_stream->segment_all_articles(file_path, min_article_character, workers=workers, include_interlinks=include_interlinks)
A:gensim.scripts.segment_wiki.elem->xml.etree.ElementTree.fromstring(page_xml)
A:gensim.scripts.segment_wiki.namespace->get_namespace(elem.tag)
A:gensim.scripts.segment_wiki.interlinks->find_interlinks(text)
A:gensim.scripts.segment_wiki.section_contents->re.split(top_level_heading_regex, text)
A:gensim.scripts.segment_wiki.sections->list(zip(section_headings, section_contents))
A:gensim.scripts.segment_wiki.processes->max(1, multiprocessing.cpu_count() - 1)
A:gensim.scripts.segment_wiki.page_xmls->extract_page_xmls(self.fileobj)
A:gensim.scripts.segment_wiki.pool->multiprocessing.Pool(self.processes)
A:gensim.scripts.segment_wiki.parser->argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description=__doc__[:-136])
A:gensim.scripts.segment_wiki.default_workers->max(1, multiprocessing.cpu_count() - 1)
A:gensim.scripts.segment_wiki.args->argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description=__doc__[:-136]).parse_args()
gensim.scripts.segment_wiki._WikiSectionsCorpus(self,fileobj,min_article_character=200,processes=None,lemmatize=None,filter_namespaces=('0',),include_interlinks=False)
gensim.scripts.segment_wiki._WikiSectionsCorpus.__init__(self,fileobj,min_article_character=200,processes=None,lemmatize=None,filter_namespaces=('0',),include_interlinks=False)
gensim.scripts.segment_wiki._WikiSectionsCorpus.get_texts_with_sections(self)
gensim.scripts.segment_wiki.extract_page_xmls(f)
gensim.scripts.segment_wiki.segment(page_xml,include_interlinks=False)
gensim.scripts.segment_wiki.segment_all_articles(file_path,min_article_character=200,workers=None,include_interlinks=False)
gensim.scripts.segment_wiki.segment_and_write_all_articles(file_path,output_file,min_article_character=200,workers=None,include_interlinks=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/scripts/package_info.py----------------------------------------
A:gensim.scripts.package_info.parser->argparse.ArgumentParser(description=__doc__[:-65], formatter_class=argparse.RawDescriptionHelpFormatter)
A:gensim.scripts.package_info.args->argparse.ArgumentParser(description=__doc__[:-65], formatter_class=argparse.RawDescriptionHelpFormatter).parse_args()
gensim.scripts.package_info.package_info()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/malletcorpus.py----------------------------------------
A:gensim.corpora.malletcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.malletcorpus.result->sum((1 for _ in fin))
A:gensim.corpora.malletcorpus.split_line->gensim.utils.to_unicode(line).strip().split(None, 2)
A:gensim.corpora.malletcorpus.doc->super(MalletCorpus, self).line2doc(words)
A:gensim.corpora.malletcorpus.id2word->gensim.utils.dict_from_corpus(corpus)
gensim.corpora.MalletCorpus(self,fname,id2word=None,metadata=False)
gensim.corpora.MalletCorpus.__iter__(self)
gensim.corpora.MalletCorpus._calculate_num_docs(self)
gensim.corpora.MalletCorpus.docbyoffset(self,offset)
gensim.corpora.MalletCorpus.line2doc(self,line)
gensim.corpora.MalletCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.malletcorpus.MalletCorpus(self,fname,id2word=None,metadata=False)
gensim.corpora.malletcorpus.MalletCorpus.__init__(self,fname,id2word=None,metadata=False)
gensim.corpora.malletcorpus.MalletCorpus.__iter__(self)
gensim.corpora.malletcorpus.MalletCorpus._calculate_num_docs(self)
gensim.corpora.malletcorpus.MalletCorpus.docbyoffset(self,offset)
gensim.corpora.malletcorpus.MalletCorpus.line2doc(self,line)
gensim.corpora.malletcorpus.MalletCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/svmlightcorpus.py----------------------------------------
A:gensim.corpora.svmlightcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.svmlightcorpus.doc->self.line2doc(line)
A:gensim.corpora.svmlightcorpus.labels->list(labels)
A:gensim.corpora.svmlightcorpus.line->line[:line.find('#')].strip()
A:gensim.corpora.svmlightcorpus.parts->line[:line.find('#')].strip().split()
A:gensim.corpora.svmlightcorpus.pairs->' '.join(('%i:%s' % (termid + 1, termval) for (termid, termval) in doc))
gensim.corpora.SvmLightCorpus(self,fname,store_labels=True)
gensim.corpora.SvmLightCorpus.__iter__(self)
gensim.corpora.SvmLightCorpus.doc2line(doc,label=0)
gensim.corpora.SvmLightCorpus.docbyoffset(self,offset)
gensim.corpora.SvmLightCorpus.line2doc(self,line)
gensim.corpora.SvmLightCorpus.save_corpus(fname,corpus,id2word=None,labels=False,metadata=False)
gensim.corpora.svmlightcorpus.SvmLightCorpus(self,fname,store_labels=True)
gensim.corpora.svmlightcorpus.SvmLightCorpus.__init__(self,fname,store_labels=True)
gensim.corpora.svmlightcorpus.SvmLightCorpus.__iter__(self)
gensim.corpora.svmlightcorpus.SvmLightCorpus.doc2line(doc,label=0)
gensim.corpora.svmlightcorpus.SvmLightCorpus.docbyoffset(self,offset)
gensim.corpora.svmlightcorpus.SvmLightCorpus.line2doc(self,line)
gensim.corpora.svmlightcorpus.SvmLightCorpus.save_corpus(fname,corpus,id2word=None,labels=False,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/textcorpus.py----------------------------------------
A:gensim.corpora.textcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.textcorpus.text->character_filter(text)
A:gensim.corpora.textcorpus.tokens->self.tokenizer(text)
A:gensim.corpora.textcorpus.lines->self.getstream()
A:gensim.corpora.textcorpus.length->len(self)
A:gensim.corpora.textcorpus.chance->random_generator.randint(1, remaining_in_corpus)
A:gensim.corpora.textcorpus.self.length->sum((1 for _ in self.getstream()))
A:gensim.corpora.textcorpus.names->os.listdir(top)
A:gensim.corpora.textcorpus.new_path->join(top, name)
gensim.corpora.TextCorpus(self,input=None,dictionary=None,metadata=False,character_filters=None,tokenizer=None,token_filters=None)
gensim.corpora.TextCorpus.__iter__(self)
gensim.corpora.TextCorpus.__len__(self)
gensim.corpora.TextCorpus.get_texts(self)
gensim.corpora.TextCorpus.getstream(self)
gensim.corpora.TextCorpus.init_dictionary(self,dictionary)
gensim.corpora.TextCorpus.preprocess_text(self,text)
gensim.corpora.TextCorpus.sample_texts(self,n,seed=None,length=None)
gensim.corpora.TextCorpus.step_through_preprocess(self,text)
gensim.corpora.TextDirectoryCorpus(self,input,dictionary=None,metadata=False,min_depth=0,max_depth=None,pattern=None,exclude_pattern=None,lines_are_documents=False,**kwargs)
gensim.corpora.TextDirectoryCorpus.__len__(self)
gensim.corpora.TextDirectoryCorpus._cache_corpus_length(self)
gensim.corpora.TextDirectoryCorpus.exclude_pattern(self)
gensim.corpora.TextDirectoryCorpus.exclude_pattern(self,pattern)
gensim.corpora.TextDirectoryCorpus.getstream(self)
gensim.corpora.TextDirectoryCorpus.iter_filepaths(self)
gensim.corpora.TextDirectoryCorpus.lines_are_documents(self)
gensim.corpora.TextDirectoryCorpus.lines_are_documents(self,lines_are_documents)
gensim.corpora.TextDirectoryCorpus.max_depth(self)
gensim.corpora.TextDirectoryCorpus.max_depth(self,max_depth)
gensim.corpora.TextDirectoryCorpus.min_depth(self)
gensim.corpora.TextDirectoryCorpus.min_depth(self,min_depth)
gensim.corpora.TextDirectoryCorpus.pattern(self)
gensim.corpora.TextDirectoryCorpus.pattern(self,pattern)
gensim.corpora.textcorpus.TextCorpus(self,input=None,dictionary=None,metadata=False,character_filters=None,tokenizer=None,token_filters=None)
gensim.corpora.textcorpus.TextCorpus.__init__(self,input=None,dictionary=None,metadata=False,character_filters=None,tokenizer=None,token_filters=None)
gensim.corpora.textcorpus.TextCorpus.__iter__(self)
gensim.corpora.textcorpus.TextCorpus.__len__(self)
gensim.corpora.textcorpus.TextCorpus.get_texts(self)
gensim.corpora.textcorpus.TextCorpus.getstream(self)
gensim.corpora.textcorpus.TextCorpus.init_dictionary(self,dictionary)
gensim.corpora.textcorpus.TextCorpus.preprocess_text(self,text)
gensim.corpora.textcorpus.TextCorpus.sample_texts(self,n,seed=None,length=None)
gensim.corpora.textcorpus.TextCorpus.step_through_preprocess(self,text)
gensim.corpora.textcorpus.TextDirectoryCorpus(self,input,dictionary=None,metadata=False,min_depth=0,max_depth=None,pattern=None,exclude_pattern=None,lines_are_documents=False,**kwargs)
gensim.corpora.textcorpus.TextDirectoryCorpus.__init__(self,input,dictionary=None,metadata=False,min_depth=0,max_depth=None,pattern=None,exclude_pattern=None,lines_are_documents=False,**kwargs)
gensim.corpora.textcorpus.TextDirectoryCorpus.__len__(self)
gensim.corpora.textcorpus.TextDirectoryCorpus._cache_corpus_length(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.exclude_pattern(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.exclude_pattern(self,pattern)
gensim.corpora.textcorpus.TextDirectoryCorpus.getstream(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.iter_filepaths(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.lines_are_documents(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.lines_are_documents(self,lines_are_documents)
gensim.corpora.textcorpus.TextDirectoryCorpus.max_depth(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.max_depth(self,max_depth)
gensim.corpora.textcorpus.TextDirectoryCorpus.min_depth(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.min_depth(self,min_depth)
gensim.corpora.textcorpus.TextDirectoryCorpus.pattern(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.pattern(self,pattern)
gensim.corpora.textcorpus.walk(top,topdown=True,onerror=None,followlinks=False,depth=0)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/hashdictionary.py----------------------------------------
A:gensim.corpora.hashdictionary.logger->logging.getLogger(__name__)
A:gensim.corpora.hashdictionary.document->sorted(document)
A:gensim.corpora.hashdictionary.frequency->len(list(group))
A:gensim.corpora.hashdictionary.tokenid->self.restricted_hash(word_norm)
A:gensim.corpora.hashdictionary.result->sorted(result.items())
A:gensim.corpora.hashdictionary.no_above_abs->int(no_above * self.num_docs)
A:gensim.corpora.hashdictionary.ok->frozenset((word for (word, freq) in sorted(ok, key=lambda x: -x[1])[:keep_n]))
A:gensim.corpora.hashdictionary.words->sorted(self[tokenid])
A:gensim.corpora.hashdictionary.words_df->'\t'.join(words_df)
gensim.corpora.HashDictionary(self,documents=None,id_range=32000,myhash=zlib.adler32,debug=True)
gensim.corpora.HashDictionary.__getitem__(self,tokenid)
gensim.corpora.HashDictionary.__len__(self)
gensim.corpora.HashDictionary.__str__(self)
gensim.corpora.HashDictionary.add_documents(self,documents)
gensim.corpora.HashDictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.HashDictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000)
gensim.corpora.HashDictionary.from_documents(*args,**kwargs)
gensim.corpora.HashDictionary.keys(self)
gensim.corpora.HashDictionary.restricted_hash(self,token)
gensim.corpora.HashDictionary.save_as_text(self,fname)
gensim.corpora.hashdictionary.HashDictionary(self,documents=None,id_range=32000,myhash=zlib.adler32,debug=True)
gensim.corpora.hashdictionary.HashDictionary.__getitem__(self,tokenid)
gensim.corpora.hashdictionary.HashDictionary.__init__(self,documents=None,id_range=32000,myhash=zlib.adler32,debug=True)
gensim.corpora.hashdictionary.HashDictionary.__len__(self)
gensim.corpora.hashdictionary.HashDictionary.__str__(self)
gensim.corpora.hashdictionary.HashDictionary.add_documents(self,documents)
gensim.corpora.hashdictionary.HashDictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.hashdictionary.HashDictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000)
gensim.corpora.hashdictionary.HashDictionary.from_documents(*args,**kwargs)
gensim.corpora.hashdictionary.HashDictionary.keys(self)
gensim.corpora.hashdictionary.HashDictionary.restricted_hash(self,token)
gensim.corpora.hashdictionary.HashDictionary.save_as_text(self,fname)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/lowcorpus.py----------------------------------------
A:gensim.corpora.lowcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.lowcorpus.self.num_docs->self._calculate_num_docs()
A:gensim.corpora.lowcorpus.all_terms->sorted(all_terms)
A:gensim.corpora.lowcorpus.self.id2word->dict(zip(range(len(all_terms)), all_terms))
A:gensim.corpora.lowcorpus.self.num_terms->len(self.word2id)
A:gensim.corpora.lowcorpus.result->int(next(fin))
A:gensim.corpora.lowcorpus.words->self.line2words(line)
A:gensim.corpora.lowcorpus.word_freqs->Counter(words)
A:gensim.corpora.lowcorpus.doc->list(word_freqs.items())
A:gensim.corpora.lowcorpus.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.corpora.lowcorpus.self.word2id->gensim.utils.revdict(val)
gensim.corpora.LowCorpus(self,fname,id2word=None,line2words=split_on_space)
gensim.corpora.LowCorpus.__iter__(self)
gensim.corpora.LowCorpus.__len__(self)
gensim.corpora.LowCorpus._calculate_num_docs(self)
gensim.corpora.LowCorpus.docbyoffset(self,offset)
gensim.corpora.LowCorpus.id2word(self)
gensim.corpora.LowCorpus.id2word(self,val)
gensim.corpora.LowCorpus.line2doc(self,line)
gensim.corpora.LowCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.lowcorpus.LowCorpus(self,fname,id2word=None,line2words=split_on_space)
gensim.corpora.lowcorpus.LowCorpus.__init__(self,fname,id2word=None,line2words=split_on_space)
gensim.corpora.lowcorpus.LowCorpus.__iter__(self)
gensim.corpora.lowcorpus.LowCorpus.__len__(self)
gensim.corpora.lowcorpus.LowCorpus._calculate_num_docs(self)
gensim.corpora.lowcorpus.LowCorpus.docbyoffset(self,offset)
gensim.corpora.lowcorpus.LowCorpus.id2word(self)
gensim.corpora.lowcorpus.LowCorpus.id2word(self,val)
gensim.corpora.lowcorpus.LowCorpus.line2doc(self,line)
gensim.corpora.lowcorpus.LowCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/sharded_corpus.py----------------------------------------
A:gensim.corpora.sharded_corpus.logger->logging.getLogger(__name__)
A:gensim.corpora.sharded_corpus.(is_corpus, corpus)->gensim.utils.is_corpus(corpus)
A:gensim.corpora.sharded_corpus.proposed_dim->self._guess_n_features(corpus)
A:gensim.corpora.sharded_corpus.start_time->time.perf_counter()
A:gensim.corpora.sharded_corpus.current_shard->scipy.sparse.csr_matrix(current_shard)
A:gensim.corpora.sharded_corpus.doc->dict(doc)
A:gensim.corpora.sharded_corpus.current_shard[i][list(doc)]->list(doc.values())
A:gensim.corpora.sharded_corpus.end_time->time.perf_counter()
A:gensim.corpora.sharded_corpus.temp->self.__class__.load(self.output_prefix)
A:gensim.corpora.sharded_corpus.filename->self._shard_name(n)
A:gensim.corpora.sharded_corpus.shard->gensim.utils.unpickle(filename)
A:gensim.corpora.sharded_corpus.k->int(offset / self.shardsize)
A:gensim.corpora.sharded_corpus.n_new_shards->int(math.floor(self.n_docs / float(shardsize)))
A:gensim.corpora.sharded_corpus.new_shard_name->self._resized_shard_name(new_shard_idx)
A:gensim.corpora.sharded_corpus.n_features->len(corpus.dictionary)
A:gensim.corpora.sharded_corpus.shard_n->self.shard_by_offset(offset)
A:gensim.corpora.sharded_corpus.l_result->scipy.sparse.csr_matrix(l_result)
A:gensim.corpora.sharded_corpus.first_shard->self.shard_by_offset(start)
A:gensim.corpora.sharded_corpus.last_shard->self.shard_by_offset(stop)
A:gensim.corpora.sharded_corpus.s_result->scipy.sparse.csr_matrix(s_result)
A:gensim.corpora.sharded_corpus.output->gensim.matutils.full2sparse(result)
A:gensim.corpora.sharded_corpus.kwargs['ignore']->frozenset(attrs_to_ignore)
gensim.corpora.sharded_corpus.ShardedCorpus(self,output_prefix,corpus,dim=None,shardsize=4096,overwrite=False,sparse_serialization=False,sparse_retrieval=False,gensim=False)
gensim.corpora.sharded_corpus.ShardedCorpus.__add_to_slice(self,s_result,result_start,result_stop,start,stop)
gensim.corpora.sharded_corpus.ShardedCorpus.__getitem__(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.__init__(self,output_prefix,corpus,dim=None,shardsize=4096,overwrite=False,sparse_serialization=False,sparse_retrieval=False,gensim=False)
gensim.corpora.sharded_corpus.ShardedCorpus.__iter__(self)
gensim.corpora.sharded_corpus.ShardedCorpus.__len__(self)
gensim.corpora.sharded_corpus.ShardedCorpus._ensure_shard(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus._getitem_dense2gensim(self,result)
gensim.corpora.sharded_corpus.ShardedCorpus._getitem_format(self,s_result)
gensim.corpora.sharded_corpus.ShardedCorpus._getitem_sparse2gensim(self,result)
gensim.corpora.sharded_corpus.ShardedCorpus._guess_n_features(self,corpus)
gensim.corpora.sharded_corpus.ShardedCorpus._resized_shard_name(self,n)
gensim.corpora.sharded_corpus.ShardedCorpus._shard_name(self,n)
gensim.corpora.sharded_corpus.ShardedCorpus.get_by_offset(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.in_current(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.in_next(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.init_by_clone(self)
gensim.corpora.sharded_corpus.ShardedCorpus.init_shards(self,output_prefix,corpus,shardsize=4096,dtype=_default_dtype)
gensim.corpora.sharded_corpus.ShardedCorpus.load(cls,fname,mmap=None)
gensim.corpora.sharded_corpus.ShardedCorpus.load_shard(self,n)
gensim.corpora.sharded_corpus.ShardedCorpus.reset(self)
gensim.corpora.sharded_corpus.ShardedCorpus.resize_shards(self,shardsize)
gensim.corpora.sharded_corpus.ShardedCorpus.save(self,*args,**kwargs)
gensim.corpora.sharded_corpus.ShardedCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=1000,metadata=False,**kwargs)
gensim.corpora.sharded_corpus.ShardedCorpus.save_shard(self,shard,n=None,filename=None)
gensim.corpora.sharded_corpus.ShardedCorpus.serialize(serializer,fname,corpus,id2word=None,index_fname=None,progress_cnt=None,labels=None,metadata=False,**kwargs)
gensim.corpora.sharded_corpus.ShardedCorpus.shard_by_offset(self,offset)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/bleicorpus.py----------------------------------------
A:gensim.corpora.bleicorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.bleicorpus.(fname_base, _)->os.path.splitext(fname)
A:gensim.corpora.bleicorpus.fname_dir->os.path.dirname(fname)
A:gensim.corpora.bleicorpus.self.id2word->dict(enumerate(words))
A:gensim.corpora.bleicorpus.parts->gensim.utils.to_unicode(line).split()
A:gensim.corpora.bleicorpus.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.corpora.bleicorpus.num_terms->len(id2word)
A:gensim.corpora.bleicorpus.doc->list(doc)
A:gensim.corpora.bleicorpus.fname_vocab->gensim.utils.smart_extension(fname, '.vocab')
gensim.corpora.BleiCorpus(self,fname,fname_vocab=None)
gensim.corpora.BleiCorpus.__iter__(self)
gensim.corpora.BleiCorpus.docbyoffset(self,offset)
gensim.corpora.BleiCorpus.line2doc(self,line)
gensim.corpora.BleiCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.bleicorpus.BleiCorpus(self,fname,fname_vocab=None)
gensim.corpora.bleicorpus.BleiCorpus.__init__(self,fname,fname_vocab=None)
gensim.corpora.bleicorpus.BleiCorpus.__iter__(self)
gensim.corpora.bleicorpus.BleiCorpus.docbyoffset(self,offset)
gensim.corpora.bleicorpus.BleiCorpus.line2doc(self,line)
gensim.corpora.bleicorpus.BleiCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/mmcorpus.py----------------------------------------
A:gensim.corpora.mmcorpus.logger->logging.getLogger(__name__)
gensim.corpora.MmCorpus(self,fname)
gensim.corpora.MmCorpus.__iter__(self)
gensim.corpora.MmCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=1000,metadata=False)
gensim.corpora.mmcorpus.MmCorpus(self,fname)
gensim.corpora.mmcorpus.MmCorpus.__init__(self,fname)
gensim.corpora.mmcorpus.MmCorpus.__iter__(self)
gensim.corpora.mmcorpus.MmCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=1000,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/ucicorpus.py----------------------------------------
A:gensim.corpora.ucicorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.ucicorpus.self.num_docs->int(next(fin).strip())
A:gensim.corpora.ucicorpus.self.num_terms->int(next(fin).strip())
A:gensim.corpora.ucicorpus.self.num_nnz->int(next(fin).strip())
A:gensim.corpora.ucicorpus.FAKE_HEADER->gensim.utils.to_utf8(' ' * MAX_HEADER_LENGTH + '\n')
A:gensim.corpora.ucicorpus.writer->UciWriter(fname)
A:gensim.corpora.ucicorpus.posnow->UciWriter(fname).fout.tell()
A:gensim.corpora.ucicorpus.(max_id, veclen)->UciWriter(fname).write_vector(docno, vector)
A:gensim.corpora.ucicorpus.num_terms->len(id2word)
A:gensim.corpora.ucicorpus.fname_vocab->gensim.utils.smart_extension(fname, '.vocab')
A:gensim.corpora.ucicorpus.self.id2word->dict(enumerate(words))
A:gensim.corpora.ucicorpus.dictionary->Dictionary()
A:gensim.corpora.ucicorpus.dictionary.dfs->defaultdict(int)
A:gensim.corpora.ucicorpus.dictionary.token2id->gensim.utils.revdict(self.id2word)
A:gensim.corpora.ucicorpus.id2word->gensim.utils.dict_from_corpus(corpus)
gensim.corpora.UciCorpus(self,fname,fname_vocab=None)
gensim.corpora.UciCorpus.__iter__(self)
gensim.corpora.UciCorpus.create_dictionary(self)
gensim.corpora.UciCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=10000,metadata=False)
gensim.corpora.ucicorpus.UciCorpus(self,fname,fname_vocab=None)
gensim.corpora.ucicorpus.UciCorpus.__init__(self,fname,fname_vocab=None)
gensim.corpora.ucicorpus.UciCorpus.__iter__(self)
gensim.corpora.ucicorpus.UciCorpus.create_dictionary(self)
gensim.corpora.ucicorpus.UciCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=10000,metadata=False)
gensim.corpora.ucicorpus.UciReader(self,input)
gensim.corpora.ucicorpus.UciReader.__init__(self,input)
gensim.corpora.ucicorpus.UciReader.skip_headers(self,input_file)
gensim.corpora.ucicorpus.UciWriter(MmWriter)
gensim.corpora.ucicorpus.UciWriter.update_headers(self,num_docs,num_terms,num_nnz)
gensim.corpora.ucicorpus.UciWriter.write_corpus(fname,corpus,progress_cnt=1000,index=False)
gensim.corpora.ucicorpus.UciWriter.write_headers(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/csvcorpus.py----------------------------------------
A:gensim.corpora.csvcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.csvcorpus.head->''.join(itertools.islice(f, 5))
A:gensim.corpora.csvcorpus.self.headers->csv.Sniffer().has_header(head)
A:gensim.corpora.csvcorpus.self.dialect->csv.Sniffer().sniff(head)
A:gensim.corpora.csvcorpus.reader->csv.reader(f, self.dialect)
gensim.corpora.csvcorpus.CsvCorpus(self,fname,labels)
gensim.corpora.csvcorpus.CsvCorpus.__init__(self,fname,labels)
gensim.corpora.csvcorpus.CsvCorpus.__iter__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/dictionary.py----------------------------------------
A:gensim.corpora.dictionary.logger->logging.getLogger(__name__)
A:gensim.corpora.dictionary.self.id2token->gensim.utils.revdict(self.token2id)
A:gensim.corpora.dictionary.some_keys->list(itertools.islice(self.token2id.keys(), 5))
A:gensim.corpora.dictionary.counter->defaultdict(int)
A:gensim.corpora.dictionary.missing->sorted((x for x in counter.items() if x[0] not in token2id))
A:gensim.corpora.dictionary.token2id[w]->len(token2id)
A:gensim.corpora.dictionary.result->Dictionary()
A:gensim.corpora.dictionary.no_above_abs->int(no_above * self.num_docs)
A:gensim.corpora.dictionary.most_frequent_ids->sorted(most_frequent_ids, key=self.dfs.get, reverse=True)
A:gensim.corpora.dictionary.bad_ids->set(bad_ids)
A:gensim.corpora.dictionary.good_ids->set(good_ids)
A:gensim.corpora.dictionary.idmap->dict(zip(sorted(self.token2id.values()), range(len(self.token2id))))
A:gensim.corpora.dictionary.new_id->len(self.token2id)
A:gensim.corpora.dictionary.line->gensim.utils.to_unicode(line)
A:gensim.corpora.dictionary.result.num_docs->int(line.strip())
A:gensim.corpora.dictionary.(wordid, word, docfreq)->line[:-1].split('\t')
A:gensim.corpora.dictionary.wordid->int(wordid)
A:gensim.corpora.dictionary.result.dfs[wordid]->int(docfreq)
A:gensim.corpora.dictionary.max_id->max(wordid, max_id)
A:gensim.corpora.dictionary.result.dfs[idx]->Dictionary().dfs.get(idx, 0)
gensim.corpora.Dictionary(self,documents=None,prune_at=2000000)
gensim.corpora.Dictionary.__getitem__(self,tokenid)
gensim.corpora.Dictionary.__iter__(self)
gensim.corpora.Dictionary.__len__(self)
gensim.corpora.Dictionary.__str__(self)
gensim.corpora.Dictionary.add_documents(self,documents,prune_at=2000000)
gensim.corpora.Dictionary.compactify(self)
gensim.corpora.Dictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.Dictionary.doc2idx(self,document,unknown_word_index=-1)
gensim.corpora.Dictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000,keep_tokens=None)
gensim.corpora.Dictionary.filter_n_most_frequent(self,remove_n)
gensim.corpora.Dictionary.filter_tokens(self,bad_ids=None,good_ids=None)
gensim.corpora.Dictionary.from_corpus(corpus,id2word=None)
gensim.corpora.Dictionary.from_documents(documents)
gensim.corpora.Dictionary.iteritems(self)
gensim.corpora.Dictionary.itervalues(self)
gensim.corpora.Dictionary.keys(self)
gensim.corpora.Dictionary.load_from_text(fname)
gensim.corpora.Dictionary.merge_with(self,other)
gensim.corpora.Dictionary.most_common(self,n:Optional[int]=None)->List[Tuple[str, int]]
gensim.corpora.Dictionary.patch_with_special_tokens(self,special_token_dict)
gensim.corpora.Dictionary.save_as_text(self,fname,sort_by_word=True)
gensim.corpora.dictionary.Dictionary(self,documents=None,prune_at=2000000)
gensim.corpora.dictionary.Dictionary.__getitem__(self,tokenid)
gensim.corpora.dictionary.Dictionary.__init__(self,documents=None,prune_at=2000000)
gensim.corpora.dictionary.Dictionary.__iter__(self)
gensim.corpora.dictionary.Dictionary.__len__(self)
gensim.corpora.dictionary.Dictionary.__str__(self)
gensim.corpora.dictionary.Dictionary.add_documents(self,documents,prune_at=2000000)
gensim.corpora.dictionary.Dictionary.compactify(self)
gensim.corpora.dictionary.Dictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.dictionary.Dictionary.doc2idx(self,document,unknown_word_index=-1)
gensim.corpora.dictionary.Dictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000,keep_tokens=None)
gensim.corpora.dictionary.Dictionary.filter_n_most_frequent(self,remove_n)
gensim.corpora.dictionary.Dictionary.filter_tokens(self,bad_ids=None,good_ids=None)
gensim.corpora.dictionary.Dictionary.from_corpus(corpus,id2word=None)
gensim.corpora.dictionary.Dictionary.from_documents(documents)
gensim.corpora.dictionary.Dictionary.iteritems(self)
gensim.corpora.dictionary.Dictionary.itervalues(self)
gensim.corpora.dictionary.Dictionary.keys(self)
gensim.corpora.dictionary.Dictionary.load_from_text(fname)
gensim.corpora.dictionary.Dictionary.merge_with(self,other)
gensim.corpora.dictionary.Dictionary.most_common(self,n:Optional[int]=None)->List[Tuple[str, int]]
gensim.corpora.dictionary.Dictionary.patch_with_special_tokens(self,special_token_dict)
gensim.corpora.dictionary.Dictionary.save_as_text(self,fname,sort_by_word=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/wikicorpus.py----------------------------------------
A:gensim.corpora.wikicorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.wikicorpus.RE_P0->re.compile('<!--.*?-->', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P1->re.compile('<ref([> ].*?)(</ref>|/>)', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P2->re.compile('(\\n\\[\\[[a-z][a-z][\\w-]*:[^:\\]]+\\]\\])+$', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P3->re.compile('{{([^}{]*)}}', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P4->re.compile('{{([^}]*)}}', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P5->re.compile('\\[(\\w+):\\/\\/(.*?)(( (.*?))|())\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P6->re.compile('\\[([^][]*)\\|([^][]*)\\]', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P7->re.compile('\\n\\[\\[[iI]mage(.*?)(\\|.*?)*\\|(.*?)\\]\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P8->re.compile('\\n\\[\\[[fF]ile(.*?)(\\|.*?)*\\|(.*?)\\]\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P9->re.compile('<nowiki([> ].*?)(</nowiki>|/>)', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P10->re.compile('<math([> ].*?)(</math>|/>)', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P11->re.compile('<(.*?)>', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P12->re.compile('(({\\|)|(\\|-(?!\\d))|(\\|}))(.*?)(?=\\n)', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P13->re.compile('(?<=(\\n[ ])|(\\n\\n)|([ ]{2})|(.\\n)|(.\\t))(\\||\\!)([^[\\]\\n]*?\\|)*', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P14->re.compile('\\[\\[Category:[^][]*\\]\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P15->re.compile('\\[\\[([fF]ile:|[iI]mage)[^]]*(\\]\\])', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P16->re.compile('\\[{2}(.*?)\\]{2}', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P17->re.compile('(\\n.{0,4}((bgcolor)|(\\d{0,1}[ ]?colspan)|(rowspan)|(style=)|(class=)|(align=)|(scope=))(.*))|(^.{0,2}((bgcolor)|(\\d{0,1}[ ]?colspan)|(rowspan)|(style=)|(class=)|(align=))(.*))', re.UNICODE)
A:gensim.corpora.wikicorpus._regex_de_excellent->re.compile('.*\\{\\{(Exzellent.*?)\\}\\}[\\s]*', flags=re.DOTALL)
A:gensim.corpora.wikicorpus._regex_de_featured->re.compile('.*\\{\\{(Lesenswert.*?)\\}\\}[\\s]*', flags=re.DOTALL)
A:gensim.corpora.wikicorpus.filtered->filter_wiki(raw, promote_remaining=False, simplify_links=False)
A:gensim.corpora.wikicorpus.interlinks_raw->re.findall(RE_P16, filtered)
A:gensim.corpora.wikicorpus.text->filter_wiki(text)
A:gensim.corpora.wikicorpus.m->re.match('^{(.*?)}', tag)
A:gensim.corpora.wikicorpus.s->s.replace(m, caption, 1).replace(m, caption, 1)
A:gensim.corpora.wikicorpus.elem->next(elems)
A:gensim.corpora.wikicorpus.namespace->get_namespace(elem.tag)
A:gensim.corpora.wikicorpus.result->tokenizer_func(text, token_min_len, token_max_len, lower)
A:gensim.corpora.wikicorpus.processes->max(1, multiprocessing.cpu_count() - 1)
A:gensim.corpora.wikicorpus.self.dictionary->Dictionary(self.get_texts())
A:gensim.corpora.wikicorpus.pool->multiprocessing.Pool(self.processes, init_to_ignore_interrupt)
gensim.corpora.WikiCorpus(self,fname,processes=None,lemmatize=None,dictionary=None,filter_namespaces=('0',),tokenizer_func=tokenize,article_min_tokens=ARTICLE_MIN_WORDS,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True,filter_articles=None)
gensim.corpora.WikiCorpus.get_texts(self)
gensim.corpora.WikiCorpus.input(self)
gensim.corpora.wikicorpus.WikiCorpus(self,fname,processes=None,lemmatize=None,dictionary=None,filter_namespaces=('0',),tokenizer_func=tokenize,article_min_tokens=ARTICLE_MIN_WORDS,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True,filter_articles=None)
gensim.corpora.wikicorpus.WikiCorpus.__init__(self,fname,processes=None,lemmatize=None,dictionary=None,filter_namespaces=('0',),tokenizer_func=tokenize,article_min_tokens=ARTICLE_MIN_WORDS,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True,filter_articles=None)
gensim.corpora.wikicorpus.WikiCorpus.get_texts(self)
gensim.corpora.wikicorpus.WikiCorpus.input(self)
gensim.corpora.wikicorpus._process_article(args)
gensim.corpora.wikicorpus.extract_pages(f,filter_namespaces=False,filter_articles=None)
gensim.corpora.wikicorpus.filter_example(elem,text,*args,**kwargs)
gensim.corpora.wikicorpus.filter_wiki(raw,promote_remaining=True,simplify_links=True)
gensim.corpora.wikicorpus.find_interlinks(raw)
gensim.corpora.wikicorpus.get_namespace(tag)
gensim.corpora.wikicorpus.init_to_ignore_interrupt()
gensim.corpora.wikicorpus.process_article(args,tokenizer_func=tokenize,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)
gensim.corpora.wikicorpus.remove_file(s)
gensim.corpora.wikicorpus.remove_markup(text,promote_remaining=True,simplify_links=True)
gensim.corpora.wikicorpus.remove_template(s)
gensim.corpora.wikicorpus.tokenize(content,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/indexedcorpus.py----------------------------------------
A:gensim.corpora.indexedcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.indexedcorpus.index_fname->gensim.utils.smart_extension(fname, '.index')
A:gensim.corpora.indexedcorpus.self.index->numpy.asarray(self.index)
A:gensim.corpora.indexedcorpus.offsets->serializer.save_corpus(fname, corpus, id2word, **kwargs)
A:gensim.corpora.indexedcorpus.self.length->sum((1 for _ in self))
gensim.corpora.IndexedCorpus(self,fname,index_fname=None)
gensim.corpora.IndexedCorpus.__getitem__(self,docno)
gensim.corpora.IndexedCorpus.__len__(self)
gensim.corpora.IndexedCorpus.serialize(serializer,fname,corpus,id2word=None,index_fname=None,progress_cnt=None,labels=None,metadata=False)
gensim.corpora.indexedcorpus.IndexedCorpus(self,fname,index_fname=None)
gensim.corpora.indexedcorpus.IndexedCorpus.__getitem__(self,docno)
gensim.corpora.indexedcorpus.IndexedCorpus.__init__(self,fname,index_fname=None)
gensim.corpora.indexedcorpus.IndexedCorpus.__len__(self)
gensim.corpora.indexedcorpus.IndexedCorpus.serialize(serializer,fname,corpus,id2word=None,index_fname=None,progress_cnt=None,labels=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/corpora/opinosiscorpus.py----------------------------------------
A:gensim.corpora.opinosiscorpus.path->os.path.join(path, 'summaries-gold')
A:gensim.corpora.opinosiscorpus.dictionary->Dictionary()
A:gensim.corpora.opinosiscorpus.stemmer->PorterStemmer()
A:gensim.corpora.opinosiscorpus.doc->file.read()
gensim.corpora.OpinosisCorpus(self,path)
gensim.corpora.opinosiscorpus.OpinosisCorpus(self,path)
gensim.corpora.opinosiscorpus.OpinosisCorpus.__init__(self,path)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_datatype.py----------------------------------------
A:gensim.test.test_datatype.path->datapath('high_precision.kv.txt')
A:gensim.test.test_datatype.kv->self.load_model(np.float16)
A:gensim.test.test_datatype.binary_path->datapath('high_precision.kv.bin')
A:gensim.test.test_datatype.model1->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(path, datatype=np.float16)
A:gensim.test.test_datatype.model2->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(binary_path, datatype=np.float64, binary=True)
gensim.test.test_datatype.TestDataType(unittest.TestCase)
gensim.test.test_datatype.TestDataType.load_model(self,datatype)
gensim.test.test_datatype.TestDataType.test_high_precision(self)
gensim.test.test_datatype.TestDataType.test_low_precision(self)
gensim.test.test_datatype.TestDataType.test_medium_precision(self)
gensim.test.test_datatype.TestDataType.test_type_conversion(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_matutils.py----------------------------------------
A:gensim.test.test_matutils.x_max->numpy.max(x)
A:gensim.test.test_matutils.x->numpy.log(np.sum(np.exp(x - x_max)))
A:gensim.test.test_matutils.self.random_state->numpy.random.RandomState()
A:gensim.test.test_matutils.input->rs.uniform(-1000, 1000, size=(self.num_topics, 1))
A:gensim.test.test_matutils.known_good->dirichlet_expectation(input_2d)
A:gensim.test.test_matutils.test_values->gensim.matutils.dirichlet_expectation(input_2d)
A:gensim.test.test_matutils.msg->'dirichlet_expectation_2d failed for dtype={}'.format(dtype)
A:gensim.test.test_matutils.input1->rs.uniform(-10000, 10000, size=(self.num_topics,))
A:gensim.test.test_matutils.input2->rs.uniform(-10000, 10000, size=(self.num_topics,))
A:gensim.test.test_matutils.input_1d->rs.uniform(0.01, 10000, size=(self.num_topics,))
A:gensim.test.test_matutils.input_2d->rs.uniform(0.01, 10000, size=(1, self.num_topics))
A:gensim.test.test_matutils.vec->vec.astype(float).astype(float)
A:gensim.test.test_matutils.vec_sum_of_squares->vec.astype(float).astype(float).multiply(vec)
A:gensim.test.test_matutils.sum_vec_squared->numpy.sum(vec ** 2)
A:gensim.test.test_matutils.input_vector->numpy.array([], dtype=np.int32)
A:gensim.test.test_matutils.unit_vector->gensim.matutils.unitvec(input_vector)
A:gensim.test.test_matutils.man_unit_vector->manual_unitvec(input_vector)
A:gensim.test.test_matutils.return_value->gensim.matutils.unitvec(input_vector, return_norm=True)
gensim.test.test_matutils.TestLdaModelInner(unittest.TestCase)
gensim.test.test_matutils.TestLdaModelInner.setUp(self)
gensim.test.test_matutils.TestLdaModelInner.test_dirichlet_expectation(self)
gensim.test.test_matutils.TestLdaModelInner.test_log_sum_exp(self)
gensim.test.test_matutils.TestLdaModelInner.test_mean_absolute_difference(self)
gensim.test.test_matutils.UnitvecTestCase(unittest.TestCase)
gensim.test.test_matutils.UnitvecTestCase.test_dense_npfloat32(self)
gensim.test.test_matutils.UnitvecTestCase.test_dense_npfloat64(self)
gensim.test.test_matutils.UnitvecTestCase.test_dense_npint32(self)
gensim.test.test_matutils.UnitvecTestCase.test_dense_npint64(self)
gensim.test.test_matutils.UnitvecTestCase.test_dense_python_float(self)
gensim.test.test_matutils.UnitvecTestCase.test_dense_python_int(self)
gensim.test.test_matutils.UnitvecTestCase.test_return_norm_zero_vector_gensim_sparse(self)
gensim.test.test_matutils.UnitvecTestCase.test_return_norm_zero_vector_numpy(self)
gensim.test.test_matutils.UnitvecTestCase.test_return_norm_zero_vector_scipy_sparse(self)
gensim.test.test_matutils.UnitvecTestCase.test_sparse_npfloat32(self)
gensim.test.test_matutils.UnitvecTestCase.test_sparse_npfloat64(self)
gensim.test.test_matutils.UnitvecTestCase.test_sparse_npint32(self)
gensim.test.test_matutils.UnitvecTestCase.test_sparse_npint64(self)
gensim.test.test_matutils.UnitvecTestCase.test_sparse_python_float(self)
gensim.test.test_matutils.UnitvecTestCase.test_sparse_python_int(self)
gensim.test.test_matutils.dirichlet_expectation(alpha)
gensim.test.test_matutils.logsumexp(x)
gensim.test.test_matutils.manual_unitvec(vec)
gensim.test.test_matutils.mean_absolute_difference(a,b)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_normmodel.py----------------------------------------
A:gensim.test.test_normmodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_normmodel.self.model_l1->gensim.models.normmodel.NormModel(self.corpus, norm='l1')
A:gensim.test.test_normmodel.self.model_l2->gensim.models.normmodel.NormModel(self.corpus, norm='l2')
A:gensim.test.test_normmodel.normalized->self.model_l2.normalize(ndarray_matrix)
A:gensim.test.test_normmodel.row->numpy.array([0, 0, 1, 2, 2, 2])
A:gensim.test.test_normmodel.col->numpy.array([0, 2, 2, 0, 1, 2])
A:gensim.test.test_normmodel.data->numpy.array([1, 2, 3, 4, 5, 6])
A:gensim.test.test_normmodel.sparse_matrix->csr_matrix((data, (row, col)), shape=(3, 3))
A:gensim.test.test_normmodel.expected->numpy.array([[0.10482848, 0.0, 0.20965697], [0.0, 0.0, 0.31448545], [0.41931393, 0.52414242, 0.6289709]])
A:gensim.test.test_normmodel.ndarray_matrix->numpy.array([[1, 0, 2], [0, 0, 3], [4, 5, 6]])
A:gensim.test.test_normmodel.fname->get_tmpfile('gensim_models.tst.gz')
A:gensim.test.test_normmodel.model->gensim.models.normmodel.NormModel(self.corpus)
A:gensim.test.test_normmodel.model2->gensim.models.normmodel.NormModel.load(fname, mmap=None)
gensim.test.test_normmodel.TestNormModel(unittest.TestCase)
gensim.test.test_normmodel.TestNormModel.setUp(self)
gensim.test.test_normmodel.TestNormModel.test_init(self)
gensim.test.test_normmodel.TestNormModel.test_numpyndarrayInput_l1(self)
gensim.test.test_normmodel.TestNormModel.test_numpyndarrayInput_l2(self)
gensim.test.test_normmodel.TestNormModel.test_persistence(self)
gensim.test.test_normmodel.TestNormModel.test_persistence_compressed(self)
gensim.test.test_normmodel.TestNormModel.test_sparseCSRInput_l1(self)
gensim.test.test_normmodel.TestNormModel.test_sparseCSRInput_l2(self)
gensim.test.test_normmodel.TestNormModel.test_tupleInput_l1(self)
gensim.test.test_normmodel.TestNormModel.test_tupleInput_l2(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_segmentation.py----------------------------------------
A:gensim.test.test_segmentation.actual->gensim.topic_coherence.segmentation.s_one_set(self.topics)
gensim.test.test_segmentation.TestSegmentation(unittest.TestCase)
gensim.test.test_segmentation.TestSegmentation.setUp(self)
gensim.test.test_segmentation.TestSegmentation.test_s_one_one(self)
gensim.test.test_segmentation.TestSegmentation.test_s_one_pre(self)
gensim.test.test_segmentation.TestSegmentation.test_s_one_set(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_translation_matrix.py----------------------------------------
A:gensim.test.test_translation_matrix.self.source_word_vec_file->datapath('EN.1-10.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt')
A:gensim.test.test_translation_matrix.self.target_word_vec_file->datapath('IT.1-10.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt')
A:gensim.test.test_translation_matrix.self.source_word_vec->gensim.models.KeyedVectors.load_word2vec_format(self.source_word_vec_file, binary=False)
A:gensim.test.test_translation_matrix.self.target_word_vec->gensim.models.KeyedVectors.load_word2vec_format(self.target_word_vec_file, binary=False)
A:gensim.test.test_translation_matrix.model->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5])
A:gensim.test.test_translation_matrix.tmpf->get_tmpfile('transmat-en-it.pkl')
A:gensim.test.test_translation_matrix.loaded_model->gensim.models.translation_matrix.TranslationMatrix.load(tmpf)
A:gensim.test.test_translation_matrix.(test_source_word, test_target_word)->zip(*self.test_word_pairs)
A:gensim.test.test_translation_matrix.translated_words->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5]).translate(test_source_word, topn=5, gc=1, sample_num=3, source_lang_vec=self.source_word_vec, target_lang_vec=self.target_word_vec)
A:gensim.test.test_translation_matrix.sentiment_document->namedtuple('SentimentDocument', 'words tags')
A:gensim.test.test_translation_matrix.tokens->gensim.utils.to_unicode(line).split()
A:gensim.test.test_translation_matrix.tags->str(line_no)
A:gensim.test.test_translation_matrix.filename->datapath('alldata-id-10.txt')
A:gensim.test.test_translation_matrix.train_docs->read_sentiment_docs(filename)
A:gensim.test.test_translation_matrix.self.source_doc_vec->Doc2Vec(documents=train_docs[:5], vector_size=8, epochs=50, seed=1)
A:gensim.test.test_translation_matrix.self.target_doc_vec->Doc2Vec(documents=train_docs, vector_size=8, epochs=50, seed=2)
A:gensim.test.test_translation_matrix.transmat->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5]).train(self.train_docs[:5])
A:gensim.test.test_translation_matrix.backmapped_vec->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5]).infer_vector(self.target_doc_vec.dv[self.train_docs[5].tags[0]])
A:gensim.test.test_translation_matrix.d2v_inferred_vector->self.source_doc_vec.infer_vector(self.train_docs[5].words)
A:gensim.test.test_translation_matrix.distance->cosine(backmapped_vec, d2v_inferred_vector)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix(unittest.TestCase)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix.setUp(self)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix.test_infer_vector(self)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix.test_translation_matrix(self)
gensim.test.test_translation_matrix.TestTranslationMatrix(unittest.TestCase)
gensim.test.test_translation_matrix.TestTranslationMatrix.setUp(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_persistence(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_translate_gc(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_translate_nn(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_translation_matrix(self)
gensim.test.test_translation_matrix.read_sentiment_docs(filename)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_similarity_metrics.py----------------------------------------
A:gensim.test.test_similarity_metrics.result->gensim.matutils.jaccard(vec_1, vec_2)
A:gensim.test.test_similarity_metrics.potentialbow->numpy.array([[1, 0.4], [0, 0.2], [2, 0.2]])
A:gensim.test.test_similarity_metrics.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_similarity_metrics.self.model->self.class_(common_corpus, id2word=common_dictionary, num_topics=2, passes=100)
A:gensim.test.test_similarity_metrics.vec_1->numpy.array([6, 1, 2, 3])
A:gensim.test.test_similarity_metrics.result_symmetric->gensim.matutils.hellinger(vec_2, vec_1)
A:gensim.test.test_similarity_metrics.vec_2->csr_matrix([[1, 4], [0, 2], [2, 2]])
A:gensim.test.test_similarity_metrics.model->self.class_(self.corpus, id2word=common_dictionary, num_topics=2, passes=100)
gensim.test.test_similarity_metrics.TestHellinger(unittest.TestCase)
gensim.test.test_similarity_metrics.TestHellinger.setUp(self)
gensim.test.test_similarity_metrics.TestHellinger.test_distributions(self)
gensim.test.test_similarity_metrics.TestHellinger.test_inputs(self)
gensim.test.test_similarity_metrics.TestIsBow(unittest.TestCase)
gensim.test.test_similarity_metrics.TestIsBow.test_None(self)
gensim.test.test_similarity_metrics.TestIsBow.test_bow(self)
gensim.test.test_similarity_metrics.TestJaccard(unittest.TestCase)
gensim.test.test_similarity_metrics.TestJaccard.test_distributions(self)
gensim.test.test_similarity_metrics.TestJaccard.test_inputs(self)
gensim.test.test_similarity_metrics.TestKL(unittest.TestCase)
gensim.test.test_similarity_metrics.TestKL.setUp(self)
gensim.test.test_similarity_metrics.TestKL.test_distributions(self)
gensim.test.test_similarity_metrics.TestKL.test_inputs(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_corpora.py----------------------------------------
A:gensim.test.test_corpora.AZURE->bool(os.environ.get('PIPELINE_WORKSPACE'))
A:gensim.test.test_corpora.fname->datapath('testcorpus.' + self.file_extension.lstrip('.'))
A:gensim.test.test_corpora.corpus->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath)
A:gensim.test.test_corpora.docs->list(corpus)
A:gensim.test.test_corpora.tmpf->get_tmpfile('gensim_corpus.tst')
A:gensim.test.test_corpora.corpus2->self.corpus_class(fname)
A:gensim.test.test_corpora.firstdoc->next(iter(corpus))
A:gensim.test.test_corpora.testdoc->set(((to_unicode(corpus.id2word[x]), y) for (x, y) in firstdoc))
A:gensim.test.test_corpora.firstdoc2->next(iter(corpus))
A:gensim.test.test_corpora.testdoc2->set(((to_unicode(corpus.id2word[x]), y) for (x, y) in firstdoc2))
A:gensim.test.test_corpora.corpus_->TransformedCorpus(DummyTransformer(), corpus)
A:gensim.test.test_corpora.self.corpus->self.corpus_class(datapath('test_mmcorpus_overflow.mm'))
A:gensim.test.test_corpora.file_obj->open(datapath('testcorpus.mm'))
A:gensim.test.test_corpora.it->iter(self.corpus)
A:gensim.test.test_corpora.path->get_tmpfile('svml.corpus')
A:gensim.test.test_corpora.serialized_corpus->self.corpus_class(path)
A:gensim.test.test_corpora.test_file->get_tmpfile('gensim_corpus.tst')
A:gensim.test.test_corpora.tokens->line.split()
A:gensim.test.test_corpora.words_len->int(tokens[0])
A:gensim.test.test_corpora.(word, count)->token.split(':')
A:gensim.test.test_corpora.(doc, (docid, doclang))->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).line2doc(self.CORPUS_LINE)
A:gensim.test.test_corpora.texts->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).get_texts()
A:gensim.test.test_corpora.fpath->os.path.join(dirpath, 'test_file.txt')
A:gensim.test.test_corpora.sample1->list(corpus.sample_texts(5, seed=42))
A:gensim.test.test_corpora.sample2->list(corpus.sample_texts(5, seed=42))
A:gensim.test.test_corpora.self.fname->datapath('testcorpus.' + self.file_extension.lstrip('.'))
A:gensim.test.test_corpora.self.enwiki->datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')
A:gensim.test.test_corpora.first_text->next(corpus.get_texts())
A:gensim.test.test_corpora.all_articles->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).get_texts()
A:gensim.test.test_corpora.bgwiki->datapath('bgwiki-latest-pages-articles-shortened.xml.bz2')
A:gensim.test.test_corpora.wc->self.corpus_class(self.enwiki, processes=1, tokenizer_func=custom_tokenizer, token_max_len=16, token_min_len=1, lower=False)
A:gensim.test.test_corpora.row->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).get_texts()
A:gensim.test.test_corpora.list_tokens->next(row)
A:gensim.test.test_corpora.enwiki_file->datapath('enwiki-table-markup.xml.bz2')
A:gensim.test.test_corpora.wiki->self.corpus_class(self.enwiki)
A:gensim.test.test_corpora.dirpath->tempfile.mkdtemp()
A:gensim.test.test_corpora.next_level->os.path.join(dirpath, 'level_two')
A:gensim.test.test_corpora.(dirpath, next_level)->self.write_two_levels()
A:gensim.test.test_corpora.filenames->list(corpus.iter_filepaths())
A:gensim.test.test_corpora.a_folder->os.path.join(dirpath, 'a_folder')
A:gensim.test.test_corpora.b_folder->os.path.join(dirpath, 'b_folder')
A:gensim.test.test_corpora.c_folder->os.path.join(b_folder, 'c_folder')
A:gensim.test.test_corpora.base_names->sorted((name[len(dirpath) + 1:] for name in filenames))
A:gensim.test.test_corpora.expected->sorted(['0.txt', 'a_folder/1.txt', 'b_folder/2.txt', 'b_folder/3.txt', 'b_folder/c_folder/4.txt'])
gensim.test.test_corpora.CorpusTestCase(unittest.TestCase)
gensim.test.test_corpora.CorpusTestCase.run(self,result=None)
gensim.test.test_corpora.CorpusTestCase.setUp(self)
gensim.test.test_corpora.CorpusTestCase.tearDown(self)
gensim.test.test_corpora.CorpusTestCase.test_empty_input(self)
gensim.test.test_corpora.CorpusTestCase.test_indexing(self)
gensim.test.test_corpora.CorpusTestCase.test_len(self)
gensim.test.test_corpora.CorpusTestCase.test_load(self)
gensim.test.test_corpora.CorpusTestCase.test_save(self)
gensim.test.test_corpora.CorpusTestCase.test_serialize(self)
gensim.test.test_corpora.CorpusTestCase.test_serialize_compressed(self)
gensim.test.test_corpora.CorpusTestCase.test_switch_id2word(self)
gensim.test.test_corpora.DummyTransformer
gensim.test.test_corpora.DummyTransformer.__getitem__(self,bow)
gensim.test.test_corpora.TestBleiCorpus(CorpusTestCase)
gensim.test.test_corpora.TestBleiCorpus.setUp(self)
gensim.test.test_corpora.TestBleiCorpus.test_save_format_for_dtm(self)
gensim.test.test_corpora.TestLowCorpus(CorpusTestCase)
gensim.test.test_corpora.TestLowCorpus.setUp(self)
gensim.test.test_corpora.TestLowCorpus.test_line2doc(self)
gensim.test.test_corpora.TestMalletCorpus(TestLowCorpus)
gensim.test.test_corpora.TestMalletCorpus.setUp(self)
gensim.test.test_corpora.TestMalletCorpus.test_line2doc(self)
gensim.test.test_corpora.TestMalletCorpus.test_load_with_metadata(self)
gensim.test.test_corpora.TestMmCorpusCorrupt(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusCorrupt.setUp(self)
gensim.test.test_corpora.TestMmCorpusCorrupt.test_load(self)
gensim.test.test_corpora.TestMmCorpusCorrupt.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusNoIndex(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusNoIndex.setUp(self)
gensim.test.test_corpora.TestMmCorpusNoIndex.test_load(self)
gensim.test.test_corpora.TestMmCorpusNoIndex.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip.setUp(self)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip.test_load(self)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip.setUp(self)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip.test_load(self)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusOverflow(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusOverflow.setUp(self)
gensim.test.test_corpora.TestMmCorpusOverflow.test_load(self)
gensim.test.test_corpora.TestMmCorpusOverflow.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusWithIndex(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusWithIndex.setUp(self)
gensim.test.test_corpora.TestMmCorpusWithIndex.test_closed_file_object(self)
gensim.test.test_corpora.TestMmCorpusWithIndex.test_load(self)
gensim.test.test_corpora.TestMmCorpusWithIndex.test_serialize_compressed(self)
gensim.test.test_corpora.TestSvmLightCorpus(CorpusTestCase)
gensim.test.test_corpora.TestSvmLightCorpus.setUp(self)
gensim.test.test_corpora.TestSvmLightCorpus.test_serialization(self)
gensim.test.test_corpora.TestTextCorpus(CorpusTestCase)
gensim.test.test_corpora.TestTextCorpus.corpus_from_lines(self,lines)
gensim.test.test_corpora.TestTextCorpus.setUp(self)
gensim.test.test_corpora.TestTextCorpus.test_default_preprocessing(self)
gensim.test.test_corpora.TestTextCorpus.test_indexing(self)
gensim.test.test_corpora.TestTextCorpus.test_load_with_metadata(self)
gensim.test.test_corpora.TestTextCorpus.test_sample_text(self)
gensim.test.test_corpora.TestTextCorpus.test_sample_text_length(self)
gensim.test.test_corpora.TestTextCorpus.test_sample_text_seed(self)
gensim.test.test_corpora.TestTextCorpus.test_save(self)
gensim.test.test_corpora.TestTextCorpus.test_serialize(self)
gensim.test.test_corpora.TestTextCorpus.test_serialize_compressed(self)
gensim.test.test_corpora.TestTextDirectoryCorpus(unittest.TestCase)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_filename_filtering(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_lines_are_documents(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_non_trivial_structure(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_one_level_directory(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_two_level_directory(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.write_docs_to_directory(self,dirpath,*args)
gensim.test.test_corpora.TestTextDirectoryCorpus.write_one_level(self,*args)
gensim.test.test_corpora.TestTextDirectoryCorpus.write_two_levels(self)
gensim.test.test_corpora.TestUciCorpus(CorpusTestCase)
gensim.test.test_corpora.TestUciCorpus.setUp(self)
gensim.test.test_corpora.TestUciCorpus.test_serialize_compressed(self)
gensim.test.test_corpora.TestWikiCorpus(TestTextCorpus)
gensim.test.test_corpora.TestWikiCorpus.setUp(self)
gensim.test.test_corpora.TestWikiCorpus.test_custom_filterfunction(self)
gensim.test.test_corpora.TestWikiCorpus.test_custom_tokenizer(self)
gensim.test.test_corpora.TestWikiCorpus.test_default_preprocessing(self)
gensim.test.test_corpora.TestWikiCorpus.test_empty_input(self)
gensim.test.test_corpora.TestWikiCorpus.test_first_element(self)
gensim.test.test_corpora.TestWikiCorpus.test_get_stream(self)
gensim.test.test_corpora.TestWikiCorpus.test_len(self)
gensim.test.test_corpora.TestWikiCorpus.test_load(self)
gensim.test.test_corpora.TestWikiCorpus.test_load_with_metadata(self)
gensim.test.test_corpora.TestWikiCorpus.test_lower_case_set_false(self)
gensim.test.test_corpora.TestWikiCorpus.test_lower_case_set_true(self)
gensim.test.test_corpora.TestWikiCorpus.test_max_token_len_not_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_max_token_len_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_min_token_len_not_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_min_token_len_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_removed_table_markup(self)
gensim.test.test_corpora.TestWikiCorpus.test_sample_text(self)
gensim.test.test_corpora.TestWikiCorpus.test_sample_text_length(self)
gensim.test.test_corpora.TestWikiCorpus.test_sample_text_seed(self)
gensim.test.test_corpora.TestWikiCorpus.test_unicode_element(self)
gensim.test.test_corpora.custom_tokenizer(content,token_min_len=2,token_max_len=15,lower=True)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_dtm.py----------------------------------------
A:gensim.test.test_dtm.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('dtm_test.mm'))
A:gensim.test.test_dtm.self.id2word->gensim.corpora.Dictionary.load(datapath('dtm_test.dict'))
A:gensim.test.test_dtm.self.dtm_path->os.environ.get('DTM_PATH', None)
A:gensim.test.test_dtm.model->gensim.models.wrappers.DtmModel(self.dtm_path, self.corpus, self.time_slices, num_topics=2, id2word=self.id2word, model='fixed', initialize_lda=True, rng_seed=1)
A:gensim.test.test_dtm.topics->gensim.models.wrappers.DtmModel(self.dtm_path, self.corpus, self.time_slices, num_topics=2, id2word=self.id2word, model='fixed', initialize_lda=True, rng_seed=1).show_topics(num_topics=2, times=2, num_words=10)
A:gensim.test.test_dtm.one_topic->gensim.models.wrappers.DtmModel(self.dtm_path, self.corpus, self.time_slices, num_topics=2, id2word=self.id2word, model='fixed', initialize_lda=True, rng_seed=1).show_topic(topicid=1, time=1, topn=10)
gensim.test.test_dtm.TestDtmModel(unittest.TestCase)
gensim.test.test_dtm.TestDtmModel.setUp(self)
gensim.test.test_dtm.TestDtmModel.test_called_process_error(self)
gensim.test.test_dtm.TestDtmModel.test_dim(self)
gensim.test.test_dtm.TestDtmModel.test_dtm(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_lee.py----------------------------------------
A:gensim.test.test_lee.pre_path->os.path.join(os.path.dirname(__file__), 'test_data')
A:gensim.test.test_lee.latin1->partial(utils.to_unicode, encoding='latin1')
A:gensim.test.test_lee.bg_corpus->preprocess_documents((latin1(line) for line in f))
A:gensim.test.test_lee.corpus->preprocess_documents((latin1(line) for line in f))
A:gensim.test.test_lee.sim_matrix->numpy.loadtxt(os.path.join(pre_path, sim_file))
A:gensim.test.test_lee.dictionary->gensim.corpora.Dictionary(bg_corpus)
A:gensim.test.test_lee.log_ent->gensim.models.LogEntropyModel(bg_corpus)
A:gensim.test.test_lee.lsi->gensim.models.LsiModel(bg_corpus_ent, id2word=dictionary, num_topics=200)
A:gensim.test.test_lee.res->numpy.zeros((len(corpus), len(corpus)))
A:gensim.test.test_lee.res[i, j]->gensim.matutils.cossim(par1, par2)
gensim.test.test_lee.TestLeeTest(unittest.TestCase)
gensim.test.test_lee.TestLeeTest.setUp(self)
gensim.test.test_lee.TestLeeTest.test_corpus(self)
gensim.test.test_lee.TestLeeTest.test_lee(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_indirect_confirmation.py----------------------------------------
A:gensim.test.test_indirect_confirmation.self.dictionary->Dictionary()
A:gensim.test.test_indirect_confirmation.accumulator->gensim.topic_coherence.text_analysis.WordVectorsAccumulator({1, 2}, self.dictionary)
A:gensim.test.test_indirect_confirmation.obtained->gensim.topic_coherence.indirect_confirmation_measure.cosine_similarity(self.segmentation, accumulator, self.topics, self.measure, self.gamma)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation(unittest.TestCase)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation.setUp(self)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation.test_cosine_similarity(self)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation.test_word2vec_similarity(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_ldaseqmodel.py----------------------------------------
A:gensim.test.test_ldaseqmodel.sstats->numpy.loadtxt(datapath('DTM/sstats_test.txt'))
A:gensim.test.test_ldaseqmodel.dictionary->Dictionary(texts)
A:gensim.test.test_ldaseqmodel.self.ldaseq->gensim.models.ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, num_topics=2, time_slice=[10, 10, 11], initialize='own', sstats=sstats, passes=2, lda_inference_max_iter=10, em_min_iter=1, em_max_iter=4)
A:gensim.test.test_ldaseqmodel.topics->self.ldaseq.print_topics(0)
A:gensim.test.test_ldaseqmodel.doc_topic->self.ldaseq.doc_topics(0)
A:gensim.test.test_ldaseqmodel.ldaseq_3_0_1_fname->datapath('DTM/ldaseq_3_0_1_model')
A:gensim.test.test_ldaseqmodel.model->gensim.models.ldaseqmodel.LdaSeqModel.load(ldaseq_3_0_1_fname)
gensim.test.test_ldaseqmodel.TestLdaSeq(unittest.TestCase)
gensim.test.test_ldaseqmodel.TestLdaSeq.setUp(self)
gensim.test.test_ldaseqmodel.TestLdaSeq.test_doc_topic(self)
gensim.test.test_ldaseqmodel.TestLdaSeq.test_dtype_backward_compatibility(self)
gensim.test.test_ldaseqmodel.TestLdaSeq.test_topic_word(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_doc2vec.py----------------------------------------
A:gensim.test.test_doc2vec.list_corpus->list(DocsLeeCorpus())
A:gensim.test.test_doc2vec.tmpf->get_tmpfile('gensim_doc2vec_resave.tst')
A:gensim.test.test_doc2vec.model->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, vector_size=5)
A:gensim.test.test_doc2vec.test_doc_word->get_tmpfile('gensim_doc2vec.dw')
A:gensim.test.test_doc2vec.binary_model_dv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(test_word, binary=True)
A:gensim.test.test_doc2vec.test_doc->get_tmpfile('gensim_doc2vec.d')
A:gensim.test.test_doc2vec.test_word->get_tmpfile('gensim_doc2vec.w')
A:gensim.test.test_doc2vec.saved_models_dir->datapath('old_d2v_models/d2v_{}.mdl')
A:gensim.test.test_doc2vec.doc0_inferred->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, vector_size=5).infer_vector(list(DocsLeeCorpus())[0].words)
A:gensim.test.test_doc2vec.sims_to_infer->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, vector_size=5).dv.most_similar([doc0_inferred], topn=len(model.dv))
A:gensim.test.test_doc2vec.loaded_model->gensim.models.doc2vec.Doc2Vec.load(tmpf)
A:gensim.test.test_doc2vec.(offsets, start_doctags)->gensim.models.doc2vec.Doc2Vec._get_offsets_and_start_doctags_for_corpusfile(tmpf, 5)
A:gensim.test.test_doc2vec.ls->CythonLineSentence(tmpf, offset)
A:gensim.test.test_doc2vec.sentence->CythonLineSentence(tmpf, offset).read_sentence()
A:gensim.test.test_doc2vec.corpus->gensim.utils.RepeatCorpus(DocsLeeCorpus(), 6000)
A:gensim.test.test_doc2vec.fire2->numpy.int64(8)
A:gensim.test.test_doc2vec.f_rank->sims_ids.index(fire1)
A:gensim.test.test_doc2vec.sims->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, vector_size=5).dv.most_similar(fire1, topn=len(model.dv))
A:gensim.test.test_doc2vec.f2_rank->[docid for (docid, sim) in sims].index(fire2)
A:gensim.test.test_doc2vec.sims2->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, vector_size=5).dv.most_similar(positive=[doc0_vec], topn=21)
A:gensim.test.test_doc2vec.clip_sims->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, vector_size=5).dv.most_similar(fire1, clip_start=len(model.dv) // 2, clip_end=len(model.dv) * 2 // 3)
A:gensim.test.test_doc2vec.loaded->gensim.models.doc2vec.Doc2Vec.load(tmpf)
A:gensim.test.test_doc2vec.model2->gensim.models.doc2vec.Doc2Vec(DocsLeeCorpus(), dm=1, dm_concat=1, vector_size=24, window=4, hs=1, negative=3, seed=42, workers=1)
A:gensim.test.test_doc2vec.self.dv->ConcatenatedDocvecs([model.dv for model in models])
A:gensim.test.test_doc2vec.SentimentDocument->namedtuple('SentimentDocument', 'words tags split sentiment')
A:gensim.test.test_doc2vec.(id, text)->sentence_line.split('\t')
A:gensim.test.test_doc2vec.id->int(id)
A:gensim.test.test_doc2vec.text->text.replace(junk, fix).replace(junk, fix)
A:gensim.test.test_doc2vec.(id2, split_i)->split_line.split(',')
A:gensim.test.test_doc2vec.(text, id)->line.split('|')
A:gensim.test.test_doc2vec.phrases[int(id)]->text.replace(junk, fix).replace(junk, fix).rstrip()
A:gensim.test.test_doc2vec.SentimentPhrase->namedtuple('SentimentPhrase', SentimentDocument._fields + ('sentence_id',))
A:gensim.test.test_doc2vec.(id, sentiment)->line.split('|')
A:gensim.test.test_doc2vec.sentiment->float(sentiment)
A:gensim.test.test_doc2vec.words->text.replace(junk, fix).replace(junk, fix).split()
A:gensim.test.test_doc2vec.(sentence_id, split_i)->info_by_sentence.get(text, (None, 0))
A:gensim.test.test_doc2vec.phrases[id]->SentimentPhrase(words, [id], split, sentiment, sentence_id)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec(self,models)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.__getitem__(self,token)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.__init__(self,models)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.__str__(self)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.epochs(self)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.infer_vector(self,document,alpha=None,min_alpha=None,epochs=None)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.train(self,*ignore_args,**ignore_kwargs)
gensim.test.test_doc2vec.ConcatenatedDocvecs(self,models)
gensim.test.test_doc2vec.ConcatenatedDocvecs.__getitem__(self,token)
gensim.test.test_doc2vec.ConcatenatedDocvecs.__init__(self,models)
gensim.test.test_doc2vec.DocsLeeCorpus(self,string_tags=False,unicode_tags=False)
gensim.test.test_doc2vec.DocsLeeCorpus.__init__(self,string_tags=False,unicode_tags=False)
gensim.test.test_doc2vec.DocsLeeCorpus.__iter__(self)
gensim.test.test_doc2vec.DocsLeeCorpus._tag(self,i)
gensim.test.test_doc2vec.TestDoc2VecModel(unittest.TestCase)
gensim.test.test_doc2vec.TestDoc2VecModel._check_old_version(self,old_version)
gensim.test.test_doc2vec.TestDoc2VecModel.model_sanity(self,model,keep_training=True)
gensim.test.test_doc2vec.TestDoc2VecModel.models_equal(self,model,model2)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_testLoadOldModel(self)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_testLoadOldModelSeparates(self)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_test_load_old_models_1_x(self)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_test_load_old_models_2_x(self)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_test_load_old_models_post_3_2(self)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_test_load_old_models_pre_1_0(self)
gensim.test.test_doc2vec.TestDoc2VecModel.obsolete_test_load_old_models_pre_3_3(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_build_vocab_warning(self,loglines)
gensim.test.test_doc2vec.TestDoc2VecModel.test_cython_linesentence_readline_after_getting_offsets(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_fixedwindowsize(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_fixedwindowsize_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_hs_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_neg_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_deterministic_dmc(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_deterministic_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_deterministic_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmc_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmc_hs_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmc_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmc_neg_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_fixedwindowsize(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_fixedwindowsize_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_hs_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_neg_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dms_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dms_hs_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dms_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dms_neg_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_doc2vec_train_parameters(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_empty_errors(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_get_offsets_and_start_doctags(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_get_offsets_and_start_doctags_win(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_int_doctags(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_load_mmap(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_load_on_class_error(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_missing_string_doctag(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_mixed_tag_types(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_parallel(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_persistence(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_persistence_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_persistence_word2vec_format(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_similarity_unseen_docs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_string_doctags(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_train_warning(self,loglines)
gensim.test.test_doc2vec.TestDoc2VecModel.test_training(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_training_fromfile(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_unicode_in_doctag(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_word_vec_non_writeable(self)
gensim.test.test_doc2vec.load_on_instance()
gensim.test.test_doc2vec.read_su_sentiment_rotten_tomatoes(dirname,lowercase=True)
gensim.test.test_doc2vec.save_lee_corpus_as_line_sentence(corpus_file)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_ensemblelda.py----------------------------------------
A:gensim.test.test_ensemblelda.sum_over_terms->self.get_elda().ttda.sum(axis=1)
A:gensim.test.test_ensemblelda.expected_sum_over_terms->numpy.ones(len(elda.ttda)).astype(np.float32)
A:gensim.test.test_ensemblelda.elda->self.get_elda()
A:gensim.test.test_ensemblelda.loaded_elda->gensim.models.EnsembleLda.load(fname)
A:gensim.test.test_ensemblelda.loaded_cluster_model_results->deepcopy(elda.cluster_model.results)
A:gensim.test.test_ensemblelda.loaded_valid_clusters->deepcopy(elda.valid_clusters)
A:gensim.test.test_ensemblelda.loaded_stable_topics->deepcopy(elda.get_topics())
A:gensim.test.test_ensemblelda.elda_mem_unfriendly->EnsembleLda(corpus=common_corpus, id2word=common_dictionary, num_topics=num_new_topics, passes=1, num_models=num_new_models, iterations=1, random_state=RANDOM_STATE, topic_model_class=LdaMulticore, workers=3, ensemble_workers=2, memory_friendly_ttda=False)
A:gensim.test.test_ensemblelda.gensim_model->self.get_elda().generate_gensim_representation()
A:gensim.test.test_ensemblelda.topics->loaded_elda_mem_unfriendly.generate_gensim_representation().get_topics()
A:gensim.test.test_ensemblelda.fname->get_tmpfile('gensim_models_ensemblelda')
A:gensim.test.test_ensemblelda.loaded_elda_mem_unfriendly->gensim.models.EnsembleLda.load(fname)
A:gensim.test.test_ensemblelda.loaded_elda_representation->gensim.models.EnsembleLda.load(fname).generate_gensim_representation()
A:gensim.test.test_ensemblelda.loaded_elda_mem_unfriendly_representation->gensim.models.EnsembleLda.load(fname).generate_gensim_representation()
A:gensim.test.test_ensemblelda.elda_multiprocessing->EnsembleLda(corpus=common_corpus, id2word=common_dictionary, topic_model_class=LdaModel, num_topics=NUM_TOPICS, passes=PASSES, num_models=NUM_MODELS, random_state=random_state, ensemble_workers=workers, distance_workers=workers)
A:gensim.test.test_ensemblelda.elda_multiprocessing_mem_unfriendly->EnsembleLda(corpus=common_corpus, id2word=common_dictionary, topic_model_class=LdaModel, num_topics=NUM_TOPICS, passes=PASSES, num_models=NUM_MODELS, random_state=random_state, ensemble_workers=workers, distance_workers=workers, memory_friendly_ttda=False)
A:gensim.test.test_ensemblelda.ensemble->EnsembleLda(id2word=common_dictionary, num_models=0)
A:gensim.test.test_ensemblelda.loaded_ensemble->gensim.models.EnsembleLda.load(fname)
A:gensim.test.test_ensemblelda.base_elda->self.get_elda()
A:gensim.test.test_ensemblelda.cumulative_elda->EnsembleLda(corpus=common_corpus, id2word=common_dictionary, num_topics=num_new_topics, passes=1, num_models=num_new_models, iterations=1, random_state=RANDOM_STATE, topic_model_class=LdaMulticore, workers=3, ensemble_workers=2)
A:gensim.test.test_ensemblelda.num_topics_before_add_model->len(elda_mem_unfriendly.tms)
A:gensim.test.test_ensemblelda.base_elda_mem_unfriendly->self.get_elda_mem_unfriendly()
A:gensim.test.test_ensemblelda.elda_1->EnsembleLda(corpus=common_corpus, id2word=common_dictionary, num_topics=num_new_topics, passes=10, num_models=num_new_models, iterations=30, random_state=random_state, topic_model_class='lda', distance_workers=4)
A:gensim.test.test_ensemblelda.elda_mem_unfriendly_1->EnsembleLda(corpus=common_corpus, id2word=common_dictionary, num_topics=num_new_topics, passes=10, num_models=num_new_models, iterations=30, random_state=random_state, topic_model_class=LdaModel, distance_workers=4, memory_friendly_ttda=False)
A:gensim.test.test_ensemblelda.elda_2->self.get_elda()
A:gensim.test.test_ensemblelda.elda_mem_unfriendly_2->self.get_elda_mem_unfriendly()
A:gensim.test.test_ensemblelda.max_id->numpy.argmax(elda.get_topics()[0, :])
gensim.test.test_ensemblelda.TestEnsembleLda(unittest.TestCase)
gensim.test.test_ensemblelda.TestEnsembleLda.assert_clustering_results_equal(self,clustering_results_1,clustering_results_2)
gensim.test.test_ensemblelda.TestEnsembleLda.assert_ttda_is_valid(self,elda)
gensim.test.test_ensemblelda.TestEnsembleLda.get_elda(self)
gensim.test.test_ensemblelda.TestEnsembleLda.get_elda_mem_unfriendly(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_add_and_recluster(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_add_models(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_add_models_to_empty(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_backwards_compatibility_with_persisted_model(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_elda(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_generate_gensim_representation(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_inference(self,elda=None)
gensim.test.test_ensemblelda.TestEnsembleLda.test_mem_unfriendly(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_multiprocessing(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_not_trained_given_no_corpus(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_not_trained_given_zero_iterations(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_not_trained_given_zero_models(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_not_trained_given_zero_passes(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_persisting(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_recluster(self)
gensim.test.test_ensemblelda.TestEnsembleLda.test_recluster_does_nothing_when_stable_topics_already_found(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_probability_estimation.py----------------------------------------
A:gensim.test.test_probability_estimation.accumulator->gensim.topic_coherence.probability_estimation.p_boolean_sliding_window(self.texts, self.segmented_topics, self.dictionary, 2)
A:gensim.test.test_probability_estimation.obtained->gensim.topic_coherence.probability_estimation.p_boolean_sliding_window(self.texts, self.segmented_topics, self.dictionary, 2).index_to_dict()
A:gensim.test.test_probability_estimation.self.dictionary->Dictionary(self.texts)
gensim.test.test_probability_estimation.BaseTestCases
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase(unittest.TestCase)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.build_segmented_topics(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.setUp(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.setup_dictionary(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.test_p_boolean_document(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.test_p_boolean_sliding_window(self)
gensim.test.test_probability_estimation.TestProbabilityEstimation(BaseTestCases.ProbabilityEstimationBase)
gensim.test.test_probability_estimation.TestProbabilityEstimation.setup_dictionary(self)
gensim.test.test_probability_estimation.TestProbabilityEstimationWithNormalDictionary(BaseTestCases.ProbabilityEstimationBase)
gensim.test.test_probability_estimation.TestProbabilityEstimationWithNormalDictionary.setup_dictionary(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/utils.py----------------------------------------
A:gensim.test.utils.module_path->os.path.dirname(__file__)
A:gensim.test.utils.tmp->tempfile.mkdtemp()
A:gensim.test.utils.common_dictionary->Dictionary(common_texts)
A:gensim.test.utils.lee_corpus_list->list(LeeCorpus())
gensim.test.utils.LeeCorpus
gensim.test.utils.LeeCorpus.__iter__(self)
gensim.test.utils.datapath(fname)
gensim.test.utils.get_tmpfile(suffix)
gensim.test.utils.temporary_file(name='')


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_word2vec.py----------------------------------------
A:gensim.test.test_word2vec.tmpf->get_tmpfile('gensim_word2vec.tst')
A:gensim.test.test_word2vec.model->gensim.models.word2vec.Word2Vec(sentences, min_count=1)
A:gensim.test.test_word2vec.freq_dict_orig->freq_dict.copy()
A:gensim.test.test_word2vec.model_hs->gensim.models.word2vec.Word2Vec(corpus_file=corpus_file, vector_size=10, min_count=0, seed=42, hs=1, negative=0)
A:gensim.test.test_word2vec.model_neg->gensim.models.word2vec.Word2Vec.load(tmpf)
A:gensim.test.test_word2vec.reported_values->gensim.models.word2vec.Word2Vec(sentences, min_count=1).prepare_vocab()
A:gensim.test.test_word2vec.orig0->numpy.copy(model.wv.vectors[0])
A:gensim.test.test_word2vec.sim->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.n_similarity(['war'], ['terrorism'])
A:gensim.test.test_word2vec.loaded_wv->gensim.models.keyedvectors.KeyedVectors.load(tmpf)
A:gensim.test.test_word2vec.binary_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_word2vec.norm_only_model->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=False)
A:gensim.test.test_word2vec.limited_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True, limit=3)
A:gensim.test.test_word2vec.half_precision_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True, datatype=np.float16)
A:gensim.test.test_word2vec.kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_word2vec.binary_model->gensim.models.word2vec.Word2Vec()
A:gensim.test.test_word2vec.tfile->get_tmpfile('gensim_word2vec.tst')
A:gensim.test.test_word2vec.f->open(tfile, 'r+b')
A:gensim.test.test_word2vec.text_model->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=False)
A:gensim.test.test_word2vec.testvocab->get_tmpfile('gensim_word2vec.vocab')
A:gensim.test.test_word2vec.binary_model_with_vocab_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, testvocab, binary=True)
A:gensim.test.test_word2vec.kv_binary_model_with_vocab->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, testvocab, binary=True)
A:gensim.test.test_word2vec.corpus->gensim.utils.RepeatCorpus(LeeCorpus(), 10000)
A:gensim.test.test_word2vec.total_words->sum((len(sentence) for sentence in corpus))
A:gensim.test.test_word2vec.sims->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.most_similar(origin_word, topn=len(model.wv))
A:gensim.test.test_word2vec.graph_vector->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.get_vector('graph', norm=True)
A:gensim.test.test_word2vec.sims2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.most_similar(positive=[graph_vector], topn=11)
A:gensim.test.test_word2vec.model2->gensim.models.word2vec.Word2Vec(sentences, min_count=2, seed=42, workers=1)
A:gensim.test.test_word2vec.scores->gensim.models.word2vec.Word2Vec(sentences, min_count=1).score(sentences, len(sentences))
A:gensim.test.test_word2vec.locked0->numpy.copy(model.wv.vectors[0])
A:gensim.test.test_word2vec.unlocked1->numpy.copy(model.wv.vectors[1])
A:gensim.test.test_word2vec.model.wv.vectors_lockf->numpy.ones(len(model.wv), dtype=np.float32)
A:gensim.test.test_word2vec.(score, sections)->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.evaluate_word_analogies(datapath('questions-words.txt'))
A:gensim.test.test_word2vec.correlation->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.evaluate_word_pairs(datapath('wordsim353.tsv'))
A:gensim.test.test_word2vec.tmpfile->get_tmpfile('gensim_word2vec.tst')
A:gensim.test.test_word2vec.t_rank->[word for (word, score) in sims].index(expected_word)
A:gensim.test.test_word2vec.reps->int(os.environ['BULK_TEST_REPS'])
A:gensim.test.test_word2vec.method_name->os.environ.get('METHOD_NAME', 'test_cbow_hs')
A:gensim.test.test_word2vec.method_fn->getattr(self, method_name)
A:gensim.test.test_word2vec.wordsims->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.similar_by_word('graph', topn=10)
A:gensim.test.test_word2vec.wordsims2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.most_similar(positive='graph', topn=10)
A:gensim.test.test_word2vec.vectorsims->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.similar_by_vector(model.wv['graph'], topn=10)
A:gensim.test.test_word2vec.vectorsims2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.most_similar([model.wv['graph']], topn=10)
A:gensim.test.test_word2vec.neighbor_rank->[word for (word, sim) in sims].index(expected_neighbor)
A:gensim.test.test_word2vec.model_with_neg->gensim.models.word2vec.Word2Vec(sentences, min_count=1)
A:gensim.test.test_word2vec.predictions_with_neg->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(['system', 'human'], topn=5)
A:gensim.test.test_word2vec.predictions_out_of_vocab->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(['some', 'random', 'words'], topn=5)
A:gensim.test.test_word2vec.kv_model_with_neg->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_word2vec.binary_model_with_neg->gensim.models.word2vec.Word2Vec()
A:gensim.test.test_word2vec.model_without_neg->gensim.models.word2vec.Word2Vec(sentences, min_count=1, negative=0)
A:gensim.test.test_word2vec.prediction_from_str->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(str_context, topn=5)
A:gensim.test.test_word2vec.prediction_from_mixed->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(mixed_context, topn=5)
A:gensim.test.test_word2vec.prediction_from_idx->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(idx_context, topn=5)
A:gensim.test.test_word2vec.saved_models_dir->datapath('old_w2v_models/w2v_{}.mdl')
A:gensim.test.test_word2vec.loaded_model->gensim.models.word2vec.Word2Vec.load(tmpf)
A:gensim.test.test_word2vec.other_model->gensim.models.word2vec.Word2Vec(new_sentences, min_count=1)
A:gensim.test.test_word2vec.training_loss_val->gensim.models.word2vec.Word2Vec(sentences, min_count=1).get_latest_training_loss()
A:gensim.test.test_word2vec.distance->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.wmdistance(sentence, sentence)
A:gensim.test.test_word2vec.distance1->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.wmdistance(sentence1, sentence2)
A:gensim.test.test_word2vec.distance2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.wmdistance(sentence2, sentence1)
A:gensim.test.test_word2vec.sentences->gensim.models.word2vec.PathLineSentences(test_file)
A:gensim.test.test_word2vec.test_file->os.path.join(datapath('PathLineSentences'), '1.txt')
gensim.test.test_word2vec.TestWMD(unittest.TestCase)
gensim.test.test_word2vec.TestWMD.test_identical_sentences(self)
gensim.test.test_word2vec.TestWMD.test_nonzero(self)
gensim.test.test_word2vec.TestWMD.test_symmetry(self)
gensim.test.test_word2vec.TestWord2VecModel(unittest.TestCase)
gensim.test.test_word2vec.TestWord2VecModel._check_old_version(self,old_version)
gensim.test.test_word2vec.TestWord2VecModel.model_sanity(self,model,train=True,with_corpus_file=False,ranks=None)
gensim.test.test_word2vec.TestWord2VecModel.models_equal(self,model,model2)
gensim.test.test_word2vec.TestWord2VecModel.obsolete_testLoadPreKeyedVectorModel(self)
gensim.test.test_word2vec.TestWord2VecModel.obsolete_test_load_old_models_pre_1_0(self)
gensim.test.test_word2vec.TestWord2VecModel.onlineSanity(self,model,trained_model=False)
gensim.test.test_word2vec.TestWord2VecModel.test_build_vocab_from_freq(self)
gensim.test.test_word2vec.TestWord2VecModel.test_build_vocab_warning(self,loglines)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_fixedwindowsize(self,ranks=None)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_fixedwindowsize_fromfile(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_hs(self,ranks=None)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_hs_fromfile(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_hs_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_neg(self,ranks=None)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_neg_fromfile(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_neg_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_compute_training_loss(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cosmul(self)
gensim.test.test_word2vec.TestWord2VecModel.test_evaluate_word_analogies(self)
gensim.test.test_word2vec.TestWord2VecModel.test_evaluate_word_pairs(self)
gensim.test.test_word2vec.TestWord2VecModel.test_evaluate_word_pairs_from_file(self)
gensim.test.test_word2vec.TestWord2VecModel.test_lambda_rule(self)
gensim.test.test_word2vec.TestWord2VecModel.test_large_mmap(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_old_model(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_old_model_separates(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_old_models_1_x(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_old_models_2_x(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_old_models_3_x(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_on_class_error(self)
gensim.test.test_word2vec.TestWord2VecModel.test_load_pre_keyed_vector_model_c_format(self)
gensim.test.test_word2vec.TestWord2VecModel.test_locking(self)
gensim.test.test_word2vec.TestWord2VecModel.test_max_final_vocab(self)
gensim.test.test_word2vec.TestWord2VecModel.test_method_in_bulk(self)
gensim.test.test_word2vec.TestWord2VecModel.test_no_training_c_format(self)
gensim.test.test_word2vec.TestWord2VecModel.test_online_learning(self)
gensim.test.test_word2vec.TestWord2VecModel.test_online_learning_after_save(self)
gensim.test.test_word2vec.TestWord2VecModel.test_online_learning_after_save_from_file(self)
gensim.test.test_word2vec.TestWord2VecModel.test_online_learning_from_file(self)
gensim.test.test_word2vec.TestWord2VecModel.test_parallel(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_from_file(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_keyed_vectors_format_with_vocab(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_with_constructor_rule(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_word2vec_format(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_word2vec_format_combination_with_standard_persistence(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_word2vec_format_non_binary(self)
gensim.test.test_word2vec.TestWord2VecModel.test_persistence_word2vec_format_with_vocab(self)
gensim.test.test_word2vec.TestWord2VecModel.test_predict_output_word(self)
gensim.test.test_word2vec.TestWord2VecModel.test_prune_vocab(self)
gensim.test.test_word2vec.TestWord2VecModel.test_r_n_g(self)
gensim.test.test_word2vec.TestWord2VecModel.test_reset_from(self)
gensim.test.test_word2vec.TestWord2VecModel.test_rule(self)
gensim.test.test_word2vec.TestWord2VecModel.test_rule_with_min_count(self)
gensim.test.test_word2vec.TestWord2VecModel.test_scoring(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sentences_should_not_be_a_generator(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_fixedwindowsize(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_fixedwindowsize_fromfile(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_hs(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_hs_fromfile(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_hs_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_neg(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_neg_fromfile(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_neg_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_similar_by(self)
gensim.test.test_word2vec.TestWord2VecModel.test_similarities(self)
gensim.test.test_word2vec.TestWord2VecModel.test_too_short_binary_word2vec_format(self)
gensim.test.test_word2vec.TestWord2VecModel.test_too_short_text_word2vec_format(self)
gensim.test.test_word2vec.TestWord2VecModel.test_total_word_count(self)
gensim.test.test_word2vec.TestWord2VecModel.test_train_warning(self,loglines)
gensim.test.test_word2vec.TestWord2VecModel.test_train_with_explicit_param(self)
gensim.test.test_word2vec.TestWord2VecModel.test_training(self)
gensim.test.test_word2vec.TestWord2VecModel.test_training_cbow(self)
gensim.test.test_word2vec.TestWord2VecModel.test_training_cbow_negative(self)
gensim.test.test_word2vec.TestWord2VecModel.test_training_from_file(self)
gensim.test.test_word2vec.TestWord2VecModel.test_training_sg_negative(self)
gensim.test.test_word2vec.TestWord2VecModel.test_vocab(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators(unittest.TestCase)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.test_cython_line_sentence_works_with_filename(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.test_line_sentence_works_with_compressed_file(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.test_line_sentence_works_with_filename(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.test_line_sentence_works_with_normal_file(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.test_path_line_sentences(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.test_path_line_sentences_one_file(self)
gensim.test.test_word2vec._rule(word,count,min_count)
gensim.test.test_word2vec.load_on_instance()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_phrases.py----------------------------------------
A:gensim.test.test_phrases.phrase->'_'.join([word_a] + in_between + [word_b])
A:gensim.test.test_phrases.score->self.scores.get(phrase, -1)
A:gensim.test.test_phrases.connector_words->frozenset({'of'})
A:gensim.test.test_phrases.self.bigram->FrozenPhrases(bigram_phrases)
A:gensim.test.test_phrases.self.bigram_default->FrozenPhrases(bigram_default_phrases)
A:gensim.test.test_phrases.bigram_phrases->Phrases(self.sentences, min_count=1, threshold=1, connector_words=self.connector_words)
A:gensim.test.test_phrases.bigram_phraser->FrozenPhrases(bigram_phrases)
A:gensim.test.test_phrases.trigram_phrases->Phrases(bigram_phraser[self.sentences])
A:gensim.test.test_phrases.trigram_phraser->FrozenPhrases(trigram_phrases)
A:gensim.test.test_phrases.bigram->Phrases(self.sentences, min_count=1, threshold=1, connector_words=self.connector_words)
A:gensim.test.test_phrases.trigram->Phrases(bigram[self.sentences], min_count=1, threshold=1, delimiter=' ')
A:gensim.test.test_phrases.seen_bigrams->set(bigram.export_phrases().keys())
A:gensim.test.test_phrases.seen_trigrams->set(trigram.export_phrases().keys())
A:gensim.test.test_phrases.seen_scores->list(bigram.find_phrases(test_sentences).values())
A:gensim.test.test_phrases.phrased_sentence->next(bigram[test_sentences].__iter__())
A:gensim.test.test_phrases.bigram_loaded->gensim.models.phrases.FrozenPhrases.load(datapath('phraser-no-common-terms.pkl'))
A:gensim.test.test_phrases.phraser->gensim.models.phrases.FrozenPhrases.load(datapath('phraser-3.6.0.model'))
A:gensim.test.test_phrases.bigram_default_phrases->Phrases(self.sentences, connector_words=self.connector_words)
A:gensim.test.test_phrases.min_count->float(bigram.min_count)
A:gensim.test.test_phrases.len_vocab->float(len(bigram.vocab))
A:gensim.test.test_phrases.graph->float(bigram.vocab['graph'])
A:gensim.test.test_phrases.data->float(bigram.vocab['data'])
A:gensim.test.test_phrases.data_and_graph->float(bigram.vocab['data_and_graph'])
A:gensim.test.test_phrases.human->float(bigram.vocab['human'])
A:gensim.test.test_phrases.interface->float(bigram.vocab['interface'])
A:gensim.test.test_phrases.human_interface->float(bigram.vocab['human_interface'])
A:gensim.test.test_phrases.phrases->gensim.models.phrases.Phrases.load(datapath('phrases-3.6.0.model'))
gensim.test.test_phrases.CommonTermsPhrasesData
gensim.test.test_phrases.CommonTermsPhrasesData.gen_sentences(self)
gensim.test.test_phrases.PhrasesCommon(PhrasesData)
gensim.test.test_phrases.PhrasesCommon.setUp(self)
gensim.test.test_phrases.PhrasesCommon.test_bigram_construction(self)
gensim.test.test_phrases.PhrasesCommon.test_bigram_construction_from_array(self)
gensim.test.test_phrases.PhrasesCommon.test_bigram_construction_from_generator(self)
gensim.test.test_phrases.PhrasesCommon.test_empty_inputs_on_bigram_construction(self)
gensim.test.test_phrases.PhrasesCommon.test_empty_phrasified_sentences_iterator(self)
gensim.test.test_phrases.PhrasesCommon.test_sentence_generation(self)
gensim.test.test_phrases.PhrasesCommon.test_sentence_generation_with_generator(self)
gensim.test.test_phrases.PhrasesData
gensim.test.test_phrases.PhrasesData.gen_sentences(self)
gensim.test.test_phrases.TestFrozenPhrasesModel(PhrasesCommon,unittest.TestCase)
gensim.test.test_phrases.TestFrozenPhrasesModel.setUp(self)
gensim.test.test_phrases.TestFrozenPhrasesModelCompatibility(unittest.TestCase)
gensim.test.test_phrases.TestFrozenPhrasesModelCompatibility.test_compatibility(self)
gensim.test.test_phrases.TestFrozenPhrasesPersistence(PhrasesData,unittest.TestCase)
gensim.test.test_phrases.TestFrozenPhrasesPersistence.test_save_load(self)
gensim.test.test_phrases.TestFrozenPhrasesPersistence.test_save_load_custom_scorer(self)
gensim.test.test_phrases.TestFrozenPhrasesPersistence.test_save_load_no_common_terms(self)
gensim.test.test_phrases.TestFrozenPhrasesPersistence.test_save_load_no_scoring(self)
gensim.test.test_phrases.TestFrozenPhrasesPersistence.test_save_load_string_scoring(self)
gensim.test.test_phrases.TestFrozenPhrasesPersistence.test_save_load_with_connector_words(self)
gensim.test.test_phrases.TestPhraseAnalysis(unittest.TestCase)
gensim.test.test_phrases.TestPhraseAnalysis.AnalysisTester(self,scores,threshold)
gensim.test.test_phrases.TestPhraseAnalysis.AnalysisTester.__init__(self,scores,threshold)
gensim.test.test_phrases.TestPhraseAnalysis.AnalysisTester.score_candidate(self,word_a,word_b,in_between)
gensim.test.test_phrases.TestPhraseAnalysis.test_analysis_bigrams(self)
gensim.test.test_phrases.TestPhraseAnalysis.test_analysis_connector_words(self)
gensim.test.test_phrases.TestPhraseAnalysis.test_analysis_connector_words_in_between(self)
gensim.test.test_phrases.TestPhraseAnalysis.test_simple_analysis(self)
gensim.test.test_phrases.TestPhrasesModel(PhrasesCommon,unittest.TestCase)
gensim.test.test_phrases.TestPhrasesModel.test__getitem__(self)
gensim.test.test_phrases.TestPhrasesModel.test_bad_parameters(self)
gensim.test.test_phrases.TestPhrasesModel.test_custom_scorer(self)
gensim.test.test_phrases.TestPhrasesModel.test_export_phrases(self)
gensim.test.test_phrases.TestPhrasesModel.test_find_phrases(self)
gensim.test.test_phrases.TestPhrasesModel.test_multiple_bigrams_single_entry(self)
gensim.test.test_phrases.TestPhrasesModel.test_pruning(self)
gensim.test.test_phrases.TestPhrasesModel.test_scoring_default(self)
gensim.test.test_phrases.TestPhrasesModel.test_scoring_npmi(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms(CommonTermsPhrasesData,TestPhrasesModel)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test__getitem__(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test_custom_scorer(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test_export_phrases(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test_find_phrases(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test_multiple_bigrams_single_entry(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test_scoring_default(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test_scoring_npmi(self)
gensim.test.test_phrases.TestPhrasesPersistence(PhrasesData,unittest.TestCase)
gensim.test.test_phrases.TestPhrasesPersistence.test_save_load(self)
gensim.test.test_phrases.TestPhrasesPersistence.test_save_load_custom_scorer(self)
gensim.test.test_phrases.TestPhrasesPersistence.test_save_load_no_common_terms(self)
gensim.test.test_phrases.TestPhrasesPersistence.test_save_load_no_scoring(self)
gensim.test.test_phrases.TestPhrasesPersistence.test_save_load_string_scoring(self)
gensim.test.test_phrases.TestPhrasesPersistence.test_save_load_with_connector_words(self)
gensim.test.test_phrases.dumb_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_rpmodel.py----------------------------------------
A:gensim.test.test_rpmodel.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_rpmodel.model->gensim.models.rpmodel.RpModel(self.corpus, num_topics=2)
A:gensim.test.test_rpmodel.vec->gensim.matutils.sparse2full(transformed, 2)
A:gensim.test.test_rpmodel.expected->numpy.array([-0.70710677, 0.70710677])
A:gensim.test.test_rpmodel.fname->get_tmpfile('gensim_models.tst.gz')
A:gensim.test.test_rpmodel.model2->gensim.models.rpmodel.RpModel.load(fname, mmap=None)
gensim.test.test_rpmodel.TestRpModel(unittest.TestCase)
gensim.test.test_rpmodel.TestRpModel.setUp(self)
gensim.test.test_rpmodel.TestRpModel.test_persistence(self)
gensim.test.test_rpmodel.TestRpModel.test_persistence_compressed(self)
gensim.test.test_rpmodel.TestRpModel.test_transform(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_hdpmodel.py----------------------------------------
A:gensim.test.test_hdpmodel.dictionary->Dictionary(common_texts)
A:gensim.test.test_hdpmodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_hdpmodel.self.model->self.class_(corpus, id2word=dictionary, random_state=np.random.seed(0))
A:gensim.test.test_hdpmodel.(prob, word)->results[1].split('+')[0].split('*')
A:gensim.test.test_hdpmodel.ldam->self.model.suggested_lda_model()
gensim.test.test_hdpmodel.TestHdpModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_hdpmodel.TestHdpModel.setUp(self)
gensim.test.test_hdpmodel.TestHdpModel.test_ldamodel(self)
gensim.test.test_hdpmodel.TestHdpModel.test_topic_values(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_ldamodel.py----------------------------------------
A:gensim.test.test_ldamodel.AZURE->bool(os.environ.get('PIPELINE_WORKSPACE'))
A:gensim.test.test_ldamodel.dictionary->Dictionary(common_texts)
A:gensim.test.test_ldamodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_ldamodel.self.model->self.class_(corpus, id2word=dictionary, num_topics=2, passes=100)
A:gensim.test.test_ldamodel.model2->self.class_.load(fname, mmap='r')
A:gensim.test.test_ldamodel.model2.state->copy.deepcopy(self.model.state)
A:gensim.test.test_ldamodel.self.model.random_state->numpy.random.RandomState(0)
A:gensim.test.test_ldamodel.model2.random_state->numpy.random.RandomState(0)
A:gensim.test.test_ldamodel.model->self.class_.load(lda_3_0_1_fname)
A:gensim.test.test_ldamodel.vec->gensim.matutils.sparse2full(transformed, 2)
A:gensim.test.test_ldamodel.passed->numpy.allclose(sorted(vec), sorted(expected), atol=0.1)
A:gensim.test.test_ldamodel.model1->self.class_(corpus, id2word=dictionary, eta='symmetric', passes=10)
A:gensim.test.test_ldamodel.modelauto->self.class_(corpus, id2word=dictionary, eta='auto', passes=10)
A:gensim.test.test_ldamodel.kwargs->dict(id2word=dictionary, num_topics=2, eta=None)
A:gensim.test.test_ldamodel.kwargs['alpha']->numpy.array([0.3, 0.3])
A:gensim.test.test_ldamodel.num_terms->len(dictionary)
A:gensim.test.test_ldamodel.kwargs['eta']->numpy.array([[0.5] * len(dictionary)] * 2).reshape(tuple(reversed(testeta.shape)))
A:gensim.test.test_ldamodel.testeta->numpy.array([[0.5] * len(dictionary)] * 2)
A:gensim.test.test_ldamodel.top_topics->self.model.top_topics(self.corpus)
A:gensim.test.test_ldamodel.topic_terms->self.model.get_topic_terms(1)
A:gensim.test.test_ldamodel.doc_topics->self.class_.load(lda_3_0_1_fname).get_document_topics(self.corpus)
A:gensim.test.test_ldamodel.all_topics->self.class_.load(lda_3_0_1_fname).get_document_topics(self.corpus, minimum_probability=0.8, minimum_phi_value=1.0, per_word_topics=True)
A:gensim.test.test_ldamodel.(doc_topics, word_topics, word_phis)->self.class_.load(lda_3_0_1_fname).get_document_topics(self.corpus[1], per_word_topics=True)
A:gensim.test.test_ldamodel.result->self.class_.load(lda_3_0_1_fname).get_term_topics(str(model.id2word[2]))
A:gensim.test.test_ldamodel.test_rhots->list()
A:gensim.test.test_ldamodel.msg->', '.join((str(x) for x in [passes, model.num_updates, model.state.numdocs]))
A:gensim.test.test_ldamodel.fname->get_tmpfile('gensim_models_lda.tst.gz')
A:gensim.test.test_ldamodel.fname_model_2_7->datapath('ldamodel_python_2_7')
A:gensim.test.test_ldamodel.model_2_7->self.class_.load(fname_model_2_7)
A:gensim.test.test_ldamodel.fname_model_3_5->datapath('ldamodel_python_3_5')
A:gensim.test.test_ldamodel.model_3_5->self.class_.load(fname_model_3_5)
A:gensim.test.test_ldamodel.id2word_2_7->dict(model_2_7.id2word.iteritems())
A:gensim.test.test_ldamodel.id2word_3_5->dict(model_3_5.id2word.iteritems())
A:gensim.test.test_ldamodel.pre_0_13_2_fname->datapath('pre_0_13_2_model')
A:gensim.test.test_ldamodel.model_pre_0_13_2->self.class_.load(pre_0_13_2_fname)
A:gensim.test.test_ldamodel.model_topics->self.class_.load(pre_0_13_2_fname).print_topics(num_topics=2, num_words=3)
A:gensim.test.test_ldamodel.post_0_13_2_fname->get_tmpfile('gensim_models_lda_post_0_13_2_model.tst')
A:gensim.test.test_ldamodel.model_post_0_13_2->self.class_.load(post_0_13_2_fname)
A:gensim.test.test_ldamodel.model_topics_new->self.class_.load(post_0_13_2_fname).print_topics(num_topics=2, num_words=3)
A:gensim.test.test_ldamodel.lda_3_0_1_fname->datapath('lda_3_0_1_model')
gensim.test.test_ldamodel.TestLdaModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_ldamodel.TestLdaModel.setUp(self)
gensim.test.test_ldamodel.TestLdaModel.test_alpha(self)
gensim.test.test_ldamodel.TestLdaModel.test_alpha_auto(self)
gensim.test.test_ldamodel.TestLdaModel.test_dtype_backward_compatibility(self)
gensim.test.test_ldamodel.TestLdaModel.test_eta(self)
gensim.test.test_ldamodel.TestLdaModel.test_eta_auto(self)
gensim.test.test_ldamodel.TestLdaModel.test_get_document_topics(self)
gensim.test.test_ldamodel.TestLdaModel.test_get_topic_terms(self)
gensim.test.test_ldamodel.TestLdaModel.test_large_mmap(self)
gensim.test.test_ldamodel.TestLdaModel.test_large_mmap_compressed(self)
gensim.test.test_ldamodel.TestLdaModel.test_model_compatibility_with_python_versions(self)
gensim.test.test_ldamodel.TestLdaModel.test_passes(self)
gensim.test.test_ldamodel.TestLdaModel.test_persistence(self)
gensim.test.test_ldamodel.TestLdaModel.test_persistence_compressed(self)
gensim.test.test_ldamodel.TestLdaModel.test_persistence_ignore(self)
gensim.test.test_ldamodel.TestLdaModel.test_random_state_backward_compatibility(self)
gensim.test.test_ldamodel.TestLdaModel.test_sync_state(self)
gensim.test.test_ldamodel.TestLdaModel.test_term_topics(self)
gensim.test.test_ldamodel.TestLdaModel.test_top_topics(self)
gensim.test.test_ldamodel.TestLdaModel.test_transform(self)
gensim.test.test_ldamodel.TestLdaMulticore(TestLdaModel)
gensim.test.test_ldamodel.TestLdaMulticore.setUp(self)
gensim.test.test_ldamodel.TestLdaMulticore.test_alpha_auto(self)
gensim.test.test_ldamodel.test_random_state()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_similarities.py----------------------------------------
A:gensim.test.test_similarities.index->WordEmbeddingSimilarityIndex(self.vectors, exponent=2.0)
A:gensim.test.test_similarities.expected->gensim.matutils.sparse2full(expected, len(index))
A:gensim.test.test_similarities.sims->gensim.matutils.sparse2full(sims, len(index))
A:gensim.test.test_similarities.vec_scipy->scipy.sparse.csr_matrix(vec)
A:gensim.test.test_similarities.vec_scipy_clipped->gensim.matutils.scipy2scipy_clipped(vec_scipy, topn=3)
A:gensim.test.test_similarities.matrix_scipy->scipy.sparse.csr_matrix([vec] * 3)
A:gensim.test.test_similarities.matrix_scipy_clipped->gensim.matutils.scipy2scipy_clipped(matrix_scipy, topn=3)
A:gensim.test.test_similarities.fname->get_tmpfile('gensim_similarities.tst.pkl')
A:gensim.test.test_similarities.index2->gensim.similarities.nmslib.NmslibIndexer.load(fname)
A:gensim.test.test_similarities.index.index->WordEmbeddingSimilarityIndex(self.vectors, exponent=2.0).index.todense()
A:gensim.test.test_similarities.index2.index->gensim.similarities.nmslib.NmslibIndexer.load(fname).index.todense()
A:gensim.test.test_similarities.self.tfidf->TfidfModel(dictionary=self.dictionary)
A:gensim.test.test_similarities.similarity_matrix->scipy.sparse.identity(12, format='lil')
A:gensim.test.test_similarities.self.similarity_matrix->SparseTermSimilarityMatrix(similarity_matrix)
A:gensim.test.test_similarities.query->gensim.test.utils.common_dictionary.doc2bow(TEXTS[0])
A:gensim.test.test_similarities.num_features->len(DICTIONARY)
A:gensim.test.test_similarities.model->gensim.models.KeyedVectors.load_word2vec_format(keyVectors_file)
A:gensim.test.test_similarities.keyVectors_file->datapath('lee_fasttext.vec')
A:gensim.test.test_similarities.test_index->AnnoyIndexer()
A:gensim.test.test_similarities.approx_neighbors->self.model.dv.most_similar([self.vector], topn=5, indexer=self.index)
A:gensim.test.test_similarities.exact_neighbors->self.model.dv.most_similar([self.vector], topn=5)
A:gensim.test.test_similarities.approx_similarities->gensim.models.KeyedVectors.load_word2vec_format(keyVectors_file).most_similar([vector], topn=None, indexer=index)
A:gensim.test.test_similarities.exact_similarities->gensim.models.KeyedVectors.load_word2vec_format(keyVectors_file).most_similar(positive=[vector], topn=None)
A:gensim.test.test_similarities.self.model->gensim.models.doc2vec.Doc2Vec(SENTENCES, min_count=1)
A:gensim.test.test_similarities.self.index->LevenshteinSimilarityIndex(self.dictionary, max_distance=max_distance)
A:gensim.test.test_similarities.self.test_index->AnnoyIndexer()
A:gensim.test.test_similarities.self.index2->gensim.similarities.nmslib.NmslibIndexer.load(fname)
A:gensim.test.test_similarities.self.dictionary->Dictionary(self.documents)
A:gensim.test.test_similarities.results->list(index.most_similar(u'holiday', topn=10))
A:gensim.test.test_similarities.similarities->numpy.array([similarity for (term, similarity) in index.most_similar(u'holiday', topn=len(self.dictionary))])
A:gensim.test.test_similarities.zero_index->UniformTermSimilarityIndex(self.dictionary, term_similarity=0.0)
A:gensim.test.test_similarities.self.identity_matrix->SparseTermSimilarityMatrix(zero_index, self.dictionary)
A:gensim.test.test_similarities.self.uniform_matrix->SparseTermSimilarityMatrix(self.index, self.dictionary)
A:gensim.test.test_similarities.self.vec1->self.dictionary.doc2bow([u'government', u'government', u'denied'])
A:gensim.test.test_similarities.self.vec2->self.dictionary.doc2bow([u'government', u'holiday'])
A:gensim.test.test_similarities.matrix->SparseTermSimilarityMatrix(self.index, self.dictionary, nonzero_limit=1, tfidf=self.tfidf).matrix.todense()
A:gensim.test.test_similarities.expected_matrix->numpy.array([[1.0, 2.0, 3.0], [0.0, 1.0, 4.0], [0.0, 0.0, 1.0]])
A:gensim.test.test_similarities.negative_index->UniformTermSimilarityIndex(self.dictionary, term_similarity=-0.5)
A:gensim.test.test_similarities.result->self.uniform_matrix.inner_product([self.vec1] * 3, [self.vec2] * 2, normalized=(True, True))
A:gensim.test.test_similarities.expected_result->numpy.full((3, 2), expected_result)
A:gensim.test.test_similarities.max_distance->max((len(term) for term in self.dictionary.values()))
A:gensim.test.test_similarities.(terms, _)->zip(*results)
A:gensim.test.test_similarities.first_similarities->numpy.array([similarity for (term, similarity) in index.most_similar(u'holiday', topn=10)])
A:gensim.test.test_similarities.second_similarities->numpy.array([similarity for (term, similarity) in index.most_similar(u'holiday', topn=10)])
A:gensim.test.test_similarities.self.vectors->gensim.models.KeyedVectors.load_word2vec_format(datapath('euclidean_vectors.bin'), binary=True, datatype=numpy.float64)
A:gensim.test.test_similarities.actual->editdist('ika', 'siska')
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer(unittest.TestCase)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.setUp(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.test_approx_neighbors_match_exact(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.test_document_is_similar_to_itself(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.test_load_not_exist(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.test_save(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.test_save_load(self)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer(unittest.TestCase)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer.setUp(self)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer.test_approx_neighbors_match_exact(self)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer.test_document_is_similar_to_itself(self)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer.test_load_not_exist(self)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer.test_save(self)
gensim.test.test_similarities.TestDoc2VecNmslibIndexer.test_save_load(self)
gensim.test.test_similarities.TestFastSS(unittest.TestCase)
gensim.test.test_similarities.TestFastSS.test_editdist_different_unicode_kinds(self)
gensim.test.test_similarities.TestFastSS.test_editdist_same_unicode_kind_latin1(self)
gensim.test.test_similarities.TestFastSS.test_editdist_same_unicode_kind_ucs2(self)
gensim.test.test_similarities.TestFastSS.test_editdist_same_unicode_kind_ucs4(self)
gensim.test.test_similarities.TestLevenshteinSimilarityIndex(unittest.TestCase)
gensim.test.test_similarities.TestLevenshteinSimilarityIndex.setUp(self)
gensim.test.test_similarities.TestLevenshteinSimilarityIndex.test_most_similar_alpha(self)
gensim.test.test_similarities.TestLevenshteinSimilarityIndex.test_most_similar_beta(self)
gensim.test.test_similarities.TestLevenshteinSimilarityIndex.test_most_similar_result_order(self)
gensim.test.test_similarities.TestLevenshteinSimilarityIndex.test_most_similar_topn(self)
gensim.test.test_similarities.TestMatrixSimilarity(_TestSimilarityABC)
gensim.test.test_similarities.TestMatrixSimilarity.setUp(self)
gensim.test.test_similarities.TestSimilarity(_TestSimilarityABC)
gensim.test.test_similarities.TestSimilarity.factoryMethod(self)
gensim.test.test_similarities.TestSimilarity.setUp(self)
gensim.test.test_similarities.TestSimilarity.test_chunksize(self)
gensim.test.test_similarities.TestSimilarity.test_mmap_compressed(self)
gensim.test.test_similarities.TestSimilarity.test_nlargest(self)
gensim.test.test_similarities.TestSimilarity.test_reopen(self)
gensim.test.test_similarities.TestSimilarity.test_sharding(self)
gensim.test.test_similarities.TestSoftCosineSimilarity(_TestSimilarityABC)
gensim.test.test_similarities.TestSoftCosineSimilarity.factoryMethod(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.setUp(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.test_chunking(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.test_full(self,num_best=None)
gensim.test.test_similarities.TestSoftCosineSimilarity.test_iter(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.test_non_increasing(self)
gensim.test.test_similarities.TestSparseMatrixSimilarity(_TestSimilarityABC)
gensim.test.test_similarities.TestSparseMatrixSimilarity.setUp(self)
gensim.test.test_similarities.TestSparseMatrixSimilarity.test_maintain_sparsity(self)
gensim.test.test_similarities.TestSparseMatrixSimilarity.test_maintain_sparsity_with_num_best(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix(unittest.TestCase)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.setUp(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_diagonal(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_dominant(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_dtype(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_empty_dictionary(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_encapsulation(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_corpus_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_corpus_vector_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_corpus_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_vector_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_vector_zerovector_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_vector_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_default(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_false_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_false_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_maintain_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_maintain_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_maintain_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_true_false(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_true_maintain(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_inner_product_zerovector_zerovector_true_true(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_nonzero_limit(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_order(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_symmetric(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_tfidf(self)
gensim.test.test_similarities.TestSparseTermSimilarityMatrix.test_type(self)
gensim.test.test_similarities.TestUniformTermSimilarityIndex(unittest.TestCase)
gensim.test.test_similarities.TestUniformTermSimilarityIndex.setUp(self)
gensim.test.test_similarities.TestUniformTermSimilarityIndex.test_most_similar(self)
gensim.test.test_similarities.TestWmdSimilarity(_TestSimilarityABC)
gensim.test.test_similarities.TestWmdSimilarity.factoryMethod(self)
gensim.test.test_similarities.TestWmdSimilarity.setUp(self)
gensim.test.test_similarities.TestWmdSimilarity.test_chunking(self)
gensim.test.test_similarities.TestWmdSimilarity.test_full(self,num_best=None)
gensim.test.test_similarities.TestWmdSimilarity.test_iter(self)
gensim.test.test_similarities.TestWmdSimilarity.test_non_increasing(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer(unittest.TestCase)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertAllSimilaritiesDisableIndexer(self,model,wv,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertApproxNeighborsMatchExact(self,model,wv,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertIndexSaved(self,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertLoadedIndexEqual(self,index,model)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertVectorIsSimilarToItself(self,wv,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.setUp(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.test_annoy_indexing_of_keyed_vectors(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.test_fast_text(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.test_load_missing_raises_error(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.test_word2vec(self)
gensim.test.test_similarities.TestWord2VecNmslibIndexer(unittest.TestCase)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.assertApproxNeighborsMatchExact(self,model,wv,index)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.assertIndexSaved(self,index)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.assertLoadedIndexEqual(self,index,model)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.assertVectorIsSimilarToItself(self,wv,index)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.setUp(self)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.test_fasttext(self)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.test_indexing_keyedvectors(self)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.test_load_missing_raises_error(self)
gensim.test.test_similarities.TestWord2VecNmslibIndexer.test_word2vec(self)
gensim.test.test_similarities.TestWordEmbeddingSimilarityIndex(unittest.TestCase)
gensim.test.test_similarities.TestWordEmbeddingSimilarityIndex.setUp(self)
gensim.test.test_similarities.TestWordEmbeddingSimilarityIndex.test_most_similar(self)
gensim.test.test_similarities._TestSimilarityABC(unittest.TestCase)
gensim.test.test_similarities._TestSimilarityABC.factoryMethod(self)
gensim.test.test_similarities._TestSimilarityABC.test_chunking(self)
gensim.test.test_similarities._TestSimilarityABC.test_empty_query(self)
gensim.test.test_similarities._TestSimilarityABC.test_full(self,num_best=None,shardsize=100)
gensim.test.test_similarities._TestSimilarityABC.test_full2sparse_clipped(self)
gensim.test.test_similarities._TestSimilarityABC.test_iter(self)
gensim.test.test_similarities._TestSimilarityABC.test_large(self)
gensim.test.test_similarities._TestSimilarityABC.test_large_compressed(self)
gensim.test.test_similarities._TestSimilarityABC.test_mmap(self)
gensim.test.test_similarities._TestSimilarityABC.test_mmap_compressed(self)
gensim.test.test_similarities._TestSimilarityABC.test_num_best(self)
gensim.test.test_similarities._TestSimilarityABC.test_persistency(self)
gensim.test.test_similarities._TestSimilarityABC.test_persistency_compressed(self)
gensim.test.test_similarities._TestSimilarityABC.test_scipy2scipy_clipped(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_utils.py----------------------------------------
A:gensim.test.test_utils.result->gensim.utils.is_corpus(noCorpus)
A:gensim.test.test_utils.potentials->list()
A:gensim.test.test_utils.file_obj->open(datapath('testcorpus.mm'))
A:gensim.test.test_utils.sampled_dict->gensim.utils.sample_dict(d, 2, False)
A:gensim.test.test_utils.sampled_dict_random->gensim.utils.sample_dict(d, 2)
A:gensim.test.test_utils.res_dict->gensim.utils.merge_counts(d1, d2)
A:gensim.test.test_utils.arr10_5->numpy.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7], [4, 5, 6, 7, 8], [5, 6, 7, 8, 9]])
A:gensim.test.test_utils.out->gensim.utils.iter_windows(texts, 3)
A:gensim.test.test_utils.expected->numpy.array([input_arr.copy()])
A:gensim.test.test_utils.input_arr->numpy.array(['this', 'is', 'test'], dtype='object')
A:gensim.test.test_utils.windows->list(utils.iter_windows(texts, 2, copy=True))
A:gensim.test.test_utils.corpus_file->get_tmpfile('gensim_utils.tst')
gensim.test.test_utils.TestIsCorpus(unittest.TestCase)
gensim.test.test_utils.TestIsCorpus.test_None(self)
gensim.test.test_utils.TestIsCorpus.test_int_tuples(self)
gensim.test.test_utils.TestIsCorpus.test_invalid_formats(self)
gensim.test.test_utils.TestIsCorpus.test_simple_lists_of_tuples(self)
gensim.test.test_utils.TestMergeDicts(unittest.TestCase)
gensim.test.test_utils.TestMergeDicts.test_merge_dicts(self)
gensim.test.test_utils.TestSampleDict(unittest.TestCase)
gensim.test.test_utils.TestSampleDict.test_sample_dict(self)
gensim.test.test_utils.TestSaveAsLineSentence(unittest.TestCase)
gensim.test.test_utils.TestSaveAsLineSentence.test_save_as_line_sentence_en(self)
gensim.test.test_utils.TestSaveAsLineSentence.test_save_as_line_sentence_ru(self)
gensim.test.test_utils.TestTrimVocabByFreq(unittest.TestCase)
gensim.test.test_utils.TestTrimVocabByFreq.test_trim_vocab(self)
gensim.test.test_utils.TestUtils(unittest.TestCase)
gensim.test.test_utils.TestUtils.test_decode_entities(self)
gensim.test.test_utils.TestUtils.test_open_file_existent_file(self)
gensim.test.test_utils.TestUtils.test_open_file_existent_file_object(self)
gensim.test.test_utils.TestUtils.test_open_file_non_existent_file(self)
gensim.test.test_utils.TestUtils.test_open_file_non_existent_file_object(self)
gensim.test.test_utils.TestWindowing(unittest.TestCase)
gensim.test.test_utils.TestWindowing._assert_arrays_equal(self,expected,actual)
gensim.test.test_utils.TestWindowing.test_flatten_nested(self)
gensim.test.test_utils.TestWindowing.test_flatten_not_nested(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_include_below_window_size(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_list_texts(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_uses_views(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_with_copy(self)
gensim.test.test_utils.TestWindowing.test_strided_windows1(self)
gensim.test.test_utils.TestWindowing.test_strided_windows2(self)
gensim.test.test_utils.TestWindowing.test_strided_windows_window_size_equals_size(self)
gensim.test.test_utils.TestWindowing.test_strided_windows_window_size_exceeds_size(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_corpora_hashdictionary.py----------------------------------------
A:gensim.test.test_corpora_hashdictionary.d->HashDictionary(['loouk konek'.split(), '   '.split()])
A:gensim.test.test_corpora_hashdictionary.tmpf->get_tmpfile('dict_test.txt.bz2')
A:gensim.test.test_corpora_hashdictionary.d2->HashDictionary(['loouk konek'.split(), '   '.split()]).load(tmpf)
gensim.test.test_corpora_hashdictionary.TestHashDictionary(unittest.TestCase)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.setUp(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_build(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_debug_mode(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_doc_freq_and_token2id_for_several_docs_with_one_word(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_doc_freq_for_one_doc_with_several_word(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_doc_freq_one_doc(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_filter(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_range(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_saveAsText(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_saveAsTextBz2(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_miislita.py----------------------------------------
A:gensim.test.test_miislita.logger->logging.getLogger(__name__)
A:gensim.test.test_miislita.stoplist->set('for a of the and to in on'.split())
A:gensim.test.test_miislita.self.length->sum((1 for _ in self.get_texts()))
A:gensim.test.test_miislita.miislita->CorpusMiislita(datapath('miIslita.cor'))
A:gensim.test.test_miislita.ftmp->get_tmpfile('test_textcorpus.mm')
A:gensim.test.test_miislita.miislita2->CorpusMiislita.load(tmpf)
A:gensim.test.test_miislita.corpusname->datapath('miIslita.cor')
A:gensim.test.test_miislita.tmpf->get_tmpfile('tc_test.cpickle')
A:gensim.test.test_miislita.tfidf->gensim.models.TfidfModel(miislita, miislita.dictionary, normalize=False)
A:gensim.test.test_miislita.index->gensim.similarities.SparseMatrixSimilarity(tfidf[miislita], num_features=len(miislita.dictionary))
A:gensim.test.test_miislita.vec_bow->CorpusMiislita(datapath('miIslita.cor')).dictionary.doc2bow(query.lower().split())
gensim.test.test_miislita.CorpusMiislita(corpora.TextCorpus)
gensim.test.test_miislita.CorpusMiislita.__len__(self)
gensim.test.test_miislita.CorpusMiislita.get_texts(self)
gensim.test.test_miislita.TestMiislita(unittest.TestCase)
gensim.test.test_miislita.TestMiislita.test_miislita_high_level(self)
gensim.test.test_miislita.TestMiislita.test_save_load_ability(self)
gensim.test.test_miislita.TestMiislita.test_textcorpus(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_tfidfmodel.py----------------------------------------
A:gensim.test.test_tfidfmodel.dictionary->Dictionary(texts)
A:gensim.test.test_tfidfmodel.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_tfidfmodel.model->gensim.models.tfidfmodel.TfidfModel.load(datapath('tfidf_model_3_2.tst'))
A:gensim.test.test_tfidfmodel.model1->gensim.models.tfidfmodel.TfidfModel(common_corpus)
A:gensim.test.test_tfidfmodel.model2->gensim.models.tfidfmodel.TfidfModel.load(fname, mmap=None)
A:gensim.test.test_tfidfmodel.fname->get_tmpfile('gensim_models_smartirs.tst.gz')
A:gensim.test.test_tfidfmodel.model3->gensim.models.tfidfmodel.TfidfModel(self.corpus, pivot=0, slope=1)
A:gensim.test.test_tfidfmodel.model4->gensim.models.tfidfmodel.TfidfModel.load(datapath('tfidf_model.tst.bz2'))
gensim.test.test_tfidfmodel.TestTfidfModel(unittest.TestCase)
gensim.test.test_tfidfmodel.TestTfidfModel.setUp(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_backwards_compatibility(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_consistency(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_init(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_persistence(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_persistence_compressed(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_pivoted_normalization(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_transform(self)
gensim.test.test_tfidfmodel.TestTfidfModel.test_wlocal_wglobal(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_parsing.py----------------------------------------
A:gensim.test.test_parsing.classes->numpy.array([[1, 0], [1, 0], [0, 1], [0, 1]])
gensim.test.test_parsing.TestPreprocessing(unittest.TestCase)
gensim.test.test_parsing.TestPreprocessing.test_split_alphanum(self)
gensim.test.test_parsing.TestPreprocessing.test_split_on_space(self)
gensim.test.test_parsing.TestPreprocessing.test_stem_text(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_multiple_whitespaces(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_non_alphanum(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_numeric(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_short(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_short_tokens(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_stopword_tokens(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_stopwords(self)
gensim.test.test_parsing.TestPreprocessing.test_strip_tags(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_coherencemodel.py----------------------------------------
A:gensim.test.test_coherencemodel.self.ldamodel->LdaModel(corpus=self.corpus, id2word=self.dictionary, num_topics=2, passes=0, iterations=0)
A:gensim.test.test_coherencemodel.kwargs->dict(corpus=self.corpus, dictionary=self.dictionary, topn=5, coherence='u_mass')
A:gensim.test.test_coherencemodel.cm1->CoherenceModel(model=self.ldamodel, **kwargs)
A:gensim.test.test_coherencemodel.cm2->CoherenceModel(topics=self.topics2, **kwargs)
A:gensim.test.test_coherencemodel.cm3->CoherenceModel(topics=self.topics3, **kwargs)
A:gensim.test.test_coherencemodel.cm4->CoherenceModel(topics=self.topicIds1, **kwargs)
A:gensim.test.test_coherencemodel.get_model->partial(CoherenceModel, topics=self.topics1, corpus=self.corpus, dictionary=self.dictionary, coherence='u_mass')
A:gensim.test.test_coherencemodel.fname->get_tmpfile('gensim_similarities.tst.pkl')
A:gensim.test.test_coherencemodel.model->CoherenceModel(topics=self.topics1, texts=self.texts, dictionary=self.dictionary, coherence='c_v')
A:gensim.test.test_coherencemodel.model2->gensim.models.coherencemodel.CoherenceModel.load(fname)
A:gensim.test.test_coherencemodel.bestn->argsort(topic, topn=cm1.topn, reverse=True)
A:gensim.test.test_coherencemodel.cm->gensim.models.coherencemodel.CoherenceModel.for_models(models, dictionary=self.dictionary, texts=self.texts, coherence='c_v')
A:gensim.test.test_coherencemodel.((coherence_topics1, coherence1), (coherence_topics2, coherence2))->gensim.models.coherencemodel.CoherenceModel.for_models(models, dictionary=self.dictionary, texts=self.texts, coherence='c_v').compare_models(models)
gensim.test.test_coherencemodel.TestCoherenceModel(unittest.TestCase)
gensim.test.test_coherencemodel.TestCoherenceModel.check_coherence_measure(self,coherence)
gensim.test.test_coherencemodel.TestCoherenceModel.setUp(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingSameSizeTopics(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingTopicSubsets(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingWithModelSetting(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingWithTopnSettingGivenModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingWithTopnSettingGivenTopics(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCnpmi(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCnpmiLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCompareCoherenceForModels(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCompareCoherenceForTopics(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCuci(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCuciLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCv(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCvLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCw2vLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testErrors(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistence(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistenceAfterProbabilityEstimationUsingCorpus(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistenceAfterProbabilityEstimationUsingTexts(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistenceCompressed(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testProcesses(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testUMass(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testUMassLdaModel(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_fasttext.py----------------------------------------
A:gensim.test.test_fasttext.logger->logging.getLogger(__name__)
A:gensim.test.test_fasttext.FT_HOME->os.environ.get('FT_HOME')
A:gensim.test.test_fasttext.self.test_model_file->datapath('lee_fasttext.bin')
A:gensim.test.test_fasttext.self.test_model->gensim.models.fasttext.load_facebook_model(self.test_model_file)
A:gensim.test.test_fasttext.self.test_new_model_file->datapath('lee_fasttext_new.bin')
A:gensim.test.test_fasttext.model->_create_and_save_fb_model(fpath, model_params)
A:gensim.test.test_fasttext.sims->_create_and_save_fb_model(fpath, model_params).wv.most_similar('graph', topn=10)
A:gensim.test.test_fasttext.graph_vector->_create_and_save_fb_model(fpath, model_params).wv.get_vector('graph', norm=True)
A:gensim.test.test_fasttext.sims2->_create_and_save_fb_model(fpath, model_params).wv.most_similar(positive=[graph_vector], topn=11)
A:gensim.test.test_fasttext.model2->FT_gensim(sentences, vector_size=12, min_count=1, hs=1, negative=0, seed=42, workers=1, bucket=BUCKET)
A:gensim.test.test_fasttext.tmpf->get_tmpfile('gensim_fasttext_w2v_format.tst')
A:gensim.test.test_fasttext.loaded_wv->gensim.models.fasttext.FastTextKeyedVectors.load(tmpf)
A:gensim.test.test_fasttext.new_model->gensim.models.fasttext.load_facebook_model(self.test_new_model_file)
A:gensim.test.test_fasttext.most_similar->self.test_model.wv.most_similar(word)
A:gensim.test.test_fasttext.dist->self.test_model.wv.wmdistance(doc, oov_doc)
A:gensim.test.test_fasttext.model_gensim->FT_gensim(vector_size=48, sg=1, cbow_mean=1, alpha=0.025, window=5, hs=1, negative=0, min_count=5, epochs=10, batch_words=1000, word_ngrams=1, sample=0.001, min_n=3, max_n=6, sorted_vocab=1, workers=1, min_alpha=0.0, bucket=BUCKET, shrink_windows=shrink_windows)
A:gensim.test.test_fasttext.lee_data->LineSentence(datapath('lee_background.cor'))
A:gensim.test.test_fasttext.orig0->numpy.copy(model_gensim.wv.vectors[0])
A:gensim.test.test_fasttext.sims_gensim->FT_gensim(vector_size=48, sg=1, cbow_mean=1, alpha=0.025, window=5, hs=1, negative=0, min_count=5, epochs=10, batch_words=1000, word_ngrams=1, sample=0.001, min_n=3, max_n=6, sorted_vocab=1, workers=1, min_alpha=0.0, bucket=BUCKET, shrink_windows=shrink_windows).wv.most_similar('night', topn=10)
A:gensim.test.test_fasttext.overlaps->set(sims_gensim_words).intersection(expected_sims_words)
A:gensim.test.test_fasttext.overlap_count->len(overlaps)
A:gensim.test.test_fasttext.model_hs->FT_gensim(corpus_file=corpus_file, vector_size=12, min_count=1, seed=42, hs=1, negative=0, bucket=BUCKET)
A:gensim.test.test_fasttext.model_neg->gensim.models.fasttext.FastText.load(tmpf)
A:gensim.test.test_fasttext.model_reload->gensim.models.fasttext.load_facebook_model(tmpf)
A:gensim.test.test_fasttext.tmpf2->get_tmpfile('gensim_ft_format2.tst')
A:gensim.test.test_fasttext.start_vecs->_create_and_save_fb_model(fpath, model_params).wv.vectors_vocab.copy()
A:gensim.test.test_fasttext.orig0_all->numpy.copy(model.wv.vectors_ngrams)
A:gensim.test.test_fasttext.sim->_create_and_save_fb_model(fpath, model_params).wv.n_similarity(['war'], ['terrorism'])
A:gensim.test.test_fasttext.original_syn0_vocab->numpy.copy(model.wv.vectors_vocab)
A:gensim.test.test_fasttext.loaded_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_fasttext.report->_create_and_save_fb_model(fpath, model_params).estimate_memory()
A:gensim.test.test_fasttext.vectors_for_all->self.test_model.wv.vectors_for_all(words, allow_inference=False)
A:gensim.test.test_fasttext.predicted->len(vectors_for_all)
A:gensim.test.test_fasttext.smaller_distance->numpy.linalg.norm(vectors_for_all['an out-of-vocabulary word'] - vectors_for_all['another out-of-vocabulary word'])
A:gensim.test.test_fasttext.greater_distance->numpy.linalg.norm(vectors_for_all['an out-of-vocabulary word'] - vectors_for_all['responding'])
A:gensim.test.test_fasttext.path->datapath('toy-model.bin')
A:gensim.test.test_fasttext.columns->fin.readline().rstrip().split(' ')
A:gensim.test.test_fasttext.word->fin.readline().rstrip()
A:gensim.test.test_fasttext.native->load_native()
A:gensim.test.test_fasttext.expected->numpy.array([0.76222, 1.0669, 0.7055, -0.090969, -0.53508])
A:gensim.test.test_fasttext.actual_vector->load_native().wv.get_vector(word)
A:gensim.test.test_fasttext.trained->train_gensim()
A:gensim.test.test_fasttext.old_vector->_create_and_save_fb_model(fpath, model_params).wv.get_vector(word).tolist()
A:gensim.test.test_fasttext.new_vector->_create_and_save_fb_model(fpath, model_params).wv.get_vector(word).tolist()
A:gensim.test.test_fasttext.vectors_ngrams_before->numpy.copy(model.wv.vectors_ngrams)
A:gensim.test.test_fasttext.vectors_ngrams_after->numpy.copy(model.wv.vectors_ngrams)
A:gensim.test.test_fasttext.cap_path->datapath('crime-and-punishment.bin')
A:gensim.test.test_fasttext.fbkv->gensim.models.fasttext.load_facebook_vectors(cap_path)
A:gensim.test.test_fasttext.origin->numpy.zeros(v1.shape, v1.dtype)
A:gensim.test.test_fasttext.training_text->datapath('toy-data.txt')
A:gensim.test.test_fasttext.pretrained_file->datapath('pretrained.vec')
A:gensim.test.test_fasttext.m->numpy.array(range(9))
A:gensim.test.test_fasttext.self.model->gensim.models.fasttext.load_facebook_model(datapath('crime-and-punishment.bin'))
A:gensim.test.test_fasttext.self.expected->dict(load_vec(fin))
A:gensim.test.test_fasttext.words->fin.readline().rstrip().rstrip().split(' ')
A:gensim.test.test_fasttext.minn->int(sys.argv[2])
A:gensim.test.test_fasttext.maxn->int(sys.argv[3])
A:gensim.test.test_fasttext.ngrams->fun(word, minn, maxn)
A:gensim.test.test_fasttext.actual->fin.read(len(_BYTES))
A:gensim.test.test_fasttext.fb->dict(_read_fb(fin))
A:gensim.test.test_fasttext.line->fin.readline().rstrip()
A:gensim.test.test_fasttext.term->' '.join(columns[:-5])
A:gensim.test.test_fasttext.buf->io.BytesIO()
A:gensim.test.test_fasttext.(raw_vocab, vocab_size, nlabels, ntokens)->gensim.models._fasttext_bin._load_vocab(buf, False)
A:gensim.test.test_fasttext._ARRAY->numpy.array([0.0, 1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0], dtype=np.dtype('float32'))
A:gensim.test.test_fasttext.array->gensim.models._fasttext_bin._fromfile(fin, _ARRAY.dtype, _ARRAY.shape[0])
A:gensim.test.test_fasttext.model_trained->_create_and_save_fb_model(fpath, model_params)
A:gensim.test.test_fasttext.model_loaded->gensim.models.fasttext.load_facebook_model(fpath)
A:gensim.test.test_fasttext.data->f.read()
A:gensim.test.test_fasttext.bin1->_read_binary_file(m1)
A:gensim.test.test_fasttext.bin2->_read_binary_file(m2)
A:gensim.test.test_fasttext.inp_fname->datapath('lee_background.cor')
A:gensim.test.test_fasttext.size->str(model_params['vector_size'])
A:gensim.test.test_fasttext.seed->str(model_params['seed'])
A:gensim.test.test_fasttext.process->subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE)
A:gensim.test.test_fasttext.words_str->'\n'.join(words)
A:gensim.test.test_fasttext.(out, _)->subprocess.Popen(cmd, stdin=subprocess.PIPE, stdout=subprocess.PIPE).communicate(input=words_str.encode('utf-8'))
A:gensim.test.test_fasttext.wv->_read_wordvectors_using_fasttext(fpath, model.wv.index_to_key)
A:gensim.test.test_fasttext.diff->calc_max_diff(wv[i, :], model.wv[w])
A:gensim.test.test_fasttext.n->_unpack(m, 25, hash2index)
gensim.test.test_fasttext.FTHashFunctionsTest(unittest.TestCase)
gensim.test.test_fasttext.FTHashFunctionsTest.setUp(self)
gensim.test.test_fasttext.FTHashFunctionsTest.test_cython(self)
gensim.test.test_fasttext.FTHashResultsTest(unittest.TestCase)
gensim.test.test_fasttext.FTHashResultsTest.setUp(self)
gensim.test.test_fasttext.FTHashResultsTest.test_ascii(self)
gensim.test.test_fasttext.FTHashResultsTest.test_out_of_vocab(self)
gensim.test.test_fasttext.FTHashResultsTest.test_unicode(self)
gensim.test.test_fasttext.HashCompatibilityTest(unittest.TestCase)
gensim.test.test_fasttext.HashCompatibilityTest.test_compatibility_true(self)
gensim.test.test_fasttext.HashCompatibilityTest.test_hash_native(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest(unittest.TestCase)
gensim.test.test_fasttext.NativeTrainingContinuationTest.setUp(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_continuation_gensim(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_continuation_native(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_in_vocab(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_load_native_pretrained(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_load_native_vectors(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_no_ngrams(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_out_of_vocab(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_sanity(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_save_load_gensim(self)
gensim.test.test_fasttext.NativeTrainingContinuationTest.test_save_load_native(self)
gensim.test.test_fasttext.NgramsTest(unittest.TestCase)
gensim.test.test_fasttext.NgramsTest.setUp(self)
gensim.test.test_fasttext.NgramsTest.test_bytes_cy(self)
gensim.test.test_fasttext.NgramsTest.test_fb(self)
gensim.test.test_fasttext.NgramsTest.test_text_cy(self)
gensim.test.test_fasttext.NgramsTest.test_text_cy_wide_unicode(self)
gensim.test.test_fasttext.SaveFacebookByteIdentityTest(unittest.TestCase)
gensim.test.test_fasttext.SaveFacebookByteIdentityTest._check_roundtrip_file_file(self,sg)
gensim.test.test_fasttext.SaveFacebookByteIdentityTest.test_cbow(self)
gensim.test.test_fasttext.SaveFacebookByteIdentityTest.test_skipgram(self)
gensim.test.test_fasttext.SaveFacebookFormatModelTest(unittest.TestCase)
gensim.test.test_fasttext.SaveFacebookFormatModelTest._check_roundtrip(self,sg)
gensim.test.test_fasttext.SaveFacebookFormatModelTest.test_cbow(self)
gensim.test.test_fasttext.SaveFacebookFormatModelTest.test_skipgram(self)
gensim.test.test_fasttext.SaveFacebookFormatReadingTest(unittest.TestCase)
gensim.test.test_fasttext.SaveFacebookFormatReadingTest._check_load_fasttext_format(self,sg)
gensim.test.test_fasttext.SaveFacebookFormatReadingTest.test_cbow(self)
gensim.test.test_fasttext.SaveFacebookFormatReadingTest.test_skipgram(self)
gensim.test.test_fasttext.SaveGensimByteIdentityTest(unittest.TestCase)
gensim.test.test_fasttext.SaveGensimByteIdentityTest._check_roundtrip_file_file(self,sg)
gensim.test.test_fasttext.SaveGensimByteIdentityTest.test_cbow(self)
gensim.test.test_fasttext.SaveGensimByteIdentityTest.test_skipgram(self)
gensim.test.test_fasttext.TestFastTextModel(unittest.TestCase)
gensim.test.test_fasttext.TestFastTextModel.model_sanity(self,model)
gensim.test.test_fasttext.TestFastTextModel.model_structural_sanity(self,model)
gensim.test.test_fasttext.TestFastTextModel.models_equal(self,model,model2)
gensim.test.test_fasttext.TestFastTextModel.obsolete_testLoadOldModel(self)
gensim.test.test_fasttext.TestFastTextModel.online_sanity(self,model)
gensim.test.test_fasttext.TestFastTextModel.setUp(self)
gensim.test.test_fasttext.TestFastTextModel.test_bucket_ngrams(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_hs_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_neg_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_neg_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_neg_training_fromfile(self)
gensim.test.test_fasttext.TestFastTextModel.test_contains(self)
gensim.test.test_fasttext.TestFastTextModel.test_estimate_memory(self)
gensim.test.test_fasttext.TestFastTextModel.test_fast_text_train_parameters(self)
gensim.test.test_fasttext.TestFastTextModel.test_get_vocab_word_vecs(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_fasttext_format(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_fasttext_new_format(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_model_non_utf8_encoding(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_model_supervised(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_model_with_non_ascii_vocab(self)
gensim.test.test_fasttext.TestFastTextModel.test_lookup(self)
gensim.test.test_fasttext.TestFastTextModel.test_most_similar(self)
gensim.test.test_fasttext.TestFastTextModel.test_most_similar_cosmul(self)
gensim.test.test_fasttext.TestFastTextModel.test_n_similarity(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning_after_save(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning_after_save_fromfile(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning_fromfile(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning_through_ft_format_saves(self)
gensim.test.test_fasttext.TestFastTextModel.test_oov_similarity(self)
gensim.test.test_fasttext.TestFastTextModel.test_persistence(self)
gensim.test.test_fasttext.TestFastTextModel.test_persistence_fromfile(self)
gensim.test.test_fasttext.TestFastTextModel.test_persistence_word2vec_format(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_hs_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_neg_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_neg_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_neg_training_fromfile(self)
gensim.test.test_fasttext.TestFastTextModel.test_similarity(self)
gensim.test.test_fasttext.TestFastTextModel.test_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_training_fromfile(self)
gensim.test.test_fasttext.TestFastTextModel.test_vectors_for_all_with_inference(self)
gensim.test.test_fasttext.TestFastTextModel.test_vectors_for_all_without_inference(self)
gensim.test.test_fasttext.TestFastTextModel.test_wm_distance(self)
gensim.test.test_fasttext.TestFromfile(unittest.TestCase)
gensim.test.test_fasttext.TestFromfile._run(self,fin)
gensim.test.test_fasttext.TestFromfile.test_compressed(self)
gensim.test.test_fasttext.TestFromfile.test_decompressed(self)
gensim.test.test_fasttext.UnicodeVocabTest(unittest.TestCase)
gensim.test.test_fasttext.UnicodeVocabTest.test_ascii(self)
gensim.test.test_fasttext.UnicodeVocabTest.test_bad_unicode(self)
gensim.test.test_fasttext.UnpackTest(unittest.TestCase)
gensim.test.test_fasttext.UnpackTest.test_identity(self)
gensim.test.test_fasttext.UnpackTest.test_sanity(self)
gensim.test.test_fasttext.UnpackTest.test_tricky(self)
gensim.test.test_fasttext.ZeroBucketTest(unittest.TestCase)
gensim.test.test_fasttext.ZeroBucketTest.test_cbow_neg(self)
gensim.test.test_fasttext.ZeroBucketTest.test_in_vocab(self)
gensim.test.test_fasttext.ZeroBucketTest.test_out_of_vocab(self)
gensim.test.test_fasttext._create_and_save_fb_model(fname,model_params)
gensim.test.test_fasttext._read_binary_file(fname)
gensim.test.test_fasttext._read_fb(fin)
gensim.test.test_fasttext._read_wordvectors_using_fasttext(fasttext_fname,words)
gensim.test.test_fasttext._save_test_model(out_base_fname,model_params)
gensim.test.test_fasttext._train_model_with_pretrained_vectors()
gensim.test.test_fasttext.calc_max_diff(v1,v2)
gensim.test.test_fasttext.compare_nn(a,b,t)
gensim.test.test_fasttext.compare_vocabulary(a,b,t)
gensim.test.test_fasttext.compare_wv(a,b,t)
gensim.test.test_fasttext.hash_main(alg)
gensim.test.test_fasttext.load_native()
gensim.test.test_fasttext.load_vec(fin)
gensim.test.test_fasttext.ngram_main()
gensim.test.test_fasttext.test_cbow_hs_training(shrink_windows)
gensim.test.test_fasttext.test_cbow_hs_training_fromfile(shrink_windows)
gensim.test.test_fasttext.test_sg_hs_training(shrink_windows)
gensim.test.test_fasttext.test_sg_hs_training_fromfile(shrink_windows)
gensim.test.test_fasttext.train_gensim(bucket=100,min_count=5)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_nmf.py----------------------------------------
A:gensim.test.test_nmf.self.model->gensim.models.nmf.Nmf(common_corpus, id2word=common_dictionary, chunksize=1, num_topics=2, passes=100, random_state=42)
A:gensim.test.test_nmf.model_1->gensim.models.nmf.Nmf(common_corpus, id2word=common_dictionary, chunksize=1, num_topics=2, passes=100, random_state=42)
A:gensim.test.test_nmf.model_2->gensim.models.nmf.Nmf(common_corpus, id2word=common_dictionary, chunksize=1, num_topics=2, passes=100, random_state=0)
A:gensim.test.test_nmf.model->gensim.models.nmf.Nmf.load(nmf_fname)
A:gensim.test.test_nmf.vec->gensim.matutils.sparse2full(transformed, 2)
A:gensim.test.test_nmf.transformed->self.model.get_term_topics(word)
A:gensim.test.test_nmf.top_topics->self.model.top_topics(common_corpus)
A:gensim.test.test_nmf.topic_terms->self.model.get_topic_terms(1)
A:gensim.test.test_nmf.doc_topics->self.model.get_document_topics(common_corpus)
A:gensim.test.test_nmf.all_topics->self.model.get_document_topics(common_corpus)
A:gensim.test.test_nmf.result->self.model.get_term_topics(str(self.model.id2word[2]))
A:gensim.test.test_nmf.fname->get_tmpfile('gensim_models_nmf.tst.gz')
A:gensim.test.test_nmf.model2->gensim.models.nmf.Nmf.load(fname, mmap='r')
A:gensim.test.test_nmf.nmf_fname->datapath('nmf_model')
gensim.test.test_nmf.TestNmf(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_nmf.TestNmf.setUp(self)
gensim.test.test_nmf.TestNmf.test_dtype_backward_compatibility(self)
gensim.test.test_nmf.TestNmf.test_generator(self)
gensim.test.test_nmf.TestNmf.test_get_document_topics(self)
gensim.test.test_nmf.TestNmf.test_get_topic_terms(self)
gensim.test.test_nmf.TestNmf.test_large_mmap(self)
gensim.test.test_nmf.TestNmf.test_large_mmap_compressed(self)
gensim.test.test_nmf.TestNmf.test_persistence(self)
gensim.test.test_nmf.TestNmf.test_random_state(self)
gensim.test.test_nmf.TestNmf.test_term_topics(self)
gensim.test.test_nmf.TestNmf.test_top_topics(self)
gensim.test.test_nmf.TestNmf.test_transform(self)
gensim.test.test_nmf.TestNmf.test_update(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_direct_confirmation.py----------------------------------------
A:gensim.test.test_direct_confirmation.dictionary->namedtuple('Dictionary', 'token2id, id2token')(token2id, id2token)
A:gensim.test.test_direct_confirmation.self.accumulator->gensim.topic_coherence.text_analysis.InvertedIndexAccumulator({1, 2}, dictionary)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure(unittest.TestCase)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.setUp(self)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.test_log_conditional_probability(self)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.test_log_ratio_measure(self)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.test_normalized_log_ratio_measure(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_scripts.py----------------------------------------
A:gensim.test.test_scripts.self.fname->datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')
A:gensim.test.test_scripts.fname->get_tmpfile('script.tst')
A:gensim.test.test_scripts.(title, sections, interlinks)->next(segment_all_articles(self.fname, include_interlinks=True))
A:gensim.test.test_scripts.num_articles->sum((1 for line in f))
A:gensim.test.test_scripts.tmpf->get_tmpfile('script.tst.json')
A:gensim.test.test_scripts.first->next(f)
A:gensim.test.test_scripts.article->json.loads(first)
A:gensim.test.test_scripts.self.datapath->datapath('word2vec_pre_kv_c')
A:gensim.test.test_scripts.self.output_folder->get_tmpfile('w2v2t_test')
A:gensim.test.test_scripts.metadata->f.readlines()
A:gensim.test.test_scripts.vectors->f.readlines()
A:gensim.test.test_scripts.first_line->f.readline().strip()
A:gensim.test.test_scripts.(number_words, vector_size)->map(int, first_line.split(b' '))
A:gensim.test.test_scripts.orig_model->gensim.models.KeyedVectors.load_word2vec_format(self.datapath, binary=False)
A:gensim.test.test_scripts.word_string->word.decode('utf8')
A:gensim.test.test_scripts.vector_string->vector.decode('utf8')
A:gensim.test.test_scripts.vector_array->numpy.array(list(map(float, vector_string.split())))
gensim.test.test_scripts.TestSegmentWiki(unittest.TestCase)
gensim.test.test_scripts.TestSegmentWiki.setUp(self)
gensim.test.test_scripts.TestSegmentWiki.tearDown(self)
gensim.test.test_scripts.TestSegmentWiki.test_generator_len(self)
gensim.test.test_scripts.TestSegmentWiki.test_json_len(self)
gensim.test.test_scripts.TestSegmentWiki.test_segment_all_articles(self)
gensim.test.test_scripts.TestSegmentWiki.test_segment_and_write_all_articles(self)
gensim.test.test_scripts.TestWord2Vec2Tensor(unittest.TestCase)
gensim.test.test_scripts.TestWord2Vec2Tensor.setUp(self)
gensim.test.test_scripts.TestWord2Vec2Tensor.test_conversion(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/basetmtests.py----------------------------------------
A:gensim.test.basetmtests.topics->self.model.get_topics()
A:gensim.test.basetmtests.topic->self.model.show_topic(1)
A:gensim.test.basetmtests.vocab_size->len(self.model.id2word)
gensim.test.basetmtests.TestBaseTopicModel
gensim.test.basetmtests.TestBaseTopicModel.test_get_topics(self)
gensim.test.basetmtests.TestBaseTopicModel.test_print_topic(self)
gensim.test.basetmtests.TestBaseTopicModel.test_print_topics(self)
gensim.test.basetmtests.TestBaseTopicModel.test_show_topic(self)
gensim.test.basetmtests.TestBaseTopicModel.test_show_topics(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_poincare.py----------------------------------------
A:gensim.test.test_poincare.logger->logging.getLogger(__name__)
A:gensim.test.test_poincare.non_utf8_file->datapath('poincare_cp852.tsv')
A:gensim.test.test_poincare.utf8_file->datapath('poincare_utf8.tsv')
A:gensim.test.test_poincare.self.data->PoincareRelations(datapath('poincare_hypernyms.tsv'))
A:gensim.test.test_poincare.self.data_large->PoincareRelations(datapath('poincare_hypernyms_large.tsv'))
A:gensim.test.test_poincare.model->PoincareModel(self.data_large, negative=3)
A:gensim.test.test_poincare.loaded->gensim.models.poincare.PoincareModel.load(datapath('poincare_test_3.4.0'))
A:gensim.test.test_poincare.old_vectors->numpy.copy(model.kv.vectors)
A:gensim.test.test_poincare.model._loss_grad->Mock(return_value=np.zeros((2 + model.negative, model.size)))
A:gensim.test.test_poincare.model_1->PoincareModel(self.data_large, seed=1, negative=3, burn_in=1)
A:gensim.test.test_poincare.model_2->PoincareModel(self.data_large, seed=1, negative=3, burn_in=1)
A:gensim.test.test_poincare.original_vectors->numpy.copy(model.kv.vectors)
A:gensim.test.test_poincare.negatives->PoincareModel(self.data_large, negative=3)._sample_negatives(0)
A:gensim.test.test_poincare.vector_updates->numpy.array([[0.5, 0.5], [0.1, 0.2], [0.3, -0.2]])
A:gensim.test.test_poincare.vector_updates_expected->numpy.array([[0.0, 0.0], [0.1, 0.2], [0.8, 0.3]])
A:gensim.test.test_poincare.self.vectors->gensim.models.poincare.PoincareKeyedVectors.load_word2vec_format(datapath('poincare_vectors.bin'), binary=True)
A:gensim.test.test_poincare.predicted->self.vectors.most_similar_to_given('dog.n.01', ['carnivore.n.01', 'placental.n.01', 'mammal.n.01'])
A:gensim.test.test_poincare.expected->set(['canine.n.02', 'hunting_dog.n.01'])
A:gensim.test.test_poincare.distances->self.vectors.vector_distance_batch(vector_1, vectors_2)
A:gensim.test.test_poincare.distance->self.vectors.vector_distance(vector_1, vector_1)
gensim.test.test_poincare.TestPoincareData(unittest.TestCase)
gensim.test.test_poincare.TestPoincareData.test_encoding_handling(self)
gensim.test.test_poincare.TestPoincareKeyedVectors(unittest.TestCase)
gensim.test.test_poincare.TestPoincareKeyedVectors.norm(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.setUp(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_ancestors(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_closer_than(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_closest_child(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_closest_parent(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_descendants(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_difference_in_hierarchy(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_distance(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_distances(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_distances_with_vector_input(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_raises_keyerror(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_restrict_vocab(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_to_given(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_topn(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_with_vector_input(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_poincare_distance(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_poincare_distances_batch(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_rank(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_similarity(self)
gensim.test.test_poincare.TestPoincareModel(unittest.TestCase)
gensim.test.test_poincare.TestPoincareModel.models_equal(self,model_1,model_2)
gensim.test.test_poincare.TestPoincareModel.setUp(self)
gensim.test.test_poincare.TestPoincareModel.tearDownClass(cls)
gensim.test.test_poincare.TestPoincareModel.test_burn_in(self)
gensim.test.test_poincare.TestPoincareModel.test_burn_in_only_done_once(self)
gensim.test.test_poincare.TestPoincareModel.test_data_counts(self)
gensim.test.test_poincare.TestPoincareModel.test_data_counts_with_bytes(self)
gensim.test.test_poincare.TestPoincareModel.test_error_if_negative_more_than_population(self)
gensim.test.test_poincare.TestPoincareModel.test_gradients_check(self)
gensim.test.test_poincare.TestPoincareModel.test_handle_duplicates(self)
gensim.test.test_poincare.TestPoincareModel.test_invalid_data_raises_error(self)
gensim.test.test_poincare.TestPoincareModel.test_negatives(self)
gensim.test.test_poincare.TestPoincareModel.test_no_duplicates_and_positives_in_negative_sample(self)
gensim.test.test_poincare.TestPoincareModel.test_online_learning(self)
gensim.test.test_poincare.TestPoincareModel.test_persistence(self)
gensim.test.test_poincare.TestPoincareModel.test_persistence_old_model(self)
gensim.test.test_poincare.TestPoincareModel.test_persistence_separate_file(self)
gensim.test.test_poincare.TestPoincareModel.test_reproducible(self)
gensim.test.test_poincare.TestPoincareModel.test_train_after_load(self)
gensim.test.test_poincare.TestPoincareModel.test_train_old_model_after_load(self)
gensim.test.test_poincare.TestPoincareModel.test_training(self)
gensim.test.test_poincare.TestPoincareModel.test_training_multiple(self)
gensim.test.test_poincare.TestPoincareModel.test_vector_dtype(self)
gensim.test.test_poincare.TestPoincareModel.test_vector_shape(self)
gensim.test.test_poincare.TestPoincareModel.test_wrong_gradients_raises_assertion(self)
gensim.test.test_poincare.testfile()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_sharded_corpus.py----------------------------------------
A:gensim.test.test_sharded_corpus.self.random_string->''.join((random.choice('1234567890') for _ in range(8)))
A:gensim.test.test_sharded_corpus.self.tmp_fname->os.path.join(self.tmp_dir, 'shcorp.' + self.random_string + '.tmp')
A:gensim.test.test_sharded_corpus.self.data->mock_data(dim=1000)
A:gensim.test.test_sharded_corpus.self.corpus->ShardedCorpus(self.tmp_fname, self.data, dim=self.dim, shardsize=100)
A:gensim.test.test_sharded_corpus.loaded_corpus->gensim.corpora.sharded_corpus.ShardedCorpus.load(self.tmp_fname)
A:gensim.test.test_sharded_corpus.corpus->ShardedCorpus(gen_tmp_fname, data_generator(), dim=2)
A:gensim.test.test_sharded_corpus.dense_corpus->ShardedCorpus(self.tmp_fname, self.data, shardsize=100, dim=self.dim, sparse_serialization=False, sparse_retrieval=False)
A:gensim.test.test_sharded_corpus.expected_nnz->sum((len(self.data[i]) for i in range(2, 6)))
A:gensim.test.test_sharded_corpus.dslice->list(dslice)
A:gensim.test.test_sharded_corpus.(iscorp, _)->is_corpus(ilist)
A:gensim.test.test_sharded_corpus.ilist->list(ilist)
A:gensim.test.test_sharded_corpus.dataset->ShardedCorpus(self.tmp_fname, self.data, shardsize=100, dim=self.dim)
A:gensim.test.test_sharded_corpus.fname->ShardedCorpus(self.tmp_fname, self.data, shardsize=100, dim=self.dim)._shard_name(n)
A:gensim.test.test_sharded_corpus.suite->unittest.TestSuite()
A:gensim.test.test_sharded_corpus.loader->unittest.TestLoader()
A:gensim.test.test_sharded_corpus.tests->unittest.TestLoader().loadTestsFromTestCase(TestShardedCorpus)
A:gensim.test.test_sharded_corpus.runner->unittest.TextTestRunner()
gensim.test.test_sharded_corpus.TestShardedCorpus(unittest.TestCase)
gensim.test.test_sharded_corpus.TestShardedCorpus.setUp(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.tearDown(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_dense2dense(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_dense2gensim(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_dense2sparse(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_sparse2dense(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_sparse2sparse(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_init(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_init_with_generator(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_load(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_resize(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_sparse_serialization(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_api.py----------------------------------------
A:gensim.test.test_api.dataset_path->os.path.join(api.BASE_DIR, '__testing_multipart-matrix-synopsis', '__testing_multipart-matrix-synopsis.gz')
A:gensim.test.test_api.vector_dead->numpy.array([0.17403787, -0.10167074, -0.00950371, -0.10367849, -0.14034484, -0.08751217, 0.10030612, 0.07677923, -0.32563496, 0.01929072, 0.20521086, -0.1617067, 0.00475458, 0.21956187, -0.08783089, -0.05937332, 0.26528183, -0.06771874, -0.12369668, 0.12020949, 0.28731, 0.36735833, 0.28051138, -0.10407482, 0.2496888, -0.19372769, -0.28719661, 0.11989869, -0.00393865, -0.2431484, 0.02725661, -0.20421691, 0.0328669, -0.26947051, -0.08068217, -0.10245913, 0.1170633, 0.16583319, 0.1183883, -0.11217165, 0.1261425, -0.0319365, -0.15787181, 0.03753783, 0.14748634, 0.00414471, -0.02296237, 0.18336892, -0.23840059, 0.17924534])
A:gensim.test.test_api.model->gensim.downloader.load('__testing_word2vec-matrix-synopsis')
A:gensim.test.test_api.dataset->gensim.downloader.load('__testing_multipart-matrix-synopsis')
A:gensim.test.test_api.data->gensim.downloader.info()
A:gensim.test.test_api.name_only_data->gensim.downloader.info(name_only=True)
gensim.test.test_api.TestApi(unittest.TestCase)
gensim.test.test_api.TestApi.test_base_dir_creation(self)
gensim.test.test_api.TestApi.test_info(self)
gensim.test.test_api.TestApi.test_load_dataset(self)
gensim.test.test_api.TestApi.test_load_model(self)
gensim.test.test_api.TestApi.test_multipart_load(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_aggregation.py----------------------------------------
A:gensim.test.test_aggregation.obtained->gensim.topic_coherence.aggregation.arithmetic_mean(self.confirmed_measures)
gensim.test.test_aggregation.TestAggregation(unittest.TestCase)
gensim.test.test_aggregation.TestAggregation.setUp(self)
gensim.test.test_aggregation.TestAggregation.test_arithmetic_mean(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_text_analysis.py----------------------------------------
A:gensim.test.test_text_analysis.dictionary->Dictionary(texts)
A:gensim.test.test_text_analysis.top_ids->set(token2id.values())
A:gensim.test.test_text_analysis.dictionary2->Dictionary(texts2)
A:gensim.test.test_text_analysis.top_ids2->set(dictionary2.token2id.values())
A:gensim.test.test_text_analysis.accumulator->CorpusAccumulator(self.top_ids).accumulate(self.corpus)
A:gensim.test.test_text_analysis.inverted_index->CorpusAccumulator(self.top_ids).accumulate(self.corpus).index_to_dict()
gensim.test.test_text_analysis.BaseTestCases
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase(unittest.TestCase)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.init_accumulator(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.init_accumulator2(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.test_occurences_for_irrelevant_words(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.test_occurrence_counting(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.test_occurrence_counting2(self)
gensim.test.test_text_analysis.TestCorpusAnalyzer(unittest.TestCase)
gensim.test.test_text_analysis.TestCorpusAnalyzer.setUp(self)
gensim.test.test_text_analysis.TestCorpusAnalyzer.test_index_accumulation(self)
gensim.test.test_text_analysis.TestInvertedIndexAccumulator(BaseTestCases.TextAnalyzerTestBase)
gensim.test.test_text_analysis.TestInvertedIndexAccumulator.test_accumulate1(self)
gensim.test.test_text_analysis.TestInvertedIndexAccumulator.test_accumulate2(self)
gensim.test.test_text_analysis.TestParallelWordOccurrenceAccumulator(BaseTestCases.TextAnalyzerTestBase)
gensim.test.test_text_analysis.TestParallelWordOccurrenceAccumulator.init_accumulator(self)
gensim.test.test_text_analysis.TestParallelWordOccurrenceAccumulator.init_accumulator2(self)
gensim.test.test_text_analysis.TestWordOccurrenceAccumulator(BaseTestCases.TextAnalyzerTestBase)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/simspeed.py----------------------------------------
A:gensim.test.simspeed.program->os.path.basename(sys.argv[0])
A:gensim.test.simspeed.corpus_dense->list(itertools.islice(corpus_dense, NUMDOCS))
A:gensim.test.simspeed.corpus_sparse->list(itertools.islice(corpus_sparse, NUMDOCS))
A:gensim.test.simspeed.NUMDOCS->int(sys.argv[3])
A:gensim.test.simspeed.index_dense->gensim.similarities.MatrixSimilarity(corpus_dense)
A:gensim.test.simspeed.index_sparse->gensim.similarities.SparseMatrixSimilarity(corpus_sparse, num_terms=NUMTERMS)
A:gensim.test.simspeed.query->list(itertools.islice(corpus_sparse, 1000))
A:gensim.test.simspeed.start->time()
A:gensim.test.simspeed.queries->math.ceil(1.0 * len(corpus_sparse) / chunksize)
A:gensim.test.simspeed.sims->list(index_sparse)
A:gensim.test.simspeed.diff->gensim.matutils.mean_absolute_difference(unchunksizeed, sims)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/simspeed2.py----------------------------------------
A:gensim.test.simspeed2.program->os.path.basename(sys.argv[0])
A:gensim.test.simspeed2.corpus_dense->list(itertools.islice(corpus_dense, NUMDOCS))
A:gensim.test.simspeed2.corpus_sparse->list(itertools.islice(corpus_sparse, NUMDOCS))
A:gensim.test.simspeed2.NUMDOCS->int(sys.argv[3])
A:gensim.test.simspeed2.index_dense->gensim.similarities.Similarity('/tmp/tstdense', corpus_dense, dense_features)
A:gensim.test.simspeed2.index_sparse->gensim.similarities.Similarity('/tmp/tstsparse', corpus_sparse, sparse_features)
A:gensim.test.simspeed2.start->time()
A:gensim.test.simspeed2.queries->math.ceil(1.0 * len(query) / chunksize)
A:gensim.test.simspeed2.query->list(itertools.islice(corpus_dense, 1000))


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_lda_callback.py----------------------------------------
A:gensim.test.test_lda_callback.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_lda_callback.self.ch_umass->CoherenceMetric(corpus=self.corpus, coherence='u_mass', logger='visdom', title='Coherence')
A:gensim.test.test_lda_callback.self.model->LdaModel(id2word=common_dictionary, num_topics=2, passes=10, callbacks=self.callback)
A:gensim.test.test_lda_callback.viz->Visdom(server=self.host, port=self.port)
gensim.test.test_lda_callback.TestLdaCallback(unittest.TestCase)
gensim.test.test_lda_callback.TestLdaCallback.setUp(self)
gensim.test.test_lda_callback.TestLdaCallback.test_callback_update_graph(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_logentropy_model.py----------------------------------------
A:gensim.test.test_logentropy_model.self.corpus_small->MmCorpus(datapath('test_corpus_small.mm'))
A:gensim.test.test_logentropy_model.self.corpus_ok->MmCorpus(datapath('test_corpus_ok.mm'))
A:gensim.test.test_logentropy_model.model->gensim.models.logentropy_model.LogEntropyModel(self.corpus_ok, normalize=True)
A:gensim.test.test_logentropy_model.fname->get_tmpfile('gensim_models_logentry.tst.gz')
A:gensim.test.test_logentropy_model.model2->gensim.models.logentropy_model.LogEntropyModel.load(fname, mmap=None)
gensim.test.test_logentropy_model.TestLogEntropyModel(unittest.TestCase)
gensim.test.test_logentropy_model.TestLogEntropyModel.setUp(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.test_empty_fail(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.test_generator_fail(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.test_persistence(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.test_persistence_compressed(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.test_transform(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_atmodel.py----------------------------------------
A:gensim.test.test_atmodel.dictionary_new->Dictionary(texts_new)
A:gensim.test.test_atmodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_atmodel.self.model->self.class_(corpus, id2word=dictionary, author2doc=author2doc, num_topics=2, passes=100)
A:gensim.test.test_atmodel.model->self.class_.load(atmodel_3_0_1_fname)
A:gensim.test.test_atmodel.jill_topics->gensim.matutils.sparse2full(jill_topics, model.num_topics)
A:gensim.test.test_atmodel.vec->gensim.matutils.sparse2full(jill_topics, 2)
A:gensim.test.test_atmodel.passed->numpy.allclose(sorted(vec), sorted(expected), atol=0.1)
A:gensim.test.test_atmodel.dictionary->Dictionary(local_texts)
A:gensim.test.test_atmodel.a2d->author2doc.copy()
A:gensim.test.test_atmodel.model2->self.class_.load(fname, mmap='r')
A:gensim.test.test_atmodel.jill_topics2->gensim.matutils.sparse2full(jill_topics2, model.num_topics)
A:gensim.test.test_atmodel.sally_topics->gensim.matutils.sparse2full(sally_topics, model.num_topics)
A:gensim.test.test_atmodel.model1->self.class_(corpus, author2doc=author2doc, id2word=dictionary, eta='symmetric', passes=10, num_topics=2)
A:gensim.test.test_atmodel.modelauto->self.class_(corpus, author2doc=author2doc, id2word=dictionary, eta='auto', passes=10, num_topics=2)
A:gensim.test.test_atmodel.kwargs->dict(author2doc=author2doc, id2word=dictionary, num_topics=2, eta=None)
A:gensim.test.test_atmodel.kwargs['alpha']->numpy.array([0.3, 0.3])
A:gensim.test.test_atmodel.num_terms->len(dictionary)
A:gensim.test.test_atmodel.kwargs['eta']->numpy.array([[0.5] * len(dictionary)] * 2).reshape(tuple(reversed(testeta.shape)))
A:gensim.test.test_atmodel.testeta->numpy.array([[0.5] * len(dictionary)] * 2)
A:gensim.test.test_atmodel.top_topics->self.model.top_topics(corpus)
A:gensim.test.test_atmodel.topic_terms->self.model.get_topic_terms(1)
A:gensim.test.test_atmodel.result->self.class_.load(atmodel_3_0_1_fname).get_term_topics(str(model.id2word[2]))
A:gensim.test.test_atmodel.state_gamma_len->len(model.state.gamma)
A:gensim.test.test_atmodel.author2doc_len->len(model.author2doc)
A:gensim.test.test_atmodel.author2id_len->len(model.author2id)
A:gensim.test.test_atmodel.id2author_len->len(model.id2author)
A:gensim.test.test_atmodel.doc2author_len->len(model.doc2author)
A:gensim.test.test_atmodel.new_author_topics->self.class_.load(atmodel_3_0_1_fname).get_new_author_topics(corpus=corpus[0:2])
A:gensim.test.test_atmodel.msg->'{}, {}, {}'.format(passes, model.num_updates, model.state.numdocs)
A:gensim.test.test_atmodel.fname->get_tmpfile('gensim_models_atmodel.tst.gz')
A:gensim.test.test_atmodel.atmodel_3_0_1_fname->datapath('atmodel_3_0_1_model')
gensim.test.test_atmodel.TestAuthorTopicModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_atmodel.TestAuthorTopicModel.setUp(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_alpha(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_alpha_auto(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_author2doc_missing(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_basic(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_doc2author_missing(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_dtype_backward_compatibility(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_empty_document(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_eta(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_eta_auto(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_get_author_topics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_get_topic_terms(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_large_mmap(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_large_mmap_compressed(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_new_author_topics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_passes(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_persistence(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_persistence_compressed(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_persistence_ignore(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_serialized(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_term_topics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_top_topics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_transform(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_transform_serialized(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_update(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_update_new_data_new_author(self)
gensim.test.test_atmodel.TestAuthorTopicModel.test_update_new_data_old_author(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_big.py----------------------------------------
A:gensim.test.test_big.self.dictionary->gensim.utils.FakeDict(num_terms)
A:gensim.test.test_big.doc_len->numpy.random.poisson(self.doc_len)
A:gensim.test.test_big.ids->numpy.random.randint(0, len(self.dictionary), doc_len)
A:gensim.test.test_big.weights->numpy.random.poisson(3, doc_len)
A:gensim.test.test_big.corpus->BigCorpus(num_docs=5000)
A:gensim.test.test_big.tmpf->get_tmpfile('gensim_big.tst')
A:gensim.test.test_big.model->gensim.models.LdaModel(corpus, num_topics=500, id2word=corpus.dictionary)
gensim.test.test_big.BigCorpus(self,words_only=False,num_terms=200000,num_docs=1000000,doc_len=100)
gensim.test.test_big.BigCorpus.__init__(self,words_only=False,num_terms=200000,num_docs=1000000,doc_len=100)
gensim.test.test_big.BigCorpus.__iter__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_lsimodel.py----------------------------------------
A:gensim.test.test_lsimodel.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_lsimodel.self.model->gensim.models.lsimodel.LsiModel(self.corpus, num_topics=2)
A:gensim.test.test_lsimodel.(u, s, vt)->scipy.linalg.svd(matutils.corpus2dense(self.corpus, self.corpus.num_terms), full_matrices=False)
A:gensim.test.test_lsimodel.vec->gensim.matutils.sparse2full(transformed, model.num_topics)
A:gensim.test.test_lsimodel.expected->numpy.array([-0.66493785, -0.28314203, -1.56376302, 0.05488682, 0.17123269])
A:gensim.test.test_lsimodel.model->gensim.models.lsimodel.LsiModel(corpus=None, id2word=model2.id2word, num_topics=5)
A:gensim.test.test_lsimodel.got->numpy.vstack([matutils.sparse2full(doc, 2) for doc in model[self.corpus]])
A:gensim.test.test_lsimodel.corpus->list(self.corpus)
A:gensim.test.test_lsimodel.model2->gensim.models.lsimodel.LsiModel.load(fname, mmap='r')
A:gensim.test.test_lsimodel.vec1->gensim.matutils.sparse2full(model[doc], model.num_topics)
A:gensim.test.test_lsimodel.vec2->gensim.matutils.sparse2full(model2[doc], model2.num_topics)
A:gensim.test.test_lsimodel.fname->get_tmpfile('gensim_models_lsi.tst.gz')
A:gensim.test.test_lsimodel.topics->self.model.get_topics()
A:gensim.test.test_lsimodel.vocab_size->len(self.model.id2word)
gensim.test.test_lsimodel.TestLsiModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_lsimodel.TestLsiModel.setUp(self)
gensim.test.test_lsimodel.TestLsiModel.test_corpus_transform(self)
gensim.test.test_lsimodel.TestLsiModel.test_docs_processed(self)
gensim.test.test_lsimodel.TestLsiModel.test_get_topics(self)
gensim.test.test_lsimodel.TestLsiModel.test_large_mmap(self)
gensim.test.test_lsimodel.TestLsiModel.test_large_mmap_compressed(self)
gensim.test.test_lsimodel.TestLsiModel.test_online_transform(self)
gensim.test.test_lsimodel.TestLsiModel.test_persistence(self)
gensim.test.test_lsimodel.TestLsiModel.test_persistence_compressed(self)
gensim.test.test_lsimodel.TestLsiModel.test_transform(self)
gensim.test.test_lsimodel.TestLsiModel.test_transform_float32(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_glove2word2vec.py----------------------------------------
A:gensim.test.test_glove2word2vec.self.datapath->datapath('test_glove.txt')
A:gensim.test.test_glove2word2vec.self.output_file->get_tmpfile('glove2word2vec.test')
A:gensim.test.test_glove2word2vec.self.test_model->gensim.models.KeyedVectors.load_word2vec_format(self.output_file)
gensim.test.test_glove2word2vec.TestGlove2Word2Vec(unittest.TestCase)
gensim.test.test_glove2word2vec.TestGlove2Word2Vec.setUp(self)
gensim.test.test_glove2word2vec.TestGlove2Word2Vec.test_conversion(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_corpora_dictionary.py----------------------------------------
A:gensim.test.test_corpora_dictionary.d->Dictionary(texts)
A:gensim.test.test_corpora_dictionary.expected_keys->sorted(['computer', 'eps', 'graph', 'human', 'interface', 'minors', 'response', 'survey', 'system', 'time', 'trees', 'user'])
A:gensim.test.test_corpora_dictionary.expected_values->list(range(12))
A:gensim.test.test_corpora_dictionary.f->Dictionary(self.texts[:3])
A:gensim.test.test_corpora_dictionary.g->Dictionary(self.texts[3:])
A:gensim.test.test_corpora_dictionary.expected[removed_word]->len(expected)
A:gensim.test.test_corpora_dictionary.tmpf->get_tmpfile('dict_test.txt')
A:gensim.test.test_corpora_dictionary.serialized_lines->file.readlines()
A:gensim.test.test_corpora_dictionary.no_num_docs_serialization->to_utf8('2\n1\tprv\t1\n2\tslovo\t2\n')
A:gensim.test.test_corpora_dictionary.d_loaded->gensim.corpora.Dictionary.load_from_text(tmpf)
A:gensim.test.test_corpora_dictionary.stoplist->set('for a of the and to in'.split())
A:gensim.test.test_corpora_dictionary.all_tokens->list(chain.from_iterable(texts))
A:gensim.test.test_corpora_dictionary.tokens_once->set((word for word in set(all_tokens) if all_tokens.count(word) == 1))
A:gensim.test.test_corpora_dictionary.dictionary->gensim.corpora.Dictionary.from_corpus(bow)
A:gensim.test.test_corpora_dictionary.dictionary_from_corpus->gensim.corpora.Dictionary.from_corpus(corpus)
A:gensim.test.test_corpora_dictionary.dict_token2id_vals->sorted(dictionary.token2id.values())
A:gensim.test.test_corpora_dictionary.dict_from_corpus_vals->sorted(dictionary_from_corpus.token2id.values())
A:gensim.test.test_corpora_dictionary.dictionary_from_corpus_2->gensim.corpora.Dictionary.from_corpus(corpus, id2word=dictionary)
A:gensim.test.test_corpora_dictionary.bow->gensim.matutils.Sparse2Corpus(scipy.sparse.rand(10, 100))
gensim.test.test_corpora_dictionary.TestDictionary(unittest.TestCase)
gensim.test.test_corpora_dictionary.TestDictionary.setUp(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_keepTokens(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_keepn(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_unchangedFunctionality(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_unseenToken(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_build(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_dict_interface(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_doc2bow(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_doc_freq_and_collection_freq(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_doc_freq_and_token2id_for_several_docs_with_one_word(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_doc_freq_for_one_doc_with_several_word(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_doc_freq_one_doc(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_filter(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_filter_most_frequent(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_filter_tokens(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_from_corpus(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_loadFromText(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_loadFromText_legacy(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_merge(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_most_common_with_n(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_most_common_without_n(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_patch_with_special_tokens(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_saveAsText(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_saveAsText_and_loadFromText(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_tmdiff.py----------------------------------------
A:gensim.test.test_tmdiff.self.model->LdaModel(corpus=self.corpus, id2word=self.dictionary, num_topics=self.num_topics, passes=10)
A:gensim.test.test_tmdiff.(mdiff, annotation)->self.model.diff(self.model, n_ann_terms=self.n_ann_terms, distance=dist_name, diagonal=True)
gensim.test.test_tmdiff.TestLdaDiff(unittest.TestCase)
gensim.test.test_tmdiff.TestLdaDiff.setUp(self)
gensim.test.test_tmdiff.TestLdaDiff.test_basic(self)
gensim.test.test_tmdiff.TestLdaDiff.test_identity(self)
gensim.test.test_tmdiff.TestLdaDiff.test_input(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/svd_error.py----------------------------------------
A:gensim.test.svd_error.program->os.path.basename(sys.argv[0])
A:gensim.test.svd_error.mm->gensim.corpora.MmCorpus(fname)
A:gensim.test.svd_error.n->int(sys.argv[2])
A:gensim.test.svd_error.m->int(sys.argv[3])
A:gensim.test.svd_error.corpus->ClippedCorpus(mm, n, m)
A:gensim.test.svd_error.id2word->gensim.utils.FakeDict(m)
A:gensim.test.svd_error.aat->aat.astype(np.float32).astype(np.float32)
A:gensim.test.svd_error.num_nnz->sum((len(doc) for doc in chunk))
A:gensim.test.svd_error.chunk->chunk.toarray().toarray()
A:gensim.test.svd_error.(spectrum_s, spectrum_u)->scipy.linalg.eigh(aat)
A:gensim.test.svd_error.ideal_fro->numpy.linalg.norm(err)
A:gensim.test.svd_error.taken->time.time()
A:gensim.test.svd_error.corpus_ram->gensim.matutils.corpus2csc(corpus, num_terms=m)
A:gensim.test.svd_error.(ut, s, vt)->sparsesvd(corpus_ram, factors)
A:gensim.test.svd_error.model->gensim.models.LsiModel(corpus, id2word=id2word, num_topics=factors, chunksize=2000, onepass=False, power_iters=power_iters)
gensim.test.svd_error.ClippedCorpus(self,corpus,max_docs,max_terms)
gensim.test.svd_error.ClippedCorpus.__init__(self,corpus,max_docs,max_terms)
gensim.test.svd_error.ClippedCorpus.__iter__(self)
gensim.test.svd_error.norm2(a)
gensim.test.svd_error.print_error(name,aat,u,s,ideal_nf,ideal_n2)
gensim.test.svd_error.rmse(diff)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/test/test_keyedvectors.py----------------------------------------
A:gensim.test.test_keyedvectors.logger->logging.getLogger(__name__)
A:gensim.test.test_keyedvectors.self.vectors->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(datapath('euclidean_vectors.bin'), binary=True)
A:gensim.test.test_keyedvectors.self.model_path->datapath('w2v_keyedvectors_load_test.modeldata')
A:gensim.test.test_keyedvectors.self.vocab_path->datapath('w2v_keyedvectors_load_test.vocab')
A:gensim.test.test_keyedvectors.most_similar->self.vectors.most_similar(positive=positive)
A:gensim.test.test_keyedvectors.partial->functools.partial(self.vectors.most_similar_cosmul, topn=5)
A:gensim.test.test_keyedvectors.position->partial('war', 'peace')
A:gensim.test.test_keyedvectors.position_list->partial(['war'], ['peace'])
A:gensim.test.test_keyedvectors.keyword->partial(positive='war', negative='peace')
A:gensim.test.test_keyedvectors.keyword_list->partial(positive=['war'], negative=['peace'])
A:gensim.test.test_keyedvectors.vectors_for_all->self.vectors.vectors_for_all(words, copy_vecattrs=False)
A:gensim.test.test_keyedvectors.predicted->self.vectors.most_similar_to_given('war', ['terrorism', 'call', 'waging'])
A:gensim.test.test_keyedvectors.expected->set(['conflict', 'administration'])
A:gensim.test.test_keyedvectors.not_expected->self.vectors.get_vecattr('conflict', 'count')
A:gensim.test.test_keyedvectors.cos_sim->sorted(cos_sim, reverse=True)
A:gensim.test.test_keyedvectors.rcs->self.vectors.relative_cosine_similarity('good', 'worst', 10)
A:gensim.test.test_keyedvectors.kv->KeyedVectors(2)
A:gensim.test.test_keyedvectors.vocab_size->len(self.vectors)
A:gensim.test.test_keyedvectors.vector->numpy.random.randn(self.vectors.vector_size)
A:gensim.test.test_keyedvectors.model->gensim.models.KeyedVectors.load_word2vec_format(self.model_path, fvocab=self.vocab_path, binary=False, unicode_errors='ignore')
A:gensim.test.test_keyedvectors.randkv->KeyedVectors(vector_size=100)
A:gensim.test.test_keyedvectors.tmpfiletxt->gensim.test.utils.get_tmpfile('tmp_kv.txt')
A:gensim.test.test_keyedvectors.reloadtxtkv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpfiletxt, binary=False, no_header=True)
A:gensim.test.test_keyedvectors.tmpfilebin->gensim.test.utils.get_tmpfile('tmp_kv.bin')
A:gensim.test.test_keyedvectors.reloadbinkv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpfilebin, binary=True)
A:gensim.test.test_keyedvectors.path->datapath('old_keyedvectors_320.dat')
A:gensim.test.test_keyedvectors.vectors->gensim.models.keyedvectors.KeyedVectors.load(path)
A:gensim.test.test_keyedvectors.num_words->len(word2vec_dict)
A:gensim.test.test_keyedvectors.vector_length->len(list(word2vec_dict.values())[0])
A:gensim.test.test_keyedvectors.tmpfile->gensim.test.utils.get_tmpfile('tmp_w2v')
A:gensim.test.test_keyedvectors.w2v_model->gensim.models.keyedvectors._load_word2vec_format(cls=gensim.models.KeyedVectors, fname=tmpfile, binary=True, limit=limit, binary_chunk_size=binary_chunk_size)
A:gensim.test.test_keyedvectors.limit->len(w2v_dict)
gensim.test.test_keyedvectors.Gensim320Test(unittest.TestCase)
gensim.test.test_keyedvectors.Gensim320Test.test(self)
gensim.test.test_keyedvectors.LoadWord2VecFormatTest(unittest.TestCase)
gensim.test.test_keyedvectors.LoadWord2VecFormatTest.assert_dict_equal_to_model(self,d,m)
gensim.test.test_keyedvectors.LoadWord2VecFormatTest.test_load_word2vec_format_basic(self)
gensim.test.test_keyedvectors.LoadWord2VecFormatTest.test_load_word2vec_format_limit(self)
gensim.test.test_keyedvectors.LoadWord2VecFormatTest.test_load_word2vec_format_space_stripping(self)
gensim.test.test_keyedvectors.LoadWord2VecFormatTest.verify_load2vec_binary_result(self,w2v_dict,binary_chunk_size,limit)
gensim.test.test_keyedvectors.TestKeyedVectors(unittest.TestCase)
gensim.test.test_keyedvectors.TestKeyedVectors.setUp(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_add_multiple(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_add_single(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_add_type(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_closer_than(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_distance(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_load_model_and_vocab_file_ignore(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_load_model_and_vocab_file_replace(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_load_model_and_vocab_file_strict(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_cosmul_parameter_types(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_parameter_types(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_raises_keyerror(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_restrict_vocab(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_to_given(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_topn(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_vector(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_most_similar_with_vector_input(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_no_header(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_rank(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_relative_cosine_similarity(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_save_reload(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_set_item(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_similar_by_vector(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_similar_by_word(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_similarity(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_vectors_for_all_list(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_vectors_for_all_with_copy_vecattrs(self)
gensim.test.test_keyedvectors.TestKeyedVectors.test_vectors_for_all_without_copy_vecattrs(self)
gensim.test.test_keyedvectors.save_dict_to_word2vec_formated_file(fname,word2vec_dict)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/similarities/nmslib.py----------------------------------------
A:gensim.similarities.nmslib.d->pickle.load(f)
A:gensim.similarities.nmslib.nmslib_instance->cls(model=None, index_params=index_params, query_time_params=query_time_params)
A:gensim.similarities.nmslib.index->nmslib.init(method='hnsw', space='cosinesimil')
gensim.similarities.nmslib.NmslibIndexer(self,model,index_params=None,query_time_params=None)
gensim.similarities.nmslib.NmslibIndexer.__init__(self,model,index_params=None,query_time_params=None)
gensim.similarities.nmslib.NmslibIndexer._build_from_doc2vec(self)
gensim.similarities.nmslib.NmslibIndexer._build_from_keyedvectors(self)
gensim.similarities.nmslib.NmslibIndexer._build_from_model(self,vectors,labels)
gensim.similarities.nmslib.NmslibIndexer._build_from_word2vec(self)
gensim.similarities.nmslib.NmslibIndexer.load(cls,fname)
gensim.similarities.nmslib.NmslibIndexer.most_similar(self,vector,num_neighbors)
gensim.similarities.nmslib.NmslibIndexer.save(self,fname,protocol=utils.PICKLE_PROTOCOL)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/similarities/levenshtein.py----------------------------------------
A:gensim.similarities.levenshtein.logger->logging.getLogger(__name__)
A:gensim.similarities.levenshtein.self.index->FastSS(words=self.dictionary.values(), max_dist=max_distance)
A:gensim.similarities.levenshtein.effective_topn->min(len(self.dictionary), effective_topn)
A:gensim.similarities.levenshtein.similarity->self.levsim(t1, t2, distance)
gensim.similarities.LevenshteinSimilarityIndex(self,dictionary,alpha=1.8,beta=5.0,max_distance=2)
gensim.similarities.LevenshteinSimilarityIndex.levsim(self,t1,t2,distance)
gensim.similarities.LevenshteinSimilarityIndex.most_similar(self,t1,topn=10)
gensim.similarities.levenshtein.LevenshteinSimilarityIndex(self,dictionary,alpha=1.8,beta=5.0,max_distance=2)
gensim.similarities.levenshtein.LevenshteinSimilarityIndex.__init__(self,dictionary,alpha=1.8,beta=5.0,max_distance=2)
gensim.similarities.levenshtein.LevenshteinSimilarityIndex.levsim(self,t1,t2,distance)
gensim.similarities.levenshtein.LevenshteinSimilarityIndex.most_similar(self,t1,topn=10)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/similarities/termsim.py----------------------------------------
A:gensim.similarities.termsim.logger->logging.getLogger(__name__)
A:gensim.similarities.termsim.members->', '.join(('%s=%s' % pair for pair in vars(self).items()))
A:gensim.similarities.termsim.self.dictionary->sorted(dictionary.items())
A:gensim.similarities.termsim.most_similar->self.keyedvectors.most_similar(positive=[t1], topn=topn, **self.kwargs)
A:gensim.similarities.termsim.matrix_order->len(dictionary)
A:gensim.similarities.termsim.columns->sorted(tfidf.idfs.keys(), key=tfidf_sort_key)
A:gensim.similarities.termsim.nonzero_counter_dtype->_shortest_uint_dtype(nonzero_limit)
A:gensim.similarities.termsim.column_nonzero->numpy.array([0] * matrix_order, dtype=nonzero_counter_dtype)
A:gensim.similarities.termsim.column_sum->numpy.zeros(matrix_order, dtype=dtype)
A:gensim.similarities.termsim.assigned_cells->set()
A:gensim.similarities.termsim.row_buffer->numpy.frombuffer(row_buffer, dtype=np.uint64)
A:gensim.similarities.termsim.column_buffer->numpy.frombuffer(column_buffer, dtype=np.uint64)
A:gensim.similarities.termsim.data_buffer->numpy.frombuffer(data_buffer, dtype=dtype)
A:gensim.similarities.termsim.rows->sorted(most_similar, key=tfidf_sort_key)
A:gensim.similarities.termsim.matrix->self.matrix[word_indices[:, None], word_indices].todense()
A:gensim.similarities.termsim.vector_norm->sqrt(vector_norm)
A:gensim.similarities.termsim.corpus_norm->numpy.sqrt(corpus_norm)
A:gensim.similarities.termsim.normalized_corpus->corpus.multiply(sparse.csr_matrix(1.0 / corpus_norm))
A:gensim.similarities.termsim.source->_create_source(*args)
A:gensim.similarities.termsim.self.matrix->_create_source(*args).tocsc()
A:gensim.similarities.termsim.(is_corpus_X, X)->is_corpus(X)
A:gensim.similarities.termsim.(is_corpus_Y, Y)->is_corpus(Y)
A:gensim.similarities.termsim.X->_normalize_sparse_corpus(X, matrix, normalized_X)
A:gensim.similarities.termsim.Y->_normalize_sparse_corpus(Y, matrix, normalized_Y)
A:gensim.similarities.termsim.word_indices->numpy.array(sorted(expanded_X.nonzero()[1]))
A:gensim.similarities.termsim.result->_normalize_sparse_corpus(X, matrix, normalized_X).T.dot(matrix).dot(Y)
A:gensim.similarities.termsim.expanded_X->corpus2csc([X], num_terms=self.matrix.shape[0], dtype=dtype).T.dot(self.matrix)
A:gensim.similarities.termsim.result.data->numpy.clip(result.data, -1.0, 1.0)
gensim.similarities.SparseTermSimilarityMatrix(self,source,dictionary=None,tfidf=None,symmetric=True,dominant=False,nonzero_limit=100,dtype=np.float32)
gensim.similarities.SparseTermSimilarityMatrix.inner_product(self,X,Y,normalized=(False,False))
gensim.similarities.TermSimilarityIndex(SaveLoad)
gensim.similarities.TermSimilarityIndex.__str__(self)
gensim.similarities.TermSimilarityIndex.most_similar(self,term,topn=10)
gensim.similarities.UniformTermSimilarityIndex(self,dictionary,term_similarity=0.5)
gensim.similarities.UniformTermSimilarityIndex.most_similar(self,t1,topn=10)
gensim.similarities.WordEmbeddingSimilarityIndex(self,keyedvectors,threshold=0.0,exponent=2.0,kwargs=None)
gensim.similarities.WordEmbeddingSimilarityIndex.most_similar(self,t1,topn=10)
gensim.similarities.termsim.SparseTermSimilarityMatrix(self,source,dictionary=None,tfidf=None,symmetric=True,dominant=False,nonzero_limit=100,dtype=np.float32)
gensim.similarities.termsim.SparseTermSimilarityMatrix.__init__(self,source,dictionary=None,tfidf=None,symmetric=True,dominant=False,nonzero_limit=100,dtype=np.float32)
gensim.similarities.termsim.SparseTermSimilarityMatrix.inner_product(self,X,Y,normalized=(False,False))
gensim.similarities.termsim.TermSimilarityIndex(SaveLoad)
gensim.similarities.termsim.TermSimilarityIndex.__str__(self)
gensim.similarities.termsim.TermSimilarityIndex.most_similar(self,term,topn=10)
gensim.similarities.termsim.UniformTermSimilarityIndex(self,dictionary,term_similarity=0.5)
gensim.similarities.termsim.UniformTermSimilarityIndex.__init__(self,dictionary,term_similarity=0.5)
gensim.similarities.termsim.UniformTermSimilarityIndex.most_similar(self,t1,topn=10)
gensim.similarities.termsim.WordEmbeddingSimilarityIndex(self,keyedvectors,threshold=0.0,exponent=2.0,kwargs=None)
gensim.similarities.termsim.WordEmbeddingSimilarityIndex.__init__(self,keyedvectors,threshold=0.0,exponent=2.0,kwargs=None)
gensim.similarities.termsim.WordEmbeddingSimilarityIndex.most_similar(self,t1,topn=10)
gensim.similarities.termsim._create_source(index,dictionary,tfidf,symmetric,dominant,nonzero_limit,dtype)
gensim.similarities.termsim._normalize_dense_corpus(corpus,matrix,normalization)
gensim.similarities.termsim._normalize_dense_vector(vector,matrix,normalization)
gensim.similarities.termsim._normalize_sparse_corpus(corpus,matrix,normalization)
gensim.similarities.termsim._shortest_uint_dtype(max_value)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/similarities/docsim.py----------------------------------------
A:gensim.similarities.docsim.logger->logging.getLogger(__name__)
A:gensim.similarities.docsim.(self.dirname, self.fname)->os.path.split(fname)
A:gensim.similarities.docsim.self.length->len(index)
A:gensim.similarities.docsim.self.index->self.index.tocsr()
A:gensim.similarities.docsim.result->result.toarray().flatten().toarray().flatten()
A:gensim.similarities.docsim.index->MatrixSimilarity(self.fresh_docs, num_features=self.num_features)
A:gensim.similarities.docsim.self.output_prefix->gensim.utils.randfname(prefix='simserver')
A:gensim.similarities.docsim.self.chunksize->int(chunksize)
A:gensim.similarities.docsim.doclen->len(doc)
A:gensim.similarities.docsim.doc->gensim.matutils.unitvec(matutils.sparse2full(doc, self.num_features), self.norm)
A:gensim.similarities.docsim.shardid->len(self.shards)
A:gensim.similarities.docsim.shard->Shard(self.shardid2filename(shardid), index)
A:gensim.similarities.docsim.last_index->last_shard.get_index()
A:gensim.similarities.docsim.self.fresh_docs->list(last_index.index)
A:gensim.similarities.docsim.args->zip([query] * len(self.shards), self.shards)
A:gensim.similarities.docsim.pool->multiprocessing.Pool(PARALLEL_SHARDS)
A:gensim.similarities.docsim.(pool, shard_results)->self.query_shards(query)
A:gensim.similarities.docsim.offsets->numpy.cumsum([0] + [len(shard) for shard in self.shards])
A:gensim.similarities.docsim.(is_corpus, query)->gensim.utils.is_corpus(query)
A:gensim.similarities.docsim.merged->_nlargest(self.num_best, parts)
A:gensim.similarities.docsim.query->gensim.matutils.corpus2csc([query], self.index.shape[1], dtype=self.index.dtype)
A:gensim.similarities.docsim.chunk_end->min(query.shape[0], chunk_start + chunksize)
A:gensim.similarities.docsim.dirname->os.path.dirname(self.output_prefix)
A:gensim.similarities.docsim.corpus_len->len(corpus)
A:gensim.similarities.docsim.vector->gensim.matutils.unitvec(matutils.sparse2full(vector, num_features))
A:gensim.similarities.docsim.self.corpus->list(corpus)
A:gensim.similarities.docsim.n_queries->len(query)
A:gensim.similarities.docsim.qresult->numpy.array(qresult)
gensim.similarities.MatrixSimilarity(self,corpus,num_best=None,dtype=numpy.float32,num_features=None,chunksize=256,corpus_len=None)
gensim.similarities.MatrixSimilarity.__len__(self)
gensim.similarities.MatrixSimilarity.__str__(self)
gensim.similarities.MatrixSimilarity.get_similarities(self,query)
gensim.similarities.Similarity(self,output_prefix,corpus,num_features,num_best=None,chunksize=256,shardsize=32768,norm='l2')
gensim.similarities.Similarity.__getitem__(self,query)
gensim.similarities.Similarity.__iter__(self)
gensim.similarities.Similarity.__len__(self)
gensim.similarities.Similarity.__str__(self)
gensim.similarities.Similarity.add_documents(self,corpus)
gensim.similarities.Similarity.check_moved(self)
gensim.similarities.Similarity.close_shard(self)
gensim.similarities.Similarity.destroy(self)
gensim.similarities.Similarity.iter_chunks(self,chunksize=None)
gensim.similarities.Similarity.query_shards(self,query)
gensim.similarities.Similarity.reopen_shard(self)
gensim.similarities.Similarity.save(self,fname=None,*args,**kwargs)
gensim.similarities.Similarity.shardid2filename(self,shardid)
gensim.similarities.Similarity.similarity_by_id(self,docpos)
gensim.similarities.Similarity.vector_by_id(self,docpos)
gensim.similarities.SoftCosineSimilarity(self,corpus,similarity_matrix,num_best=None,chunksize=256,normalized=(True,True))
gensim.similarities.SoftCosineSimilarity.__len__(self)
gensim.similarities.SoftCosineSimilarity.__str__(self)
gensim.similarities.SoftCosineSimilarity.get_similarities(self,query)
gensim.similarities.SparseMatrixSimilarity(self,corpus,num_features=None,num_terms=None,num_docs=None,num_nnz=None,num_best=None,chunksize=500,dtype=numpy.float32,maintain_sparsity=False)
gensim.similarities.SparseMatrixSimilarity.__len__(self)
gensim.similarities.SparseMatrixSimilarity.get_similarities(self,query)
gensim.similarities.WmdSimilarity(self,corpus,kv_model,num_best=None,chunksize=256)
gensim.similarities.WmdSimilarity.__len__(self)
gensim.similarities.WmdSimilarity.__str__(self)
gensim.similarities.WmdSimilarity.get_similarities(self,query)
gensim.similarities.docsim.MatrixSimilarity(self,corpus,num_best=None,dtype=numpy.float32,num_features=None,chunksize=256,corpus_len=None)
gensim.similarities.docsim.MatrixSimilarity.__init__(self,corpus,num_best=None,dtype=numpy.float32,num_features=None,chunksize=256,corpus_len=None)
gensim.similarities.docsim.MatrixSimilarity.__len__(self)
gensim.similarities.docsim.MatrixSimilarity.__str__(self)
gensim.similarities.docsim.MatrixSimilarity.get_similarities(self,query)
gensim.similarities.docsim.Shard(self,fname,index)
gensim.similarities.docsim.Shard.__getitem__(self,query)
gensim.similarities.docsim.Shard.__getstate__(self)
gensim.similarities.docsim.Shard.__init__(self,fname,index)
gensim.similarities.docsim.Shard.__len__(self)
gensim.similarities.docsim.Shard.__str__(self)
gensim.similarities.docsim.Shard.fullname(self)
gensim.similarities.docsim.Shard.get_document_id(self,pos)
gensim.similarities.docsim.Shard.get_index(self)
gensim.similarities.docsim.Similarity(self,output_prefix,corpus,num_features,num_best=None,chunksize=256,shardsize=32768,norm='l2')
gensim.similarities.docsim.Similarity.__getitem__(self,query)
gensim.similarities.docsim.Similarity.__init__(self,output_prefix,corpus,num_features,num_best=None,chunksize=256,shardsize=32768,norm='l2')
gensim.similarities.docsim.Similarity.__iter__(self)
gensim.similarities.docsim.Similarity.__len__(self)
gensim.similarities.docsim.Similarity.__str__(self)
gensim.similarities.docsim.Similarity.add_documents(self,corpus)
gensim.similarities.docsim.Similarity.check_moved(self)
gensim.similarities.docsim.Similarity.close_shard(self)
gensim.similarities.docsim.Similarity.destroy(self)
gensim.similarities.docsim.Similarity.iter_chunks(self,chunksize=None)
gensim.similarities.docsim.Similarity.query_shards(self,query)
gensim.similarities.docsim.Similarity.reopen_shard(self)
gensim.similarities.docsim.Similarity.save(self,fname=None,*args,**kwargs)
gensim.similarities.docsim.Similarity.shardid2filename(self,shardid)
gensim.similarities.docsim.Similarity.similarity_by_id(self,docpos)
gensim.similarities.docsim.Similarity.vector_by_id(self,docpos)
gensim.similarities.docsim.SoftCosineSimilarity(self,corpus,similarity_matrix,num_best=None,chunksize=256,normalized=(True,True))
gensim.similarities.docsim.SoftCosineSimilarity.__init__(self,corpus,similarity_matrix,num_best=None,chunksize=256,normalized=(True,True))
gensim.similarities.docsim.SoftCosineSimilarity.__len__(self)
gensim.similarities.docsim.SoftCosineSimilarity.__str__(self)
gensim.similarities.docsim.SoftCosineSimilarity.get_similarities(self,query)
gensim.similarities.docsim.SparseMatrixSimilarity(self,corpus,num_features=None,num_terms=None,num_docs=None,num_nnz=None,num_best=None,chunksize=500,dtype=numpy.float32,maintain_sparsity=False)
gensim.similarities.docsim.SparseMatrixSimilarity.__init__(self,corpus,num_features=None,num_terms=None,num_docs=None,num_nnz=None,num_best=None,chunksize=500,dtype=numpy.float32,maintain_sparsity=False)
gensim.similarities.docsim.SparseMatrixSimilarity.__len__(self)
gensim.similarities.docsim.SparseMatrixSimilarity.get_similarities(self,query)
gensim.similarities.docsim.WmdSimilarity(self,corpus,kv_model,num_best=None,chunksize=256)
gensim.similarities.docsim.WmdSimilarity.__init__(self,corpus,kv_model,num_best=None,chunksize=256)
gensim.similarities.docsim.WmdSimilarity.__len__(self)
gensim.similarities.docsim.WmdSimilarity.__str__(self)
gensim.similarities.docsim.WmdSimilarity.get_similarities(self,query)
gensim.similarities.docsim._nlargest(n,iterable)
gensim.similarities.docsim.query_shard(args)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/similarities/annoy.py----------------------------------------
A:gensim.similarities.annoy._NOANNOY->ImportError('Annoy not installed. To use the Annoy indexer, please run `pip install annoy`.')
A:gensim.similarities.annoy.d->pickle.loads(f.read())
A:gensim.similarities.annoy.self.index->AnnoyIndex(d['f'], metric='angular')
A:gensim.similarities.annoy.index->AnnoyIndex(num_features, metric='angular')
A:gensim.similarities.annoy.(ids, distances)->self.index.get_nns_by_vector(vector, num_neighbors, include_distances=True)
gensim.similarities.annoy.AnnoyIndexer(self,model=None,num_trees=None)
gensim.similarities.annoy.AnnoyIndexer.__init__(self,model=None,num_trees=None)
gensim.similarities.annoy.AnnoyIndexer._build_from_model(self,vectors,labels,num_features)
gensim.similarities.annoy.AnnoyIndexer.load(self,fname)
gensim.similarities.annoy.AnnoyIndexer.most_similar(self,vector,num_neighbors)
gensim.similarities.annoy.AnnoyIndexer.save(self,fname,protocol=utils.PICKLE_PROTOCOL)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/similarities/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/parsing/preprocessing.py----------------------------------------
A:gensim.parsing.preprocessing.STOPWORDS->frozenset(['all', 'six', 'just', 'less', 'being', 'indeed', 'over', 'move', 'anyway', 'four', 'not', 'own', 'through', 'using', 'fifty', 'where', 'mill', 'only', 'find', 'before', 'one', 'whose', 'system', 'how', 'somewhere', 'much', 'thick', 'show', 'had', 'enough', 'should', 'to', 'must', 'whom', 'seeming', 'yourselves', 'under', 'ours', 'two', 'has', 'might', 'thereafter', 'latterly', 'do', 'them', 'his', 'around', 'than', 'get', 'very', 'de', 'none', 'cannot', 'every', 'un', 'they', 'front', 'during', 'thus', 'now', 'him', 'nor', 'name', 'regarding', 'several', 'hereafter', 'did', 'always', 'who', 'didn', 'whither', 'this', 'someone', 'either', 'each', 'become', 'thereupon', 'sometime', 'side', 'towards', 'therein', 'twelve', 'because', 'often', 'ten', 'our', 'doing', 'km', 'eg', 'some', 'back', 'used', 'up', 'go', 'namely', 'computer', 'are', 'further', 'beyond', 'ourselves', 'yet', 'out', 'even', 'will', 'what', 'still', 'for', 'bottom', 'mine', 'since', 'please', 'forty', 'per', 'its', 'everything', 'behind', 'does', 'various', 'above', 'between', 'it', 'neither', 'seemed', 'ever', 'across', 'she', 'somehow', 'be', 'we', 'full', 'never', 'sixty', 'however', 'here', 'otherwise', 'were', 'whereupon', 'nowhere', 'although', 'found', 'alone', 're', 'along', 'quite', 'fifteen', 'by', 'both', 'about', 'last', 'would', 'anything', 'via', 'many', 'could', 'thence', 'put', 'against', 'keep', 'etc', 'amount', 'became', 'ltd', 'hence', 'onto', 'or', 'con', 'among', 'already', 'co', 'afterwards', 'formerly', 'within', 'seems', 'into', 'others', 'while', 'whatever', 'except', 'down', 'hers', 'everyone', 'done', 'least', 'another', 'whoever', 'moreover', 'couldnt', 'throughout', 'anyhow', 'yourself', 'three', 'from', 'her', 'few', 'together', 'top', 'there', 'due', 'been', 'next', 'anyone', 'eleven', 'cry', 'call', 'therefore', 'interest', 'then', 'thru', 'themselves', 'hundred', 'really', 'sincere', 'empty', 'more', 'himself', 'elsewhere', 'mostly', 'on', 'fire', 'am', 'becoming', 'hereby', 'amongst', 'else', 'part', 'everywhere', 'too', 'kg', 'herself', 'former', 'those', 'he', 'me', 'myself', 'made', 'twenty', 'these', 'was', 'bill', 'cant', 'us', 'until', 'besides', 'nevertheless', 'below', 'anywhere', 'nine', 'can', 'whether', 'of', 'your', 'toward', 'my', 'say', 'something', 'and', 'whereafter', 'whenever', 'give', 'almost', 'wherever', 'is', 'describe', 'beforehand', 'herein', 'doesn', 'an', 'as', 'itself', 'at', 'have', 'in', 'seem', 'whence', 'ie', 'any', 'fill', 'again', 'hasnt', 'inc', 'thereby', 'thin', 'no', 'perhaps', 'latter', 'meanwhile', 'when', 'detail', 'same', 'wherein', 'beside', 'also', 'that', 'other', 'take', 'which', 'becomes', 'you', 'if', 'nobody', 'unless', 'whereas', 'see', 'though', 'may', 'after', 'upon', 'most', 'hereupon', 'eight', 'but', 'serious', 'nothing', 'such', 'why', 'off', 'a', 'don', 'whereby', 'third', 'i', 'whole', 'noone', 'sometimes', 'well', 'amoungst', 'yours', 'their', 'rather', 'without', 'so', 'five', 'the', 'first', 'with', 'make', 'once'])
A:gensim.parsing.preprocessing.RE_PUNCT->re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)
A:gensim.parsing.preprocessing.RE_TAGS->re.compile('<([^>]+)>', re.UNICODE)
A:gensim.parsing.preprocessing.RE_NUMERIC->re.compile('[0-9]+', re.UNICODE)
A:gensim.parsing.preprocessing.RE_NONALPHA->re.compile('\\W', re.UNICODE)
A:gensim.parsing.preprocessing.RE_AL_NUM->re.compile('([a-z]+)([0-9]+)', flags=re.UNICODE)
A:gensim.parsing.preprocessing.RE_NUM_AL->re.compile('([0-9]+)([a-z]+)', flags=re.UNICODE)
A:gensim.parsing.preprocessing.RE_WHITESPACE->re.compile('(\\s)+', re.UNICODE)
A:gensim.parsing.preprocessing.s->f(s)
A:gensim.parsing.preprocessing.text->gensim.utils.to_unicode(text)
A:gensim.parsing.preprocessing.p->PorterStemmer()
gensim.parsing.preprocess_documents(docs)
gensim.parsing.preprocess_string(s,filters=DEFAULT_FILTERS)
gensim.parsing.preprocessing.lower_to_unicode(text,encoding='utf8',errors='strict')
gensim.parsing.preprocessing.preprocess_documents(docs)
gensim.parsing.preprocessing.preprocess_string(s,filters=DEFAULT_FILTERS)
gensim.parsing.preprocessing.read_file(path)
gensim.parsing.preprocessing.read_files(pattern)
gensim.parsing.preprocessing.remove_short_tokens(tokens,minsize=3)
gensim.parsing.preprocessing.remove_stopword_tokens(tokens,stopwords=None)
gensim.parsing.preprocessing.remove_stopwords(s,stopwords=None)
gensim.parsing.preprocessing.split_alphanum(s)
gensim.parsing.preprocessing.split_on_space(s)
gensim.parsing.preprocessing.stem_text(text)
gensim.parsing.preprocessing.strip_multiple_whitespaces(s)
gensim.parsing.preprocessing.strip_non_alphanum(s)
gensim.parsing.preprocessing.strip_numeric(s)
gensim.parsing.preprocessing.strip_punctuation(s)
gensim.parsing.preprocessing.strip_short(s,minsize=3)
gensim.parsing.preprocessing.strip_tags(s)
gensim.parsing.read_file(path)
gensim.parsing.read_files(pattern)
gensim.parsing.remove_stopwords(s,stopwords=None)
gensim.parsing.split_alphanum(s)
gensim.parsing.stem_text(text)
gensim.parsing.strip_multiple_whitespaces(s)
gensim.parsing.strip_non_alphanum(s)
gensim.parsing.strip_numeric(s)
gensim.parsing.strip_punctuation(s)
gensim.parsing.strip_short(s,minsize=3)
gensim.parsing.strip_tags(s)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/parsing/porter.py----------------------------------------
A:gensim.parsing.porter.length->len(s)
A:gensim.parsing.porter.a->self._m()
A:gensim.parsing.porter.w->w.lower().lower()
A:gensim.parsing.porter.p->PorterStemmer()
gensim.parsing.PorterStemmer(self)
gensim.parsing.PorterStemmer._cons(self,i)
gensim.parsing.PorterStemmer._cvc(self,i)
gensim.parsing.PorterStemmer._doublec(self,j)
gensim.parsing.PorterStemmer._ends(self,s)
gensim.parsing.PorterStemmer._m(self)
gensim.parsing.PorterStemmer._r(self,s)
gensim.parsing.PorterStemmer._setto(self,s)
gensim.parsing.PorterStemmer._step1ab(self)
gensim.parsing.PorterStemmer._step1c(self)
gensim.parsing.PorterStemmer._step2(self)
gensim.parsing.PorterStemmer._step3(self)
gensim.parsing.PorterStemmer._step4(self)
gensim.parsing.PorterStemmer._step5(self)
gensim.parsing.PorterStemmer._vowelinstem(self)
gensim.parsing.PorterStemmer.stem(self,w)
gensim.parsing.PorterStemmer.stem_documents(self,docs)
gensim.parsing.PorterStemmer.stem_sentence(self,txt)
gensim.parsing.porter.PorterStemmer(self)
gensim.parsing.porter.PorterStemmer.__init__(self)
gensim.parsing.porter.PorterStemmer._cons(self,i)
gensim.parsing.porter.PorterStemmer._cvc(self,i)
gensim.parsing.porter.PorterStemmer._doublec(self,j)
gensim.parsing.porter.PorterStemmer._ends(self,s)
gensim.parsing.porter.PorterStemmer._m(self)
gensim.parsing.porter.PorterStemmer._r(self,s)
gensim.parsing.porter.PorterStemmer._setto(self,s)
gensim.parsing.porter.PorterStemmer._step1ab(self)
gensim.parsing.porter.PorterStemmer._step1c(self)
gensim.parsing.porter.PorterStemmer._step2(self)
gensim.parsing.porter.PorterStemmer._step3(self)
gensim.parsing.porter.PorterStemmer._step4(self)
gensim.parsing.porter.PorterStemmer._step5(self)
gensim.parsing.porter.PorterStemmer._vowelinstem(self)
gensim.parsing.porter.PorterStemmer.stem(self,w)
gensim.parsing.porter.PorterStemmer.stem_documents(self,docs)
gensim.parsing.porter.PorterStemmer.stem_sentence(self,txt)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/parsing/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/tfidfmodel.py----------------------------------------
A:gensim.models.tfidfmodel.logger->logging.getLogger(__name__)
A:gensim.models.tfidfmodel.match->re.match('(?P<ddd>...)\\.(?P<qqq>...)', smartirs)
A:gensim.models.tfidfmodel.(_, length)->gensim.matutils.unitvec(x, return_norm=return_norm)
A:gensim.models.tfidfmodel.self.wlocal->partial(smartirs_wlocal, local_scheme=n_tf)
A:gensim.models.tfidfmodel.self.wglobal->partial(smartirs_wglobal, global_scheme=n_df)
A:gensim.models.tfidfmodel.self.cfs->dictionary.cfs.copy()
A:gensim.models.tfidfmodel.self.dfs->dictionary.dfs.copy()
A:gensim.models.tfidfmodel.self.idfs->precompute_idfs(self.wglobal, self.dfs, self.num_docs)
A:gensim.models.tfidfmodel.model->super(TfidfModel, cls).load(*args, **kwargs)
A:gensim.models.tfidfmodel.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.tfidfmodel.tf_array->self.wlocal(np.array(tf_array))
A:gensim.models.tfidfmodel.(_, old_norm)->self.normalize(vector, return_norm=True)
A:gensim.models.tfidfmodel.norm_vector->self.normalize(vector)
A:gensim.models.tfidfmodel.old_norm->sum((freq * (self.term_lens[termid] + 1.0) for (termid, freq) in bow))
gensim.models.TfidfModel(self,corpus=None,id2word=None,dictionary=None,wlocal=utils.identity,wglobal=df2idf,normalize=True,smartirs=None,pivot=None,slope=0.25)
gensim.models.TfidfModel.__getitem__(self,bow,eps=1e-12)
gensim.models.TfidfModel.__str__(self)
gensim.models.TfidfModel.initialize(self,corpus)
gensim.models.TfidfModel.load(cls,*args,**kwargs)
gensim.models.tfidfmodel.TfidfModel(self,corpus=None,id2word=None,dictionary=None,wlocal=utils.identity,wglobal=df2idf,normalize=True,smartirs=None,pivot=None,slope=0.25)
gensim.models.tfidfmodel.TfidfModel.__getitem__(self,bow,eps=1e-12)
gensim.models.tfidfmodel.TfidfModel.__init__(self,corpus=None,id2word=None,dictionary=None,wlocal=utils.identity,wglobal=df2idf,normalize=True,smartirs=None,pivot=None,slope=0.25)
gensim.models.tfidfmodel.TfidfModel.__str__(self)
gensim.models.tfidfmodel.TfidfModel.initialize(self,corpus)
gensim.models.tfidfmodel.TfidfModel.load(cls,*args,**kwargs)
gensim.models.tfidfmodel.df2idf(docfreq,totaldocs,log_base=2.0,add=0.0)
gensim.models.tfidfmodel.precompute_idfs(wglobal,dfs,total_docs)
gensim.models.tfidfmodel.resolve_weights(smartirs)
gensim.models.tfidfmodel.smartirs_normalize(x,norm_scheme,return_norm=False)
gensim.models.tfidfmodel.smartirs_wglobal(docfreq,totaldocs,global_scheme)
gensim.models.tfidfmodel.smartirs_wlocal(tf,local_scheme)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/ldamodel.py----------------------------------------
A:gensim.models.ldamodel.logger->logging.getLogger(__name__)
A:gensim.models.ldamodel.self.eta->update_dir_prior(self.eta, N, logphat, rho)
A:gensim.models.ldamodel.self.sstats->numpy.zeros(shape, dtype=dtype)
A:gensim.models.ldamodel.result->super(LdaModel, cls).load(fname, *args, **kwargs)
A:gensim.models.ldamodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.ldamodel.self.num_terms->len(self.id2word)
A:gensim.models.ldamodel.self.distributed->bool(distributed)
A:gensim.models.ldamodel.self.num_topics->int(num_topics)
A:gensim.models.ldamodel.(self.alpha, self.optimize_alpha)->self.init_dir_prior(alpha, 'alpha')
A:gensim.models.ldamodel.(self.eta, self.optimize_eta)->self.init_dir_prior(eta, 'eta')
A:gensim.models.ldamodel.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.ldamodel.self.dispatcher->Pyro4.Proxy(ns.list(prefix=LDA_DISPATCHER_PREFIX)[LDA_DISPATCHER_PREFIX])
A:gensim.models.ldamodel.self.numworkers->len(self.dispatcher.getworkers())
A:gensim.models.ldamodel.self.state->LdaState(self.eta, (self.num_topics, self.num_terms), dtype=self.dtype)
A:gensim.models.ldamodel.self.state.sstats[...]->self.random_state.gamma(100.0, 1.0 / 100.0, (self.num_topics, self.num_terms))
A:gensim.models.ldamodel.self.expElogbeta->numpy.exp(current_Elogbeta)
A:gensim.models.ldamodel.start->time.time()
A:gensim.models.ldamodel.init_prior->numpy.fromiter((prior for i in range(prior_shape)), dtype=self.dtype)
A:gensim.models.ldamodel.current_Elogbeta->self.state.get_Elogbeta()
A:gensim.models.ldamodel.chunk->list(chunk)
A:gensim.models.ldamodel.gamma->self.random_state.gamma(100.0, 1.0 / 100.0, (len(chunk), self.num_topics)).astype(self.dtype, copy=False)
A:gensim.models.ldamodel.Elogtheta->dirichlet_expectation(gamma)
A:gensim.models.ldamodel.expElogtheta->numpy.exp(Elogtheta)
A:gensim.models.ldamodel.sstats->numpy.zeros_like(self.expElogbeta, dtype=self.dtype)
A:gensim.models.ldamodel.cts->numpy.fromiter((cnt for (_, cnt) in doc), dtype=self.dtype, count=len(doc))
A:gensim.models.ldamodel.Elogthetad->dirichlet_expectation(gammad)
A:gensim.models.ldamodel.expElogthetad->numpy.exp(Elogthetad)
A:gensim.models.ldamodel.meanchange->mean_absolute_difference(gammad, lastgamma)
A:gensim.models.ldamodel.(gamma, sstats)->self.inference(chunk, collect_sstats=True)
A:gensim.models.ldamodel.N->float(lambdat.shape[0])
A:gensim.models.ldamodel.self.alpha->update_dir_prior(self.alpha, N, logphat, rho)
A:gensim.models.ldamodel.logphat->(sum((dirichlet_expectation(lambda_) for lambda_ in lambdat)) / N).reshape((self.num_terms,))
A:gensim.models.ldamodel.total_docs->len(chunk)
A:gensim.models.ldamodel.corpus_words->sum((cnt for document in chunk for (_, cnt) in document))
A:gensim.models.ldamodel.lencorpus->sum((1 for _ in corpus))
A:gensim.models.ldamodel.chunksize->min(lencorpus, self.chunksize)
A:gensim.models.ldamodel.updateafter->min(lencorpus, update_every * self.numworkers * chunksize)
A:gensim.models.ldamodel.evalafter->min(lencorpus, (eval_every or 0) * self.numworkers * chunksize)
A:gensim.models.ldamodel.updates_per_pass->max(1, lencorpus / updateafter)
A:gensim.models.ldamodel.callback->Callback(self.callbacks)
A:gensim.models.ldamodel.self.metrics->defaultdict(list)
A:gensim.models.ldamodel.other->self.dispatcher.getstate()
A:gensim.models.ldamodel.chunks->gensim.utils.grouper(corpus, chunksize, as_numpy=chunks_as_numpy, dtype=self.dtype)
A:gensim.models.ldamodel.gammat->self.do_estep(chunk, other)
A:gensim.models.ldamodel.current_metrics->Callback(self.callbacks).on_epoch_end(pass_)
A:gensim.models.ldamodel.previous_Elogbeta->self.state.get_Elogbeta()
A:gensim.models.ldamodel.diff->mean_absolute_difference(previous_Elogbeta.ravel(), current_Elogbeta.ravel())
A:gensim.models.ldamodel._lambda->self.state.get_lambda()
A:gensim.models.ldamodel.Elogbeta->dirichlet_expectation(_lambda)
A:gensim.models.ldamodel.(gammad, _)->self.inference([doc])
A:gensim.models.ldamodel.sum_eta->numpy.sum(self.eta)
A:gensim.models.ldamodel.chosen_topics->range(num_topics)
A:gensim.models.ldamodel.num_topics->min(num_topics, self.num_topics)
A:gensim.models.ldamodel.sorted_topics->list(matutils.argsort(sort_alpha))
A:gensim.models.ldamodel.topic->self.state.get_lambda()
A:gensim.models.ldamodel.bestn->gensim.matutils.argsort(topic, topn=topn, reverse=True)
A:gensim.models.ldamodel.topic_->' + '.join(('%.3f*"%s"' % (v, k) for (k, v) in topic_))
A:gensim.models.ldamodel.topics->self.state.get_lambda()
A:gensim.models.ldamodel.cm->CoherenceModel(model=self, corpus=corpus, texts=texts, dictionary=dictionary, window_size=window_size, coherence=coherence, topn=topn, processes=processes)
A:gensim.models.ldamodel.coherence_scores->CoherenceModel(model=self, corpus=corpus, texts=texts, dictionary=dictionary, window_size=window_size, coherence=coherence, topn=topn, processes=processes).get_coherence_per_topic()
A:gensim.models.ldamodel.scored_topics->zip(str_topics, coherence_scores)
A:gensim.models.ldamodel.minimum_probability->max(minimum_probability, 1e-08)
A:gensim.models.ldamodel.minimum_phi_value->max(minimum_phi_value, 1e-08)
A:gensim.models.ldamodel.(is_corpus, corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.ldamodel.kwargs->dict(per_word_topics=per_word_topics, minimum_probability=minimum_probability, minimum_phi_value=minimum_phi_value)
A:gensim.models.ldamodel.(gamma, phis)->self.inference([bow], collect_sstats=per_word_topics)
A:gensim.models.ldamodel.sorted_phi_values->sorted(phi_values, reverse=True)
A:gensim.models.ldamodel.valid_keys->', '.join(('`{}`'.format(x) for x in distances.keys()))
A:gensim.models.ldamodel.z->numpy.zeros((t1_size, t2_size))
A:gensim.models.ldamodel.annotation_terms->numpy.zeros((t1_size, t2_size), dtype=list)
A:gensim.models.ldamodel.z[topic]->distance_func(d1[topic1], d2[topic2])
A:gensim.models.ldamodel.neg_tokens->fst_topics[topic1].symmetric_difference(snd_topics[topic2])
A:gensim.models.ldamodel.ignore->list({'state', 'dispatcher', 'id2word'} | set(ignore))
A:gensim.models.ldamodel.separately->list(set(separately_explicit) | set(separately))
A:gensim.models.ldamodel.kwargs['mmap']->dict(per_word_topics=per_word_topics, minimum_probability=minimum_probability, minimum_phi_value=minimum_phi_value).get('mmap', None)
A:gensim.models.ldamodel.result.random_state->gensim.utils.get_random_state(None)
A:gensim.models.ldamodel.state_fname->gensim.utils.smart_extension(fname, '.state')
A:gensim.models.ldamodel.result.state->LdaState.load(state_fname, *args, **kwargs)
A:gensim.models.ldamodel.id2word_fname->gensim.utils.smart_extension(fname, '.id2word')
A:gensim.models.ldamodel.result.id2word->gensim.utils.unpickle(id2word_fname)
gensim.models.LdaModel(self,corpus=None,num_topics=100,id2word=None,distributed=False,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,ns_conf=None,minimum_phi_value=0.01,per_word_topics=False,callbacks=None,dtype=np.float32)
gensim.models.LdaModel.__getitem__(self,bow,eps=None)
gensim.models.LdaModel.__str__(self)
gensim.models.LdaModel.bound(self,corpus,gamma=None,subsample_ratio=1.0)
gensim.models.LdaModel.clear(self)
gensim.models.LdaModel.diff(self,other,distance='kullback_leibler',num_words=100,n_ann_terms=10,diagonal=False,annotation=True,normed=True)
gensim.models.LdaModel.do_estep(self,chunk,state=None)
gensim.models.LdaModel.do_mstep(self,rho,other,extra_pass=False)
gensim.models.LdaModel.get_document_topics(self,bow,minimum_probability=None,minimum_phi_value=None,per_word_topics=False)
gensim.models.LdaModel.get_term_topics(self,word_id,minimum_probability=None)
gensim.models.LdaModel.get_topic_terms(self,topicid,topn=10)
gensim.models.LdaModel.get_topics(self)
gensim.models.LdaModel.inference(self,chunk,collect_sstats=False)
gensim.models.LdaModel.init_dir_prior(self,prior,name)
gensim.models.LdaModel.load(cls,fname,*args,**kwargs)
gensim.models.LdaModel.log_perplexity(self,chunk,total_docs=None)
gensim.models.LdaModel.save(self,fname,ignore=('state','dispatcher'),separately=None,*args,**kwargs)
gensim.models.LdaModel.show_topic(self,topicid,topn=10)
gensim.models.LdaModel.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.LdaModel.sync_state(self,current_Elogbeta=None)
gensim.models.LdaModel.top_topics(self,corpus=None,texts=None,dictionary=None,window_size=None,coherence='u_mass',topn=20,processes=-1)
gensim.models.LdaModel.update(self,corpus,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.LdaModel.update_alpha(self,gammat,rho)
gensim.models.LdaModel.update_eta(self,lambdat,rho)
gensim.models.ldamodel.LdaModel(self,corpus=None,num_topics=100,id2word=None,distributed=False,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,ns_conf=None,minimum_phi_value=0.01,per_word_topics=False,callbacks=None,dtype=np.float32)
gensim.models.ldamodel.LdaModel.__getitem__(self,bow,eps=None)
gensim.models.ldamodel.LdaModel.__init__(self,corpus=None,num_topics=100,id2word=None,distributed=False,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,ns_conf=None,minimum_phi_value=0.01,per_word_topics=False,callbacks=None,dtype=np.float32)
gensim.models.ldamodel.LdaModel.__str__(self)
gensim.models.ldamodel.LdaModel.bound(self,corpus,gamma=None,subsample_ratio=1.0)
gensim.models.ldamodel.LdaModel.clear(self)
gensim.models.ldamodel.LdaModel.diff(self,other,distance='kullback_leibler',num_words=100,n_ann_terms=10,diagonal=False,annotation=True,normed=True)
gensim.models.ldamodel.LdaModel.do_estep(self,chunk,state=None)
gensim.models.ldamodel.LdaModel.do_mstep(self,rho,other,extra_pass=False)
gensim.models.ldamodel.LdaModel.get_document_topics(self,bow,minimum_probability=None,minimum_phi_value=None,per_word_topics=False)
gensim.models.ldamodel.LdaModel.get_term_topics(self,word_id,minimum_probability=None)
gensim.models.ldamodel.LdaModel.get_topic_terms(self,topicid,topn=10)
gensim.models.ldamodel.LdaModel.get_topics(self)
gensim.models.ldamodel.LdaModel.inference(self,chunk,collect_sstats=False)
gensim.models.ldamodel.LdaModel.init_dir_prior(self,prior,name)
gensim.models.ldamodel.LdaModel.load(cls,fname,*args,**kwargs)
gensim.models.ldamodel.LdaModel.log_perplexity(self,chunk,total_docs=None)
gensim.models.ldamodel.LdaModel.save(self,fname,ignore=('state','dispatcher'),separately=None,*args,**kwargs)
gensim.models.ldamodel.LdaModel.show_topic(self,topicid,topn=10)
gensim.models.ldamodel.LdaModel.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.ldamodel.LdaModel.sync_state(self,current_Elogbeta=None)
gensim.models.ldamodel.LdaModel.top_topics(self,corpus=None,texts=None,dictionary=None,window_size=None,coherence='u_mass',topn=20,processes=-1)
gensim.models.ldamodel.LdaModel.update(self,corpus,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.ldamodel.LdaModel.update_alpha(self,gammat,rho)
gensim.models.ldamodel.LdaModel.update_eta(self,lambdat,rho)
gensim.models.ldamodel.LdaState(self,eta,shape,dtype=np.float32)
gensim.models.ldamodel.LdaState.__init__(self,eta,shape,dtype=np.float32)
gensim.models.ldamodel.LdaState.blend(self,rhot,other,targetsize=None)
gensim.models.ldamodel.LdaState.blend2(self,rhot,other,targetsize=None)
gensim.models.ldamodel.LdaState.get_Elogbeta(self)
gensim.models.ldamodel.LdaState.get_lambda(self)
gensim.models.ldamodel.LdaState.load(cls,fname,*args,**kwargs)
gensim.models.ldamodel.LdaState.merge(self,other)
gensim.models.ldamodel.LdaState.reset(self)
gensim.models.ldamodel.update_dir_prior(prior,N,logphat,rho)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/keyedvectors.py----------------------------------------
A:gensim.models.keyedvectors.logger->logging.getLogger(__name__)
A:gensim.models.keyedvectors.self.vectors->vstack((self.vectors, weights[~in_vocab_mask].astype(self.vectors.dtype)))
A:gensim.models.keyedvectors.self.index_to_key->self.__dict__.pop('index2word', self.__dict__.pop('index2entity', None))
A:gensim.models.keyedvectors.old_vocab->self.__dict__.pop('vocab', None)
A:gensim.models.keyedvectors.self.expandos['sample_int']->self.expandos['sample_int'].astype(np.uint32)
A:gensim.models.keyedvectors.attrs->list(self.expandos.keys())
A:gensim.models.keyedvectors.target_size->len(self.index_to_key)
A:gensim.models.keyedvectors.self.expandos[attr]->numpy.vstack((self.expandos[attr], extra[~in_vocab_mask]))
A:gensim.models.keyedvectors.prev_count->len(prev_expando)
A:gensim.models.keyedvectors.index->self.get_index(key)
A:gensim.models.keyedvectors.val->self.key_to_index.get(key, -1)
A:gensim.models.keyedvectors.target_index->len(self)
A:gensim.models.keyedvectors.weights->numpy.fromstring(fin.read(binary_len), dtype=REAL)
A:gensim.models.keyedvectors.in_vocab_mask->numpy.zeros(len(keys), dtype=bool)
A:gensim.models.keyedvectors.self.key_to_index[key]->len(self.index_to_key)
A:gensim.models.keyedvectors.all_distances->self.distances(key1)
A:gensim.models.keyedvectors.e1_index->self.get_index(key1)
A:gensim.models.keyedvectors.e2_index->self.get_index(key2)
A:gensim.models.keyedvectors.self.norms->numpy.ones((len(self.vectors),))
A:gensim.models.keyedvectors.positive->_ensure_list(positive)
A:gensim.models.keyedvectors.negative->_ensure_list(negative)
A:gensim.models.keyedvectors.mean->gensim.matutils.unitvec(vectors.mean(axis=0)).astype(REAL)
A:gensim.models.keyedvectors.best->gensim.matutils.argsort(dists, topn=topn + len(all_words), reverse=True)
A:gensim.models.keyedvectors.len_pre_oov1->len(document1)
A:gensim.models.keyedvectors.len_pre_oov2->len(document2)
A:gensim.models.keyedvectors.dictionary->Dictionary(documents=[document1, document2])
A:gensim.models.keyedvectors.vocab_len->len(dictionary)
A:gensim.models.keyedvectors.doclist1->list(set(document1))
A:gensim.models.keyedvectors.doclist2->list(set(document2))
A:gensim.models.keyedvectors.v1->numpy.array([self.get_vector(token, norm=norm) for token in doclist1])
A:gensim.models.keyedvectors.v2->numpy.array([self.get_vector(token, norm=norm) for token in doclist2])
A:gensim.models.keyedvectors.doc1_indices->Dictionary(documents=[document1, document2]).doc2idx(doclist1)
A:gensim.models.keyedvectors.doc2_indices->Dictionary(documents=[document1, document2]).doc2idx(doclist2)
A:gensim.models.keyedvectors.distance_matrix->zeros((vocab_len, vocab_len), dtype=double)
A:gensim.models.keyedvectors.distance_matrix[np.ix_(doc1_indices, doc2_indices)]->cdist(v1, v2)
A:gensim.models.keyedvectors.d->zeros(vocab_len, dtype=double)
A:gensim.models.keyedvectors.nbow->Dictionary(documents=[document1, document2]).doc2bow(document)
A:gensim.models.keyedvectors.doc_len->len(document)
A:gensim.models.keyedvectors.d1->nbow(document1)
A:gensim.models.keyedvectors.d2->nbow(document2)
A:gensim.models.keyedvectors.vectors->vstack([self.get_vector(word, norm=use_norm) for word in used_words]).astype(REAL)
A:gensim.models.keyedvectors.dists->dot(vectors, mean)
A:gensim.models.keyedvectors.norm->numpy.linalg.norm(vector_1)
A:gensim.models.keyedvectors.all_norms->numpy.linalg.norm(vectors_all, axis=1)
A:gensim.models.keyedvectors.dot_products->dot(vectors_all, vector_1)
A:gensim.models.keyedvectors.input_vector->self.get_vector(word_or_vector)
A:gensim.models.keyedvectors.line->gensim.utils.open(fname, 'rb').readline()
A:gensim.models.keyedvectors.sims->self.similar_by_word(wa, topn)
A:gensim.models.keyedvectors.analogies_score->self._log_evaluate_word_analogies(total)
A:gensim.models.keyedvectors.sim->float(sim)
A:gensim.models.keyedvectors.spearman->scipy.stats.spearmanr(similarity_gold, similarity_model)
A:gensim.models.keyedvectors.pearson->scipy.stats.pearsonr(similarity_gold, similarity_model)
A:gensim.models.keyedvectors.total_vec->len(self.index_to_key)
A:gensim.models.keyedvectors.store_order_vocab_keys->sorted(self.key_to_index.keys(), key=lambda k: -self.get_vecattr(k, sort_attr))
A:gensim.models.keyedvectors.keys_to_write->itertools.chain(range(0, index_id_count), store_order_vocab_keys)
A:gensim.models.keyedvectors.header->gensim.utils.to_unicode(fin.readline(), encoding=encoding)
A:gensim.models.keyedvectors.ch->gensim.utils.open(fname, 'rb').read(1)
A:gensim.models.keyedvectors.word->word.lstrip('\n').lstrip('\n')
A:gensim.models.keyedvectors.parts->gensim.utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(' ')
A:gensim.models.keyedvectors.kv->cls(vector_size, vocab_size, dtype=datatype)
A:gensim.models.keyedvectors.old_offset->self.get_vecattr(k, 'offset')
A:gensim.models.keyedvectors.word_id->cls(vector_size, vocab_size, dtype=datatype).add_vector(word, weights)
A:gensim.models.keyedvectors.i_space->chunk.find(b' ', start)
A:gensim.models.keyedvectors.vector->frombuffer(chunk, offset=i_vector, count=vector_size, dtype=REAL).astype(datatype)
A:gensim.models.keyedvectors.new_chunk->gensim.utils.open(fname, 'rb').read(binary_chunk_size)
A:gensim.models.keyedvectors.(processed_words, chunk)->_add_bytes_to_kv(kv, counts, chunk, vocab_size, vector_size, datatype, unicode_errors)
A:gensim.models.keyedvectors.(word, weights)->_word2vec_line_to_vector(line, datatype, unicode_errors, encoding)
A:gensim.models.keyedvectors.vector_size->len(weights)
A:gensim.models.keyedvectors.(word, count)->gensim.utils.to_unicode(line, errors=unicode_errors).strip().split()
A:gensim.models.keyedvectors.counts[word]->int(count)
A:gensim.models.keyedvectors.(vocab_size, vector_size)->_word2vec_detect_sizes_text(fin, limit, datatype, unicode_errors, encoding)
A:gensim.models.keyedvectors.fin->gensim.utils.open(fname, 'rb')
A:gensim.models.keyedvectors.vocab_size->min(vocab_size, limit)
A:gensim.models.keyedvectors.kv.vectors->ascontiguousarray(kv.vectors[:len(kv)])
A:gensim.models.keyedvectors.once->numpy.random.Generator(np.random.SFC64(hashfxn(seed_string) & 4294967295))
A:gensim.models.keyedvectors.prior_vectors->numpy.zeros((0, 0))
A:gensim.models.keyedvectors.rng->numpy.random.default_rng(seed=seed)
A:gensim.models.keyedvectors.new_vectors->numpy.random.default_rng(seed=seed).random(target_shape, dtype=dtype)
gensim.models.KeyedVectors(self,vector_size,count=0,dtype=np.float32,mapfile_path=None)
gensim.models.KeyedVectors.__contains__(self,key)
gensim.models.KeyedVectors.__getitem__(self,key_or_keys)
gensim.models.KeyedVectors.__len__(self)
gensim.models.KeyedVectors.__setitem__(self,keys,weights)
gensim.models.KeyedVectors._load_specials(self,*args,**kwargs)
gensim.models.KeyedVectors._log_evaluate_word_analogies(section)
gensim.models.KeyedVectors._upconvert_old_d2vkv(self)
gensim.models.KeyedVectors._upconvert_old_vocab(self)
gensim.models.KeyedVectors.add_vector(self,key,vector)
gensim.models.KeyedVectors.add_vectors(self,keys,weights,extras=None,replace=False)
gensim.models.KeyedVectors.allocate_vecattrs(self,attrs=None,types=None)
gensim.models.KeyedVectors.closer_than(self,key1,key2)
gensim.models.KeyedVectors.cosine_similarities(vector_1,vectors_all)
gensim.models.KeyedVectors.distance(self,w1,w2)
gensim.models.KeyedVectors.distances(self,word_or_vector,other_words=())
gensim.models.KeyedVectors.doesnt_match(self,words)
gensim.models.KeyedVectors.evaluate_word_analogies(self,analogies,restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.KeyedVectors.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.KeyedVectors.fill_norms(self,force=False)
gensim.models.KeyedVectors.get_index(self,key,default=None)
gensim.models.KeyedVectors.get_normed_vectors(self)
gensim.models.KeyedVectors.get_vecattr(self,key,attr)
gensim.models.KeyedVectors.get_vector(self,key,norm=False)
gensim.models.KeyedVectors.has_index_for(self,key)
gensim.models.KeyedVectors.index2entity(self)
gensim.models.KeyedVectors.index2entity(self,value)
gensim.models.KeyedVectors.index2word(self)
gensim.models.KeyedVectors.index2word(self,value)
gensim.models.KeyedVectors.init_sims(self,replace=False)
gensim.models.KeyedVectors.intersect_word2vec_format(self,fname,lockf=0.0,binary=False,encoding='utf8',unicode_errors='strict')
gensim.models.KeyedVectors.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL,no_header=False)
gensim.models.KeyedVectors.log_accuracy(section)
gensim.models.KeyedVectors.log_evaluate_word_pairs(pearson,spearman,oov,pairs)
gensim.models.KeyedVectors.most_similar(self,positive=None,negative=None,topn=10,clip_start=0,clip_end=None,restrict_vocab=None,indexer=None)
gensim.models.KeyedVectors.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.KeyedVectors.most_similar_to_given(self,key1,keys_list)
gensim.models.KeyedVectors.n_similarity(self,ws1,ws2)
gensim.models.KeyedVectors.rank(self,key1,key2)
gensim.models.KeyedVectors.rank_by_centrality(self,words,use_norm=True)
gensim.models.KeyedVectors.relative_cosine_similarity(self,wa,wb,topn=10)
gensim.models.KeyedVectors.resize_vectors(self,seed=0)
gensim.models.KeyedVectors.save(self,*args,**kwargs)
gensim.models.KeyedVectors.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None,write_header=True,prefix='',append=False,sort_attr='count')
gensim.models.KeyedVectors.set_vecattr(self,key,attr,val)
gensim.models.KeyedVectors.similar_by_key(self,key,topn=10,restrict_vocab=None)
gensim.models.KeyedVectors.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.KeyedVectors.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.KeyedVectors.similarity(self,w1,w2)
gensim.models.KeyedVectors.similarity_unseen_docs(self,*args,**kwargs)
gensim.models.KeyedVectors.sort_by_descending_frequency(self)
gensim.models.KeyedVectors.unit_normalize_all(self)
gensim.models.KeyedVectors.vectors_for_all(self,keys:Iterable,allow_inference:bool=True,copy_vecattrs:bool=False)->'KeyedVectors'
gensim.models.KeyedVectors.vectors_norm(self)
gensim.models.KeyedVectors.vectors_norm(self,_)
gensim.models.KeyedVectors.vocab(self)
gensim.models.KeyedVectors.vocab(self,value)
gensim.models.KeyedVectors.wmdistance(self,document1,document2,norm=True)
gensim.models.KeyedVectors.word_vec(self,*args,**kwargs)
gensim.models.KeyedVectors.words_closer_than(self,word1,word2)
gensim.models.keyedvectors.CompatVocab(self,**kwargs)
gensim.models.keyedvectors.CompatVocab.__init__(self,**kwargs)
gensim.models.keyedvectors.CompatVocab.__lt__(self,other)
gensim.models.keyedvectors.CompatVocab.__str__(self)
gensim.models.keyedvectors.KeyedVectors(self,vector_size,count=0,dtype=np.float32,mapfile_path=None)
gensim.models.keyedvectors.KeyedVectors.__contains__(self,key)
gensim.models.keyedvectors.KeyedVectors.__getitem__(self,key_or_keys)
gensim.models.keyedvectors.KeyedVectors.__init__(self,vector_size,count=0,dtype=np.float32,mapfile_path=None)
gensim.models.keyedvectors.KeyedVectors.__len__(self)
gensim.models.keyedvectors.KeyedVectors.__setitem__(self,keys,weights)
gensim.models.keyedvectors.KeyedVectors._load_specials(self,*args,**kwargs)
gensim.models.keyedvectors.KeyedVectors._log_evaluate_word_analogies(section)
gensim.models.keyedvectors.KeyedVectors._upconvert_old_d2vkv(self)
gensim.models.keyedvectors.KeyedVectors._upconvert_old_vocab(self)
gensim.models.keyedvectors.KeyedVectors.add_vector(self,key,vector)
gensim.models.keyedvectors.KeyedVectors.add_vectors(self,keys,weights,extras=None,replace=False)
gensim.models.keyedvectors.KeyedVectors.allocate_vecattrs(self,attrs=None,types=None)
gensim.models.keyedvectors.KeyedVectors.closer_than(self,key1,key2)
gensim.models.keyedvectors.KeyedVectors.cosine_similarities(vector_1,vectors_all)
gensim.models.keyedvectors.KeyedVectors.distance(self,w1,w2)
gensim.models.keyedvectors.KeyedVectors.distances(self,word_or_vector,other_words=())
gensim.models.keyedvectors.KeyedVectors.doesnt_match(self,words)
gensim.models.keyedvectors.KeyedVectors.evaluate_word_analogies(self,analogies,restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.keyedvectors.KeyedVectors.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.keyedvectors.KeyedVectors.fill_norms(self,force=False)
gensim.models.keyedvectors.KeyedVectors.get_index(self,key,default=None)
gensim.models.keyedvectors.KeyedVectors.get_normed_vectors(self)
gensim.models.keyedvectors.KeyedVectors.get_vecattr(self,key,attr)
gensim.models.keyedvectors.KeyedVectors.get_vector(self,key,norm=False)
gensim.models.keyedvectors.KeyedVectors.has_index_for(self,key)
gensim.models.keyedvectors.KeyedVectors.index2entity(self)
gensim.models.keyedvectors.KeyedVectors.index2entity(self,value)
gensim.models.keyedvectors.KeyedVectors.index2word(self)
gensim.models.keyedvectors.KeyedVectors.index2word(self,value)
gensim.models.keyedvectors.KeyedVectors.init_sims(self,replace=False)
gensim.models.keyedvectors.KeyedVectors.intersect_word2vec_format(self,fname,lockf=0.0,binary=False,encoding='utf8',unicode_errors='strict')
gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL,no_header=False)
gensim.models.keyedvectors.KeyedVectors.log_accuracy(section)
gensim.models.keyedvectors.KeyedVectors.log_evaluate_word_pairs(pearson,spearman,oov,pairs)
gensim.models.keyedvectors.KeyedVectors.most_similar(self,positive=None,negative=None,topn=10,clip_start=0,clip_end=None,restrict_vocab=None,indexer=None)
gensim.models.keyedvectors.KeyedVectors.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.keyedvectors.KeyedVectors.most_similar_to_given(self,key1,keys_list)
gensim.models.keyedvectors.KeyedVectors.n_similarity(self,ws1,ws2)
gensim.models.keyedvectors.KeyedVectors.rank(self,key1,key2)
gensim.models.keyedvectors.KeyedVectors.rank_by_centrality(self,words,use_norm=True)
gensim.models.keyedvectors.KeyedVectors.relative_cosine_similarity(self,wa,wb,topn=10)
gensim.models.keyedvectors.KeyedVectors.resize_vectors(self,seed=0)
gensim.models.keyedvectors.KeyedVectors.save(self,*args,**kwargs)
gensim.models.keyedvectors.KeyedVectors.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None,write_header=True,prefix='',append=False,sort_attr='count')
gensim.models.keyedvectors.KeyedVectors.set_vecattr(self,key,attr,val)
gensim.models.keyedvectors.KeyedVectors.similar_by_key(self,key,topn=10,restrict_vocab=None)
gensim.models.keyedvectors.KeyedVectors.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.keyedvectors.KeyedVectors.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.keyedvectors.KeyedVectors.similarity(self,w1,w2)
gensim.models.keyedvectors.KeyedVectors.similarity_unseen_docs(self,*args,**kwargs)
gensim.models.keyedvectors.KeyedVectors.sort_by_descending_frequency(self)
gensim.models.keyedvectors.KeyedVectors.unit_normalize_all(self)
gensim.models.keyedvectors.KeyedVectors.vectors_for_all(self,keys:Iterable,allow_inference:bool=True,copy_vecattrs:bool=False)->'KeyedVectors'
gensim.models.keyedvectors.KeyedVectors.vectors_norm(self)
gensim.models.keyedvectors.KeyedVectors.vectors_norm(self,_)
gensim.models.keyedvectors.KeyedVectors.vocab(self)
gensim.models.keyedvectors.KeyedVectors.vocab(self,value)
gensim.models.keyedvectors.KeyedVectors.wmdistance(self,document1,document2,norm=True)
gensim.models.keyedvectors.KeyedVectors.word_vec(self,*args,**kwargs)
gensim.models.keyedvectors.KeyedVectors.words_closer_than(self,word1,word2)
gensim.models.keyedvectors._add_bytes_to_kv(kv,counts,chunk,vocab_size,vector_size,datatype,unicode_errors)
gensim.models.keyedvectors._add_word_to_kv(kv,counts,word,weights,vocab_size)
gensim.models.keyedvectors._ensure_list(value)
gensim.models.keyedvectors._load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=sys.maxsize,datatype=REAL,no_header=False,binary_chunk_size=100*1024)
gensim.models.keyedvectors._word2vec_detect_sizes_text(fin,limit,datatype,unicode_errors,encoding)
gensim.models.keyedvectors._word2vec_line_to_vector(line,datatype,unicode_errors,encoding)
gensim.models.keyedvectors._word2vec_read_binary(fin,kv,counts,vocab_size,vector_size,datatype,unicode_errors,binary_chunk_size)
gensim.models.keyedvectors._word2vec_read_text(fin,kv,counts,vocab_size,vector_size,datatype,unicode_errors,encoding)
gensim.models.keyedvectors.load_word2vec_format(*args,**kwargs)
gensim.models.keyedvectors.prep_vectors(target_shape,prior_vectors=None,seed=0,dtype=REAL)
gensim.models.keyedvectors.pseudorandom_weak_vector(size,seed_string=None,hashfxn=hash)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/hdpmodel.py----------------------------------------
A:gensim.models.hdpmodel.logger->logging.getLogger(__name__)
A:gensim.models.hdpmodel.dig_sum->psi(np.sum(v, 0))
A:gensim.models.hdpmodel.Elogsticks->numpy.zeros(n)
A:gensim.models.hdpmodel.gamma->numpy.zeros((len(chunk), self.lda_beta.shape[0]))
A:gensim.models.hdpmodel.expElogtheta->numpy.exp(Elogtheta)
A:gensim.models.hdpmodel.counts->numpy.array(doc_word_counts)
A:gensim.models.hdpmodel.Elogtheta->dirichlet_expectation(gamma)
A:gensim.models.hdpmodel.meanchange->mean_absolute_difference(gamma, lastgamma)
A:gensim.models.hdpmodel.likelihood->numpy.sum(counts * np.log(phinorm))
A:gensim.models.hdpmodel.self.m_var_sticks_ss->numpy.zeros(T)
A:gensim.models.hdpmodel.self.m_var_beta_ss->numpy.zeros((T, Wt))
A:gensim.models.hdpmodel.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.hdpmodel.self.m_W->len(id2word)
A:gensim.models.hdpmodel.self.m_D->len(corpus)
A:gensim.models.hdpmodel.self.m_var_sticks->numpy.zeros((2, T - 1))
A:gensim.models.hdpmodel.self.m_var_sticks[1]->range(T - 1, 0, -1)
A:gensim.models.hdpmodel.self.m_varphi_ss->numpy.zeros(T)
A:gensim.models.hdpmodel.self.m_Elogbeta->dirichlet_expectation(self.m_eta + self.m_lambda)
A:gensim.models.hdpmodel.self.m_timestamp->numpy.zeros(self.m_W, dtype=int)
A:gensim.models.hdpmodel.self.m_lambda_sum->numpy.sum(self.m_lambda, axis=1)
A:gensim.models.hdpmodel.chunk->list(chunk)
A:gensim.models.hdpmodel.(ids, counts)->zip(*doc)
A:gensim.models.hdpmodel.(_, gammad)->lda_e_step(ids, counts, self.lda_alpha, self.lda_beta)
A:gensim.models.hdpmodel.(is_corpus, corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.hdpmodel.save_freq->max(1, int(10000 / self.chunksize))
A:gensim.models.hdpmodel.start_time->time.perf_counter()
A:gensim.models.hdpmodel.(alpha, beta)->self.hdp_to_lda()
A:gensim.models.hdpmodel.unique_words->dict()
A:gensim.models.hdpmodel.unique_words[word_id]->len(unique_words)
A:gensim.models.hdpmodel.wt->len(word_list)
A:gensim.models.hdpmodel.rw->numpy.array([self.m_r[t] for t in self.m_timestamp[word_list]])
A:gensim.models.hdpmodel.ss->SuffStats(self.m_T, wt, len(chunk))
A:gensim.models.hdpmodel.Elogsticks_1st->expect_log_sticks(self.m_var_sticks)
A:gensim.models.hdpmodel.(doc_word_ids, doc_word_counts)->zip(*doc)
A:gensim.models.hdpmodel.doc_score->self.doc_e_step(ss, Elogsticks_1st, unique_words, doc_word_ids, doc_word_counts, self.m_var_converge)
A:gensim.models.hdpmodel.v->numpy.zeros((2, self.m_K - 1))
A:gensim.models.hdpmodel.var_phi->numpy.exp(log_var_phi)
A:gensim.models.hdpmodel.(log_var_phi, log_norm)->gensim.matutils.ret_log_normalize_vec(var_phi)
A:gensim.models.hdpmodel.(log_phi, log_norm)->gensim.matutils.ret_log_normalize_vec(phi)
A:gensim.models.hdpmodel.phi->numpy.exp(log_phi)
A:gensim.models.hdpmodel.phi_cum->numpy.flipud(np.sum(phi_all[:, 1:], 0))
A:gensim.models.hdpmodel.Elogsticks_2nd->expect_log_sticks(v)
A:gensim.models.hdpmodel.log_alpha->numpy.log(self.m_alpha)
A:gensim.models.hdpmodel.var_phi_sum->numpy.flipud(self.m_varphi_ss[1:])
A:gensim.models.hdpmodel.idx->gensim.matutils.argsort(topics_sums, reverse=True)
A:gensim.models.hdpmodel.hdp_formatter->HdpTopicFormatter(self.id2word, betas)
A:gensim.models.hdpmodel.alpha->numpy.zeros(self.m_T)
A:gensim.models.hdpmodel.ldam->gensim.models.ldamodel.LdaModel(num_topics=self.m_T, alpha=alpha, id2word=self.id2word, random_state=self.random_state, dtype=np.float64)
A:gensim.models.hdpmodel.(self.lda_alpha, self.lda_beta)->self.hdp_to_lda()
A:gensim.models.hdpmodel.(likelihood, gamma)->lda_e_step(doc_word_ids, doc_word_counts, self.lda_alpha, self.lda_beta)
A:gensim.models.hdpmodel.log_predicts->numpy.log(np.dot(theta, lda_betad))
A:gensim.models.hdpmodel.topics->numpy.loadtxt('%s' % topic_file)
A:gensim.models.hdpmodel.topics_sums->numpy.sum(topics, axis=1)
A:gensim.models.hdpmodel.num_topics->min(num_topics, len(self.data))
A:gensim.models.hdpmodel.temp->sorted(temp, key=lambda x: x[0], reverse=True)
A:gensim.models.hdpmodel.topic_terms->self.show_topic_terms(temp, topn)
A:gensim.models.hdpmodel.topic->self.format_topic(topic_id, topic_terms)
A:gensim.models.hdpmodel.fmt->'\n'.join(('    %20s    %.8f' % (word, weight) for (word, weight) in topic_terms))
gensim.models.HdpModel(self,corpus,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.models.HdpModel.__getitem__(self,bow,eps=0.01)
gensim.models.HdpModel.doc_e_step(self,ss,Elogsticks_1st,unique_words,doc_word_ids,doc_word_counts,var_converge)
gensim.models.HdpModel.evaluate_test_corpus(self,corpus)
gensim.models.HdpModel.get_topics(self)
gensim.models.HdpModel.hdp_to_lda(self)
gensim.models.HdpModel.inference(self,chunk)
gensim.models.HdpModel.optimal_ordering(self)
gensim.models.HdpModel.save_options(self)
gensim.models.HdpModel.save_topics(self,doc_count=None)
gensim.models.HdpModel.show_topic(self,topic_id,topn=20,log=False,formatted=False,num_words=None)
gensim.models.HdpModel.show_topics(self,num_topics=20,num_words=20,log=False,formatted=True)
gensim.models.HdpModel.suggested_lda_model(self)
gensim.models.HdpModel.update(self,corpus)
gensim.models.HdpModel.update_chunk(self,chunk,update=True,opt_o=True)
gensim.models.HdpModel.update_expectations(self)
gensim.models.HdpModel.update_finished(self,start_time,chunks_processed,docs_processed)
gensim.models.HdpModel.update_lambda(self,sstats,word_list,opt_o)
gensim.models.hdpmodel.HdpModel(self,corpus,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.models.hdpmodel.HdpModel.__getitem__(self,bow,eps=0.01)
gensim.models.hdpmodel.HdpModel.__init__(self,corpus,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.models.hdpmodel.HdpModel.doc_e_step(self,ss,Elogsticks_1st,unique_words,doc_word_ids,doc_word_counts,var_converge)
gensim.models.hdpmodel.HdpModel.evaluate_test_corpus(self,corpus)
gensim.models.hdpmodel.HdpModel.get_topics(self)
gensim.models.hdpmodel.HdpModel.hdp_to_lda(self)
gensim.models.hdpmodel.HdpModel.inference(self,chunk)
gensim.models.hdpmodel.HdpModel.optimal_ordering(self)
gensim.models.hdpmodel.HdpModel.save_options(self)
gensim.models.hdpmodel.HdpModel.save_topics(self,doc_count=None)
gensim.models.hdpmodel.HdpModel.show_topic(self,topic_id,topn=20,log=False,formatted=False,num_words=None)
gensim.models.hdpmodel.HdpModel.show_topics(self,num_topics=20,num_words=20,log=False,formatted=True)
gensim.models.hdpmodel.HdpModel.suggested_lda_model(self)
gensim.models.hdpmodel.HdpModel.update(self,corpus)
gensim.models.hdpmodel.HdpModel.update_chunk(self,chunk,update=True,opt_o=True)
gensim.models.hdpmodel.HdpModel.update_expectations(self)
gensim.models.hdpmodel.HdpModel.update_finished(self,start_time,chunks_processed,docs_processed)
gensim.models.hdpmodel.HdpModel.update_lambda(self,sstats,word_list,opt_o)
gensim.models.hdpmodel.HdpTopicFormatter(self,dictionary=None,topic_data=None,topic_file=None,style=None)
gensim.models.hdpmodel.HdpTopicFormatter.__init__(self,dictionary=None,topic_data=None,topic_file=None,style=None)
gensim.models.hdpmodel.HdpTopicFormatter.format_topic(self,topic_id,topic_terms)
gensim.models.hdpmodel.HdpTopicFormatter.print_topic(self,topic_id,topn=None,num_words=None)
gensim.models.hdpmodel.HdpTopicFormatter.print_topics(self,num_topics=10,num_words=10)
gensim.models.hdpmodel.HdpTopicFormatter.show_topic(self,topic_id,topn=20,log=False,formatted=False,num_words=None)
gensim.models.hdpmodel.HdpTopicFormatter.show_topic_terms(self,topic_data,num_words)
gensim.models.hdpmodel.HdpTopicFormatter.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.hdpmodel.SuffStats(self,T,Wt,Dt)
gensim.models.hdpmodel.SuffStats.__init__(self,T,Wt,Dt)
gensim.models.hdpmodel.SuffStats.set_zero(self)
gensim.models.hdpmodel.expect_log_sticks(sticks)
gensim.models.hdpmodel.lda_e_step(doc_word_ids,doc_word_counts,alpha,beta,max_iter=100)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/translation_matrix.py----------------------------------------
A:gensim.models.translation_matrix.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.translation_matrix.(self.source_word, self.target_word)->zip(*word_pairs)
A:gensim.models.translation_matrix.self.source_space->Space.build(self.source_lang_vec, set(self.source_word))
A:gensim.models.translation_matrix.self.target_space->Space.build(self.target_lang_vec, set(self.target_word))
A:gensim.models.translation_matrix.kwargs['ignore']->kwargs.get('ignore', ['source_space', 'target_space'])
A:gensim.models.translation_matrix.lexicon->self.random_state.choice(list(lexicon.difference(source_words)), addition)
A:gensim.models.translation_matrix.addition->min(sample_num, len(lexicon) - len(source_words))
A:gensim.models.translation_matrix.source_space->Space.build(source_lang_vec, source_words)
A:gensim.models.translation_matrix.target_space->Space.build(target_lang_vec)
A:gensim.models.translation_matrix.mapped_source_space->self.apply_transmat(source_space)
A:gensim.models.translation_matrix.srtd_idx->numpy.argsort(np.argsort(sim_matrix, axis=1), axis=1)
A:gensim.models.translation_matrix.sim_matrix_idx->numpy.argsort(sim_matrix, axis=0)
A:gensim.models.translation_matrix.translated_word->OrderedDict()
gensim.models.BackMappingTranslationMatrix(self,source_lang_vec,target_lang_vec,tagged_docs=None,random_state=None)
gensim.models.BackMappingTranslationMatrix.infer_vector(self,target_doc_vec)
gensim.models.BackMappingTranslationMatrix.train(self,tagged_docs)
gensim.models.TranslationMatrix(self,source_lang_vec,target_lang_vec,word_pairs=None,random_state=None)
gensim.models.TranslationMatrix.apply_transmat(self,words_space)
gensim.models.TranslationMatrix.save(self,*args,**kwargs)
gensim.models.TranslationMatrix.train(self,word_pairs)
gensim.models.TranslationMatrix.translate(self,source_words,topn=5,gc=0,sample_num=None,source_lang_vec=None,target_lang_vec=None)
gensim.models.translation_matrix.BackMappingTranslationMatrix(self,source_lang_vec,target_lang_vec,tagged_docs=None,random_state=None)
gensim.models.translation_matrix.BackMappingTranslationMatrix.__init__(self,source_lang_vec,target_lang_vec,tagged_docs=None,random_state=None)
gensim.models.translation_matrix.BackMappingTranslationMatrix.infer_vector(self,target_doc_vec)
gensim.models.translation_matrix.BackMappingTranslationMatrix.train(self,tagged_docs)
gensim.models.translation_matrix.Space(self,matrix,index2word)
gensim.models.translation_matrix.Space.__init__(self,matrix,index2word)
gensim.models.translation_matrix.Space.build(cls,lang_vec,lexicon=None)
gensim.models.translation_matrix.Space.normalize(self)
gensim.models.translation_matrix.TranslationMatrix(self,source_lang_vec,target_lang_vec,word_pairs=None,random_state=None)
gensim.models.translation_matrix.TranslationMatrix.__init__(self,source_lang_vec,target_lang_vec,word_pairs=None,random_state=None)
gensim.models.translation_matrix.TranslationMatrix.apply_transmat(self,words_space)
gensim.models.translation_matrix.TranslationMatrix.save(self,*args,**kwargs)
gensim.models.translation_matrix.TranslationMatrix.train(self,word_pairs)
gensim.models.translation_matrix.TranslationMatrix.translate(self,source_words,topn=5,gc=0,sample_num=None,source_lang_vec=None,target_lang_vec=None)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/atmodel.py----------------------------------------
A:gensim.models.atmodel.logger->logging.getLogger(__name__)
A:gensim.models.atmodel.self.sstats->numpy.zeros(lambda_shape)
A:gensim.models.atmodel.self.gamma->numpy.zeros(gamma_shape)
A:gensim.models.atmodel.authors_ids->set()
A:gensim.models.atmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.atmodel.self.num_terms->len(self.id2word)
A:gensim.models.atmodel.(self.alpha, self.optimize_alpha)->self.init_dir_prior(alpha, 'alpha')
A:gensim.models.atmodel.(self.eta, self.optimize_eta)->self.init_dir_prior(eta, 'eta')
A:gensim.models.atmodel.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.atmodel.self.state->AuthorTopicState(self.eta, (self.num_topics, self.num_terms), (self.num_authors, self.num_topics))
A:gensim.models.atmodel.self.state.sstats->self.random_state.gamma(100.0, 1.0 / 100.0, (self.num_topics, self.num_terms))
A:gensim.models.atmodel.self.expElogbeta->numpy.exp(dirichlet_expectation(self.state.sstats))
A:gensim.models.atmodel.self.corpus->MmCorpus(self.serialization_path)
A:gensim.models.atmodel.corpus_chain->chain(self.corpus, corpus)
A:gensim.models.atmodel.expElogtheta_sum->numpy.exp(Elogthetad).sum(axis=0)
A:gensim.models.atmodel.chunk->list(chunk)
A:gensim.models.atmodel.sstats->numpy.zeros_like(self.expElogbeta)
A:gensim.models.atmodel.gamma_chunk->numpy.vstack([gamma_chunk, tilde_gamma])
A:gensim.models.atmodel.ids->numpy.fromiter((id for (id, _) in doc), dtype=int, count=len(doc))
A:gensim.models.atmodel.cts->numpy.fromiter((cnt for (_, cnt) in doc), dtype=int, count=len(doc))
A:gensim.models.atmodel.authors_d->numpy.fromiter((self.author2id[a] for a in self.doc2author[doc_no]), dtype=int)
A:gensim.models.atmodel.tilde_gamma->gammad.copy()
A:gensim.models.atmodel.Elogthetad->dirichlet_expectation(tilde_gamma)
A:gensim.models.atmodel.expElogthetad->numpy.exp(Elogthetad)
A:gensim.models.atmodel.phinorm->self.compute_phinorm(expElogtheta[authors_d, :], expElogbeta[:, ids])
A:gensim.models.atmodel.lastgamma->gammad.copy().copy()
A:gensim.models.atmodel.dot->numpy.dot(cts / phinorm, expElogbetad.T)
A:gensim.models.atmodel.meanchange_gamma->mean_absolute_difference(tilde_gamma.ravel(), lastgamma.ravel())
A:gensim.models.atmodel.expElogtheta_sum_a->numpy.exp(Elogthetad).sum(axis=0)
A:gensim.models.atmodel.(gamma, sstats)->self.inference(chunk, author2doc, doc2author, rhot, collect_sstats=True, chunk_doc_idx=chunk_doc_idx)
A:gensim.models.atmodel.total_docs->len(chunk)
A:gensim.models.atmodel.corpus_words->sum((cnt for document in chunk for (_, cnt) in document))
A:gensim.models.atmodel.author2doc->construct_author2doc(doc2author)
A:gensim.models.atmodel.doc2author->construct_doc2author(corpus, author2doc)
A:gensim.models.atmodel.num_input_authors->len(author2doc)
A:gensim.models.atmodel.len_input_corpus->sum((1 for _ in corpus))
A:gensim.models.atmodel.num_new_authors->len(new_authors)
A:gensim.models.atmodel.gamma_new->self.random_state.gamma(100.0, 1.0 / 100.0, (num_new_authors, self.num_topics))
A:gensim.models.atmodel.self.state.gamma->numpy.vstack([self.state.gamma, gamma_new])
A:gensim.models.atmodel.train_corpus_idx->sorted(train_corpus_idx)
A:gensim.models.atmodel.lencorpus->len(train_corpus_idx)
A:gensim.models.atmodel.chunksize->min(lencorpus, self.chunksize)
A:gensim.models.atmodel.updateafter->min(lencorpus, update_every * self.numworkers * chunksize)
A:gensim.models.atmodel.evalafter->min(lencorpus, (eval_every or 0) * self.numworkers * chunksize)
A:gensim.models.atmodel.updates_per_pass->max(1, lencorpus / updateafter)
A:gensim.models.atmodel.other->self.dispatcher.getstate()
A:gensim.models.atmodel.gammat->self.do_estep(chunk, self.author2doc, self.doc2author, rho(), other, chunk_doc_idx)
A:gensim.models.atmodel._lambda->self.state.get_lambda()
A:gensim.models.atmodel.Elogbeta->dirichlet_expectation(_lambda)
A:gensim.models.atmodel.expElogbeta->numpy.exp(Elogbeta)
A:gensim.models.atmodel.Elogtheta->dirichlet_expectation(gamma)
A:gensim.models.atmodel.expElogtheta->numpy.exp(Elogtheta)
A:gensim.models.atmodel.sum_eta->numpy.sum(self.eta)
A:gensim.models.atmodel.corpus_doc_idx->list(range(self.total_docs, self.total_docs + len_input_corpus))
A:gensim.models.atmodel.(gammat, _)->self.inference(corpus, self.author2doc, self.doc2author, rho(), collect_sstats=False, chunk_doc_idx=corpus_doc_idx)
A:gensim.models.atmodel.new_author_topics->self.get_author_topics(new_author_name, minimum_probability)
A:gensim.models.atmodel.minimum_probability->max(minimum_probability, 1e-08)
A:gensim.models.atmodel.items->self.get_author_topics(author_names, minimum_probability=eps)
gensim.models.AuthorTopicModel(self,corpus=None,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.models.AuthorTopicModel.__getitem__(self,author_names,eps=None)
gensim.models.AuthorTopicModel.__str__(self)
gensim.models.AuthorTopicModel.bound(self,chunk,chunk_doc_idx=None,subsample_ratio=1.0,author2doc=None,doc2author=None)
gensim.models.AuthorTopicModel.compute_phinorm(self,expElogthetad,expElogbetad)
gensim.models.AuthorTopicModel.do_estep(self,chunk,author2doc,doc2author,rhot,state=None,chunk_doc_idx=None)
gensim.models.AuthorTopicModel.extend_corpus(self,corpus)
gensim.models.AuthorTopicModel.get_author_topics(self,author_name,minimum_probability=None)
gensim.models.AuthorTopicModel.get_document_topics(self,word_id,minimum_probability=None)
gensim.models.AuthorTopicModel.get_new_author_topics(self,corpus,minimum_probability=None)
gensim.models.AuthorTopicModel.inference(self,chunk,author2doc,doc2author,rhot,collect_sstats=False,chunk_doc_idx=None)
gensim.models.AuthorTopicModel.init_empty_corpus(self)
gensim.models.AuthorTopicModel.log_perplexity(self,chunk,chunk_doc_idx=None,total_docs=None)
gensim.models.AuthorTopicModel.update(self,corpus=None,author2doc=None,doc2author=None,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.atmodel.AuthorTopicModel(self,corpus=None,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.models.atmodel.AuthorTopicModel.__getitem__(self,author_names,eps=None)
gensim.models.atmodel.AuthorTopicModel.__init__(self,corpus=None,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.models.atmodel.AuthorTopicModel.__str__(self)
gensim.models.atmodel.AuthorTopicModel.bound(self,chunk,chunk_doc_idx=None,subsample_ratio=1.0,author2doc=None,doc2author=None)
gensim.models.atmodel.AuthorTopicModel.compute_phinorm(self,expElogthetad,expElogbetad)
gensim.models.atmodel.AuthorTopicModel.do_estep(self,chunk,author2doc,doc2author,rhot,state=None,chunk_doc_idx=None)
gensim.models.atmodel.AuthorTopicModel.extend_corpus(self,corpus)
gensim.models.atmodel.AuthorTopicModel.get_author_topics(self,author_name,minimum_probability=None)
gensim.models.atmodel.AuthorTopicModel.get_document_topics(self,word_id,minimum_probability=None)
gensim.models.atmodel.AuthorTopicModel.get_new_author_topics(self,corpus,minimum_probability=None)
gensim.models.atmodel.AuthorTopicModel.inference(self,chunk,author2doc,doc2author,rhot,collect_sstats=False,chunk_doc_idx=None)
gensim.models.atmodel.AuthorTopicModel.init_empty_corpus(self)
gensim.models.atmodel.AuthorTopicModel.log_perplexity(self,chunk,chunk_doc_idx=None,total_docs=None)
gensim.models.atmodel.AuthorTopicModel.update(self,corpus=None,author2doc=None,doc2author=None,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.atmodel.AuthorTopicState(self,eta,lambda_shape,gamma_shape)
gensim.models.atmodel.AuthorTopicState.__init__(self,eta,lambda_shape,gamma_shape)
gensim.models.atmodel.construct_author2doc(doc2author)
gensim.models.atmodel.construct_doc2author(corpus,author2doc)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/phrases.py----------------------------------------
A:gensim.models.phrases.logger->logging.getLogger(__name__)
A:gensim.models.phrases.NEGATIVE_INFINITY->float('-inf')
A:gensim.models.phrases.ENGLISH_CONNECTOR_WORDS->frozenset(' a an the  for of with without at from to in on by  and or '.split())
A:gensim.models.phrases.corpus_word_count->float(corpus_word_count)
A:gensim.models.phrases.obj_iter->itertools.chain([peek], obj_iter)
A:gensim.models.phrases.peek->next(obj_iter)
A:gensim.models.phrases.self.connector_words->frozenset(connector_words)
A:gensim.models.phrases.(phrase, score)->self.score_candidate(unigrams[0], unigrams[-1], unigrams[1:-1])
A:gensim.models.phrases.(is_single, sentence)->_is_single(sentence)
A:gensim.models.phrases.model->super(_PhrasesTransformation, cls).load(*args, **kwargs)
A:gensim.models.phrases.phrasegrams->getattr(model, 'phrasegrams', {})
A:gensim.models.phrases.(component, score)->next(iter(phrasegrams.items()))
A:gensim.models.phrases.model.connector_words->frozenset()
A:gensim.models.phrases.word->next(iter(model.vocab))
A:gensim.models.phrases.model.delimiter->str(model.delimiter, encoding='utf8')
A:gensim.models.phrases.start->time.time()
A:gensim.models.phrases.phrase_tokens->itertools.chain([start_token], in_between, [word])
A:gensim.models.phrases.joined_phrase_token->delimiter.join(phrase_tokens)
A:gensim.models.phrases.(min_reduce, vocab, total_words)->self._learn_vocab(sentences, max_vocab_size=self.max_vocab_size, delimiter=self.delimiter, progress_per=self.progress_per, connector_words=self.connector_words)
A:gensim.models.phrases.self.min_reduce->max(self.min_reduce, min_reduce)
A:gensim.models.phrases.word_a_cnt->self.vocab.get(word_a, 0)
A:gensim.models.phrases.word_b_cnt->self.vocab.get(word_b, 0)
A:gensim.models.phrases.phrase->self.delimiter.join([word_a] + in_between + [word_b])
A:gensim.models.phrases.phrase_cnt->self.vocab.get(phrase, 0)
A:gensim.models.phrases.score->self.phrasegrams.get(phrase, NEGATIVE_INFINITY)
A:gensim.models.phrases.unigrams->token.split(self.delimiter)
A:gensim.models.phrases.self.phrasegrams->phrases_model.export_phrases()
gensim.models.Phrases(self,sentences=None,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter='_',progress_per=10000,scoring='default',connector_words=frozenset())
gensim.models.Phrases.__str__(self)
gensim.models.Phrases._learn_vocab(sentences,max_vocab_size,delimiter,connector_words,progress_per)
gensim.models.Phrases.add_vocab(self,sentences)
gensim.models.Phrases.export_phrases(self)
gensim.models.Phrases.freeze(self)
gensim.models.Phrases.score_candidate(self,word_a,word_b,in_between)
gensim.models.phrases.FrozenPhrases(self,phrases_model)
gensim.models.phrases.FrozenPhrases.__init__(self,phrases_model)
gensim.models.phrases.FrozenPhrases.__str__(self)
gensim.models.phrases.FrozenPhrases.score_candidate(self,word_a,word_b,in_between)
gensim.models.phrases.Phrases(self,sentences=None,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter='_',progress_per=10000,scoring='default',connector_words=frozenset())
gensim.models.phrases.Phrases.__init__(self,sentences=None,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter='_',progress_per=10000,scoring='default',connector_words=frozenset())
gensim.models.phrases.Phrases.__str__(self)
gensim.models.phrases.Phrases._learn_vocab(sentences,max_vocab_size,delimiter,connector_words,progress_per)
gensim.models.phrases.Phrases.add_vocab(self,sentences)
gensim.models.phrases.Phrases.export_phrases(self)
gensim.models.phrases.Phrases.freeze(self)
gensim.models.phrases.Phrases.score_candidate(self,word_a,word_b,in_between)
gensim.models.phrases._PhrasesTransformation(self,connector_words)
gensim.models.phrases._PhrasesTransformation.__getitem__(self,sentence)
gensim.models.phrases._PhrasesTransformation.__init__(self,connector_words)
gensim.models.phrases._PhrasesTransformation.analyze_sentence(self,sentence)
gensim.models.phrases._PhrasesTransformation.find_phrases(self,sentences)
gensim.models.phrases._PhrasesTransformation.load(cls,*args,**kwargs)
gensim.models.phrases._PhrasesTransformation.score_candidate(self,word_a,word_b,in_between)
gensim.models.phrases._is_single(obj)
gensim.models.phrases.npmi_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)
gensim.models.phrases.original_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/ldamulticore.py----------------------------------------
A:gensim.models.ldamulticore.logger->logging.getLogger(__name__)
A:gensim.models.ldamulticore.lencorpus->sum((1 for _ in corpus))
A:gensim.models.ldamulticore.evalafter->min(lencorpus, eval_every * updateafter)
A:gensim.models.ldamulticore.updates_per_pass->max(1, lencorpus / updateafter)
A:gensim.models.ldamulticore.job_queue->Queue(maxsize=2 * self.workers)
A:gensim.models.ldamulticore.result_queue->Queue()
A:gensim.models.ldamulticore.pool->Pool(self.workers, worker_e_step, (job_queue, result_queue, self))
A:gensim.models.ldamulticore.other->LdaState(self.eta, self.state.sstats.shape)
A:gensim.models.ldamulticore.chunk_stream->gensim.utils.grouper(corpus, self.chunksize, as_numpy=chunks_as_numpy)
A:gensim.models.ldamulticore.(chunk_no, chunk, w_state)->input_queue.get()
gensim.models.LdaMulticore(self,corpus=None,num_topics=100,id2word=None,workers=None,chunksize=2000,passes=1,batch=False,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,random_state=None,minimum_probability=0.01,minimum_phi_value=0.01,per_word_topics=False,dtype=np.float32)
gensim.models.LdaMulticore.update(self,corpus,chunks_as_numpy=False)
gensim.models.ldamulticore.LdaMulticore(self,corpus=None,num_topics=100,id2word=None,workers=None,chunksize=2000,passes=1,batch=False,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,random_state=None,minimum_probability=0.01,minimum_phi_value=0.01,per_word_topics=False,dtype=np.float32)
gensim.models.ldamulticore.LdaMulticore.__init__(self,corpus=None,num_topics=100,id2word=None,workers=None,chunksize=2000,passes=1,batch=False,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,random_state=None,minimum_probability=0.01,minimum_phi_value=0.01,per_word_topics=False,dtype=np.float32)
gensim.models.ldamulticore.LdaMulticore.update(self,corpus,chunks_as_numpy=False)
gensim.models.ldamulticore.worker_e_step(input_queue,result_queue,worker_lda)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/lsimodel.py----------------------------------------
A:gensim.models.lsimodel.logger->logging.getLogger(__name__)
A:gensim.models.lsimodel.rel_spectrum->numpy.abs(1.0 - np.cumsum(s / np.sum(s)))
A:gensim.models.lsimodel.k->clip_spectrum(s_k ** 2, self.k)
A:gensim.models.lsimodel.a->numpy.ascontiguousarray(a)
A:gensim.models.lsimodel.(u, s)->stochastic_svd(docs, k, chunksize=sys.maxsize, num_terms=m, power_iters=self.power_iters, extra_dims=self.extra_dims, dtype=dtype)
A:gensim.models.lsimodel.docs->gensim.matutils.corpus2csc(docs)
A:gensim.models.lsimodel.(ut, s, vt)->sparsesvd.sparsesvd(docs, k + 30)
A:gensim.models.lsimodel.self.u->numpy.dot(self.u, u1_k)
A:gensim.models.lsimodel.self.s->other.s.copy()
A:gensim.models.lsimodel.c->numpy.asarray(self.projection.u.T[topicno, :]).flatten()
A:gensim.models.lsimodel.(q, r)->gensim.matutils.qr_destroy(other.u)
A:gensim.models.lsimodel.(u_k, s_k, _)->scipy.linalg.svd(np.dot(k, k.T), full_matrices=False)
A:gensim.models.lsimodel.s_k->numpy.sqrt(s_k)
A:gensim.models.lsimodel.q->q[:, :samples].T.copy().T.copy()
A:gensim.models.lsimodel.self.num_topics->int(num_topics)
A:gensim.models.lsimodel.self.chunksize->int(chunksize)
A:gensim.models.lsimodel.self.decay->float(decay)
A:gensim.models.lsimodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.lsimodel.self.num_terms->len(self.id2word)
A:gensim.models.lsimodel.self.projection->self.dispatcher.getstate()
A:gensim.models.lsimodel.dispatcher->Pyro4.Proxy('PYRONAME:gensim.lsi_dispatcher')
A:gensim.models.lsimodel.self.numworkers->len(dispatcher.getworkers())
A:gensim.models.lsimodel.start->time.time()
A:gensim.models.lsimodel.update->Projection(self.num_terms, self.num_topics, corpus.tocsc(), extra_dims=self.extra_samples, power_iters=self.power_iters, dtype=self.dtype)
A:gensim.models.lsimodel.(update.u, update.s)->stochastic_svd(corpus, self.num_topics, num_terms=self.num_terms, chunksize=chunksize, extra_dims=self.extra_samples, power_iters=self.power_iters, dtype=self.dtype)
A:gensim.models.lsimodel.nnz->sum((len(doc) for doc in chunk))
A:gensim.models.lsimodel.job->gensim.matutils.corpus2csc(chunk, num_docs=len(chunk), num_terms=self.num_terms, num_nnz=nnz, dtype=self.dtype)
A:gensim.models.lsimodel.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.lsimodel.vec->gensim.matutils.corpus2csc(bow, num_terms=self.num_terms, dtype=self.projection.u.dtype)
A:gensim.models.lsimodel.topic_dist->topic_dist.reshape(-1).reshape(-1)
A:gensim.models.lsimodel.result->super(LsiModel, cls).load(fname, *args, **kwargs)
A:gensim.models.lsimodel.num_topics->len(projections)
A:gensim.models.lsimodel.norm->numpy.sqrt(np.sum(np.dot(c, c)))
A:gensim.models.lsimodel.most->gensim.matutils.argsort(np.abs(c), topn, reverse=True)
A:gensim.models.lsimodel.topic->self.show_topic(i, topn=num_words)
A:gensim.models.lsimodel.kwargs['mmap']->kwargs.get('mmap', None)
A:gensim.models.lsimodel.projection_fname->gensim.utils.smart_extension(fname, '.projection')
A:gensim.models.lsimodel.result.projection->super(LsiModel, cls).load(projection_fname, *args, **kwargs)
A:gensim.models.lsimodel.uvec->numpy.abs(np.asarray(uvec).flatten())
A:gensim.models.lsimodel.weights->sorted(result[topic], key=lambda x: -abs(x[0]))
A:gensim.models.lsimodel.rank->int(rank)
A:gensim.models.lsimodel.samples->max(10, 2 * rank)
A:gensim.models.lsimodel.num_terms->int(num_terms)
A:gensim.models.lsimodel.y->y.astype(dtype).astype(dtype)
A:gensim.models.lsimodel.o->numpy.random.normal(0.0, 1.0, (n, samples)).astype(dtype)
A:gensim.models.lsimodel.(q, _)->gensim.matutils.qr_destroy(q)
A:gensim.models.lsimodel.s->numpy.sqrt(s)
A:gensim.models.lsimodel.chunk->gensim.matutils.corpus2csc(chunk, num_terms=num_terms, dtype=qt.dtype)
A:gensim.models.lsimodel.yold->q[:, :samples].T.copy().T.copy().copy()
A:gensim.models.lsimodel.qt->q[:, :samples].T.copy()
A:gensim.models.lsimodel.(u, s, vt)->scipy.linalg.svd(x)
A:gensim.models.lsimodel.x->numpy.zeros(shape=(qt.shape[0], qt.shape[0]), dtype=dtype)
A:gensim.models.lsimodel.keep->clip_spectrum(s ** 2, rank, discard=eps)
A:gensim.models.lsimodel.u->numpy.dot(q, u)
gensim.models.LsiModel(self,corpus=None,num_topics=200,id2word=None,chunksize=20000,decay=1.0,distributed=False,onepass=True,power_iters=P2_EXTRA_ITERS,extra_samples=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.LsiModel.__getitem__(self,bow,scaled=False,chunksize=512)
gensim.models.LsiModel.__str__(self)
gensim.models.LsiModel.add_documents(self,corpus,chunksize=None,decay=None)
gensim.models.LsiModel.get_topics(self)
gensim.models.LsiModel.load(cls,fname,*args,**kwargs)
gensim.models.LsiModel.print_debug(self,num_topics=5,num_words=10)
gensim.models.LsiModel.save(self,fname,*args,**kwargs)
gensim.models.LsiModel.show_topic(self,topicno,topn=10)
gensim.models.LsiModel.show_topics(self,num_topics=-1,num_words=10,log=False,formatted=True)
gensim.models.lsimodel.LsiModel(self,corpus=None,num_topics=200,id2word=None,chunksize=20000,decay=1.0,distributed=False,onepass=True,power_iters=P2_EXTRA_ITERS,extra_samples=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.LsiModel.__getitem__(self,bow,scaled=False,chunksize=512)
gensim.models.lsimodel.LsiModel.__init__(self,corpus=None,num_topics=200,id2word=None,chunksize=20000,decay=1.0,distributed=False,onepass=True,power_iters=P2_EXTRA_ITERS,extra_samples=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.LsiModel.__str__(self)
gensim.models.lsimodel.LsiModel.add_documents(self,corpus,chunksize=None,decay=None)
gensim.models.lsimodel.LsiModel.get_topics(self)
gensim.models.lsimodel.LsiModel.load(cls,fname,*args,**kwargs)
gensim.models.lsimodel.LsiModel.print_debug(self,num_topics=5,num_words=10)
gensim.models.lsimodel.LsiModel.save(self,fname,*args,**kwargs)
gensim.models.lsimodel.LsiModel.show_topic(self,topicno,topn=10)
gensim.models.lsimodel.LsiModel.show_topics(self,num_topics=-1,num_words=10,log=False,formatted=True)
gensim.models.lsimodel.Projection(self,m,k,docs=None,use_svdlibc=False,power_iters=P2_EXTRA_ITERS,extra_dims=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.Projection.__init__(self,m,k,docs=None,use_svdlibc=False,power_iters=P2_EXTRA_ITERS,extra_dims=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.Projection.empty_like(self)
gensim.models.lsimodel.Projection.merge(self,other,decay=1.0)
gensim.models.lsimodel.ascarray(a,name='')
gensim.models.lsimodel.asfarray(a,name='')
gensim.models.lsimodel.clip_spectrum(s,k,discard=0.001)
gensim.models.lsimodel.print_debug(id2token,u,s,topics,num_words=10,num_neg=None)
gensim.models.lsimodel.stochastic_svd(corpus,rank,num_terms,chunksize=20000,extra_dims=None,power_iters=0,dtype=np.float64,eps=1e-06)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/nmf.py----------------------------------------
A:gensim.models.nmf.logger->logging.getLogger(__name__)
A:gensim.models.nmf.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.nmf.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.nmf.self.num_tokens->len(self.id2word)
A:gensim.models.nmf.sparsity->numpy.zeros(self._W.shape[1])
A:gensim.models.nmf.chosen_topics->range(num_topics)
A:gensim.models.nmf.num_topics->min(num_topics, self.num_topics)
A:gensim.models.nmf.sorted_topics->list(matutils.argsort(sparsity))
A:gensim.models.nmf.topics->self.get_topics(normalize=normalize)
A:gensim.models.nmf.bestn->gensim.matutils.argsort(topic, topn=topn, reverse=True)
A:gensim.models.nmf.topic->' + '.join(['%.3f*"%s"' % (v, k) for (k, v) in topic])
A:gensim.models.nmf.cm->CoherenceModel(model=self, corpus=corpus, texts=texts, dictionary=dictionary, window_size=window_size, coherence=coherence, topn=topn, processes=processes)
A:gensim.models.nmf.coherence_scores->CoherenceModel(model=self, corpus=corpus, texts=texts, dictionary=dictionary, window_size=window_size, coherence=coherence, topn=topn, processes=processes).get_coherence_per_topic()
A:gensim.models.nmf.scored_topics->zip(str_topics, coherence_scores)
A:gensim.models.nmf.minimum_probability->max(minimum_probability, 1e-08)
A:gensim.models.nmf.(is_corpus, corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.nmf.kwargs->dict(minimum_probability=minimum_probability)
A:gensim.models.nmf.v->gensim.matutils.corpus2csc(chunk, num_terms=self.num_tokens)
A:gensim.models.nmf.h->numpy.zeros(hshape)
A:gensim.models.nmf.the_sum->numpy.zeros(hshape).sum()
A:gensim.models.nmf.self.w_std->numpy.sqrt(v.mean() / (self.num_tokens * self.num_topics))
A:gensim.models.nmf.self._W->numpy.abs(self.w_std * halfnorm.rvs(size=(self.num_tokens, self.num_topics), random_state=self.random_state))
A:gensim.models.nmf.self.A->numpy.zeros((self.num_topics, self.num_topics))
A:gensim.models.nmf.self.B->numpy.zeros((self.num_tokens, self.num_topics))
A:gensim.models.nmf.lencorpus->len(corpus)
A:gensim.models.nmf.chunksize->min(lencorpus, self.chunksize)
A:gensim.models.nmf.evalafter->min(lencorpus, (eval_every or 0) * chunksize)
A:gensim.models.nmf.grouper->gensim.utils.grouper(corpus, self.chunksize)
A:gensim.models.nmf.chunk_len->len(chunk)
A:gensim.models.nmf.self._h->self._solveproj(v, self._W, h=self._h, v_max=self.v_max)
A:gensim.models.nmf.WA->self._W.dot(self.A)
A:gensim.models.nmf.error_->solve_h(h, Wtv, WtW, permutation, self._kappa)
A:gensim.models.nmf.sumsq->numpy.sqrt(np.einsum('ij,ij->j', self._W, self._W))
A:gensim.models.nmf.self.v_max->gensim.matutils.corpus2csc(chunk, num_terms=self.num_tokens).max()
A:gensim.models.nmf.WtW->Wt.dot(W)
A:gensim.models.nmf.Wtv->self._dense_dot_csc(Wt, v)
A:gensim.models.nmf.permutation->self.random_state.permutation(self.num_topics).astype(np.int32)
gensim.models.Nmf(self,corpus=None,num_topics=100,id2word=None,chunksize=2000,passes=1,kappa=1.0,minimum_probability=0.01,w_max_iter=200,w_stop_condition=0.0001,h_max_iter=50,h_stop_condition=0.001,eval_every=10,normalize=True,random_state=None)
gensim.models.Nmf.__getitem__(self,bow,eps=None)
gensim.models.Nmf._apply(self,corpus,chunksize=None,**kwargs)
gensim.models.Nmf._dense_dot_csc(dense,csc)
gensim.models.Nmf._setup(self,v)
gensim.models.Nmf._solve_w(self)
gensim.models.Nmf._solveproj(self,v,W,h=None,v_max=None)
gensim.models.Nmf._transform(self)
gensim.models.Nmf.get_document_topics(self,bow,minimum_probability=None,normalize=None)
gensim.models.Nmf.get_term_topics(self,word_id,minimum_probability=None,normalize=None)
gensim.models.Nmf.get_topic_terms(self,topicid,topn=10,normalize=None)
gensim.models.Nmf.get_topics(self,normalize=None)
gensim.models.Nmf.l2_norm(self,v)
gensim.models.Nmf.show_topic(self,topicid,topn=10,normalize=None)
gensim.models.Nmf.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True,normalize=None)
gensim.models.Nmf.top_topics(self,corpus,texts=None,dictionary=None,window_size=None,coherence='u_mass',topn=20,processes=-1)
gensim.models.Nmf.update(self,corpus,chunksize=None,passes=None,eval_every=None)
gensim.models.nmf.Nmf(self,corpus=None,num_topics=100,id2word=None,chunksize=2000,passes=1,kappa=1.0,minimum_probability=0.01,w_max_iter=200,w_stop_condition=0.0001,h_max_iter=50,h_stop_condition=0.001,eval_every=10,normalize=True,random_state=None)
gensim.models.nmf.Nmf.__getitem__(self,bow,eps=None)
gensim.models.nmf.Nmf.__init__(self,corpus=None,num_topics=100,id2word=None,chunksize=2000,passes=1,kappa=1.0,minimum_probability=0.01,w_max_iter=200,w_stop_condition=0.0001,h_max_iter=50,h_stop_condition=0.001,eval_every=10,normalize=True,random_state=None)
gensim.models.nmf.Nmf._apply(self,corpus,chunksize=None,**kwargs)
gensim.models.nmf.Nmf._dense_dot_csc(dense,csc)
gensim.models.nmf.Nmf._setup(self,v)
gensim.models.nmf.Nmf._solve_w(self)
gensim.models.nmf.Nmf._solveproj(self,v,W,h=None,v_max=None)
gensim.models.nmf.Nmf._transform(self)
gensim.models.nmf.Nmf.get_document_topics(self,bow,minimum_probability=None,normalize=None)
gensim.models.nmf.Nmf.get_term_topics(self,word_id,minimum_probability=None,normalize=None)
gensim.models.nmf.Nmf.get_topic_terms(self,topicid,topn=10,normalize=None)
gensim.models.nmf.Nmf.get_topics(self,normalize=None)
gensim.models.nmf.Nmf.l2_norm(self,v)
gensim.models.nmf.Nmf.show_topic(self,topicid,topn=10,normalize=None)
gensim.models.nmf.Nmf.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True,normalize=None)
gensim.models.nmf.Nmf.top_topics(self,corpus,texts=None,dictionary=None,window_size=None,coherence='u_mass',topn=20,processes=-1)
gensim.models.nmf.Nmf.update(self,corpus,chunksize=None,passes=None,eval_every=None)
gensim.models.nmf.version_tuple(version,prefix=2)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/ldaseqmodel.py----------------------------------------
A:gensim.models.ldaseqmodel.logger->logging.getLogger(__name__)
A:gensim.models.ldaseqmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.ldaseqmodel.self.vocab_len->len(self.id2word)
A:gensim.models.ldaseqmodel.self.corpus_len->sum((1 for _ in corpus))
A:gensim.models.ldaseqmodel.self.num_time_slices->len(time_slice)
A:gensim.models.ldaseqmodel.self.alphas->numpy.full(num_topics, alphas)
A:gensim.models.ldaseqmodel.sslm_->sslm(num_time_slices=self.num_time_slices, vocab_len=self.vocab_len, num_topics=self.num_topics, chain_variance=chain_variance, obs_variance=obs_variance)
A:gensim.models.ldaseqmodel.self.max_doc_len->max((len(line) for line in corpus))
A:gensim.models.ldaseqmodel.lda_model->self.make_lda_seq_slice(lda_model, time)
A:gensim.models.ldaseqmodel.self.sstats->numpy.transpose(lda_model.state.sstats)
A:gensim.models.ldaseqmodel.gammas->numpy.zeros((corpus_len, num_topics))
A:gensim.models.ldaseqmodel.lhoods->numpy.zeros((corpus_len, num_topics + 1))
A:gensim.models.ldaseqmodel.(bound, gammas)->self.inferDIMseq(corpus, topic_suffstats, gammas, lhoods, lda, ldapost, iter_, bound, lda_inference_max_iter, chunksize)
A:gensim.models.ldaseqmodel.topic_bound->self.fit_lda_seq_topics(topic_suffstats)
A:gensim.models.ldaseqmodel.convergence->numpy.fabs((bound - old_bound) / old_bound)
A:gensim.models.ldaseqmodel.lda->self.make_lda_seq_slice(lda, time)
A:gensim.models.ldaseqmodel.lda.topics->numpy.zeros((vocab_len, num_topics))
A:gensim.models.ldaseqmodel.ldapost->LdaPost(num_topics=self.num_topics, max_doc_len=len(doc), lda=lda_model, doc=doc)
A:gensim.models.ldaseqmodel.time_slice->numpy.cumsum(np.array(self.time_slice))
A:gensim.models.ldaseqmodel.doc_lhood->LdaPost.fit_lda_post(ldapost, doc_num, time, self, lda_inference_max_iter=lda_inference_max_iter)
A:gensim.models.ldaseqmodel.topic_suffstats->LdaPost.update_lda_seq_ss(ldapost, time, doc, topic_suffstats)
A:gensim.models.ldaseqmodel.lda.alpha->numpy.copy(self.alphas)
A:gensim.models.ldaseqmodel.lhood_term->sslm.fit_sslm(chain, topic_suffstats[k])
A:gensim.models.ldaseqmodel.topic->numpy.exp(topic[time])
A:gensim.models.ldaseqmodel.bestn->gensim.matutils.argsort(topic, top_terms, reverse=True)
A:gensim.models.ldaseqmodel.term_frequency->numpy.zeros(self.vocab_len)
A:gensim.models.ldaseqmodel.lda_model.topics->numpy.zeros((self.vocab_len, self.num_topics))
A:gensim.models.ldaseqmodel.lhood->self.compute_lda_lhood()
A:gensim.models.ldaseqmodel.self.obs->numpy.repeat(log_norm_counts, T, axis=0).reshape(W, T)
A:gensim.models.ldaseqmodel.self.e_log_prob->self.compute_expected_log_prob()
A:gensim.models.ldaseqmodel.self.mean->numpy.zeros((vocab_len, num_time_slices + 1))
A:gensim.models.ldaseqmodel.self.fwd_mean->numpy.zeros((vocab_len, num_time_slices + 1))
A:gensim.models.ldaseqmodel.self.fwd_variance->numpy.zeros((vocab_len, num_time_slices + 1))
A:gensim.models.ldaseqmodel.self.variance->numpy.zeros((vocab_len, num_time_slices + 1))
A:gensim.models.ldaseqmodel.self.zeta->self.update_zeta()
A:gensim.models.ldaseqmodel.self.zeta[j]->numpy.sum(np.exp(self.mean[:, j + 1] + self.variance[:, j + 1] / 2))
A:gensim.models.ldaseqmodel.c->numpy.power(fwd_variance[t] / (fwd_variance[t] + chain_variance), 2)
A:gensim.models.ldaseqmodel.log_norm_counts->numpy.log(log_norm_counts)
A:gensim.models.ldaseqmodel.(self.variance[w], self.fwd_variance[w])->self.compute_post_variance(w, self.chain_variance)
A:gensim.models.ldaseqmodel.(self.mean[w], self.fwd_mean[w])->self.compute_post_mean(w, self.chain_variance)
A:gensim.models.ldaseqmodel.totals->sstats.sum(axis=0)
A:gensim.models.ldaseqmodel.bound->self.compute_bound_fixed(sstats, totals)
A:gensim.models.ldaseqmodel.(self.obs, self.zeta)->self.update_obs(sstats, totals)
A:gensim.models.ldaseqmodel.converged->numpy.fabs((lhood_old - lhood) / (lhood_old * total))
A:gensim.models.ldaseqmodel.mean_deriv_mtx->numpy.zeros((T, T + 1))
A:gensim.models.ldaseqmodel.counts_norm->numpy.sqrt(counts_norm)
A:gensim.models.ldaseqmodel.norm_cutoff_obs->numpy.copy(obs)
A:gensim.models.ldaseqmodel.w_counts->numpy.zeros(len(w_counts))
A:gensim.models.ldaseqmodel.mean_deriv_mtx[t]->self.compute_mean_deriv(w, t, mean_deriv_mtx[t])
A:gensim.models.ldaseqmodel.deriv->sslm.compute_obs_deriv_fixed(p.word, p.word_counts, p.totals, p.sslm, p.mean_deriv_mtx, deriv)
A:gensim.models.ldaseqmodel.obs->scipy.optimize.fmin_cg(f=f_obs, fprime=df_obs, x0=obs, gtol=TOL, args=args, epsilon=STEP_SIZE, disp=0)
A:gensim.models.ldaseqmodel.self.temp_vect->numpy.zeros(T)
A:gensim.models.ldaseqmodel.self.temp_vect[u]->numpy.exp(mean[u + 1] + variance[u + 1] / 2)
A:gensim.models.ldaseqmodel.self.gamma->self.update_gamma()
A:gensim.models.ldaseqmodel.self.lhood->numpy.zeros(num_topics + 1)
A:gensim.models.ldaseqmodel.self.phi->numpy.zeros((max_doc_len, num_topics))
A:gensim.models.ldaseqmodel.self.log_phi->numpy.zeros((max_doc_len, num_topics))
A:gensim.models.ldaseqmodel.dig->numpy.zeros(num_topics)
A:gensim.models.ldaseqmodel.dig[k]->digamma(self.gamma[k])
A:gensim.models.ldaseqmodel.v->numpy.logaddexp(v, log_phi_row[i])
A:gensim.models.ldaseqmodel.phi_row->numpy.exp(log_phi_row)
A:gensim.models.ldaseqmodel.total->sum((count for (word_id, count) in self.doc))
A:gensim.models.ldaseqmodel.gamma_sum->numpy.sum(self.gamma)
A:gensim.models.ldaseqmodel.digsum->digamma(gamma_sum)
A:gensim.models.ldaseqmodel.(self.phi, self.log_phi)->self.update_phi_fixed(doc_number, time, sslm, g3_matrix, g4_matrix, g5_matrix)
A:gensim.models.ldaseqmodel.T->len(x)
A:gensim.models.ldaseqmodel.(sslm.mean[word], sslm.fwd_mean[word])->sslm.compute_post_mean(word, sslm.chain_variance)
gensim.models.LdaSeqModel(self,corpus=None,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.models.LdaSeqModel.__getitem__(self,doc)
gensim.models.LdaSeqModel.doc_topics(self,doc_number)
gensim.models.LdaSeqModel.dtm_coherence(self,time)
gensim.models.LdaSeqModel.dtm_vis(self,time,corpus)
gensim.models.LdaSeqModel.fit_lda_seq(self,corpus,lda_inference_max_iter,em_min_iter,em_max_iter,chunksize)
gensim.models.LdaSeqModel.fit_lda_seq_topics(self,topic_suffstats)
gensim.models.LdaSeqModel.inferDTMseq(self,corpus,topic_suffstats,gammas,lhoods,lda,ldapost,iter_,bound,lda_inference_max_iter,chunksize)
gensim.models.LdaSeqModel.init_ldaseq_ss(self,topic_chain_variance,topic_obs_variance,alpha,init_suffstats)
gensim.models.LdaSeqModel.lda_seq_infer(self,corpus,topic_suffstats,gammas,lhoods,iter_,lda_inference_max_iter,chunksize)
gensim.models.LdaSeqModel.make_lda_seq_slice(self,lda,time)
gensim.models.LdaSeqModel.print_topic(self,topic,time=0,top_terms=20)
gensim.models.LdaSeqModel.print_topic_times(self,topic,top_terms=20)
gensim.models.LdaSeqModel.print_topics(self,time=0,top_terms=20)
gensim.models.ldaseqmodel.LdaPost(self,doc=None,lda=None,max_doc_len=None,num_topics=None,gamma=None,lhood=None)
gensim.models.ldaseqmodel.LdaPost.__init__(self,doc=None,lda=None,max_doc_len=None,num_topics=None,gamma=None,lhood=None)
gensim.models.ldaseqmodel.LdaPost.compute_lda_lhood(self)
gensim.models.ldaseqmodel.LdaPost.fit_lda_post(self,doc_number,time,ldaseq,LDA_INFERENCE_CONVERGED=1e-08,lda_inference_max_iter=25,g=None,g3_matrix=None,g4_matrix=None,g5_matrix=None)
gensim.models.ldaseqmodel.LdaPost.init_lda_post(self)
gensim.models.ldaseqmodel.LdaPost.update_gamma(self)
gensim.models.ldaseqmodel.LdaPost.update_lda_seq_ss(self,time,doc,topic_suffstats)
gensim.models.ldaseqmodel.LdaPost.update_phi(self,doc_number,time)
gensim.models.ldaseqmodel.LdaSeqModel(self,corpus=None,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.models.ldaseqmodel.LdaSeqModel.__getitem__(self,doc)
gensim.models.ldaseqmodel.LdaSeqModel.__init__(self,corpus=None,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.models.ldaseqmodel.LdaSeqModel.doc_topics(self,doc_number)
gensim.models.ldaseqmodel.LdaSeqModel.dtm_coherence(self,time)
gensim.models.ldaseqmodel.LdaSeqModel.dtm_vis(self,time,corpus)
gensim.models.ldaseqmodel.LdaSeqModel.fit_lda_seq(self,corpus,lda_inference_max_iter,em_min_iter,em_max_iter,chunksize)
gensim.models.ldaseqmodel.LdaSeqModel.fit_lda_seq_topics(self,topic_suffstats)
gensim.models.ldaseqmodel.LdaSeqModel.inferDTMseq(self,corpus,topic_suffstats,gammas,lhoods,lda,ldapost,iter_,bound,lda_inference_max_iter,chunksize)
gensim.models.ldaseqmodel.LdaSeqModel.init_ldaseq_ss(self,topic_chain_variance,topic_obs_variance,alpha,init_suffstats)
gensim.models.ldaseqmodel.LdaSeqModel.lda_seq_infer(self,corpus,topic_suffstats,gammas,lhoods,iter_,lda_inference_max_iter,chunksize)
gensim.models.ldaseqmodel.LdaSeqModel.make_lda_seq_slice(self,lda,time)
gensim.models.ldaseqmodel.LdaSeqModel.print_topic(self,topic,time=0,top_terms=20)
gensim.models.ldaseqmodel.LdaSeqModel.print_topic_times(self,topic,top_terms=20)
gensim.models.ldaseqmodel.LdaSeqModel.print_topics(self,time=0,top_terms=20)
gensim.models.ldaseqmodel.df_obs(x,*args)
gensim.models.ldaseqmodel.f_obs(x,*args)
gensim.models.ldaseqmodel.sslm(self,vocab_len=None,num_time_slices=None,num_topics=None,obs_variance=0.5,chain_variance=0.005)
gensim.models.ldaseqmodel.sslm.__init__(self,vocab_len=None,num_time_slices=None,num_topics=None,obs_variance=0.5,chain_variance=0.005)
gensim.models.ldaseqmodel.sslm.compute_bound(self,sstats,totals)
gensim.models.ldaseqmodel.sslm.compute_expected_log_prob(self)
gensim.models.ldaseqmodel.sslm.compute_mean_deriv(self,word,time,deriv)
gensim.models.ldaseqmodel.sslm.compute_obs_deriv(self,word,word_counts,totals,mean_deriv_mtx,deriv)
gensim.models.ldaseqmodel.sslm.compute_post_mean(self,word,chain_variance)
gensim.models.ldaseqmodel.sslm.compute_post_variance(self,word,chain_variance)
gensim.models.ldaseqmodel.sslm.fit_sslm(self,sstats)
gensim.models.ldaseqmodel.sslm.sslm_counts_init(self,obs_variance,chain_variance,sstats)
gensim.models.ldaseqmodel.sslm.update_obs(self,sstats,totals)
gensim.models.ldaseqmodel.sslm.update_zeta(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/normmodel.py----------------------------------------
A:gensim.models.normmodel.logger->logging.getLogger(__name__)
A:gensim.models.normmodel.vector->gensim.matutils.unitvec(bow, self.norm)
gensim.models.NormModel(self,corpus=None,norm='l2')
gensim.models.NormModel.__getitem__(self,bow)
gensim.models.NormModel.__str__(self)
gensim.models.NormModel.calc_norm(self,corpus)
gensim.models.NormModel.normalize(self,bow)
gensim.models.normmodel.NormModel(self,corpus=None,norm='l2')
gensim.models.normmodel.NormModel.__getitem__(self,bow)
gensim.models.normmodel.NormModel.__init__(self,corpus=None,norm='l2')
gensim.models.normmodel.NormModel.__str__(self)
gensim.models.normmodel.NormModel.calc_norm(self,corpus)
gensim.models.normmodel.NormModel.normalize(self,bow)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/lda_worker.py----------------------------------------
A:gensim.models.lda_worker.logger->logging.getLogger('gensim.models.lda_worker')
A:gensim.models.lda_worker.self.lock_update->threading.Lock()
A:gensim.models.lda_worker.self.model->gensim.models.ldamodel.LdaModel(**model_params)
A:gensim.models.lda_worker.job->self.dispatcher.getjob(self.myid)
A:gensim.models.lda_worker.fname->os.path.join(tempfile.gettempdir(), 'lda_worker.pkl')
A:gensim.models.lda_worker.parser->argparse.ArgumentParser(description=__doc__[:-130], formatter_class=argparse.RawTextHelpFormatter)
A:gensim.models.lda_worker.args->argparse.ArgumentParser(description=__doc__[:-130], formatter_class=argparse.RawTextHelpFormatter).parse_args()
gensim.models.lda_worker.Worker(self)
gensim.models.lda_worker.Worker.__init__(self)
gensim.models.lda_worker.Worker.exit(self)
gensim.models.lda_worker.Worker.getstate(self)
gensim.models.lda_worker.Worker.initialize(self,myid,dispatcher,**model_params)
gensim.models.lda_worker.Worker.ping(self)
gensim.models.lda_worker.Worker.processjob(self,job)
gensim.models.lda_worker.Worker.requestjob(self)
gensim.models.lda_worker.Worker.reset(self,state)
gensim.models.lda_worker.main()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/poincare.py----------------------------------------
A:gensim.models.poincare.logger->logging.getLogger(__name__)
A:gensim.models.poincare.self.kv->PoincareKeyedVectors(size, 0)
A:gensim.models.poincare.self.node_relations->defaultdict(set)
A:gensim.models.poincare.self._negatives_buffer->NegativesBuffer(cumsum_table_indices)
A:gensim.models.poincare.self._np_random->numpy.random.RandomState(seed)
A:gensim.models.poincare.old_index_to_key_len->len(self.kv.index_to_key)
A:gensim.models.poincare.self.kv.key_to_index[item]->len(self.kv.index_to_key)
A:gensim.models.poincare.self.indices_set->set(range(len(self.kv.index_to_key)))
A:gensim.models.poincare.self.indices_array->numpy.fromiter(range(len(self.kv.index_to_key)), dtype=int)
A:gensim.models.poincare.self.kv.vectors->numpy.concatenate([self.kv.vectors, v])
A:gensim.models.poincare.v->self._np_random.uniform(self.init_range[0], self.init_range[1], shape).astype(self.dtype)
A:gensim.models.poincare.counts->Counter(node_indices)
A:gensim.models.poincare.self._node_counts_cumsum->numpy.cumsum(counts)
A:gensim.models.poincare.uniform_numbers->self._np_random.randint(1, max_cumsum_value + 1, self._negatives_buffer_size)
A:gensim.models.poincare.cumsum_table_indices->numpy.searchsorted(self._node_counts_cumsum, uniform_numbers)
A:gensim.models.poincare.indices->list(range(len(self.all_relations)))
A:gensim.models.poincare.unique_indices->set(indices)
A:gensim.models.poincare.valid_negatives->numpy.array(list(self.indices_set - node_relations))
A:gensim.models.poincare.euclidean_dists->numpy.linalg.norm(vector_1 - vectors_all, axis=1)
A:gensim.models.poincare.norm->numpy.linalg.norm(vector_1)
A:gensim.models.poincare.all_norms->numpy.linalg.norm(self.vectors, axis=1)
A:gensim.models.poincare.poincare_dists->numpy.arccosh(gamma)
A:gensim.models.poincare.exp_negative_distances->numpy.exp(-poincare_dists)
A:gensim.models.poincare.norms->numpy.linalg.norm(vectors, axis=1)
A:gensim.models.poincare.kwargs['ignore']->set(list(kwargs.get('ignore', [])) + attrs_to_ignore)
A:gensim.models.poincare.model->super(PoincareModel, cls).load(*args, **kwargs)
A:gensim.models.poincare.batch_size->len(indices_u)
A:gensim.models.poincare.vectors_v->vectors_v.swapaxes(0, 1).swapaxes(1, 2).swapaxes(0, 1).swapaxes(1, 2)
A:gensim.models.poincare.batch->self._prepare_training_batch(relations, all_negatives, check_gradients)
A:gensim.models.poincare.self._loss_grad->grad(PoincareModel._loss_fn)
A:gensim.models.poincare.auto_gradients->self._loss_grad(np.vstack((self.kv.vectors[u], self.kv.vectors[[v] + negatives])), self.regularization_coeff)
A:gensim.models.poincare.computed_gradients->numpy.vstack((batch.gradients_u[:, i], batch.gradients_v[:, :, i]))
A:gensim.models.poincare.diff->numpy.abs(auto_gradients - computed_gradients).max()
A:gensim.models.poincare.all_negatives->self._sample_negatives_batch((relation[0] for relation in relations))
A:gensim.models.poincare.node_dict->defaultdict(list)
A:gensim.models.poincare.vector_updates[positions[-1]]->vector_updates[positions].sum(axis=0)
A:gensim.models.poincare.self.kv.vectors[indices_u]->self._clip_vectors(self.kv.vectors[indices_u], self.epsilon)
A:gensim.models.poincare.v_updates->v_updates.reshape(((1 + self.negative) * batch_size, self.size)).reshape(((1 + self.negative) * batch_size, self.size))
A:gensim.models.poincare.self.kv.vectors[indices_v]->self._clip_vectors(self.kv.vectors[indices_v], self.epsilon)
A:gensim.models.poincare.old_settings->numpy.seterr(divide='ignore', invalid='ignore')
A:gensim.models.poincare.last_time->time.time()
A:gensim.models.poincare.result->self._train_on_batch(relations, check_gradients=check_gradients)
A:gensim.models.poincare.norms_u->numpy.linalg.norm(self.vectors_u, axis=1)
A:gensim.models.poincare.norms_v->numpy.linalg.norm(self.vectors_v, axis=1)
A:gensim.models.poincare.Z->numpy.exp(-poincare_dists).sum(axis=0)
A:gensim.models.poincare.gradients_u->gradients_u.sum(axis=0).sum(axis=0)
A:gensim.models.poincare.self.vectors->self.__dict__.pop('syn0')
A:gensim.models.poincare.all_distances->self.distances(node_or_vector, nodes_to_use)
A:gensim.models.poincare.closest_child_index->numpy.ma.argmin(all_distances)
A:gensim.models.poincare.ancestor->self.closest_parent(ancestors[-1])
A:gensim.models.poincare.vector_1->self.get_vector(w1)
A:gensim.models.poincare.vector_2->self.get_vector(w2)
A:gensim.models.poincare.node_index->self.get_index(node_or_vector)
A:gensim.models.poincare.closest_indices->gensim.matutils.argsort(all_distances, topn=1 + topn)
A:gensim.models.poincare.input_vector->self.get_vector(node_or_vector)
A:gensim.models.poincare.reader->csv.DictReader(f, delimiter=' ')
A:gensim.models.poincare.items->set()
A:gensim.models.poincare.relations->defaultdict(set)
A:gensim.models.poincare.item_1_index->embedding.get_index(row[0])
A:gensim.models.poincare.item_2_index->embedding.get_index(row[1])
A:gensim.models.poincare.negative_relation_distances->numpy.ma.array(all_distances, mask=False)
A:gensim.models.poincare.avg_precision->(np.arange(1, len(map_ranks) + 1) / np.sort(map_ranks)).mean()
A:gensim.models.poincare.(mean_rank, map_)->self.evaluate_mean_rank_and_map(max_n)
A:gensim.models.poincare.item_relations->list(self.relations[item])
A:gensim.models.poincare.item_distances->self.embedding.distances(item_term)
A:gensim.models.poincare.(positive_relation_ranks, avg_precision)->self.get_positive_relation_ranks_and_avg_prec(item_distances, item_relations)
A:gensim.models.poincare.unknown_relations->list(self.relations['unknown'][item])
A:gensim.models.poincare.known_relations->list(self.relations['known'][item])
A:gensim.models.poincare.(unknown_relation_ranks, avg_precision)->self.get_unknown_relation_ranks_and_avg_prec(item_distances, unknown_relations, known_relations)
A:gensim.models.poincare.expected_scores[word_1, word_2]->float(row['AVG_SCORE'])
A:gensim.models.poincare.word_1_terms->self.find_matching_terms(trie, term_1)
A:gensim.models.poincare.word_2_terms->self.find_matching_terms(trie, term_2)
A:gensim.models.poincare.distance->embedding.distance(term_1, term_2)
A:gensim.models.poincare.matches->trie.items('%s.' % word)
A:gensim.models.poincare.vocab_trie->self.create_vocab_trie(embedding)
A:gensim.models.poincare.predicted_score->self.score_function(embedding, vocab_trie, word_1, word_2)
A:gensim.models.poincare.spearman->spearmanr(expected_scores, predicted_scores)
gensim.models.poincare.LexicalEntailmentEvaluation(self,filepath)
gensim.models.poincare.LexicalEntailmentEvaluation.__init__(self,filepath)
gensim.models.poincare.LexicalEntailmentEvaluation.create_vocab_trie(embedding)
gensim.models.poincare.LexicalEntailmentEvaluation.evaluate_spearman(self,embedding)
gensim.models.poincare.LexicalEntailmentEvaluation.find_matching_terms(trie,word)
gensim.models.poincare.LexicalEntailmentEvaluation.score_function(self,embedding,trie,term_1,term_2)
gensim.models.poincare.LinkPredictionEvaluation(self,train_path,test_path,embedding)
gensim.models.poincare.LinkPredictionEvaluation.__init__(self,train_path,test_path,embedding)
gensim.models.poincare.LinkPredictionEvaluation.evaluate(self,max_n=None)
gensim.models.poincare.LinkPredictionEvaluation.evaluate_mean_rank_and_map(self,max_n=None)
gensim.models.poincare.LinkPredictionEvaluation.get_unknown_relation_ranks_and_avg_prec(all_distances,unknown_relations,known_relations)
gensim.models.poincare.NegativesBuffer(self,items)
gensim.models.poincare.NegativesBuffer.__init__(self,items)
gensim.models.poincare.NegativesBuffer.get_items(self,num_items)
gensim.models.poincare.NegativesBuffer.num_items(self)
gensim.models.poincare.PoincareBatch(self,vectors_u,vectors_v,indices_u,indices_v,regularization_coeff=1.0)
gensim.models.poincare.PoincareBatch.__init__(self,vectors_u,vectors_v,indices_u,indices_v,regularization_coeff=1.0)
gensim.models.poincare.PoincareBatch.compute_all(self)
gensim.models.poincare.PoincareBatch.compute_distance_gradients(self)
gensim.models.poincare.PoincareBatch.compute_distances(self)
gensim.models.poincare.PoincareBatch.compute_gradients(self)
gensim.models.poincare.PoincareBatch.compute_loss(self)
gensim.models.poincare.PoincareKeyedVectors(self,vector_size,vector_count,dtype=REAL)
gensim.models.poincare.PoincareKeyedVectors.__init__(self,vector_size,vector_count,dtype=REAL)
gensim.models.poincare.PoincareKeyedVectors._load_specials(self,*args,**kwargs)
gensim.models.poincare.PoincareKeyedVectors.ancestors(self,node)
gensim.models.poincare.PoincareKeyedVectors.closest_child(self,node)
gensim.models.poincare.PoincareKeyedVectors.closest_parent(self,node)
gensim.models.poincare.PoincareKeyedVectors.descendants(self,node,max_depth=5)
gensim.models.poincare.PoincareKeyedVectors.difference_in_hierarchy(self,node_or_vector_1,node_or_vector_2)
gensim.models.poincare.PoincareKeyedVectors.distance(self,w1,w2)
gensim.models.poincare.PoincareKeyedVectors.distances(self,node_or_vector,other_nodes=())
gensim.models.poincare.PoincareKeyedVectors.most_similar(self,node_or_vector,topn=10,restrict_vocab=None)
gensim.models.poincare.PoincareKeyedVectors.norm(self,node_or_vector)
gensim.models.poincare.PoincareKeyedVectors.similarity(self,w1,w2)
gensim.models.poincare.PoincareKeyedVectors.vector_distance(vector_1,vector_2)
gensim.models.poincare.PoincareKeyedVectors.vector_distance_batch(vector_1,vectors_all)
gensim.models.poincare.PoincareModel(self,train_data,size=50,alpha=0.1,negative=10,workers=1,epsilon=1e-05,regularization_coeff=1.0,burn_in=10,burn_in_alpha=0.01,init_range=(-0.001,0.001),dtype=np.float64,seed=0)
gensim.models.poincare.PoincareModel.__init__(self,train_data,size=50,alpha=0.1,negative=10,workers=1,epsilon=1e-05,regularization_coeff=1.0,burn_in=10,burn_in_alpha=0.01,init_range=(-0.001,0.001),dtype=np.float64,seed=0)
gensim.models.poincare.PoincareModel._check_gradients(self,relations,all_negatives,batch,tol=1e-08)
gensim.models.poincare.PoincareModel._clip_vectors(vectors,epsilon)
gensim.models.poincare.PoincareModel._get_candidate_negatives(self)
gensim.models.poincare.PoincareModel._handle_duplicates(vector_updates,node_indices)
gensim.models.poincare.PoincareModel._init_embeddings(self)
gensim.models.poincare.PoincareModel._init_node_probabilities(self)
gensim.models.poincare.PoincareModel._loss_fn(matrix,regularization_coeff=1.0)
gensim.models.poincare.PoincareModel._prepare_training_batch(self,relations,all_negatives,check_gradients=False)
gensim.models.poincare.PoincareModel._sample_negatives(self,node_index)
gensim.models.poincare.PoincareModel._sample_negatives_batch(self,nodes)
gensim.models.poincare.PoincareModel._train_batchwise(self,epochs,batch_size=10,print_every=1000,check_gradients_every=None)
gensim.models.poincare.PoincareModel._train_on_batch(self,relations,check_gradients=False)
gensim.models.poincare.PoincareModel._update_embeddings(self,old_index_to_key_len)
gensim.models.poincare.PoincareModel._update_vectors_batch(self,batch)
gensim.models.poincare.PoincareModel.build_vocab(self,relations,update=False)
gensim.models.poincare.PoincareModel.load(cls,*args,**kwargs)
gensim.models.poincare.PoincareModel.save(self,*args,**kwargs)
gensim.models.poincare.PoincareModel.train(self,epochs,batch_size=10,print_every=1000,check_gradients_every=None)
gensim.models.poincare.PoincareRelations(self,file_path,encoding='utf8',delimiter='\t')
gensim.models.poincare.PoincareRelations.__init__(self,file_path,encoding='utf8',delimiter='\t')
gensim.models.poincare.PoincareRelations.__iter__(self)
gensim.models.poincare.ReconstructionEvaluation(self,file_path,embedding)
gensim.models.poincare.ReconstructionEvaluation.__init__(self,file_path,embedding)
gensim.models.poincare.ReconstructionEvaluation.evaluate(self,max_n=None)
gensim.models.poincare.ReconstructionEvaluation.evaluate_mean_rank_and_map(self,max_n=None)
gensim.models.poincare.ReconstructionEvaluation.get_positive_relation_ranks_and_avg_prec(all_distances,positive_relations)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/basemodel.py----------------------------------------
gensim.models.basemodel.BaseTopicModel
gensim.models.basemodel.BaseTopicModel.get_topics(self)
gensim.models.basemodel.BaseTopicModel.print_topic(self,topicno,topn=10)
gensim.models.basemodel.BaseTopicModel.print_topics(self,num_topics=20,num_words=10)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/lsi_dispatcher.py----------------------------------------
A:gensim.models.lsi_dispatcher.logger->logging.getLogger(__name__)
A:gensim.models.lsi_dispatcher.self.jobs->Queue(maxsize=self.maxsize)
A:gensim.models.lsi_dispatcher.self.lock_update->threading.Lock()
A:gensim.models.lsi_dispatcher.self.callback->Pyro4.Proxy('PYRONAME:gensim.lsi_dispatcher')
A:gensim.models.lsi_dispatcher.worker->Pyro4.Proxy(uri)
A:gensim.models.lsi_dispatcher.workerid->len(self.workers)
A:gensim.models.lsi_dispatcher.job->self.jobs.get(block=True, timeout=1)
A:gensim.models.lsi_dispatcher.workers->list(self.workers.items())
A:gensim.models.lsi_dispatcher.result->workers[0][1].getstate()
A:gensim.models.lsi_dispatcher.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter)
A:gensim.models.lsi_dispatcher.args->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter).parse_args()
gensim.models.lsi_dispatcher.Dispatcher(self,maxsize=0)
gensim.models.lsi_dispatcher.Dispatcher.__init__(self,maxsize=0)
gensim.models.lsi_dispatcher.Dispatcher.exit(self)
gensim.models.lsi_dispatcher.Dispatcher.getjob(self,worker_id)
gensim.models.lsi_dispatcher.Dispatcher.getstate(self)
gensim.models.lsi_dispatcher.Dispatcher.getworkers(self)
gensim.models.lsi_dispatcher.Dispatcher.initialize(self,**model_params)
gensim.models.lsi_dispatcher.Dispatcher.jobdone(self,workerid)
gensim.models.lsi_dispatcher.Dispatcher.jobsdone(self)
gensim.models.lsi_dispatcher.Dispatcher.putjob(self,job)
gensim.models.lsi_dispatcher.Dispatcher.reset(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/rpmodel.py----------------------------------------
A:gensim.models.rpmodel.logger->logging.getLogger(__name__)
A:gensim.models.rpmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.rpmodel.self.num_terms->len(self.id2word)
A:gensim.models.rpmodel.self.projection->self.projection.copy('F')
A:gensim.models.rpmodel.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.rpmodel.vec->numpy.asfortranarray(vec, dtype=np.float32)
A:gensim.models.rpmodel.topic_dist->numpy.dot(self.projection, vec)
gensim.models.RpModel(self,corpus,id2word=None,num_topics=300)
gensim.models.RpModel.__getitem__(self,bow)
gensim.models.RpModel.__setstate__(self,state)
gensim.models.RpModel.__str__(self)
gensim.models.RpModel.initialize(self,corpus)
gensim.models.rpmodel.RpModel(self,corpus,id2word=None,num_topics=300)
gensim.models.rpmodel.RpModel.__getitem__(self,bow)
gensim.models.rpmodel.RpModel.__init__(self,corpus,id2word=None,num_topics=300)
gensim.models.rpmodel.RpModel.__setstate__(self,state)
gensim.models.rpmodel.RpModel.__str__(self)
gensim.models.rpmodel.RpModel.initialize(self,corpus)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/lsi_worker.py----------------------------------------
A:gensim.models.lsi_worker.logger->logging.getLogger(__name__)
A:gensim.models.lsi_worker.self.lock_update->threading.Lock()
A:gensim.models.lsi_worker.self.model->gensim.models.lsimodel.LsiModel(**model_params)
A:gensim.models.lsi_worker.job->self.dispatcher.getjob(self.myid)
A:gensim.models.lsi_worker.fname->os.path.join(tempfile.gettempdir(), 'lsi_worker.pkl')
A:gensim.models.lsi_worker.self.model.projection->self.model.projection.empty_like()
A:gensim.models.lsi_worker.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter)
A:gensim.models.lsi_worker._->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter).parse_args()
gensim.models.lsi_worker.Worker(self)
gensim.models.lsi_worker.Worker.__init__(self)
gensim.models.lsi_worker.Worker.exit(self)
gensim.models.lsi_worker.Worker.getstate(self)
gensim.models.lsi_worker.Worker.initialize(self,myid,dispatcher,**model_params)
gensim.models.lsi_worker.Worker.processjob(self,job)
gensim.models.lsi_worker.Worker.requestjob(self)
gensim.models.lsi_worker.Worker.reset(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/doc2vec.py----------------------------------------
A:gensim.models.doc2vec.logger->logging.getLogger(__name__)
A:gensim.models.doc2vec.self.dbow_words->int(dbow_words)
A:gensim.models.doc2vec.self.dm_concat->int(dm_concat)
A:gensim.models.doc2vec.self.dm_tag_count->int(dm_tag_count)
A:gensim.models.doc2vec.self.dv.vectors_lockf->numpy.ones(1, dtype=REAL)
A:gensim.models.doc2vec.(examples, tally, raw_tally)->d2v_train_epoch_dm(self, corpus_file, offset, start_doctag, cython_vocab, cur_epoch, total_examples, total_words, work, neu1, len(self.dv), doctag_vectors=doctag_vectors, doctags_lockf=doctags_lockf)
A:gensim.models.doc2vec.(offsets, start_doctags)->self._get_offsets_and_start_doctags_for_corpusfile(corpus_file, self.workers)
A:gensim.models.doc2vec.corpus_file_size->os.path.getsize(corpus_file)
A:gensim.models.doc2vec.doctag_vectors->doctag_vectors.reshape(1, self.dv.vector_size).reshape(1, self.dv.vector_size)
A:gensim.models.doc2vec.doctags_lockf->numpy.ones(1, dtype=REAL)
A:gensim.models.doc2vec.work->zeros(self.layer1_size, dtype=REAL)
A:gensim.models.doc2vec.neu1->gensim.matutils.zeros_aligned(self.layer1_size, dtype=REAL)
A:gensim.models.doc2vec.report['doctag_lookup']->self.estimated_lookup_memory()
A:gensim.models.doc2vec.(total_words, corpus_count)->self._scan_vocab(corpus_iterable, progress_per, trim_rule)
A:gensim.models.doc2vec.report_values->self.prepare_vocab(keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, update=update)
A:gensim.models.doc2vec.report_values['memory']->self.estimate_memory(vocab_size=report_values['num_retained_words'])
A:gensim.models.doc2vec.vocab->defaultdict(int)
A:gensim.models.doc2vec.interval_start->default_timer()
A:gensim.models.doc2vec.document_length->len(document.words)
A:gensim.models.doc2vec.max_rawint->max(max_rawint, tag)
A:gensim.models.doc2vec.doctags_lookup[tag]->Doctag(index=len(doctags_list), word_count=document_length, doc_count=1)
A:gensim.models.doc2vec.corpus_iterable->TaggedLineDocument(corpus_file)
A:gensim.models.doc2vec.d1->self.infer_vector(doc_words=doc_words1, alpha=alpha, min_alpha=min_alpha, epochs=epochs)
A:gensim.models.doc2vec.d2->self.infer_vector(doc_words=doc_words2, alpha=alpha, min_alpha=min_alpha, epochs=epochs)
A:gensim.models.doc2vec.fname->os.path.join(self.dirname, fname)
A:gensim.models.doc2vec.line->gensim.utils.to_unicode(line)
gensim.models.Doc2Vec(self,documents=None,corpus_file=None,vector_size=100,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,dv=None,dv_mapfile=None,comment=None,trim_rule=None,callbacks=(),window=5,epochs=10,shrink_windows=True,**kwargs)
gensim.models.Doc2Vec.__getitem__(self,tag)
gensim.models.Doc2Vec.__str__(self)
gensim.models.Doc2Vec._clear_post_train(self)
gensim.models.Doc2Vec._do_train_epoch(self,corpus_file,thread_id,offset,cython_vocab,thread_private_mem,cur_epoch,total_examples=None,total_words=None,offsets=None,start_doctags=None,**kwargs)
gensim.models.Doc2Vec._do_train_job(self,job,alpha,inits)
gensim.models.Doc2Vec._get_offsets_and_start_doctags_for_corpusfile(cls,corpus_file,workers)
gensim.models.Doc2Vec._raw_word_count(self,job)
gensim.models.Doc2Vec._scan_vocab(self,corpus_iterable,progress_per,trim_rule)
gensim.models.Doc2Vec.build_vocab(self,corpus_iterable=None,corpus_file=None,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.Doc2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.Doc2Vec.dbow(self)
gensim.models.Doc2Vec.dm(self)
gensim.models.Doc2Vec.docvecs(self)
gensim.models.Doc2Vec.docvecs(self,value)
gensim.models.Doc2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.Doc2Vec.estimated_lookup_memory(self)
gensim.models.Doc2Vec.infer_vector(self,doc_words,alpha=None,min_alpha=None,epochs=None)
gensim.models.Doc2Vec.init_sims(self,replace=False)
gensim.models.Doc2Vec.init_weights(self)
gensim.models.Doc2Vec.load(cls,*args,**kwargs)
gensim.models.Doc2Vec.reset_from(self,other_model)
gensim.models.Doc2Vec.save_word2vec_format(self,fname,doctag_vec=False,word_vec=True,prefix='*dt_',fvocab=None,binary=False)
gensim.models.Doc2Vec.scan_vocab(self,corpus_iterable=None,corpus_file=None,progress_per=10000,trim_rule=None)
gensim.models.Doc2Vec.similarity_unseen_docs(self,doc_words1,doc_words2,alpha=None,min_alpha=None,epochs=None)
gensim.models.Doc2Vec.train(self,corpus_iterable=None,corpus_file=None,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,callbacks=(),**kwargs)
gensim.models.Doc2VecTrainables(utils.SaveLoad)
gensim.models.Doc2VecVocab(utils.SaveLoad)
gensim.models.doc2vec.Doc2Vec(self,documents=None,corpus_file=None,vector_size=100,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,dv=None,dv_mapfile=None,comment=None,trim_rule=None,callbacks=(),window=5,epochs=10,shrink_windows=True,**kwargs)
gensim.models.doc2vec.Doc2Vec.__getitem__(self,tag)
gensim.models.doc2vec.Doc2Vec.__init__(self,documents=None,corpus_file=None,vector_size=100,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,dv=None,dv_mapfile=None,comment=None,trim_rule=None,callbacks=(),window=5,epochs=10,shrink_windows=True,**kwargs)
gensim.models.doc2vec.Doc2Vec.__str__(self)
gensim.models.doc2vec.Doc2Vec._clear_post_train(self)
gensim.models.doc2vec.Doc2Vec._do_train_epoch(self,corpus_file,thread_id,offset,cython_vocab,thread_private_mem,cur_epoch,total_examples=None,total_words=None,offsets=None,start_doctags=None,**kwargs)
gensim.models.doc2vec.Doc2Vec._do_train_job(self,job,alpha,inits)
gensim.models.doc2vec.Doc2Vec._get_offsets_and_start_doctags_for_corpusfile(cls,corpus_file,workers)
gensim.models.doc2vec.Doc2Vec._raw_word_count(self,job)
gensim.models.doc2vec.Doc2Vec._scan_vocab(self,corpus_iterable,progress_per,trim_rule)
gensim.models.doc2vec.Doc2Vec.build_vocab(self,corpus_iterable=None,corpus_file=None,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.doc2vec.Doc2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.doc2vec.Doc2Vec.dbow(self)
gensim.models.doc2vec.Doc2Vec.dm(self)
gensim.models.doc2vec.Doc2Vec.docvecs(self)
gensim.models.doc2vec.Doc2Vec.docvecs(self,value)
gensim.models.doc2vec.Doc2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.doc2vec.Doc2Vec.estimated_lookup_memory(self)
gensim.models.doc2vec.Doc2Vec.infer_vector(self,doc_words,alpha=None,min_alpha=None,epochs=None)
gensim.models.doc2vec.Doc2Vec.init_sims(self,replace=False)
gensim.models.doc2vec.Doc2Vec.init_weights(self)
gensim.models.doc2vec.Doc2Vec.load(cls,*args,**kwargs)
gensim.models.doc2vec.Doc2Vec.reset_from(self,other_model)
gensim.models.doc2vec.Doc2Vec.save_word2vec_format(self,fname,doctag_vec=False,word_vec=True,prefix='*dt_',fvocab=None,binary=False)
gensim.models.doc2vec.Doc2Vec.scan_vocab(self,corpus_iterable=None,corpus_file=None,progress_per=10000,trim_rule=None)
gensim.models.doc2vec.Doc2Vec.similarity_unseen_docs(self,doc_words1,doc_words2,alpha=None,min_alpha=None,epochs=None)
gensim.models.doc2vec.Doc2Vec.train(self,corpus_iterable=None,corpus_file=None,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,callbacks=(),**kwargs)
gensim.models.doc2vec.Doc2VecTrainables(utils.SaveLoad)
gensim.models.doc2vec.Doc2VecVocab(utils.SaveLoad)
gensim.models.doc2vec.Doctag
gensim.models.doc2vec.Doctag.count(self)
gensim.models.doc2vec.Doctag.count(self,new_val)
gensim.models.doc2vec.TaggedBrownCorpus(self,dirname)
gensim.models.doc2vec.TaggedBrownCorpus.__init__(self,dirname)
gensim.models.doc2vec.TaggedBrownCorpus.__iter__(self)
gensim.models.doc2vec.TaggedDocument(namedtuple('TaggedDocument','wordstags'))
gensim.models.doc2vec.TaggedDocument.__str__(self)
gensim.models.doc2vec.TaggedLineDocument(self,source)
gensim.models.doc2vec.TaggedLineDocument.__init__(self,source)
gensim.models.doc2vec.TaggedLineDocument.__iter__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/ensemblelda.py----------------------------------------
A:gensim.models.ensemblelda.logger->logging.getLogger(__name__)
A:gensim.models.ensemblelda.max_num_neighboring_labels->max(topic.num_neighboring_labels, max_num_neighboring_labels)
A:gensim.models.ensemblelda.topic.num_neighboring_labels->len(topic.neighboring_labels)
A:gensim.models.ensemblelda.sorted_clusters->sorted(clusters, key=_cluster_sort_key, reverse=False)
A:gensim.models.ensemblelda.workers->os.cpu_count()
A:gensim.models.ensemblelda.(parent_conn, child_conn)->Pipe()
A:gensim.models.ensemblelda.num_subprocess_models->int(num_models_unhandled / (workers - i))
A:gensim.models.ensemblelda.process->Process(target=_asymmetric_distance_matrix_worker, args=args)
A:gensim.models.ensemblelda.answer->parent_conn.recv()
A:gensim.models.ensemblelda.ttda->numpy.concatenate([model.get_topics() for model in target], axis=0)
A:gensim.models.ensemblelda.ensemble.ttda->numpy.concatenate([ensemble.ttda, tm.get_topics()])
A:gensim.models.ensemblelda.kwargs->ensemble.gensim_kw_args.copy()
A:gensim.models.ensemblelda.tm->ensemble.get_topic_model_class()(**kwargs)
A:gensim.models.ensemblelda.ensemble.sstats_sum->ensemble.get_topic_model_class()(**kwargs).state.sstats.sum()
A:gensim.models.ensemblelda.distances->numpy.ndarray((len(ttda1), len(ttda2)))
A:gensim.models.ensemblelda.mask->masking_method(ttd1, masking_threshold)
A:gensim.models.ensemblelda.distance->cosine(ttd1_masked, ttd2_masked)
A:gensim.models.ensemblelda.percent->round(100 * avg_mask_size / ttda1.shape[0] / ttda1.shape[1], 1)
A:gensim.models.ensemblelda.distance_chunk->_calculate_asymmetric_distance_matrix_chunk(ttda1=ttda1, ttda2=entire_ttda, start_index=ttdas_sent, masking_method=masking_method, masking_threshold=masking_threshold)
A:gensim.models.ensemblelda.n_ttdas->int((len(entire_ttda) - ttdas_sent) / (workers - i))
A:gensim.models.ensemblelda.(worker_id, distance_chunk)->parent_conn.recv()
A:gensim.models.ensemblelda.gensim_kw_args['id2word']->gensim.utils.dict_from_corpus(gensim_kw_args['corpus'])
A:gensim.models.ensemblelda.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.ensemblelda.self.ttda->numpy.append(self.ttda, ttda, axis=0)
A:gensim.models.ensemblelda.module->importlib.import_module(self.topic_model_module_string)
A:gensim.models.ensemblelda.self.topic_model_class->getattr(module, self.topic_model_class_string)
A:gensim.models.ensemblelda.kwargs['ignore']->frozenset(kwargs.get('ignore', ())).union(('topic_model_class',))
A:gensim.models.ensemblelda.stable_topics->numpy.empty((num_stable_topics, len(self.id2word)))
A:gensim.models.ensemblelda.num_stable_topics->len(unique_labels)
A:gensim.models.ensemblelda.params->self.gensim_kw_args.copy()
A:gensim.models.ensemblelda.classic_model_representation->self.get_topic_model_class()(**params)
A:gensim.models.ensemblelda.sstats_sum->self.get_topic_model_class()(**params).state.sstats.sum()
A:gensim.models.ensemblelda.eta_sum->numpy.array(eta.sum(axis=1)[:, None])
A:gensim.models.ensemblelda.classic_model_representation.state.sstats->sstats.astype(np.float32)
A:gensim.models.ensemblelda.target->numpy.array(target)
A:gensim.models.ensemblelda.detected_num_models->len(target)
A:gensim.models.ensemblelda.self.num_models->len(self.tms)
A:gensim.models.ensemblelda.self.asymmetric_distance_matrix->_calculate_assymetric_distance_matrix_multiproc(workers=workers, entire_ttda=self.ttda, masking_method=self.masking_method, masking_threshold=self.masking_threshold)
A:gensim.models.ensemblelda.min_samples->int(self.num_models / 2)
A:gensim.models.ensemblelda.self.cluster_model->CBDBSCAN(eps=eps, min_samples=min_samples)
A:gensim.models.ensemblelda.min_cores->min(3, max(1, int(self.num_models / 4 + 1)))
A:gensim.models.ensemblelda.grouped_by_labels->_group_by_labels(cbdbscan_topics)
A:gensim.models.ensemblelda.clusters->_aggregate_topics(grouped_by_labels)
A:gensim.models.ensemblelda.valid_clusters->_validate_clusters(clusters, min_cores)
A:gensim.models.ensemblelda.valid_core_mask->numpy.vectorize(_is_valid_core)(cbdbscan_topics)
A:gensim.models.ensemblelda.unique_labels->numpy.unique(topic_labels)
A:gensim.models.ensemblelda.topics_of_cluster->numpy.array([topic for (t, topic) in enumerate(valid_topics) if topic_labels[t] == label])
A:gensim.models.ensemblelda.stable_topics[label_index]->numpy.array([topic for (t, topic) in enumerate(valid_topics) if topic_labels[t] == label]).mean(axis=0)
A:gensim.models.ensemblelda.amatrix_copy->amatrix.copy()
A:gensim.models.ensemblelda.min_distance_per_topic_sorted->sorted(min_distance_per_topic, key=lambda distance: distance[0])
A:gensim.models.ensemblelda.neighbors_sorted->sorted([(distance, index) for (index, distance) in enumerate(amatrix_copy[topic_index])], key=lambda x: x[0])
A:gensim.models.ensemblelda.num_neighboring_topics->len(neighboring_topic_indices)
A:gensim.models.ensemblelda.next_topic_index->ordered_min_similarity.pop(0)
gensim.models.EnsembleLda(self,topic_model_class='ldamulticore',num_models=3,min_cores=None,epsilon=0.1,ensemble_workers=1,memory_friendly_ttda=True,min_samples=None,masking_method=mass_masking,masking_threshold=None,distance_workers=1,random_state=None,**gensim_kw_args)
gensim.models.EnsembleLda.__getitem__(self,i)
gensim.models.EnsembleLda._ensure_gensim_representation(self)
gensim.models.EnsembleLda._generate_asymmetric_distance_matrix(self)
gensim.models.EnsembleLda._generate_stable_topics(self,min_cores=None)
gensim.models.EnsembleLda._generate_topic_clusters(self,eps=0.1,min_samples=None)
gensim.models.EnsembleLda.add_model(self,target,num_new_models=None)
gensim.models.EnsembleLda.convert_to_memory_friendly(self)
gensim.models.EnsembleLda.generate_gensim_representation(self)
gensim.models.EnsembleLda.get_topic_model_class(self)
gensim.models.EnsembleLda.get_topics(self)
gensim.models.EnsembleLda.id2word(self)
gensim.models.EnsembleLda.inference(self,*posargs,**kwargs)
gensim.models.EnsembleLda.log_perplexity(self,*posargs,**kwargs)
gensim.models.EnsembleLda.print_topics(self,*posargs,**kwargs)
gensim.models.EnsembleLda.recluster(self,eps=0.1,min_samples=None,min_cores=None)
gensim.models.EnsembleLda.save(self,*args,**kwargs)
gensim.models.ensemblelda.CBDBSCAN(self,eps,min_samples)
gensim.models.ensemblelda.CBDBSCAN.__init__(self,eps,min_samples)
gensim.models.ensemblelda.CBDBSCAN.fit(self,amatrix)
gensim.models.ensemblelda.Cluster
gensim.models.ensemblelda.EnsembleLda(self,topic_model_class='ldamulticore',num_models=3,min_cores=None,epsilon=0.1,ensemble_workers=1,memory_friendly_ttda=True,min_samples=None,masking_method=mass_masking,masking_threshold=None,distance_workers=1,random_state=None,**gensim_kw_args)
gensim.models.ensemblelda.EnsembleLda.__getitem__(self,i)
gensim.models.ensemblelda.EnsembleLda.__init__(self,topic_model_class='ldamulticore',num_models=3,min_cores=None,epsilon=0.1,ensemble_workers=1,memory_friendly_ttda=True,min_samples=None,masking_method=mass_masking,masking_threshold=None,distance_workers=1,random_state=None,**gensim_kw_args)
gensim.models.ensemblelda.EnsembleLda._ensure_gensim_representation(self)
gensim.models.ensemblelda.EnsembleLda._generate_asymmetric_distance_matrix(self)
gensim.models.ensemblelda.EnsembleLda._generate_stable_topics(self,min_cores=None)
gensim.models.ensemblelda.EnsembleLda._generate_topic_clusters(self,eps=0.1,min_samples=None)
gensim.models.ensemblelda.EnsembleLda.add_model(self,target,num_new_models=None)
gensim.models.ensemblelda.EnsembleLda.convert_to_memory_friendly(self)
gensim.models.ensemblelda.EnsembleLda.generate_gensim_representation(self)
gensim.models.ensemblelda.EnsembleLda.get_topic_model_class(self)
gensim.models.ensemblelda.EnsembleLda.get_topics(self)
gensim.models.ensemblelda.EnsembleLda.id2word(self)
gensim.models.ensemblelda.EnsembleLda.inference(self,*posargs,**kwargs)
gensim.models.ensemblelda.EnsembleLda.log_perplexity(self,*posargs,**kwargs)
gensim.models.ensemblelda.EnsembleLda.print_topics(self,*posargs,**kwargs)
gensim.models.ensemblelda.EnsembleLda.recluster(self,eps=0.1,min_samples=None,min_cores=None)
gensim.models.ensemblelda.EnsembleLda.save(self,*args,**kwargs)
gensim.models.ensemblelda.Topic
gensim.models.ensemblelda._aggregate_topics(grouped_by_labels)
gensim.models.ensemblelda._asymmetric_distance_matrix_worker(worker_id,entire_ttda,ttdas_sent,n_ttdas,masking_method,masking_threshold,pipe)
gensim.models.ensemblelda._calculate_assymetric_distance_matrix_multiproc(workers,entire_ttda,masking_method,masking_threshold)
gensim.models.ensemblelda._calculate_asymmetric_distance_matrix_chunk(ttda1,ttda2,start_index,masking_method,masking_threshold)
gensim.models.ensemblelda._contains_isolated_cores(label,cluster,min_cores)
gensim.models.ensemblelda._generate_topic_models(ensemble,num_models,random_states=None)
gensim.models.ensemblelda._generate_topic_models_multiproc(ensemble,num_models,ensemble_workers)
gensim.models.ensemblelda._generate_topic_models_worker(ensemble,num_models,random_states,pipe)
gensim.models.ensemblelda._group_by_labels(cbdbscan_topics)
gensim.models.ensemblelda._is_valid_core(topic)
gensim.models.ensemblelda._remove_from_all_sets(label,clusters)
gensim.models.ensemblelda._teardown(pipes,processes,i)
gensim.models.ensemblelda._validate_clusters(clusters,min_cores)
gensim.models.ensemblelda.mass_masking(a,threshold=None)
gensim.models.ensemblelda.rank_masking(a,threshold=None)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/coherencemodel.py----------------------------------------
A:gensim.models.coherencemodel.logger->logging.getLogger(__name__)
A:gensim.models.coherencemodel._make_pipeline->namedtuple('Coherence_Measure', 'seg, prob, conf, aggr')
A:gensim.models.coherencemodel.bestn->gensim.matutils.argsort(topic, topn=topn, reverse=True)
A:gensim.models.coherencemodel.topn->min(kwargs.pop('topn', topn), topn)
A:gensim.models.coherencemodel.super_topic->gensim.utils.flatten(topics_as_topn_terms)
A:gensim.models.coherencemodel.cm->CoherenceModel(topics=[super_topic], topn=len(super_topic), **kwargs)
A:gensim.models.coherencemodel.new_topics->self._get_topics()
A:gensim.models.coherencemodel.current_topic_length->len(self._topics[0])
A:gensim.models.coherencemodel.topic_token_ids->self._ensure_elements_are_ids(topic)
A:gensim.models.coherencemodel.new_set->unique_ids_from_segments(self.measure.seg(new_topics))
A:gensim.models.coherencemodel.segmented_topics->measure.seg(self.topics)
A:gensim.models.coherencemodel.self._accumulator->self.measure.prob(**kwargs)
A:gensim.models.coherencemodel.kwargs->dict(with_std=with_std, with_support=with_support)
A:gensim.models.coherencemodel.confirmed_measures->self.get_coherence_per_topic()
A:gensim.models.coherencemodel.coherences->self._compare_model_topics(model_topics)
A:gensim.models.coherencemodel.last_topn_value->min(self.topn - 1, 4)
A:gensim.models.coherencemodel.topn_grid->list(range(self.topn, last_topn_value, -5))
A:gensim.models.coherencemodel.topic_coherences->self.get_coherence_per_topic()
A:gensim.models.coherencemodel.filled_coherences->numpy.array(topic_coherences)
A:gensim.models.coherencemodel.filled_coherences[np.isnan(filled_coherences)]->numpy.nanmean(filled_coherences)
A:gensim.models.coherencemodel.(topic_coherences, avg_coherences)->zip(*coherence_at_n.values())
A:gensim.models.coherencemodel.avg_topic_coherences->numpy.vstack(topic_coherences).mean(0)
A:gensim.models.coherencemodel.model_coherence->numpy.mean(avg_coherences)
gensim.models.CoherenceModel(self,model=None,topics=None,texts=None,corpus=None,dictionary=None,window_size=None,keyed_vectors=None,coherence='c_v',topn=20,processes=-1)
gensim.models.CoherenceModel.__str__(self)
gensim.models.CoherenceModel._compare_model_topics(self,model_topics)
gensim.models.CoherenceModel._ensure_elements_are_ids(self,topic)
gensim.models.CoherenceModel._get_topics(self)
gensim.models.CoherenceModel._get_topics_from_model(model,topn)
gensim.models.CoherenceModel._relevant_ids_will_differ(self,new_topics)
gensim.models.CoherenceModel._topics_differ(self,new_topics)
gensim.models.CoherenceModel._update_accumulator(self,new_topics)
gensim.models.CoherenceModel.aggregate_measures(self,topic_coherences)
gensim.models.CoherenceModel.compare_model_topics(self,model_topics)
gensim.models.CoherenceModel.compare_models(self,models)
gensim.models.CoherenceModel.estimate_probabilities(self,segmented_topics=None)
gensim.models.CoherenceModel.for_models(cls,models,dictionary,topn=20,**kwargs)
gensim.models.CoherenceModel.for_topics(cls,topics_as_topn_terms,**kwargs)
gensim.models.CoherenceModel.get_coherence(self)
gensim.models.CoherenceModel.get_coherence_per_topic(self,segmented_topics=None,with_std=False,with_support=False)
gensim.models.CoherenceModel.measure(self)
gensim.models.CoherenceModel.model(self)
gensim.models.CoherenceModel.model(self,model)
gensim.models.CoherenceModel.segment_topics(self)
gensim.models.CoherenceModel.top_topics_as_word_lists(model,dictionary,topn=20)
gensim.models.CoherenceModel.topics(self)
gensim.models.CoherenceModel.topics(self,topics)
gensim.models.CoherenceModel.topn(self)
gensim.models.CoherenceModel.topn(self,topn)
gensim.models.coherencemodel.CoherenceModel(self,model=None,topics=None,texts=None,corpus=None,dictionary=None,window_size=None,keyed_vectors=None,coherence='c_v',topn=20,processes=-1)
gensim.models.coherencemodel.CoherenceModel.__init__(self,model=None,topics=None,texts=None,corpus=None,dictionary=None,window_size=None,keyed_vectors=None,coherence='c_v',topn=20,processes=-1)
gensim.models.coherencemodel.CoherenceModel.__str__(self)
gensim.models.coherencemodel.CoherenceModel._compare_model_topics(self,model_topics)
gensim.models.coherencemodel.CoherenceModel._ensure_elements_are_ids(self,topic)
gensim.models.coherencemodel.CoherenceModel._get_topics(self)
gensim.models.coherencemodel.CoherenceModel._get_topics_from_model(model,topn)
gensim.models.coherencemodel.CoherenceModel._relevant_ids_will_differ(self,new_topics)
gensim.models.coherencemodel.CoherenceModel._topics_differ(self,new_topics)
gensim.models.coherencemodel.CoherenceModel._update_accumulator(self,new_topics)
gensim.models.coherencemodel.CoherenceModel.aggregate_measures(self,topic_coherences)
gensim.models.coherencemodel.CoherenceModel.compare_model_topics(self,model_topics)
gensim.models.coherencemodel.CoherenceModel.compare_models(self,models)
gensim.models.coherencemodel.CoherenceModel.estimate_probabilities(self,segmented_topics=None)
gensim.models.coherencemodel.CoherenceModel.for_models(cls,models,dictionary,topn=20,**kwargs)
gensim.models.coherencemodel.CoherenceModel.for_topics(cls,topics_as_topn_terms,**kwargs)
gensim.models.coherencemodel.CoherenceModel.get_coherence(self)
gensim.models.coherencemodel.CoherenceModel.get_coherence_per_topic(self,segmented_topics=None,with_std=False,with_support=False)
gensim.models.coherencemodel.CoherenceModel.measure(self)
gensim.models.coherencemodel.CoherenceModel.model(self)
gensim.models.coherencemodel.CoherenceModel.model(self,model)
gensim.models.coherencemodel.CoherenceModel.segment_topics(self)
gensim.models.coherencemodel.CoherenceModel.top_topics_as_word_lists(model,dictionary,topn=20)
gensim.models.coherencemodel.CoherenceModel.topics(self)
gensim.models.coherencemodel.CoherenceModel.topics(self,topics)
gensim.models.coherencemodel.CoherenceModel.topn(self)
gensim.models.coherencemodel.CoherenceModel.topn(self,topn)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/_fasttext_bin.py----------------------------------------
A:gensim.models._fasttext_bin.logger->logging.getLogger(__name__)
A:gensim.models._fasttext_bin._FASTTEXT_VERSION->numpy.int32(12)
A:gensim.models._fasttext_bin._FASTTEXT_FILEFORMAT_MAGIC->numpy.int32(793712314)
A:gensim.models._fasttext_bin._FLOAT_SIZE->struct.calcsize('@f')
A:gensim.models._fasttext_bin._FLOAT_DTYPE->numpy.dtype(np.float64)
A:gensim.models._fasttext_bin._FIELD_NAMES->sorted(set(_yield_field_names()))
A:gensim.models._fasttext_bin.Model->collections.namedtuple('Model', _FIELD_NAMES)
A:gensim.models._fasttext_bin.num_bytes->struct.calcsize(fmt)
A:gensim.models._fasttext_bin.(vocab_size, nwords, nlabels)->_struct_unpack(fin, '@3i')
A:gensim.models._fasttext_bin.(pruneidx_size,)->_struct_unpack(fin, '@q')
A:gensim.models._fasttext_bin.raw_vocab->collections.OrderedDict()
A:gensim.models._fasttext_bin.word_bytes->word_bytes.getvalue().getvalue()
A:gensim.models._fasttext_bin.char_byte->open(fin, 'rb').read(1)
A:gensim.models._fasttext_bin.word->word_bytes.getvalue().getvalue().decode(encoding, errors='backslashreplace')
A:gensim.models._fasttext_bin.(count, _)->_struct_unpack(fin, '@qb')
A:gensim.models._fasttext_bin.(num_vectors, dim)->_struct_unpack(fin, '@2q')
A:gensim.models._fasttext_bin.matrix->matrix.reshape((num_vectors, dim)).reshape((num_vectors, dim))
A:gensim.models._fasttext_bin.batch->_struct_unpack(fin, '@%df' % count)
A:gensim.models._fasttext_bin.fin->open(fin, 'rb')
A:gensim.models._fasttext_bin.(magic, version)->_struct_unpack(fin, '@2i')
A:gensim.models._fasttext_bin.(raw_vocab, vocab_size, nwords, ntokens)->_load_vocab(fin, new_format, encoding=encoding)
A:gensim.models._fasttext_bin.vectors_ngrams->_load_matrix(fin, new_format=new_format)
A:gensim.models._fasttext_bin.hidden_output->_load_matrix(fin, new_format=new_format)
A:gensim.models._fasttext_bin.text->u''.join(('\\x{:02x}'.format(ord(c)) for c in bstr[start:end]))
A:gensim.models._fasttext_bin.field_value->_get_field_from_model(model, field)
A:gensim.models._fasttext_bin.word_count->model.wv.get_vecattr(word, 'count')
gensim.models._fasttext_bin._args_save(fout,model,fb_fasttext_parameters)
gensim.models._fasttext_bin._backslashreplace_backport(ex)
gensim.models._fasttext_bin._batched_generator(fin,count,batch_size=1000000.0)
gensim.models._fasttext_bin._conv_field_to_bytes(field_value,field_type)
gensim.models._fasttext_bin._dict_save(fout,model,encoding)
gensim.models._fasttext_bin._fromfile(fin,dtype,count)
gensim.models._fasttext_bin._get_field_from_model(model,field)
gensim.models._fasttext_bin._input_save(fout,model)
gensim.models._fasttext_bin._load_matrix(fin,new_format=True)
gensim.models._fasttext_bin._load_vocab(fin,new_format,encoding='utf-8')
gensim.models._fasttext_bin._output_save(fout,model)
gensim.models._fasttext_bin._save_to_stream(model,fout,fb_fasttext_parameters,encoding)
gensim.models._fasttext_bin._sign_model(fout)
gensim.models._fasttext_bin._struct_unpack(fin,fmt)
gensim.models._fasttext_bin._yield_field_names()
gensim.models._fasttext_bin.load(fin,encoding='utf-8',full_model=True)
gensim.models._fasttext_bin.save(model,fout,fb_fasttext_parameters,encoding)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/callbacks.py----------------------------------------
A:gensim.models.callbacks.cm->gensim.models.CoherenceModel(model=self.model, topics=self.topics, texts=self.texts, corpus=self.corpus, dictionary=self.dictionary, window_size=self.window_size, coherence=self.coherence, topn=self.topn)
A:gensim.models.callbacks.corpus_words->sum((cnt for document in self.corpus for (_, cnt) in document))
A:gensim.models.callbacks.(diff_diagonal, _)->self.model.diff(self.other_model, self.distance, self.num_words, self.n_ann_terms, self.diagonal, self.annotation, self.normed)
A:gensim.models.callbacks.self.previous->copy.deepcopy(self.model)
A:gensim.models.callbacks.self.diff_mat->Queue()
A:gensim.models.callbacks.self.viz->Visdom()
A:gensim.models.callbacks.self.log_type->logging.getLogger('gensim.models.ldamodel')
A:gensim.models.callbacks.label->str(metric)
A:gensim.models.callbacks.value->metric.get_value(topics=topics, model=self.model, other_model=self.previous)
A:gensim.models.callbacks.diff_mat->numpy.concatenate((self.diff_mat.get(), np.array([value])))
A:gensim.models.callbacks.viz_metric->self.viz.line(Y=np.array([value]), X=np.array([epoch]), env=metric.viz_env, opts=dict(xlabel='Epochs', ylabel=label, title=label))
A:gensim.models.callbacks.statement->''.join(('Epoch ', str(epoch), ': ', label, ' estimate: ', str(value)))
gensim.models.callbacks.Callback(self,metrics)
gensim.models.callbacks.Callback.__init__(self,metrics)
gensim.models.callbacks.Callback.on_epoch_end(self,epoch,topics=None)
gensim.models.callbacks.Callback.set_model(self,model)
gensim.models.callbacks.CallbackAny2Vec
gensim.models.callbacks.CallbackAny2Vec.on_epoch_begin(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_epoch_end(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_train_begin(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_train_end(self,model)
gensim.models.callbacks.CoherenceMetric(self,corpus=None,texts=None,dictionary=None,coherence=None,window_size=None,topn=10,logger=None,viz_env=None,title=None)
gensim.models.callbacks.CoherenceMetric.__init__(self,corpus=None,texts=None,dictionary=None,coherence=None,window_size=None,topn=10,logger=None,viz_env=None,title=None)
gensim.models.callbacks.CoherenceMetric.get_value(self,**kwargs)
gensim.models.callbacks.ConvergenceMetric(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.ConvergenceMetric.__init__(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.ConvergenceMetric.get_value(self,**kwargs)
gensim.models.callbacks.DiffMetric(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.DiffMetric.__init__(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.DiffMetric.get_value(self,**kwargs)
gensim.models.callbacks.Metric
gensim.models.callbacks.Metric.__str__(self)
gensim.models.callbacks.Metric.get_value(self)
gensim.models.callbacks.Metric.set_parameters(self,**parameters)
gensim.models.callbacks.PerplexityMetric(self,corpus=None,logger=None,viz_env=None,title=None)
gensim.models.callbacks.PerplexityMetric.__init__(self,corpus=None,logger=None,viz_env=None,title=None)
gensim.models.callbacks.PerplexityMetric.get_value(self,**kwargs)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/__init__.py----------------------------------------
A:gensim.models.__init__.(is_corpus, bow)->gensim.utils.is_corpus(bow)
gensim.models.__init__.VocabTransform(self,old2new,id2token=None)
gensim.models.__init__.VocabTransform.__getitem__(self,bow)
gensim.models.__init__.VocabTransform.__init__(self,old2new,id2token=None)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/logentropy_model.py----------------------------------------
A:gensim.models.logentropy_model.logger->logging.getLogger(__name__)
A:gensim.models.logentropy_model.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.logentropy_model.vector->gensim.matutils.unitvec(vector)
gensim.models.LogEntropyModel(self,corpus,normalize=True)
gensim.models.LogEntropyModel.__getitem__(self,bow)
gensim.models.LogEntropyModel.__str__(self)
gensim.models.LogEntropyModel.initialize(self,corpus)
gensim.models.logentropy_model.LogEntropyModel(self,corpus,normalize=True)
gensim.models.logentropy_model.LogEntropyModel.__getitem__(self,bow)
gensim.models.logentropy_model.LogEntropyModel.__init__(self,corpus,normalize=True)
gensim.models.logentropy_model.LogEntropyModel.__str__(self)
gensim.models.logentropy_model.LogEntropyModel.initialize(self,corpus)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/word2vec.py----------------------------------------
A:gensim.models.word2vec.logger->logging.getLogger(__name__)
A:gensim.models.word2vec.self.vector_size->int(vector_size)
A:gensim.models.word2vec.self.workers->int(workers)
A:gensim.models.word2vec.self.sg->int(sg)
A:gensim.models.word2vec.self.alpha->float(alpha)
A:gensim.models.word2vec.self.min_alpha->float(min_alpha)
A:gensim.models.word2vec.self.window->int(window)
A:gensim.models.word2vec.self.shrink_windows->bool(shrink_windows)
A:gensim.models.word2vec.self.random->numpy.random.default_rng(seed=self.seed)
A:gensim.models.word2vec.self.hs->int(hs)
A:gensim.models.word2vec.self.negative->int(negative)
A:gensim.models.word2vec.self.cbow_mean->int(cbow_mean)
A:gensim.models.word2vec.self.compute_loss->bool(compute_loss)
A:gensim.models.word2vec.self.min_alpha_yet_reached->float(alpha)
A:gensim.models.word2vec.self.wv->KeyedVectors(self.vector_size)
A:gensim.models.word2vec.self.wv.vectors_lockf->numpy.ones(1, dtype=REAL)
A:gensim.models.word2vec.(total_words, corpus_count)->self._scan_vocab(corpus_iterable, progress_per, trim_rule)
A:gensim.models.word2vec.report_values->self.prepare_vocab(keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, update=update)
A:gensim.models.word2vec.report_values['memory']->self.estimate_memory(vocab_size=report_values['num_retained_words'])
A:gensim.models.word2vec.vocab->defaultdict(int)
A:gensim.models.word2vec.corpus_iterable->LineSentence(corpus_file)
A:gensim.models.word2vec.sorted_vocab->sorted(self.raw_vocab.keys(), key=lambda word: self.raw_vocab[word], reverse=True)
A:gensim.models.word2vec.self.effective_min_count->max(calc_min_count, min_count)
A:gensim.models.word2vec.self.wv.key_to_index[word]->len(self.wv)
A:gensim.models.word2vec.threshold_count->int(sample * (3 + np.sqrt(5)) / 2)
A:gensim.models.word2vec.self.raw_vocab->defaultdict(int)
A:gensim.models.word2vec.report['total']->sum(report.values())
A:gensim.models.word2vec.vocab_size->len(self.wv.index_to_key)
A:gensim.models.word2vec.self.cum_table->numpy.zeros(vocab_size, dtype=np.uint32)
A:gensim.models.word2vec.count->self.wv.get_vecattr(word_index, 'count')
A:gensim.models.word2vec.self.cum_table[word_index]->round(cumulative / train_words_pow * domain)
A:gensim.models.word2vec.self.syn1->numpy.vstack([self.syn1, np.zeros((gained_vocab, self.layer1_size), dtype=REAL)])
A:gensim.models.word2vec.self.syn1neg->numpy.vstack([self.syn1neg, pad])
A:gensim.models.word2vec.preresize_count->len(self.wv.vectors)
A:gensim.models.word2vec.pad->numpy.zeros((gained_vocab, self.layer1_size), dtype=REAL)
A:gensim.models.word2vec.(examples, tally, raw_tally)->self._do_train_epoch(corpus_file, thread_id, offset, cython_vocab, thread_private_mem, cur_epoch, total_examples=total_examples, total_words=total_words, **kwargs)
A:gensim.models.word2vec.(trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch)->self._train_epoch_corpusfile(corpus_file, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words, callbacks=callbacks, **kwargs)
A:gensim.models.word2vec.thread_private_mem->self._get_thread_working_mem()
A:gensim.models.word2vec.job->Queue(maxsize=queue_factor * self.workers).get()
A:gensim.models.word2vec.(tally, raw_tally)->self._do_train_job(data_iterable, alpha, thread_private_mem)
A:gensim.models.word2vec.next_alpha->max(end_alpha, next_alpha)
A:gensim.models.word2vec.data_length->self._raw_word_count([data])
A:gensim.models.word2vec.report->Queue(maxsize=(queue_factor + 1) * self.workers).get()
A:gensim.models.word2vec.cython_vocab->CythonVocab(self.wv, hs=self.hs, fasttext=isinstance(self, FastText))
A:gensim.models.word2vec.progress_queue->Queue(maxsize=(queue_factor + 1) * self.workers)
A:gensim.models.word2vec.corpus_file_size->os.path.getsize(corpus_file)
A:gensim.models.word2vec.thread_kwargs->copy.copy(kwargs)
A:gensim.models.word2vec.(trained_word_count, raw_word_count, job_tally)->self._log_epoch_progress(progress_queue, job_queue, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words, report_delay=report_delay, is_corpus_file_mode=False)
A:gensim.models.word2vec.job_queue->Queue(maxsize=queue_factor * self.workers)
A:gensim.models.word2vec.work->numpy.zeros(1, dtype=REAL)
A:gensim.models.word2vec.neu1->gensim.matutils.zeros_aligned(self.layer1_size, dtype=REAL)
A:gensim.models.word2vec.score->score_sentence_cbow(self, sentence, work, neu1)
A:gensim.models.word2vec.sentence_scores->gensim.matutils.zeros_aligned(total_sentences, dtype=REAL)
A:gensim.models.word2vec.jobs_source->enumerate(utils.grouper(enumerate(sentences), chunksize))
A:gensim.models.word2vec.(job_no, items)->next(jobs_source)
A:gensim.models.word2vec.ns->Queue(maxsize=(queue_factor + 1) * self.workers).get(push_done)
A:gensim.models.word2vec.l1->numpy.sum(self.wv.vectors[word2_indices], axis=0)
A:gensim.models.word2vec.prob_values->numpy.exp(np.dot(l1, self.syn1neg.T))
A:gensim.models.word2vec.top_indices->gensim.matutils.argsort(prob_values, topn=topn, reverse=True)
A:gensim.models.word2vec.ignore->set(ignore).union(['cum_table'])
A:gensim.models.word2vec.model->Word2Vec(corpus, vector_size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, epochs=args.iter)
A:gensim.models.word2vec.fname->os.path.join(self.dirname, fname)
A:gensim.models.word2vec.line->gensim.utils.to_unicode(line).split()
A:gensim.models.word2vec.words->gensim.utils.to_unicode(text).split()
A:gensim.models.word2vec.last_token->text.rfind(b' ')
A:gensim.models.word2vec.self.source->os.path.join(self.source, '')
A:gensim.models.word2vec.self.input_files->os.listdir(self.source)
A:gensim.models.word2vec.heap->_build_heap(wv)
A:gensim.models.word2vec.(node, codes, points)->stack.pop()
A:gensim.models.word2vec.max_depth->max(len(codes), max_depth)
A:gensim.models.word2vec.points->numpy.array(list(points) + [node.index - len(wv)], dtype=np.uint32)
A:gensim.models.word2vec.program->os.path.basename(sys.argv[0])
A:gensim.models.word2vec.parser->argparse.ArgumentParser()
A:gensim.models.word2vec.args->argparse.ArgumentParser().parse_args()
A:gensim.models.word2vec.corpus->LineSentence(args.train)
gensim.models.Word2Vec(self,sentences=None,corpus_file=None,vector_size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,ns_exponent=0.75,cbow_mean=1,hashfxn=hash,epochs=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False,callbacks=(),comment=None,max_final_vocab=None,shrink_windows=True)
gensim.models.Word2Vec.__str__(self)
gensim.models.Word2Vec._check_corpus_sanity(self,corpus_iterable=None,corpus_file=None,passes=1)
gensim.models.Word2Vec._check_training_sanity(self,epochs=0,total_examples=None,total_words=None,**kwargs)
gensim.models.Word2Vec._clear_post_train(self)
gensim.models.Word2Vec._do_train_epoch(self,corpus_file,thread_id,offset,cython_vocab,thread_private_mem,cur_epoch,total_examples=None,total_words=None,**kwargs)
gensim.models.Word2Vec._do_train_job(self,sentences,alpha,inits)
gensim.models.Word2Vec._get_next_alpha(self,epoch_progress,cur_epoch)
gensim.models.Word2Vec._get_thread_working_mem(self)
gensim.models.Word2Vec._job_producer(self,data_iterator,job_queue,cur_epoch=0,total_examples=None,total_words=None)
gensim.models.Word2Vec._load_specials(self,*args,**kwargs)
gensim.models.Word2Vec._log_epoch_end(self,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed,is_corpus_file_mode)
gensim.models.Word2Vec._log_epoch_progress(self,progress_queue=None,job_queue=None,cur_epoch=0,total_examples=None,total_words=None,report_delay=1.0,is_corpus_file_mode=None)
gensim.models.Word2Vec._log_progress(self,job_queue,progress_queue,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed)
gensim.models.Word2Vec._log_train_end(self,raw_word_count,trained_word_count,total_elapsed,job_tally)
gensim.models.Word2Vec._raw_word_count(self,job)
gensim.models.Word2Vec._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.models.Word2Vec._scan_vocab(self,sentences,progress_per,trim_rule)
gensim.models.Word2Vec._train_epoch(self,data_iterable,cur_epoch=0,total_examples=None,total_words=None,queue_factor=2,report_delay=1.0,callbacks=())
gensim.models.Word2Vec._train_epoch_corpusfile(self,corpus_file,cur_epoch=0,total_examples=None,total_words=None,callbacks=(),**kwargs)
gensim.models.Word2Vec._worker_loop(self,job_queue,progress_queue)
gensim.models.Word2Vec._worker_loop_corpusfile(self,corpus_file,thread_id,offset,cython_vocab,progress_queue,cur_epoch=0,total_examples=None,total_words=None,**kwargs)
gensim.models.Word2Vec.add_null_word(self)
gensim.models.Word2Vec.build_vocab(self,corpus_iterable=None,corpus_file=None,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.Word2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.Word2Vec.create_binary_tree(self)
gensim.models.Word2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.Word2Vec.get_latest_training_loss(self)
gensim.models.Word2Vec.init_sims(self,replace=False)
gensim.models.Word2Vec.init_weights(self)
gensim.models.Word2Vec.load(cls,*args,rethrow=False,**kwargs)
gensim.models.Word2Vec.make_cum_table(self,domain=2**31-1)
gensim.models.Word2Vec.predict_output_word(self,context_words_list,topn=10)
gensim.models.Word2Vec.prepare_vocab(self,update=False,keep_raw_vocab=False,trim_rule=None,min_count=None,sample=None,dry_run=False)
gensim.models.Word2Vec.prepare_weights(self,update=False)
gensim.models.Word2Vec.reset_from(self,other_model)
gensim.models.Word2Vec.save(self,*args,**kwargs)
gensim.models.Word2Vec.scan_vocab(self,corpus_iterable=None,corpus_file=None,progress_per=10000,workers=None,trim_rule=None)
gensim.models.Word2Vec.score(self,sentences,total_sentences=int(1000000.0),chunksize=100,queue_factor=2,report_delay=1)
gensim.models.Word2Vec.seeded_vector(self,seed_string,vector_size)
gensim.models.Word2Vec.train(self,corpus_iterable=None,corpus_file=None,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=False,callbacks=(),**kwargs)
gensim.models.Word2Vec.update_weights(self)
gensim.models.Word2VecTrainables(utils.SaveLoad)
gensim.models.Word2VecVocab(utils.SaveLoad)
gensim.models.word2vec.BrownCorpus(self,dirname)
gensim.models.word2vec.BrownCorpus.__init__(self,dirname)
gensim.models.word2vec.BrownCorpus.__iter__(self)
gensim.models.word2vec.Heapitem(namedtuple('Heapitem','count,index,left,right'))
gensim.models.word2vec.Heapitem.__lt__(self,other)
gensim.models.word2vec.LineSentence(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.LineSentence.__init__(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.LineSentence.__iter__(self)
gensim.models.word2vec.PathLineSentences(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.PathLineSentences.__init__(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.PathLineSentences.__iter__(self)
gensim.models.word2vec.Text8Corpus(self,fname,max_sentence_length=MAX_WORDS_IN_BATCH)
gensim.models.word2vec.Text8Corpus.__init__(self,fname,max_sentence_length=MAX_WORDS_IN_BATCH)
gensim.models.word2vec.Text8Corpus.__iter__(self)
gensim.models.word2vec.Word2Vec(self,sentences=None,corpus_file=None,vector_size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,ns_exponent=0.75,cbow_mean=1,hashfxn=hash,epochs=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False,callbacks=(),comment=None,max_final_vocab=None,shrink_windows=True)
gensim.models.word2vec.Word2Vec.__init__(self,sentences=None,corpus_file=None,vector_size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,ns_exponent=0.75,cbow_mean=1,hashfxn=hash,epochs=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False,callbacks=(),comment=None,max_final_vocab=None,shrink_windows=True)
gensim.models.word2vec.Word2Vec.__str__(self)
gensim.models.word2vec.Word2Vec._check_corpus_sanity(self,corpus_iterable=None,corpus_file=None,passes=1)
gensim.models.word2vec.Word2Vec._check_training_sanity(self,epochs=0,total_examples=None,total_words=None,**kwargs)
gensim.models.word2vec.Word2Vec._clear_post_train(self)
gensim.models.word2vec.Word2Vec._do_train_epoch(self,corpus_file,thread_id,offset,cython_vocab,thread_private_mem,cur_epoch,total_examples=None,total_words=None,**kwargs)
gensim.models.word2vec.Word2Vec._do_train_job(self,sentences,alpha,inits)
gensim.models.word2vec.Word2Vec._get_next_alpha(self,epoch_progress,cur_epoch)
gensim.models.word2vec.Word2Vec._get_thread_working_mem(self)
gensim.models.word2vec.Word2Vec._job_producer(self,data_iterator,job_queue,cur_epoch=0,total_examples=None,total_words=None)
gensim.models.word2vec.Word2Vec._load_specials(self,*args,**kwargs)
gensim.models.word2vec.Word2Vec._log_epoch_end(self,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed,is_corpus_file_mode)
gensim.models.word2vec.Word2Vec._log_epoch_progress(self,progress_queue=None,job_queue=None,cur_epoch=0,total_examples=None,total_words=None,report_delay=1.0,is_corpus_file_mode=None)
gensim.models.word2vec.Word2Vec._log_progress(self,job_queue,progress_queue,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed)
gensim.models.word2vec.Word2Vec._log_train_end(self,raw_word_count,trained_word_count,total_elapsed,job_tally)
gensim.models.word2vec.Word2Vec._raw_word_count(self,job)
gensim.models.word2vec.Word2Vec._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.models.word2vec.Word2Vec._scan_vocab(self,sentences,progress_per,trim_rule)
gensim.models.word2vec.Word2Vec._train_epoch(self,data_iterable,cur_epoch=0,total_examples=None,total_words=None,queue_factor=2,report_delay=1.0,callbacks=())
gensim.models.word2vec.Word2Vec._train_epoch_corpusfile(self,corpus_file,cur_epoch=0,total_examples=None,total_words=None,callbacks=(),**kwargs)
gensim.models.word2vec.Word2Vec._worker_loop(self,job_queue,progress_queue)
gensim.models.word2vec.Word2Vec._worker_loop_corpusfile(self,corpus_file,thread_id,offset,cython_vocab,progress_queue,cur_epoch=0,total_examples=None,total_words=None,**kwargs)
gensim.models.word2vec.Word2Vec.add_null_word(self)
gensim.models.word2vec.Word2Vec.build_vocab(self,corpus_iterable=None,corpus_file=None,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.word2vec.Word2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.word2vec.Word2Vec.create_binary_tree(self)
gensim.models.word2vec.Word2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.word2vec.Word2Vec.get_latest_training_loss(self)
gensim.models.word2vec.Word2Vec.init_sims(self,replace=False)
gensim.models.word2vec.Word2Vec.init_weights(self)
gensim.models.word2vec.Word2Vec.load(cls,*args,rethrow=False,**kwargs)
gensim.models.word2vec.Word2Vec.make_cum_table(self,domain=2**31-1)
gensim.models.word2vec.Word2Vec.predict_output_word(self,context_words_list,topn=10)
gensim.models.word2vec.Word2Vec.prepare_vocab(self,update=False,keep_raw_vocab=False,trim_rule=None,min_count=None,sample=None,dry_run=False)
gensim.models.word2vec.Word2Vec.prepare_weights(self,update=False)
gensim.models.word2vec.Word2Vec.reset_from(self,other_model)
gensim.models.word2vec.Word2Vec.save(self,*args,**kwargs)
gensim.models.word2vec.Word2Vec.scan_vocab(self,corpus_iterable=None,corpus_file=None,progress_per=10000,workers=None,trim_rule=None)
gensim.models.word2vec.Word2Vec.score(self,sentences,total_sentences=int(1000000.0),chunksize=100,queue_factor=2,report_delay=1)
gensim.models.word2vec.Word2Vec.seeded_vector(self,seed_string,vector_size)
gensim.models.word2vec.Word2Vec.train(self,corpus_iterable=None,corpus_file=None,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=False,callbacks=(),**kwargs)
gensim.models.word2vec.Word2Vec.update_weights(self)
gensim.models.word2vec.Word2VecTrainables(utils.SaveLoad)
gensim.models.word2vec.Word2VecVocab(utils.SaveLoad)
gensim.models.word2vec._assign_binary_codes(wv)
gensim.models.word2vec._build_heap(wv)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/lda_dispatcher.py----------------------------------------
A:gensim.models.lda_dispatcher.logger->logging.getLogger('gensim.models.lda_dispatcher')
A:gensim.models.lda_dispatcher.self.jobs->Queue(maxsize=self.maxsize)
A:gensim.models.lda_dispatcher.self.lock_update->threading.Lock()
A:gensim.models.lda_dispatcher.self.callback->Pyro4.Proxy(ns.list(prefix=LDA_DISPATCHER_PREFIX)[LDA_DISPATCHER_PREFIX])
A:gensim.models.lda_dispatcher.worker->Pyro4.Proxy(uri)
A:gensim.models.lda_dispatcher.workerid->len(self.workers)
A:gensim.models.lda_dispatcher.job->self.jobs.get(block=True, timeout=1)
A:gensim.models.lda_dispatcher.workers->list(self.workers.values())
A:gensim.models.lda_dispatcher.result->workers[0].getstate()
A:gensim.models.lda_dispatcher.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter)
A:gensim.models.lda_dispatcher.args->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter).parse_args()
gensim.models.lda_dispatcher.Dispatcher(self,maxsize=MAX_JOBS_QUEUE,ns_conf=None)
gensim.models.lda_dispatcher.Dispatcher.__init__(self,maxsize=MAX_JOBS_QUEUE,ns_conf=None)
gensim.models.lda_dispatcher.Dispatcher.exit(self)
gensim.models.lda_dispatcher.Dispatcher.getjob(self,worker_id)
gensim.models.lda_dispatcher.Dispatcher.getstate(self)
gensim.models.lda_dispatcher.Dispatcher.getworkers(self)
gensim.models.lda_dispatcher.Dispatcher.initialize(self,**model_params)
gensim.models.lda_dispatcher.Dispatcher.jobdone(self,workerid)
gensim.models.lda_dispatcher.Dispatcher.jobsdone(self)
gensim.models.lda_dispatcher.Dispatcher.putjob(self,job)
gensim.models.lda_dispatcher.Dispatcher.reset(self,state)
gensim.models.lda_dispatcher.main()


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/models/fasttext.py----------------------------------------
A:gensim.models.fasttext.logger->logging.getLogger(__name__)
A:gensim.models.fasttext.self.wv->FastTextKeyedVectors(vector_size, min_n, max_n, bucket)
A:gensim.models.fasttext.self.wv.vectors_vocab_lockf->ones(1, dtype=REAL)
A:gensim.models.fasttext.self.wv.vectors_ngrams_lockf->ones(1, dtype=REAL)
A:gensim.models.fasttext.num_vectors->len(self.wv.vectors)
A:gensim.models.fasttext.vocab_size->len(self.wv)
A:gensim.models.fasttext.hashes->ft_ngram_hashes(word, self.wv.min_n, self.wv.max_n, self.wv.bucket)
A:gensim.models.fasttext.report['total']->sum(report.values())
A:gensim.models.fasttext.(examples, tally, raw_tally)->train_epoch_cbow(self, corpus_file, offset, cython_vocab, cur_epoch, total_examples, total_words, work, neu1)
A:gensim.models.fasttext.tally->train_batch_any(self, sentences, alpha, work, neu1)
A:gensim.models.fasttext.m->numpy.concatenate([m, [fill] * (num_rows - orig_rows)])
A:gensim.models.fasttext.new_arr->numpy.ones(new_len, dtype=REAL)
A:gensim.models.fasttext.full_model->_load_fasttext_format(path, encoding=encoding, full_model=False)
A:gensim.models.fasttext.model->FastText(vector_size=m.dim, window=m.ws, epochs=m.epoch, negative=m.neg, hs=int(m.loss == 1), sg=int(m.model == 2), bucket=m.bucket, min_count=m.min_count, sample=m.t, min_n=m.minn, max_n=m.maxn)
A:gensim.models.fasttext.self.vectors_vocab->numpy.array(fb_vectors[:vocab_words, :])
A:gensim.models.fasttext.self.vectors_vocab_lockf->ones(1, dtype=REAL)
A:gensim.models.fasttext.self.vectors_ngrams_lockf->ones(1, dtype=REAL)
A:gensim.models.fasttext.ignore->set(ignore).union(['buckets_word', 'vectors'])
A:gensim.models.fasttext.word_vec->numpy.zeros(self.vectors_ngrams.shape[1], dtype=np.float32)
A:gensim.models.fasttext.ngram_hashes->ft_ngram_hashes(word, self.min_n, self.max_n, self.bucket)
A:gensim.models.fasttext.self.vectors_ngrams->numpy.array(fb_vectors[vocab_words:, :])
A:gensim.models.fasttext.vocab_words->len(self)
A:gensim.models.fasttext.self.vectors->self.vectors_vocab[:].copy()
A:gensim.models.fasttext.self.buckets_word[i]->numpy.array(ft_ngram_hashes(word, self.min_n, self.max_n, self.bucket), dtype=np.uint32)
A:gensim.models.fasttext.suffix->rand.uniform(low, high, (new_rows, columns)).astype(REAL)
A:gensim.models.fasttext.encoded_ngrams->compute_ngrams_bytes(word, minn, maxn)
gensim.models.FastText(self,sentences=None,corpus_file=None,sg=0,hs=0,vector_size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,ns_exponent=0.75,cbow_mean=1,hashfxn=hash,epochs=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH,callbacks=(),max_final_vocab=None,shrink_windows=True)
gensim.models.FastText._clear_post_train(self)
gensim.models.FastText._do_train_epoch(self,corpus_file,thread_id,offset,cython_vocab,thread_private_mem,cur_epoch,total_examples=None,total_words=None,**kwargs)
gensim.models.FastText._do_train_job(self,sentences,alpha,inits)
gensim.models.FastText._init_post_load(self,hidden_output)
gensim.models.FastText._load_specials(self,*args,**kwargs)
gensim.models.FastText.estimate_memory(self,vocab_size=None,report=None)
gensim.models.FastText.init_sims(self,replace=False)
gensim.models.FastText.load(cls,*args,**kwargs)
gensim.models.FastText.load_binary_data(self,encoding='utf8')
gensim.models.FastText.load_fasttext_format(cls,model_file,encoding='utf8')
gensim.models.FastText.save(self,*args,**kwargs)
gensim.models.FastTextKeyedVectors(self,vector_size,min_n,max_n,bucket,count=0,dtype=REAL)
gensim.models.FastTextKeyedVectors.__contains__(self,word)
gensim.models.FastTextKeyedVectors._load_specials(self,*args,**kwargs)
gensim.models.FastTextKeyedVectors._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.models.FastTextKeyedVectors.adjust_vectors(self)
gensim.models.FastTextKeyedVectors.get_vector(self,word,norm=False)
gensim.models.FastTextKeyedVectors.init_post_load(self,fb_vectors)
gensim.models.FastTextKeyedVectors.load(cls,fname_or_handle,**kwargs)
gensim.models.FastTextKeyedVectors.recalc_char_ngram_buckets(self)
gensim.models.FastTextKeyedVectors.resize_vectors(self,seed=0)
gensim.models.FastTextKeyedVectors.save(self,*args,**kwargs)
gensim.models.FastTextTrainables(utils.SaveLoad)
gensim.models.FastTextVocab(utils.SaveLoad)
gensim.models.fasttext.FastText(self,sentences=None,corpus_file=None,sg=0,hs=0,vector_size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,ns_exponent=0.75,cbow_mean=1,hashfxn=hash,epochs=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH,callbacks=(),max_final_vocab=None,shrink_windows=True)
gensim.models.fasttext.FastText.__init__(self,sentences=None,corpus_file=None,sg=0,hs=0,vector_size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,ns_exponent=0.75,cbow_mean=1,hashfxn=hash,epochs=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH,callbacks=(),max_final_vocab=None,shrink_windows=True)
gensim.models.fasttext.FastText._clear_post_train(self)
gensim.models.fasttext.FastText._do_train_epoch(self,corpus_file,thread_id,offset,cython_vocab,thread_private_mem,cur_epoch,total_examples=None,total_words=None,**kwargs)
gensim.models.fasttext.FastText._do_train_job(self,sentences,alpha,inits)
gensim.models.fasttext.FastText._init_post_load(self,hidden_output)
gensim.models.fasttext.FastText._load_specials(self,*args,**kwargs)
gensim.models.fasttext.FastText.estimate_memory(self,vocab_size=None,report=None)
gensim.models.fasttext.FastText.init_sims(self,replace=False)
gensim.models.fasttext.FastText.load(cls,*args,**kwargs)
gensim.models.fasttext.FastText.load_binary_data(self,encoding='utf8')
gensim.models.fasttext.FastText.load_fasttext_format(cls,model_file,encoding='utf8')
gensim.models.fasttext.FastText.save(self,*args,**kwargs)
gensim.models.fasttext.FastTextKeyedVectors(self,vector_size,min_n,max_n,bucket,count=0,dtype=REAL)
gensim.models.fasttext.FastTextKeyedVectors.__contains__(self,word)
gensim.models.fasttext.FastTextKeyedVectors.__init__(self,vector_size,min_n,max_n,bucket,count=0,dtype=REAL)
gensim.models.fasttext.FastTextKeyedVectors._load_specials(self,*args,**kwargs)
gensim.models.fasttext.FastTextKeyedVectors._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.models.fasttext.FastTextKeyedVectors.adjust_vectors(self)
gensim.models.fasttext.FastTextKeyedVectors.get_vector(self,word,norm=False)
gensim.models.fasttext.FastTextKeyedVectors.init_post_load(self,fb_vectors)
gensim.models.fasttext.FastTextKeyedVectors.load(cls,fname_or_handle,**kwargs)
gensim.models.fasttext.FastTextKeyedVectors.recalc_char_ngram_buckets(self)
gensim.models.fasttext.FastTextKeyedVectors.resize_vectors(self,seed=0)
gensim.models.fasttext.FastTextKeyedVectors.save(self,*args,**kwargs)
gensim.models.fasttext.FastTextTrainables(utils.SaveLoad)
gensim.models.fasttext.FastTextVocab(utils.SaveLoad)
gensim.models.fasttext._check_model(m)
gensim.models.fasttext._is_utf8_continue(b)
gensim.models.fasttext._load_fasttext_format(model_file,encoding='utf-8',full_model=True)
gensim.models.fasttext._pad_ones(m,new_len)
gensim.models.fasttext._pad_random(m,new_rows,rand)
gensim.models.fasttext._unpack(m,num_rows,hash2index,seed=1,fill=None)
gensim.models.fasttext.ft_ngram_hashes(word,minn,maxn,num_buckets)
gensim.models.fasttext.load_facebook_model(path,encoding='utf-8')
gensim.models.fasttext.load_facebook_vectors(path,encoding='utf-8')
gensim.models.fasttext.save_facebook_model(model,path,encoding='utf-8',lr_update_rate=100,word_ngrams=1)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/indirect_confirmation_measure.py----------------------------------------
A:gensim.topic_coherence.indirect_confirmation_measure.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.indirect_confirmation_measure.context_vectors->ContextVectorComputer(measure, topics, accumulator, gamma)
A:gensim.topic_coherence.indirect_confirmation_measure.topic_words->tuple(topic_words)
A:gensim.topic_coherence.indirect_confirmation_measure.segment_sims->numpy.zeros(len(topic_segments))
A:gensim.topic_coherence.indirect_confirmation_measure.segment_sims[i]->_cossim(w_prime_cv, w_star_cv)
A:gensim.topic_coherence.indirect_confirmation_measure.self.mapping->_map_to_contiguous(topics)
A:gensim.topic_coherence.indirect_confirmation_measure.self.vocab_size->len(self.mapping)
A:gensim.topic_coherence.indirect_confirmation_measure.key->_key_for_segment(segment_word_ids, topic_word_ids)
A:gensim.topic_coherence.indirect_confirmation_measure.context_vector->scipy.sparse.lil_matrix((self.vocab_size, 1))
A:gensim.topic_coherence.indirect_confirmation_measure.self.sim_cache[pair]->self.similarity(pair, self.accumulator)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer(self,measure,topics,accumulator,gamma)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer.__getitem__(self,idx)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer.__init__(self,measure,topics,accumulator,gamma)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer._make_seg(self,segment_word_ids,topic_word_ids)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer.compute_context_vector(self,segment_word_ids,topic_word_ids)
gensim.topic_coherence.indirect_confirmation_measure._cossim(cv1,cv2)
gensim.topic_coherence.indirect_confirmation_measure._key_for_segment(segment,topic_words)
gensim.topic_coherence.indirect_confirmation_measure._magnitude(sparse_vec)
gensim.topic_coherence.indirect_confirmation_measure._map_to_contiguous(ids_iterable)
gensim.topic_coherence.indirect_confirmation_measure._pair_npmi(pair,accumulator)
gensim.topic_coherence.indirect_confirmation_measure.cosine_similarity(segmented_topics,accumulator,topics,measure='nlr',gamma=1,with_std=False,with_support=False)
gensim.topic_coherence.indirect_confirmation_measure.word2vec_similarity(segmented_topics,accumulator,with_std=False,with_support=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/probability_estimation.py----------------------------------------
A:gensim.topic_coherence.probability_estimation.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.probability_estimation.top_ids->unique_ids_from_segments(segmented_topics)
A:gensim.topic_coherence.probability_estimation.accumulator->WordVectorsAccumulator(top_ids, dictionary, model, window=window_size, workers=processes)
A:gensim.topic_coherence.probability_estimation.unique_ids->set()
gensim.topic_coherence.probability_estimation.p_boolean_document(corpus,segmented_topics)
gensim.topic_coherence.probability_estimation.p_boolean_sliding_window(texts,segmented_topics,dictionary,window_size,processes=1)
gensim.topic_coherence.probability_estimation.p_word2vec(texts,segmented_topics,dictionary,window_size=None,processes=1,model=None)
gensim.topic_coherence.probability_estimation.unique_ids_from_segments(segmented_topics)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/segmentation.py----------------------------------------
A:gensim.topic_coherence.segmentation.logger->logging.getLogger(__name__)
gensim.topic_coherence.segmentation.s_one_one(topics)
gensim.topic_coherence.segmentation.s_one_pre(topics)
gensim.topic_coherence.segmentation.s_one_set(topics)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/aggregation.py----------------------------------------
A:gensim.topic_coherence.aggregation.logger->logging.getLogger(__name__)
gensim.topic_coherence.aggregation.arithmetic_mean(confirmed_measures)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/direct_confirmation_measure.py----------------------------------------
A:gensim.topic_coherence.direct_confirmation_measure.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.direct_confirmation_measure.num_docs->float(accumulator.num_docs)
A:gensim.topic_coherence.direct_confirmation_measure.m_lc_i->numpy.log((co_occur_count / num_docs + EPSILON) / (w_star_count / num_docs))
A:gensim.topic_coherence.direct_confirmation_measure.mean->numpy.mean(segment_sims)
A:gensim.topic_coherence.direct_confirmation_measure.m_lr_i->numpy.log(numerator / denominator)
gensim.topic_coherence.direct_confirmation_measure.aggregate_segment_sims(segment_sims,with_std,with_support)
gensim.topic_coherence.direct_confirmation_measure.log_conditional_probability(segmented_topics,accumulator,with_std=False,with_support=False)
gensim.topic_coherence.direct_confirmation_measure.log_ratio_measure(segmented_topics,accumulator,normalize=False,with_std=False,with_support=False)


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim4.1.2/topic_coherence/text_analysis.py----------------------------------------
A:gensim.topic_coherence.text_analysis.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.text_analysis.top_words->top_words.union(word).union(word)
A:gensim.topic_coherence.text_analysis.self._vocab_size->len(self.relevant_ids)
A:gensim.topic_coherence.text_analysis.self.relevant_words->_ids_to_words(self.relevant_ids, dictionary)
A:gensim.topic_coherence.text_analysis.word_id1->self._word2_contiguous_id(word1)
A:gensim.topic_coherence.text_analysis.word_id2->self._word2_contiguous_id(word2)
A:gensim.topic_coherence.text_analysis.self._inverted_index->numpy.array([set() for _ in range(self._vocab_size)])
A:gensim.topic_coherence.text_analysis.doc_words->frozenset((x[0] for x in text))
A:gensim.topic_coherence.text_analysis.top_ids_in_doc->self.relevant_ids.intersection(doc_words)
A:gensim.topic_coherence.text_analysis.relevant_texts->self._iter_texts(texts)
A:gensim.topic_coherence.text_analysis.windows->gensim.utils.iter_windows(relevant_texts, window_size, ignore_below_size=False, include_doc_num=True)
A:gensim.topic_coherence.text_analysis.self._occurrences->numpy.zeros(self._vocab_size, dtype='uint32')
A:gensim.topic_coherence.text_analysis.self._co_occurrences->self._co_occurrences.tolil()
A:gensim.topic_coherence.text_analysis.self._uniq_words->numpy.zeros((self._vocab_size + 1,), dtype=bool)
A:gensim.topic_coherence.text_analysis.self._counter->Counter()
A:gensim.topic_coherence.text_analysis.self.batch_size->self.model_kwargs.copy().get('batch_size', 64)
A:gensim.topic_coherence.text_analysis.(workers, input_q, output_q)->self.start_workers(window_size)
A:gensim.topic_coherence.text_analysis.accumulators->self.terminate_workers(input_q, output_q, workers, interrupted)
A:gensim.topic_coherence.text_analysis.input_q->multiprocessing.Queue(maxsize=self.processes)
A:gensim.topic_coherence.text_analysis.output_q->multiprocessing.Queue()
A:gensim.topic_coherence.text_analysis.accumulator->WordOccurrenceAccumulator(self.relevant_ids, self.dictionary)
A:gensim.topic_coherence.text_analysis.worker->AccumulatingWorker(input_q, output_q, accumulator, window_size)
A:gensim.topic_coherence.text_analysis.docs->self.input_q.get(block=True)
A:gensim.topic_coherence.text_analysis.uniq_words->set(utils.flatten(words))
A:gensim.topic_coherence.text_analysis.kwargs->self.model_kwargs.copy()
A:gensim.topic_coherence.text_analysis.kwargs['min_count']->self.model_kwargs.copy().get('min_count', 1)
A:gensim.topic_coherence.text_analysis.kwargs['sg']->self.model_kwargs.copy().get('sg', 1)
A:gensim.topic_coherence.text_analysis.kwargs['hs']->self.model_kwargs.copy().get('hw', 0)
A:gensim.topic_coherence.text_analysis.self.model->Word2Vec(**kwargs)
A:gensim.topic_coherence.text_analysis.words1->self._words_with_embeddings(ids1)
A:gensim.topic_coherence.text_analysis.words2->self._words_with_embeddings(ids2)
gensim.topic_coherence.text_analysis.AccumulatingWorker(self,input_q,output_q,accumulator,window_size)
gensim.topic_coherence.text_analysis.AccumulatingWorker.__init__(self,input_q,output_q,accumulator,window_size)
gensim.topic_coherence.text_analysis.AccumulatingWorker._run(self)
gensim.topic_coherence.text_analysis.AccumulatingWorker.reply_to_master(self)
gensim.topic_coherence.text_analysis.AccumulatingWorker.run(self)
gensim.topic_coherence.text_analysis.BaseAnalyzer(self,relevant_ids)
gensim.topic_coherence.text_analysis.BaseAnalyzer.__getitem__(self,word_or_words)
gensim.topic_coherence.text_analysis.BaseAnalyzer.__init__(self,relevant_ids)
gensim.topic_coherence.text_analysis.BaseAnalyzer._get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.BaseAnalyzer._get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.BaseAnalyzer.analyze_text(self,text,doc_num=None)
gensim.topic_coherence.text_analysis.BaseAnalyzer.get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.BaseAnalyzer.get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.BaseAnalyzer.num_docs(self)
gensim.topic_coherence.text_analysis.BaseAnalyzer.num_docs(self,num)
gensim.topic_coherence.text_analysis.CorpusAccumulator(InvertedIndexBased)
gensim.topic_coherence.text_analysis.CorpusAccumulator.accumulate(self,corpus)
gensim.topic_coherence.text_analysis.CorpusAccumulator.analyze_text(self,text,doc_num=None)
gensim.topic_coherence.text_analysis.InvertedIndexAccumulator(WindowedTextsAnalyzer,InvertedIndexBased)
gensim.topic_coherence.text_analysis.InvertedIndexAccumulator.analyze_text(self,window,doc_num=None)
gensim.topic_coherence.text_analysis.InvertedIndexBased(self,*args)
gensim.topic_coherence.text_analysis.InvertedIndexBased.__init__(self,*args)
gensim.topic_coherence.text_analysis.InvertedIndexBased._get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.InvertedIndexBased._get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.InvertedIndexBased.index_to_dict(self)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator(self,processes,*args,**kwargs)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.__init__(self,processes,*args,**kwargs)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.__str__(self)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.merge_accumulators(self,accumulators)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.queue_all_texts(self,q,texts,window_size)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.start_workers(self,window_size)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.terminate_workers(self,input_q,output_q,workers,interrupted=False)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.yield_batches(self,texts)
gensim.topic_coherence.text_analysis.PatchedWordOccurrenceAccumulator(WordOccurrenceAccumulator)
gensim.topic_coherence.text_analysis.PatchedWordOccurrenceAccumulator._iter_texts(self,texts)
gensim.topic_coherence.text_analysis.UsesDictionary(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.UsesDictionary.__init__(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.UsesDictionary._word2_contiguous_id(self,word)
gensim.topic_coherence.text_analysis.UsesDictionary.get_co_occurrences(self,word1,word2)
gensim.topic_coherence.text_analysis.UsesDictionary.get_occurrences(self,word)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer.__init__(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer._iter_texts(self,texts)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer.text_is_relevant(self,text)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator(self,*args)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.__init__(self,*args)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.__str__(self)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._slide_window(self,window,doc_num)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._symmetrize(self)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.analyze_text(self,window,doc_num=None)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.merge(self,other)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.partial_accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator(self,relevant_ids,dictionary,model=None,**model_kwargs)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.__init__(self,relevant_ids,dictionary,model=None,**model_kwargs)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator._words_with_embeddings(self,ids)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.get_co_occurrences(self,word1,word2)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.get_occurrences(self,word)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.ids_similarity(self,ids1,ids2)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.not_in_vocab(self,words)
gensim.topic_coherence.text_analysis._ids_to_words(ids,dictionary)

