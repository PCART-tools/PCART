
----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/downloader.py----------------------------------------
A:gensim.downloader.user_dir->os.path.expanduser('~')
A:gensim.downloader.base_dir->os.path.join(user_dir, 'gensim-data')
A:gensim.downloader.logger->logging.getLogger('gensim.api')
A:gensim.downloader.size_downloaded->float(chunks_downloaded * chunk_size)
A:gensim.downloader.filled_len->int(math.floor(bar_len * size_downloaded / total_size))
A:gensim.downloader.percent_downloaded->round(size_downloaded * 100 / total_size, 1)
A:gensim.downloader.hash_md5->hashlib.md5()
A:gensim.downloader.information->info()
A:gensim.downloader.url_load_file->'{base}/{fname}/__init__.py'.format(base=DOWNLOAD_BASE_URL, fname=name)
A:gensim.downloader.data_folder_dir->os.path.join(base_dir, name)
A:gensim.downloader.tmp_dir->tempfile.mkdtemp()
A:gensim.downloader.init_path->os.path.join(tmp_dir, '__init__.py')
A:gensim.downloader.total_parts->_get_parts(name)
A:gensim.downloader.concatenated_folder_name->'{fname}.gz'.format(fname=name)
A:gensim.downloader.concatenated_folder_dir->os.path.join(tmp_dir, concatenated_folder_name)
A:gensim.downloader.url_data->'{base}/{fname}/{fname}.gz'.format(base=DOWNLOAD_BASE_URL, fname=name)
A:gensim.downloader.fname->'{fname}.gz'.format(fname=name)
A:gensim.downloader.dst_path->os.path.join(tmp_dir, fname)
A:gensim.downloader.part_path->os.path.join(tmp_dir, '{fname}.gz_0{part}'.format(fname=name, part=part))
A:gensim.downloader.file_name->_get_filename(name)
A:gensim.downloader.folder_dir->os.path.join(base_dir, name)
A:gensim.downloader.path->os.path.join(folder_dir, file_name)
A:gensim.downloader.module->__import__(name)
A:gensim.downloader.parser->argparse.ArgumentParser(description='Gensim console API', usage='python -m gensim.api.downloader  [-h] [-d data_name | -i data_name | -c]')
A:gensim.downloader.group->argparse.ArgumentParser(description='Gensim console API', usage='python -m gensim.api.downloader  [-h] [-d data_name | -i data_name | -c]').add_mutually_exclusive_group()
A:gensim.downloader.args->argparse.ArgumentParser(description='Gensim console API', usage='python -m gensim.api.downloader  [-h] [-d data_name | -i data_name | -c]').parse_args()
A:gensim.downloader.data_path->load(args.download[0], return_path=True)
gensim.downloader._calculate_md5_checksum(fname)
gensim.downloader._create_base_dir()
gensim.downloader._download(name)
gensim.downloader._get_checksum(name,part=None)
gensim.downloader._get_filename(name)
gensim.downloader._get_parts(name)
gensim.downloader._progress(chunks_downloaded,chunk_size,total_size,part=1,total_parts=1)
gensim.downloader.info(name=None,show_only_latest=True)
gensim.downloader.load(name,return_path=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/utils.py----------------------------------------
A:gensim.utils.logger->logging.getLogger(__name__)
A:gensim.utils.PAT_ALPHABETIC->re.compile('(((?![\\d])\\w)+)', re.UNICODE)
A:gensim.utils.RE_HTML_ENTITY->re.compile('&(#?)([xX]?)(\\w{1,8});', re.UNICODE)
A:gensim.utils.tlock->getattr(self, tlockname)
A:gensim.utils.result->socket.gethostbyname(socket.gethostname())
A:gensim.utils.mgr->file_or_filename(input)
A:gensim.utils.text->deaccent(text)
A:gensim.utils.norm->unicodedata.normalize('NFD', text)
A:gensim.utils.(compress, subname)->SaveLoad._adapt_by_suffix(fname)
A:gensim.utils.obj->itertools.chain([doc1], obj)
A:gensim.utils.cfname->'.'.join((fname, attrib))
A:gensim.utils.val->numpy.load(subname(fname, attrib), mmap_mode=mmap)
A:gensim.utils.sparse->unpickle(subname(fname, attrib))
A:gensim.utils.sparse.data->numpy.load(subname(fname, attrib, 'data'), mmap_mode=mmap)
A:gensim.utils.sparse.indptr->numpy.load(subname(fname, attrib, 'indptr'), mmap_mode=mmap)
A:gensim.utils.sparse.indices->numpy.load(subname(fname, attrib, 'indices'), mmap_mode=mmap)
A:gensim.utils.restores->self._save_specials(fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)
A:gensim.utils.asides[attrib]->getattr(self, attrib)
A:gensim.utils.maxid->max(maxid, max([-1] + [fieldid for (fieldid, _) in document]))
A:gensim.utils.id2word->FakeDict(num_terms)
A:gensim.utils.doc1->next(iter(obj))
A:gensim.utils.(id1, val1)->next(iter(doc1))
A:gensim.utils.ns->locateNS()
A:gensim.utils.s->socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
A:gensim.utils.(result, port)->socket.socket(socket.AF_INET, socket.SOCK_DGRAM).getsockname()
A:gensim.utils.self.length->sum((1 for x in self))
A:gensim.utils.(start, end, step)->self.slice_.indices(len(self.corpus.index))
A:gensim.utils.ent->match.group(3)
A:gensim.utils.cp->htmlentitydefs.name2codepoint.get(ent)
A:gensim.utils.it->iter(self.corpus)
A:gensim.utils.chunk->itertools.islice(it, self.chunksize)
A:gensim.utils.qsize->self.q.qsize()
A:gensim.utils.q->multiprocessing.Queue(maxsize=maxsize)
A:gensim.utils.worker->InputQueue(q, corpus, chunksize, maxsize=maxsize, as_numpy=as_numpy)
A:gensim.utils.(fname, oext)->os.path.splitext(fname)
A:gensim.utils.sims->sorted(enumerate(sims), key=lambda item: -item[1])
A:gensim.utils.doc['tokens']->preprocess(doc['text'])
A:gensim.utils.uri->daemon.register(obj, name)
A:gensim.utils.content->u(' ').join(tokenize(content, lower=True, errors='ignore'))
A:gensim.utils.parsed->parse(content, lemmata=True, collapse=False)
A:gensim.utils.nnz->numpy.random.uniform(size=(dim,))
A:gensim.utils.old_len->len(vocab)
A:gensim.utils.rule_res->trim_rule(word, count, min_count)
A:gensim.utils.process->subprocess.Popen(*popenargs, stdout=stdout, **kwargs)
A:gensim.utils.(output, unused_err)->subprocess.Popen(*popenargs, stdout=stdout, **kwargs).communicate()
A:gensim.utils.retcode->subprocess.Popen(*popenargs, stdout=stdout, **kwargs).poll()
A:gensim.utils.cmd->kwargs.get('args')
A:gensim.utils.error->subprocess.CalledProcessError(retcode, cmd)
A:gensim.utils.ndarray->numpy.asarray(ndarray)
A:gensim.utils.doc_windows->strided_windows(document, window_size)
gensim.utils.ClippedCorpus(self,corpus,max_docs=None)
gensim.utils.ClippedCorpus.__init__(self,corpus,max_docs=None)
gensim.utils.ClippedCorpus.__iter__(self)
gensim.utils.ClippedCorpus.__len__(self)
gensim.utils.FakeDict(self,num_terms)
gensim.utils.FakeDict.__getitem__(self,val)
gensim.utils.FakeDict.__init__(self,num_terms)
gensim.utils.FakeDict.__len__(self)
gensim.utils.FakeDict.__str__(self)
gensim.utils.FakeDict.get(self,val,default=None)
gensim.utils.FakeDict.iteritems(self)
gensim.utils.FakeDict.keys(self)
gensim.utils.InputQueue(self,q,corpus,chunksize,maxsize,as_numpy)
gensim.utils.InputQueue.__init__(self,q,corpus,chunksize,maxsize,as_numpy)
gensim.utils.InputQueue.run(self)
gensim.utils.RepeatCorpus(self,corpus,reps)
gensim.utils.RepeatCorpus.__init__(self,corpus,reps)
gensim.utils.RepeatCorpus.__iter__(self)
gensim.utils.RepeatCorpusNTimes(self,corpus,n)
gensim.utils.RepeatCorpusNTimes.__init__(self,corpus,n)
gensim.utils.RepeatCorpusNTimes.__iter__(self)
gensim.utils.SaveLoad(object)
gensim.utils.SaveLoad._adapt_by_suffix(fname)
gensim.utils.SaveLoad._load_specials(self,fname,mmap,compress,subname)
gensim.utils.SaveLoad._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.utils.SaveLoad._smart_save(self,fname,separately=None,sep_limit=10*1024**2,ignore=frozenset(),pickle_protocol=2)
gensim.utils.SaveLoad.load(cls,fname,mmap=None)
gensim.utils.SaveLoad.save(self,fname_or_handle,separately=None,sep_limit=10*1024**2,ignore=frozenset(),pickle_protocol=2)
gensim.utils.SlicedCorpus(self,corpus,slice_)
gensim.utils.SlicedCorpus.__init__(self,corpus,slice_)
gensim.utils.SlicedCorpus.__iter__(self)
gensim.utils.SlicedCorpus.__len__(self)
gensim.utils._iter_windows(document,window_size,copy=False,ignore_below_size=True)
gensim.utils.any2unicode(text,encoding='utf8',errors='strict')
gensim.utils.any2utf8(text,errors='strict',encoding='utf8')
gensim.utils.call_on_class_only(*args,**kwargs)
gensim.utils.check_output(stdout=subprocess.PIPE,*popenargs,**kwargs)
gensim.utils.chunkize_serial(iterable,chunksize,as_numpy=False)
gensim.utils.copytree_hardlink(source,dest)
gensim.utils.deaccent(text)
gensim.utils.decode_htmlentities(text)
gensim.utils.deprecated(reason)
gensim.utils.dict_from_corpus(corpus)
gensim.utils.file_or_filename(input)
gensim.utils.flatten(nested_list)
gensim.utils.getNS(host=None,port=None,broadcast=True,hmac_key=None)
gensim.utils.get_max_id(corpus)
gensim.utils.get_my_ip()
gensim.utils.get_random_state(seed)
gensim.utils.has_pattern()
gensim.utils.identity(p)
gensim.utils.is_corpus(obj)
gensim.utils.iter_windows(texts,window_size,copy=False,ignore_below_size=True,include_doc_num=False)
gensim.utils.keep_vocab_item(word,count,min_count,trim_rule=None)
gensim.utils.lazy_flatten(nested_list)
gensim.utils.lemmatize(content,allowed_tags=re.compile('(NN|VB|JJ|RB)'),light=False,stopwords=frozenset(),min_length=2,max_length=15)
gensim.utils.mock_data(n_items=1000,dim=1000,prob_nnz=0.5,lam=1.0)
gensim.utils.mock_data_row(dim=1000,prob_nnz=0.5,lam=1.0)
gensim.utils.open_file(input)
gensim.utils.pickle(obj,fname,protocol=2)
gensim.utils.prune_vocab(vocab,min_reduce,trim_rule=None)
gensim.utils.pyro_daemon(name,obj,random_suffix=False,ip=None,port=None,ns_conf=None)
gensim.utils.qsize(queue)
gensim.utils.randfname(prefix='gensim')
gensim.utils.revdict(d)
gensim.utils.safe_unichr(intval)
gensim.utils.sample_dict(d,n=10,use_random=True)
gensim.utils.simple_preprocess(doc,deacc=False,min_len=2,max_len=15)
gensim.utils.simple_tokenize(text)
gensim.utils.smart_extension(fname,ext)
gensim.utils.strided_windows(ndarray,window_size)
gensim.utils.synchronous(tlockname)
gensim.utils.tokenize(text,lowercase=False,deacc=False,encoding='utf8',errors='strict',to_lower=False,lower=False)
gensim.utils.toptexts(query,texts,index,n=10)
gensim.utils.unpickle(fname)
gensim.utils.upload_chunked(server,docs,chunksize=1000,preprocess=None)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/matutils.py----------------------------------------
A:gensim.matutils.logger->logging.getLogger(__name__)
A:gensim.matutils.x->numpy.log(np.sum(np.exp(x - x_max)))
A:gensim.matutils.indices->set(list(vec1.keys()) + list(vec2.keys()))
A:gensim.matutils.data->numpy.asarray(data, dtype=dtype)
A:gensim.matutils.result->sum((value * vec2.get(index, 0.0) for (index, value) in iteritems(vec1)))
A:gensim.matutils.buffer->numpy.zeros(nbytes + align, dtype=np.uint8)
A:gensim.matutils.biggest->nnz.take(argsort(abs(vec).take(nnz), topn, reverse=True))
A:gensim.matutils.matrix_abs->abs(matrix)
A:gensim.matutils.v->matrix.getrow(i)
A:gensim.matutils.v_abs->abs(matrix).getrow(i)
A:gensim.matutils.matrix_indices->numpy.concatenate(matrix_indices).ravel()
A:gensim.matutils.matrix_data->numpy.concatenate(matrix_data).ravel()
A:gensim.matutils.vec->vec.todense().tolist().todense().tolist()
A:gensim.matutils.doc->dict(doc)
A:gensim.matutils.result[list(doc)]->list(itervalues(doc))
A:gensim.matutils.result[:, docno]->sparse2full(doc, num_terms)
A:gensim.matutils.self.sparse->sparse.tocsc()
A:gensim.matutils.max_val->numpy.max(vec, 1)
A:gensim.matutils.tot->numpy.sum(np.exp(vec + log_shift[:, np.newaxis]), 1)
A:gensim.matutils.k->ret_log_normalize_vec(vec.T)
A:gensim.matutils.blas_nrm2->blas('nrm2', np.array([], dtype=float))
A:gensim.matutils.blas_scal->blas('scal', np.array([], dtype=float))
A:gensim.matutils.veclen->blas_nrm2(vec)
A:gensim.matutils.first->next(iter(vec))
A:gensim.matutils.length->float(sum((abs(val) for (_, val) in vec)))
A:gensim.matutils.vec1->set(vec1)
A:gensim.matutils.vec2->set(vec2)
A:gensim.matutils.word_indices->sorted(set(chain(vec1, vec2)))
A:gensim.matutils.dense_matrix->similarity_matrix[[[i] for i in word_indices], word_indices].todense()
A:gensim.matutils.dense1->sparse2full(vec1, max_len)
A:gensim.matutils.dense2->sparse2full(vec2, max_len)
A:gensim.matutils.max_len->max(len(vec1), len(vec2))
A:gensim.matutils.(vec1, vec2)->convert_vec(vec1, vec2, num_features=num_features)
A:gensim.matutils.sim->numpy.sqrt(0.5 * ((np.sqrt(vec1) - np.sqrt(vec2)) ** 2).sum())
A:gensim.matutils.union_cardinality->len(set1 | set2)
A:gensim.matutils.x_max->numpy.max(x)
A:gensim.matutils.a->numpy.asfortranarray(la[0])
A:gensim.matutils.(geqrf,)->get_lapack_funcs(('geqrf',), (a,))
A:gensim.matutils.(qr, tau, work, info)->geqrf(a, lwork=work[0], overwrite_a=True)
A:gensim.matutils.r->triu(qr[:n, :n])
A:gensim.matutils.(gorgqr,)->get_lapack_funcs(('orgqr',), (qr,))
A:gensim.matutils.(q, work, info)->gorgqr(qr, tau, lwork=work[0], overwrite_a=True)
A:gensim.matutils.self.fout->gensim.utils.smart_open(self.fname, 'wb+')
A:gensim.matutils.vector->sorted(((i, w) for (i, w) in vector if abs(w) > 1e-12))
A:gensim.matutils.mw->MmWriter(fname)
A:gensim.matutils.posnow->MmWriter(fname).fout.tell()
A:gensim.matutils.(max_id, veclen)->MmWriter(fname).write_vector(docno, bow)
A:gensim.matutils._num_terms->max(_num_terms, 1 + max_id)
A:gensim.matutils.header->gensim.utils.to_unicode(next(lines)).strip()
A:gensim.matutils.line->gensim.utils.to_unicode(line)
A:gensim.matutils.(docid, termid, val)->gensim.utils.to_unicode(line).split()
gensim.matutils.Dense2Corpus(self,dense,documents_columns=True)
gensim.matutils.Dense2Corpus.__init__(self,dense,documents_columns=True)
gensim.matutils.Dense2Corpus.__iter__(self)
gensim.matutils.Dense2Corpus.__len__(self)
gensim.matutils.MmWriter(self,fname)
gensim.matutils.MmWriter.__del__(self)
gensim.matutils.MmWriter.__init__(self,fname)
gensim.matutils.MmWriter.close(self)
gensim.matutils.MmWriter.fake_headers(self,num_docs,num_terms,num_nnz)
gensim.matutils.MmWriter.write_corpus(fname,corpus,progress_cnt=1000,index=False,num_terms=None,metadata=False)
gensim.matutils.MmWriter.write_headers(self,num_docs,num_terms,num_nnz)
gensim.matutils.MmWriter.write_vector(self,docno,vector)
gensim.matutils.Scipy2Corpus(self,vecs)
gensim.matutils.Scipy2Corpus.__init__(self,vecs)
gensim.matutils.Scipy2Corpus.__iter__(self)
gensim.matutils.Scipy2Corpus.__len__(self)
gensim.matutils.Sparse2Corpus(self,sparse,documents_columns=True)
gensim.matutils.Sparse2Corpus.__getitem__(self,document_index)
gensim.matutils.Sparse2Corpus.__init__(self,sparse,documents_columns=True)
gensim.matutils.Sparse2Corpus.__iter__(self)
gensim.matutils.Sparse2Corpus.__len__(self)
gensim.matutils.any2sparse(vec,eps=1e-09)
gensim.matutils.argsort(x,topn=None,reverse=False)
gensim.matutils.blas(name,ndarray)
gensim.matutils.convert_vec(vec1,vec2,num_features=None)
gensim.matutils.corpus2csc(corpus,num_terms=None,dtype=np.float64,num_docs=None,num_nnz=None,printprogress=0)
gensim.matutils.corpus2dense(corpus,num_terms,num_docs=None,dtype=np.float32)
gensim.matutils.cossim(vec1,vec2)
gensim.matutils.full2sparse(vec,eps=1e-09)
gensim.matutils.full2sparse_clipped(vec,topn,eps=1e-09)
gensim.matutils.hellinger(vec1,vec2)
gensim.matutils.isbow(vec)
gensim.matutils.ismatrix(m)
gensim.matutils.jaccard(vec1,vec2)
gensim.matutils.jaccard_distance(set1,set2)
gensim.matutils.jensen_shannon(vec1,vec2,num_features=None)
gensim.matutils.kullback_leibler(vec1,vec2,num_features=None)
gensim.matutils.pad(mat,padrow,padcol)
gensim.matutils.qr_destroy(la)
gensim.matutils.ret_log_normalize_vec(vec,axis=1)
gensim.matutils.ret_normalized_vec(vec,length)
gensim.matutils.scipy2scipy_clipped(matrix,topn,eps=1e-09)
gensim.matutils.scipy2sparse(vec,eps=1e-09)
gensim.matutils.softcossim(vec1,vec2,similarity_matrix)
gensim.matutils.sparse2full(doc,length)
gensim.matutils.unitvec(vec,norm='l2')
gensim.matutils.veclen(vec)
gensim.matutils.zeros_aligned(shape,dtype,order='C',align=128)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/interfaces.py----------------------------------------
A:gensim.interfaces.logger->logging.getLogger(__name__)
A:gensim.interfaces.(is_corpus, query)->gensim.utils.is_corpus(query)
A:gensim.interfaces.query->gensim.matutils.unitvec(query)
A:gensim.interfaces.result->self.get_similarities(query)
A:gensim.interfaces.chunk_end->min(self.index.shape[0], chunk_start + self.chunksize)
gensim.interfaces.CorpusABC(utils.SaveLoad)
gensim.interfaces.CorpusABC.__iter__(self)
gensim.interfaces.CorpusABC.__len__(self)
gensim.interfaces.CorpusABC.save(self,*args,**kwargs)
gensim.interfaces.CorpusABC.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.interfaces.SimilarityABC(self,corpus)
gensim.interfaces.SimilarityABC.__getitem__(self,query)
gensim.interfaces.SimilarityABC.__init__(self,corpus)
gensim.interfaces.SimilarityABC.__iter__(self)
gensim.interfaces.SimilarityABC.get_similarities(self,doc)
gensim.interfaces.TransformationABC(utils.SaveLoad)
gensim.interfaces.TransformationABC.__getitem__(self,vec)
gensim.interfaces.TransformationABC._apply(self,corpus,chunksize=None,**kwargs)
gensim.interfaces.TransformedCorpus(self,obj,corpus,chunksize=None,**kwargs)
gensim.interfaces.TransformedCorpus.__getitem__(self,docno)
gensim.interfaces.TransformedCorpus.__init__(self,obj,corpus,chunksize=None,**kwargs)
gensim.interfaces.TransformedCorpus.__iter__(self)
gensim.interfaces.TransformedCorpus.__len__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/__init__.py----------------------------------------
A:gensim.__init__.logger->logging.getLogger('gensim')
gensim.__init__.NullHandler(logging.Handler)
gensim.__init__.NullHandler.emit(self,record)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/nosy.py----------------------------------------
A:gensim.nosy.stats->os.stat(os.path.join(root, f))
A:gensim.nosy.val->check_sum()
gensim.nosy.check_sum()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/viz/poincare.py----------------------------------------
A:gensim.viz.poincare.logger->logging.getLogger(__name__)
A:gensim.viz.poincare.nodes_x->list(vectors[:, 0])
A:gensim.viz.poincare.nodes_y->list(vectors[:, 1])
A:gensim.viz.poincare.nodes->plotly.graph_objs.Scatter(x=nodes_x, y=nodes_y, mode='markers', marker=dict(color='rgb(30, 100, 200)'), text=node_labels, textposition='bottom')
A:gensim.viz.poincare.nodes_with_labels->plotly.graph_objs.Scatter(x=nodes_x, y=nodes_y, mode='markers+text', marker=dict(color='rgb(200, 100, 200)'), text=node_labels, textposition='bottom')
A:gensim.viz.poincare.node_out_degrees->Counter((hypernym_pair[1] for hypernym_pair in tree))
A:gensim.viz.poincare.chosen_nodes->list(node_out_degrees.keys())
A:gensim.viz.poincare.edges->plotly.graph_objs.Scatter(x=edges_x, y=edges_y, mode='line', hoverinfo=False, line=dict(color='rgb(50,50,50)', width=1))
A:gensim.viz.poincare.layout->plotly.graph_objs.Layout(width=900, height=800, showlegend=False, title='Poincare Distances from (%.2f, %.2f)' % (origin_point[0], origin_point[1]), hovermode='closest')
A:gensim.viz.poincare.x_axis_values->numpy.linspace(x_range[0], x_range[1], num=num_points)
A:gensim.viz.poincare.y_axis_values->numpy.linspace(x_range[0], x_range[1], num=num_points)
A:gensim.viz.poincare.(x, y)->numpy.meshgrid(x_axis_values, y_axis_values)
A:gensim.viz.poincare.norms->numpy.linalg.norm(all_points, axis=1)
A:gensim.viz.poincare.origin_point->numpy.array(origin_point)
A:gensim.viz.poincare.all_distances->gensim.models.poincare.PoincareKeyedVectors.poincare_dists(origin_point, all_points)
A:gensim.viz.poincare.distances->plotly.graph_objs.Scatter(x=all_points[:, 0], y=all_points[:, 1], mode='markers', marker=dict(size='9', color=all_distances, colorscale='Viridis', showscale=True, colorbar=go.ColorBar(title='Poincare Distance')), text=['Distance from (%.2f, %.2f): %.2f' % (origin_point[0], origin_point[1], d) for d in all_distances], name='')
A:gensim.viz.poincare.origin->plotly.graph_objs.Scatter(x=[origin_point[0]], y=[origin_point[1]], name='Distance from (%.2f, %.2f)' % (origin_point[0], origin_point[1]), mode='markers+text', marker=dict(size='10', color='rgb(200, 50, 50)'))
gensim.viz.poincare.poincare_2d_visualization(model,tree,figure_title,num_nodes=50,show_node_labels=())
gensim.viz.poincare.poincare_distance_heatmap(origin_point,x_range=(-1.0,1.0),y_range=(-1.0,1.0),num_points=100)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/viz/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/word2vec_standalone.py----------------------------------------
A:gensim.scripts.word2vec_standalone.logger->logging.getLogger(__name__)
A:gensim.scripts.word2vec_standalone.parser->argparse.ArgumentParser()
A:gensim.scripts.word2vec_standalone.args->argparse.ArgumentParser().parse_args()
A:gensim.scripts.word2vec_standalone.corpus->LineSentence(args.train)
A:gensim.scripts.word2vec_standalone.model->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, alpha=args.alpha, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/word2vec2tensor.py----------------------------------------
A:gensim.scripts.word2vec2tensor.logger->logging.getLogger(__name__)
A:gensim.scripts.word2vec2tensor.model->gensim.models.KeyedVectors.load_word2vec_format(word2vec_model_path, binary=binary)
A:gensim.scripts.word2vec2tensor.vector_row->'\t'.join((str(x) for x in model[word]))
A:gensim.scripts.word2vec2tensor.parser->argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=__doc__[:-138])
A:gensim.scripts.word2vec2tensor.args->argparse.ArgumentParser(formatter_class=argparse.RawDescriptionHelpFormatter, description=__doc__[:-138]).parse_args()
gensim.scripts.word2vec2tensor.word2vec2tensor(word2vec_model_path,tensor_filename,binary=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/make_wiki_online_nodebug.py----------------------------------------
A:gensim.scripts.make_wiki_online_nodebug.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki_online_nodebug.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki_online_nodebug.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki_online_nodebug.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki_online_nodebug.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki_online_nodebug.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki_online_nodebug.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/make_wiki.py----------------------------------------
A:gensim.scripts.make_wiki.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/make_wiki_online.py----------------------------------------
A:gensim.scripts.make_wiki_online.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki_online.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki_online.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki_online.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki_online.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki_online.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki_online.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/make_wiki_lemma.py----------------------------------------
A:gensim.scripts.make_wiki_lemma.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki_lemma.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki_lemma.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki_lemma.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki_lemma.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki_lemma.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki_lemma.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/make_wikicorpus.py----------------------------------------
A:gensim.scripts.make_wikicorpus.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wikicorpus.logger->logging.getLogger(program)
A:gensim.scripts.make_wikicorpus.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wikicorpus.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wikicorpus.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wikicorpus.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wikicorpus.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/glove2word2vec.py----------------------------------------
A:gensim.scripts.glove2word2vec.logger->logging.getLogger(__name__)
A:gensim.scripts.glove2word2vec.num_lines->sum((1 for _ in f))
A:gensim.scripts.glove2word2vec.(num_lines, num_dims)->glove2word2vec(args.input, args.output)
A:gensim.scripts.glove2word2vec.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawDescriptionHelpFormatter)
A:gensim.scripts.glove2word2vec.args->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawDescriptionHelpFormatter).parse_args()
gensim.scripts.glove2word2vec.get_glove_info(glove_file_name)
gensim.scripts.glove2word2vec.glove2word2vec(glove_input_file,word2vec_output_file)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/segment_wiki.py----------------------------------------
A:gensim.scripts.segment_wiki.logger->logging.getLogger(__name__)
A:gensim.scripts.segment_wiki.wiki_sections_corpus->_WikiSectionsCorpus(xml_fileobj, min_article_character=min_article_character, processes=workers, include_interlinks=include_interlinks)
A:gensim.scripts.segment_wiki.wiki_sections_text->_WikiSectionsCorpus(xml_fileobj, min_article_character=min_article_character, processes=workers, include_interlinks=include_interlinks).get_texts_with_sections()
A:gensim.scripts.segment_wiki.outfile->smart_open(output_file, 'wb')
A:gensim.scripts.segment_wiki.article_stream->segment_all_articles(file_path, min_article_character, workers=workers, include_interlinks=include_interlinks)
A:gensim.scripts.segment_wiki.elem->xml.etree.cElementTree.fromstring(page_xml)
A:gensim.scripts.segment_wiki.namespace->get_namespace(elem.tag)
A:gensim.scripts.segment_wiki.interlinks->find_interlinks(text)
A:gensim.scripts.segment_wiki.section_contents->re.split(top_level_heading_regex, text)
A:gensim.scripts.segment_wiki.sections->list(zip(section_headings, section_contents))
A:gensim.scripts.segment_wiki.processes->max(1, multiprocessing.cpu_count() - 1)
A:gensim.scripts.segment_wiki.page_xmls->extract_page_xmls(self.fileobj)
A:gensim.scripts.segment_wiki.pool->multiprocessing.Pool(self.processes)
A:gensim.scripts.segment_wiki.parser->argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description=__doc__[:-136])
A:gensim.scripts.segment_wiki.default_workers->max(1, multiprocessing.cpu_count() - 1)
A:gensim.scripts.segment_wiki.args->argparse.ArgumentParser(formatter_class=argparse.RawTextHelpFormatter, description=__doc__[:-136]).parse_args()
gensim.scripts.segment_wiki._WikiSectionsCorpus(self,fileobj,min_article_character=200,processes=None,lemmatize=utils.has_pattern(),filter_namespaces=('0',),include_interlinks=False)
gensim.scripts.segment_wiki._WikiSectionsCorpus.__init__(self,fileobj,min_article_character=200,processes=None,lemmatize=utils.has_pattern(),filter_namespaces=('0',),include_interlinks=False)
gensim.scripts.segment_wiki._WikiSectionsCorpus.get_texts_with_sections(self)
gensim.scripts.segment_wiki.extract_page_xmls(f)
gensim.scripts.segment_wiki.segment(page_xml,include_interlinks=False)
gensim.scripts.segment_wiki.segment_all_articles(file_path,min_article_character=200,workers=None,include_interlinks=False)
gensim.scripts.segment_wiki.segment_and_write_all_articles(file_path,output_file,min_article_character=200,workers=None,include_interlinks=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/make_wiki_online_lemma.py----------------------------------------
A:gensim.scripts.make_wiki_online_lemma.program->os.path.basename(sys.argv[0])
A:gensim.scripts.make_wiki_online_lemma.logger->logging.getLogger(program)
A:gensim.scripts.make_wiki_online_lemma.keep_words->int(sys.argv[3])
A:gensim.scripts.make_wiki_online_lemma.dictionary->gensim.corpora.Dictionary.load_from_text(outp + '_wordids.txt.bz2')
A:gensim.scripts.make_wiki_online_lemma.wiki->WikiCorpus(inp, lemmatize=lemmatize)
A:gensim.scripts.make_wiki_online_lemma.mm->MmCorpus(outp + '_bow.mm')
A:gensim.scripts.make_wiki_online_lemma.tfidf->TfidfModel(mm, id2word=dictionary, normalize=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/scripts/package_info.py----------------------------------------
A:gensim.scripts.package_info.parser->argparse.ArgumentParser(description=__doc__[:-65], formatter_class=argparse.RawDescriptionHelpFormatter)
A:gensim.scripts.package_info.args->argparse.ArgumentParser(description=__doc__[:-65], formatter_class=argparse.RawDescriptionHelpFormatter).parse_args()
gensim.scripts.package_info.package_info()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/hdp.py----------------------------------------
A:gensim.sklearn_api.hdp.corpus->gensim.matutils.Sparse2Corpus(sparse=X, documents_columns=False)
A:gensim.sklearn_api.hdp.self.gensim_model->gensim.models.HdpModel(id2word=self.id2word, max_chunks=self.max_chunks, max_time=self.max_time, chunksize=self.chunksize, kappa=self.kappa, tau=self.tau, K=self.K, T=self.T, alpha=self.alpha, gamma=self.gamma, eta=self.eta, scale=self.scale, var_converge=self.var_converge, outputdir=self.outputdir, random_state=self.random_state)
A:gensim.sklearn_api.hdp.max_num_topics->max(max_num_topics, max((topic[0] for topic in topicd)) + 1)
A:gensim.sklearn_api.hdp.X->gensim.matutils.Sparse2Corpus(sparse=X, documents_columns=False)
gensim.sklearn_api.HdpTransformer(self,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.sklearn_api.HdpTransformer.fit(self,X,y=None)
gensim.sklearn_api.HdpTransformer.partial_fit(self,X)
gensim.sklearn_api.HdpTransformer.transform(self,docs)
gensim.sklearn_api.hdp.HdpTransformer(self,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.sklearn_api.hdp.HdpTransformer.__init__(self,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.sklearn_api.hdp.HdpTransformer.fit(self,X,y=None)
gensim.sklearn_api.hdp.HdpTransformer.partial_fit(self,X)
gensim.sklearn_api.hdp.HdpTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/ldamodel.py----------------------------------------
A:gensim.sklearn_api.ldamodel.corpus->gensim.matutils.Sparse2Corpus(sparse=X, documents_columns=False)
A:gensim.sklearn_api.ldamodel.self.gensim_model->gensim.models.LdaModel(num_topics=self.num_topics, id2word=self.id2word, chunksize=self.chunksize, passes=self.passes, update_every=self.update_every, alpha=self.alpha, eta=self.eta, decay=self.decay, offset=self.offset, eval_every=self.eval_every, iterations=self.iterations, gamma_threshold=self.gamma_threshold, minimum_probability=self.minimum_probability, random_state=self.random_state, dtype=self.dtype)
A:gensim.sklearn_api.ldamodel.X->gensim.matutils.Sparse2Corpus(sparse=X, documents_columns=False)
A:gensim.sklearn_api.ldamodel.corpus_words->sum((cnt for document in X for (_, cnt) in document))
A:gensim.sklearn_api.ldamodel.goodcm->gensim.models.CoherenceModel(model=self.gensim_model, corpus=X, coherence=self.scorer, topn=3)
gensim.sklearn_api.LdaTransformer(self,num_topics=100,id2word=None,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,scorer='perplexity',dtype=np.float32)
gensim.sklearn_api.LdaTransformer.fit(self,X,y=None)
gensim.sklearn_api.LdaTransformer.partial_fit(self,X)
gensim.sklearn_api.LdaTransformer.score(self,X,y=None)
gensim.sklearn_api.LdaTransformer.transform(self,docs)
gensim.sklearn_api.ldamodel.LdaTransformer(self,num_topics=100,id2word=None,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,scorer='perplexity',dtype=np.float32)
gensim.sklearn_api.ldamodel.LdaTransformer.__init__(self,num_topics=100,id2word=None,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,scorer='perplexity',dtype=np.float32)
gensim.sklearn_api.ldamodel.LdaTransformer.fit(self,X,y=None)
gensim.sklearn_api.ldamodel.LdaTransformer.partial_fit(self,X)
gensim.sklearn_api.ldamodel.LdaTransformer.score(self,X,y=None)
gensim.sklearn_api.ldamodel.LdaTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/d2vmodel.py----------------------------------------
A:gensim.sklearn_api.d2vmodel.self.cbow_mean->int(cbow_mean)
A:gensim.sklearn_api.d2vmodel.self.gensim_model->gensim.models.Doc2Vec(documents=d2v_sentences, dm_mean=self.dm_mean, dm=self.dm, dbow_words=self.dbow_words, dm_concat=self.dm_concat, dm_tag_count=self.dm_tag_count, docvecs=self.docvecs, docvecs_mapfile=self.docvecs_mapfile, comment=self.comment, trim_rule=self.trim_rule, size=self.size, alpha=self.alpha, window=self.window, min_count=self.min_count, max_vocab_size=self.max_vocab_size, sample=self.sample, seed=self.seed, workers=self.workers, min_alpha=self.min_alpha, hs=self.hs, negative=self.negative, cbow_mean=self.cbow_mean, hashfxn=self.hashfxn, iter=self.iter, sorted_vocab=self.sorted_vocab, batch_words=self.batch_words)
gensim.sklearn_api.D2VTransformer(self,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,sorted_vocab=1,batch_words=10000)
gensim.sklearn_api.D2VTransformer.fit(self,X,y=None)
gensim.sklearn_api.D2VTransformer.transform(self,docs)
gensim.sklearn_api.d2vmodel.D2VTransformer(self,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,sorted_vocab=1,batch_words=10000)
gensim.sklearn_api.d2vmodel.D2VTransformer.__init__(self,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,sorted_vocab=1,batch_words=10000)
gensim.sklearn_api.d2vmodel.D2VTransformer.fit(self,X,y=None)
gensim.sklearn_api.d2vmodel.D2VTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/w2vmodel.py----------------------------------------
A:gensim.sklearn_api.w2vmodel.self.cbow_mean->int(cbow_mean)
A:gensim.sklearn_api.w2vmodel.self.gensim_model->gensim.models.Word2Vec(sentences=X, size=self.size, alpha=self.alpha, window=self.window, min_count=self.min_count, max_vocab_size=self.max_vocab_size, sample=self.sample, seed=self.seed, workers=self.workers, min_alpha=self.min_alpha, sg=self.sg, hs=self.hs, negative=self.negative, cbow_mean=self.cbow_mean, hashfxn=self.hashfxn, iter=self.iter, null_word=self.null_word, trim_rule=self.trim_rule, sorted_vocab=self.sorted_vocab, batch_words=self.batch_words)
gensim.sklearn_api.W2VTransformer(self,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=10000)
gensim.sklearn_api.W2VTransformer.fit(self,X,y=None)
gensim.sklearn_api.W2VTransformer.partial_fit(self,X)
gensim.sklearn_api.W2VTransformer.transform(self,words)
gensim.sklearn_api.w2vmodel.W2VTransformer(self,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=10000)
gensim.sklearn_api.w2vmodel.W2VTransformer.__init__(self,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=10000)
gensim.sklearn_api.w2vmodel.W2VTransformer.fit(self,X,y=None)
gensim.sklearn_api.w2vmodel.W2VTransformer.partial_fit(self,X)
gensim.sklearn_api.w2vmodel.W2VTransformer.transform(self,words)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/text2bow.py----------------------------------------
A:gensim.sklearn_api.text2bow.self.gensim_model->Dictionary(prune_at=self.prune_at)
gensim.sklearn_api.Text2BowTransformer(self,prune_at=2000000,tokenizer=tokenize)
gensim.sklearn_api.Text2BowTransformer.fit(self,X,y=None)
gensim.sklearn_api.Text2BowTransformer.partial_fit(self,X)
gensim.sklearn_api.Text2BowTransformer.transform(self,docs)
gensim.sklearn_api.text2bow.Text2BowTransformer(self,prune_at=2000000,tokenizer=tokenize)
gensim.sklearn_api.text2bow.Text2BowTransformer.__init__(self,prune_at=2000000,tokenizer=tokenize)
gensim.sklearn_api.text2bow.Text2BowTransformer.fit(self,X,y=None)
gensim.sklearn_api.text2bow.Text2BowTransformer.partial_fit(self,X)
gensim.sklearn_api.text2bow.Text2BowTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/atmodel.py----------------------------------------
A:gensim.sklearn_api.atmodel.self.gensim_model->gensim.models.AuthorTopicModel(corpus=X, num_topics=self.num_topics, id2word=self.id2word, author2doc=self.author2doc, doc2author=self.doc2author, chunksize=self.chunksize, passes=self.passes, iterations=self.iterations, decay=self.decay, offset=self.offset, alpha=self.alpha, eta=self.eta, update_every=self.update_every, eval_every=self.eval_every, gamma_threshold=self.gamma_threshold, serialized=self.serialized, serialization_path=self.serialization_path, minimum_probability=self.minimum_probability, random_state=self.random_state)
gensim.sklearn_api.AuthorTopicTransformer(self,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.sklearn_api.AuthorTopicTransformer.fit(self,X,y=None)
gensim.sklearn_api.AuthorTopicTransformer.partial_fit(self,X,author2doc=None,doc2author=None)
gensim.sklearn_api.AuthorTopicTransformer.transform(self,author_names)
gensim.sklearn_api.atmodel.AuthorTopicTransformer(self,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.sklearn_api.atmodel.AuthorTopicTransformer.__init__(self,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.sklearn_api.atmodel.AuthorTopicTransformer.fit(self,X,y=None)
gensim.sklearn_api.atmodel.AuthorTopicTransformer.partial_fit(self,X,author2doc=None,doc2author=None)
gensim.sklearn_api.atmodel.AuthorTopicTransformer.transform(self,author_names)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/phrases.py----------------------------------------
A:gensim.sklearn_api.phrases.self.gensim_model->gensim.models.Phrases(sentences=X, min_count=self.min_count, threshold=self.threshold, max_vocab_size=self.max_vocab_size, delimiter=self.delimiter, progress_per=self.progress_per, scoring=self.scoring)
gensim.sklearn_api.PhrasesTransformer(self,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter=b'_',progress_per=10000,scoring='default')
gensim.sklearn_api.PhrasesTransformer.fit(self,X,y=None)
gensim.sklearn_api.PhrasesTransformer.partial_fit(self,X)
gensim.sklearn_api.PhrasesTransformer.transform(self,docs)
gensim.sklearn_api.phrases.PhrasesTransformer(self,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter=b'_',progress_per=10000,scoring='default')
gensim.sklearn_api.phrases.PhrasesTransformer.__init__(self,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter=b'_',progress_per=10000,scoring='default')
gensim.sklearn_api.phrases.PhrasesTransformer.fit(self,X,y=None)
gensim.sklearn_api.phrases.PhrasesTransformer.partial_fit(self,X)
gensim.sklearn_api.phrases.PhrasesTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/lsimodel.py----------------------------------------
A:gensim.sklearn_api.lsimodel.corpus->gensim.matutils.Sparse2Corpus(sparse=X, documents_columns=False)
A:gensim.sklearn_api.lsimodel.self.gensim_model->gensim.models.LsiModel(num_topics=self.num_topics, id2word=self.id2word, chunksize=self.chunksize, decay=self.decay, onepass=self.onepass, power_iters=self.power_iters, extra_samples=self.extra_samples)
A:gensim.sklearn_api.lsimodel.X->gensim.matutils.Sparse2Corpus(sparse=X, documents_columns=False)
gensim.sklearn_api.LsiTransformer(self,num_topics=200,id2word=None,chunksize=20000,decay=1.0,onepass=True,power_iters=2,extra_samples=100)
gensim.sklearn_api.LsiTransformer.fit(self,X,y=None)
gensim.sklearn_api.LsiTransformer.partial_fit(self,X)
gensim.sklearn_api.LsiTransformer.transform(self,docs)
gensim.sklearn_api.lsimodel.LsiTransformer(self,num_topics=200,id2word=None,chunksize=20000,decay=1.0,onepass=True,power_iters=2,extra_samples=100)
gensim.sklearn_api.lsimodel.LsiTransformer.__init__(self,num_topics=200,id2word=None,chunksize=20000,decay=1.0,onepass=True,power_iters=2,extra_samples=100)
gensim.sklearn_api.lsimodel.LsiTransformer.fit(self,X,y=None)
gensim.sklearn_api.lsimodel.LsiTransformer.partial_fit(self,X)
gensim.sklearn_api.lsimodel.LsiTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/ldaseqmodel.py----------------------------------------
A:gensim.sklearn_api.ldaseqmodel.self.gensim_model->gensim.models.LdaSeqModel(corpus=X, time_slice=self.time_slice, id2word=self.id2word, alphas=self.alphas, num_topics=self.num_topics, initialize=self.initialize, sstats=self.sstats, lda_model=self.lda_model, obs_variance=self.obs_variance, chain_variance=self.chain_variance, passes=self.passes, random_state=self.random_state, lda_inference_max_iter=self.lda_inference_max_iter, em_min_iter=self.em_min_iter, em_max_iter=self.em_max_iter, chunksize=self.chunksize)
gensim.sklearn_api.LdaSeqTransformer(self,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.sklearn_api.LdaSeqTransformer.fit(self,X,y=None)
gensim.sklearn_api.LdaSeqTransformer.transform(self,docs)
gensim.sklearn_api.ldaseqmodel.LdaSeqTransformer(self,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.sklearn_api.ldaseqmodel.LdaSeqTransformer.__init__(self,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.sklearn_api.ldaseqmodel.LdaSeqTransformer.fit(self,X,y=None)
gensim.sklearn_api.ldaseqmodel.LdaSeqTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/tfidf.py----------------------------------------
A:gensim.sklearn_api.tfidf.self.gensim_model->TfidfModel(corpus=X, id2word=self.id2word, dictionary=self.dictionary, wlocal=self.wlocal, wglobal=self.wglobal, normalize=self.normalize, smartirs=self.smartirs)
gensim.sklearn_api.TfIdfTransformer(self,id2word=None,dictionary=None,wlocal=gensim.utils.identity,wglobal=gensim.models.tfidfmodel.df2idf,normalize=True,smartirs='ntc')
gensim.sklearn_api.TfIdfTransformer.fit(self,X,y=None)
gensim.sklearn_api.TfIdfTransformer.transform(self,docs)
gensim.sklearn_api.tfidf.TfIdfTransformer(self,id2word=None,dictionary=None,wlocal=gensim.utils.identity,wglobal=gensim.models.tfidfmodel.df2idf,normalize=True,smartirs='ntc')
gensim.sklearn_api.tfidf.TfIdfTransformer.__init__(self,id2word=None,dictionary=None,wlocal=gensim.utils.identity,wglobal=gensim.models.tfidfmodel.df2idf,normalize=True,smartirs='ntc')
gensim.sklearn_api.tfidf.TfIdfTransformer.fit(self,X,y=None)
gensim.sklearn_api.tfidf.TfIdfTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/rpmodel.py----------------------------------------
A:gensim.sklearn_api.rpmodel.self.gensim_model->gensim.models.RpModel(corpus=X, id2word=self.id2word, num_topics=self.num_topics)
gensim.sklearn_api.RpTransformer(self,id2word=None,num_topics=300)
gensim.sklearn_api.RpTransformer.fit(self,X,y=None)
gensim.sklearn_api.RpTransformer.transform(self,docs)
gensim.sklearn_api.rpmodel.RpTransformer(self,id2word=None,num_topics=300)
gensim.sklearn_api.rpmodel.RpTransformer.__init__(self,id2word=None,num_topics=300)
gensim.sklearn_api.rpmodel.RpTransformer.fit(self,X,y=None)
gensim.sklearn_api.rpmodel.RpTransformer.transform(self,docs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/sklearn_api/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/malletcorpus.py----------------------------------------
A:gensim.corpora.malletcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.malletcorpus.result->sum((1 for _ in fin))
A:gensim.corpora.malletcorpus.doc->super(MalletCorpus, self).line2doc(' '.join(words))
A:gensim.corpora.malletcorpus.id2word->gensim.utils.dict_from_corpus(corpus)
gensim.corpora.MalletCorpus(self,fname,id2word=None,metadata=False)
gensim.corpora.MalletCorpus.__iter__(self)
gensim.corpora.MalletCorpus._calculate_num_docs(self)
gensim.corpora.MalletCorpus.docbyoffset(self,offset)
gensim.corpora.MalletCorpus.line2doc(self,line)
gensim.corpora.MalletCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.malletcorpus.MalletCorpus(self,fname,id2word=None,metadata=False)
gensim.corpora.malletcorpus.MalletCorpus.__init__(self,fname,id2word=None,metadata=False)
gensim.corpora.malletcorpus.MalletCorpus.__iter__(self)
gensim.corpora.malletcorpus.MalletCorpus._calculate_num_docs(self)
gensim.corpora.malletcorpus.MalletCorpus.docbyoffset(self,offset)
gensim.corpora.malletcorpus.MalletCorpus.line2doc(self,line)
gensim.corpora.malletcorpus.MalletCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/svmlightcorpus.py----------------------------------------
A:gensim.corpora.svmlightcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.svmlightcorpus.doc->self.line2doc(line)
A:gensim.corpora.svmlightcorpus.line->line[:line.find('#')].strip()
A:gensim.corpora.svmlightcorpus.parts->line[:line.find('#')].strip().split()
A:gensim.corpora.svmlightcorpus.pairs->' '.join(('%i:%s' % (termid + 1, termval) for (termid, termval) in doc))
gensim.corpora.SvmLightCorpus(self,fname,store_labels=True)
gensim.corpora.SvmLightCorpus.__iter__(self)
gensim.corpora.SvmLightCorpus.doc2line(doc,label=0)
gensim.corpora.SvmLightCorpus.docbyoffset(self,offset)
gensim.corpora.SvmLightCorpus.line2doc(self,line)
gensim.corpora.SvmLightCorpus.save_corpus(fname,corpus,id2word=None,labels=False,metadata=False)
gensim.corpora.svmlightcorpus.SvmLightCorpus(self,fname,store_labels=True)
gensim.corpora.svmlightcorpus.SvmLightCorpus.__init__(self,fname,store_labels=True)
gensim.corpora.svmlightcorpus.SvmLightCorpus.__iter__(self)
gensim.corpora.svmlightcorpus.SvmLightCorpus.doc2line(doc,label=0)
gensim.corpora.svmlightcorpus.SvmLightCorpus.docbyoffset(self,offset)
gensim.corpora.svmlightcorpus.SvmLightCorpus.line2doc(self,line)
gensim.corpora.svmlightcorpus.SvmLightCorpus.save_corpus(fname,corpus,id2word=None,labels=False,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/textcorpus.py----------------------------------------
A:gensim.corpora.textcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.textcorpus.text->character_filter(text)
A:gensim.corpora.textcorpus.tokens->self.tokenizer(text)
A:gensim.corpora.textcorpus.lines->self.getstream()
A:gensim.corpora.textcorpus.length->len(self)
A:gensim.corpora.textcorpus.chance->random_generator.randint(1, remaining_in_corpus)
A:gensim.corpora.textcorpus.self.length->sum((1 for _ in self.getstream()))
A:gensim.corpora.textcorpus.names->os.listdir(top)
A:gensim.corpora.textcorpus.new_path->join(top, name)
gensim.corpora.TextCorpus(self,input=None,dictionary=None,metadata=False,character_filters=None,tokenizer=None,token_filters=None)
gensim.corpora.TextCorpus.__iter__(self)
gensim.corpora.TextCorpus.__len__(self)
gensim.corpora.TextCorpus.get_texts(self)
gensim.corpora.TextCorpus.getstream(self)
gensim.corpora.TextCorpus.init_dictionary(self,dictionary)
gensim.corpora.TextCorpus.preprocess_text(self,text)
gensim.corpora.TextCorpus.sample_texts(self,n,seed=None,length=None)
gensim.corpora.TextCorpus.step_through_preprocess(self,text)
gensim.corpora.TextDirectoryCorpus(self,input,dictionary=None,metadata=False,min_depth=0,max_depth=None,pattern=None,exclude_pattern=None,lines_are_documents=False,**kwargs)
gensim.corpora.TextDirectoryCorpus.__len__(self)
gensim.corpora.TextDirectoryCorpus._cache_corpus_length(self)
gensim.corpora.TextDirectoryCorpus.exclude_pattern(self)
gensim.corpora.TextDirectoryCorpus.exclude_pattern(self,pattern)
gensim.corpora.TextDirectoryCorpus.getstream(self)
gensim.corpora.TextDirectoryCorpus.iter_filepaths(self)
gensim.corpora.TextDirectoryCorpus.lines_are_documents(self)
gensim.corpora.TextDirectoryCorpus.lines_are_documents(self,lines_are_documents)
gensim.corpora.TextDirectoryCorpus.max_depth(self)
gensim.corpora.TextDirectoryCorpus.max_depth(self,max_depth)
gensim.corpora.TextDirectoryCorpus.min_depth(self)
gensim.corpora.TextDirectoryCorpus.min_depth(self,min_depth)
gensim.corpora.TextDirectoryCorpus.pattern(self)
gensim.corpora.TextDirectoryCorpus.pattern(self,pattern)
gensim.corpora.textcorpus.TextCorpus(self,input=None,dictionary=None,metadata=False,character_filters=None,tokenizer=None,token_filters=None)
gensim.corpora.textcorpus.TextCorpus.__init__(self,input=None,dictionary=None,metadata=False,character_filters=None,tokenizer=None,token_filters=None)
gensim.corpora.textcorpus.TextCorpus.__iter__(self)
gensim.corpora.textcorpus.TextCorpus.__len__(self)
gensim.corpora.textcorpus.TextCorpus.get_texts(self)
gensim.corpora.textcorpus.TextCorpus.getstream(self)
gensim.corpora.textcorpus.TextCorpus.init_dictionary(self,dictionary)
gensim.corpora.textcorpus.TextCorpus.preprocess_text(self,text)
gensim.corpora.textcorpus.TextCorpus.sample_texts(self,n,seed=None,length=None)
gensim.corpora.textcorpus.TextCorpus.step_through_preprocess(self,text)
gensim.corpora.textcorpus.TextDirectoryCorpus(self,input,dictionary=None,metadata=False,min_depth=0,max_depth=None,pattern=None,exclude_pattern=None,lines_are_documents=False,**kwargs)
gensim.corpora.textcorpus.TextDirectoryCorpus.__init__(self,input,dictionary=None,metadata=False,min_depth=0,max_depth=None,pattern=None,exclude_pattern=None,lines_are_documents=False,**kwargs)
gensim.corpora.textcorpus.TextDirectoryCorpus.__len__(self)
gensim.corpora.textcorpus.TextDirectoryCorpus._cache_corpus_length(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.exclude_pattern(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.exclude_pattern(self,pattern)
gensim.corpora.textcorpus.TextDirectoryCorpus.getstream(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.iter_filepaths(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.lines_are_documents(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.lines_are_documents(self,lines_are_documents)
gensim.corpora.textcorpus.TextDirectoryCorpus.max_depth(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.max_depth(self,max_depth)
gensim.corpora.textcorpus.TextDirectoryCorpus.min_depth(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.min_depth(self,min_depth)
gensim.corpora.textcorpus.TextDirectoryCorpus.pattern(self)
gensim.corpora.textcorpus.TextDirectoryCorpus.pattern(self,pattern)
gensim.corpora.textcorpus.lower_to_unicode(text,encoding='utf8',errors='strict')
gensim.corpora.textcorpus.remove_short(tokens,minsize=3)
gensim.corpora.textcorpus.remove_stopwords(tokens,stopwords=STOPWORDS)
gensim.corpora.textcorpus.strip_multiple_whitespaces(s)
gensim.corpora.textcorpus.walk(top,topdown=True,onerror=None,followlinks=False,depth=0)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/hashdictionary.py----------------------------------------
A:gensim.corpora.hashdictionary.logger->logging.getLogger(__name__)
A:gensim.corpora.hashdictionary.document->sorted(document)
A:gensim.corpora.hashdictionary.frequency->len(list(group))
A:gensim.corpora.hashdictionary.tokenid->self.restricted_hash(word_norm)
A:gensim.corpora.hashdictionary.result->sorted(iteritems(result))
A:gensim.corpora.hashdictionary.no_above_abs->int(no_above * self.num_docs)
A:gensim.corpora.hashdictionary.ok->frozenset((word for (word, freq) in sorted(ok, key=lambda x: -x[1])[:keep_n]))
A:gensim.corpora.hashdictionary.words->sorted(self[tokenid])
A:gensim.corpora.hashdictionary.words_df->'\t'.join(words_df)
gensim.corpora.HashDictionary(self,documents=None,id_range=32000,myhash=zlib.adler32,debug=True)
gensim.corpora.HashDictionary.__getitem__(self,tokenid)
gensim.corpora.HashDictionary.__len__(self)
gensim.corpora.HashDictionary.__str__(self)
gensim.corpora.HashDictionary.add_documents(self,documents)
gensim.corpora.HashDictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.HashDictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000)
gensim.corpora.HashDictionary.from_documents(*args,**kwargs)
gensim.corpora.HashDictionary.keys(self)
gensim.corpora.HashDictionary.restricted_hash(self,token)
gensim.corpora.HashDictionary.save_as_text(self,fname)
gensim.corpora.hashdictionary.HashDictionary(self,documents=None,id_range=32000,myhash=zlib.adler32,debug=True)
gensim.corpora.hashdictionary.HashDictionary.__getitem__(self,tokenid)
gensim.corpora.hashdictionary.HashDictionary.__init__(self,documents=None,id_range=32000,myhash=zlib.adler32,debug=True)
gensim.corpora.hashdictionary.HashDictionary.__len__(self)
gensim.corpora.hashdictionary.HashDictionary.__str__(self)
gensim.corpora.hashdictionary.HashDictionary.add_documents(self,documents)
gensim.corpora.hashdictionary.HashDictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.hashdictionary.HashDictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000)
gensim.corpora.hashdictionary.HashDictionary.from_documents(*args,**kwargs)
gensim.corpora.hashdictionary.HashDictionary.keys(self)
gensim.corpora.hashdictionary.HashDictionary.restricted_hash(self,token)
gensim.corpora.hashdictionary.HashDictionary.save_as_text(self,fname)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/lowcorpus.py----------------------------------------
A:gensim.corpora.lowcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.lowcorpus.self.num_docs->self._calculate_num_docs()
A:gensim.corpora.lowcorpus.all_terms->sorted(all_terms)
A:gensim.corpora.lowcorpus.self.id2word->dict(izip(xrange(len(all_terms)), all_terms))
A:gensim.corpora.lowcorpus.self.num_terms->len(self.word2id)
A:gensim.corpora.lowcorpus.result->int(next(fin))
A:gensim.corpora.lowcorpus.words->self.line2words(line)
A:gensim.corpora.lowcorpus.uniq_words->set(words)
A:gensim.corpora.lowcorpus.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.corpora.lowcorpus.self.word2id->gensim.utils.revdict(val)
gensim.corpora.LowCorpus(self,fname,id2word=None,line2words=split_on_space)
gensim.corpora.LowCorpus.__iter__(self)
gensim.corpora.LowCorpus.__len__(self)
gensim.corpora.LowCorpus._calculate_num_docs(self)
gensim.corpora.LowCorpus.docbyoffset(self,offset)
gensim.corpora.LowCorpus.id2word(self)
gensim.corpora.LowCorpus.id2word(self,val)
gensim.corpora.LowCorpus.line2doc(self,line)
gensim.corpora.LowCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.lowcorpus.LowCorpus(self,fname,id2word=None,line2words=split_on_space)
gensim.corpora.lowcorpus.LowCorpus.__init__(self,fname,id2word=None,line2words=split_on_space)
gensim.corpora.lowcorpus.LowCorpus.__iter__(self)
gensim.corpora.lowcorpus.LowCorpus.__len__(self)
gensim.corpora.lowcorpus.LowCorpus._calculate_num_docs(self)
gensim.corpora.lowcorpus.LowCorpus.docbyoffset(self,offset)
gensim.corpora.lowcorpus.LowCorpus.id2word(self)
gensim.corpora.lowcorpus.LowCorpus.id2word(self,val)
gensim.corpora.lowcorpus.LowCorpus.line2doc(self,line)
gensim.corpora.lowcorpus.LowCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.lowcorpus.split_on_space(s)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/sharded_corpus.py----------------------------------------
A:gensim.corpora.sharded_corpus.logger->logging.getLogger(__name__)
A:gensim.corpora.sharded_corpus.(is_corpus, corpus)->gensim.utils.is_corpus(corpus)
A:gensim.corpora.sharded_corpus.proposed_dim->self._guess_n_features(corpus)
A:gensim.corpora.sharded_corpus.start_time->time.clock()
A:gensim.corpora.sharded_corpus.current_shard->scipy.sparse.csr_matrix(current_shard)
A:gensim.corpora.sharded_corpus.doc->dict(doc)
A:gensim.corpora.sharded_corpus.current_shard[i][list(doc)]->list(gensim.matutils.itervalues(doc))
A:gensim.corpora.sharded_corpus.end_time->time.clock()
A:gensim.corpora.sharded_corpus.temp->self.__class__.load(self.output_prefix)
A:gensim.corpora.sharded_corpus.filename->self._shard_name(n)
A:gensim.corpora.sharded_corpus.shard->gensim.utils.unpickle(filename)
A:gensim.corpora.sharded_corpus.k->int(offset / self.shardsize)
A:gensim.corpora.sharded_corpus.n_new_shards->int(math.floor(self.n_docs / float(shardsize)))
A:gensim.corpora.sharded_corpus.new_shard_name->self._resized_shard_name(new_shard_idx)
A:gensim.corpora.sharded_corpus.n_features->len(corpus.dictionary)
A:gensim.corpora.sharded_corpus.shard_n->self.shard_by_offset(offset)
A:gensim.corpora.sharded_corpus.l_result->scipy.sparse.csr_matrix(l_result)
A:gensim.corpora.sharded_corpus.first_shard->self.shard_by_offset(start)
A:gensim.corpora.sharded_corpus.last_shard->self.shard_by_offset(stop)
A:gensim.corpora.sharded_corpus.s_result->scipy.sparse.csr_matrix(s_result)
A:gensim.corpora.sharded_corpus.output->gensim.matutils.full2sparse(result)
A:gensim.corpora.sharded_corpus.args->tuple([self.output_prefix])
A:gensim.corpora.sharded_corpus.kwargs['ignore']->frozenset([v for v in kwargs['ignore']] + attrs_to_ignore)
gensim.corpora.sharded_corpus.ShardedCorpus(self,output_prefix,corpus,dim=None,shardsize=4096,overwrite=False,sparse_serialization=False,sparse_retrieval=False,gensim=False)
gensim.corpora.sharded_corpus.ShardedCorpus.__add_to_slice(self,s_result,result_start,result_stop,start,stop)
gensim.corpora.sharded_corpus.ShardedCorpus.__getitem__(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.__init__(self,output_prefix,corpus,dim=None,shardsize=4096,overwrite=False,sparse_serialization=False,sparse_retrieval=False,gensim=False)
gensim.corpora.sharded_corpus.ShardedCorpus.__iter__(self)
gensim.corpora.sharded_corpus.ShardedCorpus.__len__(self)
gensim.corpora.sharded_corpus.ShardedCorpus._ensure_shard(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus._getitem_dense2gensim(self,result)
gensim.corpora.sharded_corpus.ShardedCorpus._getitem_format(self,s_result)
gensim.corpora.sharded_corpus.ShardedCorpus._getitem_sparse2gensim(self,result)
gensim.corpora.sharded_corpus.ShardedCorpus._guess_n_features(self,corpus)
gensim.corpora.sharded_corpus.ShardedCorpus._resized_shard_name(self,n)
gensim.corpora.sharded_corpus.ShardedCorpus._shard_name(self,n)
gensim.corpora.sharded_corpus.ShardedCorpus.get_by_offset(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.in_current(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.in_next(self,offset)
gensim.corpora.sharded_corpus.ShardedCorpus.init_by_clone(self)
gensim.corpora.sharded_corpus.ShardedCorpus.init_shards(self,output_prefix,corpus,shardsize=4096,dtype=_default_dtype)
gensim.corpora.sharded_corpus.ShardedCorpus.load(cls,fname,mmap=None)
gensim.corpora.sharded_corpus.ShardedCorpus.load_shard(self,n)
gensim.corpora.sharded_corpus.ShardedCorpus.reset(self)
gensim.corpora.sharded_corpus.ShardedCorpus.resize_shards(self,shardsize)
gensim.corpora.sharded_corpus.ShardedCorpus.save(self,*args,**kwargs)
gensim.corpora.sharded_corpus.ShardedCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=1000,metadata=False,**kwargs)
gensim.corpora.sharded_corpus.ShardedCorpus.save_shard(self,shard,n=None,filename=None)
gensim.corpora.sharded_corpus.ShardedCorpus.serialize(serializer,fname,corpus,id2word=None,index_fname=None,progress_cnt=None,labels=None,metadata=False,**kwargs)
gensim.corpora.sharded_corpus.ShardedCorpus.shard_by_offset(self,offset)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/bleicorpus.py----------------------------------------
A:gensim.corpora.bleicorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.bleicorpus.(fname_base, _)->os.path.splitext(fname)
A:gensim.corpora.bleicorpus.fname_dir->os.path.dirname(fname)
A:gensim.corpora.bleicorpus.self.id2word->dict(enumerate(words))
A:gensim.corpora.bleicorpus.parts->gensim.utils.to_unicode(line).split()
A:gensim.corpora.bleicorpus.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.corpora.bleicorpus.num_terms->len(id2word)
A:gensim.corpora.bleicorpus.doc->list(doc)
A:gensim.corpora.bleicorpus.fname_vocab->gensim.utils.smart_extension(fname, '.vocab')
gensim.corpora.BleiCorpus(self,fname,fname_vocab=None)
gensim.corpora.BleiCorpus.__iter__(self)
gensim.corpora.BleiCorpus.docbyoffset(self,offset)
gensim.corpora.BleiCorpus.line2doc(self,line)
gensim.corpora.BleiCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)
gensim.corpora.bleicorpus.BleiCorpus(self,fname,fname_vocab=None)
gensim.corpora.bleicorpus.BleiCorpus.__init__(self,fname,fname_vocab=None)
gensim.corpora.bleicorpus.BleiCorpus.__iter__(self)
gensim.corpora.bleicorpus.BleiCorpus.docbyoffset(self,offset)
gensim.corpora.bleicorpus.BleiCorpus.line2doc(self,line)
gensim.corpora.bleicorpus.BleiCorpus.save_corpus(fname,corpus,id2word=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/mmcorpus.py----------------------------------------
A:gensim.corpora.mmcorpus.logger->logging.getLogger(__name__)
gensim.corpora.MmCorpus(self,fname)
gensim.corpora.MmCorpus.__iter__(self)
gensim.corpora.MmCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=1000,metadata=False)
gensim.corpora.mmcorpus.MmCorpus(self,fname)
gensim.corpora.mmcorpus.MmCorpus.__init__(self,fname)
gensim.corpora.mmcorpus.MmCorpus.__iter__(self)
gensim.corpora.mmcorpus.MmCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=1000,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/ucicorpus.py----------------------------------------
A:gensim.corpora.ucicorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.ucicorpus.self.num_docs->int(next(fin).strip())
A:gensim.corpora.ucicorpus.self.num_terms->int(next(fin).strip())
A:gensim.corpora.ucicorpus.self.num_nnz->int(next(fin).strip())
A:gensim.corpora.ucicorpus.FAKE_HEADER->gensim.utils.to_utf8(' ' * MAX_HEADER_LENGTH + '\n')
A:gensim.corpora.ucicorpus.writer->UciWriter(fname)
A:gensim.corpora.ucicorpus.posnow->UciWriter(fname).fout.tell()
A:gensim.corpora.ucicorpus.(max_id, veclen)->UciWriter(fname).write_vector(docno, vector)
A:gensim.corpora.ucicorpus.num_terms->len(id2word)
A:gensim.corpora.ucicorpus.fname_vocab->gensim.utils.smart_extension(fname, '.vocab')
A:gensim.corpora.ucicorpus.self.id2word->dict(enumerate(words))
A:gensim.corpora.ucicorpus.dictionary->Dictionary()
A:gensim.corpora.ucicorpus.dictionary.dfs->defaultdict(int)
A:gensim.corpora.ucicorpus.dictionary.token2id->gensim.utils.revdict(self.id2word)
A:gensim.corpora.ucicorpus.id2word->gensim.utils.dict_from_corpus(corpus)
gensim.corpora.UciCorpus(self,fname,fname_vocab=None)
gensim.corpora.UciCorpus.__iter__(self)
gensim.corpora.UciCorpus.create_dictionary(self)
gensim.corpora.UciCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=10000,metadata=False)
gensim.corpora.ucicorpus.UciCorpus(self,fname,fname_vocab=None)
gensim.corpora.ucicorpus.UciCorpus.__init__(self,fname,fname_vocab=None)
gensim.corpora.ucicorpus.UciCorpus.__iter__(self)
gensim.corpora.ucicorpus.UciCorpus.create_dictionary(self)
gensim.corpora.ucicorpus.UciCorpus.save_corpus(fname,corpus,id2word=None,progress_cnt=10000,metadata=False)
gensim.corpora.ucicorpus.UciReader(self,input)
gensim.corpora.ucicorpus.UciReader.__init__(self,input)
gensim.corpora.ucicorpus.UciReader.skip_headers(self,input_file)
gensim.corpora.ucicorpus.UciWriter(MmWriter)
gensim.corpora.ucicorpus.UciWriter.update_headers(self,num_docs,num_terms,num_nnz)
gensim.corpora.ucicorpus.UciWriter.write_corpus(fname,corpus,progress_cnt=1000,index=False)
gensim.corpora.ucicorpus.UciWriter.write_headers(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/csvcorpus.py----------------------------------------
A:gensim.corpora.csvcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.csvcorpus.head->''.join(itertools.islice(utils.smart_open(self.fname), 5))
A:gensim.corpora.csvcorpus.self.headers->csv.Sniffer().has_header(head)
A:gensim.corpora.csvcorpus.self.dialect->csv.Sniffer().sniff(head)
A:gensim.corpora.csvcorpus.reader->csv.reader(utils.smart_open(self.fname), self.dialect)
gensim.corpora.csvcorpus.CsvCorpus(self,fname,labels)
gensim.corpora.csvcorpus.CsvCorpus.__init__(self,fname,labels)
gensim.corpora.csvcorpus.CsvCorpus.__iter__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/dictionary.py----------------------------------------
A:gensim.corpora.dictionary.logger->logging.getLogger(__name__)
A:gensim.corpora.dictionary.self.id2token->gensim.utils.revdict(self.token2id)
A:gensim.corpora.dictionary.some_keys->list(itertools.islice(iterkeys(self.token2id), 5))
A:gensim.corpora.dictionary.counter->defaultdict(int)
A:gensim.corpora.dictionary.missing->sorted((x for x in iteritems(counter) if x[0] not in token2id))
A:gensim.corpora.dictionary.token2id[w]->len(token2id)
A:gensim.corpora.dictionary.result->Dictionary()
A:gensim.corpora.dictionary.no_above_abs->int(no_above * self.num_docs)
A:gensim.corpora.dictionary.good_ids->set(good_ids)
A:gensim.corpora.dictionary.most_frequent_ids->sorted(most_frequent_ids, key=self.dfs.get, reverse=True)
A:gensim.corpora.dictionary.bad_ids->set(bad_ids)
A:gensim.corpora.dictionary.idmap->dict(izip(sorted(itervalues(self.token2id)), xrange(len(self.token2id))))
A:gensim.corpora.dictionary.new_id->len(self.token2id)
A:gensim.corpora.dictionary.line->gensim.utils.to_unicode(line)
A:gensim.corpora.dictionary.result.num_docs->int(line.strip())
A:gensim.corpora.dictionary.(wordid, word, docfreq)->line[:-1].split('\t')
A:gensim.corpora.dictionary.wordid->int(wordid)
A:gensim.corpora.dictionary.result.dfs[wordid]->int(docfreq)
A:gensim.corpora.dictionary.max_id->max(wordid, max_id)
A:gensim.corpora.dictionary.result.dfs[idx]->Dictionary().dfs.get(idx, 0)
gensim.corpora.Dictionary(self,documents=None,prune_at=2000000)
gensim.corpora.Dictionary.__getitem__(self,tokenid)
gensim.corpora.Dictionary.__iter__(self)
gensim.corpora.Dictionary.__len__(self)
gensim.corpora.Dictionary.__str__(self)
gensim.corpora.Dictionary.add_documents(self,documents,prune_at=2000000)
gensim.corpora.Dictionary.compactify(self)
gensim.corpora.Dictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.Dictionary.doc2idx(self,document,unknown_word_index=-1)
gensim.corpora.Dictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000,keep_tokens=None)
gensim.corpora.Dictionary.filter_n_most_frequent(self,remove_n)
gensim.corpora.Dictionary.filter_tokens(self,bad_ids=None,good_ids=None)
gensim.corpora.Dictionary.from_corpus(corpus,id2word=None)
gensim.corpora.Dictionary.from_documents(documents)
gensim.corpora.Dictionary.keys(self)
gensim.corpora.Dictionary.load_from_text(fname)
gensim.corpora.Dictionary.merge_with(self,other)
gensim.corpora.Dictionary.save_as_text(self,fname,sort_by_word=True)
gensim.corpora.dictionary.Dictionary(self,documents=None,prune_at=2000000)
gensim.corpora.dictionary.Dictionary.__getitem__(self,tokenid)
gensim.corpora.dictionary.Dictionary.__init__(self,documents=None,prune_at=2000000)
gensim.corpora.dictionary.Dictionary.__iter__(self)
gensim.corpora.dictionary.Dictionary.__len__(self)
gensim.corpora.dictionary.Dictionary.__str__(self)
gensim.corpora.dictionary.Dictionary.add_documents(self,documents,prune_at=2000000)
gensim.corpora.dictionary.Dictionary.compactify(self)
gensim.corpora.dictionary.Dictionary.doc2bow(self,document,allow_update=False,return_missing=False)
gensim.corpora.dictionary.Dictionary.doc2idx(self,document,unknown_word_index=-1)
gensim.corpora.dictionary.Dictionary.filter_extremes(self,no_below=5,no_above=0.5,keep_n=100000,keep_tokens=None)
gensim.corpora.dictionary.Dictionary.filter_n_most_frequent(self,remove_n)
gensim.corpora.dictionary.Dictionary.filter_tokens(self,bad_ids=None,good_ids=None)
gensim.corpora.dictionary.Dictionary.from_corpus(corpus,id2word=None)
gensim.corpora.dictionary.Dictionary.from_documents(documents)
gensim.corpora.dictionary.Dictionary.keys(self)
gensim.corpora.dictionary.Dictionary.load_from_text(fname)
gensim.corpora.dictionary.Dictionary.merge_with(self,other)
gensim.corpora.dictionary.Dictionary.save_as_text(self,fname,sort_by_word=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/wikicorpus.py----------------------------------------
A:gensim.corpora.wikicorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.wikicorpus.RE_P0->re.compile('<!--.*?-->', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P1->re.compile('<ref([> ].*?)(</ref>|/>)', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P2->re.compile('(\\n\\[\\[[a-z][a-z][\\w-]*:[^:\\]]+\\]\\])+$', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P3->re.compile('{{([^}{]*)}}', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P4->re.compile('{{([^}]*)}}', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P5->re.compile('\\[(\\w+):\\/\\/(.*?)(( (.*?))|())\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P6->re.compile('\\[([^][]*)\\|([^][]*)\\]', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P7->re.compile('\\n\\[\\[[iI]mage(.*?)(\\|.*?)*\\|(.*?)\\]\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P8->re.compile('\\n\\[\\[[fF]ile(.*?)(\\|.*?)*\\|(.*?)\\]\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P9->re.compile('<nowiki([> ].*?)(</nowiki>|/>)', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P10->re.compile('<math([> ].*?)(</math>|/>)', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P11->re.compile('<(.*?)>', re.DOTALL | re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P12->re.compile('\\n(({\\|)|(\\|-)|(\\|}))(.*?)(?=\\n)', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P13->re.compile('\\n(\\||\\!)(.*?\\|)*([^|]*?)', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P14->re.compile('\\[\\[Category:[^][]*\\]\\]', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P15->re.compile('\\[\\[([fF]ile:|[iI]mage)[^]]*(\\]\\])', re.UNICODE)
A:gensim.corpora.wikicorpus.RE_P16->re.compile('\\[{2}(.*?)\\]{2}', re.UNICODE)
A:gensim.corpora.wikicorpus.filtered->filter_wiki(raw, promote_remaining=False, simplify_links=False)
A:gensim.corpora.wikicorpus.interlinks_raw->re.findall(RE_P16, filtered)
A:gensim.corpora.wikicorpus.text->filter_wiki(text)
A:gensim.corpora.wikicorpus.m->re.match('^{(.*?)}', tag)
A:gensim.corpora.wikicorpus.s->s.replace(m, caption, 1).replace(m, caption, 1)
A:gensim.corpora.wikicorpus.elem->next(elems)
A:gensim.corpora.wikicorpus.namespace->get_namespace(elem.tag)
A:gensim.corpora.wikicorpus.result->tokenizer_func(text, token_min_len, token_max_len, lower)
A:gensim.corpora.wikicorpus.processes->max(1, multiprocessing.cpu_count() - 1)
A:gensim.corpora.wikicorpus.pool->multiprocessing.Pool(self.processes, init_to_ignore_interrupt)
gensim.corpora.WikiCorpus(self,fname,processes=None,lemmatize=utils.has_pattern(),dictionary=None,filter_namespaces=('0',),tokenizer_func=tokenize,article_min_tokens=ARTICLE_MIN_WORDS,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)
gensim.corpora.WikiCorpus.get_texts(self)
gensim.corpora.wikicorpus.WikiCorpus(self,fname,processes=None,lemmatize=utils.has_pattern(),dictionary=None,filter_namespaces=('0',),tokenizer_func=tokenize,article_min_tokens=ARTICLE_MIN_WORDS,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)
gensim.corpora.wikicorpus.WikiCorpus.__init__(self,fname,processes=None,lemmatize=utils.has_pattern(),dictionary=None,filter_namespaces=('0',),tokenizer_func=tokenize,article_min_tokens=ARTICLE_MIN_WORDS,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)
gensim.corpora.wikicorpus.WikiCorpus.get_texts(self)
gensim.corpora.wikicorpus._process_article(args)
gensim.corpora.wikicorpus.extract_pages(f,filter_namespaces=False)
gensim.corpora.wikicorpus.filter_wiki(raw,promote_remaining=True,simplify_links=True)
gensim.corpora.wikicorpus.find_interlinks(raw)
gensim.corpora.wikicorpus.get_namespace(tag)
gensim.corpora.wikicorpus.init_to_ignore_interrupt()
gensim.corpora.wikicorpus.process_article(args,tokenizer_func=tokenize,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)
gensim.corpora.wikicorpus.remove_file(s)
gensim.corpora.wikicorpus.remove_markup(text,promote_remaining=True,simplify_links=True)
gensim.corpora.wikicorpus.remove_template(s)
gensim.corpora.wikicorpus.tokenize(content,token_min_len=TOKEN_MIN_LEN,token_max_len=TOKEN_MAX_LEN,lower=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/indexedcorpus.py----------------------------------------
A:gensim.corpora.indexedcorpus.logger->logging.getLogger(__name__)
A:gensim.corpora.indexedcorpus.index_fname->gensim.utils.smart_extension(fname, '.index')
A:gensim.corpora.indexedcorpus.self.index->numpy.asarray(self.index)
A:gensim.corpora.indexedcorpus.offsets->serializer.save_corpus(fname, corpus, id2word, **kwargs)
A:gensim.corpora.indexedcorpus.self.length->sum((1 for _ in self))
gensim.corpora.IndexedCorpus(self,fname,index_fname=None)
gensim.corpora.IndexedCorpus.__getitem__(self,docno)
gensim.corpora.IndexedCorpus.__len__(self)
gensim.corpora.IndexedCorpus.serialize(serializer,fname,corpus,id2word=None,index_fname=None,progress_cnt=None,labels=None,metadata=False)
gensim.corpora.indexedcorpus.IndexedCorpus(self,fname,index_fname=None)
gensim.corpora.indexedcorpus.IndexedCorpus.__getitem__(self,docno)
gensim.corpora.indexedcorpus.IndexedCorpus.__init__(self,fname,index_fname=None)
gensim.corpora.indexedcorpus.IndexedCorpus.__len__(self)
gensim.corpora.indexedcorpus.IndexedCorpus.serialize(serializer,fname,corpus,id2word=None,index_fname=None,progress_cnt=None,labels=None,metadata=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/corpora/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_datatype.py----------------------------------------
A:gensim.test.test_datatype.path->datapath('high_precision.kv.txt')
A:gensim.test.test_datatype.kv->self.load_model(np.float16)
A:gensim.test.test_datatype.binary_path->datapath('high_precision.kv.bin')
A:gensim.test.test_datatype.model1->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(path, datatype=np.float16)
A:gensim.test.test_datatype.model2->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(binary_path, datatype=np.float64, binary=True)
gensim.test.test_datatype.TestDataType(unittest.TestCase)
gensim.test.test_datatype.TestDataType.load_model(self,datatype)
gensim.test.test_datatype.TestDataType.test_high_precision(self)
gensim.test.test_datatype.TestDataType.test_low_precision(self)
gensim.test.test_datatype.TestDataType.test_medium_precision(self)
gensim.test.test_datatype.TestDataType.test_type_conversion(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_matutils.py----------------------------------------
A:gensim.test.test_matutils.x_max->numpy.max(x)
A:gensim.test.test_matutils.x->numpy.log(np.sum(np.exp(x - x_max)))
A:gensim.test.test_matutils.self.random_state->numpy.random.RandomState()
A:gensim.test.test_matutils.input->rs.uniform(-1000, 1000, size=(self.num_topics, 1))
A:gensim.test.test_matutils.known_good->dirichlet_expectation(input_2d)
A:gensim.test.test_matutils.test_values->gensim.matutils.dirichlet_expectation(input_2d)
A:gensim.test.test_matutils.msg->'dirichlet_expectation_2d failed for dtype={}'.format(dtype)
A:gensim.test.test_matutils.input1->rs.uniform(-10000, 10000, size=(self.num_topics,))
A:gensim.test.test_matutils.input2->rs.uniform(-10000, 10000, size=(self.num_topics,))
A:gensim.test.test_matutils.input_1d->rs.uniform(0.01, 10000, size=(self.num_topics,))
A:gensim.test.test_matutils.input_2d->rs.uniform(0.01, 10000, size=(1, self.num_topics))
gensim.test.test_matutils.TestLdaModelInner(unittest.TestCase)
gensim.test.test_matutils.TestLdaModelInner.setUp(self)
gensim.test.test_matutils.TestLdaModelInner.testDirichletExpectation(self)
gensim.test.test_matutils.TestLdaModelInner.testLogSumExp(self)
gensim.test.test_matutils.TestLdaModelInner.testMeanAbsoluteDifference(self)
gensim.test.test_matutils.dirichlet_expectation(alpha)
gensim.test.test_matutils.logsumexp(x)
gensim.test.test_matutils.mean_absolute_difference(a,b)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_normmodel.py----------------------------------------
A:gensim.test.test_normmodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_normmodel.self.model_l1->gensim.models.normmodel.NormModel(self.corpus, norm='l1')
A:gensim.test.test_normmodel.self.model_l2->gensim.models.normmodel.NormModel(self.corpus, norm='l2')
A:gensim.test.test_normmodel.normalized->self.model_l2.normalize(ndarray_matrix)
A:gensim.test.test_normmodel.row->numpy.array([0, 0, 1, 2, 2, 2])
A:gensim.test.test_normmodel.col->numpy.array([0, 2, 2, 0, 1, 2])
A:gensim.test.test_normmodel.data->numpy.array([1, 2, 3, 4, 5, 6])
A:gensim.test.test_normmodel.sparse_matrix->csr_matrix((data, (row, col)), shape=(3, 3))
A:gensim.test.test_normmodel.expected->numpy.array([[0.10482848, 0.0, 0.20965697], [0.0, 0.0, 0.31448545], [0.41931393, 0.52414242, 0.6289709]])
A:gensim.test.test_normmodel.ndarray_matrix->numpy.array([[1, 0, 2], [0, 0, 3], [4, 5, 6]])
A:gensim.test.test_normmodel.fname->get_tmpfile('gensim_models.tst.gz')
A:gensim.test.test_normmodel.model->gensim.models.normmodel.NormModel(self.corpus)
A:gensim.test.test_normmodel.model2->gensim.models.normmodel.NormModel.load(fname, mmap=None)
gensim.test.test_normmodel.TestNormModel(unittest.TestCase)
gensim.test.test_normmodel.TestNormModel.setUp(self)
gensim.test.test_normmodel.TestNormModel.testInit(self)
gensim.test.test_normmodel.TestNormModel.testPersistence(self)
gensim.test.test_normmodel.TestNormModel.testPersistenceCompressed(self)
gensim.test.test_normmodel.TestNormModel.test_numpyndarrayInput_l1(self)
gensim.test.test_normmodel.TestNormModel.test_numpyndarrayInput_l2(self)
gensim.test.test_normmodel.TestNormModel.test_sparseCSRInput_l1(self)
gensim.test.test_normmodel.TestNormModel.test_sparseCSRInput_l2(self)
gensim.test.test_normmodel.TestNormModel.test_tupleInput_l1(self)
gensim.test.test_normmodel.TestNormModel.test_tupleInput_l2(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_segmentation.py----------------------------------------
A:gensim.test.test_segmentation.actual->gensim.topic_coherence.segmentation.s_one_set(self.topics)
gensim.test.test_segmentation.TestSegmentation(unittest.TestCase)
gensim.test.test_segmentation.TestSegmentation.setUp(self)
gensim.test.test_segmentation.TestSegmentation.testSOneOne(self)
gensim.test.test_segmentation.TestSegmentation.testSOnePre(self)
gensim.test.test_segmentation.TestSegmentation.testSOneSet(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_translation_matrix.py----------------------------------------
A:gensim.test.test_translation_matrix.self.source_word_vec_file->datapath('EN.1-10.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt')
A:gensim.test.test_translation_matrix.self.target_word_vec_file->datapath('IT.1-10.cbow1_wind5_hs0_neg10_size300_smpl1e-05.txt')
A:gensim.test.test_translation_matrix.self.source_word_vec->gensim.models.KeyedVectors.load_word2vec_format(self.source_word_vec_file, binary=False)
A:gensim.test.test_translation_matrix.self.target_word_vec->gensim.models.KeyedVectors.load_word2vec_format(self.target_word_vec_file, binary=False)
A:gensim.test.test_translation_matrix.model->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5])
A:gensim.test.test_translation_matrix.tmpf->get_tmpfile('transmat-en-it.pkl')
A:gensim.test.test_translation_matrix.loaded_model->gensim.models.translation_matrix.TranslationMatrix.load(tmpf)
A:gensim.test.test_translation_matrix.(test_source_word, test_target_word)->zip(*self.test_word_pairs)
A:gensim.test.test_translation_matrix.translated_words->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5]).translate(test_source_word, topn=5, gc=1, sample_num=3, source_lang_vec=self.source_word_vec, target_lang_vec=self.target_word_vec)
A:gensim.test.test_translation_matrix.sentiment_document->namedtuple('SentimentDocument', 'words tags')
A:gensim.test.test_translation_matrix.tokens->gensim.utils.to_unicode(line).split()
A:gensim.test.test_translation_matrix.tags->str(line_no)
A:gensim.test.test_translation_matrix.filename->datapath('alldata-id-10.txt')
A:gensim.test.test_translation_matrix.train_docs->read_sentiment_docs(filename)
A:gensim.test.test_translation_matrix.self.source_doc_vec_file->datapath('small_tag_doc_5_iter50')
A:gensim.test.test_translation_matrix.self.target_doc_vec_file->datapath('large_tag_doc_10_iter50')
A:gensim.test.test_translation_matrix.self.source_doc_vec->gensim.models.doc2vec.Doc2Vec.load(self.source_doc_vec_file)
A:gensim.test.test_translation_matrix.self.target_doc_vec->gensim.models.doc2vec.Doc2Vec.load(self.target_doc_vec_file)
A:gensim.test.test_translation_matrix.transmat->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5]).train(self.train_docs[:5])
A:gensim.test.test_translation_matrix.infered_vec->gensim.models.translation_matrix.BackMappingTranslationMatrix(self.source_doc_vec, self.target_doc_vec, self.train_docs[:5]).infer_vector(self.target_doc_vec.docvecs[self.train_docs[5].tags])
A:gensim.test.test_translation_matrix.caculated->cosine(self.target_doc_vec.docvecs[self.train_docs[5].tags], infered_vec)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix(unittest.TestCase)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix.setUp(self)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix.test_infer_vector(self)
gensim.test.test_translation_matrix.TestBackMappingTranslationMatrix.test_translation_matrix(self)
gensim.test.test_translation_matrix.TestTranslationMatrix(unittest.TestCase)
gensim.test.test_translation_matrix.TestTranslationMatrix.setUp(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.testPersistence(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_translate_gc(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_translate_nn(self)
gensim.test.test_translation_matrix.TestTranslationMatrix.test_translation_matrix(self)
gensim.test.test_translation_matrix.read_sentiment_docs(filename)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_similarity_metrics.py----------------------------------------
A:gensim.test.test_similarity_metrics.result->gensim.matutils.softcossim(vec_1, vec_2, similarity_matrix)
A:gensim.test.test_similarity_metrics.potentialbow->numpy.array([[1, 0.4], [0, 0.2], [2, 0.2]])
A:gensim.test.test_similarity_metrics.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_similarity_metrics.self.model->self.class_(common_corpus, id2word=common_dictionary, num_topics=2, passes=100)
A:gensim.test.test_similarity_metrics.vec_1->numpy.array([6, 1, 2, 3])
A:gensim.test.test_similarity_metrics.result_symmetric->gensim.matutils.hellinger(vec_2, vec_1)
A:gensim.test.test_similarity_metrics.vec_2->csr_matrix([[1, 4], [0, 2], [2, 2]])
A:gensim.test.test_similarity_metrics.model->self.class_(self.corpus, id2word=common_dictionary, num_topics=2, passes=100)
A:gensim.test.test_similarity_metrics.similarity_matrix->csc_matrix([[1, 0.5, 0], [0.5, 1, 0], [0, 0, 1]])
gensim.test.test_similarity_metrics.TestHellinger(unittest.TestCase)
gensim.test.test_similarity_metrics.TestHellinger.setUp(self)
gensim.test.test_similarity_metrics.TestHellinger.test_distributions(self)
gensim.test.test_similarity_metrics.TestHellinger.test_inputs(self)
gensim.test.test_similarity_metrics.TestIsBow(unittest.TestCase)
gensim.test.test_similarity_metrics.TestIsBow.test_None(self)
gensim.test.test_similarity_metrics.TestIsBow.test_bow(self)
gensim.test.test_similarity_metrics.TestJaccard(unittest.TestCase)
gensim.test.test_similarity_metrics.TestJaccard.test_distributions(self)
gensim.test.test_similarity_metrics.TestJaccard.test_inputs(self)
gensim.test.test_similarity_metrics.TestKL(unittest.TestCase)
gensim.test.test_similarity_metrics.TestKL.setUp(self)
gensim.test.test_similarity_metrics.TestKL.test_distributions(self)
gensim.test.test_similarity_metrics.TestKL.test_inputs(self)
gensim.test.test_similarity_metrics.TestSoftCosineSimilarity(unittest.TestCase)
gensim.test.test_similarity_metrics.TestSoftCosineSimilarity.test_distributions(self)
gensim.test.test_similarity_metrics.TestSoftCosineSimilarity.test_inputs(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_corpora.py----------------------------------------
A:gensim.test.test_corpora.fname->datapath('testcorpus.' + self.file_extension.lstrip('.'))
A:gensim.test.test_corpora.corpus->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath)
A:gensim.test.test_corpora.docs->list(corpus)
A:gensim.test.test_corpora.tmpf->get_tmpfile('gensim_corpus.tst')
A:gensim.test.test_corpora.corpus2->self.corpus_class(fname)
A:gensim.test.test_corpora.firstdoc->next(iter(corpus))
A:gensim.test.test_corpora.testdoc->set(((to_unicode(corpus.id2word[x]), y) for (x, y) in firstdoc))
A:gensim.test.test_corpora.firstdoc2->next(iter(corpus))
A:gensim.test.test_corpora.testdoc2->set(((to_unicode(corpus.id2word[x]), y) for (x, y) in firstdoc2))
A:gensim.test.test_corpora.corpus_->TransformedCorpus(DummyTransformer(), corpus)
A:gensim.test.test_corpora.self.corpus->self.corpus_class(datapath('test_mmcorpus_corrupt.mm'))
A:gensim.test.test_corpora.file_obj->open(datapath('testcorpus.mm'))
A:gensim.test.test_corpora.it->iter(self.corpus)
A:gensim.test.test_corpora.test_file->get_tmpfile('gensim_corpus.tst')
A:gensim.test.test_corpora.tokens->line.split()
A:gensim.test.test_corpora.words_len->int(tokens[0])
A:gensim.test.test_corpora.(word, count)->token.split(':')
A:gensim.test.test_corpora.texts->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).get_texts()
A:gensim.test.test_corpora.fpath->os.path.join(dirpath, 'test_file.txt')
A:gensim.test.test_corpora.sample1->list(corpus.sample_texts(5, seed=42))
A:gensim.test.test_corpora.sample2->list(corpus.sample_texts(5, seed=42))
A:gensim.test.test_corpora.self.fname->datapath('testcorpus.' + self.file_extension.lstrip('.'))
A:gensim.test.test_corpora.self.enwiki->datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')
A:gensim.test.test_corpora.first_text->next(corpus.get_texts())
A:gensim.test.test_corpora.all_articles->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).get_texts()
A:gensim.test.test_corpora.bgwiki->datapath('bgwiki-latest-pages-articles-shortened.xml.bz2')
A:gensim.test.test_corpora.wc->self.corpus_class(self.enwiki, processes=1, lemmatize=False, tokenizer_func=custom_tokenizer, token_max_len=16, token_min_len=1, lower=False)
A:gensim.test.test_corpora.row->gensim.corpora.textcorpus.TextDirectoryCorpus(dirpath).get_texts()
A:gensim.test.test_corpora.list_tokens->next(row)
A:gensim.test.test_corpora.dirpath->tempfile.mkdtemp()
A:gensim.test.test_corpora.next_level->os.path.join(dirpath, 'level_two')
A:gensim.test.test_corpora.(dirpath, next_level)->self.write_two_levels()
A:gensim.test.test_corpora.filenames->list(corpus.iter_filepaths())
A:gensim.test.test_corpora.a_folder->os.path.join(dirpath, 'a_folder')
A:gensim.test.test_corpora.b_folder->os.path.join(dirpath, 'b_folder')
A:gensim.test.test_corpora.c_folder->os.path.join(b_folder, 'c_folder')
A:gensim.test.test_corpora.base_names->sorted([name[len(dirpath) + 1:] for name in filenames])
A:gensim.test.test_corpora.expected->sorted(['0.txt', 'a_folder/1.txt', 'b_folder/2.txt', 'b_folder/3.txt', 'b_folder/c_folder/4.txt'])
gensim.test.test_corpora.CorpusTestCase(unittest.TestCase)
gensim.test.test_corpora.CorpusTestCase.run(self,result=None)
gensim.test.test_corpora.CorpusTestCase.setUp(self)
gensim.test.test_corpora.CorpusTestCase.tearDown(self)
gensim.test.test_corpora.CorpusTestCase.test_empty_input(self)
gensim.test.test_corpora.CorpusTestCase.test_indexing(self)
gensim.test.test_corpora.CorpusTestCase.test_len(self)
gensim.test.test_corpora.CorpusTestCase.test_load(self)
gensim.test.test_corpora.CorpusTestCase.test_save(self)
gensim.test.test_corpora.CorpusTestCase.test_serialize(self)
gensim.test.test_corpora.CorpusTestCase.test_serialize_compressed(self)
gensim.test.test_corpora.CorpusTestCase.test_switch_id2word(self)
gensim.test.test_corpora.DummyTransformer(object)
gensim.test.test_corpora.DummyTransformer.__getitem__(self,bow)
gensim.test.test_corpora.TestBleiCorpus(CorpusTestCase)
gensim.test.test_corpora.TestBleiCorpus.setUp(self)
gensim.test.test_corpora.TestBleiCorpus.test_save_format_for_dtm(self)
gensim.test.test_corpora.TestLowCorpus(CorpusTestCase)
gensim.test.test_corpora.TestLowCorpus.setUp(self)
gensim.test.test_corpora.TestMalletCorpus(CorpusTestCase)
gensim.test.test_corpora.TestMalletCorpus.setUp(self)
gensim.test.test_corpora.TestMalletCorpus.test_load_with_metadata(self)
gensim.test.test_corpora.TestMmCorpusCorrupt(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusCorrupt.setUp(self)
gensim.test.test_corpora.TestMmCorpusCorrupt.test_load(self)
gensim.test.test_corpora.TestMmCorpusCorrupt.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusNoIndex(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusNoIndex.setUp(self)
gensim.test.test_corpora.TestMmCorpusNoIndex.test_load(self)
gensim.test.test_corpora.TestMmCorpusNoIndex.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip.setUp(self)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip.test_load(self)
gensim.test.test_corpora.TestMmCorpusNoIndexBzip.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip.setUp(self)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip.test_load(self)
gensim.test.test_corpora.TestMmCorpusNoIndexGzip.test_serialize_compressed(self)
gensim.test.test_corpora.TestMmCorpusWithIndex(CorpusTestCase)
gensim.test.test_corpora.TestMmCorpusWithIndex.setUp(self)
gensim.test.test_corpora.TestMmCorpusWithIndex.test_closed_file_object(self)
gensim.test.test_corpora.TestMmCorpusWithIndex.test_load(self)
gensim.test.test_corpora.TestMmCorpusWithIndex.test_serialize_compressed(self)
gensim.test.test_corpora.TestSvmLightCorpus(CorpusTestCase)
gensim.test.test_corpora.TestSvmLightCorpus.setUp(self)
gensim.test.test_corpora.TestTextCorpus(CorpusTestCase)
gensim.test.test_corpora.TestTextCorpus.corpus_from_lines(self,lines)
gensim.test.test_corpora.TestTextCorpus.setUp(self)
gensim.test.test_corpora.TestTextCorpus.test_default_preprocessing(self)
gensim.test.test_corpora.TestTextCorpus.test_indexing(self)
gensim.test.test_corpora.TestTextCorpus.test_load_with_metadata(self)
gensim.test.test_corpora.TestTextCorpus.test_sample_text(self)
gensim.test.test_corpora.TestTextCorpus.test_sample_text_length(self)
gensim.test.test_corpora.TestTextCorpus.test_sample_text_seed(self)
gensim.test.test_corpora.TestTextCorpus.test_save(self)
gensim.test.test_corpora.TestTextCorpus.test_serialize(self)
gensim.test.test_corpora.TestTextCorpus.test_serialize_compressed(self)
gensim.test.test_corpora.TestTextDirectoryCorpus(unittest.TestCase)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_filename_filtering(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_lines_are_documents(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_non_trivial_structure(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_one_level_directory(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.test_two_level_directory(self)
gensim.test.test_corpora.TestTextDirectoryCorpus.write_docs_to_directory(self,dirpath,*args)
gensim.test.test_corpora.TestTextDirectoryCorpus.write_one_level(self,*args)
gensim.test.test_corpora.TestTextDirectoryCorpus.write_two_levels(self)
gensim.test.test_corpora.TestUciCorpus(CorpusTestCase)
gensim.test.test_corpora.TestUciCorpus.setUp(self)
gensim.test.test_corpora.TestUciCorpus.test_serialize_compressed(self)
gensim.test.test_corpora.TestWikiCorpus(TestTextCorpus)
gensim.test.test_corpora.TestWikiCorpus.setUp(self)
gensim.test.test_corpora.TestWikiCorpus.test_custom_tokenizer(self)
gensim.test.test_corpora.TestWikiCorpus.test_default_preprocessing(self)
gensim.test.test_corpora.TestWikiCorpus.test_empty_input(self)
gensim.test.test_corpora.TestWikiCorpus.test_first_element(self)
gensim.test.test_corpora.TestWikiCorpus.test_len(self)
gensim.test.test_corpora.TestWikiCorpus.test_load(self)
gensim.test.test_corpora.TestWikiCorpus.test_load_with_metadata(self)
gensim.test.test_corpora.TestWikiCorpus.test_lower_case_set_false(self)
gensim.test.test_corpora.TestWikiCorpus.test_lower_case_set_true(self)
gensim.test.test_corpora.TestWikiCorpus.test_max_token_len_not_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_max_token_len_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_min_token_len_not_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_min_token_len_set(self)
gensim.test.test_corpora.TestWikiCorpus.test_sample_text(self)
gensim.test.test_corpora.TestWikiCorpus.test_sample_text_length(self)
gensim.test.test_corpora.TestWikiCorpus.test_sample_text_seed(self)
gensim.test.test_corpora.TestWikiCorpus.test_unicode_element(self)
gensim.test.test_corpora.custom_tokenizer(content,token_min_len=2,token_max_len=15,lower=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_dtm.py----------------------------------------
A:gensim.test.test_dtm.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('dtm_test.mm'))
A:gensim.test.test_dtm.self.id2word->gensim.corpora.Dictionary.load(datapath('dtm_test.dict'))
A:gensim.test.test_dtm.self.dtm_path->os.environ.get('DTM_PATH', None)
A:gensim.test.test_dtm.model->gensim.models.wrappers.DtmModel(self.dtm_path, self.corpus, self.time_slices, num_topics=2, id2word=self.id2word, model='fixed', initialize_lda=True, rng_seed=1)
A:gensim.test.test_dtm.topics->gensim.models.wrappers.DtmModel(self.dtm_path, self.corpus, self.time_slices, num_topics=2, id2word=self.id2word, model='fixed', initialize_lda=True, rng_seed=1).show_topics(num_topics=2, times=2, num_words=10)
A:gensim.test.test_dtm.one_topic->gensim.models.wrappers.DtmModel(self.dtm_path, self.corpus, self.time_slices, num_topics=2, id2word=self.id2word, model='fixed', initialize_lda=True, rng_seed=1).show_topic(topicid=1, time=1, num_words=10)
gensim.test.test_dtm.TestDtmModel(unittest.TestCase)
gensim.test.test_dtm.TestDtmModel.setUp(self)
gensim.test.test_dtm.TestDtmModel.testCalledProcessError(self)
gensim.test.test_dtm.TestDtmModel.testDim(self)
gensim.test.test_dtm.TestDtmModel.testDtm(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_varembed_wrapper.py----------------------------------------
A:gensim.test.test_varembed_wrapper.varembed_model_vector_file->datapath('varembed_vectors.pkl')
A:gensim.test.test_varembed_wrapper.varembed_model_morfessor_file->datapath('varembed_morfessor.bin')
A:gensim.test.test_varembed_wrapper.model->gensim.models.wrappers.varembed.VarEmbed.load_varembed_format(vectors=varembed_model_vector_file)
A:gensim.test.test_varembed_wrapper.model_with_morphemes->gensim.models.wrappers.varembed.VarEmbed.load_varembed_format(vectors=varembed_model_vector_file, morfessor_model=varembed_model_morfessor_file)
gensim.test.test_varembed_wrapper.TestVarembed(unittest.TestCase)
gensim.test.test_varembed_wrapper.TestVarembed.model_sanity(self,model)
gensim.test.test_varembed_wrapper.TestVarembed.testAddMorphemesToEmbeddings(self)
gensim.test.test_varembed_wrapper.TestVarembed.testLoadVarembedFormat(self)
gensim.test.test_varembed_wrapper.TestVarembed.testLookup(self)
gensim.test.test_varembed_wrapper.TestVarembed.testSimilarity(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_lee.py----------------------------------------
A:gensim.test.test_lee.pre_path->os.path.join(os.path.dirname(__file__), 'test_data')
A:gensim.test.test_lee.latin1->partial(utils.to_unicode, encoding='latin1')
A:gensim.test.test_lee.bg_corpus->preprocess_documents((latin1(line) for line in f))
A:gensim.test.test_lee.corpus->preprocess_documents((latin1(line) for line in f))
A:gensim.test.test_lee.sim_matrix->numpy.loadtxt(os.path.join(pre_path, sim_file))
A:gensim.test.test_lee.dictionary->gensim.corpora.Dictionary(bg_corpus)
A:gensim.test.test_lee.log_ent->gensim.models.LogEntropyModel(bg_corpus)
A:gensim.test.test_lee.lsi->gensim.models.LsiModel(bg_corpus_ent, id2word=dictionary, num_topics=200)
A:gensim.test.test_lee.res->numpy.zeros((len(corpus), len(corpus)))
A:gensim.test.test_lee.res[i, j]->gensim.matutils.cossim(par1, par2)
gensim.test.test_lee.TestLeeTest(unittest.TestCase)
gensim.test.test_lee.TestLeeTest.setUp(self)
gensim.test.test_lee.TestLeeTest.test_corpus(self)
gensim.test.test_lee.TestLeeTest.test_lee(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_indirect_confirmation.py----------------------------------------
A:gensim.test.test_indirect_confirmation.self.dictionary->Dictionary()
A:gensim.test.test_indirect_confirmation.accumulator->gensim.topic_coherence.text_analysis.WordVectorsAccumulator({1, 2}, self.dictionary)
A:gensim.test.test_indirect_confirmation.obtained->gensim.topic_coherence.indirect_confirmation_measure.cosine_similarity(self.segmentation, accumulator, self.topics, self.measure, self.gamma)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation(unittest.TestCase)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation.setUp(self)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation.testCosineSimilarity(self)
gensim.test.test_indirect_confirmation.TestIndirectConfirmation.testWord2VecSimilarity(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_ldaseqmodel.py----------------------------------------
A:gensim.test.test_ldaseqmodel.sstats->numpy.loadtxt(datapath('DTM/sstats_test.txt'))
A:gensim.test.test_ldaseqmodel.dictionary->Dictionary(texts)
A:gensim.test.test_ldaseqmodel.self.ldaseq->gensim.models.ldaseqmodel.LdaSeqModel(corpus=corpus, id2word=dictionary, num_topics=2, time_slice=[10, 10, 11], initialize='own', sstats=sstats)
A:gensim.test.test_ldaseqmodel.topics->self.ldaseq.print_topics(0)
A:gensim.test.test_ldaseqmodel.doc_topic->self.ldaseq.doc_topics(0)
A:gensim.test.test_ldaseqmodel.ldaseq_3_0_1_fname->datapath('DTM/ldaseq_3_0_1_model')
A:gensim.test.test_ldaseqmodel.model->gensim.models.ldaseqmodel.LdaSeqModel.load(ldaseq_3_0_1_fname)
gensim.test.test_ldaseqmodel.TestLdaSeq(unittest.TestCase)
gensim.test.test_ldaseqmodel.TestLdaSeq.setUp(self)
gensim.test.test_ldaseqmodel.TestLdaSeq.testDocTopic(self)
gensim.test.test_ldaseqmodel.TestLdaSeq.testDtypeBackwardCompatibility(self)
gensim.test.test_ldaseqmodel.TestLdaSeq.testTopicWord(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_doc2vec.py----------------------------------------
A:gensim.test.test_doc2vec.list_corpus->list(DocsLeeCorpus())
A:gensim.test.test_doc2vec.tmpf->get_tmpfile('gensim_doc2vec.tst')
A:gensim.test.test_doc2vec.model->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, size=5)
A:gensim.test.test_doc2vec.test_doc_word->get_tmpfile('gensim_doc2vec.dw')
A:gensim.test.test_doc2vec.binary_model_dv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(test_word, binary=True)
A:gensim.test.test_doc2vec.test_doc->get_tmpfile('gensim_doc2vec.d')
A:gensim.test.test_doc2vec.test_word->get_tmpfile('gensim_doc2vec.w')
A:gensim.test.test_doc2vec.corpus->gensim.utils.RepeatCorpus(DocsLeeCorpus(), 10000)
A:gensim.test.test_doc2vec.fire2->numpy.int64(8)
A:gensim.test.test_doc2vec.doc0_inferred->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, size=5).infer_vector(list(DocsLeeCorpus())[0].words)
A:gensim.test.test_doc2vec.sims_to_infer->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, size=5).docvecs.most_similar([doc0_inferred], topn=len(model.docvecs))
A:gensim.test.test_doc2vec.f_rank->[docid for (docid, sim) in sims_to_infer].index(fire1)
A:gensim.test.test_doc2vec.sims->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, size=5).docvecs.most_similar(fire1, topn=len(model.docvecs))
A:gensim.test.test_doc2vec.f2_rank->[docid for (docid, sim) in sims].index(fire2)
A:gensim.test.test_doc2vec.sims2->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, size=5).docvecs.most_similar(positive=[doc0_vec], topn=21)
A:gensim.test.test_doc2vec.clip_sims->gensim.models.doc2vec.Doc2Vec(alpha=0.025, min_alpha=0.025, min_count=1, workers=8, size=5).docvecs.most_similar(fire1, clip_start=len(model.docvecs) // 2, clip_end=len(model.docvecs) * 2 // 3)
A:gensim.test.test_doc2vec.loaded->gensim.models.doc2vec.Doc2Vec.load(tmpf)
A:gensim.test.test_doc2vec.model2->gensim.models.doc2vec.Doc2Vec(DocsLeeCorpus(), dm=1, dm_concat=1, size=24, window=4, hs=1, negative=3, seed=42, workers=1)
A:gensim.test.test_doc2vec.self.docvecs->ConcatenatedDocvecs([model.docvecs for model in models])
A:gensim.test.test_doc2vec.SentimentDocument->namedtuple('SentimentDocument', 'words tags split sentiment')
A:gensim.test.test_doc2vec.(id, text)->sentence_line.split('\t')
A:gensim.test.test_doc2vec.id->int(id)
A:gensim.test.test_doc2vec.text->text.replace(junk, fix).replace(junk, fix)
A:gensim.test.test_doc2vec.(id2, split_i)->split_line.split(',')
A:gensim.test.test_doc2vec.(text, id)->line.split('|')
A:gensim.test.test_doc2vec.phrases[int(id)]->text.replace(junk, fix).replace(junk, fix).rstrip()
A:gensim.test.test_doc2vec.SentimentPhrase->namedtuple('SentimentPhrase', SentimentDocument._fields + ('sentence_id',))
A:gensim.test.test_doc2vec.(id, sentiment)->line.split('|')
A:gensim.test.test_doc2vec.sentiment->float(sentiment)
A:gensim.test.test_doc2vec.words->text.replace(junk, fix).replace(junk, fix).split()
A:gensim.test.test_doc2vec.(sentence_id, split_i)->info_by_sentence.get(text, (None, 0))
A:gensim.test.test_doc2vec.phrases[id]->SentimentPhrase(words, [id], split, sentiment, sentence_id)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec(self,models)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.__getitem__(self,token)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.__init__(self,models)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.infer_vector(self,document,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.test.test_doc2vec.ConcatenatedDoc2Vec.train(self,*ignore_args,**ignore_kwargs)
gensim.test.test_doc2vec.ConcatenatedDocvecs(self,models)
gensim.test.test_doc2vec.ConcatenatedDocvecs.__getitem__(self,token)
gensim.test.test_doc2vec.ConcatenatedDocvecs.__init__(self,models)
gensim.test.test_doc2vec.DocsLeeCorpus(self,string_tags=False,unicode_tags=False)
gensim.test.test_doc2vec.DocsLeeCorpus.__init__(self,string_tags=False,unicode_tags=False)
gensim.test.test_doc2vec.DocsLeeCorpus.__iter__(self)
gensim.test.test_doc2vec.DocsLeeCorpus._tag(self,i)
gensim.test.test_doc2vec.TestDoc2VecModel(unittest.TestCase)
gensim.test.test_doc2vec.TestDoc2VecModel.model_sanity(self,model,keep_training=True)
gensim.test.test_doc2vec.TestDoc2VecModel.models_equal(self,model,model2)
gensim.test.test_doc2vec.TestDoc2VecModel.testBuildVocabWarning(self,l)
gensim.test.test_doc2vec.TestDoc2VecModel.testLoadOldModel(self)
gensim.test.test_doc2vec.TestDoc2VecModel.testLoadOnClassError(self)
gensim.test.test_doc2vec.TestDoc2VecModel.testPersistenceWord2VecFormat(self)
gensim.test.test_doc2vec.TestDoc2VecModel.testTrainWarning(self,l)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dbow_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_delete_temporary_training_data(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_deterministic_dmc(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_deterministic_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_deterministic_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmc_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmc_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dmm_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dms_hs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_dms_neg(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_empty_errors(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_int_doctags(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_load_mmap(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_missing_string_doctag(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_mixed_tag_types(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_parallel(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_persistence(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_similarity_unseen_docs(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_string_doctags(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_training(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_unicode_in_doctag(self)
gensim.test.test_doc2vec.TestDoc2VecModel.test_word_vec_non_writeable(self)
gensim.test.test_doc2vec.load_on_instance()
gensim.test.test_doc2vec.read_su_sentiment_rotten_tomatoes(dirname,lowercase=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_probability_estimation.py----------------------------------------
A:gensim.test.test_probability_estimation.accumulator->gensim.topic_coherence.probability_estimation.p_boolean_sliding_window(self.texts, self.segmented_topics, self.dictionary, 2)
A:gensim.test.test_probability_estimation.obtained->gensim.topic_coherence.probability_estimation.p_boolean_sliding_window(self.texts, self.segmented_topics, self.dictionary, 2).index_to_dict()
A:gensim.test.test_probability_estimation.self.dictionary->Dictionary(self.texts)
gensim.test.test_probability_estimation.BaseTestCases(object)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase(unittest.TestCase)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.build_segmented_topics(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.setUp(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.setup_dictionary(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.testPBooleanDocument(self)
gensim.test.test_probability_estimation.BaseTestCases.ProbabilityEstimationBase.testPBooleanSlidingWindow(self)
gensim.test.test_probability_estimation.TestProbabilityEstimation(BaseTestCases.ProbabilityEstimationBase)
gensim.test.test_probability_estimation.TestProbabilityEstimation.setup_dictionary(self)
gensim.test.test_probability_estimation.TestProbabilityEstimationWithNormalDictionary(BaseTestCases.ProbabilityEstimationBase)
gensim.test.test_probability_estimation.TestProbabilityEstimationWithNormalDictionary.setup_dictionary(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/utils.py----------------------------------------
A:gensim.test.utils.module_path->os.path.dirname(__file__)
A:gensim.test.utils.tmp->tempfile.mkdtemp()
A:gensim.test.utils.common_dictionary->Dictionary(common_texts)
gensim.test.utils.datapath(fname)
gensim.test.utils.get_tmpfile(suffix)
gensim.test.utils.temporary_file(name='')


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_word2vec.py----------------------------------------
A:gensim.test.test_word2vec.list_corpus->list(LeeCorpus())
A:gensim.test.test_word2vec.tmpf->get_tmpfile('gensim_word2vec.tst')
A:gensim.test.test_word2vec.model->gensim.models.word2vec.Word2Vec(sentences, min_count=1)
A:gensim.test.test_word2vec.model_hs->gensim.models.word2vec.Word2Vec(sentences, size=10, min_count=0, seed=42, hs=1, negative=0)
A:gensim.test.test_word2vec.model_neg->gensim.models.word2vec.Word2Vec.load(tmpf)
A:gensim.test.test_word2vec.orig0->numpy.copy(model.wv.syn0[0])
A:gensim.test.test_word2vec.sim->gensim.models.word2vec.Word2Vec(sentences, min_count=1).n_similarity(['war'], ['terrorism'])
A:gensim.test.test_word2vec.loaded_wv->gensim.models.keyedvectors.KeyedVectors.load(tmpf)
A:gensim.test.test_word2vec.loaded_model->gensim.models.word2vec.Word2Vec.load(tmpf)
A:gensim.test.test_word2vec.loaded_kv->gensim.models.keyedvectors.KeyedVectors.load(tmpf)
A:gensim.test.test_word2vec.binary_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_word2vec.norm_only_model->gensim.models.word2vec.Word2Vec.load(tmpf)
A:gensim.test.test_word2vec.limited_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True, limit=3)
A:gensim.test.test_word2vec.half_precision_model_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True, datatype=np.float16)
A:gensim.test.test_word2vec.kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_word2vec.binary_model->gensim.models.word2vec.Word2Vec()
A:gensim.test.test_word2vec.tfile->get_tmpfile('gensim_word2vec.tst')
A:gensim.test.test_word2vec.f->open(tfile, 'r+b')
A:gensim.test.test_word2vec.text_model->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=False)
A:gensim.test.test_word2vec.testvocab->get_tmpfile('gensim_word2vec.vocab')
A:gensim.test.test_word2vec.binary_model_with_vocab_kv->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, testvocab, binary=True)
A:gensim.test.test_word2vec.kv_binary_model_with_vocab->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, testvocab, binary=True)
A:gensim.test.test_word2vec.corpus->gensim.utils.RepeatCorpus(LeeCorpus(), 10000)
A:gensim.test.test_word2vec.total_words->sum((len(sentence) for sentence in corpus))
A:gensim.test.test_word2vec.sims->gensim.models.word2vec.Word2Vec(sentences, min_count=1).most_similar('israeli')
A:gensim.test.test_word2vec.sims2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).most_similar(positive=[graph_vector], topn=11)
A:gensim.test.test_word2vec.model2->gensim.models.word2vec.Word2Vec(sentences, min_count=2, seed=42, workers=1)
A:gensim.test.test_word2vec.scores->gensim.models.word2vec.Word2Vec(sentences, min_count=1).score(sentences, len(sentences))
A:gensim.test.test_word2vec.locked0->numpy.copy(model.wv.syn0[0])
A:gensim.test.test_word2vec.unlocked1->numpy.copy(model.wv.syn0[1])
A:gensim.test.test_word2vec.w2v_accuracy->gensim.models.word2vec.Word2Vec(sentences, min_count=1).accuracy(datapath('questions-words.txt'))
A:gensim.test.test_word2vec.kv_accuracy->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wv.accuracy(datapath('questions-words.txt'))
A:gensim.test.test_word2vec.correlation->gensim.models.word2vec.Word2Vec(sentences, min_count=1).evaluate_word_pairs(datapath('wordsim353.tsv'))
A:gensim.test.test_word2vec.t_rank->[word for (word, score) in sims].index('terrorism')
A:gensim.test.test_word2vec.wordsims->gensim.models.word2vec.Word2Vec(sentences, min_count=1).similar_by_word('graph', topn=10)
A:gensim.test.test_word2vec.wordsims2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).most_similar(positive='graph', topn=10)
A:gensim.test.test_word2vec.vectorsims->gensim.models.word2vec.Word2Vec(sentences, min_count=1).similar_by_vector(model['graph'], topn=10)
A:gensim.test.test_word2vec.vectorsims2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).most_similar([model['graph']], topn=10)
A:gensim.test.test_word2vec.model_with_neg->gensim.models.word2vec.Word2Vec(sentences, min_count=1)
A:gensim.test.test_word2vec.predictions_with_neg->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(['system', 'human'], topn=5)
A:gensim.test.test_word2vec.predictions_out_of_vocab->gensim.models.word2vec.Word2Vec(sentences, min_count=1).predict_output_word(['some', 'random', 'words'], topn=5)
A:gensim.test.test_word2vec.kv_model_with_neg->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_word2vec.binary_model_with_neg->gensim.models.word2vec.Word2Vec()
A:gensim.test.test_word2vec.model_without_neg->gensim.models.word2vec.Word2Vec(sentences, min_count=1, negative=0)
A:gensim.test.test_word2vec.other_model->gensim.models.word2vec.Word2Vec(new_sentences, min_count=1)
A:gensim.test.test_word2vec.training_loss_val->gensim.models.word2vec.Word2Vec(sentences, min_count=1).get_latest_training_loss()
A:gensim.test.test_word2vec.distance->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wmdistance(sentence, sentence)
A:gensim.test.test_word2vec.distance1->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wmdistance(sentence1, sentence2)
A:gensim.test.test_word2vec.distance2->gensim.models.word2vec.Word2Vec(sentences, min_count=1).wmdistance(sentence2, sentence1)
A:gensim.test.test_word2vec.sentences->gensim.models.word2vec.PathLineSentences(test_file)
A:gensim.test.test_word2vec.test_file->os.path.join(datapath('PathLineSentences'), '1.txt')
gensim.test.test_word2vec.LeeCorpus(object)
gensim.test.test_word2vec.LeeCorpus.__iter__(self)
gensim.test.test_word2vec.TestWMD(unittest.TestCase)
gensim.test.test_word2vec.TestWMD.testIdenticalSentences(self)
gensim.test.test_word2vec.TestWMD.testNonzero(self)
gensim.test.test_word2vec.TestWMD.testSymmetry(self)
gensim.test.test_word2vec.TestWord2VecModel(unittest.TestCase)
gensim.test.test_word2vec.TestWord2VecModel.model_sanity(self,model,train=True)
gensim.test.test_word2vec.TestWord2VecModel.models_equal(self,model,model2)
gensim.test.test_word2vec.TestWord2VecModel.onlineSanity(self,model)
gensim.test.test_word2vec.TestWord2VecModel.testAccuracy(self)
gensim.test.test_word2vec.TestWord2VecModel.testBuildVocabFromFreq(self)
gensim.test.test_word2vec.TestWord2VecModel.testBuildVocabWarning(self,l)
gensim.test.test_word2vec.TestWord2VecModel.testDeleteTemporaryTrainingData(self)
gensim.test.test_word2vec.TestWord2VecModel.testEvaluateWordPairs(self)
gensim.test.test_word2vec.TestWord2VecModel.testLambdaRule(self)
gensim.test.test_word2vec.TestWord2VecModel.testLargeMmap(self)
gensim.test.test_word2vec.TestWord2VecModel.testLoadOldModel(self)
gensim.test.test_word2vec.TestWord2VecModel.testLoadOnClassError(self)
gensim.test.test_word2vec.TestWord2VecModel.testLoadPreKeyedVectorModel(self)
gensim.test.test_word2vec.TestWord2VecModel.testLoadPreKeyedVectorModelCFormat(self)
gensim.test.test_word2vec.TestWord2VecModel.testLocking(self)
gensim.test.test_word2vec.TestWord2VecModel.testNoTrainingCFormat(self)
gensim.test.test_word2vec.TestWord2VecModel.testNormalizeAfterTrainingData(self)
gensim.test.test_word2vec.TestWord2VecModel.testOnlineLearning(self)
gensim.test.test_word2vec.TestWord2VecModel.testOnlineLearningAfterSave(self)
gensim.test.test_word2vec.TestWord2VecModel.testParallel(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistence(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistenceKeyedVectorsFormatWithVocab(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistenceWithConstructorRule(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistenceWord2VecFormat(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistenceWord2VecFormatCombinationWithStandardPersistence(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistenceWord2VecFormatNonBinary(self)
gensim.test.test_word2vec.TestWord2VecModel.testPersistenceWord2VecFormatWithVocab(self)
gensim.test.test_word2vec.TestWord2VecModel.testPredictOutputWord(self)
gensim.test.test_word2vec.TestWord2VecModel.testPruneVocab(self)
gensim.test.test_word2vec.TestWord2VecModel.testRNG(self)
gensim.test.test_word2vec.TestWord2VecModel.testRule(self)
gensim.test.test_word2vec.TestWord2VecModel.testRuleWithMinCount(self)
gensim.test.test_word2vec.TestWord2VecModel.testScoring(self)
gensim.test.test_word2vec.TestWord2VecModel.testSimilarBy(self)
gensim.test.test_word2vec.TestWord2VecModel.testSimilarities(self)
gensim.test.test_word2vec.TestWord2VecModel.testSyn0NormNotSaved(self)
gensim.test.test_word2vec.TestWord2VecModel.testTooShortBinaryWord2VecFormat(self)
gensim.test.test_word2vec.TestWord2VecModel.testTooShortTextWord2VecFormat(self)
gensim.test.test_word2vec.TestWord2VecModel.testTotalWordCount(self)
gensim.test.test_word2vec.TestWord2VecModel.testTrainWarning(self,l)
gensim.test.test_word2vec.TestWord2VecModel.testTraining(self)
gensim.test.test_word2vec.TestWord2VecModel.testTrainingCbow(self)
gensim.test.test_word2vec.TestWord2VecModel.testTrainingCbowNegative(self)
gensim.test.test_word2vec.TestWord2VecModel.testTrainingSgNegative(self)
gensim.test.test_word2vec.TestWord2VecModel.testVocab(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_hs(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_hs_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_neg(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cbow_neg_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_compute_training_loss(self)
gensim.test.test_word2vec.TestWord2VecModel.test_cosmul(self)
gensim.test.test_word2vec.TestWord2VecModel.test_reset_from(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sentences_should_not_be_a_generator(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_hs(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_hs_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_neg(self)
gensim.test.test_word2vec.TestWord2VecModel.test_sg_neg_online(self)
gensim.test.test_word2vec.TestWord2VecModel.test_train_with_explicit_param(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators(unittest.TestCase)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.testLineSentenceWorksWithCompressedFile(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.testLineSentenceWorksWithFilename(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.testLineSentenceWorksWithNormalFile(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.testPathLineSentences(self)
gensim.test.test_word2vec.TestWord2VecSentenceIterators.testPathLineSentencesOneFile(self)
gensim.test.test_word2vec._rule(word,count,min_count)
gensim.test.test_word2vec.load_on_instance()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_phrases.py----------------------------------------
A:gensim.test.test_phrases.result->self.analyze_words(scores, s)
A:gensim.test.test_phrases.common_terms->frozenset()
A:gensim.test.test_phrases.bigram_word->b'_'.join(components)
A:gensim.test.test_phrases.analyzer->self.AnalysisTester(scores)
A:gensim.test.test_phrases.self.bigram->Phraser(bigram_phrases)
A:gensim.test.test_phrases.self.bigram_default->Phraser(bigram_default_phrases)
A:gensim.test.test_phrases.self.bigram_utf8->Phraser(bigram_utf8_phrases)
A:gensim.test.test_phrases.self.bigram_unicode->Phraser(bigram_unicode_phrases)
A:gensim.test.test_phrases.bigram_phrases->Phrases(self.sentences, min_count=1, threshold=1, common_terms=self.common_terms)
A:gensim.test.test_phrases.bigram_phraser->Phraser(bigram_phrases)
A:gensim.test.test_phrases.trigram_phrases->Phrases(bigram_phraser[self.sentences])
A:gensim.test.test_phrases.trigram_phraser->Phraser(trigram_phrases)
A:gensim.test.test_phrases.transformed->' '.join(self.bigram_utf8[self.sentences[1]])
A:gensim.test.test_phrases.bigram->Phrases(self.sentences, min_count=1, threshold=1, common_terms=self.common_terms)
A:gensim.test.test_phrases.seen_bigrams->set()
A:gensim.test.test_phrases.seen_scores->set()
A:gensim.test.test_phrases.phrased_sentence->next(bigram[test_sentences].__iter__())
A:gensim.test.test_phrases.bigram_loaded->gensim.models.phrases.Phraser.load(datapath('phraser-no-common-terms.pkl'))
A:gensim.test.test_phrases.phraser->Phraser(bigram_loaded)
A:gensim.test.test_phrases.bigram_default_phrases->Phrases(self.sentences, common_terms=self.common_terms)
A:gensim.test.test_phrases.bigram_utf8_phrases->Phrases(self.sentences, min_count=1, threshold=1, common_terms=self.common_terms)
A:gensim.test.test_phrases.bigram_unicode_phrases->Phrases(self.unicode_sentences, min_count=1, threshold=1, common_terms=self.common_terms)
A:gensim.test.test_phrases.min_count->float(bigram.min_count)
A:gensim.test.test_phrases.len_vocab->float(len(bigram.vocab))
A:gensim.test.test_phrases.graph->float(bigram.vocab[b'graph'])
A:gensim.test.test_phrases.data->float(bigram.vocab[b'data'])
A:gensim.test.test_phrases.data_and_graph->float(bigram.vocab[b'data_and_graph'])
A:gensim.test.test_phrases.human->float(bigram.vocab[b'human'])
A:gensim.test.test_phrases.interface->float(bigram.vocab[b'interface'])
A:gensim.test.test_phrases.human_interface->float(bigram.vocab[b'human_interface'])
gensim.test.test_phrases.CommonTermsPhrasesData
gensim.test.test_phrases.CommonTermsPhrasesData.gen_sentences(self)
gensim.test.test_phrases.PhrasesCommon
gensim.test.test_phrases.PhrasesCommon.setUp(self)
gensim.test.test_phrases.PhrasesCommon.testBigramConstruction(self)
gensim.test.test_phrases.PhrasesCommon.testBigramConstructionFromGenerator(self)
gensim.test.test_phrases.PhrasesCommon.testEmptyInputsOnBigramConstruction(self)
gensim.test.test_phrases.PhrasesCommon.testEmptyPhrasifiedSentencesIterator(self)
gensim.test.test_phrases.PhrasesCommon.testEncoding(self)
gensim.test.test_phrases.PhrasesCommon.testSentenceGeneration(self)
gensim.test.test_phrases.PhrasesCommon.testSentenceGenerationWithGenerator(self)
gensim.test.test_phrases.PhrasesData
gensim.test.test_phrases.PhrasesData.gen_sentences(self)
gensim.test.test_phrases.TestPhraseAnalysis(unittest.TestCase)
gensim.test.test_phrases.TestPhraseAnalysis.AnalysisTester(self,scores)
gensim.test.test_phrases.TestPhraseAnalysis.AnalysisTester.__init__(self,scores)
gensim.test.test_phrases.TestPhraseAnalysis.AnalysisTester.score_item(self,worda,wordb,components,scorer)
gensim.test.test_phrases.TestPhraseAnalysis.analyze(self,scores,sentence)
gensim.test.test_phrases.TestPhraseAnalysis.analyze_words(self,scores,sentence)
gensim.test.test_phrases.TestPhraseAnalysis.test_analysis_bigrams(self)
gensim.test.test_phrases.TestPhraseAnalysis.test_analysis_common_terms(self)
gensim.test.test_phrases.TestPhraseAnalysis.test_analysis_common_terms_in_between(self)
gensim.test.test_phrases.TestPhraseAnalysis.test_simple_analysis(self)
gensim.test.test_phrases.TestPhraserModel(PhrasesData,PhrasesCommon,unittest.TestCase)
gensim.test.test_phrases.TestPhraserModel.setUp(self)
gensim.test.test_phrases.TestPhraserModelCommonTerms(CommonTermsPhrasesData,TestPhraserModel)
gensim.test.test_phrases.TestPhraserModelCommonTerms.testEncoding(self)
gensim.test.test_phrases.TestPhraserPersistence(PhrasesData,unittest.TestCase)
gensim.test.test_phrases.TestPhraserPersistence.testSaveLoad(self)
gensim.test.test_phrases.TestPhraserPersistence.testSaveLoadCustomScorer(self)
gensim.test.test_phrases.TestPhraserPersistence.testSaveLoadNoCommonTerms(self)
gensim.test.test_phrases.TestPhraserPersistence.testSaveLoadNoScoring(self)
gensim.test.test_phrases.TestPhraserPersistence.testSaveLoadStringScoring(self)
gensim.test.test_phrases.TestPhrasesModel(PhrasesData,PhrasesCommon,unittest.TestCase)
gensim.test.test_phrases.TestPhrasesModel.testBadParameters(self)
gensim.test.test_phrases.TestPhrasesModel.testCustomScorer(self)
gensim.test.test_phrases.TestPhrasesModel.testExportPhrases(self)
gensim.test.test_phrases.TestPhrasesModel.testMultipleBigramsSingleEntry(self)
gensim.test.test_phrases.TestPhrasesModel.testPruning(self)
gensim.test.test_phrases.TestPhrasesModel.testScoringDefault(self)
gensim.test.test_phrases.TestPhrasesModel.testScoringNpmi(self)
gensim.test.test_phrases.TestPhrasesModel.test__getitem__(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms(CommonTermsPhrasesData,TestPhrasesModel)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.testCustomScorer(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.testEncoding(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.testExportPhrases(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.testMultipleBigramsSingleEntry(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.testScoringDefault(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.testScoringNpmi(self)
gensim.test.test_phrases.TestPhrasesModelCommonTerms.test__getitem__(self)
gensim.test.test_phrases.TestPhrasesPersistence(PhrasesData,unittest.TestCase)
gensim.test.test_phrases.TestPhrasesPersistence.testSaveLoad(self)
gensim.test.test_phrases.TestPhrasesPersistence.testSaveLoadCustomScorer(self)
gensim.test.test_phrases.TestPhrasesPersistence.testSaveLoadNoCommonTerms(self)
gensim.test.test_phrases.TestPhrasesPersistence.testSaveLoadNoScoring(self)
gensim.test.test_phrases.TestPhrasesPersistence.testSaveLoadStringScoring(self)
gensim.test.test_phrases.TestUtils(unittest.TestCase)
gensim.test.test_phrases.TestUtils.test_pseudocorpus_no_common_terms(self)
gensim.test.test_phrases.TestUtils.test_pseudocorpus_with_common_terms(self)
gensim.test.test_phrases.dumb_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_rpmodel.py----------------------------------------
A:gensim.test.test_rpmodel.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_rpmodel.model->gensim.models.rpmodel.RpModel(self.corpus, num_topics=2)
A:gensim.test.test_rpmodel.vec->gensim.matutils.sparse2full(transformed, 2)
A:gensim.test.test_rpmodel.expected->numpy.array([-0.70710677, 0.70710677])
A:gensim.test.test_rpmodel.fname->get_tmpfile('gensim_models.tst.gz')
A:gensim.test.test_rpmodel.model2->gensim.models.rpmodel.RpModel.load(fname, mmap=None)
gensim.test.test_rpmodel.TestRpModel(unittest.TestCase)
gensim.test.test_rpmodel.TestRpModel.setUp(self)
gensim.test.test_rpmodel.TestRpModel.testPersistence(self)
gensim.test.test_rpmodel.TestRpModel.testPersistenceCompressed(self)
gensim.test.test_rpmodel.TestRpModel.testTransform(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_ldamallet_wrapper.py----------------------------------------
A:gensim.test.test_ldamallet_wrapper.dictionary->Dictionary(common_texts)
A:gensim.test.test_ldamallet_wrapper.mallet_home->os.environ.get('MALLET_HOME', None)
A:gensim.test.test_ldamallet_wrapper.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_ldamallet_wrapper.self.model->gensim.models.wrappers.ldamallet.LdaMallet(self.mallet_path, corpus, id2word=dictionary, num_topics=2, iterations=1)
A:gensim.test.test_ldamallet_wrapper.model->gensim.models.wrappers.ldamallet.LdaMallet(self.mallet_path, self.corpus, num_topics=2, iterations=100)
A:gensim.test.test_ldamallet_wrapper.vec->gensim.matutils.sparse2full(transformed, 2)
A:gensim.test.test_ldamallet_wrapper.passed->numpy.allclose(sorted(vec), sorted(expected), atol=0.01)
A:gensim.test.test_ldamallet_wrapper.tm1->gensim.models.wrappers.ldamallet.LdaMallet(self.mallet_path, corpus=corpus, num_topics=2, id2word=dictionary)
A:gensim.test.test_ldamallet_wrapper.tm2->gensim.models.wrappers.ldamallet.malletmodel2ldamodel(tm1)
A:gensim.test.test_ldamallet_wrapper.fname->get_tmpfile('gensim_models_lda_mallet.tst.gz')
A:gensim.test.test_ldamallet_wrapper.model2->gensim.models.ldamodel.LdaModel.load(fname, mmap='r')
gensim.test.test_ldamallet_wrapper.TestLdaMallet(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.setUp(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testLargeMmap(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testLargeMmapCompressed(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testMallet2Model(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testPersistence(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testPersistenceCompressed(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testSparseTransform(self)
gensim.test.test_ldamallet_wrapper.TestLdaMallet.testTransform(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_hdpmodel.py----------------------------------------
A:gensim.test.test_hdpmodel.dictionary->Dictionary(common_texts)
A:gensim.test.test_hdpmodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_hdpmodel.self.model->self.class_(corpus, id2word=dictionary, random_state=np.random.seed(0))
A:gensim.test.test_hdpmodel.(prob, word)->results[1].split('+')[0].split('*')
A:gensim.test.test_hdpmodel.ldam->self.model.suggested_lda_model()
gensim.test.test_hdpmodel.TestHdpModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_hdpmodel.TestHdpModel.setUp(self)
gensim.test.test_hdpmodel.TestHdpModel.testLDAmodel(self)
gensim.test.test_hdpmodel.TestHdpModel.testTopicValues(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_ldamodel.py----------------------------------------
A:gensim.test.test_ldamodel.dictionary->Dictionary(common_texts)
A:gensim.test.test_ldamodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_ldamodel.self.model->self.class_(corpus, id2word=dictionary, num_topics=2, passes=100)
A:gensim.test.test_ldamodel.model->self.class_.load(lda_3_0_1_fname)
A:gensim.test.test_ldamodel.vec->gensim.matutils.sparse2full(transformed, 2)
A:gensim.test.test_ldamodel.passed->numpy.allclose(sorted(vec), sorted(expected), atol=0.1)
A:gensim.test.test_ldamodel.model1->self.class_(corpus, id2word=dictionary, eta='symmetric', passes=10)
A:gensim.test.test_ldamodel.modelauto->self.class_(corpus, id2word=dictionary, eta='auto', passes=10)
A:gensim.test.test_ldamodel.kwargs->dict(id2word=dictionary, num_topics=2, eta=None)
A:gensim.test.test_ldamodel.kwargs['alpha']->numpy.array([0.3, 0.3])
A:gensim.test.test_ldamodel.num_terms->len(dictionary)
A:gensim.test.test_ldamodel.kwargs['eta']->numpy.array([[0.5] * len(dictionary)] * 2).reshape(tuple(reversed(testeta.shape)))
A:gensim.test.test_ldamodel.testeta->numpy.array([[0.5] * len(dictionary)] * 2)
A:gensim.test.test_ldamodel.top_topics->self.model.top_topics(self.corpus)
A:gensim.test.test_ldamodel.topic_terms->self.model.get_topic_terms(1)
A:gensim.test.test_ldamodel.doc_topics->self.class_.load(lda_3_0_1_fname).get_document_topics(self.corpus)
A:gensim.test.test_ldamodel.all_topics->self.class_.load(lda_3_0_1_fname).get_document_topics(self.corpus, minimum_probability=0.8, minimum_phi_value=1.0, per_word_topics=True)
A:gensim.test.test_ldamodel.(doc_topics, word_topics, word_phis)->self.class_.load(lda_3_0_1_fname).get_document_topics(self.corpus[1], per_word_topics=True)
A:gensim.test.test_ldamodel.result->self.class_.load(lda_3_0_1_fname).get_term_topics(str(model.id2word[2]))
A:gensim.test.test_ldamodel.test_rhots->list()
A:gensim.test.test_ldamodel.msg->', '.join((str(x) for x in [passes, model.num_updates, model.state.numdocs]))
A:gensim.test.test_ldamodel.fname->get_tmpfile('gensim_models_lda.tst.gz')
A:gensim.test.test_ldamodel.model2->self.class_.load(fname, mmap='r')
A:gensim.test.test_ldamodel.fname_model_2_7->datapath('ldamodel_python_2_7')
A:gensim.test.test_ldamodel.model_2_7->self.class_.load(fname_model_2_7)
A:gensim.test.test_ldamodel.fname_model_3_5->datapath('ldamodel_python_3_5')
A:gensim.test.test_ldamodel.model_3_5->self.class_.load(fname_model_3_5)
A:gensim.test.test_ldamodel.id2word_2_7->dict(model_2_7.id2word.iteritems())
A:gensim.test.test_ldamodel.id2word_3_5->dict(model_3_5.id2word.iteritems())
A:gensim.test.test_ldamodel.pre_0_13_2_fname->datapath('pre_0_13_2_model')
A:gensim.test.test_ldamodel.model_pre_0_13_2->self.class_.load(pre_0_13_2_fname)
A:gensim.test.test_ldamodel.model_topics->self.class_.load(pre_0_13_2_fname).print_topics(num_topics=2, num_words=3)
A:gensim.test.test_ldamodel.post_0_13_2_fname->get_tmpfile('gensim_models_lda_post_0_13_2_model.tst')
A:gensim.test.test_ldamodel.model_post_0_13_2->self.class_.load(post_0_13_2_fname)
A:gensim.test.test_ldamodel.model_topics_new->self.class_.load(post_0_13_2_fname).print_topics(num_topics=2, num_words=3)
A:gensim.test.test_ldamodel.lda_3_0_1_fname->datapath('lda_3_0_1_model')
gensim.test.test_ldamodel.TestLdaModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_ldamodel.TestLdaModel.setUp(self)
gensim.test.test_ldamodel.TestLdaModel.testAlpha(self)
gensim.test.test_ldamodel.TestLdaModel.testAlphaAuto(self)
gensim.test.test_ldamodel.TestLdaModel.testDtypeBackwardCompatibility(self)
gensim.test.test_ldamodel.TestLdaModel.testEta(self)
gensim.test.test_ldamodel.TestLdaModel.testEtaAuto(self)
gensim.test.test_ldamodel.TestLdaModel.testGetDocumentTopics(self)
gensim.test.test_ldamodel.TestLdaModel.testGetTopicTerms(self)
gensim.test.test_ldamodel.TestLdaModel.testLargeMmap(self)
gensim.test.test_ldamodel.TestLdaModel.testLargeMmapCompressed(self)
gensim.test.test_ldamodel.TestLdaModel.testModelCompatibilityWithPythonVersions(self)
gensim.test.test_ldamodel.TestLdaModel.testPasses(self)
gensim.test.test_ldamodel.TestLdaModel.testPersistence(self)
gensim.test.test_ldamodel.TestLdaModel.testPersistenceCompressed(self)
gensim.test.test_ldamodel.TestLdaModel.testPersistenceIgnore(self)
gensim.test.test_ldamodel.TestLdaModel.testRandomStateBackwardCompatibility(self)
gensim.test.test_ldamodel.TestLdaModel.testTermTopics(self)
gensim.test.test_ldamodel.TestLdaModel.testTopTopics(self)
gensim.test.test_ldamodel.TestLdaModel.testTransform(self)
gensim.test.test_ldamodel.TestLdaMulticore(TestLdaModel)
gensim.test.test_ldamodel.TestLdaMulticore.setUp(self)
gensim.test.test_ldamodel.TestLdaMulticore.testAlphaAuto(self)
gensim.test.test_ldamodel.testRandomState()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_similarities.py----------------------------------------
A:gensim.test.test_similarities.index->AnnoyIndexer(model, 10)
A:gensim.test.test_similarities.expected->gensim.matutils.sparse2full(expected, len(index))
A:gensim.test.test_similarities.sims->gensim.matutils.sparse2full(sims, len(index))
A:gensim.test.test_similarities.vec_scipy->scipy.sparse.csr_matrix(vec)
A:gensim.test.test_similarities.vec_scipy_clipped->gensim.matutils.scipy2scipy_clipped(vec_scipy, topn=3)
A:gensim.test.test_similarities.matrix_scipy->scipy.sparse.csr_matrix([vec] * 3)
A:gensim.test.test_similarities.matrix_scipy_clipped->gensim.matutils.scipy2scipy_clipped(matrix_scipy, topn=3)
A:gensim.test.test_similarities.fname->get_tmpfile('gensim_similarities.tst.pkl')
A:gensim.test.test_similarities.index2->AnnoyIndexer()
A:gensim.test.test_similarities.index.index->AnnoyIndexer(model, 10).index.todense()
A:gensim.test.test_similarities.index2.index->AnnoyIndexer().index.todense()
A:gensim.test.test_similarities.self.w2v_model->Word2Vec(texts, min_count=1)
A:gensim.test.test_similarities.self.dictionary->Dictionary(texts)
A:gensim.test.test_similarities.similarity_matrix->scipy.sparse.identity(12, format='lil')
A:gensim.test.test_similarities.self.similarity_matrix->scipy.sparse.identity(12, format='lil').tocsc()
A:gensim.test.test_similarities.query->self.dictionary.doc2bow(texts[0])
A:gensim.test.test_similarities.num_features->len(dictionary)
A:gensim.test.test_similarities.model->gensim.models.KeyedVectors.load_word2vec_format(keyVectors_file)
A:gensim.test.test_similarities.keyVectors_file->datapath('lee_fasttext.vec')
A:gensim.test.test_similarities.test_index->AnnoyIndexer()
A:gensim.test.test_similarities.approx_neighbors->self.model.docvecs.most_similar([self.vector], topn=5, indexer=self.index)
A:gensim.test.test_similarities.exact_neighbors->self.model.docvecs.most_similar(positive=[self.vector], topn=5)
A:gensim.test.test_similarities.self.model->gensim.models.doc2vec.Doc2Vec(sentences, min_count=1)
A:gensim.test.test_similarities.self.index->AnnoyIndexer(self.model, 300)
A:gensim.test.test_similarities.self.test_index->AnnoyIndexer()
A:gensim.test.test_similarities.self.index2->AnnoyIndexer()
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer(unittest.TestCase)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.setUp(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.testApproxNeighborsMatchExact(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.testDocumentIsSimilarToItself(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.testLoadNotExist(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.testSave(self)
gensim.test.test_similarities.TestDoc2VecAnnoyIndexer.testSaveLoad(self)
gensim.test.test_similarities.TestMatrixSimilarity(unittest.TestCase,_TestSimilarityABC)
gensim.test.test_similarities.TestMatrixSimilarity.setUp(self)
gensim.test.test_similarities.TestSimilarity(unittest.TestCase,_TestSimilarityABC)
gensim.test.test_similarities.TestSimilarity.factoryMethod(self)
gensim.test.test_similarities.TestSimilarity.setUp(self)
gensim.test.test_similarities.TestSimilarity.testChunksize(self)
gensim.test.test_similarities.TestSimilarity.testMmapCompressed(self)
gensim.test.test_similarities.TestSimilarity.testReopen(self)
gensim.test.test_similarities.TestSimilarity.testSharding(self)
gensim.test.test_similarities.TestSoftCosineSimilarity(unittest.TestCase,_TestSimilarityABC)
gensim.test.test_similarities.TestSoftCosineSimilarity.factoryMethod(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.setUp(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.testChunking(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.testFull(self,num_best=None)
gensim.test.test_similarities.TestSoftCosineSimilarity.testIter(self)
gensim.test.test_similarities.TestSoftCosineSimilarity.testNonIncreasing(self)
gensim.test.test_similarities.TestSparseMatrixSimilarity(unittest.TestCase,_TestSimilarityABC)
gensim.test.test_similarities.TestSparseMatrixSimilarity.setUp(self)
gensim.test.test_similarities.TestSparseMatrixSimilarity.testMaintainSparsity(self)
gensim.test.test_similarities.TestSparseMatrixSimilarity.testMaintainSparsityWithNumBest(self)
gensim.test.test_similarities.TestWmdSimilarity(unittest.TestCase,_TestSimilarityABC)
gensim.test.test_similarities.TestWmdSimilarity.factoryMethod(self)
gensim.test.test_similarities.TestWmdSimilarity.setUp(self)
gensim.test.test_similarities.TestWmdSimilarity.testChunking(self)
gensim.test.test_similarities.TestWmdSimilarity.testFull(self,num_best=None)
gensim.test.test_similarities.TestWmdSimilarity.testIter(self)
gensim.test.test_similarities.TestWmdSimilarity.testNonIncreasing(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer(unittest.TestCase)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertApproxNeighborsMatchExact(self,model,wv,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertIndexSaved(self,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertLoadedIndexEqual(self,index,model)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.assertVectorIsSimilarToItself(self,wv,index)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.setUp(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.testAnnoyIndexingOfKeyedVectors(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.testFastText(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.testLoadMissingRaisesError(self)
gensim.test.test_similarities.TestWord2VecAnnoyIndexer.testWord2Vec(self)
gensim.test.test_similarities._TestSimilarityABC(object)
gensim.test.test_similarities._TestSimilarityABC.factoryMethod(self)
gensim.test.test_similarities._TestSimilarityABC.testChunking(self)
gensim.test.test_similarities._TestSimilarityABC.testEmptyQuery(self)
gensim.test.test_similarities._TestSimilarityABC.testFull(self,num_best=None,shardsize=100)
gensim.test.test_similarities._TestSimilarityABC.testIter(self)
gensim.test.test_similarities._TestSimilarityABC.testLarge(self)
gensim.test.test_similarities._TestSimilarityABC.testLargeCompressed(self)
gensim.test.test_similarities._TestSimilarityABC.testMmap(self)
gensim.test.test_similarities._TestSimilarityABC.testMmapCompressed(self)
gensim.test.test_similarities._TestSimilarityABC.testNumBest(self)
gensim.test.test_similarities._TestSimilarityABC.testPersistency(self)
gensim.test.test_similarities._TestSimilarityABC.testPersistencyCompressed(self)
gensim.test.test_similarities._TestSimilarityABC.test_full2sparse_clipped(self)
gensim.test.test_similarities._TestSimilarityABC.test_scipy2scipy_clipped(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_summarization.py----------------------------------------
A:gensim.test.test_summarization.pre_path->os.path.join(os.path.dirname(__file__), 'test_data')
A:gensim.test.test_summarization.text->self._get_text_from_test_data('testlowdistinctwords.txt')
A:gensim.test.test_summarization.generated_summary->summarize(text)
A:gensim.test.test_summarization.summary->summary.split('\n').split('\n')
A:gensim.test.test_summarization.sentences->self._get_text_from_test_data('testlowdistinctwords.txt').split('\n')
A:gensim.test.test_summarization.dictionary->Dictionary(tokens)
A:gensim.test.test_summarization.selected_documents->summarize_corpus(corpus)
A:gensim.test.test_summarization.selected_docs->summarize_corpus(corpus, ratio=ratio)
A:gensim.test.test_summarization.expected_summary_length->int(len(corpus) * ratio)
A:gensim.test.test_summarization.kwds->mz_keywords(text)
A:gensim.test.test_summarization.kwds_u->keywords(utils.to_unicode(text))
A:gensim.test.test_summarization.kwds_lst->mz_keywords(text, split=True)
A:gensim.test.test_summarization.kwds_auto->mz_keywords(text, scores=True, weighted=False, threshold='auto')
gensim.test.test_summarization.TestSummarizationTest(unittest.TestCase)
gensim.test.test_summarization.TestSummarizationTest._get_text_from_test_data(self,file)
gensim.test.test_summarization.TestSummarizationTest.test_corpus_summarization(self)
gensim.test.test_summarization.TestSummarizationTest.test_corpus_summarization_is_not_empty_list_on_short_input_text(self)
gensim.test.test_summarization.TestSummarizationTest.test_corpus_summarization_ratio(self)
gensim.test.test_summarization.TestSummarizationTest.test_empty_corpus_summarization_is_empty_list(self)
gensim.test.test_summarization.TestSummarizationTest.test_empty_text_summarization_is_empty_string(self)
gensim.test.test_summarization.TestSummarizationTest.test_empty_text_summarization_with_split_is_empty_list(self)
gensim.test.test_summarization.TestSummarizationTest.test_keywords_runs(self)
gensim.test.test_summarization.TestSummarizationTest.test_low_distinct_words_corpus_summarization_is_empty_list(self)
gensim.test.test_summarization.TestSummarizationTest.test_low_distinct_words_summarization_is_empty_string(self)
gensim.test.test_summarization.TestSummarizationTest.test_low_distinct_words_summarization_with_split_is_empty_list(self)
gensim.test.test_summarization.TestSummarizationTest.test_mz_keywords(self)
gensim.test.test_summarization.TestSummarizationTest.test_repeated_keywords(self)
gensim.test.test_summarization.TestSummarizationTest.test_summary_from_unrelated_sentences(self)
gensim.test.test_summarization.TestSummarizationTest.test_text_summarization(self)
gensim.test.test_summarization.TestSummarizationTest.test_text_summarization_on_short_input_text_is_empty_string(self)
gensim.test.test_summarization.TestSummarizationTest.test_text_summarization_raises_exception_on_single_input_sentence(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_utils.py----------------------------------------
A:gensim.test.test_utils.result->gensim.utils.is_corpus(noCorpus)
A:gensim.test.test_utils.potentials->list()
A:gensim.test.test_utils.file_obj->open(datapath('testcorpus.mm'))
A:gensim.test.test_utils.sampled_dict->gensim.utils.sample_dict(d, 2, False)
A:gensim.test.test_utils.sampled_dict_random->gensim.utils.sample_dict(d, 2)
A:gensim.test.test_utils.arr10_5->numpy.array([[0, 1, 2, 3, 4], [1, 2, 3, 4, 5], [2, 3, 4, 5, 6], [3, 4, 5, 6, 7], [4, 5, 6, 7, 8], [5, 6, 7, 8, 9]])
A:gensim.test.test_utils.out->gensim.utils.iter_windows(texts, 3)
A:gensim.test.test_utils.expected->numpy.array([input_arr.copy()])
A:gensim.test.test_utils.input_arr->numpy.array(['this', 'is', 'test'], dtype='object')
A:gensim.test.test_utils.windows->list(utils.iter_windows(texts, 2, copy=True))
gensim.test.test_utils.TestIsCorpus(unittest.TestCase)
gensim.test.test_utils.TestIsCorpus.test_None(self)
gensim.test.test_utils.TestIsCorpus.test_int_tuples(self)
gensim.test.test_utils.TestIsCorpus.test_invalid_formats(self)
gensim.test.test_utils.TestIsCorpus.test_simple_lists_of_tuples(self)
gensim.test.test_utils.TestSampleDict(unittest.TestCase)
gensim.test.test_utils.TestSampleDict.test_sample_dict(self)
gensim.test.test_utils.TestUtils(unittest.TestCase)
gensim.test.test_utils.TestUtils.test_decode_entities(self)
gensim.test.test_utils.TestUtils.test_open_file_existent_file(self)
gensim.test.test_utils.TestUtils.test_open_file_existent_file_object(self)
gensim.test.test_utils.TestUtils.test_open_file_non_existent_file(self)
gensim.test.test_utils.TestUtils.test_open_file_non_existent_file_object(self)
gensim.test.test_utils.TestWindowing(unittest.TestCase)
gensim.test.test_utils.TestWindowing._assert_arrays_equal(self,expected,actual)
gensim.test.test_utils.TestWindowing.test_flatten_nested(self)
gensim.test.test_utils.TestWindowing.test_flatten_not_nested(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_include_below_window_size(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_list_texts(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_uses_views(self)
gensim.test.test_utils.TestWindowing.test_iter_windows_with_copy(self)
gensim.test.test_utils.TestWindowing.test_strided_windows1(self)
gensim.test.test_utils.TestWindowing.test_strided_windows2(self)
gensim.test.test_utils.TestWindowing.test_strided_windows_window_size_equals_size(self)
gensim.test.test_utils.TestWindowing.test_strided_windows_window_size_exceeds_size(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_corpora_hashdictionary.py----------------------------------------
A:gensim.test.test_corpora_hashdictionary.d->HashDictionary(['žloťoučký koníček'.split(), 'Малйж обльйквюэ ат эжт'.split()])
A:gensim.test.test_corpora_hashdictionary.tmpf->get_tmpfile('dict_test.txt.bz2')
A:gensim.test.test_corpora_hashdictionary.d2->HashDictionary(['žloťoučký koníček'.split(), 'Малйж обльйквюэ ат эжт'.split()]).load(tmpf)
gensim.test.test_corpora_hashdictionary.TestHashDictionary(unittest.TestCase)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.setUp(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testBuild(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testDebugMode(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testDocFreqAndToken2IdForSeveralDocsWithOneWord(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testDocFreqForOneDocWithSeveralWord(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testDocFreqOneDoc(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testFilter(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.testRange(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_saveAsText(self)
gensim.test.test_corpora_hashdictionary.TestHashDictionary.test_saveAsTextBz2(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_sklearn_api.py----------------------------------------
A:gensim.test.test_sklearn_api.dictionary->Dictionary(texts)
A:gensim.test.test_sklearn_api.dictionary_new->Dictionary(texts_new)
A:gensim.test.test_sklearn_api.dictionary_ldaseq->Dictionary(texts_ldaseq)
A:gensim.test.test_sklearn_api.self.model->PhrasesTransformer(min_count=1, threshold=0.9, scoring=dumb_scorer)
A:gensim.test.test_sklearn_api.bow->LsiTransformer(id2word=dictionary, num_topics=2).id2word.doc2bow(texts_new)
A:gensim.test.test_sklearn_api.matrix->HdpTransformer(id2word=id2word).fit_transform(doc)
A:gensim.test.test_sklearn_api.transformed->self.model.transform(doc)
A:gensim.test.test_sklearn_api.expected->numpy.array([1.39, 0.0])
A:gensim.test.test_sklearn_api.passed->numpy.allclose(vec_transformer_api, vec_gensim_model, atol=0.1)
A:gensim.test.test_sklearn_api.gensim_ldamodel->gensim.models.LdaModel(corpus=corpus, id2word=dictionary, num_topics=10, passes=100, minimum_probability=0, random_state=numpy.random.seed(0))
A:gensim.test.test_sklearn_api.matrix_transformer_api->self.model.transform(bow)
A:gensim.test.test_sklearn_api.matrix_gensim_model_dense->gensim.matutils.sparse2full(matrix_gensim_model, 10)
A:gensim.test.test_sklearn_api.arr->numpy.array([[1, 2, 0], [0, 0, 3], [1, 0, 0]])
A:gensim.test.test_sklearn_api.sarr->scipy.sparse.csr_matrix(arr)
A:gensim.test.test_sklearn_api.newmodel->LdaTransformer(num_topics=2, passes=100)
A:gensim.test.test_sklearn_api.transformed_vec->LdaTransformer(num_topics=2, passes=100).transform(bow)
A:gensim.test.test_sklearn_api.expected_vec->numpy.array([0.12843782, 0.87156218])
A:gensim.test.test_sklearn_api.model->HdpTransformer(id2word=id2word)
A:gensim.test.test_sklearn_api.compressed_content->f.read()
A:gensim.test.test_sklearn_api.uncompressed_content->codecs.decode(compressed_content, 'zlib_codec')
A:gensim.test.test_sklearn_api.cache->pickle.loads(uncompressed_content)
A:gensim.test.test_sklearn_api.id2word->Dictionary([x.split() for x in data.data])
A:gensim.test.test_sklearn_api.clf->sklearn.linear_model.LogisticRegression(penalty='l2', C=0.1)
A:gensim.test.test_sklearn_api.text_lda->Pipeline([('features', model), ('classifier', clf)])
A:gensim.test.test_sklearn_api.score->Pipeline([('features', model), ('classifier', clf)]).score(corpus, data.target)
A:gensim.test.test_sklearn_api.model_params->self.model.get_params()
A:gensim.test.test_sklearn_api.model_dump->pickle.dumps(self.model)
A:gensim.test.test_sklearn_api.model_load->pickle.loads(model_dump)
A:gensim.test.test_sklearn_api.loaded_bow->pickle.loads(model_dump).id2word.doc2bow(texts_new)
A:gensim.test.test_sklearn_api.loaded_matrix->pickle.loads(model_dump).transform(loaded_bow)
A:gensim.test.test_sklearn_api.original_bow->self.model.id2word.doc2bow(texts_new)
A:gensim.test.test_sklearn_api.original_matrix->self.model.transform(original_bow)
A:gensim.test.test_sklearn_api.lda_wrapper->LdaTransformer(id2word=dictionary, num_topics=2, passes=100, minimum_probability=0, random_state=numpy.random.seed(0))
A:gensim.test.test_sklearn_api.text_lsi->Pipeline([('features', model), ('classifier', clf)])
A:gensim.test.test_sklearn_api.lsi_wrapper->LsiTransformer(id2word=dictionary, num_topics=2)
A:gensim.test.test_sklearn_api.transformed_vecs->self.model.transform(doc)
A:gensim.test.test_sklearn_api.text_ldaseq->Pipeline([('features', model), ('classifier', clf)])
A:gensim.test.test_sklearn_api.loaded_transformed_vecs->pickle.loads(model_dump).transform(doc)
A:gensim.test.test_sklearn_api.original_transformed_vecs->self.model.transform(doc)
A:gensim.test.test_sklearn_api.ldaseq_wrapper->LdaSeqTransformer(num_topics=2)
A:gensim.test.test_sklearn_api.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_sklearn_api.text_rp->Pipeline([('features', model), ('classifier', clf)])
A:gensim.test.test_sklearn_api.rpmodel_wrapper->RpTransformer(num_topics=2)
A:gensim.test.test_sklearn_api.gensim_w2vmodel->gensim.models.Word2Vec(texts, size=10, min_count=0, seed=42)
A:gensim.test.test_sklearn_api.vec_transformer_api->self.model.transform(doc)
A:gensim.test.test_sklearn_api.text_w2v->Pipeline([('features', model), ('classifier', clf)])
A:gensim.test.test_sklearn_api.w2vmodel_wrapper->W2VTransformer(size=10, min_count=0, seed=42)
A:gensim.test.test_sklearn_api.author_topics->self.model.transform(author_list)
A:gensim.test.test_sklearn_api.jill_topics->self.model.transform('jill')
A:gensim.test.test_sklearn_api.output_topics->self.model.transform('sally')
A:gensim.test.test_sklearn_api.clstr->sklearn.cluster.MiniBatchKMeans(n_clusters=2)
A:gensim.test.test_sklearn_api.text_atm->Pipeline([('features', model), ('cluster', clstr)])
A:gensim.test.test_sklearn_api.ret_val->Pipeline([('features', model), ('cluster', clstr)]).predict(author_list)
A:gensim.test.test_sklearn_api.loaded_author_topics->pickle.loads(model_dump).transform(author_list)
A:gensim.test.test_sklearn_api.original_author_topics->self.model.transform(author_list)
A:gensim.test.test_sklearn_api.atmodel_wrapper->AuthorTopicTransformer(id2word=dictionary, author2doc=author2doc, num_topics=10, passes=100)
A:gensim.test.test_sklearn_api.gensim_d2vmodel->gensim.models.Doc2Vec(d2v_sentences, min_count=1)
A:gensim.test.test_sklearn_api.d2vmodel_wrapper->D2VTransformer(min_count=1)
A:gensim.test.test_sklearn_api.text2bow_model->Text2BowTransformer()
A:gensim.test.test_sklearn_api.lda_model->LdaTransformer(num_topics=2, passes=10, minimum_probability=0, random_state=numpy.random.seed(0))
A:gensim.test.test_sklearn_api.text2bow_wrapper->Text2BowTransformer()
A:gensim.test.test_sklearn_api.transformed_doc->self.model.transform(doc)
A:gensim.test.test_sklearn_api.transformed_docs->self.model.transform(docs)
A:gensim.test.test_sklearn_api.tfidf_model->TfIdfTransformer()
A:gensim.test.test_sklearn_api.text_tfidf->Pipeline([('tfidf_model', tfidf_model), ('ldamodel', lda_model), ('classifier', clf)])
A:gensim.test.test_sklearn_api.loaded_transformed_doc->pickle.loads(model_dump).transform(doc)
A:gensim.test.test_sklearn_api.original_transformed_doc->self.model.transform(doc)
A:gensim.test.test_sklearn_api.tfidf_wrapper->TfIdfTransformer()
A:gensim.test.test_sklearn_api.hdp_wrapper->HdpTransformer(id2word=dictionary)
A:gensim.test.test_sklearn_api.loaded_phrase_tokens->pickle.loads(model_dump).transform(doc)
A:gensim.test.test_sklearn_api.original_phrase_tokens->self.model.transform(doc)
A:gensim.test.test_sklearn_api.phrases_transformer->PhrasesTransformer()
gensim.test.test_sklearn_api.TestAuthorTopicWrapper(unittest.TestCase)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.setUp(self)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.testPartialFit(self)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.testPersistence(self)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.testPipeline(self)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.testSetGetParams(self)
gensim.test.test_sklearn_api.TestAuthorTopicWrapper.testTransform(self)
gensim.test.test_sklearn_api.TestD2VTransformer(unittest.TestCase)
gensim.test.test_sklearn_api.TestD2VTransformer.setUp(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testConsistencyWithGensimModel(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testFitTransform(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testPersistence(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testPipeline(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testSetGetParams(self)
gensim.test.test_sklearn_api.TestD2VTransformer.testTransform(self)
gensim.test.test_sklearn_api.TestHdpTransformer(unittest.TestCase)
gensim.test.test_sklearn_api.TestHdpTransformer.setUp(self)
gensim.test.test_sklearn_api.TestHdpTransformer.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestHdpTransformer.testPersistence(self)
gensim.test.test_sklearn_api.TestHdpTransformer.testPipeline(self)
gensim.test.test_sklearn_api.TestHdpTransformer.testSetGetParams(self)
gensim.test.test_sklearn_api.TestHdpTransformer.testTransform(self)
gensim.test.test_sklearn_api.TestLdaSeqWrapper(unittest.TestCase)
gensim.test.test_sklearn_api.TestLdaSeqWrapper.setUp(self)
gensim.test.test_sklearn_api.TestLdaSeqWrapper.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestLdaSeqWrapper.testPersistence(self)
gensim.test.test_sklearn_api.TestLdaSeqWrapper.testPipeline(self)
gensim.test.test_sklearn_api.TestLdaSeqWrapper.testSetGetParams(self)
gensim.test.test_sklearn_api.TestLdaSeqWrapper.testTransform(self)
gensim.test.test_sklearn_api.TestLdaWrapper(unittest.TestCase)
gensim.test.test_sklearn_api.TestLdaWrapper.setUp(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testCSRMatrixConversion(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testConsistencyWithGensimModel(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testPartialFit(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testPersistence(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testPipeline(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testSetGetParams(self)
gensim.test.test_sklearn_api.TestLdaWrapper.testTransform(self)
gensim.test.test_sklearn_api.TestLsiWrapper(unittest.TestCase)
gensim.test.test_sklearn_api.TestLsiWrapper.setUp(self)
gensim.test.test_sklearn_api.TestLsiWrapper.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestLsiWrapper.testPartialFit(self)
gensim.test.test_sklearn_api.TestLsiWrapper.testPersistence(self)
gensim.test.test_sklearn_api.TestLsiWrapper.testPipeline(self)
gensim.test.test_sklearn_api.TestLsiWrapper.testSetGetParams(self)
gensim.test.test_sklearn_api.TestLsiWrapper.testTransform(self)
gensim.test.test_sklearn_api.TestPhrasesTransformer(unittest.TestCase)
gensim.test.test_sklearn_api.TestPhrasesTransformer.setUp(self)
gensim.test.test_sklearn_api.TestPhrasesTransformer.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestPhrasesTransformer.testPartialFit(self)
gensim.test.test_sklearn_api.TestPhrasesTransformer.testPersistence(self)
gensim.test.test_sklearn_api.TestPhrasesTransformer.testSetGetParams(self)
gensim.test.test_sklearn_api.TestPhrasesTransformer.testTransform(self)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer(unittest.TestCase)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer.setUp(self)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer.testPartialFit(self)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer.testPersistence(self)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer.testSetGetParams(self)
gensim.test.test_sklearn_api.TestPhrasesTransformerCustomScorer.testTransform(self)
gensim.test.test_sklearn_api.TestRpWrapper(unittest.TestCase)
gensim.test.test_sklearn_api.TestRpWrapper.setUp(self)
gensim.test.test_sklearn_api.TestRpWrapper.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestRpWrapper.testPersistence(self)
gensim.test.test_sklearn_api.TestRpWrapper.testPipeline(self)
gensim.test.test_sklearn_api.TestRpWrapper.testSetGetParams(self)
gensim.test.test_sklearn_api.TestRpWrapper.testTransform(self)
gensim.test.test_sklearn_api.TestText2BowTransformer(unittest.TestCase)
gensim.test.test_sklearn_api.TestText2BowTransformer.setUp(self)
gensim.test.test_sklearn_api.TestText2BowTransformer.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestText2BowTransformer.testPersistence(self)
gensim.test.test_sklearn_api.TestText2BowTransformer.testPipeline(self)
gensim.test.test_sklearn_api.TestText2BowTransformer.testSetGetParams(self)
gensim.test.test_sklearn_api.TestText2BowTransformer.testTransform(self)
gensim.test.test_sklearn_api.TestTfIdfTransformer(unittest.TestCase)
gensim.test.test_sklearn_api.TestTfIdfTransformer.setUp(self)
gensim.test.test_sklearn_api.TestTfIdfTransformer.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestTfIdfTransformer.testPersistence(self)
gensim.test.test_sklearn_api.TestTfIdfTransformer.testPipeline(self)
gensim.test.test_sklearn_api.TestTfIdfTransformer.testSetGetParams(self)
gensim.test.test_sklearn_api.TestTfIdfTransformer.testTransform(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper(unittest.TestCase)
gensim.test.test_sklearn_api.TestWord2VecWrapper.setUp(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper.testConsistencyWithGensimModel(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper.testModelNotFitted(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper.testPersistence(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper.testPipeline(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper.testSetGetParams(self)
gensim.test.test_sklearn_api.TestWord2VecWrapper.testTransform(self)
gensim.test.test_sklearn_api.dumb_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_miislita.py----------------------------------------
A:gensim.test.test_miislita.logger->logging.getLogger('test_miislita')
A:gensim.test.test_miislita.stoplist->set('for a of the and to in on'.split())
A:gensim.test.test_miislita.self.length->sum((1 for _ in self.get_texts()))
A:gensim.test.test_miislita.miislita->CorpusMiislita(datapath('miIslita.cor'))
A:gensim.test.test_miislita.ftmp->get_tmpfile('test_textcorpus.mm')
A:gensim.test.test_miislita.miislita2->CorpusMiislita.load(tmpf)
A:gensim.test.test_miislita.corpusname->datapath('miIslita.cor')
A:gensim.test.test_miislita.tmpf->get_tmpfile('tc_test.cpickle')
A:gensim.test.test_miislita.tfidf->gensim.models.TfidfModel(miislita, miislita.dictionary, normalize=False)
A:gensim.test.test_miislita.index->gensim.similarities.SparseMatrixSimilarity(tfidf[miislita], num_features=len(miislita.dictionary))
A:gensim.test.test_miislita.vec_bow->CorpusMiislita(datapath('miIslita.cor')).dictionary.doc2bow(query.lower().split())
gensim.test.test_miislita.CorpusMiislita(corpora.TextCorpus)
gensim.test.test_miislita.CorpusMiislita.__len__(self)
gensim.test.test_miislita.CorpusMiislita.get_texts(self)
gensim.test.test_miislita.TestMiislita(unittest.TestCase)
gensim.test.test_miislita.TestMiislita.test_miislita_high_level(self)
gensim.test.test_miislita.TestMiislita.test_save_load_ability(self)
gensim.test.test_miislita.TestMiislita.test_textcorpus(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_tfidfmodel.py----------------------------------------
A:gensim.test.test_tfidfmodel.dictionary->Dictionary(texts)
A:gensim.test.test_tfidfmodel.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_tfidfmodel.model->gensim.models.tfidfmodel.TfidfModel(self.corpus, wlocal=lambda x: x * x, wglobal=lambda x, y: x, smartirs='nnc')
A:gensim.test.test_tfidfmodel.model1->gensim.models.tfidfmodel.TfidfModel(common_corpus)
A:gensim.test.test_tfidfmodel.model2->gensim.models.tfidfmodel.TfidfModel.load(fname, mmap=None)
A:gensim.test.test_tfidfmodel.fname->get_tmpfile('gensim_models_smartirs.tst.gz')
A:gensim.test.test_tfidfmodel.model3->gensim.models.tfidfmodel.TfidfModel(self.corpus, smartirs='ntc')
A:gensim.test.test_tfidfmodel.model4->gensim.models.tfidfmodel.TfidfModel.load(datapath('tfidf_model.tst.bz2'))
gensim.test.test_tfidfmodel.TestTfidfModel(unittest.TestCase)
gensim.test.test_tfidfmodel.TestTfidfModel.TestConsistency(self)
gensim.test.test_tfidfmodel.TestTfidfModel.setUp(self)
gensim.test.test_tfidfmodel.TestTfidfModel.testInit(self)
gensim.test.test_tfidfmodel.TestTfidfModel.testPersistence(self)
gensim.test.test_tfidfmodel.TestTfidfModel.testPersistenceCompressed(self)
gensim.test.test_tfidfmodel.TestTfidfModel.testTransform(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_parsing.py----------------------------------------
A:gensim.test.test_parsing.classes->numpy.array([[1, 0], [1, 0], [0, 1], [0, 1]])
gensim.test.test_parsing.TestPreprocessing(unittest.TestCase)
gensim.test.test_parsing.TestPreprocessing.testSplitAlphanum(self)
gensim.test.test_parsing.TestPreprocessing.testStemText(self)
gensim.test.test_parsing.TestPreprocessing.testStripMultipleWhitespaces(self)
gensim.test.test_parsing.TestPreprocessing.testStripNonAlphanum(self)
gensim.test.test_parsing.TestPreprocessing.testStripNumeric(self)
gensim.test.test_parsing.TestPreprocessing.testStripShort(self)
gensim.test.test_parsing.TestPreprocessing.testStripStopwords(self)
gensim.test.test_parsing.TestPreprocessing.testStripTags(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_coherencemodel.py----------------------------------------
A:gensim.test.test_coherencemodel.self.ldamodel->LdaModel(corpus=self.corpus, id2word=self.dictionary, num_topics=2, passes=0, iterations=0)
A:gensim.test.test_coherencemodel.mallet_home->os.environ.get('MALLET_HOME', None)
A:gensim.test.test_coherencemodel.self.malletmodel->LdaMallet(mallet_path=self.mallet_path, corpus=self.corpus, id2word=self.dictionary, num_topics=2, iterations=0)
A:gensim.test.test_coherencemodel.vw_path->os.environ.get('VOWPAL_WABBIT_PATH', None)
A:gensim.test.test_coherencemodel.self.vwmodel->LdaVowpalWabbit(self.vw_path, corpus=self.corpus, id2word=self.dictionary, num_topics=2, passes=0)
A:gensim.test.test_coherencemodel.kwargs->dict(corpus=self.corpus, dictionary=self.dictionary, topn=5, coherence='u_mass')
A:gensim.test.test_coherencemodel.cm1->CoherenceModel(model=self.ldamodel, **kwargs)
A:gensim.test.test_coherencemodel.cm2->CoherenceModel(topics=self.topics2, **kwargs)
A:gensim.test.test_coherencemodel.get_model->partial(CoherenceModel, topics=self.topics1, corpus=self.corpus, dictionary=self.dictionary, coherence='u_mass')
A:gensim.test.test_coherencemodel.fname->get_tmpfile('gensim_similarities.tst.pkl')
A:gensim.test.test_coherencemodel.model->CoherenceModel(topics=self.topics1, texts=self.texts, dictionary=self.dictionary, coherence='c_v')
A:gensim.test.test_coherencemodel.model2->gensim.models.coherencemodel.CoherenceModel.load(fname)
A:gensim.test.test_coherencemodel.bestn->argsort(topic, topn=cm1.topn, reverse=True)
A:gensim.test.test_coherencemodel.cm->gensim.models.coherencemodel.CoherenceModel.for_models(models, dictionary=self.dictionary, texts=self.texts, coherence='c_v')
A:gensim.test.test_coherencemodel.((coherence_topics1, coherence1), (coherence_topics2, coherence2))->gensim.models.coherencemodel.CoherenceModel.for_models(models, dictionary=self.dictionary, texts=self.texts, coherence='c_v').compare_models(models)
gensim.test.test_coherencemodel.TestCoherenceModel(unittest.TestCase)
gensim.test.test_coherencemodel.TestCoherenceModel._check_for_mallet(self)
gensim.test.test_coherencemodel.TestCoherenceModel._check_for_vw(self)
gensim.test.test_coherencemodel.TestCoherenceModel.check_coherence_measure(self,coherence)
gensim.test.test_coherencemodel.TestCoherenceModel.setUp(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingSameSizeTopics(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingTopicSubsets(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingWithModelSetting(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingWithTopnSettingGivenModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testAccumulatorCachingWithTopnSettingGivenTopics(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCnpmi(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCnpmiLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCnpmiMalletModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCnpmiVWModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCompareCoherenceForModels(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCompareCoherenceForTopics(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCuci(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCuciLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCuciMalletModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCuciVWModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCv(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCvLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCvMalletModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCvVWModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCw2vLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCw2vMalletModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testCw2vVWModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testErrors(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistence(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistenceAfterProbabilityEstimationUsingCorpus(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistenceAfterProbabilityEstimationUsingTexts(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testPersistenceCompressed(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testProcesses(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testUMass(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testUMassLdaModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testUMassMalletModel(self)
gensim.test.test_coherencemodel.TestCoherenceModel.testUMassVWModel(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_fasttext.py----------------------------------------
A:gensim.test.test_fasttext.logger->logging.getLogger(__name__)
A:gensim.test.test_fasttext.list_corpus->list(LeeCorpus())
A:gensim.test.test_fasttext.ft_home->os.environ.get('FT_HOME', None)
A:gensim.test.test_fasttext.self.test_model_file->datapath('lee_fasttext')
A:gensim.test.test_fasttext.self.test_model->gensim.models.fasttext.FastText.load_fasttext_format(self.test_model_file)
A:gensim.test.test_fasttext.self.test_new_model_file->datapath('lee_fasttext_new')
A:gensim.test.test_fasttext.model->gensim.models.fasttext.FastText.load(datapath(model_file))
A:gensim.test.test_fasttext.sims->gensim.models.fasttext.FastText.load(datapath(model_file)).most_similar('graph', topn=10)
A:gensim.test.test_fasttext.sims2->gensim.models.fasttext.FastText.load(datapath(model_file)).most_similar(positive=[graph_vector], topn=11)
A:gensim.test.test_fasttext.model2->FT_gensim(sentences, size=10, min_count=1, hs=1, negative=0, seed=42, workers=1)
A:gensim.test.test_fasttext.tmpf->get_tmpfile('gensim_fasttext.tst')
A:gensim.test.test_fasttext.loaded_wv->gensim.models.wrappers.fasttext.FastTextKeyedVectors.load(tmpf)
A:gensim.test.test_fasttext.loaded_model->gensim.models.fasttext.FastText.load(tmpf)
A:gensim.test.test_fasttext.loaded_kv->gensim.models.wrappers.fasttext.FastTextKeyedVectors.load(tmpf)
A:gensim.test.test_fasttext.new_model->gensim.models.fasttext.FastText.load_fasttext_format(self.test_new_model_file)
A:gensim.test.test_fasttext.dist->self.test_model.wmdistance(doc, oov_doc)
A:gensim.test.test_fasttext.model_gensim->FT_gensim(size=50, sg=1, cbow_mean=1, alpha=0.025, window=5, hs=1, negative=0, min_count=5, iter=5, batch_words=1000, word_ngrams=1, sample=0.001, min_n=3, max_n=6, sorted_vocab=1, workers=1, min_alpha=0.0)
A:gensim.test.test_fasttext.lee_data->LineSentence(datapath('lee_background.cor'))
A:gensim.test.test_fasttext.orig0->numpy.copy(model_gensim.wv.syn0[0])
A:gensim.test.test_fasttext.sims_gensim->FT_gensim(size=50, sg=1, cbow_mean=1, alpha=0.025, window=5, hs=1, negative=0, min_count=5, iter=5, batch_words=1000, word_ngrams=1, sample=0.001, min_n=3, max_n=6, sorted_vocab=1, workers=1, min_alpha=0.0).most_similar('night', topn=10)
A:gensim.test.test_fasttext.overlap_count->len(set(sims_gensim_words).intersection(sims_wrapper_words))
A:gensim.test.test_fasttext.model_hs->FT_gensim(sentences, size=10, min_count=1, seed=42, hs=1, negative=0)
A:gensim.test.test_fasttext.model_neg->gensim.models.fasttext.FastText.load(tmpf)
A:gensim.test.test_fasttext.orig0_all->numpy.copy(model.wv.syn0_ngrams)
A:gensim.test.test_fasttext.sim->gensim.models.fasttext.FastText.load(datapath(model_file)).n_similarity(['war'], ['terrorism'])
A:gensim.test.test_fasttext.original_syn0_vocab->numpy.copy(model.wv.syn0_vocab)
A:gensim.test.test_fasttext.loaded_model_kv->gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format(tmpf, binary=True)
A:gensim.test.test_fasttext.report->gensim.models.fasttext.FastText.load(datapath(model_file)).estimate_memory()
A:gensim.test.test_fasttext.sims_gensim_words->list(map(lambda x: x[0], sims_gensim))
A:gensim.test.test_fasttext.sims_wrapper->gensim.models.wrappers.fasttext.FastText.train(ft_path=self.ft_path, corpus_file=datapath('lee_background.cor'), output_file=tmpf, model='skipgram', size=50, alpha=0.025, window=5, min_count=5, word_ngrams=1, loss='hs', sample=0.001, negative=0, iter=5, min_n=3, max_n=6, sorted_vocab=1, threads=12).most_similar('night', topn=10)
A:gensim.test.test_fasttext.sims_wrapper_words->list(map(lambda x: x[0], sims_wrapper))
A:gensim.test.test_fasttext.model_wrapper->gensim.models.wrappers.fasttext.FastText.train(ft_path=self.ft_path, corpus_file=datapath('lee_background.cor'), output_file=tmpf, model='skipgram', size=50, alpha=0.025, window=5, min_count=5, word_ngrams=1, loss='hs', sample=0.001, negative=0, iter=5, min_n=3, max_n=6, sorted_vocab=1, threads=12)
gensim.test.test_fasttext.LeeCorpus(object)
gensim.test.test_fasttext.LeeCorpus.__iter__(self)
gensim.test.test_fasttext.TestFastTextModel(unittest.TestCase)
gensim.test.test_fasttext.TestFastTextModel.compare_with_wrapper(self,model_gensim,model_wrapper)
gensim.test.test_fasttext.TestFastTextModel.model_sanity(self,model)
gensim.test.test_fasttext.TestFastTextModel.models_equal(self,model,model2)
gensim.test.test_fasttext.TestFastTextModel.online_sanity(self,model)
gensim.test.test_fasttext.TestFastTextModel.setUp(self)
gensim.test.test_fasttext.TestFastTextModel.testLoadOldModel(self)
gensim.test.test_fasttext.TestFastTextModel.test_bucket_ngrams(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_hs_against_wrapper(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_hs_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_hs_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_neg_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_cbow_neg_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_contains(self)
gensim.test.test_fasttext.TestFastTextModel.test_estimate_memory(self)
gensim.test.test_fasttext.TestFastTextModel.test_get_vocab_word_vecs(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_fasttext_format(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_fasttext_new_format(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_model_non_utf8_encoding(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_model_supervised(self)
gensim.test.test_fasttext.TestFastTextModel.test_load_model_with_non_ascii_vocab(self)
gensim.test.test_fasttext.TestFastTextModel.test_lookup(self)
gensim.test.test_fasttext.TestFastTextModel.test_most_similar(self)
gensim.test.test_fasttext.TestFastTextModel.test_most_similar_cosmul(self)
gensim.test.test_fasttext.TestFastTextModel.test_n_similarity(self)
gensim.test.test_fasttext.TestFastTextModel.test_norm_vectors_not_saved(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning(self)
gensim.test.test_fasttext.TestFastTextModel.test_online_learning_after_save(self)
gensim.test.test_fasttext.TestFastTextModel.test_persistence(self)
gensim.test.test_fasttext.TestFastTextModel.test_persistence_word2vec_format(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_hs_against_wrapper(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_hs_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_hs_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_neg_online(self)
gensim.test.test_fasttext.TestFastTextModel.test_sg_neg_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_similarity(self)
gensim.test.test_fasttext.TestFastTextModel.test_training(self)
gensim.test.test_fasttext.TestFastTextModel.test_wm_distance(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_fasttext_wrapper.py----------------------------------------
A:gensim.test.test_fasttext_wrapper.logger->logging.getLogger(__name__)
A:gensim.test.test_fasttext_wrapper.ft_home->os.environ.get('FT_HOME', None)
A:gensim.test.test_fasttext_wrapper.self.corpus_file->datapath('lee_background.cor')
A:gensim.test.test_fasttext_wrapper.self.test_model_file->datapath('lee_fasttext')
A:gensim.test.test_fasttext_wrapper.self.test_new_model_file->datapath('lee_fasttext_new')
A:gensim.test.test_fasttext_wrapper.self.test_model->gensim.models.wrappers.fasttext.FastText.load_fasttext_format(self.test_model_file)
A:gensim.test.test_fasttext_wrapper.tmpf->get_tmpfile('gensim_fasttext_wrapper.tst')
A:gensim.test.test_fasttext_wrapper.trained_model->gensim.models.wrappers.fasttext.FastText.train(self.ft_path, self.corpus_file, size=model_size, output_file=tmpf)
A:gensim.test.test_fasttext_wrapper.test_model_min_count_5->gensim.models.wrappers.fasttext.FastText.train(self.ft_path, self.corpus_file, output_file=tmpf, size=10, min_count=5)
A:gensim.test.test_fasttext_wrapper.test_model_min_count_1->gensim.models.wrappers.fasttext.FastText.train(self.ft_path, self.corpus_file, output_file=tmpf, size=10, min_count=1)
A:gensim.test.test_fasttext_wrapper.test_model_size_20->gensim.models.wrappers.fasttext.FastText.train(self.ft_path, self.corpus_file, output_file=tmpf, size=20)
A:gensim.test.test_fasttext_wrapper.loaded->gensim.models.wrappers.fasttext.FastText.load(tmpf)
A:gensim.test.test_fasttext_wrapper.loaded_kv->gensim.models.keyedvectors.KeyedVectors.load(tmpf)
A:gensim.test.test_fasttext_wrapper.model->gensim.models.wrappers.fasttext.FastText.load_fasttext_format(datapath('cp852_fasttext'), encoding='cp852')
A:gensim.test.test_fasttext_wrapper.new_model->gensim.models.wrappers.fasttext.FastText.load_fasttext_format(self.test_new_model_file)
A:gensim.test.test_fasttext_wrapper.dist->self.test_model.wmdistance(doc, ngrams_absent_doc)
A:gensim.test.test_fasttext_wrapper.ft_hash->gensim.models.wrappers.fasttext.ft_hash('word')
A:gensim.test.test_fasttext_wrapper.old_model_path->datapath('ft_model_2.3.0')
A:gensim.test.test_fasttext_wrapper.loaded_model->gensim.models.wrappers.fasttext.FastText.load(old_model_path)
A:gensim.test.test_fasttext_wrapper.in_expected_vec->numpy.array([-2.44566941, -1.54802394, -2.61103821, -1.88549316, 1.02860415, 1.19031894, 2.01627707, 1.98942184, -1.39095843, -0.65036952])
A:gensim.test.test_fasttext_wrapper.out_expected_vec->numpy.array([-1.34948218, -0.8686831, -1.51483142, -1.0164026, 0.56272298, 0.66228276, 1.06477463, 1.1355902, -0.80972326, -0.39845538])
gensim.test.test_fasttext_wrapper.TestFastText(unittest.TestCase)
gensim.test.test_fasttext_wrapper.TestFastText.model_sanity(self,model)
gensim.test.test_fasttext_wrapper.TestFastText.models_equal(self,model1,model2)
gensim.test.test_fasttext_wrapper.TestFastText.setUp(self)
gensim.test.test_fasttext_wrapper.TestFastText.testConsistentDtype(self)
gensim.test.test_fasttext_wrapper.TestFastText.testContains(self)
gensim.test.test_fasttext_wrapper.TestFastText.testDoesntMatch(self)
gensim.test.test_fasttext_wrapper.TestFastText.testHash(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLoadFastTextFormat(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLoadFastTextNewFormat(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLoadFileName(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLoadModelNonUtf8Encoding(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLoadModelSupervised(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLoadModelWithNonAsciiVocab(self)
gensim.test.test_fasttext_wrapper.TestFastText.testLookup(self)
gensim.test.test_fasttext_wrapper.TestFastText.testMinCount(self)
gensim.test.test_fasttext_wrapper.TestFastText.testModelSize(self)
gensim.test.test_fasttext_wrapper.TestFastText.testMostSimilar(self)
gensim.test.test_fasttext_wrapper.TestFastText.testMostSimilarCosmul(self)
gensim.test.test_fasttext_wrapper.TestFastText.testNSimilarity(self)
gensim.test.test_fasttext_wrapper.TestFastText.testNormalizedVectorsNotSaved(self)
gensim.test.test_fasttext_wrapper.TestFastText.testPersistence(self)
gensim.test.test_fasttext_wrapper.TestFastText.testPersistenceForOldVersions(self)
gensim.test.test_fasttext_wrapper.TestFastText.testSimilarity(self)
gensim.test.test_fasttext_wrapper.TestFastText.testTraining(self)
gensim.test.test_fasttext_wrapper.TestFastText.testWmdistance(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_direct_confirmation.py----------------------------------------
A:gensim.test.test_direct_confirmation.dictionary->namedtuple('Dictionary', 'token2id, id2token')(token2id, id2token)
A:gensim.test.test_direct_confirmation.self.accumulator->gensim.topic_coherence.text_analysis.InvertedIndexAccumulator({1, 2}, dictionary)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure(unittest.TestCase)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.setUp(self)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.testLogConditionalProbability(self)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.testLogRatioMeasure(self)
gensim.test.test_direct_confirmation.TestDirectConfirmationMeasure.testNormalizedLogRatioMeasure(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_scripts.py----------------------------------------
A:gensim.test.test_scripts.self.fname->datapath('enwiki-latest-pages-articles1.xml-p000000010p000030302-shortened.bz2')
A:gensim.test.test_scripts.fname->get_tmpfile('script.tst')
A:gensim.test.test_scripts.(title, sections, interlinks)->next(segment_all_articles(self.fname, include_interlinks=True))
A:gensim.test.test_scripts.num_articles->sum((1 for line in smart_open(tmpf)))
A:gensim.test.test_scripts.tmpf->get_tmpfile('script.tst.json')
A:gensim.test.test_scripts.first->next(f)
A:gensim.test.test_scripts.article->json.loads(first)
gensim.test.test_scripts.TestSegmentWiki(unittest.TestCase)
gensim.test.test_scripts.TestSegmentWiki.setUp(self)
gensim.test.test_scripts.TestSegmentWiki.tearDown(self)
gensim.test.test_scripts.TestSegmentWiki.test_generator_len(self)
gensim.test.test_scripts.TestSegmentWiki.test_json_len(self)
gensim.test.test_scripts.TestSegmentWiki.test_segment_all_articles(self)
gensim.test.test_scripts.TestSegmentWiki.test_segment_and_write_all_articles(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/basetmtests.py----------------------------------------
A:gensim.test.basetmtests.topics->self.model.get_topics()
A:gensim.test.basetmtests.topic->self.model.show_topic(1)
A:gensim.test.basetmtests.vocab_size->len(self.model.id2word)
gensim.test.basetmtests.TestBaseTopicModel(object)
gensim.test.basetmtests.TestBaseTopicModel.test_get_topics(self)
gensim.test.basetmtests.TestBaseTopicModel.test_print_topic(self)
gensim.test.basetmtests.TestBaseTopicModel.test_print_topics(self)
gensim.test.basetmtests.TestBaseTopicModel.test_show_topic(self)
gensim.test.basetmtests.TestBaseTopicModel.test_show_topics(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_poincare.py----------------------------------------
A:gensim.test.test_poincare.logger->logging.getLogger(__name__)
A:gensim.test.test_poincare.non_utf8_file->datapath('poincare_cp852.tsv')
A:gensim.test.test_poincare.utf8_file->datapath('poincare_utf8.tsv')
A:gensim.test.test_poincare.self.data->PoincareRelations(datapath('poincare_hypernyms.tsv'))
A:gensim.test.test_poincare.self.data_large->PoincareRelations(datapath('poincare_hypernyms_large.tsv'))
A:gensim.test.test_poincare.model->PoincareModel(self.data_large, negative=3)
A:gensim.test.test_poincare.loaded->gensim.models.poincare.PoincareModel.load(testfile())
A:gensim.test.test_poincare.old_vectors->numpy.copy(model.kv.syn0)
A:gensim.test.test_poincare.model._loss_grad->Mock(return_value=np.zeros((2 + model.negative, model.size)))
A:gensim.test.test_poincare.model_1->PoincareModel(self.data_large, seed=1, negative=3, burn_in=1)
A:gensim.test.test_poincare.model_2->PoincareModel(self.data_large, seed=1, negative=3, burn_in=1)
A:gensim.test.test_poincare.original_vectors->numpy.copy(model.kv.syn0)
A:gensim.test.test_poincare.negatives->PoincareModel(self.data_large, negative=3)._sample_negatives(0)
A:gensim.test.test_poincare.vector_updates->numpy.array([[0.5, 0.5], [0.1, 0.2], [0.3, -0.2]])
A:gensim.test.test_poincare.vector_updates_expected->numpy.array([[0.0, 0.0], [0.1, 0.2], [0.8, 0.3]])
A:gensim.test.test_poincare.self.vectors->gensim.models.poincare.PoincareKeyedVectors.load_word2vec_format(datapath('poincare_vectors.bin'), binary=True)
A:gensim.test.test_poincare.predicted->self.vectors.most_similar_to_given('dog.n.01', ['carnivore.n.01', 'placental.n.01', 'mammal.n.01'])
A:gensim.test.test_poincare.expected->set(['canine.n.02', 'hunting_dog.n.01'])
A:gensim.test.test_poincare.distances->self.vectors.vector_distance_batch(vector_1, vectors_2)
A:gensim.test.test_poincare.distance->self.vectors.vector_distance(vector_1, vector_1)
gensim.test.test_poincare.TestPoincareData(unittest.TestCase)
gensim.test.test_poincare.TestPoincareData.test_encoding_handling(self)
gensim.test.test_poincare.TestPoincareKeyedVectors(unittest.TestCase)
gensim.test.test_poincare.TestPoincareKeyedVectors.norm(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.setUp(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_ancestors(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_closest_child(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_closest_parent(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_descendants(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_difference_in_hierarchy(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_distance(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_distances(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_distances_with_vector_input(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_raises_keyerror(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_restrict_vocab(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_to_given(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_topn(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_most_similar_with_vector_input(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_poincare_distance(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_poincare_distances_batch(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_rank(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_similarity(self)
gensim.test.test_poincare.TestPoincareKeyedVectors.test_words_closer_than(self)
gensim.test.test_poincare.TestPoincareModel(unittest.TestCase)
gensim.test.test_poincare.TestPoincareModel.models_equal(self,model_1,model_2)
gensim.test.test_poincare.TestPoincareModel.setUp(self)
gensim.test.test_poincare.TestPoincareModel.tearDownClass(cls)
gensim.test.test_poincare.TestPoincareModel.test_burn_in(self)
gensim.test.test_poincare.TestPoincareModel.test_burn_in_only_done_once(self)
gensim.test.test_poincare.TestPoincareModel.test_data_counts(self)
gensim.test.test_poincare.TestPoincareModel.test_data_counts_with_bytes(self)
gensim.test.test_poincare.TestPoincareModel.test_error_if_negative_more_than_population(self)
gensim.test.test_poincare.TestPoincareModel.test_gradients_check(self)
gensim.test.test_poincare.TestPoincareModel.test_handle_duplicates(self)
gensim.test.test_poincare.TestPoincareModel.test_invalid_data_raises_error(self)
gensim.test.test_poincare.TestPoincareModel.test_negatives(self)
gensim.test.test_poincare.TestPoincareModel.test_no_duplicates_and_positives_in_negative_sample(self)
gensim.test.test_poincare.TestPoincareModel.test_persistence(self)
gensim.test.test_poincare.TestPoincareModel.test_persistence_separate_file(self)
gensim.test.test_poincare.TestPoincareModel.test_reproducible(self)
gensim.test.test_poincare.TestPoincareModel.test_training(self)
gensim.test.test_poincare.TestPoincareModel.test_training_multiple(self)
gensim.test.test_poincare.TestPoincareModel.test_vector_dtype(self)
gensim.test.test_poincare.TestPoincareModel.test_vector_shape(self)
gensim.test.test_poincare.TestPoincareModel.test_wrong_gradients_raises_assertion(self)
gensim.test.test_poincare.testfile()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_sharded_corpus.py----------------------------------------
A:gensim.test.test_sharded_corpus.self.random_string->''.join([random.choice('1234567890') for _ in xrange(8)])
A:gensim.test.test_sharded_corpus.self.tmp_fname->os.path.join(self.tmp_dir, 'shcorp.' + self.random_string + '.tmp')
A:gensim.test.test_sharded_corpus.self.data->mock_data(dim=1000)
A:gensim.test.test_sharded_corpus.self.corpus->ShardedCorpus(self.tmp_fname, self.data, dim=self.dim, shardsize=100)
A:gensim.test.test_sharded_corpus.loaded_corpus->gensim.corpora.sharded_corpus.ShardedCorpus.load(self.tmp_fname)
A:gensim.test.test_sharded_corpus.corpus->ShardedCorpus(gen_tmp_fname, data_generator(), dim=2)
A:gensim.test.test_sharded_corpus.dense_corpus->ShardedCorpus(self.tmp_fname, self.data, shardsize=100, dim=self.dim, sparse_serialization=False, sparse_retrieval=False)
A:gensim.test.test_sharded_corpus.expected_nnz->sum([len(self.data[i]) for i in range(2, 6)])
A:gensim.test.test_sharded_corpus.dslice->list(dslice)
A:gensim.test.test_sharded_corpus.(iscorp, _)->is_corpus(ilist)
A:gensim.test.test_sharded_corpus.ilist->list(ilist)
A:gensim.test.test_sharded_corpus.dataset->ShardedCorpus(self.tmp_fname, self.data, shardsize=100, dim=self.dim)
A:gensim.test.test_sharded_corpus.fname->ShardedCorpus(self.tmp_fname, self.data, shardsize=100, dim=self.dim)._shard_name(n)
A:gensim.test.test_sharded_corpus.suite->unittest.TestSuite()
A:gensim.test.test_sharded_corpus.loader->unittest.TestLoader()
A:gensim.test.test_sharded_corpus.tests->unittest.TestLoader().loadTestsFromTestCase(TestShardedCorpus)
A:gensim.test.test_sharded_corpus.runner->unittest.TextTestRunner()
gensim.test.test_sharded_corpus.TestShardedCorpus(unittest.TestCase)
gensim.test.test_sharded_corpus.TestShardedCorpus.setUp(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.tearDown(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_dense2dense(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_dense2gensim(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_dense2sparse(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_sparse2dense(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_getitem_sparse2sparse(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_init(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_init_with_generator(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_load(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_resize(self)
gensim.test.test_sharded_corpus.TestShardedCorpus.test_sparse_serialization(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_api.py----------------------------------------
A:gensim.test.test_api.dataset_path->os.path.join(base_dir, '__testing_multipart-matrix-synopsis', '__testing_multipart-matrix-synopsis.gz')
A:gensim.test.test_api.vector_dead->numpy.array([0.17403787, -0.10167074, -0.00950371, -0.10367849, -0.14034484, -0.08751217, 0.10030612, 0.07677923, -0.32563496, 0.01929072, 0.20521086, -0.1617067, 0.00475458, 0.21956187, -0.08783089, -0.05937332, 0.26528183, -0.06771874, -0.12369668, 0.12020949, 0.28731, 0.36735833, 0.28051138, -0.10407482, 0.2496888, -0.19372769, -0.28719661, 0.11989869, -0.00393865, -0.2431484, 0.02725661, -0.20421691, 0.0328669, -0.26947051, -0.08068217, -0.10245913, 0.1170633, 0.16583319, 0.1183883, -0.11217165, 0.1261425, -0.0319365, -0.15787181, 0.03753783, 0.14748634, 0.00414471, -0.02296237, 0.18336892, -0.23840059, 0.17924534])
A:gensim.test.test_api.model->gensim.downloader.load('__testing_word2vec-matrix-synopsis')
A:gensim.test.test_api.dataset->gensim.downloader.load('__testing_multipart-matrix-synopsis')
A:gensim.test.test_api.data->gensim.downloader.info()
gensim.test.test_api.TestApi(unittest.TestCase)
gensim.test.test_api.TestApi.test_base_dir_creation(self)
gensim.test.test_api.TestApi.test_info(self)
gensim.test.test_api.TestApi.test_load_dataset(self)
gensim.test.test_api.TestApi.test_load_model(self)
gensim.test.test_api.TestApi.test_multipart_load(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_aggregation.py----------------------------------------
A:gensim.test.test_aggregation.obtained->gensim.topic_coherence.aggregation.arithmetic_mean(self.confirmed_measures)
gensim.test.test_aggregation.TestAggregation(unittest.TestCase)
gensim.test.test_aggregation.TestAggregation.setUp(self)
gensim.test.test_aggregation.TestAggregation.testArithmeticMean(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_text_analysis.py----------------------------------------
A:gensim.test.test_text_analysis.dictionary->Dictionary(texts)
A:gensim.test.test_text_analysis.top_ids->set(token2id.values())
A:gensim.test.test_text_analysis.dictionary2->Dictionary(texts2)
A:gensim.test.test_text_analysis.top_ids2->set(dictionary2.token2id.values())
A:gensim.test.test_text_analysis.accumulator->CorpusAccumulator(self.top_ids).accumulate(self.corpus)
A:gensim.test.test_text_analysis.inverted_index->CorpusAccumulator(self.top_ids).accumulate(self.corpus).index_to_dict()
gensim.test.test_text_analysis.BaseTestCases(object)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase(unittest.TestCase)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.init_accumulator(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.init_accumulator2(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.test_occurences_for_irrelevant_words(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.test_occurrence_counting(self)
gensim.test.test_text_analysis.BaseTestCases.TextAnalyzerTestBase.test_occurrence_counting2(self)
gensim.test.test_text_analysis.TestCorpusAnalyzer(unittest.TestCase)
gensim.test.test_text_analysis.TestCorpusAnalyzer.setUp(self)
gensim.test.test_text_analysis.TestCorpusAnalyzer.test_index_accumulation(self)
gensim.test.test_text_analysis.TestInvertedIndexAccumulator(BaseTestCases.TextAnalyzerTestBase)
gensim.test.test_text_analysis.TestInvertedIndexAccumulator.test_accumulate1(self)
gensim.test.test_text_analysis.TestInvertedIndexAccumulator.test_accumulate2(self)
gensim.test.test_text_analysis.TestParallelWordOccurrenceAccumulator(BaseTestCases.TextAnalyzerTestBase)
gensim.test.test_text_analysis.TestParallelWordOccurrenceAccumulator.init_accumulator(self)
gensim.test.test_text_analysis.TestParallelWordOccurrenceAccumulator.init_accumulator2(self)
gensim.test.test_text_analysis.TestWordOccurrenceAccumulator(BaseTestCases.TextAnalyzerTestBase)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/simspeed.py----------------------------------------
A:gensim.test.simspeed.program->os.path.basename(sys.argv[0])
A:gensim.test.simspeed.corpus_dense->list(itertools.islice(corpus_dense, NUMDOCS))
A:gensim.test.simspeed.corpus_sparse->list(itertools.islice(corpus_sparse, NUMDOCS))
A:gensim.test.simspeed.NUMDOCS->int(sys.argv[3])
A:gensim.test.simspeed.index_dense->gensim.similarities.MatrixSimilarity(corpus_dense)
A:gensim.test.simspeed.index_sparse->gensim.similarities.SparseMatrixSimilarity(corpus_sparse, num_terms=NUMTERMS)
A:gensim.test.simspeed.query->list(itertools.islice(corpus_sparse, 1000))
A:gensim.test.simspeed.start->time()
A:gensim.test.simspeed.queries->math.ceil(1.0 * len(corpus_sparse) / chunksize)
A:gensim.test.simspeed.sims->list(index_sparse)
A:gensim.test.simspeed.diff->numpy.mean(np.abs(unchunksizeed - sims))


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_keywords.py----------------------------------------
A:gensim.test.test_keywords.pre_path->os.path.join(os.path.dirname(__file__), 'test_data')
A:gensim.test.test_keywords.text->f.read()
A:gensim.test.test_keywords.generated_keywords->keywords(text, words=15, split=True)
A:gensim.test.test_keywords.kw->f.read().strip().split('\n')
A:gensim.test.test_keywords.generated_keywords_nnvbjj->keywords(text, pos_filter=['NN', 'VB', 'JJ'], ratio=0.3, split=True)
A:gensim.test.test_keywords.selected_docs_12->keywords(text, ratio=0.1, split=True)
A:gensim.test.test_keywords.selected_docs_21->keywords(text, ratio=0.2, split=True)
A:gensim.test.test_keywords.kwds->keywords(text, words=1, split=True)
gensim.test.test_keywords.TestKeywordsTest(unittest.TestCase)
gensim.test.test_keywords.TestKeywordsTest.test_keywords_ratio(self)
gensim.test.test_keywords.TestKeywordsTest.test_text_keywords(self)
gensim.test.test_keywords.TestKeywordsTest.test_text_keywords_pos(self)
gensim.test.test_keywords.TestKeywordsTest.test_text_keywords_with_small_graph(self)
gensim.test.test_keywords.TestKeywordsTest.test_text_keywords_words(self)
gensim.test.test_keywords.TestKeywordsTest.test_text_summarization_raises_exception_on_short_input_text(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_ldavowpalwabbit_wrapper.py----------------------------------------
A:gensim.test.test_ldavowpalwabbit_wrapper.text_path->datapath('ldavowpalwabbit.txt')
A:gensim.test.test_ldavowpalwabbit_wrapper.dict_path->datapath('ldavowpalwabbit.dict.txt')
A:gensim.test.test_ldavowpalwabbit_wrapper.dictionary->gensim.corpora.Dictionary.load_from_text(dict_path)
A:gensim.test.test_ldavowpalwabbit_wrapper.vw_path->os.environ.get('VOWPAL_WABBIT_PATH', None)
A:gensim.test.test_ldavowpalwabbit_wrapper.(corpus, dictionary)->get_corpus()
A:gensim.test.test_ldavowpalwabbit_wrapper.lda->LdaVowpalWabbit(self.vw_path, corpus=corpus, passes=10, chunksize=256, id2word=dictionary, cleanup_files=True, alpha=0.1, eta=0.1, num_topics=len(TOPIC_WORDS), random_seed=1)
A:gensim.test.test_ldavowpalwabbit_wrapper.lda2->gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.load(fhandle.name)
A:gensim.test.test_ldavowpalwabbit_wrapper.saved_topics->LdaVowpalWabbit(self.vw_path, corpus=corpus, passes=10, chunksize=256, id2word=dictionary, cleanup_files=True, alpha=0.1, eta=0.1, num_topics=len(TOPIC_WORDS), random_seed=1).show_topics(num_topics=5, num_words=10)
A:gensim.test.test_ldavowpalwabbit_wrapper.loaded_topics->gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.load(fhandle.name).show_topics(num_topics=5, num_words=10)
A:gensim.test.test_ldavowpalwabbit_wrapper.result->'\n'.join(ldavowpalwabbit.corpus_to_vw(corpus))
A:gensim.test.test_ldavowpalwabbit_wrapper.topic->LdaVowpalWabbit(self.vw_path, corpus=corpus, passes=10, chunksize=256, id2word=dictionary, cleanup_files=True, alpha=0.1, eta=0.1, num_topics=len(TOPIC_WORDS), random_seed=1).show_topic(topic_id, topn=20)
A:gensim.test.test_ldavowpalwabbit_wrapper.counts->defaultdict(int)
A:gensim.test.test_ldavowpalwabbit_wrapper.max_count->max(max_count, count)
A:gensim.test.test_ldavowpalwabbit_wrapper.expected->'\n| 0:5 7:1 5:3 0:2\n| 7:2 2:1 3:11\n| 1:1\n|\n| 5:2 0:1\n'.strip()
A:gensim.test.test_ldavowpalwabbit_wrapper.tm1->LdaVowpalWabbit(vw_path=self.vw_path, corpus=self.corpus, num_topics=2, id2word=self.dictionary)
A:gensim.test.test_ldavowpalwabbit_wrapper.tm2->gensim.models.wrappers.ldavowpalwabbit.vwmodel2ldamodel(tm1)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit(unittest.TestCase)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.setUp(self)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.test_corpus_to_vw(self)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.test_model_update(self)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.test_perplexity(self)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.test_save_load(self)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.test_topic_coherence(self)
gensim.test.test_ldavowpalwabbit_wrapper.TestLdaVowpalWabbit.testvwmodel2ldamodel(self)
gensim.test.test_ldavowpalwabbit_wrapper.get_corpus()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/simspeed2.py----------------------------------------
A:gensim.test.simspeed2.program->os.path.basename(sys.argv[0])
A:gensim.test.simspeed2.corpus_dense->list(itertools.islice(corpus_dense, NUMDOCS))
A:gensim.test.simspeed2.corpus_sparse->list(itertools.islice(corpus_sparse, NUMDOCS))
A:gensim.test.simspeed2.NUMDOCS->int(sys.argv[3])
A:gensim.test.simspeed2.index_dense->gensim.similarities.Similarity('/tmp/tstdense', corpus_dense, dense_features)
A:gensim.test.simspeed2.index_sparse->gensim.similarities.Similarity('/tmp/tstsparse', corpus_sparse, sparse_features)
A:gensim.test.simspeed2.start->time()
A:gensim.test.simspeed2.queries->math.ceil(1.0 * len(query) / chunksize)
A:gensim.test.simspeed2.query->list(itertools.islice(corpus_dense, 1000))


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_wordrank_wrapper.py----------------------------------------
A:gensim.test.test_wordrank_wrapper.wr_home->os.environ.get('WR_HOME', None)
A:gensim.test.test_wordrank_wrapper.self.corpus_file->datapath('lee.cor')
A:gensim.test.test_wordrank_wrapper.self.wr_file->datapath('test_glove.txt')
A:gensim.test.test_wordrank_wrapper.self.test_model->gensim.models.wrappers.wordrank.Wordrank.train(self.wr_path, self.corpus_file, self.out_name, iter=6, dump_period=5, period=5, np=4, cleanup_files=True)
A:gensim.test.test_wordrank_wrapper.model->gensim.models.wrappers.wordrank.Wordrank.load_wordrank_model(self.wr_file)
A:gensim.test.test_wordrank_wrapper.new_emb->self.test_model.ensemble_embedding(self.wr_file, self.wr_file)
A:gensim.test.test_wordrank_wrapper.tmpf->get_tmpfile('gensim_wordrank.test')
A:gensim.test.test_wordrank_wrapper.loaded->gensim.models.wrappers.wordrank.Wordrank.load(tmpf)
gensim.test.test_wordrank_wrapper.TestWordrank(unittest.TestCase)
gensim.test.test_wordrank_wrapper.TestWordrank.models_equal(self,model,model2)
gensim.test.test_wordrank_wrapper.TestWordrank.setUp(self)
gensim.test.test_wordrank_wrapper.TestWordrank.testEnsemble(self)
gensim.test.test_wordrank_wrapper.TestWordrank.testLoadWordrankFormat(self)
gensim.test.test_wordrank_wrapper.TestWordrank.testLookup(self)
gensim.test.test_wordrank_wrapper.TestWordrank.testPersistence(self)
gensim.test.test_wordrank_wrapper.TestWordrank.testSimilarity(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_logentropy_model.py----------------------------------------
A:gensim.test.test_logentropy_model.self.corpus_small->MmCorpus(datapath('test_corpus_small.mm'))
A:gensim.test.test_logentropy_model.self.corpus_ok->MmCorpus(datapath('test_corpus_ok.mm'))
A:gensim.test.test_logentropy_model.model->gensim.models.logentropy_model.LogEntropyModel(self.corpus_ok, normalize=True)
A:gensim.test.test_logentropy_model.fname->get_tmpfile('gensim_models_logentry.tst.gz')
A:gensim.test.test_logentropy_model.model2->gensim.models.logentropy_model.LogEntropyModel.load(fname, mmap=None)
gensim.test.test_logentropy_model.TestLogEntropyModel(unittest.TestCase)
gensim.test.test_logentropy_model.TestLogEntropyModel.setUp(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.testPersistence(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.testPersistenceCompressed(self)
gensim.test.test_logentropy_model.TestLogEntropyModel.testTransform(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_keras_integration.py----------------------------------------
A:gensim.test.test_keras_integration.self.model_cos_sim->gensim.models.word2vec.Word2Vec(common_texts, size=100, min_count=1, hs=1)
A:gensim.test.test_keras_integration.self.model_twenty_ng->gensim.models.word2vec.Word2Vec(min_count=1)
A:gensim.test.test_keras_integration.sims->Model(sequence_input, preds).most_similar('graph', topn=10)
A:gensim.test.test_keras_integration.sims2->Model(sequence_input, preds).most_similar(positive=[graph_vector], topn=11)
A:gensim.test.test_keras_integration.embedding_layer->keras_w2v_wv.get_keras_embedding()
A:gensim.test.test_keras_integration.input_a->Input(shape=(1,), dtype='int32', name='input_a')
A:gensim.test.test_keras_integration.input_b->Input(shape=(1,), dtype='int32', name='input_b')
A:gensim.test.test_keras_integration.embedding_a->embedding_layer(input_a)
A:gensim.test.test_keras_integration.embedding_b->embedding_layer(input_b)
A:gensim.test.test_keras_integration.similarity->dot([embedding_a, embedding_b], axes=2, normalize=True)
A:gensim.test.test_keras_integration.model->Model(sequence_input, preds)
A:gensim.test.test_keras_integration.output->Model(sequence_input, preds).predict([np.asarray([keras_w2v_model.wv.vocab[word_a].index]), np.asarray([keras_w2v_model.wv.vocab[word_b].index])])
A:gensim.test.test_keras_integration.data->pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)
A:gensim.test.test_keras_integration.i->file_data.find('\n\n')
A:gensim.test.test_keras_integration.curr_str->str(file_data)
A:gensim.test.test_keras_integration.sentence_list->str(file_data).split('\n')
A:gensim.test.test_keras_integration.sentence->sentence.strip().lower().strip().lower()
A:gensim.test.test_keras_integration.tokenizer->Tokenizer()
A:gensim.test.test_keras_integration.sequences->Tokenizer().texts_to_sequences(texts)
A:gensim.test.test_keras_integration.labels->to_categorical(np.asarray(labels))
A:gensim.test.test_keras_integration.sequence_input->Input(shape=(MAX_SEQUENCE_LENGTH,), dtype='int32')
A:gensim.test.test_keras_integration.embedded_sequences->embedding_layer(sequence_input)
A:gensim.test.test_keras_integration.x->Dense(128, activation='relu')(x)
A:gensim.test.test_keras_integration.preds->Dense(y_train.shape[1], activation='softmax')(x)
A:gensim.test.test_keras_integration.fit_ret_val->Model(sequence_input, preds).fit(x_train, y_train, epochs=1)
gensim.test.test_keras_integration.TestKerasWord2VecWrapper(unittest.TestCase)
gensim.test.test_keras_integration.TestKerasWord2VecWrapper.setUp(self)
gensim.test.test_keras_integration.TestKerasWord2VecWrapper.testEmbeddingLayer20NewsGroup(self)
gensim.test.test_keras_integration.TestKerasWord2VecWrapper.testEmbeddingLayerCosineSim(self)
gensim.test.test_keras_integration.TestKerasWord2VecWrapper.testWord2VecTraining(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_atmodel.py----------------------------------------
A:gensim.test.test_atmodel.dictionary_new->Dictionary(texts_new)
A:gensim.test.test_atmodel.self.corpus->gensim.corpora.mmcorpus.MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_atmodel.self.model->self.class_(corpus, id2word=dictionary, author2doc=author2doc, num_topics=2, passes=100)
A:gensim.test.test_atmodel.model->self.class_.load(atmodel_3_0_1_fname)
A:gensim.test.test_atmodel.jill_topics->gensim.matutils.sparse2full(jill_topics, model.num_topics)
A:gensim.test.test_atmodel.vec->gensim.matutils.sparse2full(jill_topics, 2)
A:gensim.test.test_atmodel.passed->numpy.allclose(sorted(vec), sorted(expected), atol=0.1)
A:gensim.test.test_atmodel.model2->self.class_.load(fname, mmap='r')
A:gensim.test.test_atmodel.jill_topics2->gensim.matutils.sparse2full(jill_topics2, model.num_topics)
A:gensim.test.test_atmodel.sally_topics->gensim.matutils.sparse2full(sally_topics, model.num_topics)
A:gensim.test.test_atmodel.model1->self.class_(corpus, author2doc=author2doc, id2word=dictionary, eta='symmetric', passes=10, num_topics=2)
A:gensim.test.test_atmodel.modelauto->self.class_(corpus, author2doc=author2doc, id2word=dictionary, eta='auto', passes=10, num_topics=2)
A:gensim.test.test_atmodel.kwargs->dict(author2doc=author2doc, id2word=dictionary, num_topics=2, eta=None)
A:gensim.test.test_atmodel.kwargs['alpha']->numpy.array([0.3, 0.3])
A:gensim.test.test_atmodel.num_terms->len(dictionary)
A:gensim.test.test_atmodel.kwargs['eta']->numpy.array([[0.5] * len(dictionary)] * 2).reshape(tuple(reversed(testeta.shape)))
A:gensim.test.test_atmodel.testeta->numpy.array([[0.5] * len(dictionary)] * 2)
A:gensim.test.test_atmodel.top_topics->self.model.top_topics(corpus)
A:gensim.test.test_atmodel.topic_terms->self.model.get_topic_terms(1)
A:gensim.test.test_atmodel.result->self.class_.load(atmodel_3_0_1_fname).get_term_topics(str(model.id2word[2]))
A:gensim.test.test_atmodel.msg->'{}, {}, {}'.format(passes, model.num_updates, model.state.numdocs)
A:gensim.test.test_atmodel.fname->get_tmpfile('gensim_models_atmodel.tst.gz')
A:gensim.test.test_atmodel.atmodel_3_0_1_fname->datapath('atmodel_3_0_1_model')
gensim.test.test_atmodel.TestAuthorTopicModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_atmodel.TestAuthorTopicModel.setUp(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testAlpha(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testAlphaAuto(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testAuthor2docMissing(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testBasic(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testDoc2authorMissing(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testDtypeBackwardCompatibility(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testEta(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testEtaAuto(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testGetAuthorTopics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testGetTopicTerms(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testLargeMmap(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testLargeMmapCompressed(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testPasses(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testPersistence(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testPersistenceCompressed(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testPersistenceIgnore(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testSerialized(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testTermTopics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testTopTopics(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testTransform(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testTransformSerialized(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testUpdate(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testUpdateNewDataNewAuthor(self)
gensim.test.test_atmodel.TestAuthorTopicModel.testUpdateNewDataOldAuthor(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_big.py----------------------------------------
A:gensim.test.test_big.self.dictionary->gensim.utils.FakeDict(num_terms)
A:gensim.test.test_big.doc_len->numpy.random.poisson(self.doc_len)
A:gensim.test.test_big.ids->numpy.random.randint(0, len(self.dictionary), doc_len)
A:gensim.test.test_big.weights->numpy.random.poisson(3, doc_len)
A:gensim.test.test_big.corpus->BigCorpus(num_docs=5000)
A:gensim.test.test_big.tmpf->get_tmpfile('gensim_big.tst')
A:gensim.test.test_big.model->gensim.models.LdaModel(corpus, num_topics=500, id2word=corpus.dictionary)
gensim.test.test_big.BigCorpus(self,words_only=False,num_terms=200000,num_docs=1000000,doc_len=100)
gensim.test.test_big.BigCorpus.__init__(self,words_only=False,num_terms=200000,num_docs=1000000,doc_len=100)
gensim.test.test_big.BigCorpus.__iter__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_lsimodel.py----------------------------------------
A:gensim.test.test_lsimodel.self.corpus->MmCorpus(datapath('testcorpus.mm'))
A:gensim.test.test_lsimodel.self.model->gensim.models.lsimodel.LsiModel(self.corpus, num_topics=2)
A:gensim.test.test_lsimodel.(u, s, vt)->scipy.linalg.svd(matutils.corpus2dense(self.corpus, self.corpus.num_terms), full_matrices=False)
A:gensim.test.test_lsimodel.vec->gensim.matutils.sparse2full(transformed, model.num_topics)
A:gensim.test.test_lsimodel.expected->numpy.array([-0.66493785, -0.28314203, -1.56376302, 0.05488682, 0.17123269])
A:gensim.test.test_lsimodel.model->gensim.models.lsimodel.LsiModel(corpus=None, id2word=model2.id2word, num_topics=5)
A:gensim.test.test_lsimodel.got->numpy.vstack((matutils.sparse2full(doc, 2) for doc in model[self.corpus]))
A:gensim.test.test_lsimodel.corpus->list(self.corpus)
A:gensim.test.test_lsimodel.model2->gensim.models.lsimodel.LsiModel.load(fname, mmap='r')
A:gensim.test.test_lsimodel.vec1->gensim.matutils.sparse2full(model[doc], model.num_topics)
A:gensim.test.test_lsimodel.vec2->gensim.matutils.sparse2full(model2[doc], model2.num_topics)
A:gensim.test.test_lsimodel.fname->get_tmpfile('gensim_models_lsi.tst.gz')
A:gensim.test.test_lsimodel.topics->self.model.get_topics()
A:gensim.test.test_lsimodel.vocab_size->len(self.model.id2word)
gensim.test.test_lsimodel.TestLsiModel(unittest.TestCase,basetmtests.TestBaseTopicModel)
gensim.test.test_lsimodel.TestLsiModel.setUp(self)
gensim.test.test_lsimodel.TestLsiModel.testCorpusTransform(self)
gensim.test.test_lsimodel.TestLsiModel.testDocsProcessed(self)
gensim.test.test_lsimodel.TestLsiModel.testLargeMmap(self)
gensim.test.test_lsimodel.TestLsiModel.testLargeMmapCompressed(self)
gensim.test.test_lsimodel.TestLsiModel.testOnlineTransform(self)
gensim.test.test_lsimodel.TestLsiModel.testPersistence(self)
gensim.test.test_lsimodel.TestLsiModel.testPersistenceCompressed(self)
gensim.test.test_lsimodel.TestLsiModel.testTransform(self)
gensim.test.test_lsimodel.TestLsiModel.testTransformFloat32(self)
gensim.test.test_lsimodel.TestLsiModel.test_get_topics(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_glove2word2vec.py----------------------------------------
A:gensim.test.test_glove2word2vec.self.datapath->datapath('test_glove.txt')
A:gensim.test.test_glove2word2vec.self.output_file->get_tmpfile('glove2word2vec.test')
A:gensim.test.test_glove2word2vec.self.test_model->gensim.models.KeyedVectors.load_word2vec_format(self.output_file)
gensim.test.test_glove2word2vec.TestGlove2Word2Vec(unittest.TestCase)
gensim.test.test_glove2word2vec.TestGlove2Word2Vec.setUp(self)
gensim.test.test_glove2word2vec.TestGlove2Word2Vec.testConversion(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_corpora_dictionary.py----------------------------------------
A:gensim.test.test_corpora_dictionary.d->Dictionary(self.texts)
A:gensim.test.test_corpora_dictionary.expected_keys->sorted(['computer', 'eps', 'graph', 'human', 'interface', 'minors', 'response', 'survey', 'system', 'time', 'trees', 'user'])
A:gensim.test.test_corpora_dictionary.expected_values->list(range(12))
A:gensim.test.test_corpora_dictionary.f->Dictionary(self.texts[:3])
A:gensim.test.test_corpora_dictionary.g->Dictionary(self.texts[3:])
A:gensim.test.test_corpora_dictionary.expected[removed_word]->len(expected)
A:gensim.test.test_corpora_dictionary.tmpf->get_tmpfile('dict_test.txt')
A:gensim.test.test_corpora_dictionary.serialized_lines->file.readlines()
A:gensim.test.test_corpora_dictionary.no_num_docs_serialization->to_utf8('2\n1\tprvé\t1\n2\tslovo\t2\n')
A:gensim.test.test_corpora_dictionary.d_loaded->gensim.corpora.Dictionary.load_from_text(tmpf)
A:gensim.test.test_corpora_dictionary.stoplist->set('for a of the and to in'.split())
A:gensim.test.test_corpora_dictionary.all_tokens->sum(texts, [])
A:gensim.test.test_corpora_dictionary.tokens_once->set((word for word in set(all_tokens) if all_tokens.count(word) == 1))
A:gensim.test.test_corpora_dictionary.dictionary->gensim.corpora.Dictionary.from_corpus(bow)
A:gensim.test.test_corpora_dictionary.dictionary_from_corpus->gensim.corpora.Dictionary.from_corpus(corpus)
A:gensim.test.test_corpora_dictionary.dict_token2id_vals->sorted(dictionary.token2id.values())
A:gensim.test.test_corpora_dictionary.dict_from_corpus_vals->sorted(dictionary_from_corpus.token2id.values())
A:gensim.test.test_corpora_dictionary.dictionary_from_corpus_2->gensim.corpora.Dictionary.from_corpus(corpus, id2word=dictionary)
A:gensim.test.test_corpora_dictionary.bow->gensim.matutils.Sparse2Corpus(scipy.sparse.rand(10, 100))
gensim.test.test_corpora_dictionary.TestDictionary(unittest.TestCase)
gensim.test.test_corpora_dictionary.TestDictionary.setUp(self)
gensim.test.test_corpora_dictionary.TestDictionary.testBuild(self)
gensim.test.test_corpora_dictionary.TestDictionary.testDocFreqAndToken2IdForSeveralDocsWithOneWord(self)
gensim.test.test_corpora_dictionary.TestDictionary.testDocFreqForOneDocWithSeveralWord(self)
gensim.test.test_corpora_dictionary.TestDictionary.testDocFreqOneDoc(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilter(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_keepTokens(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_unchangedFunctionality(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterKeepTokens_unseenToken(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterMostFrequent(self)
gensim.test.test_corpora_dictionary.TestDictionary.testFilterTokens(self)
gensim.test.test_corpora_dictionary.TestDictionary.testMerge(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_dict_interface(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_doc2bow(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_from_corpus(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_loadFromText(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_loadFromText_legacy(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_saveAsText(self)
gensim.test.test_corpora_dictionary.TestDictionary.test_saveAsText_and_loadFromText(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_BM25.py----------------------------------------
A:gensim.test.test_BM25.weights->get_bm25_weights(corpus)
A:gensim.test.test_BM25.expected->max(doc_weights)
gensim.test.test_BM25.TestBM25(unittest.TestCase)
gensim.test.test_BM25.TestBM25.test_disjoint_docs_if_weight_zero(self)
gensim.test.test_BM25.TestBM25.test_max_match_with_itself(self)
gensim.test.test_BM25.TestBM25.test_nonnegative_weights(self)
gensim.test.test_BM25.TestBM25.test_same_match_with_same_document(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_tmdiff.py----------------------------------------
A:gensim.test.test_tmdiff.self.model->LdaModel(corpus=self.corpus, id2word=self.dictionary, num_topics=self.num_topics, passes=10)
A:gensim.test.test_tmdiff.(mdiff, annotation)->self.model.diff(self.model, n_ann_terms=self.n_ann_terms, distance=dist_name, diagonal=True)
gensim.test.test_tmdiff.TestLdaDiff(unittest.TestCase)
gensim.test.test_tmdiff.TestLdaDiff.setUp(self)
gensim.test.test_tmdiff.TestLdaDiff.testBasic(self)
gensim.test.test_tmdiff.TestLdaDiff.testIdentity(self)
gensim.test.test_tmdiff.TestLdaDiff.testInput(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/svd_error.py----------------------------------------
A:gensim.test.svd_error.program->os.path.basename(sys.argv[0])
A:gensim.test.svd_error.mm->gensim.corpora.MmCorpus(fname)
A:gensim.test.svd_error.n->int(sys.argv[2])
A:gensim.test.svd_error.m->int(sys.argv[3])
A:gensim.test.svd_error.corpus->ClippedCorpus(mm, n, m)
A:gensim.test.svd_error.id2word->gensim.utils.FakeDict(m)
A:gensim.test.svd_error.aat->aat.astype(np.float32).astype(np.float32)
A:gensim.test.svd_error.num_nnz->sum((len(doc) for doc in chunk))
A:gensim.test.svd_error.chunk->chunk.toarray().toarray()
A:gensim.test.svd_error.(spectrum_s, spectrum_u)->scipy.linalg.eigh(aat)
A:gensim.test.svd_error.ideal_fro->numpy.linalg.norm(err)
A:gensim.test.svd_error.taken->time.time()
A:gensim.test.svd_error.corpus_ram->gensim.matutils.corpus2csc(corpus, num_terms=m)
A:gensim.test.svd_error.(ut, s, vt)->sparsesvd(corpus_ram, factors)
A:gensim.test.svd_error.model->gensim.models.LsiModel(corpus, id2word=id2word, num_topics=factors, chunksize=2000, onepass=False, power_iters=power_iters)
gensim.test.svd_error.ClippedCorpus(self,corpus,max_docs,max_terms)
gensim.test.svd_error.ClippedCorpus.__init__(self,corpus,max_docs,max_terms)
gensim.test.svd_error.ClippedCorpus.__iter__(self)
gensim.test.svd_error.norm2(a)
gensim.test.svd_error.print_error(name,aat,u,s,ideal_nf,ideal_n2)
gensim.test.svd_error.rmse(diff)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/test/test_keyedvectors.py----------------------------------------
A:gensim.test.test_keyedvectors.logger->logging.getLogger(__name__)
A:gensim.test.test_keyedvectors.self.vectors->gensim.models.KeyedVectors.load_word2vec_format(datapath('euclidean_vectors.bin'), binary=True, datatype=np.float64)
A:gensim.test.test_keyedvectors.dictionary->Dictionary(corpus)
A:gensim.test.test_keyedvectors.similarity_matrix->self.similarity_matrix(corpus, dictionary, nonzero_limit=3).todense()
A:gensim.test.test_keyedvectors.predicted->self.vectors.most_similar_to_given('war', ['terrorism', 'call', 'waging'])
A:gensim.test.test_keyedvectors.expected->set(['conflict', 'administration'])
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors(unittest.TestCase)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.setUp(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.similarity_matrix(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_distance(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_most_similar(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_most_similar_raises_keyerror(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_most_similar_restrict_vocab(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_most_similar_to_given(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_most_similar_topn(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_most_similar_with_vector_input(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_rank(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_similar_by_vector(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_similar_by_word(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_similarity(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_words_closer_than(self)
gensim.test.test_keyedvectors.TestEuclideanKeyedVectors.test_wv_property(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/similarities/docsim.py----------------------------------------
A:gensim.similarities.docsim.logger->logging.getLogger(__name__)
A:gensim.similarities.docsim.(self.dirname, self.fname)->os.path.split(fname)
A:gensim.similarities.docsim.self.length->len(index)
A:gensim.similarities.docsim.self.index->self.index.tocsr()
A:gensim.similarities.docsim.result->result.toarray().flatten().toarray().flatten()
A:gensim.similarities.docsim.index->MatrixSimilarity(self.fresh_docs, num_features=self.num_features)
A:gensim.similarities.docsim.self.output_prefix->gensim.utils.randfname(prefix='simserver')
A:gensim.similarities.docsim.self.chunksize->int(chunksize)
A:gensim.similarities.docsim.doclen->len(doc)
A:gensim.similarities.docsim.doc->gensim.matutils.unitvec(matutils.sparse2full(doc, self.num_features), self.norm)
A:gensim.similarities.docsim.shardid->len(self.shards)
A:gensim.similarities.docsim.shard->Shard(self.shardid2filename(shardid), index)
A:gensim.similarities.docsim.last_index->last_shard.get_index()
A:gensim.similarities.docsim.self.fresh_docs->list(last_index.index)
A:gensim.similarities.docsim.args->zip([query] * len(self.shards), self.shards)
A:gensim.similarities.docsim.pool->multiprocessing.Pool(PARALLEL_SHARDS)
A:gensim.similarities.docsim.(pool, shard_results)->self.query_shards(query)
A:gensim.similarities.docsim.offsets->numpy.cumsum([0] + [len(shard) for shard in self.shards])
A:gensim.similarities.docsim.(is_corpus, query)->gensim.utils.is_corpus(query)
A:gensim.similarities.docsim.merged->heapq.nlargest(self.num_best, itertools.chain(*parts), key=lambda item: item[1])
A:gensim.similarities.docsim.query->gensim.matutils.corpus2csc([query], self.index.shape[1], dtype=self.index.dtype)
A:gensim.similarities.docsim.chunk_end->min(query.shape[0], chunk_start + chunksize)
A:gensim.similarities.docsim.dirname->os.path.dirname(self.output_prefix)
A:gensim.similarities.docsim.corpus_len->len(corpus)
A:gensim.similarities.docsim.vector->gensim.matutils.unitvec(matutils.sparse2full(vector, num_features))
A:gensim.similarities.docsim.n_queries->len(query)
A:gensim.similarities.docsim.qresult->numpy.array(qresult)
gensim.similarities.MatrixSimilarity(self,corpus,num_best=None,dtype=numpy.float32,num_features=None,chunksize=256,corpus_len=None)
gensim.similarities.MatrixSimilarity.__len__(self)
gensim.similarities.MatrixSimilarity.__str__(self)
gensim.similarities.MatrixSimilarity.get_similarities(self,query)
gensim.similarities.Similarity(self,output_prefix,corpus,num_features,num_best=None,chunksize=256,shardsize=32768,norm='l2')
gensim.similarities.Similarity.__getitem__(self,query)
gensim.similarities.Similarity.__iter__(self)
gensim.similarities.Similarity.__len__(self)
gensim.similarities.Similarity.__str__(self)
gensim.similarities.Similarity.add_documents(self,corpus)
gensim.similarities.Similarity.check_moved(self)
gensim.similarities.Similarity.close_shard(self)
gensim.similarities.Similarity.destroy(self)
gensim.similarities.Similarity.iter_chunks(self,chunksize=None)
gensim.similarities.Similarity.query_shards(self,query)
gensim.similarities.Similarity.reopen_shard(self)
gensim.similarities.Similarity.save(self,fname=None,*args,**kwargs)
gensim.similarities.Similarity.shardid2filename(self,shardid)
gensim.similarities.Similarity.similarity_by_id(self,docpos)
gensim.similarities.Similarity.vector_by_id(self,docpos)
gensim.similarities.SoftCosineSimilarity(self,corpus,similarity_matrix,num_best=None,chunksize=256)
gensim.similarities.SoftCosineSimilarity.__len__(self)
gensim.similarities.SoftCosineSimilarity.__str__(self)
gensim.similarities.SoftCosineSimilarity.get_similarities(self,query)
gensim.similarities.SparseMatrixSimilarity(self,corpus,num_features=None,num_terms=None,num_docs=None,num_nnz=None,num_best=None,chunksize=500,dtype=numpy.float32,maintain_sparsity=False)
gensim.similarities.SparseMatrixSimilarity.__len__(self)
gensim.similarities.SparseMatrixSimilarity.get_similarities(self,query)
gensim.similarities.WmdSimilarity(self,corpus,w2v_model,num_best=None,normalize_w2v_and_replace=True,chunksize=256)
gensim.similarities.WmdSimilarity.__len__(self)
gensim.similarities.WmdSimilarity.__str__(self)
gensim.similarities.WmdSimilarity.get_similarities(self,query)
gensim.similarities.docsim.MatrixSimilarity(self,corpus,num_best=None,dtype=numpy.float32,num_features=None,chunksize=256,corpus_len=None)
gensim.similarities.docsim.MatrixSimilarity.__init__(self,corpus,num_best=None,dtype=numpy.float32,num_features=None,chunksize=256,corpus_len=None)
gensim.similarities.docsim.MatrixSimilarity.__len__(self)
gensim.similarities.docsim.MatrixSimilarity.__str__(self)
gensim.similarities.docsim.MatrixSimilarity.get_similarities(self,query)
gensim.similarities.docsim.Shard(self,fname,index)
gensim.similarities.docsim.Shard.__getitem__(self,query)
gensim.similarities.docsim.Shard.__getstate__(self)
gensim.similarities.docsim.Shard.__init__(self,fname,index)
gensim.similarities.docsim.Shard.__len__(self)
gensim.similarities.docsim.Shard.__str__(self)
gensim.similarities.docsim.Shard.fullname(self)
gensim.similarities.docsim.Shard.get_document_id(self,pos)
gensim.similarities.docsim.Shard.get_index(self)
gensim.similarities.docsim.Similarity(self,output_prefix,corpus,num_features,num_best=None,chunksize=256,shardsize=32768,norm='l2')
gensim.similarities.docsim.Similarity.__getitem__(self,query)
gensim.similarities.docsim.Similarity.__init__(self,output_prefix,corpus,num_features,num_best=None,chunksize=256,shardsize=32768,norm='l2')
gensim.similarities.docsim.Similarity.__iter__(self)
gensim.similarities.docsim.Similarity.__len__(self)
gensim.similarities.docsim.Similarity.__str__(self)
gensim.similarities.docsim.Similarity.add_documents(self,corpus)
gensim.similarities.docsim.Similarity.check_moved(self)
gensim.similarities.docsim.Similarity.close_shard(self)
gensim.similarities.docsim.Similarity.destroy(self)
gensim.similarities.docsim.Similarity.iter_chunks(self,chunksize=None)
gensim.similarities.docsim.Similarity.query_shards(self,query)
gensim.similarities.docsim.Similarity.reopen_shard(self)
gensim.similarities.docsim.Similarity.save(self,fname=None,*args,**kwargs)
gensim.similarities.docsim.Similarity.shardid2filename(self,shardid)
gensim.similarities.docsim.Similarity.similarity_by_id(self,docpos)
gensim.similarities.docsim.Similarity.vector_by_id(self,docpos)
gensim.similarities.docsim.SoftCosineSimilarity(self,corpus,similarity_matrix,num_best=None,chunksize=256)
gensim.similarities.docsim.SoftCosineSimilarity.__init__(self,corpus,similarity_matrix,num_best=None,chunksize=256)
gensim.similarities.docsim.SoftCosineSimilarity.__len__(self)
gensim.similarities.docsim.SoftCosineSimilarity.__str__(self)
gensim.similarities.docsim.SoftCosineSimilarity.get_similarities(self,query)
gensim.similarities.docsim.SparseMatrixSimilarity(self,corpus,num_features=None,num_terms=None,num_docs=None,num_nnz=None,num_best=None,chunksize=500,dtype=numpy.float32,maintain_sparsity=False)
gensim.similarities.docsim.SparseMatrixSimilarity.__init__(self,corpus,num_features=None,num_terms=None,num_docs=None,num_nnz=None,num_best=None,chunksize=500,dtype=numpy.float32,maintain_sparsity=False)
gensim.similarities.docsim.SparseMatrixSimilarity.__len__(self)
gensim.similarities.docsim.SparseMatrixSimilarity.get_similarities(self,query)
gensim.similarities.docsim.WmdSimilarity(self,corpus,w2v_model,num_best=None,normalize_w2v_and_replace=True,chunksize=256)
gensim.similarities.docsim.WmdSimilarity.__init__(self,corpus,w2v_model,num_best=None,normalize_w2v_and_replace=True,chunksize=256)
gensim.similarities.docsim.WmdSimilarity.__len__(self)
gensim.similarities.docsim.WmdSimilarity.__str__(self)
gensim.similarities.docsim.WmdSimilarity.get_similarities(self,query)
gensim.similarities.docsim.query_shard(args)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/similarities/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/similarities/index.py----------------------------------------
A:gensim.similarities.index.d->pickle.loads(f.read())
A:gensim.similarities.index.self.index->AnnoyIndex(d['f'])
A:gensim.similarities.index.index->AnnoyIndex(num_features)
A:gensim.similarities.index.(ids, distances)->self.index.get_nns_by_vector(vector, num_neighbors, include_distances=True)
gensim.similarities.index.AnnoyIndexer(self,model=None,num_trees=None)
gensim.similarities.index.AnnoyIndexer.__init__(self,model=None,num_trees=None)
gensim.similarities.index.AnnoyIndexer._build_from_model(self,vectors,labels,num_features)
gensim.similarities.index.AnnoyIndexer.build_from_doc2vec(self)
gensim.similarities.index.AnnoyIndexer.build_from_keyedvectors(self)
gensim.similarities.index.AnnoyIndexer.build_from_word2vec(self)
gensim.similarities.index.AnnoyIndexer.load(self,fname)
gensim.similarities.index.AnnoyIndexer.most_similar(self,vector,num_neighbors)
gensim.similarities.index.AnnoyIndexer.save(self,fname,protocol=2)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/textcleaner.py----------------------------------------
A:gensim.summarization.textcleaner.logger->logging.getLogger('summarizer.preprocessing.cleaner')
A:gensim.summarization.textcleaner.RE_SENTENCE->re.compile('(\\S.+?[.!?])(?=\\s+|$)|(\\S.+?)(?=[\\n]|$)', re.UNICODE)
A:gensim.summarization.textcleaner.AB_SENIOR->re.compile('([A-Z][a-z]{1,2}\\.)\\s(\\w)', re.UNICODE)
A:gensim.summarization.textcleaner.AB_ACRONYM->re.compile('(\\.[a-zA-Z]\\.)\\s(\\w)', re.UNICODE)
A:gensim.summarization.textcleaner.AB_ACRONYM_LETTERS->re.compile('([a-zA-Z])\\.([a-zA-Z])\\.', re.UNICODE)
A:gensim.summarization.textcleaner.UNDO_AB_SENIOR->re.compile('([A-Z][a-z]{1,2}\\.)' + SEPARATOR + '(\\w)', re.UNICODE)
A:gensim.summarization.textcleaner.UNDO_AB_ACRONYM->re.compile('(\\.[a-zA-Z]\\.)' + SEPARATOR + '(\\w)', re.UNICODE)
A:gensim.summarization.textcleaner.processed->replace_abbreviations(text)
A:gensim.summarization.textcleaner.result->regex.sub(replacement, result)
A:gensim.summarization.textcleaner.sentence->SyntacticUnit(text, token, tag)
A:gensim.summarization.textcleaner.original_sentences->split_sentences(text)
A:gensim.summarization.textcleaner.text_without_acronyms->replace_with_separator(text, '', [AB_ACRONYM_LETTERS])
A:gensim.summarization.textcleaner.original_words->list(tokenize(text_without_acronyms, to_lower=True, deacc=deacc))
A:gensim.summarization.textcleaner.tags->tag(join_words(original_words))
A:gensim.summarization.textcleaner.units->merge_syntactic_units(original_words, filtered_words, tags)
gensim.summarization.textcleaner.clean_text_by_sentences(text)
gensim.summarization.textcleaner.clean_text_by_word(text,deacc=True)
gensim.summarization.textcleaner.get_sentences(text)
gensim.summarization.textcleaner.join_words(words,separator='')
gensim.summarization.textcleaner.merge_syntactic_units(original_units,filtered_units,tags=None)
gensim.summarization.textcleaner.replace_abbreviations(text)
gensim.summarization.textcleaner.replace_with_separator(text,separator,regexs)
gensim.summarization.textcleaner.split_sentences(text)
gensim.summarization.textcleaner.tokenize_by_word(text)
gensim.summarization.textcleaner.undo_replacement(sentence)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/summarizer.py----------------------------------------
A:gensim.summarization.summarizer.logger->logging.getLogger(__name__)
A:gensim.summarization.summarizer.documents->_build_graph(hashable_corpus).nodes()
A:gensim.summarization.summarizer.weights->_bm25_weights(documents)
A:gensim.summarization.summarizer.nodes->_build_graph(hashable_corpus).nodes()
A:gensim.summarization.summarizer.length_1->_get_doc_length(doc1)
A:gensim.summarization.summarizer.length_2->_get_doc_length(doc2)
A:gensim.summarization.summarizer.dictionary->Dictionary(split_tokens)
A:gensim.summarization.summarizer.hashable_corpus->_build_hasheable_corpus(corpus)
A:gensim.summarization.summarizer.sentences_by_corpus->dict(zip(hashable_corpus, sentences))
A:gensim.summarization.summarizer.words_in_sentence->len(sentence.text.split())
A:gensim.summarization.summarizer.important_sentences->_get_important_sentences(sentences, corpus, important_docs)
A:gensim.summarization.summarizer.graph->_build_graph(hashable_corpus)
A:gensim.summarization.summarizer.pagerank_scores->_pagerank(graph)
A:gensim.summarization.summarizer.sentences->_clean_text_by_sentences(text)
A:gensim.summarization.summarizer.corpus->_build_corpus(sentences)
A:gensim.summarization.summarizer.most_important_docs->summarize_corpus(corpus, ratio=ratio if word_count is None else 1)
A:gensim.summarization.summarizer.extracted_sentences->_extract_important_sentences(sentences, corpus, most_important_docs, word_count)
gensim.summarization.summarize(text,ratio=0.2,word_count=None,split=False)
gensim.summarization.summarize_corpus(corpus,ratio=0.2)
gensim.summarization.summarizer._build_corpus(sentences)
gensim.summarization.summarizer._build_hasheable_corpus(corpus)
gensim.summarization.summarizer._create_valid_graph(graph)
gensim.summarization.summarizer._extract_important_sentences(sentences,corpus,important_docs,word_count)
gensim.summarization.summarizer._format_results(extracted_sentences,split)
gensim.summarization.summarizer._get_doc_length(doc)
gensim.summarization.summarizer._get_important_sentences(sentences,corpus,important_docs)
gensim.summarization.summarizer._get_sentences_with_word_count(sentences,word_count)
gensim.summarization.summarizer._get_similarity(doc1,doc2,vec1,vec2)
gensim.summarization.summarizer._set_graph_edge_weights(graph)
gensim.summarization.summarizer.summarize(text,ratio=0.2,word_count=None,split=False)
gensim.summarization.summarizer.summarize_corpus(corpus,ratio=0.2)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/syntactic_unit.py----------------------------------------
gensim.summarization.syntactic_unit.SyntacticUnit(self,text,token=None,tag=None)
gensim.summarization.syntactic_unit.SyntacticUnit.__init__(self,text,token=None,tag=None)
gensim.summarization.syntactic_unit.SyntacticUnit.__repr__(self)
gensim.summarization.syntactic_unit.SyntacticUnit.__str__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/pagerank_weighted.py----------------------------------------
A:gensim.summarization.pagerank_weighted.adjacency_matrix->build_adjacency_matrix(graph)
A:gensim.summarization.pagerank_weighted.probability_matrix->build_probability_matrix(graph)
A:gensim.summarization.pagerank_weighted.vec->principal_eigenvector(pagerank_matrix.T)
A:gensim.summarization.pagerank_weighted.nodes->graph.nodes()
A:gensim.summarization.pagerank_weighted.length->len(nodes)
A:gensim.summarization.pagerank_weighted.neighbors_sum->sum((graph.edge_weight((current_node, neighbor)) for neighbor in graph.neighbors(current_node)))
A:gensim.summarization.pagerank_weighted.edge_weight->float(graph.edge_weight((current_node, nodes[j])))
A:gensim.summarization.pagerank_weighted.dimension->len(graph.nodes())
A:gensim.summarization.pagerank_weighted.matrix->empty_matrix((dimension, dimension))
A:gensim.summarization.pagerank_weighted.(vals, vecs)->eigs(a, k=1)
A:gensim.summarization.pagerank_weighted.ind->numpy.abs(vals).argmax()
A:gensim.summarization.pagerank_weighted.scores[node]->abs(vec[i])
gensim.summarization.pagerank_weighted.build_adjacency_matrix(graph)
gensim.summarization.pagerank_weighted.build_probability_matrix(graph)
gensim.summarization.pagerank_weighted.pagerank_weighted(graph,damping=0.85)
gensim.summarization.pagerank_weighted.principal_eigenvector(a)
gensim.summarization.pagerank_weighted.process_results(graph,vec)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/graph.py----------------------------------------
gensim.summarization.graph.Graph(self)
gensim.summarization.graph.Graph.__init__(self)
gensim.summarization.graph.Graph.add_edge(self,edge,wt=1,label='',attrs=None)
gensim.summarization.graph.Graph.add_edge_attribute(self,edge,attr)
gensim.summarization.graph.Graph.add_edge_attributes(self,edge,attrs)
gensim.summarization.graph.Graph.add_node(self,node,attrs=None)
gensim.summarization.graph.Graph.del_edge(self,edge)
gensim.summarization.graph.Graph.del_edge_labeling(self,edge)
gensim.summarization.graph.Graph.del_node(self,node)
gensim.summarization.graph.Graph.edge_attributes(self,edge)
gensim.summarization.graph.Graph.edge_weight(self,edge)
gensim.summarization.graph.Graph.edges(self)
gensim.summarization.graph.Graph.get_edge_properties(self,edge)
gensim.summarization.graph.Graph.has_edge(self,edge)
gensim.summarization.graph.Graph.has_node(self,node)
gensim.summarization.graph.Graph.neighbors(self,node)
gensim.summarization.graph.Graph.nodes(self)
gensim.summarization.graph.Graph.set_edge_properties(self,edge,**properties)
gensim.summarization.graph.IGraph(object)
gensim.summarization.graph.IGraph.add_edge(self,edge,wt=1,label='',attrs=None)
gensim.summarization.graph.IGraph.add_node(self,node,attrs=None)
gensim.summarization.graph.IGraph.del_node(self,node)
gensim.summarization.graph.IGraph.edge_weight(self,edge)
gensim.summarization.graph.IGraph.edges(self)
gensim.summarization.graph.IGraph.has_edge(self,edge)
gensim.summarization.graph.IGraph.has_node(self,node)
gensim.summarization.graph.IGraph.neighbors(self,node)
gensim.summarization.graph.IGraph.nodes(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/commons.py----------------------------------------
A:gensim.summarization.commons.graph->Graph()
gensim.summarization.commons.build_graph(sequence)
gensim.summarization.commons.remove_unreachable_nodes(graph)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/keywords.py----------------------------------------
A:gensim.summarization.keywords.(include_filters, exclude_filters)->_get_pos_filters()
A:gensim.summarization.keywords.include_filters->set(pos_filter)
A:gensim.summarization.keywords.exclude_filters->frozenset([])
A:gensim.summarization.keywords.first_window->_get_first_window(split_text)
A:gensim.summarization.keywords.queue->_init_queue(split_text)
A:gensim.summarization.keywords.iterations->_init_queue(split_text).qsize()
A:gensim.summarization.keywords.var->_init_queue(split_text).get()
A:gensim.summarization.keywords.stripped_word_list->list(_tokenize_by_word(word))
A:gensim.summarization.keywords._keywords->_keywords.copy().copy()
A:gensim.summarization.keywords.len_text->len(split_text)
A:gensim.summarization.keywords.word->_strip_word(split_text[i])
A:gensim.summarization.keywords.other_word->_strip_word(split_text[j])
A:gensim.summarization.keywords.word_list->concept.split()
A:gensim.summarization.keywords.text->to_unicode(text)
A:gensim.summarization.keywords.tokens->_clean_text_by_word(text)
A:gensim.summarization.keywords.split_text->list(_tokenize_by_word(text))
A:gensim.summarization.keywords.graph->_build_graph(_get_words_for_graph(tokens))
A:gensim.summarization.keywords.pagerank_scores->_pagerank(graph)
A:gensim.summarization.keywords.extracted_lemmas->_extract_tokens(graph.nodes(), pagerank_scores, ratio, words)
A:gensim.summarization.keywords.lemmas_to_word->_lemmas_to_words(tokens)
A:gensim.summarization.keywords.keywords->_get_keywords_with_score(extracted_lemmas, lemmas_to_word)
A:gensim.summarization.keywords.combined_keywords->_get_combined_keywords(keywords, text.split())
gensim.summarization.keywords(text,ratio=0.2,words=None,split=False,scores=False,pos_filter=('NN','JJ'),lemmatize=False,deacc=True)
gensim.summarization.keywords._extract_tokens(lemmas,scores,ratio,words)
gensim.summarization.keywords._format_results(_keywords,combined_keywords,split,scores)
gensim.summarization.keywords._get_average_score(concept,_keywords)
gensim.summarization.keywords._get_combined_keywords(_keywords,split_text)
gensim.summarization.keywords._get_first_window(split_text)
gensim.summarization.keywords._get_keywords_with_score(extracted_lemmas,lemma_to_word)
gensim.summarization.keywords._get_pos_filters()
gensim.summarization.keywords._get_words_for_graph(tokens,pos_filter=None)
gensim.summarization.keywords._init_queue(split_text)
gensim.summarization.keywords._lemmas_to_words(tokens)
gensim.summarization.keywords._process_first_window(graph,tokens,split_text)
gensim.summarization.keywords._process_text(graph,tokens,split_text)
gensim.summarization.keywords._process_word(graph,tokens,queue,word)
gensim.summarization.keywords._queue_iterator(queue)
gensim.summarization.keywords._set_graph_edge(graph,tokens,word_a,word_b)
gensim.summarization.keywords._set_graph_edges(graph,tokens,split_text)
gensim.summarization.keywords._strip_word(word)
gensim.summarization.keywords._update_queue(queue,word)
gensim.summarization.keywords.get_graph(text)
gensim.summarization.keywords.keywords(text,ratio=0.2,words=None,split=False,scores=False,pos_filter=('NN','JJ'),lemmatize=False,deacc=True)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/bm25.py----------------------------------------
A:gensim.summarization.bm25.self.corpus_size->len(corpus)
A:gensim.summarization.bm25.score->self.get_score(document, index, average_idf)
A:gensim.summarization.bm25.bm25->BM25(corpus)
A:gensim.summarization.bm25.scores->BM25(corpus).get_scores(doc, average_idf)
gensim.summarization.bm25.BM25(self,corpus)
gensim.summarization.bm25.BM25.__init__(self,corpus)
gensim.summarization.bm25.BM25.get_score(self,document,index,average_idf)
gensim.summarization.bm25.BM25.get_scores(self,document,average_idf)
gensim.summarization.bm25.BM25.initialize(self)
gensim.summarization.bm25.get_bm25_weights(corpus)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/summarization/mz_entropy.py----------------------------------------
A:gensim.summarization.mz_entropy.text->to_unicode(text)
A:gensim.summarization.mz_entropy.vocab->sorted(set(words))
A:gensim.summarization.mz_entropy.word_counts->numpy.array([[words[i:i + blocksize].count(word) for word in vocab] for i in range(0, len(words), blocksize)]).astype('d')
A:gensim.summarization.mz_entropy.totals->numpy.array([[words[i:i + blocksize].count(word) for word in vocab] for i in range(0, len(words), blocksize)]).astype('d').sum(axis=0)
A:gensim.summarization.mz_entropy.n_words->numpy.array([[words[i:i + blocksize].count(word) for word in vocab] for i in range(0, len(words), blocksize)]).astype('d').sum(axis=0).sum()
A:gensim.summarization.mz_entropy.log_p->numpy.log2(p)
A:gensim.summarization.mz_entropy.h->numpy.nan_to_num(p * log_p).sum(axis=0)
A:gensim.summarization.mz_entropy.analytic->__analytic_entropy(blocksize, n_blocks, n_words)
A:gensim.summarization.mz_entropy.result->'\n'.join(result)
A:gensim.summarization.mz_entropy.__log_combinations->numpy.frompyfunc(__log_combinations_inner, 2, 1)
A:gensim.summarization.mz_entropy.marginal->__marginal_prob(blocksize, n_words)
A:gensim.summarization.mz_entropy.m->numpy.arange(1, min(blocksize, n) + 1).astype('d')
gensim.summarization.mz_entropy.__analytic_entropy(blocksize,n_blocks,n_words)
gensim.summarization.mz_entropy.__log_combinations_inner(n,m)
gensim.summarization.mz_entropy.__marginal_prob(blocksize,n_words)
gensim.summarization.mz_entropy.mz_keywords(text,blocksize=1024,scores=False,split=False,weighted=True,threshold=0.0)
gensim.summarization.mz_keywords(text,blocksize=1024,scores=False,split=False,weighted=True,threshold=0.0)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/parsing/preprocessing.py----------------------------------------
A:gensim.parsing.preprocessing.STOPWORDS->frozenset(['all', 'six', 'just', 'less', 'being', 'indeed', 'over', 'move', 'anyway', 'four', 'not', 'own', 'through', 'using', 'fify', 'where', 'mill', 'only', 'find', 'before', 'one', 'whose', 'system', 'how', 'somewhere', 'much', 'thick', 'show', 'had', 'enough', 'should', 'to', 'must', 'whom', 'seeming', 'yourselves', 'under', 'ours', 'two', 'has', 'might', 'thereafter', 'latterly', 'do', 'them', 'his', 'around', 'than', 'get', 'very', 'de', 'none', 'cannot', 'every', 'un', 'they', 'front', 'during', 'thus', 'now', 'him', 'nor', 'name', 'regarding', 'several', 'hereafter', 'did', 'always', 'who', 'didn', 'whither', 'this', 'someone', 'either', 'each', 'become', 'thereupon', 'sometime', 'side', 'towards', 'therein', 'twelve', 'because', 'often', 'ten', 'our', 'doing', 'km', 'eg', 'some', 'back', 'used', 'up', 'go', 'namely', 'computer', 'are', 'further', 'beyond', 'ourselves', 'yet', 'out', 'even', 'will', 'what', 'still', 'for', 'bottom', 'mine', 'since', 'please', 'forty', 'per', 'its', 'everything', 'behind', 'does', 'various', 'above', 'between', 'it', 'neither', 'seemed', 'ever', 'across', 'she', 'somehow', 'be', 'we', 'full', 'never', 'sixty', 'however', 'here', 'otherwise', 'were', 'whereupon', 'nowhere', 'although', 'found', 'alone', 're', 'along', 'quite', 'fifteen', 'by', 'both', 'about', 'last', 'would', 'anything', 'via', 'many', 'could', 'thence', 'put', 'against', 'keep', 'etc', 'amount', 'became', 'ltd', 'hence', 'onto', 'or', 'con', 'among', 'already', 'co', 'afterwards', 'formerly', 'within', 'seems', 'into', 'others', 'while', 'whatever', 'except', 'down', 'hers', 'everyone', 'done', 'least', 'another', 'whoever', 'moreover', 'couldnt', 'throughout', 'anyhow', 'yourself', 'three', 'from', 'her', 'few', 'together', 'top', 'there', 'due', 'been', 'next', 'anyone', 'eleven', 'cry', 'call', 'therefore', 'interest', 'then', 'thru', 'themselves', 'hundred', 'really', 'sincere', 'empty', 'more', 'himself', 'elsewhere', 'mostly', 'on', 'fire', 'am', 'becoming', 'hereby', 'amongst', 'else', 'part', 'everywhere', 'too', 'kg', 'herself', 'former', 'those', 'he', 'me', 'myself', 'made', 'twenty', 'these', 'was', 'bill', 'cant', 'us', 'until', 'besides', 'nevertheless', 'below', 'anywhere', 'nine', 'can', 'whether', 'of', 'your', 'toward', 'my', 'say', 'something', 'and', 'whereafter', 'whenever', 'give', 'almost', 'wherever', 'is', 'describe', 'beforehand', 'herein', 'doesn', 'an', 'as', 'itself', 'at', 'have', 'in', 'seem', 'whence', 'ie', 'any', 'fill', 'again', 'hasnt', 'inc', 'thereby', 'thin', 'no', 'perhaps', 'latter', 'meanwhile', 'when', 'detail', 'same', 'wherein', 'beside', 'also', 'that', 'other', 'take', 'which', 'becomes', 'you', 'if', 'nobody', 'unless', 'whereas', 'see', 'though', 'may', 'after', 'upon', 'most', 'hereupon', 'eight', 'but', 'serious', 'nothing', 'such', 'why', 'off', 'a', 'don', 'whereby', 'third', 'i', 'whole', 'noone', 'sometimes', 'well', 'amoungst', 'yours', 'their', 'rather', 'without', 'so', 'five', 'the', 'first', 'with', 'make', 'once'])
A:gensim.parsing.preprocessing.RE_PUNCT->re.compile('([%s])+' % re.escape(string.punctuation), re.UNICODE)
A:gensim.parsing.preprocessing.RE_TAGS->re.compile('<([^>]+)>', re.UNICODE)
A:gensim.parsing.preprocessing.RE_NUMERIC->re.compile('[0-9]+', re.UNICODE)
A:gensim.parsing.preprocessing.RE_NONALPHA->re.compile('\\W', re.UNICODE)
A:gensim.parsing.preprocessing.RE_AL_NUM->re.compile('([a-z]+)([0-9]+)', flags=re.UNICODE)
A:gensim.parsing.preprocessing.RE_NUM_AL->re.compile('([0-9]+)([a-z]+)', flags=re.UNICODE)
A:gensim.parsing.preprocessing.RE_WHITESPACE->re.compile('(\\s)+', re.UNICODE)
A:gensim.parsing.preprocessing.s->f(s)
A:gensim.parsing.preprocessing.text->gensim.utils.to_unicode(text)
A:gensim.parsing.preprocessing.p->PorterStemmer()
gensim.parsing.preprocess_documents(docs)
gensim.parsing.preprocess_string(s,filters=DEFAULT_FILTERS)
gensim.parsing.preprocessing.preprocess_documents(docs)
gensim.parsing.preprocessing.preprocess_string(s,filters=DEFAULT_FILTERS)
gensim.parsing.preprocessing.read_file(path)
gensim.parsing.preprocessing.read_files(pattern)
gensim.parsing.preprocessing.remove_stopwords(s)
gensim.parsing.preprocessing.split_alphanum(s)
gensim.parsing.preprocessing.stem_text(text)
gensim.parsing.preprocessing.strip_multiple_whitespaces(s)
gensim.parsing.preprocessing.strip_non_alphanum(s)
gensim.parsing.preprocessing.strip_numeric(s)
gensim.parsing.preprocessing.strip_punctuation(s)
gensim.parsing.preprocessing.strip_short(s,minsize=3)
gensim.parsing.preprocessing.strip_tags(s)
gensim.parsing.read_file(path)
gensim.parsing.read_files(pattern)
gensim.parsing.remove_stopwords(s)
gensim.parsing.split_alphanum(s)
gensim.parsing.stem_text(text)
gensim.parsing.strip_multiple_whitespaces(s)
gensim.parsing.strip_non_alphanum(s)
gensim.parsing.strip_numeric(s)
gensim.parsing.strip_punctuation(s)
gensim.parsing.strip_short(s,minsize=3)
gensim.parsing.strip_tags(s)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/parsing/porter.py----------------------------------------
A:gensim.parsing.porter.length->len(s)
A:gensim.parsing.porter.a->self._m()
A:gensim.parsing.porter.w->w.lower().lower()
A:gensim.parsing.porter.p->PorterStemmer()
gensim.parsing.PorterStemmer(self)
gensim.parsing.PorterStemmer._cons(self,i)
gensim.parsing.PorterStemmer._cvc(self,i)
gensim.parsing.PorterStemmer._doublec(self,j)
gensim.parsing.PorterStemmer._ends(self,s)
gensim.parsing.PorterStemmer._m(self)
gensim.parsing.PorterStemmer._r(self,s)
gensim.parsing.PorterStemmer._setto(self,s)
gensim.parsing.PorterStemmer._step1ab(self)
gensim.parsing.PorterStemmer._step1c(self)
gensim.parsing.PorterStemmer._step2(self)
gensim.parsing.PorterStemmer._step3(self)
gensim.parsing.PorterStemmer._step4(self)
gensim.parsing.PorterStemmer._step5(self)
gensim.parsing.PorterStemmer._vowelinstem(self)
gensim.parsing.PorterStemmer.stem(self,w)
gensim.parsing.PorterStemmer.stem_documents(self,docs)
gensim.parsing.PorterStemmer.stem_sentence(self,txt)
gensim.parsing.porter.PorterStemmer(self)
gensim.parsing.porter.PorterStemmer.__init__(self)
gensim.parsing.porter.PorterStemmer._cons(self,i)
gensim.parsing.porter.PorterStemmer._cvc(self,i)
gensim.parsing.porter.PorterStemmer._doublec(self,j)
gensim.parsing.porter.PorterStemmer._ends(self,s)
gensim.parsing.porter.PorterStemmer._m(self)
gensim.parsing.porter.PorterStemmer._r(self,s)
gensim.parsing.porter.PorterStemmer._setto(self,s)
gensim.parsing.porter.PorterStemmer._step1ab(self)
gensim.parsing.porter.PorterStemmer._step1c(self)
gensim.parsing.porter.PorterStemmer._step2(self)
gensim.parsing.porter.PorterStemmer._step3(self)
gensim.parsing.porter.PorterStemmer._step4(self)
gensim.parsing.porter.PorterStemmer._step5(self)
gensim.parsing.porter.PorterStemmer._vowelinstem(self)
gensim.parsing.porter.PorterStemmer.stem(self,w)
gensim.parsing.porter.PorterStemmer.stem_documents(self,docs)
gensim.parsing.porter.PorterStemmer.stem_sentence(self,txt)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/parsing/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/tfidfmodel.py----------------------------------------
A:gensim.models.tfidfmodel.logger->logging.getLogger(__name__)
A:gensim.models.tfidfmodel.(n_tf, n_df, n_n)->resolve_weights(smartirs)
A:gensim.models.tfidfmodel.self.wlocal->partial(updated_wlocal, n_tf=n_tf)
A:gensim.models.tfidfmodel.self.wglobal->partial(updated_wglobal, n_df=n_df)
A:gensim.models.tfidfmodel.self.normalize->partial(updated_normalize, n_n=n_n)
A:gensim.models.tfidfmodel.self.dfs->dictionary.dfs.copy()
A:gensim.models.tfidfmodel.self.idfs->precompute_idfs(self.wglobal, self.dfs, self.num_docs)
A:gensim.models.tfidfmodel.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.tfidfmodel.tf_array->self.wlocal(np.array(tf_array))
A:gensim.models.tfidfmodel.vector->self.normalize(vector)
gensim.models.TfidfModel(self,corpus=None,id2word=None,dictionary=None,wlocal=utils.identity,wglobal=df2idf,normalize=True,smartirs=None)
gensim.models.TfidfModel.__getitem__(self,bow,eps=1e-12)
gensim.models.TfidfModel.__str__(self)
gensim.models.TfidfModel.initialize(self,corpus)
gensim.models.tfidfmodel.TfidfModel(self,corpus=None,id2word=None,dictionary=None,wlocal=utils.identity,wglobal=df2idf,normalize=True,smartirs=None)
gensim.models.tfidfmodel.TfidfModel.__getitem__(self,bow,eps=1e-12)
gensim.models.tfidfmodel.TfidfModel.__init__(self,corpus=None,id2word=None,dictionary=None,wlocal=utils.identity,wglobal=df2idf,normalize=True,smartirs=None)
gensim.models.tfidfmodel.TfidfModel.__str__(self)
gensim.models.tfidfmodel.TfidfModel.initialize(self,corpus)
gensim.models.tfidfmodel.df2idf(docfreq,totaldocs,log_base=2.0,add=0.0)
gensim.models.tfidfmodel.precompute_idfs(wglobal,dfs,total_docs)
gensim.models.tfidfmodel.resolve_weights(smartirs)
gensim.models.tfidfmodel.updated_normalize(x,n_n)
gensim.models.tfidfmodel.updated_wglobal(docfreq,totaldocs,n_df)
gensim.models.tfidfmodel.updated_wlocal(tf,n_tf)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/ldamodel.py----------------------------------------
A:gensim.models.ldamodel.logger->logging.getLogger('gensim.models.ldamodel')
A:gensim.models.ldamodel.dprior->numpy.copy(prior)
A:gensim.models.ldamodel.self.eta->update_dir_prior(self.eta, N, logphat, rho)
A:gensim.models.ldamodel.self.sstats->numpy.zeros(shape, dtype=dtype)
A:gensim.models.ldamodel.result->super(LdaModel, cls).load(fname, *args, **kwargs)
A:gensim.models.ldamodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.ldamodel.self.num_terms->len(self.id2word)
A:gensim.models.ldamodel.self.distributed->bool(distributed)
A:gensim.models.ldamodel.self.num_topics->int(num_topics)
A:gensim.models.ldamodel.(self.alpha, self.optimize_alpha)->self.init_dir_prior(alpha, 'alpha')
A:gensim.models.ldamodel.(self.eta, self.optimize_eta)->self.init_dir_prior(eta, 'eta')
A:gensim.models.ldamodel.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.ldamodel.self.dispatcher->Pyro4.Proxy(ns.list(prefix=LDA_DISPATCHER_PREFIX)[LDA_DISPATCHER_PREFIX])
A:gensim.models.ldamodel.self.numworkers->len(self.dispatcher.getworkers())
A:gensim.models.ldamodel.self.state->LdaState(self.eta, (self.num_topics, self.num_terms), dtype=self.dtype)
A:gensim.models.ldamodel.self.state.sstats[...]->self.random_state.gamma(100.0, 1.0 / 100.0, (self.num_topics, self.num_terms))
A:gensim.models.ldamodel.self.expElogbeta->numpy.exp(self.state.get_Elogbeta())
A:gensim.models.ldamodel.init_prior->numpy.asarray([prior] * prior_shape, dtype=self.dtype)
A:gensim.models.ldamodel.chunk->list(chunk)
A:gensim.models.ldamodel.gamma->self.random_state.gamma(100.0, 1.0 / 100.0, (len(chunk), self.num_topics)).astype(self.dtype, copy=False)
A:gensim.models.ldamodel.Elogtheta->dirichlet_expectation(gamma)
A:gensim.models.ldamodel.expElogtheta->numpy.exp(Elogtheta)
A:gensim.models.ldamodel.sstats->numpy.zeros_like(self.expElogbeta, dtype=self.dtype)
A:gensim.models.ldamodel.cts->numpy.array([cnt for (_, cnt) in doc], dtype=self.dtype)
A:gensim.models.ldamodel.Elogthetad->dirichlet_expectation(gammad)
A:gensim.models.ldamodel.expElogthetad->numpy.exp(Elogthetad)
A:gensim.models.ldamodel.meanchange->mean_absolute_difference(gammad, lastgamma)
A:gensim.models.ldamodel.(gamma, sstats)->self.inference(chunk, collect_sstats=True)
A:gensim.models.ldamodel.N->float(lambdat.shape[0])
A:gensim.models.ldamodel.self.alpha->update_dir_prior(self.alpha, N, logphat, rho)
A:gensim.models.ldamodel.logphat->(sum((dirichlet_expectation(lambda_) for lambda_ in lambdat)) / N).reshape((self.num_terms,))
A:gensim.models.ldamodel.total_docs->len(chunk)
A:gensim.models.ldamodel.corpus_words->sum((cnt for document in chunk for (_, cnt) in document))
A:gensim.models.ldamodel.lencorpus->sum((1 for _ in corpus))
A:gensim.models.ldamodel.chunksize->min(lencorpus, self.chunksize)
A:gensim.models.ldamodel.updateafter->min(lencorpus, update_every * self.numworkers * chunksize)
A:gensim.models.ldamodel.evalafter->min(lencorpus, (eval_every or 0) * self.numworkers * chunksize)
A:gensim.models.ldamodel.updates_per_pass->max(1, lencorpus / updateafter)
A:gensim.models.ldamodel.callback->Callback(self.callbacks)
A:gensim.models.ldamodel.self.metrics->defaultdict(list)
A:gensim.models.ldamodel.other->self.dispatcher.getstate()
A:gensim.models.ldamodel.gammat->self.do_estep(chunk, other)
A:gensim.models.ldamodel.current_metrics->Callback(self.callbacks).on_epoch_end(pass_)
A:gensim.models.ldamodel.diff->numpy.log(self.expElogbeta)
A:gensim.models.ldamodel._lambda->self.state.get_lambda()
A:gensim.models.ldamodel.Elogbeta->dirichlet_expectation(_lambda)
A:gensim.models.ldamodel.(gammad, _)->self.inference([doc])
A:gensim.models.ldamodel.sum_eta->numpy.sum(self.eta)
A:gensim.models.ldamodel.chosen_topics->range(num_topics)
A:gensim.models.ldamodel.num_topics->min(num_topics, self.num_topics)
A:gensim.models.ldamodel.sorted_topics->list(matutils.argsort(sort_alpha))
A:gensim.models.ldamodel.topic->self.state.get_lambda()
A:gensim.models.ldamodel.bestn->gensim.matutils.argsort(topic, topn=topn, reverse=True)
A:gensim.models.ldamodel.topic_->' + '.join(['%.3f*"%s"' % (v, k) for (k, v) in topic_])
A:gensim.models.ldamodel.topics->self.state.get_lambda()
A:gensim.models.ldamodel.cm->CoherenceModel(model=self, corpus=corpus, texts=texts, dictionary=dictionary, window_size=window_size, coherence=coherence, topn=topn, processes=processes)
A:gensim.models.ldamodel.coherence_scores->CoherenceModel(model=self, corpus=corpus, texts=texts, dictionary=dictionary, window_size=window_size, coherence=coherence, topn=topn, processes=processes).get_coherence_per_topic()
A:gensim.models.ldamodel.scored_topics->zip(str_topics, coherence_scores)
A:gensim.models.ldamodel.minimum_probability->max(minimum_probability, 1e-08)
A:gensim.models.ldamodel.minimum_phi_value->max(minimum_phi_value, 1e-08)
A:gensim.models.ldamodel.(is_corpus, corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.ldamodel.kwargs->dict(per_word_topics=per_word_topics, minimum_probability=minimum_probability, minimum_phi_value=minimum_phi_value)
A:gensim.models.ldamodel.(gamma, phis)->self.inference([bow], collect_sstats=per_word_topics)
A:gensim.models.ldamodel.sorted_phi_values->sorted(phi_values, reverse=True)
A:gensim.models.ldamodel.valid_keys->', '.join(('`{}`'.format(x) for x in distances.keys()))
A:gensim.models.ldamodel.z->numpy.zeros((t1_size, t2_size))
A:gensim.models.ldamodel.annotation_terms->numpy.zeros((t1_size, t2_size), dtype=list)
A:gensim.models.ldamodel.z[topic]->distance_func(d1[topic1], d2[topic2])
A:gensim.models.ldamodel.neg_tokens->fst_topics[topic1].symmetric_difference(snd_topics[topic2])
A:gensim.models.ldamodel.ignore->list({'state', 'dispatcher', 'id2word'} | set(ignore))
A:gensim.models.ldamodel.separately->list(set(separately_explicit) | set(separately))
A:gensim.models.ldamodel.kwargs['mmap']->dict(per_word_topics=per_word_topics, minimum_probability=minimum_probability, minimum_phi_value=minimum_phi_value).get('mmap', None)
A:gensim.models.ldamodel.result.random_state->gensim.utils.get_random_state(None)
A:gensim.models.ldamodel.state_fname->gensim.utils.smart_extension(fname, '.state')
A:gensim.models.ldamodel.result.state->LdaState.load(state_fname, *args, **kwargs)
A:gensim.models.ldamodel.id2word_fname->gensim.utils.smart_extension(fname, '.id2word')
A:gensim.models.ldamodel.result.id2word->gensim.utils.unpickle(id2word_fname)
gensim.models.LdaModel(self,corpus=None,num_topics=100,id2word=None,distributed=False,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,ns_conf=None,minimum_phi_value=0.01,per_word_topics=False,callbacks=None,dtype=np.float32)
gensim.models.LdaModel.__getitem__(self,bow,eps=None)
gensim.models.LdaModel.__str__(self)
gensim.models.LdaModel.bound(self,corpus,gamma=None,subsample_ratio=1.0)
gensim.models.LdaModel.clear(self)
gensim.models.LdaModel.diff(self,other,distance='kullback_leibler',num_words=100,n_ann_terms=10,diagonal=False,annotation=True,normed=True)
gensim.models.LdaModel.do_estep(self,chunk,state=None)
gensim.models.LdaModel.do_mstep(self,rho,other,extra_pass=False)
gensim.models.LdaModel.get_document_topics(self,bow,minimum_probability=None,minimum_phi_value=None,per_word_topics=False)
gensim.models.LdaModel.get_term_topics(self,word_id,minimum_probability=None)
gensim.models.LdaModel.get_topic_terms(self,topicid,topn=10)
gensim.models.LdaModel.get_topics(self)
gensim.models.LdaModel.inference(self,chunk,collect_sstats=False)
gensim.models.LdaModel.init_dir_prior(self,prior,name)
gensim.models.LdaModel.load(cls,fname,*args,**kwargs)
gensim.models.LdaModel.log_perplexity(self,chunk,total_docs=None)
gensim.models.LdaModel.save(self,fname,ignore=('state','dispatcher'),separately=None,*args,**kwargs)
gensim.models.LdaModel.show_topic(self,topicid,topn=10)
gensim.models.LdaModel.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.LdaModel.sync_state(self)
gensim.models.LdaModel.top_topics(self,corpus=None,texts=None,dictionary=None,window_size=None,coherence='u_mass',topn=20,processes=-1)
gensim.models.LdaModel.update(self,corpus,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.LdaModel.update_alpha(self,gammat,rho)
gensim.models.LdaModel.update_eta(self,lambdat,rho)
gensim.models.ldamodel.LdaModel(self,corpus=None,num_topics=100,id2word=None,distributed=False,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,ns_conf=None,minimum_phi_value=0.01,per_word_topics=False,callbacks=None,dtype=np.float32)
gensim.models.ldamodel.LdaModel.__getitem__(self,bow,eps=None)
gensim.models.ldamodel.LdaModel.__init__(self,corpus=None,num_topics=100,id2word=None,distributed=False,chunksize=2000,passes=1,update_every=1,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,minimum_probability=0.01,random_state=None,ns_conf=None,minimum_phi_value=0.01,per_word_topics=False,callbacks=None,dtype=np.float32)
gensim.models.ldamodel.LdaModel.__str__(self)
gensim.models.ldamodel.LdaModel.bound(self,corpus,gamma=None,subsample_ratio=1.0)
gensim.models.ldamodel.LdaModel.clear(self)
gensim.models.ldamodel.LdaModel.diff(self,other,distance='kullback_leibler',num_words=100,n_ann_terms=10,diagonal=False,annotation=True,normed=True)
gensim.models.ldamodel.LdaModel.do_estep(self,chunk,state=None)
gensim.models.ldamodel.LdaModel.do_mstep(self,rho,other,extra_pass=False)
gensim.models.ldamodel.LdaModel.get_document_topics(self,bow,minimum_probability=None,minimum_phi_value=None,per_word_topics=False)
gensim.models.ldamodel.LdaModel.get_term_topics(self,word_id,minimum_probability=None)
gensim.models.ldamodel.LdaModel.get_topic_terms(self,topicid,topn=10)
gensim.models.ldamodel.LdaModel.get_topics(self)
gensim.models.ldamodel.LdaModel.inference(self,chunk,collect_sstats=False)
gensim.models.ldamodel.LdaModel.init_dir_prior(self,prior,name)
gensim.models.ldamodel.LdaModel.load(cls,fname,*args,**kwargs)
gensim.models.ldamodel.LdaModel.log_perplexity(self,chunk,total_docs=None)
gensim.models.ldamodel.LdaModel.save(self,fname,ignore=('state','dispatcher'),separately=None,*args,**kwargs)
gensim.models.ldamodel.LdaModel.show_topic(self,topicid,topn=10)
gensim.models.ldamodel.LdaModel.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.ldamodel.LdaModel.sync_state(self)
gensim.models.ldamodel.LdaModel.top_topics(self,corpus=None,texts=None,dictionary=None,window_size=None,coherence='u_mass',topn=20,processes=-1)
gensim.models.ldamodel.LdaModel.update(self,corpus,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.ldamodel.LdaModel.update_alpha(self,gammat,rho)
gensim.models.ldamodel.LdaModel.update_eta(self,lambdat,rho)
gensim.models.ldamodel.LdaState(self,eta,shape,dtype=np.float32)
gensim.models.ldamodel.LdaState.__init__(self,eta,shape,dtype=np.float32)
gensim.models.ldamodel.LdaState.blend(self,rhot,other,targetsize=None)
gensim.models.ldamodel.LdaState.blend2(self,rhot,other,targetsize=None)
gensim.models.ldamodel.LdaState.get_Elogbeta(self)
gensim.models.ldamodel.LdaState.get_lambda(self)
gensim.models.ldamodel.LdaState.load(cls,fname,*args,**kwargs)
gensim.models.ldamodel.LdaState.merge(self,other)
gensim.models.ldamodel.LdaState.reset(self)
gensim.models.ldamodel.update_dir_prior(prior,N,logphat,rho)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/utils_any2vec.py----------------------------------------
A:gensim.models.utils_any2vec.logger->logging.getLogger(__name__)
A:gensim.models.utils_any2vec.old_settings->numpy.seterr(all='ignore')
A:gensim.models.utils_any2vec.h->numpy.uint32(2166136261)
A:gensim.models.utils_any2vec.total_vec->len(vocab)
A:gensim.models.utils_any2vec.row->row.astype(REAL).astype(REAL)
A:gensim.models.utils_any2vec.(word, count)->gensim.utils.to_unicode(line).strip().split()
A:gensim.models.utils_any2vec.counts[word]->int(count)
A:gensim.models.utils_any2vec.header->gensim.utils.to_unicode(fin.readline(), encoding=encoding)
A:gensim.models.utils_any2vec.vocab_size->min(vocab_size, limit)
A:gensim.models.utils_any2vec.result->cls(vector_size)
A:gensim.models.utils_any2vec.result.vectors->ascontiguousarray(result.vectors[:len(result.vocab)])
A:gensim.models.utils_any2vec.word_id->len(result.vocab)
A:gensim.models.utils_any2vec.result.vocab[word]->Vocab(index=word_id, count=None)
A:gensim.models.utils_any2vec.ch->fin.read(1)
A:gensim.models.utils_any2vec.word->gensim.utils.to_unicode(b''.join(word), encoding=encoding, errors=unicode_errors)
A:gensim.models.utils_any2vec.weights->fromstring(fin.read(binary_len), dtype=REAL).astype(datatype)
A:gensim.models.utils_any2vec.line->fin.readline()
A:gensim.models.utils_any2vec.parts->gensim.utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(' ')
gensim.models.utils_any2vec._load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.utils_any2vec._save_word2vec_format(fname,vocab,vectors,fvocab=None,binary=False,total_vec=None)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/keyedvectors.py----------------------------------------
A:gensim.models.keyedvectors.logger->logging.getLogger(__name__)
A:gensim.models.keyedvectors.all_distances->self.distances(entity1)
A:gensim.models.keyedvectors.kwargs['ignore']->kwargs.get('ignore', ['vectors_norm', 'vectors_vocab_norm', 'vectors_ngrams_norm', 'buckets_word'])
A:gensim.models.keyedvectors.mean->gensim.matutils.unitvec(vectors.mean(axis=0)).astype(REAL)
A:gensim.models.keyedvectors.dists->dot(vectors, mean)
A:gensim.models.keyedvectors.best->gensim.matutils.argsort(dists, topn=topn + len(all_docs), reverse=True)
A:gensim.models.keyedvectors.matrix_order->len(dictionary)
A:gensim.models.keyedvectors.matrix->scipy.sparse.identity(matrix_order, dtype=dtype, format='dok')
A:gensim.models.keyedvectors.word_indices->range(matrix_order)
A:gensim.models.keyedvectors.columns->sorted(columns, key=lambda x: x[0])
A:gensim.models.keyedvectors.len_pre_oov1->len(document1)
A:gensim.models.keyedvectors.len_pre_oov2->len(document2)
A:gensim.models.keyedvectors.dictionary->Dictionary(documents=[document1, document2])
A:gensim.models.keyedvectors.vocab_len->len(dictionary)
A:gensim.models.keyedvectors.docset1->set(document1)
A:gensim.models.keyedvectors.docset2->set(document2)
A:gensim.models.keyedvectors.distance_matrix->zeros((vocab_len, vocab_len), dtype=double)
A:gensim.models.keyedvectors.distance_matrix[i, j]->sqrt(np_sum((self[t1] - self[t2]) ** 2))
A:gensim.models.keyedvectors.d->zeros(vocab_len, dtype=double)
A:gensim.models.keyedvectors.nbow->Dictionary(documents=[document1, document2]).doc2bow(document)
A:gensim.models.keyedvectors.doc_len->len(document)
A:gensim.models.keyedvectors.d1->model.infer_vector(doc_words=doc_words1, alpha=alpha, min_alpha=min_alpha, steps=steps)
A:gensim.models.keyedvectors.d2->model.infer_vector(doc_words=doc_words2, alpha=alpha, min_alpha=min_alpha, steps=steps)
A:gensim.models.keyedvectors.vectors->vstack((self.vectors_docs_norm[self._int_index(doc, self.doctags, self.max_rawint)] for doc in docs)).astype(REAL)
A:gensim.models.keyedvectors.norm->numpy.linalg.norm(vector_1)
A:gensim.models.keyedvectors.all_norms->numpy.linalg.norm(vectors_all, axis=1)
A:gensim.models.keyedvectors.dot_products->dot(vectors_all, vector_1)
A:gensim.models.keyedvectors.input_vector->self.word_vec(word_or_vector)
A:gensim.models.keyedvectors.line->gensim.utils.to_unicode(line)
A:gensim.models.keyedvectors.sims->most_similar(self, positive=[b, c], negative=[a], topn=False, restrict_vocab=restrict_vocab)
A:gensim.models.keyedvectors.sim->float(sim)
A:gensim.models.keyedvectors.spearman->scipy.stats.spearmanr(similarity_gold, similarity_model)
A:gensim.models.keyedvectors.pearson->scipy.stats.pearsonr(similarity_gold, similarity_model)
A:gensim.models.keyedvectors.self.vectors_norm->(self.vectors / sqrt((self.vectors ** 2).sum(-1))[..., newaxis]).astype(REAL)
A:gensim.models.keyedvectors.layer->Embedding(input_dim=weights.shape[0], output_dim=weights.shape[1], weights=[weights], trainable=train_embeddings)
A:gensim.models.keyedvectors.self.vectors_docs_norm->empty(self.vectors_docs.shape, dtype=REAL)
A:gensim.models.keyedvectors.char_ngrams->_compute_ngrams(word, self.min_n, self.max_n)
A:gensim.models.keyedvectors.word_vec->numpy.zeros(self.vectors_ngrams.shape[1], dtype=np.float32)
A:gensim.models.keyedvectors.ngrams->_compute_ngrams(word, self.min_n, self.max_n)
A:gensim.models.keyedvectors.self.vectors_ngrams_norm->(self.vectors_ngrams / sqrt((self.vectors_ngrams ** 2).sum(-1))[..., newaxis]).astype(REAL)
gensim.models.keyedvectors.BaseKeyedVectors(self,vector_size)
gensim.models.keyedvectors.BaseKeyedVectors.__contains__(self,entity)
gensim.models.keyedvectors.BaseKeyedVectors.__getitem__(self,entities)
gensim.models.keyedvectors.BaseKeyedVectors.__init__(self,vector_size)
gensim.models.keyedvectors.BaseKeyedVectors.closer_than(self,entity1,entity2)
gensim.models.keyedvectors.BaseKeyedVectors.distance(self,entity1,entity2)
gensim.models.keyedvectors.BaseKeyedVectors.distances(self,entity1,other_entities=())
gensim.models.keyedvectors.BaseKeyedVectors.get_vector(self,entity)
gensim.models.keyedvectors.BaseKeyedVectors.load(cls,fname_or_handle,**kwargs)
gensim.models.keyedvectors.BaseKeyedVectors.most_similar(self,**kwargs)
gensim.models.keyedvectors.BaseKeyedVectors.most_similar_to_given(self,entity1,entities_list)
gensim.models.keyedvectors.BaseKeyedVectors.rank(self,entity1,entity2)
gensim.models.keyedvectors.BaseKeyedVectors.save(self,fname_or_handle,**kwargs)
gensim.models.keyedvectors.BaseKeyedVectors.similarity(self,entity1,entity2)
gensim.models.keyedvectors.Doc2VecKeyedVectors(self,vector_size,mapfile_path)
gensim.models.keyedvectors.Doc2VecKeyedVectors.__contains__(self,index)
gensim.models.keyedvectors.Doc2VecKeyedVectors.__getitem__(self,index)
gensim.models.keyedvectors.Doc2VecKeyedVectors.__init__(self,vector_size,mapfile_path)
gensim.models.keyedvectors.Doc2VecKeyedVectors.__len__(self)
gensim.models.keyedvectors.Doc2VecKeyedVectors._index_to_doctag(i_index,offset2doctag,max_rawint)
gensim.models.keyedvectors.Doc2VecKeyedVectors._int_index(index,doctags,max_rawint)
gensim.models.keyedvectors.Doc2VecKeyedVectors.distance(self,d1,d2)
gensim.models.keyedvectors.Doc2VecKeyedVectors.distances(self,d1,other_docs=())
gensim.models.keyedvectors.Doc2VecKeyedVectors.doctag_syn0(self)
gensim.models.keyedvectors.Doc2VecKeyedVectors.doctag_syn0norm(self)
gensim.models.keyedvectors.Doc2VecKeyedVectors.doesnt_match(self,docs)
gensim.models.keyedvectors.Doc2VecKeyedVectors.index2entity(self)
gensim.models.keyedvectors.Doc2VecKeyedVectors.index2entity(self,value)
gensim.models.keyedvectors.Doc2VecKeyedVectors.index_to_doctag(self,i_index)
gensim.models.keyedvectors.Doc2VecKeyedVectors.init_sims(self,replace=False)
gensim.models.keyedvectors.Doc2VecKeyedVectors.int_index(self,index,doctags,max_rawint)
gensim.models.keyedvectors.Doc2VecKeyedVectors.most_similar(self,positive=None,negative=None,topn=10,clip_start=0,clip_end=None,indexer=None)
gensim.models.keyedvectors.Doc2VecKeyedVectors.n_similarity(self,ds1,ds2)
gensim.models.keyedvectors.Doc2VecKeyedVectors.save(self,*args,**kwargs)
gensim.models.keyedvectors.Doc2VecKeyedVectors.save_word2vec_format(self,fname,prefix='*dt_',fvocab=None,total_vec=None,binary=False,write_first_line=True)
gensim.models.keyedvectors.Doc2VecKeyedVectors.similarity(self,d1,d2)
gensim.models.keyedvectors.Doc2VecKeyedVectors.similarity_unseen_docs(self,model,doc_words1,doc_words2,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.models.keyedvectors.FastTextKeyedVectors(self,vector_size,min_n,max_n)
gensim.models.keyedvectors.FastTextKeyedVectors.__contains__(self,word)
gensim.models.keyedvectors.FastTextKeyedVectors.__init__(self,vector_size,min_n,max_n)
gensim.models.keyedvectors.FastTextKeyedVectors.init_sims(self,replace=False)
gensim.models.keyedvectors.FastTextKeyedVectors.save(self,*args,**kwargs)
gensim.models.keyedvectors.FastTextKeyedVectors.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None)
gensim.models.keyedvectors.FastTextKeyedVectors.syn0_ngrams(self)
gensim.models.keyedvectors.FastTextKeyedVectors.syn0_ngrams_norm(self)
gensim.models.keyedvectors.FastTextKeyedVectors.syn0_vocab(self)
gensim.models.keyedvectors.FastTextKeyedVectors.syn0_vocab_norm(self)
gensim.models.keyedvectors.FastTextKeyedVectors.word_vec(self,word,use_norm=False)
gensim.models.keyedvectors.Vocab(self,**kwargs)
gensim.models.keyedvectors.Vocab.__init__(self,**kwargs)
gensim.models.keyedvectors.Vocab.__lt__(self,other)
gensim.models.keyedvectors.Vocab.__str__(self)
gensim.models.keyedvectors.Word2VecKeyedVectors(WordEmbeddingsKeyedVectors)
gensim.models.keyedvectors.Word2VecKeyedVectors.get_keras_embedding(self,train_embeddings=False)
gensim.models.keyedvectors.Word2VecKeyedVectors.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.keyedvectors.Word2VecKeyedVectors.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors(self,vector_size)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.__contains__(self,word)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.__init__(self,vector_size)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.accuracy(self,questions,restrict_vocab=30000,most_similar=most_similar,case_insensitive=True)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.cosine_similarities(vector_1,vectors_all)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.distance(self,w1,w2)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.distances(self,word_or_vector,other_words=())
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.doesnt_match(self,words)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.get_vector(self,word)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.index2entity(self)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.index2entity(self,value)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.init_sims(self,replace=False)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.log_accuracy(section)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.log_evaluate_word_pairs(pearson,spearman,oov,pairs)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar(self,positive=None,negative=None,topn=10,restrict_vocab=None,indexer=None)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.n_similarity(self,ws1,ws2)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.save(self,*args,**kwargs)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similarity(self,w1,w2)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.similarity_matrix(self,dictionary,tfidf=None,threshold=0.0,exponent=2.0,nonzero_limit=100,dtype=REAL)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.syn0(self)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.syn0(self,value)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.syn0norm(self)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.syn0norm(self,value)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.wmdistance(self,document1,document2)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.word_vec(self,word,use_norm=False)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.words_closer_than(self,w1,w2)
gensim.models.keyedvectors.WordEmbeddingsKeyedVectors.wv(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/base_any2vec.py----------------------------------------
A:gensim.models.base_any2vec.logger->logging.getLogger(__name__)
A:gensim.models.base_any2vec.self.vector_size->int(vector_size)
A:gensim.models.base_any2vec.self.workers->int(workers)
A:gensim.models.base_any2vec.thread_private_mem->self._get_thread_working_mem()
A:gensim.models.base_any2vec.job->Queue(maxsize=queue_factor * self.workers).get()
A:gensim.models.base_any2vec.(tally, raw_tally)->self._do_train_job(data_iterable, job_parameters, thread_private_mem)
A:gensim.models.base_any2vec.next_job_params->self._update_job_params(next_job_params, epoch_progress, cur_epoch)
A:gensim.models.base_any2vec.data_length->self._raw_word_count([data])
A:gensim.models.base_any2vec.report->Queue(maxsize=(queue_factor + 1) * self.workers).get()
A:gensim.models.base_any2vec.job_queue->Queue(maxsize=queue_factor * self.workers)
A:gensim.models.base_any2vec.progress_queue->Queue(maxsize=(queue_factor + 1) * self.workers)
A:gensim.models.base_any2vec.(trained_word_count, raw_word_count, job_tally)->self._log_epoch_progress(progress_queue, job_queue, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words, report_delay=report_delay)
A:gensim.models.base_any2vec.(trained_word_count_epoch, raw_word_count_epoch, job_tally_epoch)->self._train_epoch(data_iterable, cur_epoch=cur_epoch, total_examples=total_examples, total_words=total_words, queue_factor=queue_factor, report_delay=report_delay)
A:gensim.models.base_any2vec.self.sg->int(sg)
A:gensim.models.base_any2vec.self.alpha->float(alpha)
A:gensim.models.base_any2vec.self.window->int(window)
A:gensim.models.base_any2vec.self.random->numpy.random.RandomState(seed)
A:gensim.models.base_any2vec.self.min_alpha->float(min_alpha)
A:gensim.models.base_any2vec.self.hs->int(hs)
A:gensim.models.base_any2vec.self.negative->int(negative)
A:gensim.models.base_any2vec.self.cbow_mean->int(cbow_mean)
A:gensim.models.base_any2vec.self.compute_loss->bool(compute_loss)
A:gensim.models.base_any2vec.self.min_alpha_yet_reached->float(alpha)
A:gensim.models.base_any2vec.self.neg_labels->zeros(self.negative + 1)
A:gensim.models.base_any2vec.(total_words, corpus_count)->self.vocabulary.scan_vocab(sentences, progress_per=progress_per, trim_rule=trim_rule)
A:gensim.models.base_any2vec.report_values->self.vocabulary.prepare_vocab(self.hs, self.negative, self.wv, keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, update=update)
A:gensim.models.base_any2vec.report_values['memory']->self.estimate_memory(vocab_size=report_values['num_retained_words'])
A:gensim.models.base_any2vec.report['total']->sum(report.values())
A:gensim.models.base_any2vec.next_alpha->max(end_alpha, next_alpha)
A:gensim.models.base_any2vec.work->gensim.matutils.zeros_aligned(self.trainables.layer1_size, dtype=REAL)
A:gensim.models.base_any2vec.neu1->gensim.matutils.zeros_aligned(self.trainables.layer1_size, dtype=REAL)
A:gensim.models.base_any2vec.model->super(BaseWordEmbeddingsModel, cls).load(*args, **kwargs)
A:gensim.models.base_any2vec.model.trainables.vectors_lockf->ones(len(model.wv.vectors), dtype=REAL)
A:gensim.models.base_any2vec.model.random->numpy.random.RandomState(model.trainables.seed)
gensim.models.base_any2vec.BaseAny2VecModel(self,workers=3,vector_size=100,epochs=5,callbacks=(),batch_words=10000)
gensim.models.base_any2vec.BaseAny2VecModel.__init__(self,workers=3,vector_size=100,epochs=5,callbacks=(),batch_words=10000)
gensim.models.base_any2vec.BaseAny2VecModel._check_training_sanity(self,epochs=None,total_examples=None,total_words=None,**kwargs)
gensim.models.base_any2vec.BaseAny2VecModel._clear_post_train(self)
gensim.models.base_any2vec.BaseAny2VecModel._do_train_job(self,data_iterable,job_parameters,thread_private_mem)
gensim.models.base_any2vec.BaseAny2VecModel._get_job_params(self,cur_epoch)
gensim.models.base_any2vec.BaseAny2VecModel._get_thread_working_mem(self)
gensim.models.base_any2vec.BaseAny2VecModel._job_producer(self,data_iterator,job_queue,cur_epoch=0,total_examples=None,total_words=None)
gensim.models.base_any2vec.BaseAny2VecModel._log_epoch_end(self,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed)
gensim.models.base_any2vec.BaseAny2VecModel._log_epoch_progress(self,progress_queue,job_queue,cur_epoch=0,total_examples=None,total_words=None,report_delay=1.0)
gensim.models.base_any2vec.BaseAny2VecModel._log_progress(self,job_queue,progress_queue,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed)
gensim.models.base_any2vec.BaseAny2VecModel._log_train_end(self,raw_word_count,trained_word_count,total_elapsed,job_tally)
gensim.models.base_any2vec.BaseAny2VecModel._raw_word_count(self,job)
gensim.models.base_any2vec.BaseAny2VecModel._set_train_params(self,**kwargs)
gensim.models.base_any2vec.BaseAny2VecModel._train_epoch(self,data_iterable,cur_epoch=0,total_examples=None,total_words=None,queue_factor=2,report_delay=1.0)
gensim.models.base_any2vec.BaseAny2VecModel._update_job_params(self,job_params,epoch_progress,cur_epoch)
gensim.models.base_any2vec.BaseAny2VecModel._worker_loop(self,job_queue,progress_queue)
gensim.models.base_any2vec.BaseAny2VecModel.load(cls,fname_or_handle,**kwargs)
gensim.models.base_any2vec.BaseAny2VecModel.save(self,fname_or_handle,**kwargs)
gensim.models.base_any2vec.BaseAny2VecModel.train(self,data_iterable,epochs=None,total_examples=None,total_words=None,queue_factor=2,report_delay=1.0,callbacks=(),**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel(self,sentences=None,workers=3,vector_size=100,epochs=5,callbacks=(),batch_words=10000,trim_rule=None,sg=0,alpha=0.025,window=5,seed=1,hs=0,negative=5,cbow_mean=1,min_alpha=0.0001,compute_loss=False,fast_version=0,**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.__init__(self,sentences=None,workers=3,vector_size=100,epochs=5,callbacks=(),batch_words=10000,trim_rule=None,sg=0,alpha=0.025,window=5,seed=1,hs=0,negative=5,cbow_mean=1,min_alpha=0.0001,compute_loss=False,fast_version=0,**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.__str__(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._check_training_sanity(self,epochs=None,total_examples=None,total_words=None,**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._clear_post_train(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._do_train_job(self,data_iterable,job_parameters,thread_private_mem)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._get_job_params(self,cur_epoch)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._get_thread_working_mem(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._log_epoch_end(self,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._log_progress(self,job_queue,progress_queue,cur_epoch,example_count,total_examples,raw_word_count,total_words,trained_word_count,elapsed)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._log_train_end(self,raw_word_count,trained_word_count,total_elapsed,job_tally)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._raw_word_count(self,job)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._set_train_params(self,**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel._update_job_params(self,job_params,epoch_progress,cur_epoch)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.build_vocab(self,sentences,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.cum_table(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.cum_table(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.cum_table(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.doesnt_match(self,words)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.estimate_memory(self,vocab_size=None,report=None)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.hashfxn(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.hashfxn(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.iter(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.iter(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.layer1_size(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.layer1_size(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.load(cls,*args,**kwargs)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.min_count(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.min_count(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.most_similar(self,positive=None,negative=None,topn=10,restrict_vocab=None,indexer=None)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.n_similarity(self,ws1,ws2)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.sample(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.sample(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.similarity(self,w1,w2)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn0_lockf(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn0_lockf(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn0_lockf(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn1(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn1(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn1(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn1neg(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn1neg(self)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.syn1neg(self,value)
gensim.models.base_any2vec.BaseWordEmbeddingsModel.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=False,callbacks=())
gensim.models.base_any2vec.BaseWordEmbeddingsModel.wmdistance(self,document1,document2)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/hdpmodel.py----------------------------------------
A:gensim.models.hdpmodel.logger->logging.getLogger(__name__)
A:gensim.models.hdpmodel.dig_sum->psi(np.sum(v, 0))
A:gensim.models.hdpmodel.Elogsticks->numpy.zeros(n)
A:gensim.models.hdpmodel.gamma->numpy.zeros((len(chunk), self.lda_beta.shape[0]))
A:gensim.models.hdpmodel.expElogtheta->numpy.exp(Elogtheta)
A:gensim.models.hdpmodel.counts->numpy.array(doc_word_counts)
A:gensim.models.hdpmodel.Elogtheta->dirichlet_expectation(gamma)
A:gensim.models.hdpmodel.meanchange->numpy.mean(abs(gamma - lastgamma))
A:gensim.models.hdpmodel.likelihood->numpy.sum(counts * np.log(phinorm))
A:gensim.models.hdpmodel.self.m_var_sticks_ss->numpy.zeros(T)
A:gensim.models.hdpmodel.self.m_var_beta_ss->numpy.zeros((T, Wt))
A:gensim.models.hdpmodel.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.hdpmodel.self.m_W->len(id2word)
A:gensim.models.hdpmodel.self.m_D->len(corpus)
A:gensim.models.hdpmodel.self.m_var_sticks->numpy.zeros((2, T - 1))
A:gensim.models.hdpmodel.self.m_var_sticks[1]->range(T - 1, 0, -1)
A:gensim.models.hdpmodel.self.m_varphi_ss->numpy.zeros(T)
A:gensim.models.hdpmodel.self.m_Elogbeta->dirichlet_expectation(self.m_eta + self.m_lambda)
A:gensim.models.hdpmodel.self.m_timestamp->numpy.zeros(self.m_W, dtype=int)
A:gensim.models.hdpmodel.self.m_lambda_sum->numpy.sum(self.m_lambda, axis=1)
A:gensim.models.hdpmodel.chunk->list(chunk)
A:gensim.models.hdpmodel.(ids, counts)->zip(*doc)
A:gensim.models.hdpmodel.(_, gammad)->lda_e_step(ids, counts, self.lda_alpha, self.lda_beta)
A:gensim.models.hdpmodel.(is_corpus, corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.hdpmodel.save_freq->max(1, int(10000 / self.chunksize))
A:gensim.models.hdpmodel.start_time->time.clock()
A:gensim.models.hdpmodel.(alpha, beta)->self.hdp_to_lda()
A:gensim.models.hdpmodel.unique_words->dict()
A:gensim.models.hdpmodel.unique_words[word_id]->len(unique_words)
A:gensim.models.hdpmodel.wt->len(word_list)
A:gensim.models.hdpmodel.rw->numpy.array([self.m_r[t] for t in self.m_timestamp[word_list]])
A:gensim.models.hdpmodel.ss->SuffStats(self.m_T, wt, len(chunk))
A:gensim.models.hdpmodel.Elogsticks_1st->expect_log_sticks(self.m_var_sticks)
A:gensim.models.hdpmodel.(doc_word_ids, doc_word_counts)->zip(*doc)
A:gensim.models.hdpmodel.doc_score->self.doc_e_step(ss, Elogsticks_1st, unique_words, doc_word_ids, doc_word_counts, self.m_var_converge)
A:gensim.models.hdpmodel.v->numpy.zeros((2, self.m_K - 1))
A:gensim.models.hdpmodel.var_phi->numpy.exp(log_var_phi)
A:gensim.models.hdpmodel.(log_var_phi, log_norm)->gensim.matutils.ret_log_normalize_vec(var_phi)
A:gensim.models.hdpmodel.(log_phi, log_norm)->gensim.matutils.ret_log_normalize_vec(phi)
A:gensim.models.hdpmodel.phi->numpy.exp(log_phi)
A:gensim.models.hdpmodel.phi_cum->numpy.flipud(np.sum(phi_all[:, 1:], 0))
A:gensim.models.hdpmodel.Elogsticks_2nd->expect_log_sticks(v)
A:gensim.models.hdpmodel.log_alpha->numpy.log(self.m_alpha)
A:gensim.models.hdpmodel.var_phi_sum->numpy.flipud(self.m_varphi_ss[1:])
A:gensim.models.hdpmodel.idx->gensim.matutils.argsort(topics_sums, reverse=True)
A:gensim.models.hdpmodel.hdp_formatter->HdpTopicFormatter(self.id2word, betas)
A:gensim.models.hdpmodel.alpha->numpy.zeros(self.m_T)
A:gensim.models.hdpmodel.ldam->gensim.models.ldamodel.LdaModel(num_topics=self.m_T, alpha=alpha, id2word=self.id2word, random_state=self.random_state, dtype=np.float64)
A:gensim.models.hdpmodel.(self.lda_alpha, self.lda_beta)->self.hdp_to_lda()
A:gensim.models.hdpmodel.(likelihood, gamma)->lda_e_step(doc_word_ids, doc_word_counts, self.lda_alpha, self.lda_beta)
A:gensim.models.hdpmodel.log_predicts->numpy.log(np.dot(theta, lda_betad))
A:gensim.models.hdpmodel.topics->numpy.loadtxt('%s' % topic_file)
A:gensim.models.hdpmodel.topics_sums->numpy.sum(topics, axis=1)
A:gensim.models.hdpmodel.num_topics->min(num_topics, len(self.data))
A:gensim.models.hdpmodel.lambdak->list(self.data[topic_id, :])
A:gensim.models.hdpmodel.temp->sorted(temp, key=lambda x: x[0], reverse=True)
A:gensim.models.hdpmodel.topic_terms->self.show_topic_terms(temp, topn)
A:gensim.models.hdpmodel.topic->self.format_topic(topic_id, topic_terms)
A:gensim.models.hdpmodel.fmt->'\n'.join(['    %20s    %.8f' % (word, weight) for (word, weight) in topic_terms])
gensim.models.HdpModel(self,corpus,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.models.HdpModel.__getitem__(self,bow,eps=0.01)
gensim.models.HdpModel.doc_e_step(self,ss,Elogsticks_1st,unique_words,doc_word_ids,doc_word_counts,var_converge)
gensim.models.HdpModel.evaluate_test_corpus(self,corpus)
gensim.models.HdpModel.get_topics(self)
gensim.models.HdpModel.hdp_to_lda(self)
gensim.models.HdpModel.inference(self,chunk)
gensim.models.HdpModel.optimal_ordering(self)
gensim.models.HdpModel.save_options(self)
gensim.models.HdpModel.save_topics(self,doc_count=None)
gensim.models.HdpModel.show_topic(self,topic_id,topn=20,log=False,formatted=False,num_words=None)
gensim.models.HdpModel.show_topics(self,num_topics=20,num_words=20,log=False,formatted=True)
gensim.models.HdpModel.suggested_lda_model(self)
gensim.models.HdpModel.update(self,corpus)
gensim.models.HdpModel.update_chunk(self,chunk,update=True,opt_o=True)
gensim.models.HdpModel.update_expectations(self)
gensim.models.HdpModel.update_finished(self,start_time,chunks_processed,docs_processed)
gensim.models.HdpModel.update_lambda(self,sstats,word_list,opt_o)
gensim.models.hdpmodel.HdpModel(self,corpus,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.models.hdpmodel.HdpModel.__getitem__(self,bow,eps=0.01)
gensim.models.hdpmodel.HdpModel.__init__(self,corpus,id2word,max_chunks=None,max_time=None,chunksize=256,kappa=1.0,tau=64.0,K=15,T=150,alpha=1,gamma=1,eta=0.01,scale=1.0,var_converge=0.0001,outputdir=None,random_state=None)
gensim.models.hdpmodel.HdpModel.doc_e_step(self,ss,Elogsticks_1st,unique_words,doc_word_ids,doc_word_counts,var_converge)
gensim.models.hdpmodel.HdpModel.evaluate_test_corpus(self,corpus)
gensim.models.hdpmodel.HdpModel.get_topics(self)
gensim.models.hdpmodel.HdpModel.hdp_to_lda(self)
gensim.models.hdpmodel.HdpModel.inference(self,chunk)
gensim.models.hdpmodel.HdpModel.optimal_ordering(self)
gensim.models.hdpmodel.HdpModel.save_options(self)
gensim.models.hdpmodel.HdpModel.save_topics(self,doc_count=None)
gensim.models.hdpmodel.HdpModel.show_topic(self,topic_id,topn=20,log=False,formatted=False,num_words=None)
gensim.models.hdpmodel.HdpModel.show_topics(self,num_topics=20,num_words=20,log=False,formatted=True)
gensim.models.hdpmodel.HdpModel.suggested_lda_model(self)
gensim.models.hdpmodel.HdpModel.update(self,corpus)
gensim.models.hdpmodel.HdpModel.update_chunk(self,chunk,update=True,opt_o=True)
gensim.models.hdpmodel.HdpModel.update_expectations(self)
gensim.models.hdpmodel.HdpModel.update_finished(self,start_time,chunks_processed,docs_processed)
gensim.models.hdpmodel.HdpModel.update_lambda(self,sstats,word_list,opt_o)
gensim.models.hdpmodel.HdpTopicFormatter(self,dictionary=None,topic_data=None,topic_file=None,style=None)
gensim.models.hdpmodel.HdpTopicFormatter.__init__(self,dictionary=None,topic_data=None,topic_file=None,style=None)
gensim.models.hdpmodel.HdpTopicFormatter.format_topic(self,topic_id,topic_terms)
gensim.models.hdpmodel.HdpTopicFormatter.print_topic(self,topic_id,topn=None,num_words=None)
gensim.models.hdpmodel.HdpTopicFormatter.print_topics(self,num_topics=10,num_words=10)
gensim.models.hdpmodel.HdpTopicFormatter.show_topic(self,topic_id,topn=20,log=False,formatted=False,num_words=None)
gensim.models.hdpmodel.HdpTopicFormatter.show_topic_terms(self,topic_data,num_words)
gensim.models.hdpmodel.HdpTopicFormatter.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.hdpmodel.SuffStats(self,T,Wt,Dt)
gensim.models.hdpmodel.SuffStats.__init__(self,T,Wt,Dt)
gensim.models.hdpmodel.SuffStats.set_zero(self)
gensim.models.hdpmodel.expect_log_sticks(sticks)
gensim.models.hdpmodel.lda_e_step(doc_word_ids,doc_word_counts,alpha,beta,max_iter=100)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/translation_matrix.py----------------------------------------
A:gensim.models.translation_matrix.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.translation_matrix.(self.source_word, self.target_word)->zip(*word_pairs)
A:gensim.models.translation_matrix.self.source_space->Space.build(self.source_lang_vec, set(self.source_word))
A:gensim.models.translation_matrix.self.target_space->Space.build(self.target_lang_vec, set(self.target_word))
A:gensim.models.translation_matrix.kwargs['ignore']->kwargs.get('ignore', ['source_space', 'target_space'])
A:gensim.models.translation_matrix.lexicon->self.random_state.choice(list(lexicon.difference(source_words)), addition)
A:gensim.models.translation_matrix.addition->min(sample_num, len(lexicon) - len(source_words))
A:gensim.models.translation_matrix.source_space->Space.build(source_lang_vec, source_words)
A:gensim.models.translation_matrix.target_space->Space.build(target_lang_vec)
A:gensim.models.translation_matrix.mapped_source_space->self.apply_transmat(source_space)
A:gensim.models.translation_matrix.srtd_idx->numpy.argsort(np.argsort(sim_matrix, axis=1), axis=1)
A:gensim.models.translation_matrix.sim_matrix_idx->numpy.argsort(sim_matrix, axis=0)
A:gensim.models.translation_matrix.translated_word->OrderedDict()
gensim.models.BackMappingTranslationMatrix(self,source_lang_vec,target_lang_vec,tagged_docs=None,random_state=None)
gensim.models.BackMappingTranslationMatrix.infer_vector(self,target_doc_vec)
gensim.models.BackMappingTranslationMatrix.train(self,tagged_docs)
gensim.models.TranslationMatrix(self,source_lang_vec,target_lang_vec,word_pairs=None,random_state=None)
gensim.models.TranslationMatrix.apply_transmat(self,words_space)
gensim.models.TranslationMatrix.save(self,*args,**kwargs)
gensim.models.TranslationMatrix.train(self,word_pairs)
gensim.models.TranslationMatrix.translate(self,source_words,topn=5,gc=0,sample_num=None,source_lang_vec=None,target_lang_vec=None)
gensim.models.translation_matrix.BackMappingTranslationMatrix(self,source_lang_vec,target_lang_vec,tagged_docs=None,random_state=None)
gensim.models.translation_matrix.BackMappingTranslationMatrix.__init__(self,source_lang_vec,target_lang_vec,tagged_docs=None,random_state=None)
gensim.models.translation_matrix.BackMappingTranslationMatrix.infer_vector(self,target_doc_vec)
gensim.models.translation_matrix.BackMappingTranslationMatrix.train(self,tagged_docs)
gensim.models.translation_matrix.Space(self,matrix,index2word)
gensim.models.translation_matrix.Space.__init__(self,matrix,index2word)
gensim.models.translation_matrix.Space.build(cls,lang_vec,lexicon=None)
gensim.models.translation_matrix.Space.normalize(self)
gensim.models.translation_matrix.TranslationMatrix(self,source_lang_vec,target_lang_vec,word_pairs=None,random_state=None)
gensim.models.translation_matrix.TranslationMatrix.__init__(self,source_lang_vec,target_lang_vec,word_pairs=None,random_state=None)
gensim.models.translation_matrix.TranslationMatrix.apply_transmat(self,words_space)
gensim.models.translation_matrix.TranslationMatrix.save(self,*args,**kwargs)
gensim.models.translation_matrix.TranslationMatrix.train(self,word_pairs)
gensim.models.translation_matrix.TranslationMatrix.translate(self,source_words,topn=5,gc=0,sample_num=None,source_lang_vec=None,target_lang_vec=None)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/atmodel.py----------------------------------------
A:gensim.models.atmodel.logger->logging.getLogger('gensim.models.atmodel')
A:gensim.models.atmodel.self.sstats->numpy.zeros(lambda_shape)
A:gensim.models.atmodel.self.gamma->numpy.zeros(gamma_shape)
A:gensim.models.atmodel.authors_ids->set()
A:gensim.models.atmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.atmodel.self.num_terms->len(self.id2word)
A:gensim.models.atmodel.(self.alpha, self.optimize_alpha)->self.init_dir_prior(alpha, 'alpha')
A:gensim.models.atmodel.(self.eta, self.optimize_eta)->self.init_dir_prior(eta, 'eta')
A:gensim.models.atmodel.self.random_state->gensim.utils.get_random_state(random_state)
A:gensim.models.atmodel.self.state->AuthorTopicState(self.eta, (self.num_topics, self.num_terms), (self.num_authors, self.num_topics))
A:gensim.models.atmodel.self.state.sstats->self.random_state.gamma(100.0, 1.0 / 100.0, (self.num_topics, self.num_terms))
A:gensim.models.atmodel.self.expElogbeta->numpy.exp(dirichlet_expectation(self.state.sstats))
A:gensim.models.atmodel.self.corpus->MmCorpus(self.serialization_path)
A:gensim.models.atmodel.corpus_chain->chain(self.corpus, corpus)
A:gensim.models.atmodel.expElogtheta_sum->numpy.exp(Elogthetad).sum(axis=0)
A:gensim.models.atmodel.chunk->list(chunk)
A:gensim.models.atmodel.sstats->numpy.zeros_like(self.expElogbeta)
A:gensim.models.atmodel.gamma_chunk->numpy.vstack([gamma_chunk, tilde_gamma])
A:gensim.models.atmodel.cts->numpy.array([cnt for (_, cnt) in doc])
A:gensim.models.atmodel.tilde_gamma->gammad.copy()
A:gensim.models.atmodel.Elogthetad->dirichlet_expectation(tilde_gamma)
A:gensim.models.atmodel.expElogthetad->numpy.exp(Elogthetad)
A:gensim.models.atmodel.phinorm->self.compute_phinorm(expElogtheta[authors_d, :], expElogbeta[:, ids])
A:gensim.models.atmodel.lastgamma->gammad.copy().copy()
A:gensim.models.atmodel.meanchange_gamma->numpy.mean(abs(tilde_gamma - lastgamma))
A:gensim.models.atmodel.expElogtheta_sum_a->numpy.exp(Elogthetad).sum(axis=0)
A:gensim.models.atmodel.(gamma, sstats)->self.inference(chunk, author2doc, doc2author, rhot, collect_sstats=True, chunk_doc_idx=chunk_doc_idx)
A:gensim.models.atmodel.total_docs->len(chunk)
A:gensim.models.atmodel.corpus_words->sum((cnt for document in chunk for (_, cnt) in document))
A:gensim.models.atmodel.author2doc->construct_author2doc(doc2author)
A:gensim.models.atmodel.doc2author->construct_doc2author(corpus, author2doc)
A:gensim.models.atmodel.num_input_authors->len(author2doc)
A:gensim.models.atmodel.len_input_corpus->sum((1 for _ in corpus))
A:gensim.models.atmodel.num_new_authors->len(new_authors)
A:gensim.models.atmodel.gamma_new->self.random_state.gamma(100.0, 1.0 / 100.0, (num_new_authors, self.num_topics))
A:gensim.models.atmodel.self.state.gamma->numpy.vstack([self.state.gamma, gamma_new])
A:gensim.models.atmodel.train_corpus_idx->list(set(train_corpus_idx))
A:gensim.models.atmodel.lencorpus->len(train_corpus_idx)
A:gensim.models.atmodel.chunksize->min(lencorpus, self.chunksize)
A:gensim.models.atmodel.updateafter->min(lencorpus, update_every * self.numworkers * chunksize)
A:gensim.models.atmodel.evalafter->min(lencorpus, (eval_every or 0) * self.numworkers * chunksize)
A:gensim.models.atmodel.updates_per_pass->max(1, lencorpus / updateafter)
A:gensim.models.atmodel.other->self.dispatcher.getstate()
A:gensim.models.atmodel.gammat->self.do_estep(chunk, self.author2doc, self.doc2author, rho(), other, chunk_doc_idx)
A:gensim.models.atmodel._lambda->self.state.get_lambda()
A:gensim.models.atmodel.Elogbeta->dirichlet_expectation(_lambda)
A:gensim.models.atmodel.expElogbeta->numpy.exp(Elogbeta)
A:gensim.models.atmodel.Elogtheta->dirichlet_expectation(gamma)
A:gensim.models.atmodel.expElogtheta->numpy.exp(Elogtheta)
A:gensim.models.atmodel.ids->numpy.array([id for (id, _) in doc])
A:gensim.models.atmodel.sum_eta->numpy.sum(self.eta)
A:gensim.models.atmodel.minimum_probability->max(minimum_probability, 1e-08)
A:gensim.models.atmodel.items->self.get_author_topics(author_names, minimum_probability=eps)
gensim.models.AuthorTopicModel(self,corpus=None,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.models.AuthorTopicModel.__getitem__(self,author_names,eps=None)
gensim.models.AuthorTopicModel.__str__(self)
gensim.models.AuthorTopicModel.bound(self,chunk,chunk_doc_idx=None,subsample_ratio=1.0,author2doc=None,doc2author=None)
gensim.models.AuthorTopicModel.compute_phinorm(self,expElogthetad,expElogbetad)
gensim.models.AuthorTopicModel.do_estep(self,chunk,author2doc,doc2author,rhot,state=None,chunk_doc_idx=None)
gensim.models.AuthorTopicModel.extend_corpus(self,corpus)
gensim.models.AuthorTopicModel.get_author_topics(self,author_name,minimum_probability=None)
gensim.models.AuthorTopicModel.get_document_topics(self,word_id,minimum_probability=None)
gensim.models.AuthorTopicModel.inference(self,chunk,author2doc,doc2author,rhot,collect_sstats=False,chunk_doc_idx=None)
gensim.models.AuthorTopicModel.init_empty_corpus(self)
gensim.models.AuthorTopicModel.log_perplexity(self,chunk,chunk_doc_idx=None,total_docs=None)
gensim.models.AuthorTopicModel.update(self,corpus=None,author2doc=None,doc2author=None,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.atmodel.AuthorTopicModel(self,corpus=None,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.models.atmodel.AuthorTopicModel.__getitem__(self,author_names,eps=None)
gensim.models.atmodel.AuthorTopicModel.__init__(self,corpus=None,num_topics=100,id2word=None,author2doc=None,doc2author=None,chunksize=2000,passes=1,iterations=50,decay=0.5,offset=1.0,alpha='symmetric',eta='symmetric',update_every=1,eval_every=10,gamma_threshold=0.001,serialized=False,serialization_path=None,minimum_probability=0.01,random_state=None)
gensim.models.atmodel.AuthorTopicModel.__str__(self)
gensim.models.atmodel.AuthorTopicModel.bound(self,chunk,chunk_doc_idx=None,subsample_ratio=1.0,author2doc=None,doc2author=None)
gensim.models.atmodel.AuthorTopicModel.compute_phinorm(self,expElogthetad,expElogbetad)
gensim.models.atmodel.AuthorTopicModel.do_estep(self,chunk,author2doc,doc2author,rhot,state=None,chunk_doc_idx=None)
gensim.models.atmodel.AuthorTopicModel.extend_corpus(self,corpus)
gensim.models.atmodel.AuthorTopicModel.get_author_topics(self,author_name,minimum_probability=None)
gensim.models.atmodel.AuthorTopicModel.get_document_topics(self,word_id,minimum_probability=None)
gensim.models.atmodel.AuthorTopicModel.inference(self,chunk,author2doc,doc2author,rhot,collect_sstats=False,chunk_doc_idx=None)
gensim.models.atmodel.AuthorTopicModel.init_empty_corpus(self)
gensim.models.atmodel.AuthorTopicModel.log_perplexity(self,chunk,chunk_doc_idx=None,total_docs=None)
gensim.models.atmodel.AuthorTopicModel.update(self,corpus=None,author2doc=None,doc2author=None,chunksize=None,decay=None,offset=None,passes=None,update_every=None,eval_every=None,iterations=None,gamma_threshold=None,chunks_as_numpy=False)
gensim.models.atmodel.AuthorTopicState(self,eta,lambda_shape,gamma_shape)
gensim.models.atmodel.AuthorTopicState.__init__(self,eta,lambda_shape,gamma_shape)
gensim.models.atmodel.construct_author2doc(doc2author)
gensim.models.atmodel.construct_doc2author(corpus,author2doc)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/phrases.py----------------------------------------
A:gensim.models.phrases.logger->logging.getLogger(__name__)
A:gensim.models.phrases.obj_iter->itertools.chain([peek], obj_iter)
A:gensim.models.phrases.peek->next(obj_iter)
A:gensim.models.phrases.bigram->Phrases(sentences, min_count=5, threshold=100)
A:gensim.models.phrases.score->self.score_item(worda=last_uncommon, wordb=word, components=chain, scorer=scorer)
A:gensim.models.phrases.model->super(Phrases, cls).load(*args, **kwargs)
A:gensim.models.phrases.model.common_terms->frozenset()
A:gensim.models.phrases.self.vocab->defaultdict(int)
A:gensim.models.phrases.self.common_terms->frozenset((utils.any2utf8(w) for w in common_terms))
A:gensim.models.phrases.test_pickle->pickle.dumps(self.scoring)
A:gensim.models.phrases.load_pickle->pickle.loads(test_pickle)
A:gensim.models.phrases.vocab->defaultdict(int)
A:gensim.models.phrases.components->itertools.chain([last_uncommon], in_between, [word])
A:gensim.models.phrases.(min_reduce, vocab, total_words)->self.learn_vocab(sentences, self.max_vocab_size, self.delimiter, self.progress_per, self.common_terms)
A:gensim.models.phrases.self.min_reduce->max(self.min_reduce, min_reduce)
A:gensim.models.phrases.analyze_sentence->functools.partial(self.analyze_sentence, threshold=self.threshold, common_terms=self.common_terms, scorer=ft.partial(self.scoring, len_vocab=float(len(self.vocab)), min_count=float(self.min_count), corpus_word_count=float(self.corpus_word_count)))
A:gensim.models.phrases.bigrams->self.analyze_sentence(sentence, threshold=self.threshold, common_terms=self.common_terms, scorer=None)
A:gensim.models.phrases.(is_single, sentence)->_is_single(sentence)
A:gensim.models.phrases.words->delimiter.join(words)
A:gensim.models.phrases.unigrams->k.split(sep)
A:gensim.models.phrases.cterms->list(it.takewhile(lambda w: w in common_terms, unigrams[i:]))
A:gensim.models.phrases.corpus->self.pseudocorpus(phrases_model)
A:gensim.models.phrases.program->os.path.basename(sys.argv[0])
A:gensim.models.phrases.sentences->Text8Corpus(infile)
gensim.models.Phrases(self,sentences=None,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter=b'_',progress_per=10000,scoring='default',common_terms=frozenset())
gensim.models.Phrases.__getitem__(self,sentence)
gensim.models.Phrases.__str__(self)
gensim.models.Phrases.add_vocab(self,sentences)
gensim.models.Phrases.export_phrases(self,sentences,out_delimiter=b'',as_tuples=False)
gensim.models.Phrases.learn_vocab(sentences,max_vocab_size,delimiter=b'_',progress_per=10000,common_terms=frozenset())
gensim.models.Phrases.load(cls,*args,**kwargs)
gensim.models.PhrasesTransformation(interfaces.TransformationABC)
gensim.models.PhrasesTransformation.load(cls,*args,**kwargs)
gensim.models.phrases.Phraser(self,phrases_model)
gensim.models.phrases.Phraser.__getitem__(self,sentence)
gensim.models.phrases.Phraser.__init__(self,phrases_model)
gensim.models.phrases.Phraser.pseudocorpus(self,phrases_model)
gensim.models.phrases.Phraser.score_item(self,worda,wordb,components,scorer)
gensim.models.phrases.Phrases(self,sentences=None,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter=b'_',progress_per=10000,scoring='default',common_terms=frozenset())
gensim.models.phrases.Phrases.__getitem__(self,sentence)
gensim.models.phrases.Phrases.__init__(self,sentences=None,min_count=5,threshold=10.0,max_vocab_size=40000000,delimiter=b'_',progress_per=10000,scoring='default',common_terms=frozenset())
gensim.models.phrases.Phrases.__str__(self)
gensim.models.phrases.Phrases.add_vocab(self,sentences)
gensim.models.phrases.Phrases.export_phrases(self,sentences,out_delimiter=b'',as_tuples=False)
gensim.models.phrases.Phrases.learn_vocab(sentences,max_vocab_size,delimiter=b'_',progress_per=10000,common_terms=frozenset())
gensim.models.phrases.Phrases.load(cls,*args,**kwargs)
gensim.models.phrases.PhrasesTransformation(interfaces.TransformationABC)
gensim.models.phrases.PhrasesTransformation.load(cls,*args,**kwargs)
gensim.models.phrases.SentenceAnalyzer(object)
gensim.models.phrases.SentenceAnalyzer.analyze_sentence(self,sentence,threshold,common_terms,scorer)
gensim.models.phrases.SentenceAnalyzer.score_item(self,worda,wordb,components,scorer)
gensim.models.phrases._is_single(obj)
gensim.models.phrases.npmi_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)
gensim.models.phrases.original_scorer(worda_count,wordb_count,bigram_count,len_vocab,min_count,corpus_word_count)
gensim.models.phrases.pseudocorpus(source_vocab,sep,common_terms=frozenset())


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/ldamulticore.py----------------------------------------
A:gensim.models.ldamulticore.logger->logging.getLogger(__name__)
A:gensim.models.ldamulticore.lencorpus->sum((1 for _ in corpus))
A:gensim.models.ldamulticore.evalafter->min(lencorpus, (self.eval_every or 0) * updateafter)
A:gensim.models.ldamulticore.updates_per_pass->max(1, lencorpus / updateafter)
A:gensim.models.ldamulticore.job_queue->Queue(maxsize=2 * self.workers)
A:gensim.models.ldamulticore.result_queue->Queue()
A:gensim.models.ldamulticore.pool->Pool(self.workers, worker_e_step, (job_queue, result_queue))
A:gensim.models.ldamulticore.other->LdaState(self.eta, self.state.sstats.shape)
A:gensim.models.ldamulticore.chunk_stream->gensim.utils.grouper(corpus, self.chunksize, as_numpy=chunks_as_numpy)
A:gensim.models.ldamulticore.(chunk_no, chunk, worker_lda)->input_queue.get()
gensim.models.LdaMulticore(self,corpus=None,num_topics=100,id2word=None,workers=None,chunksize=2000,passes=1,batch=False,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,random_state=None,minimum_probability=0.01,minimum_phi_value=0.01,per_word_topics=False,dtype=np.float32)
gensim.models.LdaMulticore.update(self,corpus,chunks_as_numpy=False)
gensim.models.ldamulticore.LdaMulticore(self,corpus=None,num_topics=100,id2word=None,workers=None,chunksize=2000,passes=1,batch=False,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,random_state=None,minimum_probability=0.01,minimum_phi_value=0.01,per_word_topics=False,dtype=np.float32)
gensim.models.ldamulticore.LdaMulticore.__init__(self,corpus=None,num_topics=100,id2word=None,workers=None,chunksize=2000,passes=1,batch=False,alpha='symmetric',eta=None,decay=0.5,offset=1.0,eval_every=10,iterations=50,gamma_threshold=0.001,random_state=None,minimum_probability=0.01,minimum_phi_value=0.01,per_word_topics=False,dtype=np.float32)
gensim.models.ldamulticore.LdaMulticore.update(self,corpus,chunks_as_numpy=False)
gensim.models.ldamulticore.worker_e_step(input_queue,result_queue)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/lsimodel.py----------------------------------------
A:gensim.models.lsimodel.logger->logging.getLogger(__name__)
A:gensim.models.lsimodel.rel_spectrum->numpy.abs(1.0 - np.cumsum(s / np.sum(s)))
A:gensim.models.lsimodel.k->clip_spectrum(s_k ** 2, self.k)
A:gensim.models.lsimodel.a->numpy.ascontiguousarray(a)
A:gensim.models.lsimodel.(u, s)->stochastic_svd(docs, k, chunksize=sys.maxsize, num_terms=m, power_iters=self.power_iters, extra_dims=self.extra_dims, dtype=dtype)
A:gensim.models.lsimodel.docs->gensim.matutils.corpus2csc(docs)
A:gensim.models.lsimodel.(ut, s, vt)->sparsesvd.sparsesvd(docs, k + 30)
A:gensim.models.lsimodel.self.u->numpy.dot(self.u, u1_k)
A:gensim.models.lsimodel.self.s->other.s.copy()
A:gensim.models.lsimodel.c->numpy.asarray(self.projection.u.T[topicno, :]).flatten()
A:gensim.models.lsimodel.(q, r)->gensim.matutils.qr_destroy(other.u)
A:gensim.models.lsimodel.(u_k, s_k, _)->scipy.linalg.svd(np.dot(k, k.T), full_matrices=False)
A:gensim.models.lsimodel.s_k->numpy.sqrt(s_k)
A:gensim.models.lsimodel.q->q[:, :samples].T.copy().T.copy()
A:gensim.models.lsimodel.self.num_topics->int(num_topics)
A:gensim.models.lsimodel.self.chunksize->int(chunksize)
A:gensim.models.lsimodel.self.decay->float(decay)
A:gensim.models.lsimodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.lsimodel.self.num_terms->len(self.id2word)
A:gensim.models.lsimodel.self.projection->self.dispatcher.getstate()
A:gensim.models.lsimodel.dispatcher->Pyro4.Proxy('PYRONAME:gensim.lsi_dispatcher')
A:gensim.models.lsimodel.self.numworkers->len(dispatcher.getworkers())
A:gensim.models.lsimodel.update->Projection(self.num_terms, self.num_topics, corpus.tocsc(), extra_dims=self.extra_samples, power_iters=self.power_iters, dtype=self.dtype)
A:gensim.models.lsimodel.(update.u, update.s)->stochastic_svd(corpus, self.num_topics, num_terms=self.num_terms, chunksize=chunksize, extra_dims=self.extra_samples, power_iters=self.power_iters, dtype=self.dtype)
A:gensim.models.lsimodel.nnz->sum((len(doc) for doc in chunk))
A:gensim.models.lsimodel.job->gensim.matutils.corpus2csc(chunk, num_docs=len(chunk), num_terms=self.num_terms, num_nnz=nnz, dtype=self.dtype)
A:gensim.models.lsimodel.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.lsimodel.vec->gensim.matutils.corpus2csc(bow, num_terms=self.num_terms, dtype=self.projection.u.dtype)
A:gensim.models.lsimodel.topic_dist->topic_dist.reshape(-1).reshape(-1)
A:gensim.models.lsimodel.result->super(LsiModel, cls).load(fname, *args, **kwargs)
A:gensim.models.lsimodel.num_topics->len(projections)
A:gensim.models.lsimodel.norm->numpy.sqrt(np.sum(np.dot(c, c)))
A:gensim.models.lsimodel.most->gensim.matutils.argsort(np.abs(c), topn, reverse=True)
A:gensim.models.lsimodel.topic->self.show_topic(i, topn=num_words)
A:gensim.models.lsimodel.kwargs['mmap']->kwargs.get('mmap', None)
A:gensim.models.lsimodel.projection_fname->gensim.utils.smart_extension(fname, '.projection')
A:gensim.models.lsimodel.result.projection->super(LsiModel, cls).load(projection_fname, *args, **kwargs)
A:gensim.models.lsimodel.uvec->numpy.abs(np.asarray(uvec).flatten())
A:gensim.models.lsimodel.weights->sorted(result[topic], key=lambda x: -abs(x[0]))
A:gensim.models.lsimodel.rank->int(rank)
A:gensim.models.lsimodel.samples->max(10, 2 * rank)
A:gensim.models.lsimodel.num_terms->int(num_terms)
A:gensim.models.lsimodel.y->y.astype(dtype).astype(dtype)
A:gensim.models.lsimodel.o->numpy.random.normal(0.0, 1.0, (n, samples)).astype(dtype)
A:gensim.models.lsimodel.(q, _)->gensim.matutils.qr_destroy(q)
A:gensim.models.lsimodel.s->numpy.sqrt(s)
A:gensim.models.lsimodel.chunk->gensim.matutils.corpus2csc(chunk, num_terms=num_terms, dtype=qt.dtype)
A:gensim.models.lsimodel.yold->q[:, :samples].T.copy().T.copy().copy()
A:gensim.models.lsimodel.qt->q[:, :samples].T.copy()
A:gensim.models.lsimodel.(u, s, vt)->scipy.linalg.svd(x)
A:gensim.models.lsimodel.x->numpy.zeros(shape=(qt.shape[0], qt.shape[0]), dtype=dtype)
A:gensim.models.lsimodel.keep->clip_spectrum(s ** 2, rank, discard=eps)
A:gensim.models.lsimodel.u->numpy.dot(q, u)
gensim.models.LsiModel(self,corpus=None,num_topics=200,id2word=None,chunksize=20000,decay=1.0,distributed=False,onepass=True,power_iters=P2_EXTRA_ITERS,extra_samples=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.LsiModel.__getitem__(self,bow,scaled=False,chunksize=512)
gensim.models.LsiModel.__str__(self)
gensim.models.LsiModel.add_documents(self,corpus,chunksize=None,decay=None)
gensim.models.LsiModel.get_topics(self)
gensim.models.LsiModel.load(cls,fname,*args,**kwargs)
gensim.models.LsiModel.print_debug(self,num_topics=5,num_words=10)
gensim.models.LsiModel.save(self,fname,*args,**kwargs)
gensim.models.LsiModel.show_topic(self,topicno,topn=10)
gensim.models.LsiModel.show_topics(self,num_topics=-1,num_words=10,log=False,formatted=True)
gensim.models.lsimodel.LsiModel(self,corpus=None,num_topics=200,id2word=None,chunksize=20000,decay=1.0,distributed=False,onepass=True,power_iters=P2_EXTRA_ITERS,extra_samples=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.LsiModel.__getitem__(self,bow,scaled=False,chunksize=512)
gensim.models.lsimodel.LsiModel.__init__(self,corpus=None,num_topics=200,id2word=None,chunksize=20000,decay=1.0,distributed=False,onepass=True,power_iters=P2_EXTRA_ITERS,extra_samples=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.LsiModel.__str__(self)
gensim.models.lsimodel.LsiModel.add_documents(self,corpus,chunksize=None,decay=None)
gensim.models.lsimodel.LsiModel.get_topics(self)
gensim.models.lsimodel.LsiModel.load(cls,fname,*args,**kwargs)
gensim.models.lsimodel.LsiModel.print_debug(self,num_topics=5,num_words=10)
gensim.models.lsimodel.LsiModel.save(self,fname,*args,**kwargs)
gensim.models.lsimodel.LsiModel.show_topic(self,topicno,topn=10)
gensim.models.lsimodel.LsiModel.show_topics(self,num_topics=-1,num_words=10,log=False,formatted=True)
gensim.models.lsimodel.Projection(self,m,k,docs=None,use_svdlibc=False,power_iters=P2_EXTRA_ITERS,extra_dims=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.Projection.__init__(self,m,k,docs=None,use_svdlibc=False,power_iters=P2_EXTRA_ITERS,extra_dims=P2_EXTRA_DIMS,dtype=np.float64)
gensim.models.lsimodel.Projection.empty_like(self)
gensim.models.lsimodel.Projection.merge(self,other,decay=1.0)
gensim.models.lsimodel.ascarray(a,name='')
gensim.models.lsimodel.asfarray(a,name='')
gensim.models.lsimodel.clip_spectrum(s,k,discard=0.001)
gensim.models.lsimodel.print_debug(id2token,u,s,topics,num_words=10,num_neg=None)
gensim.models.lsimodel.stochastic_svd(corpus,rank,num_terms,chunksize=20000,extra_dims=None,power_iters=0,dtype=np.float64,eps=1e-06)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/ldaseqmodel.py----------------------------------------
A:gensim.models.ldaseqmodel.logger->logging.getLogger('gensim.models.ldaseqmodel')
A:gensim.models.ldaseqmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.ldaseqmodel.self.vocab_len->len(self.id2word)
A:gensim.models.ldaseqmodel.self.corpus_len->sum((1 for _ in corpus))
A:gensim.models.ldaseqmodel.self.num_time_slices->len(time_slice)
A:gensim.models.ldaseqmodel.max_doc_len->len(line)
A:gensim.models.ldaseqmodel.self.alphas->numpy.full(num_topics, alphas)
A:gensim.models.ldaseqmodel.sslm_->sslm(num_time_slices=self.num_time_slices, vocab_len=self.vocab_len, num_topics=self.num_topics, chain_variance=chain_variance, obs_variance=obs_variance)
A:gensim.models.ldaseqmodel.lda_model->self.make_lda_seq_slice(lda_model, time)
A:gensim.models.ldaseqmodel.self.sstats->numpy.transpose(lda_model.state.sstats)
A:gensim.models.ldaseqmodel.gammas->numpy.resize(np.zeros(corpus_len * num_topics), (corpus_len, num_topics))
A:gensim.models.ldaseqmodel.lhoods->numpy.resize(np.zeros(corpus_len * num_topics + 1), (corpus_len, num_topics + 1))
A:gensim.models.ldaseqmodel.(bound, gammas)->self.inferDIMseq(corpus, topic_suffstats, gammas, lhoods, lda, ldapost, iter_, bound, lda_inference_max_iter, chunksize)
A:gensim.models.ldaseqmodel.topic_bound->self.fit_lda_seq_topics(topic_suffstats)
A:gensim.models.ldaseqmodel.convergence->numpy.fabs((bound - old_bound) / old_bound)
A:gensim.models.ldaseqmodel.lda->self.make_lda_seq_slice(lda, time)
A:gensim.models.ldaseqmodel.lda.topics->numpy.array(np.split(np.zeros(vocab_len * num_topics), vocab_len))
A:gensim.models.ldaseqmodel.ldapost->LdaPost(num_topics=self.num_topics, max_doc_len=len(doc), lda=lda_model, doc=doc)
A:gensim.models.ldaseqmodel.time_slice->numpy.cumsum(np.array(self.time_slice))
A:gensim.models.ldaseqmodel.doc_lhood->LdaPost.fit_lda_post(ldapost, doc_num, time, self, lda_inference_max_iter=lda_inference_max_iter)
A:gensim.models.ldaseqmodel.topic_suffstats->LdaPost.update_lda_seq_ss(ldapost, time, doc, topic_suffstats)
A:gensim.models.ldaseqmodel.lda.topics[:, k]->numpy.copy(self.topic_chains[k].e_log_prob[:, time])
A:gensim.models.ldaseqmodel.lda.alpha->numpy.copy(self.alphas)
A:gensim.models.ldaseqmodel.lhood_term->sslm.fit_sslm(chain, topic_suffstats[k])
A:gensim.models.ldaseqmodel.topic->numpy.exp(topic[time])
A:gensim.models.ldaseqmodel.bestn->gensim.matutils.argsort(topic, top_terms, reverse=True)
A:gensim.models.ldaseqmodel.doc_topic->numpy.copy(self.gammas)
A:gensim.models.ldaseqmodel.term_frequency->numpy.zeros(self.vocab_len)
A:gensim.models.ldaseqmodel.lda_model.topics->numpy.array(np.split(np.zeros(self.vocab_len * self.num_topics), self.vocab_len))
A:gensim.models.ldaseqmodel.lhood->self.compute_lda_lhood()
A:gensim.models.ldaseqmodel.self.obs->numpy.repeat(log_norm_counts, T, axis=0).reshape(W, T)
A:gensim.models.ldaseqmodel.self.e_log_prob->self.compute_expected_log_prob()
A:gensim.models.ldaseqmodel.self.mean->numpy.array(np.split(np.zeros((num_time_slices + 1) * vocab_len), vocab_len))
A:gensim.models.ldaseqmodel.self.fwd_mean->numpy.array(np.split(np.zeros((num_time_slices + 1) * vocab_len), vocab_len))
A:gensim.models.ldaseqmodel.self.fwd_variance->numpy.array(np.split(np.zeros((num_time_slices + 1) * vocab_len), vocab_len))
A:gensim.models.ldaseqmodel.self.variance->numpy.array(np.split(np.zeros((num_time_slices + 1) * vocab_len), vocab_len))
A:gensim.models.ldaseqmodel.self.zeta->self.update_zeta()
A:gensim.models.ldaseqmodel.self.zeta[j]->numpy.sum(np.exp(self.mean[:, j + 1] + self.variance[:, j + 1] / 2))
A:gensim.models.ldaseqmodel.c->numpy.power(fwd_variance[t] / (fwd_variance[t] + chain_variance), 2)
A:gensim.models.ldaseqmodel.log_norm_counts->numpy.log(log_norm_counts)
A:gensim.models.ldaseqmodel.(self.variance[w], self.fwd_variance[w])->self.compute_post_variance(w, self.chain_variance)
A:gensim.models.ldaseqmodel.(self.mean[w], self.fwd_mean[w])->self.compute_post_mean(w, self.chain_variance)
A:gensim.models.ldaseqmodel.totals->sstats.sum(axis=0)
A:gensim.models.ldaseqmodel.bound->self.compute_bound_fixed(sstats, totals)
A:gensim.models.ldaseqmodel.(self.obs, self.zeta)->self.update_obs(sstats, totals)
A:gensim.models.ldaseqmodel.converged->numpy.fabs((lhood_old - lhood) / (lhood_old * total))
A:gensim.models.ldaseqmodel.mean_deriv_mtx->numpy.resize(np.zeros(T * (T + 1)), (T, T + 1))
A:gensim.models.ldaseqmodel.counts_norm->numpy.sqrt(counts_norm)
A:gensim.models.ldaseqmodel.norm_cutoff_obs->numpy.copy(obs)
A:gensim.models.ldaseqmodel.w_counts->numpy.zeros(len(w_counts))
A:gensim.models.ldaseqmodel.mean_deriv->self.compute_mean_deriv(w, t, mean_deriv)
A:gensim.models.ldaseqmodel.deriv->sslm.compute_obs_deriv_fixed(p.word, p.word_counts, p.totals, p.sslm, p.mean_deriv_mtx, deriv)
A:gensim.models.ldaseqmodel.obs->scipy.optimize.fmin_cg(f=f_obs, fprime=df_obs, x0=obs, gtol=TOL, args=args, epsilon=STEP_SIZE, disp=0)
A:gensim.models.ldaseqmodel.self.temp_vect->numpy.zeros(T)
A:gensim.models.ldaseqmodel.self.temp_vect[u]->numpy.exp(mean[u + 1] + variance[u + 1] / 2)
A:gensim.models.ldaseqmodel.self.gamma->self.update_gamma()
A:gensim.models.ldaseqmodel.self.lhood->numpy.zeros(num_topics + 1)
A:gensim.models.ldaseqmodel.self.phi->numpy.resize(np.zeros(max_doc_len * num_topics), (max_doc_len, num_topics))
A:gensim.models.ldaseqmodel.self.log_phi->numpy.resize(np.zeros(max_doc_len * num_topics), (max_doc_len, num_topics))
A:gensim.models.ldaseqmodel.dig->numpy.zeros(num_topics)
A:gensim.models.ldaseqmodel.dig[k]->digamma(self.gamma[k])
A:gensim.models.ldaseqmodel.v->numpy.logaddexp(v, log_phi_row[i])
A:gensim.models.ldaseqmodel.phi_row->numpy.exp(log_phi_row)
A:gensim.models.ldaseqmodel.total->sum((count for (word_id, count) in self.doc))
A:gensim.models.ldaseqmodel.gamma_sum->numpy.sum(self.gamma)
A:gensim.models.ldaseqmodel.digsum->digamma(gamma_sum)
A:gensim.models.ldaseqmodel.(self.phi, self.log_phi)->self.update_phi_fixed(doc_number, time, sslm, g3_matrix, g4_matrix, g5_matrix)
A:gensim.models.ldaseqmodel.T->len(x)
A:gensim.models.ldaseqmodel.(sslm.mean[word], sslm.fwd_mean[word])->sslm.compute_post_mean(word, sslm.chain_variance)
gensim.models.LdaSeqModel(self,corpus=None,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.models.LdaSeqModel.__getitem__(self,doc)
gensim.models.LdaSeqModel.doc_topics(self,doc_number)
gensim.models.LdaSeqModel.dtm_coherence(self,time)
gensim.models.LdaSeqModel.dtm_vis(self,time,corpus)
gensim.models.LdaSeqModel.fit_lda_seq(self,corpus,lda_inference_max_iter,em_min_iter,em_max_iter,chunksize)
gensim.models.LdaSeqModel.fit_lda_seq_topics(self,topic_suffstats)
gensim.models.LdaSeqModel.inferDTMseq(self,corpus,topic_suffstats,gammas,lhoods,lda,ldapost,iter_,bound,lda_inference_max_iter,chunksize)
gensim.models.LdaSeqModel.init_ldaseq_ss(self,topic_chain_variance,topic_obs_variance,alpha,init_suffstats)
gensim.models.LdaSeqModel.lda_seq_infer(self,corpus,topic_suffstats,gammas,lhoods,iter_,lda_inference_max_iter,chunksize)
gensim.models.LdaSeqModel.make_lda_seq_slice(self,lda,time)
gensim.models.LdaSeqModel.print_topic(self,topic,time=0,top_terms=20)
gensim.models.LdaSeqModel.print_topic_times(self,topic,top_terms=20)
gensim.models.LdaSeqModel.print_topics(self,time=0,top_terms=20)
gensim.models.ldaseqmodel.LdaPost(self,doc=None,lda=None,max_doc_len=None,num_topics=None,gamma=None,lhood=None)
gensim.models.ldaseqmodel.LdaPost.__init__(self,doc=None,lda=None,max_doc_len=None,num_topics=None,gamma=None,lhood=None)
gensim.models.ldaseqmodel.LdaPost.compute_lda_lhood(self)
gensim.models.ldaseqmodel.LdaPost.fit_lda_post(self,doc_number,time,ldaseq,LDA_INFERENCE_CONVERGED=1e-08,lda_inference_max_iter=25,g=None,g3_matrix=None,g4_matrix=None,g5_matrix=None)
gensim.models.ldaseqmodel.LdaPost.init_lda_post(self)
gensim.models.ldaseqmodel.LdaPost.update_gamma(self)
gensim.models.ldaseqmodel.LdaPost.update_lda_seq_ss(self,time,doc,topic_suffstats)
gensim.models.ldaseqmodel.LdaPost.update_phi(self,doc_number,time)
gensim.models.ldaseqmodel.LdaSeqModel(self,corpus=None,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.models.ldaseqmodel.LdaSeqModel.__getitem__(self,doc)
gensim.models.ldaseqmodel.LdaSeqModel.__init__(self,corpus=None,time_slice=None,id2word=None,alphas=0.01,num_topics=10,initialize='gensim',sstats=None,lda_model=None,obs_variance=0.5,chain_variance=0.005,passes=10,random_state=None,lda_inference_max_iter=25,em_min_iter=6,em_max_iter=20,chunksize=100)
gensim.models.ldaseqmodel.LdaSeqModel.doc_topics(self,doc_number)
gensim.models.ldaseqmodel.LdaSeqModel.dtm_coherence(self,time)
gensim.models.ldaseqmodel.LdaSeqModel.dtm_vis(self,time,corpus)
gensim.models.ldaseqmodel.LdaSeqModel.fit_lda_seq(self,corpus,lda_inference_max_iter,em_min_iter,em_max_iter,chunksize)
gensim.models.ldaseqmodel.LdaSeqModel.fit_lda_seq_topics(self,topic_suffstats)
gensim.models.ldaseqmodel.LdaSeqModel.inferDTMseq(self,corpus,topic_suffstats,gammas,lhoods,lda,ldapost,iter_,bound,lda_inference_max_iter,chunksize)
gensim.models.ldaseqmodel.LdaSeqModel.init_ldaseq_ss(self,topic_chain_variance,topic_obs_variance,alpha,init_suffstats)
gensim.models.ldaseqmodel.LdaSeqModel.lda_seq_infer(self,corpus,topic_suffstats,gammas,lhoods,iter_,lda_inference_max_iter,chunksize)
gensim.models.ldaseqmodel.LdaSeqModel.make_lda_seq_slice(self,lda,time)
gensim.models.ldaseqmodel.LdaSeqModel.print_topic(self,topic,time=0,top_terms=20)
gensim.models.ldaseqmodel.LdaSeqModel.print_topic_times(self,topic,top_terms=20)
gensim.models.ldaseqmodel.LdaSeqModel.print_topics(self,time=0,top_terms=20)
gensim.models.ldaseqmodel.df_obs(x,*args)
gensim.models.ldaseqmodel.f_obs(x,*args)
gensim.models.ldaseqmodel.sslm(self,vocab_len=None,num_time_slices=None,num_topics=None,obs_variance=0.5,chain_variance=0.005)
gensim.models.ldaseqmodel.sslm.__init__(self,vocab_len=None,num_time_slices=None,num_topics=None,obs_variance=0.5,chain_variance=0.005)
gensim.models.ldaseqmodel.sslm.compute_bound(self,sstats,totals)
gensim.models.ldaseqmodel.sslm.compute_expected_log_prob(self)
gensim.models.ldaseqmodel.sslm.compute_mean_deriv(self,word,time,deriv)
gensim.models.ldaseqmodel.sslm.compute_obs_deriv(self,word,word_counts,totals,mean_deriv_mtx,deriv)
gensim.models.ldaseqmodel.sslm.compute_post_mean(self,word,chain_variance)
gensim.models.ldaseqmodel.sslm.compute_post_variance(self,word,chain_variance)
gensim.models.ldaseqmodel.sslm.fit_sslm(self,sstats)
gensim.models.ldaseqmodel.sslm.sslm_counts_init(self,obs_variance,chain_variance,sstats)
gensim.models.ldaseqmodel.sslm.update_obs(self,sstats,totals)
gensim.models.ldaseqmodel.sslm.update_zeta(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/normmodel.py----------------------------------------
A:gensim.models.normmodel.logger->logging.getLogger(__name__)
A:gensim.models.normmodel.vector->gensim.matutils.unitvec(bow, self.norm)
gensim.models.NormModel(self,corpus=None,norm='l2')
gensim.models.NormModel.__getitem__(self,bow)
gensim.models.NormModel.__str__(self)
gensim.models.NormModel.calc_norm(self,corpus)
gensim.models.NormModel.normalize(self,bow)
gensim.models.normmodel.NormModel(self,corpus=None,norm='l2')
gensim.models.normmodel.NormModel.__getitem__(self,bow)
gensim.models.normmodel.NormModel.__init__(self,corpus=None,norm='l2')
gensim.models.normmodel.NormModel.__str__(self)
gensim.models.normmodel.NormModel.calc_norm(self,corpus)
gensim.models.normmodel.NormModel.normalize(self,bow)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/lda_worker.py----------------------------------------
A:gensim.models.lda_worker.logger->logging.getLogger('gensim.models.lda_worker')
A:gensim.models.lda_worker.self.lock_update->threading.Lock()
A:gensim.models.lda_worker.self.model->gensim.models.ldamodel.LdaModel(**model_params)
A:gensim.models.lda_worker.job->self.dispatcher.getjob(self.myid)
A:gensim.models.lda_worker.fname->os.path.join(tempfile.gettempdir(), 'lda_worker.pkl')
A:gensim.models.lda_worker.parser->argparse.ArgumentParser(description=__doc__)
A:gensim.models.lda_worker.args->argparse.ArgumentParser(description=__doc__).parse_args()
gensim.models.lda_worker.Worker(self)
gensim.models.lda_worker.Worker.__init__(self)
gensim.models.lda_worker.Worker.exit(self)
gensim.models.lda_worker.Worker.getstate(self)
gensim.models.lda_worker.Worker.initialize(self,myid,dispatcher,**model_params)
gensim.models.lda_worker.Worker.ping(self)
gensim.models.lda_worker.Worker.processjob(self,job)
gensim.models.lda_worker.Worker.requestjob(self)
gensim.models.lda_worker.Worker.reset(self,state)
gensim.models.lda_worker.main()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/poincare.py----------------------------------------
A:gensim.models.poincare.logger->logging.getLogger(__name__)
A:gensim.models.poincare.self.kv->PoincareKeyedVectors(size)
A:gensim.models.poincare.self._np_random->numpy.random.RandomState(seed)
A:gensim.models.poincare.node_relations->defaultdict(set)
A:gensim.models.poincare.vocab[item]->Vocab(count=1, index=len(index2word))
A:gensim.models.poincare.self.indices_set->set(range(len(index2word)))
A:gensim.models.poincare.self.indices_array->numpy.array(range(len(index2word)))
A:gensim.models.poincare.counts->Counter(node_indices)
A:gensim.models.poincare.self._node_probabilities_cumsum->numpy.cumsum(self._node_probabilities)
A:gensim.models.poincare.self._negatives_buffer->NegativesBuffer(cumsum_table_indices)
A:gensim.models.poincare.self.kv.syn0->self._np_random.uniform(self.init_range[0], self.init_range[1], shape).astype(self.dtype)
A:gensim.models.poincare.uniform_numbers->self._np_random.random_sample(self._negatives_buffer_size)
A:gensim.models.poincare.cumsum_table_indices->numpy.searchsorted(self._node_probabilities_cumsum, uniform_numbers)
A:gensim.models.poincare.indices->list(range(len(self.all_relations)))
A:gensim.models.poincare.unique_indices->set(indices)
A:gensim.models.poincare.valid_negatives->numpy.array(list(self.indices_set - node_relations))
A:gensim.models.poincare.euclidean_dists->numpy.linalg.norm(vector_1 - vectors_all, axis=1)
A:gensim.models.poincare.norm->numpy.linalg.norm(vector_1)
A:gensim.models.poincare.all_norms->numpy.linalg.norm(self.syn0, axis=1)
A:gensim.models.poincare.poincare_dists->numpy.arccosh(gamma)
A:gensim.models.poincare.exp_negative_distances->numpy.exp(-poincare_dists)
A:gensim.models.poincare.norms->numpy.linalg.norm(vectors, axis=1)
A:gensim.models.poincare.model->super(PoincareModel, cls).load(*args, **kwargs)
A:gensim.models.poincare.batch_size->len(indices_u)
A:gensim.models.poincare.vectors_v->vectors_v.swapaxes(0, 1).swapaxes(1, 2).swapaxes(0, 1).swapaxes(1, 2)
A:gensim.models.poincare.batch->self._prepare_training_batch(relations, all_negatives, check_gradients)
A:gensim.models.poincare.self._loss_grad->grad(PoincareModel._loss_fn)
A:gensim.models.poincare.auto_gradients->self._loss_grad(np.vstack((self.kv.syn0[u], self.kv.syn0[[v] + negatives])), self.regularization_coeff)
A:gensim.models.poincare.computed_gradients->numpy.vstack((batch.gradients_u[:, i], batch.gradients_v[:, :, i]))
A:gensim.models.poincare.diff->numpy.abs(auto_gradients - computed_gradients).max()
A:gensim.models.poincare.all_negatives->self._sample_negatives_batch([relation[0] for relation in relations])
A:gensim.models.poincare.vector_updates[positions[-1]]->vector_updates[positions].sum(axis=0)
A:gensim.models.poincare.self.kv.syn0[indices_u]->self._clip_vectors(self.kv.syn0[indices_u], self.epsilon)
A:gensim.models.poincare.v_updates->v_updates.reshape(((1 + self.negative) * batch_size, self.size)).reshape(((1 + self.negative) * batch_size, self.size))
A:gensim.models.poincare.self.kv.syn0[indices_v]->self._clip_vectors(self.kv.syn0[indices_v], self.epsilon)
A:gensim.models.poincare.old_settings->numpy.seterr(divide='ignore', invalid='ignore')
A:gensim.models.poincare.last_time->time.time()
A:gensim.models.poincare.result->self._train_on_batch(relations, check_gradients=check_gradients)
A:gensim.models.poincare.norms_u->numpy.linalg.norm(self.vectors_u, axis=1)
A:gensim.models.poincare.norms_v->numpy.linalg.norm(self.vectors_v, axis=1)
A:gensim.models.poincare.Z->numpy.exp(-poincare_dists).sum(axis=0)
A:gensim.models.poincare.gradients_u->gradients_u.sum(axis=0).sum(axis=0)
A:gensim.models.poincare.all_distances->self.distances(node_or_vector, nodes_to_use)
A:gensim.models.poincare.closest_child_index->numpy.ma.argmin(all_distances)
A:gensim.models.poincare.ancestor->self.closest_parent(ancestors[-1])
A:gensim.models.poincare.vector_1->self.word_vec(w1)
A:gensim.models.poincare.vector_2->self.word_vec(w2)
A:gensim.models.poincare.closest_indices->gensim.matutils.argsort(all_distances, topn=1 + topn)
A:gensim.models.poincare.input_vector->self.word_vec(node_or_vector)
A:gensim.models.poincare.reader->csv.DictReader(f, delimiter=' ')
A:gensim.models.poincare.items->set()
A:gensim.models.poincare.relations->defaultdict(set)
A:gensim.models.poincare.negative_relation_distances->numpy.ma.array(all_distances, mask=False)
A:gensim.models.poincare.avg_precision->(np.arange(1, len(map_ranks) + 1) / np.sort(map_ranks)).mean()
A:gensim.models.poincare.(mean_rank, map_)->self.evaluate_mean_rank_and_map(max_n)
A:gensim.models.poincare.item_relations->list(self.relations[item])
A:gensim.models.poincare.item_distances->self.embedding.distances(item_term)
A:gensim.models.poincare.(positive_relation_ranks, avg_precision)->self.get_positive_relation_ranks_and_avg_prec(item_distances, item_relations)
A:gensim.models.poincare.unknown_relations->list(self.relations['unknown'][item])
A:gensim.models.poincare.known_relations->list(self.relations['known'][item])
A:gensim.models.poincare.(unknown_relation_ranks, avg_precision)->self.get_unknown_relation_ranks_and_avg_prec(item_distances, unknown_relations, known_relations)
A:gensim.models.poincare.expected_scores[word_1, word_2]->float(row['AVG_SCORE'])
A:gensim.models.poincare.word_1_terms->self.find_matching_terms(trie, term_1)
A:gensim.models.poincare.word_2_terms->self.find_matching_terms(trie, term_2)
A:gensim.models.poincare.distance->embedding.distance(term_1, term_2)
A:gensim.models.poincare.matches->trie.items('%s.' % word)
A:gensim.models.poincare.vocab_trie->self.create_vocab_trie(embedding)
A:gensim.models.poincare.predicted_score->self.score_function(embedding, vocab_trie, word_1, word_2)
A:gensim.models.poincare.spearman->spearmanr(expected_scores, predicted_scores)
gensim.models.poincare.LexicalEntailmentEvaluation(self,filepath)
gensim.models.poincare.LexicalEntailmentEvaluation.__init__(self,filepath)
gensim.models.poincare.LexicalEntailmentEvaluation.create_vocab_trie(embedding)
gensim.models.poincare.LexicalEntailmentEvaluation.evaluate_spearman(self,embedding)
gensim.models.poincare.LexicalEntailmentEvaluation.find_matching_terms(trie,word)
gensim.models.poincare.LexicalEntailmentEvaluation.score_function(self,embedding,trie,term_1,term_2)
gensim.models.poincare.LinkPredictionEvaluation(self,train_path,test_path,embedding)
gensim.models.poincare.LinkPredictionEvaluation.__init__(self,train_path,test_path,embedding)
gensim.models.poincare.LinkPredictionEvaluation.evaluate(self,max_n=None)
gensim.models.poincare.LinkPredictionEvaluation.evaluate_mean_rank_and_map(self,max_n=None)
gensim.models.poincare.LinkPredictionEvaluation.get_unknown_relation_ranks_and_avg_prec(all_distances,unknown_relations,known_relations)
gensim.models.poincare.NegativesBuffer(self,items)
gensim.models.poincare.NegativesBuffer.__init__(self,items)
gensim.models.poincare.NegativesBuffer.get_items(self,num_items)
gensim.models.poincare.NegativesBuffer.num_items(self)
gensim.models.poincare.PoincareBatch(self,vectors_u,vectors_v,indices_u,indices_v,regularization_coeff=1.0)
gensim.models.poincare.PoincareBatch.__init__(self,vectors_u,vectors_v,indices_u,indices_v,regularization_coeff=1.0)
gensim.models.poincare.PoincareBatch.compute_all(self)
gensim.models.poincare.PoincareBatch.compute_distance_gradients(self)
gensim.models.poincare.PoincareBatch.compute_distances(self)
gensim.models.poincare.PoincareBatch.compute_gradients(self)
gensim.models.poincare.PoincareBatch.compute_loss(self)
gensim.models.poincare.PoincareKeyedVectors(self,vector_size)
gensim.models.poincare.PoincareKeyedVectors.__init__(self,vector_size)
gensim.models.poincare.PoincareKeyedVectors.ancestors(self,node)
gensim.models.poincare.PoincareKeyedVectors.closest_child(self,node)
gensim.models.poincare.PoincareKeyedVectors.closest_parent(self,node)
gensim.models.poincare.PoincareKeyedVectors.descendants(self,node,max_depth=5)
gensim.models.poincare.PoincareKeyedVectors.difference_in_hierarchy(self,node_or_vector_1,node_or_vector_2)
gensim.models.poincare.PoincareKeyedVectors.distance(self,w1,w2)
gensim.models.poincare.PoincareKeyedVectors.distances(self,node_or_vector,other_nodes=())
gensim.models.poincare.PoincareKeyedVectors.index2entity(self)
gensim.models.poincare.PoincareKeyedVectors.index2entity(self,value)
gensim.models.poincare.PoincareKeyedVectors.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.poincare.PoincareKeyedVectors.most_similar(self,node_or_vector,topn=10,restrict_vocab=None)
gensim.models.poincare.PoincareKeyedVectors.norm(self,node_or_vector)
gensim.models.poincare.PoincareKeyedVectors.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None)
gensim.models.poincare.PoincareKeyedVectors.similarity(self,w1,w2)
gensim.models.poincare.PoincareKeyedVectors.vector_distance(vector_1,vector_2)
gensim.models.poincare.PoincareKeyedVectors.vector_distance_batch(vector_1,vectors_all)
gensim.models.poincare.PoincareKeyedVectors.vectors(self)
gensim.models.poincare.PoincareKeyedVectors.vectors(self,value)
gensim.models.poincare.PoincareKeyedVectors.word_vec(self,word)
gensim.models.poincare.PoincareKeyedVectors.words_closer_than(self,w1,w2)
gensim.models.poincare.PoincareModel(self,train_data,size=50,alpha=0.1,negative=10,workers=1,epsilon=1e-05,regularization_coeff=1.0,burn_in=10,burn_in_alpha=0.01,init_range=(-0.001,0.001),dtype=np.float64,seed=0)
gensim.models.poincare.PoincareModel.__init__(self,train_data,size=50,alpha=0.1,negative=10,workers=1,epsilon=1e-05,regularization_coeff=1.0,burn_in=10,burn_in_alpha=0.01,init_range=(-0.001,0.001),dtype=np.float64,seed=0)
gensim.models.poincare.PoincareModel._check_gradients(self,relations,all_negatives,batch,tol=1e-08)
gensim.models.poincare.PoincareModel._clip_vectors(vectors,epsilon)
gensim.models.poincare.PoincareModel._get_candidate_negatives(self)
gensim.models.poincare.PoincareModel._handle_duplicates(vector_updates,node_indices)
gensim.models.poincare.PoincareModel._init_embeddings(self)
gensim.models.poincare.PoincareModel._load_relations(self)
gensim.models.poincare.PoincareModel._loss_fn(matrix,regularization_coeff=1.0)
gensim.models.poincare.PoincareModel._prepare_training_batch(self,relations,all_negatives,check_gradients=False)
gensim.models.poincare.PoincareModel._sample_negatives(self,node_index)
gensim.models.poincare.PoincareModel._sample_negatives_batch(self,nodes)
gensim.models.poincare.PoincareModel._train_batchwise(self,epochs,batch_size=10,print_every=1000,check_gradients_every=None)
gensim.models.poincare.PoincareModel._train_on_batch(self,relations,check_gradients=False)
gensim.models.poincare.PoincareModel._update_vectors_batch(self,batch)
gensim.models.poincare.PoincareModel.load(cls,*args,**kwargs)
gensim.models.poincare.PoincareModel.save(self,*args,**kwargs)
gensim.models.poincare.PoincareModel.train(self,epochs,batch_size=10,print_every=1000,check_gradients_every=None)
gensim.models.poincare.PoincareRelations(self,file_path,encoding='utf8',delimiter='\t')
gensim.models.poincare.PoincareRelations.__init__(self,file_path,encoding='utf8',delimiter='\t')
gensim.models.poincare.PoincareRelations.__iter__(self)
gensim.models.poincare.ReconstructionEvaluation(self,file_path,embedding)
gensim.models.poincare.ReconstructionEvaluation.__init__(self,file_path,embedding)
gensim.models.poincare.ReconstructionEvaluation.evaluate(self,max_n=None)
gensim.models.poincare.ReconstructionEvaluation.evaluate_mean_rank_and_map(self,max_n=None)
gensim.models.poincare.ReconstructionEvaluation.get_positive_relation_ranks_and_avg_prec(all_distances,positive_relations)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/basemodel.py----------------------------------------
gensim.models.basemodel.BaseTopicModel(object)
gensim.models.basemodel.BaseTopicModel.get_topics(self)
gensim.models.basemodel.BaseTopicModel.print_topic(self,topicno,topn=10)
gensim.models.basemodel.BaseTopicModel.print_topics(self,num_topics=20,num_words=10)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/lsi_dispatcher.py----------------------------------------
A:gensim.models.lsi_dispatcher.logger->logging.getLogger(__name__)
A:gensim.models.lsi_dispatcher.self.jobs->Queue(maxsize=self.maxsize)
A:gensim.models.lsi_dispatcher.self.lock_update->threading.Lock()
A:gensim.models.lsi_dispatcher.self.callback->Pyro4.Proxy('PYRONAME:gensim.lsi_dispatcher')
A:gensim.models.lsi_dispatcher.worker->Pyro4.Proxy(uri)
A:gensim.models.lsi_dispatcher.workerid->len(self.workers)
A:gensim.models.lsi_dispatcher.job->self.jobs.get(block=True, timeout=1)
A:gensim.models.lsi_dispatcher.workers->list(self.workers.items())
A:gensim.models.lsi_dispatcher.result->workers[0][1].getstate()
A:gensim.models.lsi_dispatcher.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter)
A:gensim.models.lsi_dispatcher.args->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter).parse_args()
gensim.models.lsi_dispatcher.Dispatcher(self,maxsize=0)
gensim.models.lsi_dispatcher.Dispatcher.__init__(self,maxsize=0)
gensim.models.lsi_dispatcher.Dispatcher.exit(self)
gensim.models.lsi_dispatcher.Dispatcher.getjob(self,worker_id)
gensim.models.lsi_dispatcher.Dispatcher.getstate(self)
gensim.models.lsi_dispatcher.Dispatcher.getworkers(self)
gensim.models.lsi_dispatcher.Dispatcher.initialize(self,**model_params)
gensim.models.lsi_dispatcher.Dispatcher.jobdone(self,workerid)
gensim.models.lsi_dispatcher.Dispatcher.jobsdone(self)
gensim.models.lsi_dispatcher.Dispatcher.putjob(self,job)
gensim.models.lsi_dispatcher.Dispatcher.reset(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/rpmodel.py----------------------------------------
A:gensim.models.rpmodel.logger->logging.getLogger('gensim.models.rpmodel')
A:gensim.models.rpmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.rpmodel.self.num_terms->len(self.id2word)
A:gensim.models.rpmodel.self.projection->self.projection.copy('F')
A:gensim.models.rpmodel.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.rpmodel.vec->numpy.asfortranarray(vec, dtype=np.float32)
A:gensim.models.rpmodel.topic_dist->numpy.dot(self.projection, vec)
gensim.models.RpModel(self,corpus,id2word=None,num_topics=300)
gensim.models.RpModel.__getitem__(self,bow)
gensim.models.RpModel.__setstate__(self,state)
gensim.models.RpModel.__str__(self)
gensim.models.RpModel.initialize(self,corpus)
gensim.models.rpmodel.RpModel(self,corpus,id2word=None,num_topics=300)
gensim.models.rpmodel.RpModel.__getitem__(self,bow)
gensim.models.rpmodel.RpModel.__init__(self,corpus,id2word=None,num_topics=300)
gensim.models.rpmodel.RpModel.__setstate__(self,state)
gensim.models.rpmodel.RpModel.__str__(self)
gensim.models.rpmodel.RpModel.initialize(self,corpus)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/lsi_worker.py----------------------------------------
A:gensim.models.lsi_worker.logger->logging.getLogger(__name__)
A:gensim.models.lsi_worker.self.lock_update->threading.Lock()
A:gensim.models.lsi_worker.self.model->gensim.models.lsimodel.LsiModel(**model_params)
A:gensim.models.lsi_worker.job->self.dispatcher.getjob(self.myid)
A:gensim.models.lsi_worker.fname->os.path.join(tempfile.gettempdir(), 'lsi_worker.pkl')
A:gensim.models.lsi_worker.self.model.projection->self.model.projection.empty_like()
A:gensim.models.lsi_worker.parser->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter)
A:gensim.models.lsi_worker._->argparse.ArgumentParser(description=__doc__[:-135], formatter_class=argparse.RawTextHelpFormatter).parse_args()
gensim.models.lsi_worker.Worker(self)
gensim.models.lsi_worker.Worker.__init__(self)
gensim.models.lsi_worker.Worker.exit(self)
gensim.models.lsi_worker.Worker.getstate(self)
gensim.models.lsi_worker.Worker.initialize(self,myid,dispatcher,**model_params)
gensim.models.lsi_worker.Worker.processjob(self,job)
gensim.models.lsi_worker.Worker.requestjob(self)
gensim.models.lsi_worker.Worker.reset(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/doc2vec.py----------------------------------------
A:gensim.models.doc2vec.logger->logging.getLogger(__name__)
A:gensim.models.doc2vec.reduced_window->model.random.randint(model.window)
A:gensim.models.doc2vec.start->max(0, pos - model.window + reduced_window)
A:gensim.models.doc2vec.window_pos->enumerate(word_vocabs[start:pos + model.window + 1 - reduced_window], start)
A:gensim.models.doc2vec.neu1e->train_cbow_pair(model, predict_word, None, l1, alpha, learn_hidden=learn_hidden, learn_vectors=False)
A:gensim.models.doc2vec.doctag_len->len(doctag_indexes)
A:gensim.models.doc2vec.l1->concatenate((doctag_vectors[doctag_indexes], word_vectors[word_context_indexes])).ravel()
A:gensim.models.doc2vec.e_locks->concatenate((doctag_locks[doctag_indexes], word_locks[word_context_indexes]))
A:gensim.models.doc2vec.self.dbow_words->int(dbow_words)
A:gensim.models.doc2vec.self.dm_concat->int(dm_concat)
A:gensim.models.doc2vec.self.dm_tag_count->int(dm_tag_count)
A:gensim.models.doc2vec.vocabulary_kwargs->dict(((k, kwargs[k]) for k in vocabulary_keys if k in kwargs))
A:gensim.models.doc2vec.self.vocabulary->Doc2VecVocab(**vocabulary_kwargs)
A:gensim.models.doc2vec.trainables_kwargs->dict(((k, kwargs[k]) for k in trainables_keys if k in kwargs))
A:gensim.models.doc2vec.self.trainables->Doc2VecTrainables(dm=dm, dm_concat=dm_concat, dm_tag_count=dm_tag_count, vector_size=self.vector_size, **trainables_kwargs)
A:gensim.models.doc2vec.self.wv->Word2VecKeyedVectors(self.vector_size)
A:gensim.models.doc2vec.doctag_indexes->self.vocabulary.indexed_doctags(doc.tags, self.docvecs)
A:gensim.models.doc2vec.(doctag_vectors, doctag_locks)->self.trainables.get_doctag_trainables(doc_words, self.docvecs.vector_size)
A:gensim.models.doc2vec.work->zeros(self.trainables.layer1_size, dtype=REAL)
A:gensim.models.doc2vec.neu1->gensim.matutils.zeros_aligned(self.trainables.layer1_size, dtype=REAL)
A:gensim.models.doc2vec.total_vec->len(self.docvecs)
A:gensim.models.doc2vec.report['doctag_lookup']->self.estimated_lookup_memory()
A:gensim.models.doc2vec.(total_words, corpus_count)->self.vocabulary.scan_vocab(documents, self.docvecs, progress_per=progress_per, trim_rule=trim_rule)
A:gensim.models.doc2vec.report_values->self.vocabulary.prepare_vocab(self.hs, self.negative, self.wv, keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, update=update)
A:gensim.models.doc2vec.report_values['memory']->self.estimate_memory(vocab_size=report_values['num_retained_words'])
A:gensim.models.doc2vec.vocab->defaultdict(int)
A:gensim.models.doc2vec.interval_start->default_timer()
A:gensim.models.doc2vec.document_length->len(document.words)
A:gensim.models.doc2vec.docvecs.max_rawint->max(docvecs.max_rawint, key)
A:gensim.models.doc2vec.docvecs.doctags[key]->Doctag(len(docvecs.offset2doctag), document_length, 1)
A:gensim.models.doc2vec.length->max(len(docvecs.doctags), docvecs.count)
A:gensim.models.doc2vec.docvecs.vectors_docs->empty((length, docvecs.vector_size), dtype=REAL)
A:gensim.models.doc2vec.self.vectors_docs_lockf->ones((length,), dtype=REAL)
A:gensim.models.doc2vec.docvecs.vectors_docs[i]->self.seeded_vector(seed, docvecs.vector_size)
A:gensim.models.doc2vec.doctag_vectors->zeros((1, vector_size), dtype=REAL)
A:gensim.models.doc2vec.doctag_vectors[0]->self.seeded_vector(' '.join(doc_words), vector_size)
A:gensim.models.doc2vec.doctag_locks->ones(1, dtype=REAL)
A:gensim.models.doc2vec.fname->os.path.join(self.dirname, fname)
A:gensim.models.doc2vec.line->gensim.utils.to_unicode(line)
gensim.models.Doc2Vec(self,documents=None,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,callbacks=(),**kwargs)
gensim.models.Doc2Vec.__getitem__(self,tag)
gensim.models.Doc2Vec.__str__(self)
gensim.models.Doc2Vec._clear_post_train(self)
gensim.models.Doc2Vec._do_train_job(self,job,alpha,inits)
gensim.models.Doc2Vec._raw_word_count(self,job)
gensim.models.Doc2Vec._set_train_params(self,**kwargs)
gensim.models.Doc2Vec.build_vocab(self,documents,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.Doc2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.Doc2Vec.clear_sims(self)
gensim.models.Doc2Vec.dbow(self)
gensim.models.Doc2Vec.delete_temporary_training_data(self,keep_doctags_vectors=True,keep_inference=True)
gensim.models.Doc2Vec.dm(self)
gensim.models.Doc2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.Doc2Vec.estimated_lookup_memory(self)
gensim.models.Doc2Vec.infer_vector(self,doc_words,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.models.Doc2Vec.init_sims(self,replace=False)
gensim.models.Doc2Vec.load(cls,*args,**kwargs)
gensim.models.Doc2Vec.reset_from(self,other_model)
gensim.models.Doc2Vec.save_word2vec_format(self,fname,doctag_vec=False,word_vec=True,prefix='*dt_',fvocab=None,binary=False)
gensim.models.Doc2Vec.train(self,documents,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,callbacks=())
gensim.models.Doc2VecTrainables(self,dm=1,dm_concat=0,dm_tag_count=1,vector_size=100,seed=1,hashfxn=hash,window=5)
gensim.models.Doc2VecTrainables.get_doctag_trainables(self,doc_words,vector_size)
gensim.models.Doc2VecTrainables.prepare_weights(self,hs,negative,wv,docvecs,update=False)
gensim.models.Doc2VecTrainables.reset_doc_weights(self,docvecs)
gensim.models.Doc2VecTrainables.reset_weights(self,hs,negative,wv,docvecs,vocabulary=None)
gensim.models.Doc2VecVocab(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.Doc2VecVocab._tag_seen(self,index,docvecs)
gensim.models.Doc2VecVocab.indexed_doctags(self,doctag_tokens,docvecs)
gensim.models.Doc2VecVocab.note_doctag(self,key,document_no,document_length,docvecs)
gensim.models.Doc2VecVocab.scan_vocab(self,documents,docvecs,progress_per=10000,trim_rule=None)
gensim.models.doc2vec.Doc2Vec(self,documents=None,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,callbacks=(),**kwargs)
gensim.models.doc2vec.Doc2Vec.__getitem__(self,tag)
gensim.models.doc2vec.Doc2Vec.__init__(self,documents=None,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,callbacks=(),**kwargs)
gensim.models.doc2vec.Doc2Vec.__str__(self)
gensim.models.doc2vec.Doc2Vec._clear_post_train(self)
gensim.models.doc2vec.Doc2Vec._do_train_job(self,job,alpha,inits)
gensim.models.doc2vec.Doc2Vec._raw_word_count(self,job)
gensim.models.doc2vec.Doc2Vec._set_train_params(self,**kwargs)
gensim.models.doc2vec.Doc2Vec.build_vocab(self,documents,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.doc2vec.Doc2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.doc2vec.Doc2Vec.clear_sims(self)
gensim.models.doc2vec.Doc2Vec.dbow(self)
gensim.models.doc2vec.Doc2Vec.delete_temporary_training_data(self,keep_doctags_vectors=True,keep_inference=True)
gensim.models.doc2vec.Doc2Vec.dm(self)
gensim.models.doc2vec.Doc2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.doc2vec.Doc2Vec.estimated_lookup_memory(self)
gensim.models.doc2vec.Doc2Vec.infer_vector(self,doc_words,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.models.doc2vec.Doc2Vec.init_sims(self,replace=False)
gensim.models.doc2vec.Doc2Vec.load(cls,*args,**kwargs)
gensim.models.doc2vec.Doc2Vec.reset_from(self,other_model)
gensim.models.doc2vec.Doc2Vec.save_word2vec_format(self,fname,doctag_vec=False,word_vec=True,prefix='*dt_',fvocab=None,binary=False)
gensim.models.doc2vec.Doc2Vec.train(self,documents,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,callbacks=())
gensim.models.doc2vec.Doc2VecTrainables(self,dm=1,dm_concat=0,dm_tag_count=1,vector_size=100,seed=1,hashfxn=hash,window=5)
gensim.models.doc2vec.Doc2VecTrainables.__init__(self,dm=1,dm_concat=0,dm_tag_count=1,vector_size=100,seed=1,hashfxn=hash,window=5)
gensim.models.doc2vec.Doc2VecTrainables.get_doctag_trainables(self,doc_words,vector_size)
gensim.models.doc2vec.Doc2VecTrainables.prepare_weights(self,hs,negative,wv,docvecs,update=False)
gensim.models.doc2vec.Doc2VecTrainables.reset_doc_weights(self,docvecs)
gensim.models.doc2vec.Doc2VecTrainables.reset_weights(self,hs,negative,wv,docvecs,vocabulary=None)
gensim.models.doc2vec.Doc2VecVocab(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.doc2vec.Doc2VecVocab.__init__(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.doc2vec.Doc2VecVocab._tag_seen(self,index,docvecs)
gensim.models.doc2vec.Doc2VecVocab.indexed_doctags(self,doctag_tokens,docvecs)
gensim.models.doc2vec.Doc2VecVocab.note_doctag(self,key,document_no,document_length,docvecs)
gensim.models.doc2vec.Doc2VecVocab.scan_vocab(self,documents,docvecs,progress_per=10000,trim_rule=None)
gensim.models.doc2vec.Doctag(namedtuple('Doctag','offset,word_count,doc_count'))
gensim.models.doc2vec.Doctag.repeat(self,word_count)
gensim.models.doc2vec.LabeledSentence(TaggedDocument)
gensim.models.doc2vec.TaggedBrownCorpus(self,dirname)
gensim.models.doc2vec.TaggedBrownCorpus.__init__(self,dirname)
gensim.models.doc2vec.TaggedBrownCorpus.__iter__(self)
gensim.models.doc2vec.TaggedDocument(namedtuple('TaggedDocument','wordstags'))
gensim.models.doc2vec.TaggedDocument.__str__(self)
gensim.models.doc2vec.TaggedLineDocument(self,source)
gensim.models.doc2vec.TaggedLineDocument.__init__(self,source)
gensim.models.doc2vec.TaggedLineDocument.__iter__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/coherencemodel.py----------------------------------------
A:gensim.models.coherencemodel.logger->logging.getLogger(__name__)
A:gensim.models.coherencemodel._make_pipeline->namedtuple('Coherence_Measure', 'seg, prob, conf, aggr')
A:gensim.models.coherencemodel.bestn->gensim.matutils.argsort(topic, topn=topn, reverse=True)
A:gensim.models.coherencemodel.topn->min(kwargs.pop('topn', topn), topn)
A:gensim.models.coherencemodel.super_topic->gensim.utils.flatten(topics_as_topn_terms)
A:gensim.models.coherencemodel.cm->CoherenceModel(topics=[super_topic], topn=len(super_topic), **kwargs)
A:gensim.models.coherencemodel.new_topics->self._get_topics()
A:gensim.models.coherencemodel.current_topic_length->len(self._topics[0])
A:gensim.models.coherencemodel.topic_token_ids->self._ensure_elements_are_ids(topic)
A:gensim.models.coherencemodel.new_set->unique_ids_from_segments(self.measure.seg(new_topics))
A:gensim.models.coherencemodel.segmented_topics->measure.seg(self.topics)
A:gensim.models.coherencemodel.self._accumulator->self.measure.prob(**kwargs)
A:gensim.models.coherencemodel.kwargs->dict(with_std=with_std, with_support=with_support)
A:gensim.models.coherencemodel.confirmed_measures->self.get_coherence_per_topic()
A:gensim.models.coherencemodel.coherences->self._compare_model_topics(model_topics)
A:gensim.models.coherencemodel.last_topn_value->min(self.topn - 1, 4)
A:gensim.models.coherencemodel.topn_grid->list(range(self.topn, last_topn_value, -5))
A:gensim.models.coherencemodel.topic_coherences->self.get_coherence_per_topic()
A:gensim.models.coherencemodel.filled_coherences->numpy.array(topic_coherences)
A:gensim.models.coherencemodel.filled_coherences[np.isnan(filled_coherences)]->numpy.nanmean(filled_coherences)
A:gensim.models.coherencemodel.(topic_coherences, avg_coherences)->zip(*coherence_at_n.values())
A:gensim.models.coherencemodel.avg_topic_coherences->numpy.vstack(topic_coherences).mean(0)
A:gensim.models.coherencemodel.model_coherence->numpy.mean(avg_coherences)
gensim.models.CoherenceModel(self,model=None,topics=None,texts=None,corpus=None,dictionary=None,window_size=None,keyed_vectors=None,coherence='c_v',topn=20,processes=-1)
gensim.models.CoherenceModel.__str__(self)
gensim.models.CoherenceModel._compare_model_topics(self,model_topics)
gensim.models.CoherenceModel._ensure_elements_are_ids(self,topic)
gensim.models.CoherenceModel._get_topics(self)
gensim.models.CoherenceModel._get_topics_from_model(model,topn)
gensim.models.CoherenceModel._relevant_ids_will_differ(self,new_topics)
gensim.models.CoherenceModel._topics_differ(self,new_topics)
gensim.models.CoherenceModel._update_accumulator(self,new_topics)
gensim.models.CoherenceModel.aggregate_measures(self,topic_coherences)
gensim.models.CoherenceModel.compare_model_topics(self,model_topics)
gensim.models.CoherenceModel.compare_models(self,models)
gensim.models.CoherenceModel.estimate_probabilities(self,segmented_topics=None)
gensim.models.CoherenceModel.for_models(cls,models,dictionary,topn=20,**kwargs)
gensim.models.CoherenceModel.for_topics(cls,topics_as_topn_terms,**kwargs)
gensim.models.CoherenceModel.get_coherence(self)
gensim.models.CoherenceModel.get_coherence_per_topic(self,segmented_topics=None,with_std=False,with_support=False)
gensim.models.CoherenceModel.measure(self)
gensim.models.CoherenceModel.model(self)
gensim.models.CoherenceModel.model(self,model)
gensim.models.CoherenceModel.segment_topics(self)
gensim.models.CoherenceModel.top_topics_as_word_lists(model,dictionary,topn=20)
gensim.models.CoherenceModel.topics(self)
gensim.models.CoherenceModel.topics(self,topics)
gensim.models.CoherenceModel.topn(self)
gensim.models.CoherenceModel.topn(self,topn)
gensim.models.coherencemodel.CoherenceModel(self,model=None,topics=None,texts=None,corpus=None,dictionary=None,window_size=None,keyed_vectors=None,coherence='c_v',topn=20,processes=-1)
gensim.models.coherencemodel.CoherenceModel.__init__(self,model=None,topics=None,texts=None,corpus=None,dictionary=None,window_size=None,keyed_vectors=None,coherence='c_v',topn=20,processes=-1)
gensim.models.coherencemodel.CoherenceModel.__str__(self)
gensim.models.coherencemodel.CoherenceModel._compare_model_topics(self,model_topics)
gensim.models.coherencemodel.CoherenceModel._ensure_elements_are_ids(self,topic)
gensim.models.coherencemodel.CoherenceModel._get_topics(self)
gensim.models.coherencemodel.CoherenceModel._get_topics_from_model(model,topn)
gensim.models.coherencemodel.CoherenceModel._relevant_ids_will_differ(self,new_topics)
gensim.models.coherencemodel.CoherenceModel._topics_differ(self,new_topics)
gensim.models.coherencemodel.CoherenceModel._update_accumulator(self,new_topics)
gensim.models.coherencemodel.CoherenceModel.aggregate_measures(self,topic_coherences)
gensim.models.coherencemodel.CoherenceModel.compare_model_topics(self,model_topics)
gensim.models.coherencemodel.CoherenceModel.compare_models(self,models)
gensim.models.coherencemodel.CoherenceModel.estimate_probabilities(self,segmented_topics=None)
gensim.models.coherencemodel.CoherenceModel.for_models(cls,models,dictionary,topn=20,**kwargs)
gensim.models.coherencemodel.CoherenceModel.for_topics(cls,topics_as_topn_terms,**kwargs)
gensim.models.coherencemodel.CoherenceModel.get_coherence(self)
gensim.models.coherencemodel.CoherenceModel.get_coherence_per_topic(self,segmented_topics=None,with_std=False,with_support=False)
gensim.models.coherencemodel.CoherenceModel.measure(self)
gensim.models.coherencemodel.CoherenceModel.model(self)
gensim.models.coherencemodel.CoherenceModel.model(self,model)
gensim.models.coherencemodel.CoherenceModel.segment_topics(self)
gensim.models.coherencemodel.CoherenceModel.top_topics_as_word_lists(model,dictionary,topn=20)
gensim.models.coherencemodel.CoherenceModel.topics(self)
gensim.models.coherencemodel.CoherenceModel.topics(self,topics)
gensim.models.coherencemodel.CoherenceModel.topn(self)
gensim.models.coherencemodel.CoherenceModel.topn(self,topn)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/callbacks.py----------------------------------------
A:gensim.models.callbacks.cm->gensim.models.CoherenceModel(model=self.model, topics=self.topics, texts=self.texts, corpus=self.corpus, dictionary=self.dictionary, window_size=self.window_size, coherence=self.coherence, topn=self.topn)
A:gensim.models.callbacks.corpus_words->sum((cnt for document in self.corpus for (_, cnt) in document))
A:gensim.models.callbacks.(diff_diagonal, _)->self.model.diff(self.other_model, self.distance, self.num_words, self.n_ann_terms, self.diagonal, self.annotation, self.normed)
A:gensim.models.callbacks.self.previous->copy.deepcopy(self.model)
A:gensim.models.callbacks.self.diff_mat->Queue()
A:gensim.models.callbacks.self.viz->Visdom()
A:gensim.models.callbacks.self.log_type->logging.getLogger('gensim.models.ldamodel')
A:gensim.models.callbacks.label->str(metric)
A:gensim.models.callbacks.value->metric.get_value(topics=topics, model=self.model, other_model=self.previous)
A:gensim.models.callbacks.diff_mat->numpy.concatenate((self.diff_mat.get(), np.array([value])))
A:gensim.models.callbacks.viz_metric->self.viz.line(Y=np.array([value]), X=np.array([epoch]), env=metric.viz_env, opts=dict(xlabel='Epochs', ylabel=label, title=label))
A:gensim.models.callbacks.statement->''.join(('Epoch ', str(epoch), ': ', label, ' estimate: ', str(value)))
gensim.models.callbacks.Callback(self,metrics)
gensim.models.callbacks.Callback.__init__(self,metrics)
gensim.models.callbacks.Callback.on_epoch_end(self,epoch,topics=None)
gensim.models.callbacks.Callback.set_model(self,model)
gensim.models.callbacks.CallbackAny2Vec(object)
gensim.models.callbacks.CallbackAny2Vec.on_batch_begin(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_batch_end(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_epoch_begin(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_epoch_end(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_train_begin(self,model)
gensim.models.callbacks.CallbackAny2Vec.on_train_end(self,model)
gensim.models.callbacks.CoherenceMetric(self,corpus=None,texts=None,dictionary=None,coherence=None,window_size=None,topn=10,logger=None,viz_env=None,title=None)
gensim.models.callbacks.CoherenceMetric.__init__(self,corpus=None,texts=None,dictionary=None,coherence=None,window_size=None,topn=10,logger=None,viz_env=None,title=None)
gensim.models.callbacks.CoherenceMetric.get_value(self,**kwargs)
gensim.models.callbacks.ConvergenceMetric(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.ConvergenceMetric.__init__(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.ConvergenceMetric.get_value(self,**kwargs)
gensim.models.callbacks.DiffMetric(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.DiffMetric.__init__(self,distance='jaccard',num_words=100,n_ann_terms=10,diagonal=True,annotation=False,normed=True,logger=None,viz_env=None,title=None)
gensim.models.callbacks.DiffMetric.get_value(self,**kwargs)
gensim.models.callbacks.Metric(object)
gensim.models.callbacks.Metric.__str__(self)
gensim.models.callbacks.Metric.get_value(self)
gensim.models.callbacks.Metric.set_parameters(self,**parameters)
gensim.models.callbacks.PerplexityMetric(self,corpus=None,logger=None,viz_env=None,title=None)
gensim.models.callbacks.PerplexityMetric.__init__(self,corpus=None,logger=None,viz_env=None,title=None)
gensim.models.callbacks.PerplexityMetric.get_value(self,**kwargs)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/__init__.py----------------------------------------
A:gensim.models.__init__.(is_corpus, bow)->gensim.utils.is_corpus(bow)
gensim.models.__init__.VocabTransform(self,old2new,id2token=None)
gensim.models.__init__.VocabTransform.__getitem__(self,bow)
gensim.models.__init__.VocabTransform.__init__(self,old2new,id2token=None)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/logentropy_model.py----------------------------------------
A:gensim.models.logentropy_model.logger->logging.getLogger(__name__)
A:gensim.models.logentropy_model.(is_corpus, bow)->gensim.utils.is_corpus(bow)
A:gensim.models.logentropy_model.vector->gensim.matutils.unitvec(vector)
gensim.models.LogEntropyModel(self,corpus,normalize=True)
gensim.models.LogEntropyModel.__getitem__(self,bow)
gensim.models.LogEntropyModel.__str__(self)
gensim.models.LogEntropyModel.initialize(self,corpus)
gensim.models.logentropy_model.LogEntropyModel(self,corpus,normalize=True)
gensim.models.logentropy_model.LogEntropyModel.__getitem__(self,bow)
gensim.models.logentropy_model.LogEntropyModel.__init__(self,corpus,normalize=True)
gensim.models.logentropy_model.LogEntropyModel.__str__(self)
gensim.models.logentropy_model.LogEntropyModel.initialize(self,corpus)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/word2vec.py----------------------------------------
A:gensim.models.word2vec.logger->logging.getLogger(__name__)
A:gensim.models.word2vec.reduced_window->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter).random.randint(model.window)
A:gensim.models.word2vec.start->max(0, pos - model.window)
A:gensim.models.word2vec.window_pos->enumerate(word_vocabs[start:pos + model.window + 1], start)
A:gensim.models.word2vec.l1->np_sum(self.wv.vectors[word2_indices], axis=0)
A:gensim.models.word2vec.l1_ngrams->np_sum(context_vectors_ngrams[context_index[1:]], axis=0)
A:gensim.models.word2vec.neu1e->zeros(l1.shape)
A:gensim.models.word2vec.l2a->deepcopy(model.syn1[word.point])
A:gensim.models.word2vec.prod_term->dot(l1, l2b.T)
A:gensim.models.word2vec.fa->expit(prod_term)
A:gensim.models.word2vec.w->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter).cum_table.searchsorted(model.random.randint(model.cum_table[-1]))
A:gensim.models.word2vec.fb->expit(prod_term)
A:gensim.models.word2vec.self.wv->Word2VecKeyedVectors(size)
A:gensim.models.word2vec.self.vocabulary->Word2VecVocab(max_vocab_size=max_vocab_size, min_count=min_count, sample=sample, sorted_vocab=bool(sorted_vocab), null_word=null_word)
A:gensim.models.word2vec.self.trainables->Word2VecTrainables(seed=seed, vector_size=size, hashfxn=hashfxn)
A:gensim.models.word2vec.work->zeros(1, dtype=REAL)
A:gensim.models.word2vec.neu1->gensim.matutils.zeros_aligned(self.trainables.layer1_size, dtype=REAL)
A:gensim.models.word2vec.job->Queue(maxsize=queue_factor * self.workers).get()
A:gensim.models.word2vec.score->score_sentence_cbow(self, sentence, work, neu1)
A:gensim.models.word2vec.job_queue->Queue(maxsize=queue_factor * self.workers)
A:gensim.models.word2vec.progress_queue->Queue(maxsize=(queue_factor + 1) * self.workers)
A:gensim.models.word2vec.sentence_scores->gensim.matutils.zeros_aligned(total_sentences, dtype=REAL)
A:gensim.models.word2vec.jobs_source->enumerate(utils.grouper(enumerate(sentences), chunksize))
A:gensim.models.word2vec.(job_no, items)->next(jobs_source)
A:gensim.models.word2vec.ns->Queue(maxsize=(queue_factor + 1) * self.workers).get(push_done)
A:gensim.models.word2vec.header->gensim.utils.to_unicode(fin.readline(), encoding=encoding)
A:gensim.models.word2vec.ch->fin.read(1)
A:gensim.models.word2vec.word->gensim.utils.to_unicode(b''.join(word), encoding=encoding, errors=unicode_errors)
A:gensim.models.word2vec.weights->fromstring(fin.read(binary_len), dtype=REAL)
A:gensim.models.word2vec.parts->gensim.utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(' ')
A:gensim.models.word2vec.prob_values->exp(dot(l1, self.trainables.syn1neg.T))
A:gensim.models.word2vec.top_indices->gensim.matutils.argsort(prob_values, topn=topn, reverse=True)
A:gensim.models.word2vec.kwargs['ignore']->kwargs.get('ignore', ['vectors_norm', 'cum_table'])
A:gensim.models.word2vec.fname->os.path.join(self.dirname, fname)
A:gensim.models.word2vec.line->gensim.utils.to_unicode(line).split()
A:gensim.models.word2vec.words->gensim.utils.to_unicode(text).split()
A:gensim.models.word2vec.last_token->text.rfind(b' ')
A:gensim.models.word2vec.self.source->os.path.join(self.source, '')
A:gensim.models.word2vec.self.input_files->os.listdir(self.source)
A:gensim.models.word2vec.vocab->defaultdict(int)
A:gensim.models.word2vec.wv.vocab[word]->Vocab(count=v, index=len(wv.index2word))
A:gensim.models.word2vec.threshold_count->int(sample * (3 + sqrt(5)) / 2)
A:gensim.models.word2vec.wv.vocab[w].sample_int->int(round(word_probability * 2 ** 32))
A:gensim.models.word2vec.self.raw_vocab->defaultdict(int)
A:gensim.models.word2vec.v.index->len(wv.vocab)
A:gensim.models.word2vec.heap->list(itervalues(wv.vocab))
A:gensim.models.word2vec.(node, codes, points)->stack.pop()
A:gensim.models.word2vec.max_depth->max(len(codes), max_depth)
A:gensim.models.word2vec.points->array(list(points) + [node.index - len(wv.vocab)], dtype=uint32)
A:gensim.models.word2vec.vocab_size->len(wv.index2word)
A:gensim.models.word2vec.self.cum_table->zeros(vocab_size, dtype=uint32)
A:gensim.models.word2vec.self.cum_table[word_index]->round(cumulative / train_words_pow * domain)
A:gensim.models.word2vec.once->numpy.random.RandomState(self.hashfxn(seed_string) & 4294967295)
A:gensim.models.word2vec.wv.vectors->vstack([wv.vectors, newvectors])
A:gensim.models.word2vec.wv.vectors[i]->self.seeded_vector(wv.index2word[i] + str(self.seed), wv.vector_size)
A:gensim.models.word2vec.self.syn1->vstack([self.syn1, zeros((gained_vocab, self.layer1_size), dtype=REAL)])
A:gensim.models.word2vec.self.syn1neg->vstack([self.syn1neg, zeros((gained_vocab, self.layer1_size), dtype=REAL)])
A:gensim.models.word2vec.self.vectors_lockf->ones(len(wv.vocab), dtype=REAL)
A:gensim.models.word2vec.newvectors->empty((gained_vocab, wv.vector_size), dtype=REAL)
A:gensim.models.word2vec.newvectors[i - len(wv.vectors)]->self.seeded_vector(wv.index2word[i] + str(self.seed), wv.vector_size)
A:gensim.models.word2vec.program->os.path.basename(sys.argv[0])
A:gensim.models.word2vec.parser->argparse.ArgumentParser()
A:gensim.models.word2vec.args->argparse.ArgumentParser().parse_args()
A:gensim.models.word2vec.corpus->LineSentence(args.train)
A:gensim.models.word2vec.model->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter)
gensim.models.Word2Vec(self,sentences=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False,callbacks=())
gensim.models.Word2Vec.__contains__(self,word)
gensim.models.Word2Vec.__getitem__(self,words)
gensim.models.Word2Vec.__str__(self)
gensim.models.Word2Vec._clear_post_train(self)
gensim.models.Word2Vec._do_train_job(self,sentences,alpha,inits)
gensim.models.Word2Vec._minimize_model(self,save_syn1=False,save_syn1neg=False,save_vectors_lockf=False)
gensim.models.Word2Vec._set_train_params(self,**kwargs)
gensim.models.Word2Vec.accuracy(self,questions,restrict_vocab=30000,most_similar=None,case_insensitive=True)
gensim.models.Word2Vec.clear_sims(self)
gensim.models.Word2Vec.delete_temporary_training_data(self,replace_word_vectors_with_normalized=False)
gensim.models.Word2Vec.get_latest_training_loss(self)
gensim.models.Word2Vec.init_sims(self,replace=False)
gensim.models.Word2Vec.intersect_word2vec_format(self,fname,lockf=0.0,binary=False,encoding='utf8',unicode_errors='strict')
gensim.models.Word2Vec.load(cls,*args,**kwargs)
gensim.models.Word2Vec.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.Word2Vec.log_accuracy(section)
gensim.models.Word2Vec.predict_output_word(self,context_words_list,topn=10)
gensim.models.Word2Vec.reset_from(self,other_model)
gensim.models.Word2Vec.save(self,*args,**kwargs)
gensim.models.Word2Vec.save_word2vec_format(self,fname,fvocab=None,binary=False)
gensim.models.Word2Vec.score(self,sentences,total_sentences=int(1000000.0),chunksize=100,queue_factor=2,report_delay=1)
gensim.models.Word2Vec.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=False,callbacks=())
gensim.models.Word2VecTrainables(self,vector_size=100,seed=1,hashfxn=hash)
gensim.models.Word2VecTrainables.prepare_weights(self,hs,negative,wv,update=False,vocabulary=None)
gensim.models.Word2VecTrainables.reset_weights(self,hs,negative,wv)
gensim.models.Word2VecTrainables.seeded_vector(self,seed_string,vector_size)
gensim.models.Word2VecTrainables.update_weights(self,hs,negative,wv)
gensim.models.Word2VecVocab(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.Word2VecVocab.add_null_word(self,wv)
gensim.models.Word2VecVocab.create_binary_tree(self,wv)
gensim.models.Word2VecVocab.make_cum_table(self,wv,power=0.75,domain=2**31-1)
gensim.models.Word2VecVocab.prepare_vocab(self,hs,negative,wv,update=False,keep_raw_vocab=False,trim_rule=None,min_count=None,sample=None,dry_run=False)
gensim.models.Word2VecVocab.scan_vocab(self,sentences,progress_per=10000,trim_rule=None)
gensim.models.Word2VecVocab.sort_vocab(self,wv)
gensim.models.word2vec.BrownCorpus(self,dirname)
gensim.models.word2vec.BrownCorpus.__init__(self,dirname)
gensim.models.word2vec.BrownCorpus.__iter__(self)
gensim.models.word2vec.LineSentence(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.LineSentence.__init__(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.LineSentence.__iter__(self)
gensim.models.word2vec.PathLineSentences(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.PathLineSentences.__init__(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.word2vec.PathLineSentences.__iter__(self)
gensim.models.word2vec.Text8Corpus(self,fname,max_sentence_length=MAX_WORDS_IN_BATCH)
gensim.models.word2vec.Text8Corpus.__init__(self,fname,max_sentence_length=MAX_WORDS_IN_BATCH)
gensim.models.word2vec.Text8Corpus.__iter__(self)
gensim.models.word2vec.Word2Vec(self,sentences=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False,callbacks=())
gensim.models.word2vec.Word2Vec.__contains__(self,word)
gensim.models.word2vec.Word2Vec.__getitem__(self,words)
gensim.models.word2vec.Word2Vec.__init__(self,sentences=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False,callbacks=())
gensim.models.word2vec.Word2Vec.__str__(self)
gensim.models.word2vec.Word2Vec._clear_post_train(self)
gensim.models.word2vec.Word2Vec._do_train_job(self,sentences,alpha,inits)
gensim.models.word2vec.Word2Vec._minimize_model(self,save_syn1=False,save_syn1neg=False,save_vectors_lockf=False)
gensim.models.word2vec.Word2Vec._set_train_params(self,**kwargs)
gensim.models.word2vec.Word2Vec.accuracy(self,questions,restrict_vocab=30000,most_similar=None,case_insensitive=True)
gensim.models.word2vec.Word2Vec.clear_sims(self)
gensim.models.word2vec.Word2Vec.delete_temporary_training_data(self,replace_word_vectors_with_normalized=False)
gensim.models.word2vec.Word2Vec.get_latest_training_loss(self)
gensim.models.word2vec.Word2Vec.init_sims(self,replace=False)
gensim.models.word2vec.Word2Vec.intersect_word2vec_format(self,fname,lockf=0.0,binary=False,encoding='utf8',unicode_errors='strict')
gensim.models.word2vec.Word2Vec.load(cls,*args,**kwargs)
gensim.models.word2vec.Word2Vec.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.word2vec.Word2Vec.log_accuracy(section)
gensim.models.word2vec.Word2Vec.predict_output_word(self,context_words_list,topn=10)
gensim.models.word2vec.Word2Vec.reset_from(self,other_model)
gensim.models.word2vec.Word2Vec.save(self,*args,**kwargs)
gensim.models.word2vec.Word2Vec.save_word2vec_format(self,fname,fvocab=None,binary=False)
gensim.models.word2vec.Word2Vec.score(self,sentences,total_sentences=int(1000000.0),chunksize=100,queue_factor=2,report_delay=1)
gensim.models.word2vec.Word2Vec.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=False,callbacks=())
gensim.models.word2vec.Word2VecTrainables(self,vector_size=100,seed=1,hashfxn=hash)
gensim.models.word2vec.Word2VecTrainables.__init__(self,vector_size=100,seed=1,hashfxn=hash)
gensim.models.word2vec.Word2VecTrainables.prepare_weights(self,hs,negative,wv,update=False,vocabulary=None)
gensim.models.word2vec.Word2VecTrainables.reset_weights(self,hs,negative,wv)
gensim.models.word2vec.Word2VecTrainables.seeded_vector(self,seed_string,vector_size)
gensim.models.word2vec.Word2VecTrainables.update_weights(self,hs,negative,wv)
gensim.models.word2vec.Word2VecVocab(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.word2vec.Word2VecVocab.__init__(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.word2vec.Word2VecVocab.add_null_word(self,wv)
gensim.models.word2vec.Word2VecVocab.create_binary_tree(self,wv)
gensim.models.word2vec.Word2VecVocab.make_cum_table(self,wv,power=0.75,domain=2**31-1)
gensim.models.word2vec.Word2VecVocab.prepare_vocab(self,hs,negative,wv,update=False,keep_raw_vocab=False,trim_rule=None,min_count=None,sample=None,dry_run=False)
gensim.models.word2vec.Word2VecVocab.scan_vocab(self,sentences,progress_per=10000,trim_rule=None)
gensim.models.word2vec.Word2VecVocab.sort_vocab(self,wv)
gensim.models.word2vec.score_cbow_pair(model,word,l1)
gensim.models.word2vec.score_sg_pair(model,word,word2)
gensim.models.word2vec.train_cbow_pair(model,word,input_word_indices,l1,alpha,learn_vectors=True,learn_hidden=True,compute_loss=False,context_vectors=None,context_locks=None,is_ft=False)
gensim.models.word2vec.train_sg_pair(model,word,context_index,alpha,learn_vectors=True,learn_hidden=True,context_vectors=None,context_locks=None,compute_loss=False,is_ft=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/lda_dispatcher.py----------------------------------------
A:gensim.models.lda_dispatcher.logger->logging.getLogger('gensim.models.lda_dispatcher')
A:gensim.models.lda_dispatcher.self.jobs->Queue(maxsize=self.maxsize)
A:gensim.models.lda_dispatcher.self.lock_update->threading.Lock()
A:gensim.models.lda_dispatcher.self.callback->Pyro4.Proxy(ns.list(prefix=LDA_DISPATCHER_PREFIX)[LDA_DISPATCHER_PREFIX])
A:gensim.models.lda_dispatcher.worker->Pyro4.Proxy(uri)
A:gensim.models.lda_dispatcher.workerid->len(self.workers)
A:gensim.models.lda_dispatcher.job->self.jobs.get(block=True, timeout=1)
A:gensim.models.lda_dispatcher.workers->list(self.workers.values())
A:gensim.models.lda_dispatcher.result->workers[0].getstate()
A:gensim.models.lda_dispatcher.parser->argparse.ArgumentParser(description=__doc__)
A:gensim.models.lda_dispatcher.args->argparse.ArgumentParser(description=__doc__).parse_args()
gensim.models.lda_dispatcher.Dispatcher(self,maxsize=MAX_JOBS_QUEUE,ns_conf=None)
gensim.models.lda_dispatcher.Dispatcher.__init__(self,maxsize=MAX_JOBS_QUEUE,ns_conf=None)
gensim.models.lda_dispatcher.Dispatcher.exit(self)
gensim.models.lda_dispatcher.Dispatcher.getjob(self,worker_id)
gensim.models.lda_dispatcher.Dispatcher.getstate(self)
gensim.models.lda_dispatcher.Dispatcher.getworkers(self)
gensim.models.lda_dispatcher.Dispatcher.initialize(self,**model_params)
gensim.models.lda_dispatcher.Dispatcher.jobdone(self,workerid)
gensim.models.lda_dispatcher.Dispatcher.jobsdone(self)
gensim.models.lda_dispatcher.Dispatcher.putjob(self,job)
gensim.models.lda_dispatcher.Dispatcher.reset(self,state)
gensim.models.lda_dispatcher.main()


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/fasttext.py----------------------------------------
A:gensim.models.fasttext.logger->logging.getLogger(__name__)
A:gensim.models.fasttext.reduced_window->super(FastText, cls).load(*args, **kwargs).random.randint(model.window)
A:gensim.models.fasttext.start->max(0, pos - model.window + reduced_window)
A:gensim.models.fasttext.window_pos->enumerate(word_vocabs[start:pos + model.window + 1 - reduced_window], start)
A:gensim.models.fasttext.l1_vocab->np_sum(model.wv.syn0_vocab[vocab_subwords_indices], axis=0)
A:gensim.models.fasttext.l1_ngrams->np_sum(model.wv.syn0_ngrams[ngrams_subwords_indices], axis=0)
A:gensim.models.fasttext.l1->np_sum([l1_vocab, l1_ngrams], axis=0)
A:gensim.models.fasttext.self.word_ngrams->int(word_ngrams)
A:gensim.models.fasttext.self.wv->FastTextKeyedVectors(size, min_n, max_n)
A:gensim.models.fasttext.self.vocabulary->FastTextVocab(max_vocab_size=max_vocab_size, min_count=min_count, sample=sample, sorted_vocab=bool(sorted_vocab), null_word=null_word)
A:gensim.models.fasttext.self.trainables->FastTextTrainables(vector_size=size, seed=seed, bucket=bucket, hashfxn=hashfxn)
A:gensim.models.fasttext.self.vocabulary.old_vocab_len->len(self.wv.vocab)
A:gensim.models.fasttext.self.trainables.old_hash2index_len->len(self.wv.hash2index)
A:gensim.models.fasttext.buckets->set()
A:gensim.models.fasttext.ngrams->_compute_ngrams(w, wv.min_n, wv.max_n)
A:gensim.models.fasttext.num_buckets->len(buckets)
A:gensim.models.fasttext.report['total']->sum(report.values())
A:gensim.models.fasttext.model->super(FastText, cls).load(*args, **kwargs)
A:gensim.models.fasttext.(magic, version)->self.struct_unpack(file_handle, '@2i')
A:gensim.models.fasttext.(dim, ws, epoch, min_count, neg, _, loss, model, bucket, minn, maxn, _, t)->self.struct_unpack(file_handle, '@12i1d')
A:gensim.models.fasttext.(epoch, min_count, neg, _, loss, model, bucket, minn, maxn, _, t)->self.struct_unpack(file_handle, '@10i1d')
A:gensim.models.fasttext.(vocab_size, nwords, nlabels)->self.struct_unpack(file_handle, '@3i')
A:gensim.models.fasttext.(pruneidx_size,)->self.struct_unpack(file_handle, '@q')
A:gensim.models.fasttext.char_byte->file_handle.read(1)
A:gensim.models.fasttext.word->word_bytes.decode(encoding)
A:gensim.models.fasttext.(count, _)->self.struct_unpack(file_handle, '@qb')
A:gensim.models.fasttext.self.wv.vocab[word]->Vocab(index=i, count=count)
A:gensim.models.fasttext.(num_vectors, dim)->self.struct_unpack(file_handle, '@2q')
A:gensim.models.fasttext.float_size->struct.calcsize('@f')
A:gensim.models.fasttext.dtype->numpy.dtype(np.float64)
A:gensim.models.fasttext.self.wv.vectors_ngrams->self.wv.vectors_ngrams.reshape((num_vectors, dim))
A:gensim.models.fasttext.num_bytes->struct.calcsize(fmt)
A:gensim.models.fasttext.kwargs['ignore']->kwargs.get('ignore', ['vectors_norm', 'vectors_vocab_norm', 'vectors_ngrams_norm', 'buckets_word'])
A:gensim.models.fasttext.model.trainables.vectors_vocab_lockf->ones(len(model.trainables.vectors), dtype=REAL)
A:gensim.models.fasttext.model.trainables.vectors_ngrams_lockf->ones(len(model.trainables.vectors), dtype=REAL)
A:gensim.models.fasttext.report_values->super(FastTextVocab, self).prepare_vocab(hs, negative, wv, update=update, keep_raw_vocab=keep_raw_vocab, trim_rule=trim_rule, min_count=min_count, sample=sample, dry_run=dry_run)
A:gensim.models.fasttext.self.bucket->int(bucket)
A:gensim.models.fasttext.wv.vectors_vocab->vstack([wv.vectors_vocab, new_vocab_rows])
A:gensim.models.fasttext.self.vectors_vocab_lockf->vstack([self.vectors_vocab_lockf, new_vocab_lockf_rows])
A:gensim.models.fasttext.wv.vectors_ngrams->wv.vectors_ngrams.take(ngram_indices, axis=0)
A:gensim.models.fasttext.self.vectors_ngrams_lockf->vstack([self.vectors_ngrams_lockf, new_ngram_lockf_rows])
A:gensim.models.fasttext.wv.hash2index[ngram_hash]->len(ngram_indices)
A:gensim.models.fasttext.wv.buckets_word[vocab.index]->tuple(buckets)
A:gensim.models.fasttext.wv.num_ngram_vectors->len(ngram_indices)
A:gensim.models.fasttext.new_vocab_rows->rand_obj.uniform(-1.0 / wv.vector_size, 1.0 / wv.vector_size, (len(wv.vocab) - vocabulary.old_vocab_len, wv.vector_size)).astype(REAL)
A:gensim.models.fasttext.new_vocab_lockf_rows->ones((len(wv.vocab) - vocabulary.old_vocab_len, wv.vector_size), dtype=REAL)
A:gensim.models.fasttext.new_ngram_rows->rand_obj.uniform(-1.0 / wv.vector_size, 1.0 / wv.vector_size, (len(wv.hash2index) - self.old_hash2index_len, wv.vector_size)).astype(REAL)
A:gensim.models.fasttext.new_ngram_lockf_rows->ones((len(wv.hash2index) - self.old_hash2index_len, wv.vector_size), dtype=REAL)
A:gensim.models.fasttext.wv.vectors_vocab[index]->rand_obj.uniform(-1.0 / wv.vector_size, 1.0 / wv.vector_size, wv.vector_size).astype(REAL)
A:gensim.models.fasttext.wv.vectors_ngrams[index]->rand_obj.uniform(-1.0 / wv.vector_size, 1.0 / wv.vector_size, wv.vector_size).astype(REAL)
A:gensim.models.fasttext.word_vec->numpy.copy(wv.vectors_vocab[v.index])
A:gensim.models.fasttext.wv.vectors->numpy.zeros((len(wv.vocab), wv.vector_size), dtype=REAL)
A:gensim.models.fasttext.word_ngrams->_compute_ngrams(w, wv.min_n, wv.max_n)
gensim.models.FastText(self,sentences=None,sg=0,hs=0,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH,callbacks=())
gensim.models.FastText.__contains__(self,word)
gensim.models.FastText.__getitem__(self,words)
gensim.models.FastText._clear_post_train(self)
gensim.models.FastText._do_train_job(self,sentences,alpha,inits)
gensim.models.FastText._load_dict(self,file_handle,encoding='utf8')
gensim.models.FastText._load_model_params(self,file_handle)
gensim.models.FastText._load_vectors(self,file_handle)
gensim.models.FastText._set_train_params(self,**kwargs)
gensim.models.FastText.accuracy(self,questions,restrict_vocab=30000,most_similar=None,case_insensitive=True)
gensim.models.FastText.bucket(self)
gensim.models.FastText.build_vocab(self,sentences,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.FastText.clear_sims(self)
gensim.models.FastText.estimate_memory(self,vocab_size=None,report=None)
gensim.models.FastText.init_sims(self,replace=False)
gensim.models.FastText.load(cls,*args,**kwargs)
gensim.models.FastText.load_binary_data(self,encoding='utf8')
gensim.models.FastText.load_fasttext_format(cls,model_file,encoding='utf8')
gensim.models.FastText.max_n(self)
gensim.models.FastText.min_n(self)
gensim.models.FastText.num_ngram_vectors(self)
gensim.models.FastText.save(self,*args,**kwargs)
gensim.models.FastText.struct_unpack(self,file_handle,fmt)
gensim.models.FastText.syn0_ngrams_lockf(self)
gensim.models.FastText.syn0_ngrams_lockf(self)
gensim.models.FastText.syn0_ngrams_lockf(self,value)
gensim.models.FastText.syn0_vocab_lockf(self)
gensim.models.FastText.syn0_vocab_lockf(self)
gensim.models.FastText.syn0_vocab_lockf(self,value)
gensim.models.FastText.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,callbacks=(),**kwargs)
gensim.models.FastTextTrainables(self,vector_size=100,seed=1,hashfxn=hash,bucket=2000000)
gensim.models.FastTextTrainables.get_vocab_word_vecs(self,wv)
gensim.models.FastTextTrainables.init_ngrams_post_load(self,file_name,wv)
gensim.models.FastTextTrainables.init_ngrams_weights(self,wv,update=False,vocabulary=None)
gensim.models.FastTextTrainables.prepare_weights(self,hs,negative,wv,update=False,vocabulary=None)
gensim.models.FastTextTrainables.reset_ngrams_weights(self,wv)
gensim.models.FastTextVocab(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.FastTextVocab.prepare_vocab(self,hs,negative,wv,update=False,keep_raw_vocab=False,trim_rule=None,min_count=None,sample=None,dry_run=False)
gensim.models.fasttext.FastText(self,sentences=None,sg=0,hs=0,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH,callbacks=())
gensim.models.fasttext.FastText.__contains__(self,word)
gensim.models.fasttext.FastText.__getitem__(self,words)
gensim.models.fasttext.FastText.__init__(self,sentences=None,sg=0,hs=0,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH,callbacks=())
gensim.models.fasttext.FastText._clear_post_train(self)
gensim.models.fasttext.FastText._do_train_job(self,sentences,alpha,inits)
gensim.models.fasttext.FastText._load_dict(self,file_handle,encoding='utf8')
gensim.models.fasttext.FastText._load_model_params(self,file_handle)
gensim.models.fasttext.FastText._load_vectors(self,file_handle)
gensim.models.fasttext.FastText._set_train_params(self,**kwargs)
gensim.models.fasttext.FastText.accuracy(self,questions,restrict_vocab=30000,most_similar=None,case_insensitive=True)
gensim.models.fasttext.FastText.bucket(self)
gensim.models.fasttext.FastText.build_vocab(self,sentences,update=False,progress_per=10000,keep_raw_vocab=False,trim_rule=None,**kwargs)
gensim.models.fasttext.FastText.clear_sims(self)
gensim.models.fasttext.FastText.estimate_memory(self,vocab_size=None,report=None)
gensim.models.fasttext.FastText.init_sims(self,replace=False)
gensim.models.fasttext.FastText.load(cls,*args,**kwargs)
gensim.models.fasttext.FastText.load_binary_data(self,encoding='utf8')
gensim.models.fasttext.FastText.load_fasttext_format(cls,model_file,encoding='utf8')
gensim.models.fasttext.FastText.max_n(self)
gensim.models.fasttext.FastText.min_n(self)
gensim.models.fasttext.FastText.num_ngram_vectors(self)
gensim.models.fasttext.FastText.save(self,*args,**kwargs)
gensim.models.fasttext.FastText.struct_unpack(self,file_handle,fmt)
gensim.models.fasttext.FastText.syn0_ngrams_lockf(self)
gensim.models.fasttext.FastText.syn0_ngrams_lockf(self)
gensim.models.fasttext.FastText.syn0_ngrams_lockf(self,value)
gensim.models.fasttext.FastText.syn0_vocab_lockf(self)
gensim.models.fasttext.FastText.syn0_vocab_lockf(self)
gensim.models.fasttext.FastText.syn0_vocab_lockf(self,value)
gensim.models.fasttext.FastText.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,callbacks=(),**kwargs)
gensim.models.fasttext.FastTextTrainables(self,vector_size=100,seed=1,hashfxn=hash,bucket=2000000)
gensim.models.fasttext.FastTextTrainables.__init__(self,vector_size=100,seed=1,hashfxn=hash,bucket=2000000)
gensim.models.fasttext.FastTextTrainables.get_vocab_word_vecs(self,wv)
gensim.models.fasttext.FastTextTrainables.init_ngrams_post_load(self,file_name,wv)
gensim.models.fasttext.FastTextTrainables.init_ngrams_weights(self,wv,update=False,vocabulary=None)
gensim.models.fasttext.FastTextTrainables.prepare_weights(self,hs,negative,wv,update=False,vocabulary=None)
gensim.models.fasttext.FastTextTrainables.reset_ngrams_weights(self,wv)
gensim.models.fasttext.FastTextVocab(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.fasttext.FastTextVocab.__init__(self,max_vocab_size=None,min_count=5,sample=0.001,sorted_vocab=True,null_word=0)
gensim.models.fasttext.FastTextVocab.prepare_vocab(self,hs,negative,wv,update=False,keep_raw_vocab=False,trim_rule=None,min_count=None,sample=None,dry_run=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/keyedvectors.py----------------------------------------
A:gensim.models.deprecated.keyedvectors.logger->logging.getLogger(__name__)
A:gensim.models.deprecated.keyedvectors.total_vec->len(self.vocab)
A:gensim.models.deprecated.keyedvectors.(word, count)->gensim.utils.to_unicode(line).strip().split()
A:gensim.models.deprecated.keyedvectors.counts[word]->int(count)
A:gensim.models.deprecated.keyedvectors.header->gensim.utils.to_unicode(fin.readline(), encoding=encoding)
A:gensim.models.deprecated.keyedvectors.vocab_size->min(vocab_size, limit)
A:gensim.models.deprecated.keyedvectors.result->cls()
A:gensim.models.deprecated.keyedvectors.result.syn0->ascontiguousarray(result.syn0[:len(result.vocab)])
A:gensim.models.deprecated.keyedvectors.word_id->len(result.vocab)
A:gensim.models.deprecated.keyedvectors.result.vocab[word]->Vocab(index=word_id, count=None)
A:gensim.models.deprecated.keyedvectors.ch->fin.read(1)
A:gensim.models.deprecated.keyedvectors.word->gensim.utils.to_unicode(b''.join(word), encoding=encoding, errors=unicode_errors)
A:gensim.models.deprecated.keyedvectors.weights->fromstring(fin.read(binary_len), dtype=REAL)
A:gensim.models.deprecated.keyedvectors.line->gensim.utils.to_unicode(line)
A:gensim.models.deprecated.keyedvectors.parts->gensim.utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(' ')
A:gensim.models.deprecated.keyedvectors.all_distances->self.distances(w1)
A:gensim.models.deprecated.keyedvectors.kwargs['ignore']->kwargs.get('ignore', ['syn0norm'])
A:gensim.models.deprecated.keyedvectors.mean->gensim.matutils.unitvec(vectors.mean(axis=0)).astype(REAL)
A:gensim.models.deprecated.keyedvectors.dists->dot(vectors, mean)
A:gensim.models.deprecated.keyedvectors.best->gensim.matutils.argsort(dists, topn=topn + len(all_words), reverse=True)
A:gensim.models.deprecated.keyedvectors.len_pre_oov1->len(document1)
A:gensim.models.deprecated.keyedvectors.len_pre_oov2->len(document2)
A:gensim.models.deprecated.keyedvectors.dictionary->Dictionary(documents=[document1, document2])
A:gensim.models.deprecated.keyedvectors.vocab_len->len(dictionary)
A:gensim.models.deprecated.keyedvectors.docset1->set(document1)
A:gensim.models.deprecated.keyedvectors.docset2->set(document2)
A:gensim.models.deprecated.keyedvectors.distance_matrix->zeros((vocab_len, vocab_len), dtype=double)
A:gensim.models.deprecated.keyedvectors.distance_matrix[i, j]->sqrt(np_sum((self[t1] - self[t2]) ** 2))
A:gensim.models.deprecated.keyedvectors.d->zeros(vocab_len, dtype=double)
A:gensim.models.deprecated.keyedvectors.nbow->Dictionary(documents=[document1, document2]).doc2bow(document)
A:gensim.models.deprecated.keyedvectors.doc_len->len(document)
A:gensim.models.deprecated.keyedvectors.d1->nbow(document1)
A:gensim.models.deprecated.keyedvectors.d2->nbow(document2)
A:gensim.models.deprecated.keyedvectors.vectors->vstack((self.word_vec(word, use_norm=True) for word in used_words)).astype(REAL)
A:gensim.models.deprecated.keyedvectors.norm->numpy.linalg.norm(vector_1)
A:gensim.models.deprecated.keyedvectors.all_norms->numpy.linalg.norm(vectors_all, axis=1)
A:gensim.models.deprecated.keyedvectors.dot_products->dot(vectors_all, vector_1)
A:gensim.models.deprecated.keyedvectors.input_vector->self.word_vec(word_or_vector)
A:gensim.models.deprecated.keyedvectors.sims->most_similar(self, positive=[b, c], negative=[a], topn=False, restrict_vocab=restrict_vocab)
A:gensim.models.deprecated.keyedvectors.sim->float(sim)
A:gensim.models.deprecated.keyedvectors.spearman->scipy.stats.spearmanr(similarity_gold, similarity_model)
A:gensim.models.deprecated.keyedvectors.pearson->scipy.stats.pearsonr(similarity_gold, similarity_model)
A:gensim.models.deprecated.keyedvectors.self.syn0norm->(self.syn0 / sqrt((self.syn0 ** 2).sum(-1))[..., newaxis]).astype(REAL)
A:gensim.models.deprecated.keyedvectors.layer->Embedding(input_dim=weights.shape[0], output_dim=weights.shape[1], weights=[weights], trainable=train_embeddings)
gensim.models.deprecated.KeyedVectorsBase(self)
gensim.models.deprecated.KeyedVectorsBase.__contains__(self,word)
gensim.models.deprecated.KeyedVectorsBase.__getitem__(self,words)
gensim.models.deprecated.KeyedVectorsBase.distance(self,w1,w2)
gensim.models.deprecated.KeyedVectorsBase.distances(self,word_or_vector,other_words=())
gensim.models.deprecated.KeyedVectorsBase.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.deprecated.KeyedVectorsBase.most_similar_to_given(self,w1,word_list)
gensim.models.deprecated.KeyedVectorsBase.rank(self,w1,w2)
gensim.models.deprecated.KeyedVectorsBase.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None)
gensim.models.deprecated.KeyedVectorsBase.similarity(self,w1,w2)
gensim.models.deprecated.KeyedVectorsBase.word_vec(self,word)
gensim.models.deprecated.KeyedVectorsBase.words_closer_than(self,w1,w2)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors(self)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.__init__(self)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.accuracy(self,questions,restrict_vocab=30000,most_similar=most_similar,case_insensitive=True)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.cosine_similarities(vector_1,vectors_all)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.distance(self,w1,w2)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.distances(self,word_or_vector,other_words=())
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.doesnt_match(self,words)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.get_keras_embedding(self,train_embeddings=False)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.init_sims(self,replace=False)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.log_accuracy(section)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.log_evaluate_word_pairs(pearson,spearman,oov,pairs)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.most_similar(self,positive=None,negative=None,topn=10,restrict_vocab=None,indexer=None)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.n_similarity(self,ws1,ws2)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.save(self,*args,**kwargs)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.similarity(self,w1,w2)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.wmdistance(self,document1,document2)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.word_vec(self,word,use_norm=False)
gensim.models.deprecated.keyedvectors.EuclideanKeyedVectors.wv(self)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase(self)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.__contains__(self,word)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.__getitem__(self,words)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.__init__(self)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.distance(self,w1,w2)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.distances(self,word_or_vector,other_words=())
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.most_similar_to_given(self,w1,word_list)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.rank(self,w1,w2)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.save_word2vec_format(self,fname,fvocab=None,binary=False,total_vec=None)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.similarity(self,w1,w2)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.word_vec(self,word)
gensim.models.deprecated.keyedvectors.KeyedVectorsBase.words_closer_than(self,w1,w2)
gensim.models.deprecated.keyedvectors.Vocab(self,**kwargs)
gensim.models.deprecated.keyedvectors.Vocab.__init__(self,**kwargs)
gensim.models.deprecated.keyedvectors.Vocab.__lt__(self,other)
gensim.models.deprecated.keyedvectors.Vocab.__str__(self)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/fasttext_wrapper.py----------------------------------------
A:gensim.models.deprecated.fasttext_wrapper.logger->logging.getLogger(__name__)
A:gensim.models.deprecated.fasttext_wrapper.kwargs['ignore']->kwargs.get('ignore', ['syn0norm', 'syn0_vocab_norm', 'syn0_ngrams_norm'])
A:gensim.models.deprecated.fasttext_wrapper.word_vec->numpy.zeros(self.syn0_ngrams.shape[1], dtype=np.float32)
A:gensim.models.deprecated.fasttext_wrapper.ngrams->compute_ngrams(word, self.min_n, self.max_n)
A:gensim.models.deprecated.fasttext_wrapper.self.syn0_ngrams_norm->(self.syn0_ngrams / sqrt((self.syn0_ngrams ** 2).sum(-1))[..., newaxis]).astype(REAL)
A:gensim.models.deprecated.fasttext_wrapper.char_ngrams->compute_ngrams(word, self.min_n, self.max_n)
A:gensim.models.deprecated.fasttext_wrapper.self.wv->FastTextKeyedVectors()
A:gensim.models.deprecated.fasttext_wrapper.model->super(FastText, cls).load(*args, **kwargs)
A:gensim.models.deprecated.fasttext_wrapper.(magic, version)->self.struct_unpack(file_handle, '@2i')
A:gensim.models.deprecated.fasttext_wrapper.(dim, ws, epoch, min_count, neg, _, loss, model, bucket, minn, maxn, _, t)->self.struct_unpack(file_handle, '@12i1d')
A:gensim.models.deprecated.fasttext_wrapper.(epoch, min_count, neg, _, loss, model, bucket, minn, maxn, _, t)->self.struct_unpack(file_handle, '@10i1d')
A:gensim.models.deprecated.fasttext_wrapper.(vocab_size, nwords, nlabels)->self.struct_unpack(file_handle, '@3i')
A:gensim.models.deprecated.fasttext_wrapper.(pruneidx_size,)->self.struct_unpack(file_handle, '@q')
A:gensim.models.deprecated.fasttext_wrapper.char_byte->file_handle.read(1)
A:gensim.models.deprecated.fasttext_wrapper.word->word_bytes.decode(encoding)
A:gensim.models.deprecated.fasttext_wrapper.(count, _)->self.struct_unpack(file_handle, '@qb')
A:gensim.models.deprecated.fasttext_wrapper.self.wv.vocab[word]->Vocab(index=i, count=count)
A:gensim.models.deprecated.fasttext_wrapper.(num_vectors, dim)->self.struct_unpack(file_handle, '@2q')
A:gensim.models.deprecated.fasttext_wrapper.float_size->struct.calcsize('@f')
A:gensim.models.deprecated.fasttext_wrapper.dtype->numpy.dtype(np.float64)
A:gensim.models.deprecated.fasttext_wrapper.self.wv.syn0_ngrams->self.wv.syn0_ngrams.take(ngram_indices, axis=0)
A:gensim.models.deprecated.fasttext_wrapper.num_bytes->struct.calcsize(fmt)
A:gensim.models.deprecated.fasttext_wrapper.self.wv.syn0->numpy.zeros((len(self.wv.vocab), self.vector_size), dtype=REAL)
A:gensim.models.deprecated.fasttext_wrapper.all_ngrams->set(all_ngrams)
A:gensim.models.deprecated.fasttext_wrapper.self.num_ngram_vectors->len(all_ngrams)
A:gensim.models.deprecated.fasttext_wrapper.ngram_hash->ft_hash(ngram)
A:gensim.models.deprecated.fasttext_wrapper.word_ngrams->compute_ngrams(w, self.wv.min_n, self.wv.max_n)
A:gensim.models.deprecated.fasttext_wrapper.old_settings->numpy.seterr(all='ignore')
A:gensim.models.deprecated.fasttext_wrapper.h->numpy.uint32(2166136261)
gensim.models.deprecated.fasttext_wrapper.FastText(Word2Vec)
gensim.models.deprecated.fasttext_wrapper.FastText.delete_training_files(cls,model_file)
gensim.models.deprecated.fasttext_wrapper.FastText.init_ngrams(self)
gensim.models.deprecated.fasttext_wrapper.FastText.initialize_word_vectors(self)
gensim.models.deprecated.fasttext_wrapper.FastText.load(cls,*args,**kwargs)
gensim.models.deprecated.fasttext_wrapper.FastText.load_binary_data(self,encoding='utf8')
gensim.models.deprecated.fasttext_wrapper.FastText.load_dict(self,file_handle,encoding='utf8')
gensim.models.deprecated.fasttext_wrapper.FastText.load_fasttext_format(cls,model_file,encoding='utf8')
gensim.models.deprecated.fasttext_wrapper.FastText.load_model_params(self,file_handle)
gensim.models.deprecated.fasttext_wrapper.FastText.load_vectors(self,file_handle)
gensim.models.deprecated.fasttext_wrapper.FastText.save(self,*args,**kwargs)
gensim.models.deprecated.fasttext_wrapper.FastText.struct_unpack(self,file_handle,fmt)
gensim.models.deprecated.fasttext_wrapper.FastText.train(cls,ft_path,corpus_file,output_file=None,model='cbow',size=100,alpha=0.025,window=5,min_count=5,word_ngrams=1,loss='ns',sample=0.001,negative=5,iter=5,min_n=3,max_n=6,sorted_vocab=1,threads=12)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors(self)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors.__contains__(self,word)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors.__init__(self)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors.init_sims(self,replace=False)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors.load_word2vec_format(cls,*args,**kwargs)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors.save(self,*args,**kwargs)
gensim.models.deprecated.fasttext_wrapper.FastTextKeyedVectors.word_vec(self,word,use_norm=False)
gensim.models.deprecated.fasttext_wrapper.compute_ngrams(word,min_n,max_n)
gensim.models.deprecated.fasttext_wrapper.ft_hash(string)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/doc2vec.py----------------------------------------
A:gensim.models.deprecated.doc2vec.logger->logging.getLogger(__name__)
A:gensim.models.deprecated.doc2vec.old_model->Doc2Vec.load(*args, **kwargs)
A:gensim.models.deprecated.doc2vec.new_model->NewDoc2Vec(**params)
A:gensim.models.deprecated.doc2vec.reduced_window->model.random.randint(model.window)
A:gensim.models.deprecated.doc2vec.start->max(0, pos - model.window + reduced_window)
A:gensim.models.deprecated.doc2vec.window_pos->enumerate(word_vocabs[start:pos + model.window + 1 - reduced_window], start)
A:gensim.models.deprecated.doc2vec.neu1e->train_cbow_pair(model, predict_word, None, l1, alpha, learn_hidden=learn_hidden, learn_vectors=False)
A:gensim.models.deprecated.doc2vec.doctag_len->len(doctag_indexes)
A:gensim.models.deprecated.doc2vec.l1->concatenate((doctag_vectors[doctag_indexes], word_vectors[word_context_indexes])).ravel()
A:gensim.models.deprecated.doc2vec.e_locks->concatenate((doctag_locks[doctag_indexes], word_locks[word_context_indexes]))
A:gensim.models.deprecated.doc2vec.self.max_rawint->max(self.max_rawint, key)
A:gensim.models.deprecated.doc2vec.self.doctags[key]->Doctag(len(self.offset2doctag), document_length, 1)
A:gensim.models.deprecated.doc2vec.kwargs['ignore']->kwargs.get('ignore', ['syn0norm'])
A:gensim.models.deprecated.doc2vec.length->max(len(self.doctags), self.count)
A:gensim.models.deprecated.doc2vec.self.doctag_syn0->empty((length, model.vector_size), dtype=REAL)
A:gensim.models.deprecated.doc2vec.self.doctag_syn0_lockf->ones((length,), dtype=REAL)
A:gensim.models.deprecated.doc2vec.self.doctag_syn0[i]->model.seeded_vector(seed)
A:gensim.models.deprecated.doc2vec.self.doctag_syn0norm->empty(self.doctag_syn0.shape, dtype=REAL)
A:gensim.models.deprecated.doc2vec.mean->gensim.matutils.unitvec(vectors.mean(axis=0)).astype(REAL)
A:gensim.models.deprecated.doc2vec.dists->dot(vectors, mean)
A:gensim.models.deprecated.doc2vec.best->gensim.matutils.argsort(dists, topn=topn + len(all_docs), reverse=True)
A:gensim.models.deprecated.doc2vec.vectors->vstack((self.doctag_syn0norm[self._int_index(doc)] for doc in docs)).astype(REAL)
A:gensim.models.deprecated.doc2vec.d1->model.infer_vector(doc_words=doc_words1, alpha=alpha, min_alpha=min_alpha, steps=steps)
A:gensim.models.deprecated.doc2vec.d2->model.infer_vector(doc_words=doc_words2, alpha=alpha, min_alpha=min_alpha, steps=steps)
A:gensim.models.deprecated.doc2vec.vocab->defaultdict(int)
A:gensim.models.deprecated.doc2vec.interval_start->default_timer()
A:gensim.models.deprecated.doc2vec.document_length->len(document.words)
A:gensim.models.deprecated.doc2vec.indexed_doctags->self.docvecs.indexed_doctags(doc.tags)
A:gensim.models.deprecated.doc2vec.doctag_vectors->empty((1, self.vector_size), dtype=REAL)
A:gensim.models.deprecated.doc2vec.doctag_vectors[0]->self.seeded_vector(' '.join(doc_words))
A:gensim.models.deprecated.doc2vec.doctag_locks->ones(1, dtype=REAL)
A:gensim.models.deprecated.doc2vec.work->zeros(self.layer1_size, dtype=REAL)
A:gensim.models.deprecated.doc2vec.neu1->gensim.matutils.zeros_aligned(self.layer1_size, dtype=REAL)
A:gensim.models.deprecated.doc2vec.report['doctag_lookup']->self.docvecs.estimated_lookup_memory()
A:gensim.models.deprecated.doc2vec.total_vec->len(self.docvecs)
A:gensim.models.deprecated.doc2vec.fname->os.path.join(self.dirname, fname)
A:gensim.models.deprecated.doc2vec.line->gensim.utils.to_unicode(line)
gensim.models.deprecated.Doc2Vec(self,documents=None,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,**kwargs)
gensim.models.deprecated.Doc2Vec.__str__(self)
gensim.models.deprecated.Doc2Vec._do_train_job(self,job,alpha,inits)
gensim.models.deprecated.Doc2Vec._raw_word_count(self,job)
gensim.models.deprecated.Doc2Vec.clear_sims(self)
gensim.models.deprecated.Doc2Vec.dbow(self)
gensim.models.deprecated.Doc2Vec.delete_temporary_training_data(self,keep_doctags_vectors=True,keep_inference=True)
gensim.models.deprecated.Doc2Vec.dm(self)
gensim.models.deprecated.Doc2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.deprecated.Doc2Vec.infer_vector(self,doc_words,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.models.deprecated.Doc2Vec.reset_from(self,other_model)
gensim.models.deprecated.Doc2Vec.reset_weights(self)
gensim.models.deprecated.Doc2Vec.save_word2vec_format(self,fname,doctag_vec=False,word_vec=True,prefix='*dt_',fvocab=None,binary=False)
gensim.models.deprecated.Doc2Vec.scan_vocab(self,documents,progress_per=10000,trim_rule=None,update=False)
gensim.models.deprecated.doc2vec.Doc2Vec(self,documents=None,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,**kwargs)
gensim.models.deprecated.doc2vec.Doc2Vec.__init__(self,documents=None,dm_mean=None,dm=1,dbow_words=0,dm_concat=0,dm_tag_count=1,docvecs=None,docvecs_mapfile=None,comment=None,trim_rule=None,**kwargs)
gensim.models.deprecated.doc2vec.Doc2Vec.__str__(self)
gensim.models.deprecated.doc2vec.Doc2Vec._do_train_job(self,job,alpha,inits)
gensim.models.deprecated.doc2vec.Doc2Vec._raw_word_count(self,job)
gensim.models.deprecated.doc2vec.Doc2Vec.clear_sims(self)
gensim.models.deprecated.doc2vec.Doc2Vec.dbow(self)
gensim.models.deprecated.doc2vec.Doc2Vec.delete_temporary_training_data(self,keep_doctags_vectors=True,keep_inference=True)
gensim.models.deprecated.doc2vec.Doc2Vec.dm(self)
gensim.models.deprecated.doc2vec.Doc2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.deprecated.doc2vec.Doc2Vec.infer_vector(self,doc_words,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.models.deprecated.doc2vec.Doc2Vec.reset_from(self,other_model)
gensim.models.deprecated.doc2vec.Doc2Vec.reset_weights(self)
gensim.models.deprecated.doc2vec.Doc2Vec.save_word2vec_format(self,fname,doctag_vec=False,word_vec=True,prefix='*dt_',fvocab=None,binary=False)
gensim.models.deprecated.doc2vec.Doc2Vec.scan_vocab(self,documents,progress_per=10000,trim_rule=None,update=False)
gensim.models.deprecated.doc2vec.Doctag(namedtuple('Doctag','offset,word_count,doc_count'))
gensim.models.deprecated.doc2vec.Doctag.repeat(self,word_count)
gensim.models.deprecated.doc2vec.DocvecsArray(self,mapfile_path=None)
gensim.models.deprecated.doc2vec.DocvecsArray.__contains__(self,index)
gensim.models.deprecated.doc2vec.DocvecsArray.__getitem__(self,index)
gensim.models.deprecated.doc2vec.DocvecsArray.__init__(self,mapfile_path=None)
gensim.models.deprecated.doc2vec.DocvecsArray.__len__(self)
gensim.models.deprecated.doc2vec.DocvecsArray._int_index(self,index)
gensim.models.deprecated.doc2vec.DocvecsArray._key_index(self,i_index,missing=None)
gensim.models.deprecated.doc2vec.DocvecsArray.borrow_from(self,other_docvecs)
gensim.models.deprecated.doc2vec.DocvecsArray.clear_sims(self)
gensim.models.deprecated.doc2vec.DocvecsArray.doesnt_match(self,docs)
gensim.models.deprecated.doc2vec.DocvecsArray.estimated_lookup_memory(self)
gensim.models.deprecated.doc2vec.DocvecsArray.index_to_doctag(self,i_index)
gensim.models.deprecated.doc2vec.DocvecsArray.indexed_doctags(self,doctag_tokens)
gensim.models.deprecated.doc2vec.DocvecsArray.init_sims(self,replace=False)
gensim.models.deprecated.doc2vec.DocvecsArray.most_similar(self,positive=None,negative=None,topn=10,clip_start=0,clip_end=None,indexer=None)
gensim.models.deprecated.doc2vec.DocvecsArray.n_similarity(self,ds1,ds2)
gensim.models.deprecated.doc2vec.DocvecsArray.note_doctag(self,key,document_no,document_length)
gensim.models.deprecated.doc2vec.DocvecsArray.reset_weights(self,model)
gensim.models.deprecated.doc2vec.DocvecsArray.save(self,*args,**kwargs)
gensim.models.deprecated.doc2vec.DocvecsArray.similarity(self,d1,d2)
gensim.models.deprecated.doc2vec.DocvecsArray.similarity_unseen_docs(self,model,doc_words1,doc_words2,alpha=0.1,min_alpha=0.0001,steps=5)
gensim.models.deprecated.doc2vec.DocvecsArray.trained_item(self,indexed_tuple)
gensim.models.deprecated.doc2vec.LabeledSentence(TaggedDocument)
gensim.models.deprecated.doc2vec.TaggedBrownCorpus(self,dirname)
gensim.models.deprecated.doc2vec.TaggedBrownCorpus.__init__(self,dirname)
gensim.models.deprecated.doc2vec.TaggedBrownCorpus.__iter__(self)
gensim.models.deprecated.doc2vec.TaggedDocument(namedtuple('TaggedDocument','wordstags'))
gensim.models.deprecated.doc2vec.TaggedDocument.__str__(self)
gensim.models.deprecated.doc2vec.TaggedLineDocument(self,source)
gensim.models.deprecated.doc2vec.TaggedLineDocument.__init__(self,source)
gensim.models.deprecated.doc2vec.TaggedLineDocument.__iter__(self)
gensim.models.deprecated.doc2vec.load_old_doc2vec(*args,**kwargs)
gensim.models.deprecated.doc2vec.train_document_dbow(model,doc_words,doctag_indexes,alpha,work=None,train_words=False,learn_doctags=True,learn_words=True,learn_hidden=True,word_vectors=None,word_locks=None,doctag_vectors=None,doctag_locks=None)
gensim.models.deprecated.doc2vec.train_document_dm(model,doc_words,doctag_indexes,alpha,work=None,neu1=None,learn_doctags=True,learn_words=True,learn_hidden=True,word_vectors=None,word_locks=None,doctag_vectors=None,doctag_locks=None)
gensim.models.deprecated.doc2vec.train_document_dm_concat(model,doc_words,doctag_indexes,alpha,work=None,neu1=None,learn_doctags=True,learn_words=True,learn_hidden=True,word_vectors=None,word_locks=None,doctag_vectors=None,doctag_locks=None)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/old_saveload.py----------------------------------------
A:gensim.models.deprecated.old_saveload.logger->logging.getLogger(__name__)
A:gensim.models.deprecated.old_saveload.PAT_ALPHABETIC->re.compile('(((?![\\d])\\w)+)', re.UNICODE)
A:gensim.models.deprecated.old_saveload.RE_HTML_ENTITY->re.compile('&(#?)([xX]?)(\\w{1,8});', re.UNICODE)
A:gensim.models.deprecated.old_saveload.(compress, subname)->SaveLoad._adapt_by_suffix(fname)
A:gensim.models.deprecated.old_saveload.obj->unpickle(fname)
A:gensim.models.deprecated.old_saveload.cfname->'.'.join((fname, attrib))
A:gensim.models.deprecated.old_saveload.val->numpy.load(subname(fname, attrib), mmap_mode=mmap)
A:gensim.models.deprecated.old_saveload.sparse->unpickle(subname(fname, attrib))
A:gensim.models.deprecated.old_saveload.sparse.data->numpy.load(subname(fname, attrib, 'data'), mmap_mode=mmap)
A:gensim.models.deprecated.old_saveload.sparse.indptr->numpy.load(subname(fname, attrib, 'indptr'), mmap_mode=mmap)
A:gensim.models.deprecated.old_saveload.sparse.indices->numpy.load(subname(fname, attrib, 'indices'), mmap_mode=mmap)
A:gensim.models.deprecated.old_saveload.restores->self._save_specials(fname, separately, sep_limit, ignore, pickle_protocol, compress, subname)
A:gensim.models.deprecated.old_saveload.asides[attrib]->getattr(self, attrib)
A:gensim.models.deprecated.old_saveload.file_bytes->file_bytes.replace(b'gensim.models.wrappers.fasttext', b'gensim.models.deprecated.fasttext_wrapper').replace(b'gensim.models.wrappers.fasttext', b'gensim.models.deprecated.fasttext_wrapper')
gensim.models.deprecated.old_saveload.SaveLoad(object)
gensim.models.deprecated.old_saveload.SaveLoad._adapt_by_suffix(fname)
gensim.models.deprecated.old_saveload.SaveLoad._load_specials(self,fname,mmap,compress,subname)
gensim.models.deprecated.old_saveload.SaveLoad._save_specials(self,fname,separately,sep_limit,ignore,pickle_protocol,compress,subname)
gensim.models.deprecated.old_saveload.SaveLoad._smart_save(self,fname,separately=None,sep_limit=10*1024**2,ignore=frozenset(),pickle_protocol=2)
gensim.models.deprecated.old_saveload.SaveLoad.load(cls,fname,mmap=None)
gensim.models.deprecated.old_saveload.SaveLoad.save(self,fname_or_handle,separately=None,sep_limit=10*1024**2,ignore=frozenset(),pickle_protocol=2)
gensim.models.deprecated.old_saveload.pickle(obj,fname,protocol=2)
gensim.models.deprecated.old_saveload.unpickle(fname)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/word2vec.py----------------------------------------
A:gensim.models.deprecated.word2vec.logger->logging.getLogger(__name__)
A:gensim.models.deprecated.word2vec.old_model->gensim.models.word2vec.Word2Vec.load(*args, **kwargs)
A:gensim.models.deprecated.word2vec.new_model->NewWord2Vec(**params)
A:gensim.models.deprecated.word2vec.new_model.running_training_loss->gensim.models.word2vec.Word2Vec.load(*args, **kwargs).__dict__.get('running_training_loss', None)
A:gensim.models.deprecated.word2vec.new_model.model_trimmed_post_training->gensim.models.word2vec.Word2Vec.load(*args, **kwargs).__dict__.get('model_trimmed_post_training', None)
A:gensim.models.deprecated.word2vec.reduced_window->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter).random.randint(model.window)
A:gensim.models.deprecated.word2vec.start->max(0, pos - model.window)
A:gensim.models.deprecated.word2vec.window_pos->enumerate(word_vocabs[start:pos + model.window + 1], start)
A:gensim.models.deprecated.word2vec.l1->np_sum(self.wv.syn0[word2_indices], axis=0)
A:gensim.models.deprecated.word2vec.l1_ngrams->np_sum(context_vectors_ngrams[context_index[1:]], axis=0)
A:gensim.models.deprecated.word2vec.neu1e->zeros(l1.shape)
A:gensim.models.deprecated.word2vec.l2a->deepcopy(model.syn1[word.point])
A:gensim.models.deprecated.word2vec.prod_term->dot(l1, l2b.T)
A:gensim.models.deprecated.word2vec.fa->expit(prod_term)
A:gensim.models.deprecated.word2vec.w->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter).cum_table.searchsorted(model.random.randint(model.cum_table[-1]))
A:gensim.models.deprecated.word2vec.fb->expit(prod_term)
A:gensim.models.deprecated.word2vec.self.sg->int(sg)
A:gensim.models.deprecated.word2vec.self.vector_size->int(size)
A:gensim.models.deprecated.word2vec.self.layer1_size->int(size)
A:gensim.models.deprecated.word2vec.self.alpha->float(alpha)
A:gensim.models.deprecated.word2vec.self.min_alpha_yet_reached->float(alpha)
A:gensim.models.deprecated.word2vec.self.window->int(window)
A:gensim.models.deprecated.word2vec.self.random->numpy.random.RandomState(seed)
A:gensim.models.deprecated.word2vec.self.workers->int(workers)
A:gensim.models.deprecated.word2vec.self.min_alpha->float(min_alpha)
A:gensim.models.deprecated.word2vec.self.cbow_mean->int(cbow_mean)
A:gensim.models.deprecated.word2vec.self.wv->KeyedVectors()
A:gensim.models.deprecated.word2vec.vocab_size->len(self.wv.index2word)
A:gensim.models.deprecated.word2vec.self.cum_table->zeros(vocab_size, dtype=uint32)
A:gensim.models.deprecated.word2vec.self.cum_table[word_index]->round(cumulative / train_words_pow * domain)
A:gensim.models.deprecated.word2vec.heap->list(itervalues(self.wv.vocab))
A:gensim.models.deprecated.word2vec.(node, codes, points)->stack.pop()
A:gensim.models.deprecated.word2vec.max_depth->max(len(codes), max_depth)
A:gensim.models.deprecated.word2vec.points->array(list(points) + [node.index - len(self.wv.vocab)], dtype=uint32)
A:gensim.models.deprecated.word2vec.vocab->defaultdict(int)
A:gensim.models.deprecated.word2vec.self.wv.vocab[word]->Vocab(count=v, index=len(self.wv.index2word))
A:gensim.models.deprecated.word2vec.threshold_count->int(sample * (3 + sqrt(5)) / 2)
A:gensim.models.deprecated.word2vec.self.wv.vocab[w].sample_int->int(round(word_probability * 2 ** 32))
A:gensim.models.deprecated.word2vec.self.raw_vocab->defaultdict(int)
A:gensim.models.deprecated.word2vec.v.index->len(self.wv.vocab)
A:gensim.models.deprecated.word2vec.self.neg_labels->zeros(self.negative + 1)
A:gensim.models.deprecated.word2vec.sentences->gensim.utils.RepeatCorpusNTimes(sentences, epochs)
A:gensim.models.deprecated.word2vec.work->zeros(1, dtype=REAL)
A:gensim.models.deprecated.word2vec.neu1->gensim.matutils.zeros_aligned(self.layer1_size, dtype=REAL)
A:gensim.models.deprecated.word2vec.job->Queue(maxsize=queue_factor * self.workers).get()
A:gensim.models.deprecated.word2vec.(tally, raw_tally)->self._do_train_job(sentences, alpha, (work, neu1))
A:gensim.models.deprecated.word2vec.sentence_length->self._raw_word_count([sentence])
A:gensim.models.deprecated.word2vec.next_alpha->max(end_alpha, next_alpha)
A:gensim.models.deprecated.word2vec.job_queue->Queue(maxsize=queue_factor * self.workers)
A:gensim.models.deprecated.word2vec.progress_queue->Queue(maxsize=(queue_factor + 1) * self.workers)
A:gensim.models.deprecated.word2vec.unfinished_worker_count->len(workers)
A:gensim.models.deprecated.word2vec.report->Queue(maxsize=(queue_factor + 1) * self.workers).get()
A:gensim.models.deprecated.word2vec.score->score_sentence_cbow(self, sentence, work, neu1)
A:gensim.models.deprecated.word2vec.sentence_scores->gensim.matutils.zeros_aligned(total_sentences, dtype=REAL)
A:gensim.models.deprecated.word2vec.jobs_source->enumerate(utils.grouper(enumerate(sentences), chunksize))
A:gensim.models.deprecated.word2vec.(job_no, items)->next(jobs_source)
A:gensim.models.deprecated.word2vec.ns->Queue(maxsize=(queue_factor + 1) * self.workers).get(push_done)
A:gensim.models.deprecated.word2vec.newsyn0->empty((gained_vocab, self.vector_size), dtype=REAL)
A:gensim.models.deprecated.word2vec.newsyn0[i - len(self.wv.syn0)]->self.seeded_vector(self.wv.index2word[i] + str(self.seed))
A:gensim.models.deprecated.word2vec.self.wv.syn0->empty((len(self.wv.vocab), self.vector_size), dtype=REAL)
A:gensim.models.deprecated.word2vec.self.syn1->zeros((len(self.wv.vocab), self.layer1_size), dtype=REAL)
A:gensim.models.deprecated.word2vec.self.syn1neg->zeros((len(self.wv.vocab), self.layer1_size), dtype=REAL)
A:gensim.models.deprecated.word2vec.self.syn0_lockf->ones(len(self.wv.vocab), dtype=REAL)
A:gensim.models.deprecated.word2vec.self.wv.syn0[i]->self.seeded_vector(self.wv.index2word[i] + str(self.seed))
A:gensim.models.deprecated.word2vec.once->numpy.random.RandomState(self.hashfxn(seed_string) & 4294967295)
A:gensim.models.deprecated.word2vec.header->gensim.utils.to_unicode(fin.readline(), encoding=encoding)
A:gensim.models.deprecated.word2vec.ch->fin.read(1)
A:gensim.models.deprecated.word2vec.word->gensim.utils.to_unicode(b''.join(word), encoding=encoding, errors=unicode_errors)
A:gensim.models.deprecated.word2vec.weights->fromstring(fin.read(binary_len), dtype=REAL)
A:gensim.models.deprecated.word2vec.parts->gensim.utils.to_unicode(line.rstrip(), encoding=encoding, errors=unicode_errors).split(' ')
A:gensim.models.deprecated.word2vec.prob_values->exp(dot(l1, self.syn1neg.T))
A:gensim.models.deprecated.word2vec.top_indices->gensim.matutils.argsort(prob_values, topn=topn, reverse=True)
A:gensim.models.deprecated.word2vec.report['total']->sum(report.values())
A:gensim.models.deprecated.word2vec.kwargs['ignore']->kwargs.get('ignore', ['syn0norm', 'table', 'cum_table'])
A:gensim.models.deprecated.word2vec.model->Word2Vec(corpus, size=args.size, min_count=args.min_count, workers=args.threads, window=args.window, sample=args.sample, sg=skipgram, hs=args.hs, negative=args.negative, cbow_mean=1, iter=args.iter)
A:gensim.models.deprecated.word2vec.v.sample_int->int(round(v.sample_probability * 2 ** 32))
A:gensim.models.deprecated.word2vec.model.syn0_lockf->ones(len(model.wv.syn0), dtype=REAL)
A:gensim.models.deprecated.word2vec.model.random->numpy.random.RandomState(model.seed)
A:gensim.models.deprecated.word2vec.wv->KeyedVectors()
A:gensim.models.deprecated.word2vec.wv.syn0->self.__dict__.get('syn0', [])
A:gensim.models.deprecated.word2vec.wv.syn0norm->self.__dict__.get('syn0norm', None)
A:gensim.models.deprecated.word2vec.wv.vocab->self.__dict__.get('vocab', {})
A:gensim.models.deprecated.word2vec.wv.index2word->self.__dict__.get('index2word', [])
A:gensim.models.deprecated.word2vec.fname->os.path.join(self.dirname, fname)
A:gensim.models.deprecated.word2vec.line->gensim.utils.to_unicode(line).split()
A:gensim.models.deprecated.word2vec.words->gensim.utils.to_unicode(text).split()
A:gensim.models.deprecated.word2vec.last_token->text.rfind(b' ')
A:gensim.models.deprecated.word2vec.self.source->os.path.join(self.source, '')
A:gensim.models.deprecated.word2vec.self.input_files->os.listdir(self.source)
A:gensim.models.deprecated.word2vec.program->os.path.basename(sys.argv[0])
A:gensim.models.deprecated.word2vec.parser->argparse.ArgumentParser()
A:gensim.models.deprecated.word2vec.args->argparse.ArgumentParser().parse_args()
A:gensim.models.deprecated.word2vec.corpus->LineSentence(args.train)
gensim.models.deprecated.Word2Vec(self,sentences=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False)
gensim.models.deprecated.Word2Vec.__contains__(self,word)
gensim.models.deprecated.Word2Vec.__getitem__(self,words)
gensim.models.deprecated.Word2Vec.__str__(self)
gensim.models.deprecated.Word2Vec._do_train_job(self,sentences,alpha,inits)
gensim.models.deprecated.Word2Vec._load_specials(self,*args,**kwargs)
gensim.models.deprecated.Word2Vec._minimize_model(self,save_syn1=False,save_syn1neg=False,save_syn0_lockf=False)
gensim.models.deprecated.Word2Vec._raw_word_count(self,job)
gensim.models.deprecated.Word2Vec.accuracy(self,questions,restrict_vocab=30000,most_similar=None,case_insensitive=True)
gensim.models.deprecated.Word2Vec.build_vocab(self,sentences,keep_raw_vocab=False,trim_rule=None,progress_per=10000,update=False)
gensim.models.deprecated.Word2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.deprecated.Word2Vec.clear_sims(self)
gensim.models.deprecated.Word2Vec.create_binary_tree(self)
gensim.models.deprecated.Word2Vec.delete_temporary_training_data(self,replace_word_vectors_with_normalized=False)
gensim.models.deprecated.Word2Vec.doesnt_match(self,words)
gensim.models.deprecated.Word2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.deprecated.Word2Vec.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.deprecated.Word2Vec.finalize_vocab(self,update=False)
gensim.models.deprecated.Word2Vec.get_latest_training_loss(self)
gensim.models.deprecated.Word2Vec.init_sims(self,replace=False)
gensim.models.deprecated.Word2Vec.initialize_word_vectors(self)
gensim.models.deprecated.Word2Vec.intersect_word2vec_format(self,fname,lockf=0.0,binary=False,encoding='utf8',unicode_errors='strict')
gensim.models.deprecated.Word2Vec.load(cls,*args,**kwargs)
gensim.models.deprecated.Word2Vec.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.deprecated.Word2Vec.log_accuracy(section)
gensim.models.deprecated.Word2Vec.log_evaluate_word_pairs(pearson,spearman,oov,pairs)
gensim.models.deprecated.Word2Vec.make_cum_table(self,power=0.75,domain=2**31-1)
gensim.models.deprecated.Word2Vec.most_similar(self,positive=None,negative=None,topn=10,restrict_vocab=None,indexer=None)
gensim.models.deprecated.Word2Vec.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.deprecated.Word2Vec.n_similarity(self,ws1,ws2)
gensim.models.deprecated.Word2Vec.predict_output_word(self,context_words_list,topn=10)
gensim.models.deprecated.Word2Vec.reset_from(self,other_model)
gensim.models.deprecated.Word2Vec.reset_weights(self)
gensim.models.deprecated.Word2Vec.save(self,*args,**kwargs)
gensim.models.deprecated.Word2Vec.save_word2vec_format(self,fname,fvocab=None,binary=False)
gensim.models.deprecated.Word2Vec.scale_vocab(self,min_count=None,sample=None,dry_run=False,keep_raw_vocab=False,trim_rule=None,update=False)
gensim.models.deprecated.Word2Vec.scan_vocab(self,sentences,progress_per=10000,trim_rule=None)
gensim.models.deprecated.Word2Vec.score(self,sentences,total_sentences=int(1000000.0),chunksize=100,queue_factor=2,report_delay=1)
gensim.models.deprecated.Word2Vec.seeded_vector(self,seed_string)
gensim.models.deprecated.Word2Vec.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.deprecated.Word2Vec.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.deprecated.Word2Vec.similarity(self,w1,w2)
gensim.models.deprecated.Word2Vec.sort_vocab(self)
gensim.models.deprecated.Word2Vec.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=None)
gensim.models.deprecated.Word2Vec.update_weights(self)
gensim.models.deprecated.Word2Vec.wmdistance(self,document1,document2)
gensim.models.deprecated.word2vec.BrownCorpus(self,dirname)
gensim.models.deprecated.word2vec.BrownCorpus.__init__(self,dirname)
gensim.models.deprecated.word2vec.BrownCorpus.__iter__(self)
gensim.models.deprecated.word2vec.LineSentence(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.deprecated.word2vec.LineSentence.__init__(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.deprecated.word2vec.LineSentence.__iter__(self)
gensim.models.deprecated.word2vec.PathLineSentences(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.deprecated.word2vec.PathLineSentences.__init__(self,source,max_sentence_length=MAX_WORDS_IN_BATCH,limit=None)
gensim.models.deprecated.word2vec.PathLineSentences.__iter__(self)
gensim.models.deprecated.word2vec.Text8Corpus(self,fname,max_sentence_length=MAX_WORDS_IN_BATCH)
gensim.models.deprecated.word2vec.Text8Corpus.__init__(self,fname,max_sentence_length=MAX_WORDS_IN_BATCH)
gensim.models.deprecated.word2vec.Text8Corpus.__iter__(self)
gensim.models.deprecated.word2vec.Word2Vec(self,sentences=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False)
gensim.models.deprecated.word2vec.Word2Vec.__contains__(self,word)
gensim.models.deprecated.word2vec.Word2Vec.__getitem__(self,words)
gensim.models.deprecated.word2vec.Word2Vec.__init__(self,sentences=None,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,sample=0.001,seed=1,workers=3,min_alpha=0.0001,sg=0,hs=0,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,trim_rule=None,sorted_vocab=1,batch_words=MAX_WORDS_IN_BATCH,compute_loss=False)
gensim.models.deprecated.word2vec.Word2Vec.__str__(self)
gensim.models.deprecated.word2vec.Word2Vec._do_train_job(self,sentences,alpha,inits)
gensim.models.deprecated.word2vec.Word2Vec._load_specials(self,*args,**kwargs)
gensim.models.deprecated.word2vec.Word2Vec._minimize_model(self,save_syn1=False,save_syn1neg=False,save_syn0_lockf=False)
gensim.models.deprecated.word2vec.Word2Vec._raw_word_count(self,job)
gensim.models.deprecated.word2vec.Word2Vec.accuracy(self,questions,restrict_vocab=30000,most_similar=None,case_insensitive=True)
gensim.models.deprecated.word2vec.Word2Vec.build_vocab(self,sentences,keep_raw_vocab=False,trim_rule=None,progress_per=10000,update=False)
gensim.models.deprecated.word2vec.Word2Vec.build_vocab_from_freq(self,word_freq,keep_raw_vocab=False,corpus_count=None,trim_rule=None,update=False)
gensim.models.deprecated.word2vec.Word2Vec.clear_sims(self)
gensim.models.deprecated.word2vec.Word2Vec.create_binary_tree(self)
gensim.models.deprecated.word2vec.Word2Vec.delete_temporary_training_data(self,replace_word_vectors_with_normalized=False)
gensim.models.deprecated.word2vec.Word2Vec.doesnt_match(self,words)
gensim.models.deprecated.word2vec.Word2Vec.estimate_memory(self,vocab_size=None,report=None)
gensim.models.deprecated.word2vec.Word2Vec.evaluate_word_pairs(self,pairs,delimiter='\t',restrict_vocab=300000,case_insensitive=True,dummy4unknown=False)
gensim.models.deprecated.word2vec.Word2Vec.finalize_vocab(self,update=False)
gensim.models.deprecated.word2vec.Word2Vec.get_latest_training_loss(self)
gensim.models.deprecated.word2vec.Word2Vec.init_sims(self,replace=False)
gensim.models.deprecated.word2vec.Word2Vec.initialize_word_vectors(self)
gensim.models.deprecated.word2vec.Word2Vec.intersect_word2vec_format(self,fname,lockf=0.0,binary=False,encoding='utf8',unicode_errors='strict')
gensim.models.deprecated.word2vec.Word2Vec.load(cls,*args,**kwargs)
gensim.models.deprecated.word2vec.Word2Vec.load_word2vec_format(cls,fname,fvocab=None,binary=False,encoding='utf8',unicode_errors='strict',limit=None,datatype=REAL)
gensim.models.deprecated.word2vec.Word2Vec.log_accuracy(section)
gensim.models.deprecated.word2vec.Word2Vec.log_evaluate_word_pairs(pearson,spearman,oov,pairs)
gensim.models.deprecated.word2vec.Word2Vec.make_cum_table(self,power=0.75,domain=2**31-1)
gensim.models.deprecated.word2vec.Word2Vec.most_similar(self,positive=None,negative=None,topn=10,restrict_vocab=None,indexer=None)
gensim.models.deprecated.word2vec.Word2Vec.most_similar_cosmul(self,positive=None,negative=None,topn=10)
gensim.models.deprecated.word2vec.Word2Vec.n_similarity(self,ws1,ws2)
gensim.models.deprecated.word2vec.Word2Vec.predict_output_word(self,context_words_list,topn=10)
gensim.models.deprecated.word2vec.Word2Vec.reset_from(self,other_model)
gensim.models.deprecated.word2vec.Word2Vec.reset_weights(self)
gensim.models.deprecated.word2vec.Word2Vec.save(self,*args,**kwargs)
gensim.models.deprecated.word2vec.Word2Vec.save_word2vec_format(self,fname,fvocab=None,binary=False)
gensim.models.deprecated.word2vec.Word2Vec.scale_vocab(self,min_count=None,sample=None,dry_run=False,keep_raw_vocab=False,trim_rule=None,update=False)
gensim.models.deprecated.word2vec.Word2Vec.scan_vocab(self,sentences,progress_per=10000,trim_rule=None)
gensim.models.deprecated.word2vec.Word2Vec.score(self,sentences,total_sentences=int(1000000.0),chunksize=100,queue_factor=2,report_delay=1)
gensim.models.deprecated.word2vec.Word2Vec.seeded_vector(self,seed_string)
gensim.models.deprecated.word2vec.Word2Vec.similar_by_vector(self,vector,topn=10,restrict_vocab=None)
gensim.models.deprecated.word2vec.Word2Vec.similar_by_word(self,word,topn=10,restrict_vocab=None)
gensim.models.deprecated.word2vec.Word2Vec.similarity(self,w1,w2)
gensim.models.deprecated.word2vec.Word2Vec.sort_vocab(self)
gensim.models.deprecated.word2vec.Word2Vec.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0,compute_loss=None)
gensim.models.deprecated.word2vec.Word2Vec.update_weights(self)
gensim.models.deprecated.word2vec.Word2Vec.wmdistance(self,document1,document2)
gensim.models.deprecated.word2vec.load_old_word2vec(*args,**kwargs)
gensim.models.deprecated.word2vec.score_cbow_pair(model,word,l1)
gensim.models.deprecated.word2vec.score_sentence_cbow(model,sentence,work=None,neu1=None)
gensim.models.deprecated.word2vec.score_sentence_sg(model,sentence,work=None)
gensim.models.deprecated.word2vec.score_sg_pair(model,word,word2)
gensim.models.deprecated.word2vec.train_batch_cbow(model,sentences,alpha,work=None,neu1=None,compute_loss=False)
gensim.models.deprecated.word2vec.train_batch_sg(model,sentences,alpha,work=None,compute_loss=False)
gensim.models.deprecated.word2vec.train_cbow_pair(model,word,input_word_indices,l1,alpha,learn_vectors=True,learn_hidden=True,compute_loss=False,context_vectors=None,context_locks=None,is_ft=False)
gensim.models.deprecated.word2vec.train_sg_pair(model,word,context_index,alpha,learn_vectors=True,learn_hidden=True,context_vectors=None,context_locks=None,compute_loss=False,is_ft=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/deprecated/fasttext.py----------------------------------------
A:gensim.models.deprecated.fasttext.logger->logging.getLogger(__name__)
A:gensim.models.deprecated.fasttext.old_model->FastText.load(*args, **kwargs)
A:gensim.models.deprecated.fasttext.new_model->NewFastText(**params)
A:gensim.models.deprecated.fasttext.reduced_window->model.random.randint(model.window)
A:gensim.models.deprecated.fasttext.start->max(0, pos - model.window + reduced_window)
A:gensim.models.deprecated.fasttext.window_pos->enumerate(word_vocabs[start:pos + model.window + 1 - reduced_window], start)
A:gensim.models.deprecated.fasttext.l1_vocab->np_sum(model.wv.syn0_vocab[vocab_subwords_indices], axis=0)
A:gensim.models.deprecated.fasttext.l1_ngrams->np_sum(model.wv.syn0_ngrams[ngrams_subwords_indices], axis=0)
A:gensim.models.deprecated.fasttext.l1->np_sum([l1_vocab, l1_ngrams], axis=0)
A:gensim.models.deprecated.fasttext.self.wv->FastTextKeyedVectors()
A:gensim.models.deprecated.fasttext.self.old_vocab_len->len(self.wv.vocab)
A:gensim.models.deprecated.fasttext.self.old_hash2index_len->len(self.wv.hash2index)
A:gensim.models.deprecated.fasttext.self.wv.syn0_vocab->vstack([self.wv.syn0_vocab, new_vocab_rows])
A:gensim.models.deprecated.fasttext.self.syn0_vocab_lockf->vstack([self.syn0_vocab_lockf, new_vocab_lockf_rows])
A:gensim.models.deprecated.fasttext.self.wv.syn0_ngrams->vstack([self.wv.syn0_ngrams, new_ngram_rows])
A:gensim.models.deprecated.fasttext.self.syn0_ngrams_lockf->vstack([self.syn0_ngrams_lockf, new_ngram_lockf_rows])
A:gensim.models.deprecated.fasttext.self.wv.ngrams_word[w]->compute_ngrams(w, self.min_n, self.max_n)
A:gensim.models.deprecated.fasttext.all_ngrams->list(set(all_ngrams))
A:gensim.models.deprecated.fasttext.self.num_ngram_vectors->len(all_ngrams)
A:gensim.models.deprecated.fasttext.new_ngrams->list(set(new_ngrams))
A:gensim.models.deprecated.fasttext.new_vocab_rows->rand_obj.uniform(-1.0 / self.vector_size, 1.0 / self.vector_size, (len(self.wv.vocab) - self.old_vocab_len, self.vector_size)).astype(REAL)
A:gensim.models.deprecated.fasttext.new_vocab_lockf_rows->ones((len(self.wv.vocab) - self.old_vocab_len, self.vector_size), dtype=REAL)
A:gensim.models.deprecated.fasttext.new_ngram_rows->rand_obj.uniform(-1.0 / self.vector_size, 1.0 / self.vector_size, (len(self.wv.hash2index) - self.old_hash2index_len, self.vector_size)).astype(REAL)
A:gensim.models.deprecated.fasttext.new_ngram_lockf_rows->ones((len(self.wv.hash2index) - self.old_hash2index_len, self.vector_size), dtype=REAL)
A:gensim.models.deprecated.fasttext.self.wv.syn0_vocab[index]->rand_obj.uniform(-1.0 / self.vector_size, 1.0 / self.vector_size, self.vector_size).astype(REAL)
A:gensim.models.deprecated.fasttext.self.wv.syn0_ngrams[index]->rand_obj.uniform(-1.0 / self.vector_size, 1.0 / self.vector_size, self.vector_size).astype(REAL)
A:gensim.models.deprecated.fasttext.self.neg_labels->zeros(self.negative + 1)
A:gensim.models.deprecated.fasttext.word_vec->numpy.copy(self.wv.syn0_vocab[v.index])
A:gensim.models.deprecated.fasttext.kwargs['ignore']->kwargs.get('ignore', ['syn0norm', 'syn0_vocab_norm', 'syn0_ngrams_norm'])
gensim.models.deprecated.FastText(self,sentences=None,sg=0,hs=0,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH)
gensim.models.deprecated.FastText.__getitem__(self,word)
gensim.models.deprecated.FastText._do_train_job(self,sentences,alpha,inits)
gensim.models.deprecated.FastText.build_vocab(self,sentences,keep_raw_vocab=False,trim_rule=None,progress_per=10000,update=False)
gensim.models.deprecated.FastText.get_vocab_word_vecs(self)
gensim.models.deprecated.FastText.init_ngrams(self,update=False)
gensim.models.deprecated.FastText.initialize_word_vectors(self)
gensim.models.deprecated.FastText.load_fasttext_format(cls,*args,**kwargs)
gensim.models.deprecated.FastText.reset_ngram_weights(self)
gensim.models.deprecated.FastText.save(self,*args,**kwargs)
gensim.models.deprecated.FastText.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0)
gensim.models.deprecated.FastText.word_vec(self,word,use_norm=False)
gensim.models.deprecated.fasttext.FastText(self,sentences=None,sg=0,hs=0,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH)
gensim.models.deprecated.fasttext.FastText.__getitem__(self,word)
gensim.models.deprecated.fasttext.FastText.__init__(self,sentences=None,sg=0,hs=0,size=100,alpha=0.025,window=5,min_count=5,max_vocab_size=None,word_ngrams=1,sample=0.001,seed=1,workers=3,min_alpha=0.0001,negative=5,cbow_mean=1,hashfxn=hash,iter=5,null_word=0,min_n=3,max_n=6,sorted_vocab=1,bucket=2000000,trim_rule=None,batch_words=MAX_WORDS_IN_BATCH)
gensim.models.deprecated.fasttext.FastText._do_train_job(self,sentences,alpha,inits)
gensim.models.deprecated.fasttext.FastText.build_vocab(self,sentences,keep_raw_vocab=False,trim_rule=None,progress_per=10000,update=False)
gensim.models.deprecated.fasttext.FastText.get_vocab_word_vecs(self)
gensim.models.deprecated.fasttext.FastText.init_ngrams(self,update=False)
gensim.models.deprecated.fasttext.FastText.initialize_word_vectors(self)
gensim.models.deprecated.fasttext.FastText.load_fasttext_format(cls,*args,**kwargs)
gensim.models.deprecated.fasttext.FastText.reset_ngram_weights(self)
gensim.models.deprecated.fasttext.FastText.save(self,*args,**kwargs)
gensim.models.deprecated.fasttext.FastText.train(self,sentences,total_examples=None,total_words=None,epochs=None,start_alpha=None,end_alpha=None,word_count=0,queue_factor=2,report_delay=1.0)
gensim.models.deprecated.fasttext.FastText.word_vec(self,word,use_norm=False)
gensim.models.deprecated.fasttext.load_old_fasttext(*args,**kwargs)
gensim.models.deprecated.fasttext.train_batch_cbow(model,sentences,alpha,work=None,neu1=None)
gensim.models.deprecated.fasttext.train_batch_sg(model,sentences,alpha,work=None,neu1=None)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/dtmmodel.py----------------------------------------
A:gensim.models.wrappers.dtmmodel.logger->logging.getLogger(__name__)
A:gensim.models.wrappers.dtmmodel.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.wrappers.dtmmodel.self.num_terms->len(self.id2word)
A:gensim.models.wrappers.dtmmodel.lencorpus->sum((1 for _ in corpus))
A:gensim.models.wrappers.dtmmodel.prefix->os.path.join(tempfile.gettempdir(), rand_prefix)
A:gensim.models.wrappers.dtmmodel.self.lda_sequence_min_iter->int(lda_sequence_min_iter)
A:gensim.models.wrappers.dtmmodel.self.lda_sequence_max_iter->int(lda_sequence_max_iter)
A:gensim.models.wrappers.dtmmodel.self.lda_max_em_iter->int(lda_max_em_iter)
A:gensim.models.wrappers.dtmmodel.self.initialize_lda->str(initialize_lda).lower()
A:gensim.models.wrappers.dtmmodel.arguments->'--ntopics={p0} --model={mofrl}  --mode={p1} --initialize_lda={p2} --corpus_prefix={p3} --outname={p4} --alpha={p5}'.format(p0=self.num_topics, mofrl=model, p1=mode, p2=self.initialize_lda, p3=self.fcorpus(), p4=self.foutname(), p5=self.alpha)
A:gensim.models.wrappers.dtmmodel.params->'--lda_max_em_iter={p0} --lda_sequence_min_iter={p1}  --lda_sequence_max_iter={p2} --top_chain_var={p3} --rng_seed={p4} '.format(p0=self.lda_max_em_iter, p1=self.lda_sequence_min_iter, p2=self.lda_sequence_max_iter, p3=self.top_chain_var, p4=self.rng_seed)
A:gensim.models.wrappers.dtmmodel.self.em_steps->numpy.loadtxt(self.fem_steps())
A:gensim.models.wrappers.dtmmodel.self.init_ss->numpy.loadtxt(self.flda_ss())
A:gensim.models.wrappers.dtmmodel.self.init_alpha->numpy.loadtxt(self.finit_alpha())
A:gensim.models.wrappers.dtmmodel.self.init_beta->numpy.loadtxt(self.finit_beta())
A:gensim.models.wrappers.dtmmodel.self.lhood_->numpy.loadtxt(self.fout_liklihoods())
A:gensim.models.wrappers.dtmmodel.self.gamma_->numpy.loadtxt(self.fout_gamma())
A:gensim.models.wrappers.dtmmodel.self.lambda_->numpy.zeros((self.num_topics, self.num_terms * len(self.time_slices)))
A:gensim.models.wrappers.dtmmodel.self.obs_->numpy.zeros((self.num_topics, self.num_terms * len(self.time_slices)))
A:gensim.models.wrappers.dtmmodel.self.lambda_[t, :]->numpy.loadtxt(self.fout_prob().format(i=topic))
A:gensim.models.wrappers.dtmmodel.self.obs_[t, :]->numpy.loadtxt(self.fout_observations().format(i=topic))
A:gensim.models.wrappers.dtmmodel.influence->numpy.loadtxt(self.fout_influence().format(i=stamp))
A:gensim.models.wrappers.dtmmodel.chosen_topics->range(num_topics)
A:gensim.models.wrappers.dtmmodel.num_topics->min(num_topics, self.num_topics)
A:gensim.models.wrappers.dtmmodel.times->min(times, len(self.time_slices))
A:gensim.models.wrappers.dtmmodel.chosen_times->range(times)
A:gensim.models.wrappers.dtmmodel.topic->self.show_topic(topicid=topic_no, time=time, num_words=num_words)
A:gensim.models.wrappers.dtmmodel.bestn->gensim.matutils.argsort(topic, topn, reverse=True)
A:gensim.models.wrappers.dtmmodel.term_frequency->numpy.zeros(len(self.id2word))
gensim.models.wrappers.DtmModel(self,dtm_path,corpus=None,time_slices=None,mode='fit',model='dtm',num_topics=100,id2word=None,prefix=None,lda_sequence_min_iter=6,lda_sequence_max_iter=20,lda_max_em_iter=10,alpha=0.01,top_chain_var=0.005,rng_seed=0,initialize_lda=True)
gensim.models.wrappers.DtmModel.convert_input(self,corpus,time_slices)
gensim.models.wrappers.DtmModel.dtm_coherence(self,time,num_words=20)
gensim.models.wrappers.DtmModel.dtm_vis(self,corpus,time)
gensim.models.wrappers.DtmModel.fcorpus(self)
gensim.models.wrappers.DtmModel.fcorpustxt(self)
gensim.models.wrappers.DtmModel.fem_steps(self)
gensim.models.wrappers.DtmModel.finit_alpha(self)
gensim.models.wrappers.DtmModel.finit_beta(self)
gensim.models.wrappers.DtmModel.flda_ss(self)
gensim.models.wrappers.DtmModel.fout_gamma(self)
gensim.models.wrappers.DtmModel.fout_influence(self)
gensim.models.wrappers.DtmModel.fout_liklihoods(self)
gensim.models.wrappers.DtmModel.fout_observations(self)
gensim.models.wrappers.DtmModel.fout_prob(self)
gensim.models.wrappers.DtmModel.foutname(self)
gensim.models.wrappers.DtmModel.ftimeslices(self)
gensim.models.wrappers.DtmModel.print_topic(self,topicid,time,topn=10,num_words=None)
gensim.models.wrappers.DtmModel.print_topics(self,num_topics=10,times=5,num_words=10)
gensim.models.wrappers.DtmModel.show_topic(self,topicid,time,topn=50,num_words=None)
gensim.models.wrappers.DtmModel.show_topics(self,num_topics=10,times=5,num_words=10,log=False,formatted=True)
gensim.models.wrappers.DtmModel.train(self,corpus,time_slices,mode,model)
gensim.models.wrappers.dtmmodel.DtmModel(self,dtm_path,corpus=None,time_slices=None,mode='fit',model='dtm',num_topics=100,id2word=None,prefix=None,lda_sequence_min_iter=6,lda_sequence_max_iter=20,lda_max_em_iter=10,alpha=0.01,top_chain_var=0.005,rng_seed=0,initialize_lda=True)
gensim.models.wrappers.dtmmodel.DtmModel.__init__(self,dtm_path,corpus=None,time_slices=None,mode='fit',model='dtm',num_topics=100,id2word=None,prefix=None,lda_sequence_min_iter=6,lda_sequence_max_iter=20,lda_max_em_iter=10,alpha=0.01,top_chain_var=0.005,rng_seed=0,initialize_lda=True)
gensim.models.wrappers.dtmmodel.DtmModel.convert_input(self,corpus,time_slices)
gensim.models.wrappers.dtmmodel.DtmModel.dtm_coherence(self,time,num_words=20)
gensim.models.wrappers.dtmmodel.DtmModel.dtm_vis(self,corpus,time)
gensim.models.wrappers.dtmmodel.DtmModel.fcorpus(self)
gensim.models.wrappers.dtmmodel.DtmModel.fcorpustxt(self)
gensim.models.wrappers.dtmmodel.DtmModel.fem_steps(self)
gensim.models.wrappers.dtmmodel.DtmModel.finit_alpha(self)
gensim.models.wrappers.dtmmodel.DtmModel.finit_beta(self)
gensim.models.wrappers.dtmmodel.DtmModel.flda_ss(self)
gensim.models.wrappers.dtmmodel.DtmModel.fout_gamma(self)
gensim.models.wrappers.dtmmodel.DtmModel.fout_influence(self)
gensim.models.wrappers.dtmmodel.DtmModel.fout_liklihoods(self)
gensim.models.wrappers.dtmmodel.DtmModel.fout_observations(self)
gensim.models.wrappers.dtmmodel.DtmModel.fout_prob(self)
gensim.models.wrappers.dtmmodel.DtmModel.foutname(self)
gensim.models.wrappers.dtmmodel.DtmModel.ftimeslices(self)
gensim.models.wrappers.dtmmodel.DtmModel.print_topic(self,topicid,time,topn=10,num_words=None)
gensim.models.wrappers.dtmmodel.DtmModel.print_topics(self,num_topics=10,times=5,num_words=10)
gensim.models.wrappers.dtmmodel.DtmModel.show_topic(self,topicid,time,topn=50,num_words=None)
gensim.models.wrappers.dtmmodel.DtmModel.show_topics(self,num_topics=10,times=5,num_words=10,log=False,formatted=True)
gensim.models.wrappers.dtmmodel.DtmModel.train(self,corpus,time_slices,mode,model)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/ldamallet.py----------------------------------------
A:gensim.models.wrappers.ldamallet.logger->logging.getLogger(__name__)
A:gensim.models.wrappers.ldamallet.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.wrappers.ldamallet.self.num_terms->len(self.id2word)
A:gensim.models.wrappers.ldamallet.prefix->os.path.join(tempfile.gettempdir(), rand_prefix)
A:gensim.models.wrappers.ldamallet.tokens->sum(([str(tokenid)] * int(cnt) for (tokenid, cnt) in doc), [])
A:gensim.models.wrappers.ldamallet.self.word_topics->self.load_word_topics()
A:gensim.models.wrappers.ldamallet.(is_corpus, corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.wrappers.ldamallet.result->list(self.read_doctopics(self.fdoctopics() + '.infer'))
A:gensim.models.wrappers.ldamallet.word_topics->numpy.zeros((self.num_topics, self.num_terms), dtype=numpy.float64)
A:gensim.models.wrappers.ldamallet.word2id->revdict(self.id2word)
A:gensim.models.wrappers.ldamallet._->next(fin)
A:gensim.models.wrappers.ldamallet.self.alpha->numpy.array([float(val) for val in next(fin).split()[2:]])
A:gensim.models.wrappers.ldamallet.line->gensim.utils.to_unicode(line)
A:gensim.models.wrappers.ldamallet.(doc, source, pos, typeindex, token, topic)->gensim.utils.to_unicode(line).split(' ')
A:gensim.models.wrappers.ldamallet.chosen_topics->range(num_topics)
A:gensim.models.wrappers.ldamallet.num_topics->min(num_topics, self.num_topics)
A:gensim.models.wrappers.ldamallet.sorted_topics->list(matutils.argsort(sort_alpha))
A:gensim.models.wrappers.ldamallet.topic->self.show_topic(i, topn=num_words)
A:gensim.models.wrappers.ldamallet.bestn->gensim.matutils.argsort(topic, topn, reverse=True)
A:gensim.models.wrappers.ldamallet.archive->zipfile.ZipFile(direc_path, 'r')
A:gensim.models.wrappers.ldamallet.doc->xml.etree.ElementTree.parse(xml_path + 'pom.xml').getroot()
A:gensim.models.wrappers.ldamallet.mallet_version->self.get_version(self.mallet_path)
A:gensim.models.wrappers.ldamallet.total_weight->float(sum([weight for (_, weight) in doc]))
A:gensim.models.wrappers.ldamallet.model_gensim->LdaModel(id2word=mallet_model.id2word, num_topics=mallet_model.num_topics, alpha=mallet_model.alpha, iterations=iterations, gamma_threshold=gamma_threshold, dtype=numpy.float64)
gensim.models.wrappers.LdaMallet(self,mallet_path,corpus=None,num_topics=100,alpha=50,id2word=None,workers=4,prefix=None,optimize_interval=0,iterations=1000,topic_threshold=0.0)
gensim.models.wrappers.LdaMallet.__getitem__(self,bow,iterations=100)
gensim.models.wrappers.LdaMallet.convert_input(self,corpus,infer=False,serialize_corpus=True)
gensim.models.wrappers.LdaMallet.corpus2mallet(self,corpus,file_like)
gensim.models.wrappers.LdaMallet.fcorpusmallet(self)
gensim.models.wrappers.LdaMallet.fcorpustxt(self)
gensim.models.wrappers.LdaMallet.fdoctopics(self)
gensim.models.wrappers.LdaMallet.finferencer(self)
gensim.models.wrappers.LdaMallet.fstate(self)
gensim.models.wrappers.LdaMallet.ftopickeys(self)
gensim.models.wrappers.LdaMallet.fwordweights(self)
gensim.models.wrappers.LdaMallet.get_topics(self)
gensim.models.wrappers.LdaMallet.get_version(self,direc_path)
gensim.models.wrappers.LdaMallet.load_document_topics(self)
gensim.models.wrappers.LdaMallet.load_word_topics(self)
gensim.models.wrappers.LdaMallet.read_doctopics(self,fname,eps=1e-06,renorm=True)
gensim.models.wrappers.LdaMallet.show_topic(self,topicid,topn=10,num_words=None)
gensim.models.wrappers.LdaMallet.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.wrappers.LdaMallet.train(self,corpus)
gensim.models.wrappers.ldamallet.LdaMallet(self,mallet_path,corpus=None,num_topics=100,alpha=50,id2word=None,workers=4,prefix=None,optimize_interval=0,iterations=1000,topic_threshold=0.0)
gensim.models.wrappers.ldamallet.LdaMallet.__getitem__(self,bow,iterations=100)
gensim.models.wrappers.ldamallet.LdaMallet.__init__(self,mallet_path,corpus=None,num_topics=100,alpha=50,id2word=None,workers=4,prefix=None,optimize_interval=0,iterations=1000,topic_threshold=0.0)
gensim.models.wrappers.ldamallet.LdaMallet.convert_input(self,corpus,infer=False,serialize_corpus=True)
gensim.models.wrappers.ldamallet.LdaMallet.corpus2mallet(self,corpus,file_like)
gensim.models.wrappers.ldamallet.LdaMallet.fcorpusmallet(self)
gensim.models.wrappers.ldamallet.LdaMallet.fcorpustxt(self)
gensim.models.wrappers.ldamallet.LdaMallet.fdoctopics(self)
gensim.models.wrappers.ldamallet.LdaMallet.finferencer(self)
gensim.models.wrappers.ldamallet.LdaMallet.fstate(self)
gensim.models.wrappers.ldamallet.LdaMallet.ftopickeys(self)
gensim.models.wrappers.ldamallet.LdaMallet.fwordweights(self)
gensim.models.wrappers.ldamallet.LdaMallet.get_topics(self)
gensim.models.wrappers.ldamallet.LdaMallet.get_version(self,direc_path)
gensim.models.wrappers.ldamallet.LdaMallet.load_document_topics(self)
gensim.models.wrappers.ldamallet.LdaMallet.load_word_topics(self)
gensim.models.wrappers.ldamallet.LdaMallet.read_doctopics(self,fname,eps=1e-06,renorm=True)
gensim.models.wrappers.ldamallet.LdaMallet.show_topic(self,topicid,topn=10,num_words=None)
gensim.models.wrappers.ldamallet.LdaMallet.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.wrappers.ldamallet.LdaMallet.train(self,corpus)
gensim.models.wrappers.ldamallet.malletmodel2ldamodel(mallet_model,gamma_threshold=0.001,iterations=50)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/wordrank.py----------------------------------------
A:gensim.models.wrappers.wordrank.logger->logging.getLogger(__name__)
A:gensim.models.wrappers.wordrank.model_dir->os.path.join(wr_path, out_name)
A:gensim.models.wrappers.wordrank.meta_dir->os.path.join(model_dir, 'meta')
A:gensim.models.wrappers.wordrank.vocab_file->os.path.join(meta_dir, 'vocab.txt')
A:gensim.models.wrappers.wordrank.temp_vocab_file->os.path.join(meta_dir, 'tempvocab.txt')
A:gensim.models.wrappers.wordrank.cooccurrence_file->os.path.join(meta_dir, 'cooccurrence')
A:gensim.models.wrappers.wordrank.cooccurrence_shuf_file->os.path.join(meta_dir, 'wiki.toy')
A:gensim.models.wrappers.wordrank.meta_file->os.path.join(meta_dir, 'meta')
A:gensim.models.wrappers.wordrank.numwords->sum((1 for _ in f))
A:gensim.models.wrappers.wordrank.numlines->sum((1 for _ in f))
A:gensim.models.wrappers.wordrank.meta_info->'{0} {1}\n{2} {3}\n{4} {5}'.format(numwords, numwords, numlines, cooccurrence_shuf_file.split('/')[-1], numwords, vocab_file.split('/')[-1])
A:gensim.models.wrappers.wordrank.model->cls.load_word2vec_format('%s.w2vformat' % model_file)
A:gensim.models.wrappers.wordrank.vocab_size->len(self.vocab)
A:gensim.models.wrappers.wordrank.prev_syn0->copy.deepcopy(self.syn0)
A:gensim.models.wrappers.wordrank.prev_vocab->copy.deepcopy(self.vocab)
A:gensim.models.wrappers.wordrank.counts[word]->int(count)
A:gensim.models.wrappers.wordrank.w_emb->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('%s.w2vformat' % word_embedding)
A:gensim.models.wrappers.wordrank.c_emb->gensim.models.keyedvectors.KeyedVectors.load_word2vec_format('%s.w2vformat' % context_embedding)
A:gensim.models.wrappers.wordrank.prev_c_emb->copy.deepcopy(c_emb.syn0)
gensim.models.wrappers.Wordrank(KeyedVectors)
gensim.models.wrappers.Wordrank.ensemble_embedding(self,word_embedding,context_embedding)
gensim.models.wrappers.Wordrank.load_wordrank_model(cls,model_file,vocab_file=None,context_file=None,sorted_vocab=1,ensemble=1)
gensim.models.wrappers.Wordrank.sort_embeddings(self,vocab_file)
gensim.models.wrappers.Wordrank.train(cls,wr_path,corpus_file,out_name,size=100,window=15,symmetric=1,min_count=5,max_vocab_size=0,sgd_num=100,lrate=0.001,period=10,iter=90,epsilon=0.75,dump_period=10,reg=0,alpha=100,beta=99,loss='hinge',memory=4.0,np=1,cleanup_files=False,sorted_vocab=1,ensemble=0)
gensim.models.wrappers.wordrank.Wordrank(KeyedVectors)
gensim.models.wrappers.wordrank.Wordrank.ensemble_embedding(self,word_embedding,context_embedding)
gensim.models.wrappers.wordrank.Wordrank.load_wordrank_model(cls,model_file,vocab_file=None,context_file=None,sorted_vocab=1,ensemble=1)
gensim.models.wrappers.wordrank.Wordrank.sort_embeddings(self,vocab_file)
gensim.models.wrappers.wordrank.Wordrank.train(cls,wr_path,corpus_file,out_name,size=100,window=15,symmetric=1,min_count=5,max_vocab_size=0,sgd_num=100,lrate=0.001,period=10,iter=90,epsilon=0.75,dump_period=10,reg=0,alpha=100,beta=99,loss='hinge',memory=4.0,np=1,cleanup_files=False,sorted_vocab=1,ensemble=0)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/varembed.py----------------------------------------
A:gensim.models.wrappers.varembed.logger->logging.getLogger(__name__)
A:gensim.models.wrappers.varembed.result->cls()
A:gensim.models.wrappers.varembed.d->gensim.utils.unpickle(vectors)
A:gensim.models.wrappers.varembed.morfessor_model->morfessor.MorfessorIO().read_binary_model_file(morfessor_model)
A:gensim.models.wrappers.varembed.self.vocab_size->len(counts)
A:gensim.models.wrappers.varembed.self.syn0->numpy.zeros((self.vocab_size, self.vector_size))
A:gensim.models.wrappers.varembed.self.vocab[word]->Vocab(index=word_id, count=counts[word])
A:gensim.models.wrappers.varembed.morpheme_embedding->numpy.array([morpho_embeddings[morpho_to_ix.get(m, -1)] for m in morfessor_model.viterbi_segment(word)[0]]).sum(axis=0)
gensim.models.wrappers.VarEmbed(self)
gensim.models.wrappers.VarEmbed.add_morphemes_to_embeddings(self,morfessor_model,morpho_embeddings,morpho_to_ix)
gensim.models.wrappers.VarEmbed.load_varembed_format(cls,vectors,morfessor_model=None)
gensim.models.wrappers.VarEmbed.load_word_embeddings(self,word_embeddings,word_to_ix)
gensim.models.wrappers.varembed.VarEmbed(self)
gensim.models.wrappers.varembed.VarEmbed.__init__(self)
gensim.models.wrappers.varembed.VarEmbed.add_morphemes_to_embeddings(self,morfessor_model,morpho_embeddings,morpho_to_ix)
gensim.models.wrappers.varembed.VarEmbed.load_varembed_format(cls,vectors,morfessor_model=None)
gensim.models.wrappers.varembed.VarEmbed.load_word_embeddings(self,word_embeddings,word_to_ix)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/ldavowpalwabbit.py----------------------------------------
A:gensim.models.wrappers.ldavowpalwabbit.logger->logging.getLogger(__name__)
A:gensim.models.wrappers.ldavowpalwabbit.self.id2word->gensim.utils.dict_from_corpus(corpus)
A:gensim.models.wrappers.ldavowpalwabbit.self.num_terms->len(self.id2word)
A:gensim.models.wrappers.ldavowpalwabbit.corpus_size->write_corpus_as_vw(chunk, self._corpus_filename)
A:gensim.models.wrappers.ldavowpalwabbit.cmd->self._get_vw_predict_command(corpus_size)
A:gensim.models.wrappers.ldavowpalwabbit.corpus_words->sum((cnt for document in chunk for (_, cnt) in document))
A:gensim.models.wrappers.ldavowpalwabbit.topics->numpy.zeros((self.num_topics, self.num_terms), dtype=numpy.float32)
A:gensim.models.wrappers.ldavowpalwabbit.num_topics->min(num_topics, self.num_topics)
A:gensim.models.wrappers.ldavowpalwabbit.chosen_topics->range(num_topics)
A:gensim.models.wrappers.ldavowpalwabbit.topic->self.show_topic(i, topn=num_words)
A:gensim.models.wrappers.ldavowpalwabbit.bestn->gensim.matutils.argsort(topic, topn, reverse=True)
A:gensim.models.wrappers.ldavowpalwabbit.self._model_data->fhandle.read()
A:gensim.models.wrappers.ldavowpalwabbit.self._topics_data->fhandle.read()
A:gensim.models.wrappers.ldavowpalwabbit.kwargs['ignore']->frozenset(['_topics', 'tmp_dir'])
A:gensim.models.wrappers.ldavowpalwabbit.lda_vw->super(LdaVowpalWabbit, cls).load(fname, *args, **kwargs)
A:gensim.models.wrappers.ldavowpalwabbit.self.tmp_dir->tempfile.mkdtemp(prefix=prefix)
A:gensim.models.wrappers.ldavowpalwabbit.fields->line.split()
A:gensim.models.wrappers.ldavowpalwabbit.word_id->int(fields[0])
A:gensim.models.wrappers.ldavowpalwabbit.vw_data->_parse_vw_output(_run_vw_command(cmd))
A:gensim.models.wrappers.ldavowpalwabbit.predictions->numpy.zeros((corpus_size, self.num_topics), dtype=numpy.float32)
A:gensim.models.wrappers.ldavowpalwabbit.predictions[i, :]->line.split()
A:gensim.models.wrappers.ldavowpalwabbit.(is_corpus, dummy_corpus)->gensim.utils.is_corpus(bow)
A:gensim.models.wrappers.ldavowpalwabbit.data['average_loss']->float(line.split('=')[1])
A:gensim.models.wrappers.ldavowpalwabbit.proc->subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT)
A:gensim.models.wrappers.ldavowpalwabbit.output->subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT).communicate()[0].decode('utf-8')
A:gensim.models.wrappers.ldavowpalwabbit.model_gensim->LdaModel(num_topics=vw_model.num_topics, id2word=vw_model.id2word, chunksize=vw_model.chunksize, passes=vw_model.passes, alpha=vw_model.alpha, eta=vw_model.eta, decay=vw_model.decay, offset=vw_model.offset, iterations=iterations, gamma_threshold=vw_model.gamma_threshold, dtype=numpy.float32)
A:gensim.models.wrappers.ldavowpalwabbit.model_gensim.expElogbeta[:]->vw_model._get_topics()
gensim.models.wrappers.LdaVowpalWabbit(self,vw_path,corpus=None,num_topics=100,id2word=None,chunksize=256,passes=1,alpha=0.1,eta=0.1,decay=0.5,offset=1,gamma_threshold=0.001,random_seed=None,cleanup_files=True,tmp_prefix='tmp')
gensim.models.wrappers.LdaVowpalWabbit.__del__(self)
gensim.models.wrappers.LdaVowpalWabbit.__getitem__(self,bow,eps=0.01)
gensim.models.wrappers.LdaVowpalWabbit.__str__(self)
gensim.models.wrappers.LdaVowpalWabbit._cache_filename(self)
gensim.models.wrappers.LdaVowpalWabbit._corpus_filename(self)
gensim.models.wrappers.LdaVowpalWabbit._get_filename(self,name)
gensim.models.wrappers.LdaVowpalWabbit._get_topics(self)
gensim.models.wrappers.LdaVowpalWabbit._get_vw_predict_command(self,corpus_size)
gensim.models.wrappers.LdaVowpalWabbit._get_vw_train_command(self,corpus_size,update=False)
gensim.models.wrappers.LdaVowpalWabbit._get_vw_update_command(self,corpus_size)
gensim.models.wrappers.LdaVowpalWabbit._init_temp_dir(self,prefix='tmp')
gensim.models.wrappers.LdaVowpalWabbit._load_vw_topics(self)
gensim.models.wrappers.LdaVowpalWabbit._model_filename(self)
gensim.models.wrappers.LdaVowpalWabbit._predict(self,chunk)
gensim.models.wrappers.LdaVowpalWabbit._predict_filename(self)
gensim.models.wrappers.LdaVowpalWabbit._topics_filename(self)
gensim.models.wrappers.LdaVowpalWabbit.get_topics(self)
gensim.models.wrappers.LdaVowpalWabbit.load(cls,fname,*args,**kwargs)
gensim.models.wrappers.LdaVowpalWabbit.log_perplexity(self,chunk)
gensim.models.wrappers.LdaVowpalWabbit.print_topic(self,topicid,topn=10)
gensim.models.wrappers.LdaVowpalWabbit.print_topics(self,num_topics=10,num_words=10)
gensim.models.wrappers.LdaVowpalWabbit.save(self,fname,*args,**kwargs)
gensim.models.wrappers.LdaVowpalWabbit.show_topic(self,topicid,topn=10)
gensim.models.wrappers.LdaVowpalWabbit.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.wrappers.LdaVowpalWabbit.train(self,corpus)
gensim.models.wrappers.LdaVowpalWabbit.update(self,corpus)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit(self,vw_path,corpus=None,num_topics=100,id2word=None,chunksize=256,passes=1,alpha=0.1,eta=0.1,decay=0.5,offset=1,gamma_threshold=0.001,random_seed=None,cleanup_files=True,tmp_prefix='tmp')
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.__del__(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.__getitem__(self,bow,eps=0.01)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.__init__(self,vw_path,corpus=None,num_topics=100,id2word=None,chunksize=256,passes=1,alpha=0.1,eta=0.1,decay=0.5,offset=1,gamma_threshold=0.001,random_seed=None,cleanup_files=True,tmp_prefix='tmp')
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.__str__(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._cache_filename(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._corpus_filename(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._get_filename(self,name)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._get_topics(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._get_vw_predict_command(self,corpus_size)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._get_vw_train_command(self,corpus_size,update=False)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._get_vw_update_command(self,corpus_size)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._init_temp_dir(self,prefix='tmp')
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._load_vw_topics(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._model_filename(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._predict(self,chunk)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._predict_filename(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit._topics_filename(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.get_topics(self)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.load(cls,fname,*args,**kwargs)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.log_perplexity(self,chunk)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.print_topic(self,topicid,topn=10)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.print_topics(self,num_topics=10,num_words=10)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.save(self,fname,*args,**kwargs)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.show_topic(self,topicid,topn=10)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.show_topics(self,num_topics=10,num_words=10,log=False,formatted=True)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.train(self,corpus)
gensim.models.wrappers.ldavowpalwabbit.LdaVowpalWabbit.update(self,corpus)
gensim.models.wrappers.ldavowpalwabbit._bit_length(num)
gensim.models.wrappers.ldavowpalwabbit._parse_vw_output(text)
gensim.models.wrappers.ldavowpalwabbit._run_vw_command(cmd)
gensim.models.wrappers.ldavowpalwabbit.corpus_to_vw(corpus)
gensim.models.wrappers.ldavowpalwabbit.vwmodel2ldamodel(vw_model,iterations=50)
gensim.models.wrappers.ldavowpalwabbit.write_corpus_as_vw(corpus,filename)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/models/wrappers/fasttext.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/indirect_confirmation_measure.py----------------------------------------
A:gensim.topic_coherence.indirect_confirmation_measure.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.indirect_confirmation_measure.context_vectors->ContextVectorComputer(measure, topics, accumulator, gamma)
A:gensim.topic_coherence.indirect_confirmation_measure.topic_words->tuple(topic_words)
A:gensim.topic_coherence.indirect_confirmation_measure.segment_sims->numpy.zeros(len(topic_segments))
A:gensim.topic_coherence.indirect_confirmation_measure.segment_sims[i]->_cossim(w_prime_cv, w_star_cv)
A:gensim.topic_coherence.indirect_confirmation_measure.self.mapping->_map_to_contiguous(topics)
A:gensim.topic_coherence.indirect_confirmation_measure.self.vocab_size->len(self.mapping)
A:gensim.topic_coherence.indirect_confirmation_measure.key->_key_for_segment(segment_word_ids, topic_word_ids)
A:gensim.topic_coherence.indirect_confirmation_measure.context_vector->scipy.sparse.lil_matrix((self.vocab_size, 1))
A:gensim.topic_coherence.indirect_confirmation_measure.self.sim_cache[pair]->self.similarity(pair, self.accumulator)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer(self,measure,topics,accumulator,gamma)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer.__getitem__(self,idx)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer.__init__(self,measure,topics,accumulator,gamma)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer._make_seg(self,segment_word_ids,topic_word_ids)
gensim.topic_coherence.indirect_confirmation_measure.ContextVectorComputer.compute_context_vector(self,segment_word_ids,topic_word_ids)
gensim.topic_coherence.indirect_confirmation_measure._cossim(cv1,cv2)
gensim.topic_coherence.indirect_confirmation_measure._key_for_segment(segment,topic_words)
gensim.topic_coherence.indirect_confirmation_measure._magnitude(sparse_vec)
gensim.topic_coherence.indirect_confirmation_measure._map_to_contiguous(ids_iterable)
gensim.topic_coherence.indirect_confirmation_measure._pair_npmi(pair,accumulator)
gensim.topic_coherence.indirect_confirmation_measure.cosine_similarity(segmented_topics,accumulator,topics,measure='nlr',gamma=1,with_std=False,with_support=False)
gensim.topic_coherence.indirect_confirmation_measure.word2vec_similarity(segmented_topics,accumulator,with_std=False,with_support=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/probability_estimation.py----------------------------------------
A:gensim.topic_coherence.probability_estimation.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.probability_estimation.top_ids->unique_ids_from_segments(segmented_topics)
A:gensim.topic_coherence.probability_estimation.accumulator->WordVectorsAccumulator(top_ids, dictionary, model, window=window_size, workers=processes)
A:gensim.topic_coherence.probability_estimation.unique_ids->set()
gensim.topic_coherence.probability_estimation.p_boolean_document(corpus,segmented_topics)
gensim.topic_coherence.probability_estimation.p_boolean_sliding_window(texts,segmented_topics,dictionary,window_size,processes=1)
gensim.topic_coherence.probability_estimation.p_word2vec(texts,segmented_topics,dictionary,window_size=None,processes=1,model=None)
gensim.topic_coherence.probability_estimation.unique_ids_from_segments(segmented_topics)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/segmentation.py----------------------------------------
A:gensim.topic_coherence.segmentation.logger->logging.getLogger(__name__)
gensim.topic_coherence.segmentation.s_one_one(topics)
gensim.topic_coherence.segmentation.s_one_pre(topics)
gensim.topic_coherence.segmentation.s_one_set(topics)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/aggregation.py----------------------------------------
A:gensim.topic_coherence.aggregation.logger->logging.getLogger(__name__)
gensim.topic_coherence.aggregation.arithmetic_mean(confirmed_measures)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/direct_confirmation_measure.py----------------------------------------
A:gensim.topic_coherence.direct_confirmation_measure.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.direct_confirmation_measure.num_docs->float(accumulator.num_docs)
A:gensim.topic_coherence.direct_confirmation_measure.m_lc_i->numpy.log((co_occur_count / num_docs + EPSILON) / (w_star_count / num_docs))
A:gensim.topic_coherence.direct_confirmation_measure.mean->numpy.mean(segment_sims)
A:gensim.topic_coherence.direct_confirmation_measure.m_lr_i->numpy.log(numerator / denominator)
gensim.topic_coherence.direct_confirmation_measure.aggregate_segment_sims(segment_sims,with_std,with_support)
gensim.topic_coherence.direct_confirmation_measure.log_conditional_probability(segmented_topics,accumulator,with_std=False,with_support=False)
gensim.topic_coherence.direct_confirmation_measure.log_ratio_measure(segmented_topics,accumulator,normalize=False,with_std=False,with_support=False)


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/gensim/gensim3.4.0/topic_coherence/text_analysis.py----------------------------------------
A:gensim.topic_coherence.text_analysis.logger->logging.getLogger(__name__)
A:gensim.topic_coherence.text_analysis.top_words->top_words.union(word).union(word)
A:gensim.topic_coherence.text_analysis.self._vocab_size->len(self.relevant_ids)
A:gensim.topic_coherence.text_analysis.self.relevant_words->_ids_to_words(self.relevant_ids, dictionary)
A:gensim.topic_coherence.text_analysis.word_id1->self._word2_contiguous_id(word1)
A:gensim.topic_coherence.text_analysis.word_id2->self._word2_contiguous_id(word2)
A:gensim.topic_coherence.text_analysis.self._inverted_index->numpy.array([set() for _ in range(self._vocab_size)])
A:gensim.topic_coherence.text_analysis.doc_words->frozenset((x[0] for x in text))
A:gensim.topic_coherence.text_analysis.top_ids_in_doc->self.relevant_ids.intersection(doc_words)
A:gensim.topic_coherence.text_analysis.relevant_texts->self._iter_texts(texts)
A:gensim.topic_coherence.text_analysis.windows->gensim.utils.iter_windows(relevant_texts, window_size, ignore_below_size=False, include_doc_num=True)
A:gensim.topic_coherence.text_analysis.self._occurrences->numpy.zeros(self._vocab_size, dtype='uint32')
A:gensim.topic_coherence.text_analysis.self._co_occurrences->self._co_occurrences.tolil()
A:gensim.topic_coherence.text_analysis.self._uniq_words->numpy.zeros((self._vocab_size + 1,), dtype=bool)
A:gensim.topic_coherence.text_analysis.self._counter->Counter()
A:gensim.topic_coherence.text_analysis.self.batch_size->self.model_kwargs.copy().get('batch_size', 64)
A:gensim.topic_coherence.text_analysis.(workers, input_q, output_q)->self.start_workers(window_size)
A:gensim.topic_coherence.text_analysis.accumulators->self.terminate_workers(input_q, output_q, workers, interrupted)
A:gensim.topic_coherence.text_analysis.input_q->multiprocessing.Queue(maxsize=self.processes)
A:gensim.topic_coherence.text_analysis.output_q->multiprocessing.Queue()
A:gensim.topic_coherence.text_analysis.accumulator->WordOccurrenceAccumulator(self.relevant_ids, self.dictionary)
A:gensim.topic_coherence.text_analysis.worker->AccumulatingWorker(input_q, output_q, accumulator, window_size)
A:gensim.topic_coherence.text_analysis.docs->self.input_q.get(block=True)
A:gensim.topic_coherence.text_analysis.uniq_words->set(utils.flatten(words))
A:gensim.topic_coherence.text_analysis.kwargs->self.model_kwargs.copy()
A:gensim.topic_coherence.text_analysis.kwargs['min_count']->self.model_kwargs.copy().get('min_count', 1)
A:gensim.topic_coherence.text_analysis.kwargs['sg']->self.model_kwargs.copy().get('sg', 1)
A:gensim.topic_coherence.text_analysis.kwargs['hs']->self.model_kwargs.copy().get('hw', 0)
A:gensim.topic_coherence.text_analysis.self.model->Word2Vec(**kwargs)
A:gensim.topic_coherence.text_analysis.words1->self._words_with_embeddings(ids1)
A:gensim.topic_coherence.text_analysis.words2->self._words_with_embeddings(ids2)
gensim.topic_coherence.text_analysis.AccumulatingWorker(self,input_q,output_q,accumulator,window_size)
gensim.topic_coherence.text_analysis.AccumulatingWorker.__init__(self,input_q,output_q,accumulator,window_size)
gensim.topic_coherence.text_analysis.AccumulatingWorker._run(self)
gensim.topic_coherence.text_analysis.AccumulatingWorker.reply_to_master(self)
gensim.topic_coherence.text_analysis.AccumulatingWorker.run(self)
gensim.topic_coherence.text_analysis.BaseAnalyzer(self,relevant_ids)
gensim.topic_coherence.text_analysis.BaseAnalyzer.__getitem__(self,word_or_words)
gensim.topic_coherence.text_analysis.BaseAnalyzer.__init__(self,relevant_ids)
gensim.topic_coherence.text_analysis.BaseAnalyzer._get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.BaseAnalyzer._get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.BaseAnalyzer.analyze_text(self,text,doc_num=None)
gensim.topic_coherence.text_analysis.BaseAnalyzer.get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.BaseAnalyzer.get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.BaseAnalyzer.num_docs(self)
gensim.topic_coherence.text_analysis.BaseAnalyzer.num_docs(self,num)
gensim.topic_coherence.text_analysis.CorpusAccumulator(InvertedIndexBased)
gensim.topic_coherence.text_analysis.CorpusAccumulator.accumulate(self,corpus)
gensim.topic_coherence.text_analysis.CorpusAccumulator.analyze_text(self,text,doc_num=None)
gensim.topic_coherence.text_analysis.InvertedIndexAccumulator(WindowedTextsAnalyzer,InvertedIndexBased)
gensim.topic_coherence.text_analysis.InvertedIndexAccumulator.analyze_text(self,window,doc_num=None)
gensim.topic_coherence.text_analysis.InvertedIndexBased(self,*args)
gensim.topic_coherence.text_analysis.InvertedIndexBased.__init__(self,*args)
gensim.topic_coherence.text_analysis.InvertedIndexBased._get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.InvertedIndexBased._get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.InvertedIndexBased.index_to_dict(self)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator(self,processes,*args,**kwargs)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.__init__(self,processes,*args,**kwargs)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.__str__(self)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.merge_accumulators(self,accumulators)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.queue_all_texts(self,q,texts,window_size)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.start_workers(self,window_size)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.terminate_workers(self,input_q,output_q,workers,interrupted=False)
gensim.topic_coherence.text_analysis.ParallelWordOccurrenceAccumulator.yield_batches(self,texts)
gensim.topic_coherence.text_analysis.PatchedWordOccurrenceAccumulator(WordOccurrenceAccumulator)
gensim.topic_coherence.text_analysis.PatchedWordOccurrenceAccumulator._iter_texts(self,texts)
gensim.topic_coherence.text_analysis.UsesDictionary(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.UsesDictionary.__init__(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.UsesDictionary._word2_contiguous_id(self,word)
gensim.topic_coherence.text_analysis.UsesDictionary.get_co_occurrences(self,word1,word2)
gensim.topic_coherence.text_analysis.UsesDictionary.get_occurrences(self,word)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer.__init__(self,relevant_ids,dictionary)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer._iter_texts(self,texts)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WindowedTextsAnalyzer.text_is_relevant(self,text)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator(self,*args)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.__init__(self,*args)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.__str__(self)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._get_co_occurrences(self,word_id1,word_id2)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._get_occurrences(self,word_id)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._slide_window(self,window,doc_num)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator._symmetrize(self)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.analyze_text(self,window,doc_num=None)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.merge(self,other)
gensim.topic_coherence.text_analysis.WordOccurrenceAccumulator.partial_accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator(self,relevant_ids,dictionary,model=None,**model_kwargs)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.__init__(self,relevant_ids,dictionary,model=None,**model_kwargs)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator._words_with_embeddings(self,ids)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.accumulate(self,texts,window_size)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.get_co_occurrences(self,word1,word2)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.get_occurrences(self,word)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.ids_similarity(self,ids1,ids2)
gensim.topic_coherence.text_analysis.WordVectorsAccumulator.not_in_vocab(self,words)
gensim.topic_coherence.text_analysis._ids_to_words(ids,dictionary)

