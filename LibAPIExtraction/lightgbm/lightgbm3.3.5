
----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/__init__.py----------------------------------------
A:lightgbm.__init__.__version__->_version_path.read_text(encoding='utf-8').strip()


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/dask.py----------------------------------------
A:lightgbm.dask._HostWorkers->namedtuple('_HostWorkers', ['default', 'all'])
A:lightgbm.dask.TRAINSET->auto()
A:lightgbm.dask.SAMPLE_WEIGHT->auto()
A:lightgbm.dask.INIT_SCORE->auto()
A:lightgbm.dask.GROUP->auto()
A:lightgbm.dask.s->socket.socket(socket.AF_INET, socket.SOCK_STREAM)
A:lightgbm.dask.host_to_workers[hostname]->_HostWorkers(default=address, all=[address])
A:lightgbm.dask.n_workers_in_host->len(workers.all)
A:lightgbm.dask.host_ports_futures[hostname]->self.__dict__.pop('client', None).submit(_find_n_open_ports, n=n_workers_in_host, workers=[workers.default], pure=False, allow_other_workers=False)
A:lightgbm.dask.found_ports->self.__dict__.pop('client', None).gather(host_ports_futures)
A:lightgbm.dask.is_ranker->issubclass(model_factory, LGBMRanker)
A:lightgbm.dask.data->_concat([x['data'] for x in list_of_parts])
A:lightgbm.dask.label->_concat([x['label'] for x in list_of_parts])
A:lightgbm.dask.weight->_concat([x['weight'] for x in list_of_parts])
A:lightgbm.dask.group->_concat([x['group'] for x in list_of_parts])
A:lightgbm.dask.init_score->_concat([x['init_score'] for x in list_of_parts])
A:lightgbm.dask.n_evals->max((len(x.get('eval_set', [])) for x in list_of_parts))
A:lightgbm.dask.eval_names->kwargs.pop('eval_names', None)
A:lightgbm.dask.eval_class_weight->kwargs.get('eval_class_weight')
A:lightgbm.dask.has_eval_sample_weight->any((x.get('eval_sample_weight') is not None for x in list_of_parts))
A:lightgbm.dask.has_eval_init_score->any((x.get('eval_init_score') is not None for x in list_of_parts))
A:lightgbm.dask.eval_weight->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta).get('eval_sample_weight')
A:lightgbm.dask.eval_init_score->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta).get('eval_init_score')
A:lightgbm.dask.eval_group->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta).get('eval_group')
A:lightgbm.dask.(x_e, y_e, w_e, init_score_e, g_e)->_remove_list_padding(x_e, y_e, w_e, init_score_e, g_e)
A:lightgbm.dask.model->model_factory(**params)
A:lightgbm.dask.parts->self.__dict__.pop('client', None).compute(parts)
A:lightgbm.dask.machine_addresses->','.join([f'{urlparse(worker_address).hostname}:{port}' for (worker_address, port) in worker_address_to_port.items()]).split(',')
A:lightgbm.dask.machine_to_port->defaultdict(set)
A:lightgbm.dask.(host, port)->address.split(':')
A:lightgbm.dask.out[address]->machine_to_port[worker_host].pop()
A:lightgbm.dask.params->source.get_params()
A:lightgbm.dask.listen_port_in_params->any((alias in params for alias in _ConfigAliases.get('local_listen_port')))
A:lightgbm.dask.machines_in_params->any((alias in params for alias in _ConfigAliases.get('machines')))
A:lightgbm.dask.data_parts->_split_to_parts(data=data, is_matrix=True)
A:lightgbm.dask.label_parts->_split_to_parts(data=label, is_matrix=False)
A:lightgbm.dask.n_parts->len(parts)
A:lightgbm.dask.weight_parts->_split_to_parts(data=sample_weight, is_matrix=False)
A:lightgbm.dask.group_parts->_split_to_parts(data=group, is_matrix=False)
A:lightgbm.dask.init_score_parts->_split_to_parts(data=init_score, is_matrix=False)
A:lightgbm.dask.n_largest_eval_parts->max((x[0].npartitions for x in eval_set))
A:lightgbm.dask.eval_sets->defaultdict(list)
A:lightgbm.dask.eval_sample_weights->defaultdict(list)
A:lightgbm.dask.eval_groups->defaultdict(list)
A:lightgbm.dask.eval_init_scores->defaultdict(list)
A:lightgbm.dask.eval_x_parts->_split_to_parts(data=X_eval, is_matrix=True)
A:lightgbm.dask.eval_y_parts->_split_to_parts(data=y_eval, is_matrix=False)
A:lightgbm.dask.eval_w_parts->_split_to_parts(data=eval_sample_weight[i], is_matrix=False)
A:lightgbm.dask.eval_init_score_parts->_split_to_parts(data=eval_init_score[i], is_matrix=False)
A:lightgbm.dask.eval_g_parts->_split_to_parts(data=eval_group[i], is_matrix=False)
A:lightgbm.dask.who_has->self.__dict__.pop('client', None).who_has(parts)
A:lightgbm.dask.worker_map->defaultdict(list)
A:lightgbm.dask.master_worker->next(iter(worker_map))
A:lightgbm.dask.worker_ncores->self.__dict__.pop('client', None).ncores()
A:lightgbm.dask.local_listen_port->source.get_params().pop('local_listen_port')
A:lightgbm.dask.machines->','.join([f'{urlparse(worker_address).hostname}:{port}' for (worker_address, port) in worker_address_to_port.items()])
A:lightgbm.dask.worker_addresses->defaultdict(list).keys()
A:lightgbm.dask.worker_address_to_port->_assign_open_ports_to_workers(client, host_to_workers)
A:lightgbm.dask.unique_hosts->set((urlparse(a).hostname for a in worker_addresses))
A:lightgbm.dask.host_to_workers->_group_workers_by_host(worker_map.keys())
A:lightgbm.dask.num_machines->len(worker_address_to_port)
A:lightgbm.dask.results->self.__dict__.pop('client', None).gather(futures_classifiers)
A:lightgbm.dask.result->pd_Series(result, index=part.index, name='predictions')
A:lightgbm.dask.predict_function->partial(_predict_part, model=model, raw_score=False, pred_proba=pred_proba, pred_leaf=False, pred_contrib=True, **kwargs)
A:lightgbm.dask.delayed_chunks->_concat([x['data'] for x in list_of_parts]).to_delayed()
A:lightgbm.dask.bag->dask_bag_from_delayed(delayed_chunks[:, 0])
A:lightgbm.dask.preds->dask_bag_from_delayed(delayed_chunks[:, 0]).map_partitions(predict_function)
A:lightgbm.dask.part->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta)
A:lightgbm.dask.concat_fn->partial(ss.vstack, format='csc')
A:lightgbm.dask.out[i]->dask_array_from_delayed(value=delayed(concat_fn)(out[i]), shape=(data.shape[0], num_cols), meta=pred_meta)
A:lightgbm.dask.data_row->self.__dict__.pop('client', None).compute(data[[0]]).result()
A:lightgbm.dask.predict_fn->partial(_predict_part, model=model, raw_score=raw_score, pred_proba=pred_proba, pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)
A:lightgbm.dask.pred_row->predict_fn(data_row)
A:lightgbm.dask.client->self.__dict__.pop('client', None)
A:lightgbm.dask.out->deepcopy(self.__dict__)
A:lightgbm.dask.extra_param_names->set(attributes.keys()).difference(params.keys())
A:lightgbm.dask.(_before_kwargs, _kwargs, _after_kwargs)->sklearn._lgbmmodel_doc_fit.format(X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', y_shape='Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]', sample_weight_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', init_score_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', group_shape='Dask Array or Dask Series or None, optional (default=None)', eval_sample_weight_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_init_score_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_group_shape='list of Dask Array or Dask Series, or None, optional (default=None)').partition('**kwargs')
A:lightgbm.dask._base_doc->sklearn._lgbmmodel_doc_fit.format(X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', y_shape='Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]', sample_weight_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', init_score_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', group_shape='Dask Array or Dask Series or None, optional (default=None)', eval_sample_weight_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_init_score_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_group_shape='list of Dask Array or Dask Series, or None, optional (default=None)')
A:lightgbm.dask.predict.__doc__->sklearn._lgbmmodel_doc_predict.format(description='Return the predicted value for each sample.', X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', output_name='predicted_result', predicted_result_shape='Dask Array of shape = [n_samples]', X_leaves_shape='Dask Array of shape = [n_samples, n_trees]', X_SHAP_values_shape='Dask Array of shape = [n_samples, n_features + 1]')
A:lightgbm.dask.predict_proba.__doc__->sklearn._lgbmmodel_doc_predict.format(description='Return the predicted probability for each class for each sample.', X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', output_name='predicted_probability', predicted_result_shape='Dask Array of shape = [n_samples] or shape = [n_samples, n_classes]', X_leaves_shape='Dask Array of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]', X_SHAP_values_shape='Dask Array of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or (if multi-class and using sparse inputs) a list of ``n_classes`` Dask Arrays of shape = [n_samples, n_features + 1]')
lightgbm.DaskLGBMClassifier(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.DaskLGBMClassifier.__getstate__(self)->Dict[Any, Any]
lightgbm.DaskLGBMClassifier.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'DaskLGBMClassifier'
lightgbm.DaskLGBMClassifier.predict(self,X:_DaskMatrixLike,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMClassifier.predict_proba(self,X:_DaskMatrixLike,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMClassifier.to_local(self)->LGBMClassifier
lightgbm.DaskLGBMRanker(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.DaskLGBMRanker.__getstate__(self)->Dict[Any, Any]
lightgbm.DaskLGBMRanker.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,eval_at:Iterable[int]=(1,2,3,4,5),early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'DaskLGBMRanker'
lightgbm.DaskLGBMRanker.predict(self,X:_DaskMatrixLike,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMRanker.to_local(self)->LGBMRanker
lightgbm.DaskLGBMRegressor(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.DaskLGBMRegressor.__getstate__(self)->Dict[Any, Any]
lightgbm.DaskLGBMRegressor.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'DaskLGBMRegressor'
lightgbm.DaskLGBMRegressor.predict(self,X:_DaskMatrixLike,**kwargs)->dask_Array
lightgbm.DaskLGBMRegressor.to_local(self)->LGBMRegressor
lightgbm.dask.DaskLGBMClassifier(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMClassifier.__getstate__(self)->Dict[Any, Any]
lightgbm.dask.DaskLGBMClassifier.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMClassifier.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'DaskLGBMClassifier'
lightgbm.dask.DaskLGBMClassifier.predict(self,X:_DaskMatrixLike,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMClassifier.predict_proba(self,X:_DaskMatrixLike,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMClassifier.to_local(self)->LGBMClassifier
lightgbm.dask.DaskLGBMRanker(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRanker.__getstate__(self)->Dict[Any, Any]
lightgbm.dask.DaskLGBMRanker.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRanker.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,eval_at:Iterable[int]=(1,2,3,4,5),early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'DaskLGBMRanker'
lightgbm.dask.DaskLGBMRanker.predict(self,X:_DaskMatrixLike,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMRanker.to_local(self)->LGBMRanker
lightgbm.dask.DaskLGBMRegressor(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRegressor.__getstate__(self)->Dict[Any, Any]
lightgbm.dask.DaskLGBMRegressor.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[Callable,str]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:bool='warn',importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRegressor.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'DaskLGBMRegressor'
lightgbm.dask.DaskLGBMRegressor.predict(self,X:_DaskMatrixLike,**kwargs)->dask_Array
lightgbm.dask.DaskLGBMRegressor.to_local(self)->LGBMRegressor
lightgbm.dask._DaskLGBMModel
lightgbm.dask._DaskLGBMModel._lgb_dask_copy_extra_params(source:Union['_DaskLGBMModel',LGBMModel],dest:Union['_DaskLGBMModel',LGBMModel])->None
lightgbm.dask._DaskLGBMModel._lgb_dask_fit(self,model_factory:Type[LGBMModel],X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,eval_at:Optional[Iterable[int]]=None,early_stopping_rounds:Optional[int]=None,**kwargs:Any)->'_DaskLGBMModel'
lightgbm.dask._DaskLGBMModel._lgb_dask_getstate(self)->Dict[Any, Any]
lightgbm.dask._DaskLGBMModel._lgb_dask_to_local(self,model_factory:Type[LGBMModel])->LGBMModel
lightgbm.dask._DaskLGBMModel.client_(self)->Client
lightgbm.dask._DatasetNames(Enum)
lightgbm.dask._assign_open_ports_to_workers(client:Client,host_to_workers:Dict[str,_HostWorkers])->Dict[str, int]
lightgbm.dask._concat(seq:List[_DaskPart])->_DaskPart
lightgbm.dask._find_n_open_ports(n:int)->List[int]
lightgbm.dask._get_dask_client(client:Optional[Client])->Client
lightgbm.dask._group_workers_by_host(worker_addresses:Iterable[str])->Dict[str, _HostWorkers]
lightgbm.dask._machines_to_worker_map(machines:str,worker_addresses:List[str])->Dict[str, int]
lightgbm.dask._pad_eval_names(lgbm_model:LGBMModel,required_names:List[str])->LGBMModel
lightgbm.dask._predict(model:LGBMModel,data:_DaskMatrixLike,client:Client,raw_score:bool=False,pred_proba:bool=False,pred_leaf:bool=False,pred_contrib:bool=False,dtype:_PredictionDtype=np.float32,**kwargs:Any)->Union[dask_Array, List[dask_Array]]
lightgbm.dask._predict_part(part:_DaskPart,model:LGBMModel,raw_score:bool,pred_proba:bool,pred_leaf:bool,pred_contrib:bool,**kwargs:Any)->_DaskPart
lightgbm.dask._remove_list_padding(*args:Any)->List[List[Any]]
lightgbm.dask._split_to_parts(data:_DaskCollection,is_matrix:bool)->List[_DaskPart]
lightgbm.dask._train(client:Client,data:_DaskMatrixLike,label:_DaskCollection,params:Dict[str,Any],model_factory:Type[LGBMModel],sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[Union[Callable,str,List[Union[Callable,str]]]]=None,eval_at:Optional[Iterable[int]]=None,**kwargs:Any)->LGBMModel
lightgbm.dask._train_part(params:Dict[str,Any],model_factory:Type[LGBMModel],list_of_parts:List[Dict[str,_DaskPart]],machines:str,local_listen_port:int,num_machines:int,return_model:bool,time_out:int=120,**kwargs:Any)->Optional[LGBMModel]


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/engine.py----------------------------------------
A:lightgbm.engine.params->copy.deepcopy(params)
A:lightgbm.engine.num_boost_round->copy.deepcopy(params).pop(alias)
A:lightgbm.engine.early_stopping_rounds->copy.deepcopy(params).pop(alias)
A:lightgbm.engine.first_metric_only->copy.deepcopy(params).get('first_metric_only', False)
A:lightgbm.engine.predictor->init_model._to_predictor(dict(init_model.params, **params))
A:lightgbm.engine.callbacks->set(callbacks)
A:lightgbm.engine.callbacks_before_iter->sorted(callbacks_before_iter, key=attrgetter('order'))
A:lightgbm.engine.callbacks_after_iter->sorted(callbacks_after_iter, key=attrgetter('order'))
A:lightgbm.engine.booster->Booster(params=params, train_set=train_set)
A:lightgbm.engine.booster.best_score->collections.defaultdict(collections.OrderedDict)
A:lightgbm.engine.full_data->full_data.construct().construct()
A:lightgbm.engine.num_data->full_data.construct().construct().num_data()
A:lightgbm.engine.group_info->numpy.array(full_data.get_group(), dtype=np.int32, copy=False)
A:lightgbm.engine.flatted_group->numpy.repeat(range(len(group_info)), repeats=group_info)
A:lightgbm.engine.folds->zip(train_id, test_id)
A:lightgbm.engine.group_kfold->_LGBMGroupKFold(n_splits=nfold)
A:lightgbm.engine.skf->_LGBMStratifiedKFold(n_splits=nfold, shuffle=shuffle, random_state=seed)
A:lightgbm.engine.randidx->numpy.arange(num_data)
A:lightgbm.engine.kstep->int(num_data / nfold)
A:lightgbm.engine.ret->CVBooster()
A:lightgbm.engine.train_set->full_data.construct().construct().subset(sorted(train_idx))
A:lightgbm.engine.valid_set->full_data.construct().construct().subset(sorted(test_idx))
A:lightgbm.engine.(train_set, valid_set, tparam)->fpreproc(train_set, valid_set, params.copy())
A:lightgbm.engine.cvbooster->Booster(tparam, train_set)
A:lightgbm.engine.cvmap->collections.OrderedDict()
A:lightgbm.engine.results->collections.defaultdict(list)
A:lightgbm.engine.cvfolds->_make_n_folds(train_set, folds=folds, nfold=nfold, params=params, seed=seed, fpreproc=fpreproc, stratified=stratified, shuffle=shuffle, eval_train_metric=eval_train_metric)
A:lightgbm.engine.res->_agg_cv_result(cvfolds.eval_valid(feval), eval_train_metric)
lightgbm.CVBooster(self)
lightgbm.CVBooster.__getattr__(self,name)
lightgbm.CVBooster._append(self,booster)
lightgbm.cv(params,train_set,num_boost_round=100,folds=None,nfold=5,stratified=True,shuffle=True,metrics=None,fobj=None,feval=None,init_model=None,feature_name='auto',categorical_feature='auto',early_stopping_rounds=None,fpreproc=None,verbose_eval=None,show_stdv=True,seed=0,callbacks=None,eval_train_metric=False,return_cvbooster=False)
lightgbm.engine.CVBooster(self)
lightgbm.engine.CVBooster.__getattr__(self,name)
lightgbm.engine.CVBooster.__init__(self)
lightgbm.engine.CVBooster._append(self,booster)
lightgbm.engine._agg_cv_result(raw_results,eval_train_metric=False)
lightgbm.engine._make_n_folds(full_data,folds,nfold,params,seed,fpreproc=None,stratified=True,shuffle=True,eval_train_metric=False)
lightgbm.engine.cv(params,train_set,num_boost_round=100,folds=None,nfold=5,stratified=True,shuffle=True,metrics=None,fobj=None,feval=None,init_model=None,feature_name='auto',categorical_feature='auto',early_stopping_rounds=None,fpreproc=None,verbose_eval=None,show_stdv=True,seed=0,callbacks=None,eval_train_metric=False,return_cvbooster=False)
lightgbm.engine.train(params:Dict[str,Any],train_set:Dataset,num_boost_round:int=100,valid_sets:Optional[List[Dataset]]=None,valid_names:Optional[List[str]]=None,fobj:Optional[_LGBM_CustomObjectiveFunction]=None,feval:Optional[Union[_LGBM_CustomMetricFunction,List[_LGBM_CustomMetricFunction]]]=None,init_model:Optional[Union[str,Path,Booster]]=None,feature_name:Union[List[str],str]='auto',categorical_feature:Union[List[str],List[int],str]='auto',early_stopping_rounds:Optional[int]=None,evals_result:Optional[Dict[str,Any]]=None,verbose_eval:Union[bool,int,str]='warn',learning_rates:Optional[Union[List[float],Callable[[int],float]]]=None,keep_training_booster:bool=False,callbacks:Optional[List[Callable]]=None)->Booster
lightgbm.train(params:Dict[str,Any],train_set:Dataset,num_boost_round:int=100,valid_sets:Optional[List[Dataset]]=None,valid_names:Optional[List[str]]=None,fobj:Optional[_LGBM_CustomObjectiveFunction]=None,feval:Optional[Union[_LGBM_CustomMetricFunction,List[_LGBM_CustomMetricFunction]]]=None,init_model:Optional[Union[str,Path,Booster]]=None,feature_name:Union[List[str],str]='auto',categorical_feature:Union[List[str],List[int],str]='auto',early_stopping_rounds:Optional[int]=None,evals_result:Optional[Dict[str,Any]]=None,verbose_eval:Union[bool,int,str]='warn',learning_rates:Optional[Union[List[float],Callable[[int],float]]]=None,keep_training_booster:bool=False,callbacks:Optional[List[Callable]]=None)->Booster


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/sklearn.py----------------------------------------
A:lightgbm.sklearn.labels->dataset.get_label()
A:lightgbm.sklearn.argc->len(signature(self.func).parameters)
A:lightgbm.sklearn.(grad, hess)->self.func(labels, preds, dataset.get_group())
A:lightgbm.sklearn.weight->dataset.get_weight()
A:lightgbm.sklearn.grad->numpy.multiply(grad, weight)
A:lightgbm.sklearn.hess->numpy.multiply(hess, weight)
A:lightgbm.sklearn.num_data->len(weight)
A:lightgbm.sklearn.params->_choose_param_value('metric', params, original_metric)
A:lightgbm.sklearn.self._fobj->_ObjectiveFunctionWrapper(self._objective)
A:lightgbm.sklearn.params['random_state']->params['random_state'].randint(np.iinfo(np.int32).max).randint(np.iinfo(np.int32).max)
A:lightgbm.sklearn.eval_at->_choose_param_value('metric', params, original_metric).pop(alias)
A:lightgbm.sklearn.eval_metric_list->copy.deepcopy(eval_metric)
A:lightgbm.sklearn.(_X, _y)->_LGBMCheckXY(X, y, accept_sparse=True, force_all_finite=False, ensure_min_samples=2)
A:lightgbm.sklearn.sample_weight->numpy.multiply(sample_weight, class_sample_weight)
A:lightgbm.sklearn.class_sample_weight->_LGBMComputeSampleWeight(self._class_weight, y)
A:lightgbm.sklearn.train_set->_construct_dataset(_X, _y, sample_weight, init_score, group, params, categorical_feature=categorical_feature)
A:lightgbm.sklearn.valid_weight->numpy.multiply(valid_weight, valid_class_sample_weight)
A:lightgbm.sklearn.valid_class_weight->_get_meta_data(eval_class_weight, 'eval_class_weight', i)
A:lightgbm.sklearn.valid_class_sample_weight->_LGBMComputeSampleWeight(valid_class_weight, valid_data[1])
A:lightgbm.sklearn.valid_init_score->_get_meta_data(eval_init_score, 'eval_init_score', i)
A:lightgbm.sklearn.valid_group->_get_meta_data(eval_group, 'eval_group', i)
A:lightgbm.sklearn.valid_set->_construct_dataset(valid_data[0], valid_data[1], valid_weight, valid_init_score, valid_group, params)
A:lightgbm.sklearn.callbacks->copy.copy(callbacks)
A:lightgbm.sklearn.self._Booster->train(params=params, train_set=train_set, num_boost_round=self.n_estimators, valid_sets=valid_sets, valid_names=eval_names, fobj=self._fobj, feval=eval_metrics_callable, init_model=init_model, feature_name=feature_name, callbacks=callbacks)
A:lightgbm.sklearn.X->_LGBMCheckArray(X, accept_sparse=True, force_all_finite=False)
A:lightgbm.sklearn.predict.__doc__->_lgbmmodel_doc_predict.format(description='Return the predicted value for each sample.', X_shape='array-like or sparse matrix of shape = [n_samples, n_features]', output_name='predicted_result', predicted_result_shape='array-like of shape = [n_samples] or shape = [n_samples, n_classes]', X_leaves_shape='array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]', X_SHAP_values_shape='array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects')
A:lightgbm.sklearn.self._le->_LGBMLabelEncoder().fit(y)
A:lightgbm.sklearn._y->self._le.transform(y)
A:lightgbm.sklearn.self._class_map->dict(zip(self._le.classes_, self._le.transform(self._le.classes_)))
A:lightgbm.sklearn.self._n_classes->len(self._classes)
A:lightgbm.sklearn.result->super().predict(X, raw_score, start_iteration, num_iteration, pred_leaf, pred_contrib, **kwargs)
A:lightgbm.sklearn.class_index->numpy.argmax(result, axis=1)
A:lightgbm.sklearn.predict_proba.__doc__->_lgbmmodel_doc_predict.format(description='Return the predicted probability for each class for each sample.', X_shape='array-like or sparse matrix of shape = [n_samples, n_features]', output_name='predicted_probability', predicted_result_shape='array-like of shape = [n_samples] or shape = [n_samples, n_classes]', X_leaves_shape='array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]', X_SHAP_values_shape='array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects')
A:lightgbm.sklearn.(_before_early_stop, _early_stop, _after_early_stop)->_base_doc.partition('early_stopping_rounds :')
lightgbm.LGBMClassifier(_LGBMClassifierBase,LGBMModel)
lightgbm.LGBMClassifier.classes_(self)
lightgbm.LGBMClassifier.fit(self,X,y,sample_weight=None,init_score=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_class_weight=None,eval_init_score=None,eval_metric=None,early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.LGBMClassifier.n_classes_(self)
lightgbm.LGBMClassifier.predict(self,X,raw_score=False,start_iteration=0,num_iteration=None,pred_leaf=False,pred_contrib=False,**kwargs)
lightgbm.LGBMClassifier.predict_proba(self,X,raw_score=False,start_iteration=0,num_iteration=None,pred_leaf=False,pred_contrib=False,**kwargs)
lightgbm.LGBMModel(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,Callable]]=None,class_weight:Optional[Union[Dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:Union[bool,str]='warn',importance_type:str='split',**kwargs)
lightgbm.LGBMModel.__sklearn_is_fitted__(self)->bool
lightgbm.LGBMModel._more_tags(self)
lightgbm.LGBMModel.best_iteration_(self)
lightgbm.LGBMModel.best_score_(self)
lightgbm.LGBMModel.booster_(self)
lightgbm.LGBMModel.evals_result_(self)
lightgbm.LGBMModel.feature_importances_(self)
lightgbm.LGBMModel.feature_name_(self)
lightgbm.LGBMModel.fit(self,X,y,sample_weight=None,init_score=None,group=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_class_weight=None,eval_init_score=None,eval_group=None,eval_metric=None,early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.LGBMModel.get_params(self,deep=True)
lightgbm.LGBMModel.n_features_(self)
lightgbm.LGBMModel.n_features_in_(self)
lightgbm.LGBMModel.objective_(self)
lightgbm.LGBMModel.predict(self,X,raw_score=False,start_iteration=0,num_iteration=None,pred_leaf=False,pred_contrib=False,**kwargs)
lightgbm.LGBMModel.set_params(self,**params)
lightgbm.LGBMRanker(LGBMModel)
lightgbm.LGBMRanker.fit(self,X,y,sample_weight=None,init_score=None,group=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_init_score=None,eval_group=None,eval_metric=None,eval_at=(1,2,3,4,5),early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.LGBMRegressor(_LGBMRegressorBase,LGBMModel)
lightgbm.LGBMRegressor.fit(self,X,y,sample_weight=None,init_score=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_init_score=None,eval_metric=None,early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.sklearn.LGBMClassifier(_LGBMClassifierBase,LGBMModel)
lightgbm.sklearn.LGBMClassifier.classes_(self)
lightgbm.sklearn.LGBMClassifier.fit(self,X,y,sample_weight=None,init_score=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_class_weight=None,eval_init_score=None,eval_metric=None,early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.sklearn.LGBMClassifier.n_classes_(self)
lightgbm.sklearn.LGBMClassifier.predict(self,X,raw_score=False,start_iteration=0,num_iteration=None,pred_leaf=False,pred_contrib=False,**kwargs)
lightgbm.sklearn.LGBMClassifier.predict_proba(self,X,raw_score=False,start_iteration=0,num_iteration=None,pred_leaf=False,pred_contrib=False,**kwargs)
lightgbm.sklearn.LGBMModel(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,Callable]]=None,class_weight:Optional[Union[Dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:Union[bool,str]='warn',importance_type:str='split',**kwargs)
lightgbm.sklearn.LGBMModel.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,Callable]]=None,class_weight:Optional[Union[Dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState]]=None,n_jobs:int=-1,silent:Union[bool,str]='warn',importance_type:str='split',**kwargs)
lightgbm.sklearn.LGBMModel.__sklearn_is_fitted__(self)->bool
lightgbm.sklearn.LGBMModel._more_tags(self)
lightgbm.sklearn.LGBMModel.best_iteration_(self)
lightgbm.sklearn.LGBMModel.best_score_(self)
lightgbm.sklearn.LGBMModel.booster_(self)
lightgbm.sklearn.LGBMModel.evals_result_(self)
lightgbm.sklearn.LGBMModel.feature_importances_(self)
lightgbm.sklearn.LGBMModel.feature_name_(self)
lightgbm.sklearn.LGBMModel.fit(self,X,y,sample_weight=None,init_score=None,group=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_class_weight=None,eval_init_score=None,eval_group=None,eval_metric=None,early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.sklearn.LGBMModel.get_params(self,deep=True)
lightgbm.sklearn.LGBMModel.n_features_(self)
lightgbm.sklearn.LGBMModel.n_features_in_(self)
lightgbm.sklearn.LGBMModel.objective_(self)
lightgbm.sklearn.LGBMModel.predict(self,X,raw_score=False,start_iteration=0,num_iteration=None,pred_leaf=False,pred_contrib=False,**kwargs)
lightgbm.sklearn.LGBMModel.set_params(self,**params)
lightgbm.sklearn.LGBMRanker(LGBMModel)
lightgbm.sklearn.LGBMRanker.fit(self,X,y,sample_weight=None,init_score=None,group=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_init_score=None,eval_group=None,eval_metric=None,eval_at=(1,2,3,4,5),early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.sklearn.LGBMRegressor(_LGBMRegressorBase,LGBMModel)
lightgbm.sklearn.LGBMRegressor.fit(self,X,y,sample_weight=None,init_score=None,eval_set=None,eval_names=None,eval_sample_weight=None,eval_init_score=None,eval_metric=None,early_stopping_rounds=None,verbose='warn',feature_name='auto',categorical_feature='auto',callbacks=None,init_model=None)
lightgbm.sklearn._EvalFunctionWrapper(self,func)
lightgbm.sklearn._EvalFunctionWrapper.__init__(self,func)
lightgbm.sklearn._ObjectiveFunctionWrapper(self,func)
lightgbm.sklearn._ObjectiveFunctionWrapper.__init__(self,func)


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/basic.py----------------------------------------
A:lightgbm.basic.sample_cnt->_get_sample_count(total_nrow, param_str)
A:lightgbm.basic.msg->''.join(msg_normalized)
A:lightgbm.basic.lib_path->find_lib_path()
A:lightgbm.basic.lib->ctypes.cdll.LoadLibrary(lib_path[0])
A:lightgbm.basic.callback->ctypes.CFUNCTYPE(None, ctypes.c_char_p)
A:lightgbm.basic.lib.callback->callback(_log_callback)
A:lightgbm.basic._LIB->_load_lib()
A:lightgbm.basic.array->list_to_1d_numpy(data, dtype, name=field_name).ravel()
A:lightgbm.basic.self.path->Path(self.name)
A:lightgbm.basic.ret->numpy.column_stack((bin_edges[1:], hist))
A:lightgbm.basic.params->_choose_param_value(main_param_name='local_listen_port', params=params, default_value=12400)
A:lightgbm.basic.val->_choose_param_value(main_param_name='local_listen_port', params=params, default_value=12400).pop(param, None)
A:lightgbm.basic.data->list_to_1d_numpy(data, dtype, name=field_name)
A:lightgbm.basic.ptr_data->(ctypes.POINTER(ctypes.c_float) * len(mats))()
A:lightgbm.basic.cat_cols->list(data.select_dtypes(include=['category']).columns)
A:lightgbm.basic.data[col]->data[col].cat.set_categories(category).cat.set_categories(category)
A:lightgbm.basic.data[cat_cols]->data[cat_cols].apply(lambda x: x.cat.codes).replace({-1: np.nan}).apply(lambda x: x.cat.codes).replace({-1: np.nan})
A:lightgbm.basic.feature_name->list(data.columns)
A:lightgbm.basic.categorical_feature->list(categorical_feature)
A:lightgbm.basic.bad_indices->_get_bad_pandas_dtypes(data.dtypes)
A:lightgbm.basic.bad_index_cols_str->', '.join(data.columns[bad_indices])
A:lightgbm.basic.label->list_to_1d_numpy(_label_from_pandas(label), name='label')
A:lightgbm.basic.categorical_json->json.dumps(pandas_categorical, default=json_default_with_numpy)
A:lightgbm.basic.lines->f.readlines()
A:lightgbm.basic.last_line->model_str[idx:].strip()
A:lightgbm.basic.idx->state.get('handle', None).rfind('\n', 0, offset)
A:lightgbm.basic.self.handle->ctypes.c_void_p()
A:lightgbm.basic.out_num_iterations->ctypes.c_int(0)
A:lightgbm.basic.out_num_class->ctypes.c_int(0)
A:lightgbm.basic.self.pandas_categorical->_load_pandas_categorical(model_str=model_str)
A:lightgbm.basic.self.num_total_iteration->self.current_iteration()
A:lightgbm.basic.self.pred_parameter->param_dict_to_str(pred_parameter)
A:lightgbm.basic.this->self.__dict__.copy()
A:lightgbm.basic.preds->numpy.empty(n_preds, dtype=np.float64)
A:lightgbm.basic.(preds, nrow)->self.__pred_for_csr(csr, start_iteration, num_iteration, predict_type)
A:lightgbm.basic.csr->scipy.sparse.csr_matrix(data)
A:lightgbm.basic.n_preds->self.__get_num_preds(start_iteration, num_iteration, nrow, predict_type)
A:lightgbm.basic.(ptr_data, type_ptr_data, _)->c_float_array(csc.data)
A:lightgbm.basic.out_num_preds->ctypes.c_int64(0)
A:lightgbm.basic.sections->numpy.arange(start=MAX_INT32, stop=nrow, step=MAX_INT32)
A:lightgbm.basic.n_preds_sections->numpy.array([0] + n_preds, dtype=np.intp).cumsum()
A:lightgbm.basic.out_indptr->cint64_array_to_numpy(out_ptr_indptr, indptr_len)
A:lightgbm.basic.out_data->cfloat64_array_to_numpy(out_ptr_data, data_indices_len)
A:lightgbm.basic.out_indices->cint32_array_to_numpy(out_ptr_indices, data_indices_len)
A:lightgbm.basic.out_indptr_arrays->numpy.split(out_indptr, out_indptr.shape[0] / per_class_indptr_shape)
A:lightgbm.basic.(ptr_indptr, type_ptr_indptr, __)->c_int_array(csc.indptr)
A:lightgbm.basic.csr_indices->scipy.sparse.csr_matrix(data).indices.astype(np.int32, copy=False)
A:lightgbm.basic.out_ptr_indptr->ctypes.POINTER(ctypes.c_int64)()
A:lightgbm.basic.out_ptr_indices->ctypes.POINTER(ctypes.c_int32)()
A:lightgbm.basic.out_ptr_data->ctypes.POINTER(ctypes.c_double)()
A:lightgbm.basic.out_shape->numpy.empty(2, dtype=np.int64)
A:lightgbm.basic.matrices->self.__create_sparse_native(csc, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data, type_ptr_indptr, type_ptr_data, is_csr=False)
A:lightgbm.basic.csc_indices->csc.indices.astype(np.int32, copy=False)
A:lightgbm.basic.out_cur_iter->ctypes.c_int(0)
A:lightgbm.basic.self.params->deepcopy(self.params_back_up)
A:lightgbm.basic.param_str->param_dict_to_str(self.get_params())
A:lightgbm.basic.indices->self._create_sample_indices(total_nrow)
A:lightgbm.basic.(ptr_data, _, _)->c_int_array(leaf_preds)
A:lightgbm.basic.actual_sample_cnt->ctypes.c_int32(0)
A:lightgbm.basic.ncol->len(sample_indices)
A:lightgbm.basic.sample_col_ptr->(ctypes.POINTER(ctypes.c_double) * ncol)()
A:lightgbm.basic.indices_col_ptr->(ctypes.POINTER(ctypes.c_int32) * ncol)()
A:lightgbm.basic.num_per_col->numpy.array([len(d) for d in sample_indices], dtype=np.int32)
A:lightgbm.basic.(num_per_col_ptr, _, _)->c_int_array(num_per_col)
A:lightgbm.basic.params_str->param_dict_to_str(params)
A:lightgbm.basic.(data_ptr, data_type, _)->c_float_array(data)
A:lightgbm.basic.dataset_params->_ConfigAliases.get('bin_construct_sample_cnt', 'categorical_feature', 'data_random_seed', 'enable_bundle', 'feature_pre_filter', 'forcedbins_filename', 'group_column', 'header', 'ignore_column', 'is_enable_sparse', 'label_column', 'linear_tree', 'max_bin', 'max_bin_by_feature', 'min_data_in_bin', 'pre_partition', 'precise_float_parser', 'two_round', 'use_missing', 'weight_column', 'zero_as_missing')
A:lightgbm.basic.data_has_header->any((self.params.get(alias, False) for alias in _ConfigAliases.get('header')))
A:lightgbm.basic.num_data->self.num_data()
A:lightgbm.basic.init_score->numpy.zeros(self.init_score.shape, dtype=np.float64)
A:lightgbm.basic.sub_init_score->numpy.empty(num_data * predictor.num_class, dtype=np.float64)
A:lightgbm.basic.new_init_score->numpy.empty(init_score.size, dtype=np.float64)
A:lightgbm.basic.(data, feature_name, categorical_feature, self.pandas_categorical)->_data_from_pandas(data, feature_name, categorical_feature, self.pandas_categorical)
A:lightgbm.basic.categorical_indices->set()
A:lightgbm.basic.params['categorical_column']->sorted(categorical_indices)
A:lightgbm.basic.sampled->numpy.array([row for row in self._yield_row_from_seqlist(seqs, indices)])
A:lightgbm.basic.sampled_row_range->numpy.arange(len(indices), dtype=np.int32)
A:lightgbm.basic.total_nrow->sum((len(seq) for seq in seqs))
A:lightgbm.basic.(sample_data, col_indices)->self.__sample(seqs, total_nrow)
A:lightgbm.basic.nrow->numpy.empty((len(mats),), np.int32)
A:lightgbm.basic.end->min(start + batch_size, nrow)
A:lightgbm.basic.mats[i]->numpy.array(mat.reshape(mat.size), dtype=np.float32)
A:lightgbm.basic.(chunk_ptr_data, chunk_type_ptr_data, holder)->c_float_array(mats[i])
A:lightgbm.basic.reference_params->self.reference.get_params()
A:lightgbm.basic.used_indices->list_to_1d_numpy(self.used_indices, np.int32, name='used_indices')
A:lightgbm.basic.group_info->numpy.array(self.reference.group).astype(np.int32, copy=False)
A:lightgbm.basic.(_, self.group)->numpy.unique(np.repeat(range(len(group_info)), repeats=group_info)[self.used_indices], return_counts=True)
A:lightgbm.basic.ret.used_indices->sorted(used_indices)
A:lightgbm.basic.self.params_back_up->deepcopy(self.params)
A:lightgbm.basic.(ptr_data, type_data, _)->c_int_array(data)
A:lightgbm.basic.tmp_out_len->ctypes.c_int(0)
A:lightgbm.basic.out_type->ctypes.c_int(0)
A:lightgbm.basic.arr->arr.reshape((num_data, num_classes), order='F').reshape((num_data, num_classes), order='F')
A:lightgbm.basic.self.label->self.get_field('label')
A:lightgbm.basic.weight->list_to_1d_numpy(weight, name='weight')
A:lightgbm.basic.self.weight->self.get_field('weight')
A:lightgbm.basic.self.init_score->self.get_field('init_score')
A:lightgbm.basic.group->list_to_1d_numpy(group, np.int32, name='group')
A:lightgbm.basic.num_feature->self.num_feature()
A:lightgbm.basic.required_string_buffer_size->ctypes.c_size_t(0)
A:lightgbm.basic.ptr_string_buffers->(ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))
A:lightgbm.basic.self.data->dt_DataTable(np.hstack((self.data.to_numpy(), other.data.to_numpy())))
A:lightgbm.basic.self.group->numpy.diff(self.group)
A:lightgbm.basic.ref_chain->set()
A:lightgbm.basic.sparse_format->self.data.getformat()
A:lightgbm.basic.self.feature_name->self.get_feature_name()
A:lightgbm.basic.num_machines_from_machine_list->len(machines)
A:lightgbm.basic.machines->','.join(machines)
A:lightgbm.basic.model_str->state.get('handle', None)
A:lightgbm.basic.booster->Booster(model_str=model_str)
A:lightgbm.basic.this['handle']->self.model_to_string(num_iteration=-1)
A:lightgbm.basic.handle->ctypes.c_void_p()
A:lightgbm.basic.is_split->_is_split_node(tree)
A:lightgbm.basic.node_num->tree.get('split_index' if is_split else 'leaf_index', 0)
A:lightgbm.basic.node->create_node_record(tree, node_depth=node_depth, tree_index=tree_index, feature_names=feature_names, parent_node=parent_node)
A:lightgbm.basic.node['node_index']->_get_node_index(tree, tree_index)
A:lightgbm.basic.node['split_feature']->_get_split_feature(tree, feature_names)
A:lightgbm.basic.node['left_child']->_get_node_index(tree['left_child'], tree_index)
A:lightgbm.basic.node['right_child']->_get_node_index(tree['right_child'], tree_index)
A:lightgbm.basic.subtree_list->tree_dict_to_node_list(tree[child], node_depth=node_depth + 1, tree_index=tree_index, feature_names=feature_names, parent_node=node['node_index'])
A:lightgbm.basic.model_dict->self.dump_model()
A:lightgbm.basic.is_finished->ctypes.c_int(0)
A:lightgbm.basic.(grad, hess)->fobj(self.__inner_predict(0), self.train_set)
A:lightgbm.basic.grad->list_to_1d_numpy(grad, name='gradient')
A:lightgbm.basic.hess->list_to_1d_numpy(hess, name='hessian')
A:lightgbm.basic.model_per_iter->ctypes.c_int(0)
A:lightgbm.basic.num_trees->ctypes.c_int(0)
A:lightgbm.basic.string_buffer->ctypes.create_string_buffer(actual_len)
A:lightgbm.basic.ptr_string_buffer->ctypes.c_char_p(*[ctypes.addressof(string_buffer)])
A:lightgbm.basic.ret['pandas_categorical']->json.loads(json.dumps(self.pandas_categorical, default=json_default_with_numpy))
A:lightgbm.basic.predictor->_InnerPredictor(booster_handle=self.handle, pred_parameter=pred_parameter)
A:lightgbm.basic.leaf_preds->leaf_preds.reshape(-1).reshape(-1)
A:lightgbm.basic.out_is_linear->ctypes.c_bool(False)
A:lightgbm.basic.new_params->_choose_param_value(main_param_name='linear_tree', params=self.params, default_value=None)
A:lightgbm.basic.train_set->Dataset(data, label, silent=True, params=new_params)
A:lightgbm.basic.new_booster->Booster(new_params, train_set)
A:lightgbm.basic.new_booster.__attr->self.__attr.copy()
A:lightgbm.basic.out_num_feature->ctypes.c_int(0)
A:lightgbm.basic.result->numpy.empty(self.__num_inner_eval, dtype=np.float64)
A:lightgbm.basic.model->self.dump_model()
A:lightgbm.basic.feature_names->self.dump_model().get('feature_names')
A:lightgbm.basic.n_unique->len(np.unique(values))
A:lightgbm.basic.bins->max(min(n_unique, bins) if bins is not None else n_unique, 1)
A:lightgbm.basic.(hist, bin_edges)->numpy.histogram(values, bins=bins)
A:lightgbm.basic.feval_ret->eval_function(self.__inner_predict(data_idx), cur_data)
A:lightgbm.basic.self.__inner_predict_buffer[data_idx]->numpy.empty(n_preds, dtype=np.float64)
A:lightgbm.basic.data_ptr->self.__inner_predict_buffer[data_idx].ctypes.data_as(ctypes.POINTER(ctypes.c_double))
A:lightgbm.basic.out_num_eval->ctypes.c_int(0)
lightgbm.Booster(self,params=None,train_set=None,model_file=None,model_str=None,silent='warn')
lightgbm.Booster.__boost(self,grad,hess)
lightgbm.Booster.__copy__(self)
lightgbm.Booster.__deepcopy__(self,_)
lightgbm.Booster.__del__(self)
lightgbm.Booster.__get_eval_info(self)
lightgbm.Booster.__getstate__(self)
lightgbm.Booster.__inner_eval(self,data_name,data_idx,feval=None)
lightgbm.Booster.__inner_predict(self,data_idx)
lightgbm.Booster.__setstate__(self,state)
lightgbm.Booster._free_buffer(self)
lightgbm.Booster._to_predictor(self,pred_parameter=None)
lightgbm.Booster.add_valid(self,data,name)
lightgbm.Booster.attr(self,key)
lightgbm.Booster.current_iteration(self)
lightgbm.Booster.dump_model(self,num_iteration=None,start_iteration=0,importance_type='split',object_hook=None)
lightgbm.Booster.eval(self,data,name,feval=None)
lightgbm.Booster.eval_train(self,feval=None)
lightgbm.Booster.eval_valid(self,feval=None)
lightgbm.Booster.feature_importance(self,importance_type='split',iteration=None)
lightgbm.Booster.feature_name(self)
lightgbm.Booster.free_dataset(self)
lightgbm.Booster.free_network(self)
lightgbm.Booster.get_leaf_output(self,tree_id,leaf_id)
lightgbm.Booster.get_split_value_histogram(self,feature,bins=None,xgboost_style=False)
lightgbm.Booster.lower_bound(self)
lightgbm.Booster.model_from_string(self,model_str,verbose='warn')
lightgbm.Booster.model_to_string(self,num_iteration=None,start_iteration=0,importance_type='split')
lightgbm.Booster.num_feature(self)
lightgbm.Booster.num_model_per_iteration(self)
lightgbm.Booster.num_trees(self)
lightgbm.Booster.predict(self,data,start_iteration=0,num_iteration=None,raw_score=False,pred_leaf=False,pred_contrib=False,data_has_header=False,is_reshape=True,**kwargs)
lightgbm.Booster.refit(self,data,label,decay_rate=0.9,**kwargs)
lightgbm.Booster.reset_parameter(self,params)
lightgbm.Booster.rollback_one_iter(self)
lightgbm.Booster.save_model(self,filename,num_iteration=None,start_iteration=0,importance_type='split')
lightgbm.Booster.set_attr(self,**kwargs)
lightgbm.Booster.set_network(self,machines:Union[List[str],Set[str],str],local_listen_port:int=12400,listen_time_out:int=120,num_machines:int=1)->'Booster'
lightgbm.Booster.set_train_data_name(self,name)
lightgbm.Booster.shuffle_models(self,start_iteration=0,end_iteration=-1)
lightgbm.Booster.trees_to_dataframe(self)
lightgbm.Booster.update(self,train_set=None,fobj=None)
lightgbm.Booster.upper_bound(self)
lightgbm.Dataset(self,data,label=None,reference=None,weight=None,group=None,init_score=None,silent='warn',feature_name='auto',categorical_feature='auto',params=None,free_raw_data=True)
lightgbm.Dataset.__del__(self)
lightgbm.Dataset.__init_from_csc(self,csc,params_str,ref_dataset)
lightgbm.Dataset.__init_from_csr(self,csr,params_str,ref_dataset)
lightgbm.Dataset.__init_from_list_np2d(self,mats,params_str,ref_dataset)
lightgbm.Dataset.__init_from_np2d(self,mat,params_str,ref_dataset)
lightgbm.Dataset.__init_from_seqs(self,seqs:List[Sequence],ref_dataset:Optional['Dataset']=None)
lightgbm.Dataset.__sample(self,seqs:List[Sequence],total_nrow:int)->Tuple[List[np.ndarray], List[np.ndarray]]
lightgbm.Dataset._create_sample_indices(self,total_nrow:int)->np.ndarray
lightgbm.Dataset._dump_text(self,filename)
lightgbm.Dataset._free_handle(self)
lightgbm.Dataset._init_from_ref_dataset(self,total_nrow:int,ref_dataset:'Dataset')->'Dataset'
lightgbm.Dataset._init_from_sample(self,sample_data:List[np.ndarray],sample_indices:List[np.ndarray],sample_cnt:int,total_nrow:int)->'Dataset'
lightgbm.Dataset._lazy_init(self,data,label=None,reference=None,weight=None,group=None,init_score=None,predictor=None,silent=False,feature_name='auto',categorical_feature='auto',params=None)
lightgbm.Dataset._push_rows(self,data:np.ndarray)->'Dataset'
lightgbm.Dataset._reverse_update_params(self)
lightgbm.Dataset._set_init_score_by_predictor(self,predictor,data,used_indices=None)
lightgbm.Dataset._set_predictor(self,predictor)
lightgbm.Dataset._update_params(self,params)
lightgbm.Dataset._yield_row_from_seqlist(seqs:List[Sequence],indices:Iterable[int])
lightgbm.Dataset.add_features_from(self,other)
lightgbm.Dataset.construct(self)
lightgbm.Dataset.create_valid(self,data,label=None,weight=None,group=None,init_score=None,silent='warn',params=None)
lightgbm.Dataset.get_data(self)
lightgbm.Dataset.get_feature_name(self)
lightgbm.Dataset.get_field(self,field_name)
lightgbm.Dataset.get_group(self)
lightgbm.Dataset.get_init_score(self)
lightgbm.Dataset.get_label(self)
lightgbm.Dataset.get_params(self)
lightgbm.Dataset.get_ref_chain(self,ref_limit=100)
lightgbm.Dataset.get_weight(self)
lightgbm.Dataset.num_data(self)
lightgbm.Dataset.num_feature(self)
lightgbm.Dataset.save_binary(self,filename)
lightgbm.Dataset.set_categorical_feature(self,categorical_feature)
lightgbm.Dataset.set_feature_name(self,feature_name)
lightgbm.Dataset.set_field(self,field_name,data)
lightgbm.Dataset.set_group(self,group)
lightgbm.Dataset.set_init_score(self,init_score)
lightgbm.Dataset.set_label(self,label)
lightgbm.Dataset.set_reference(self,reference)
lightgbm.Dataset.set_weight(self,weight)
lightgbm.Dataset.subset(self,used_indices,params=None)
lightgbm.Sequence(abc.ABC)
lightgbm.Sequence.__getitem__(self,idx:Union[int,slice,List[int]])->np.ndarray
lightgbm.Sequence.__len__(self)->int
lightgbm.basic.Booster(self,params=None,train_set=None,model_file=None,model_str=None,silent='warn')
lightgbm.basic.Booster.__boost(self,grad,hess)
lightgbm.basic.Booster.__copy__(self)
lightgbm.basic.Booster.__deepcopy__(self,_)
lightgbm.basic.Booster.__del__(self)
lightgbm.basic.Booster.__get_eval_info(self)
lightgbm.basic.Booster.__getstate__(self)
lightgbm.basic.Booster.__init__(self,params=None,train_set=None,model_file=None,model_str=None,silent='warn')
lightgbm.basic.Booster.__inner_eval(self,data_name,data_idx,feval=None)
lightgbm.basic.Booster.__inner_predict(self,data_idx)
lightgbm.basic.Booster.__setstate__(self,state)
lightgbm.basic.Booster._free_buffer(self)
lightgbm.basic.Booster._to_predictor(self,pred_parameter=None)
lightgbm.basic.Booster.add_valid(self,data,name)
lightgbm.basic.Booster.attr(self,key)
lightgbm.basic.Booster.current_iteration(self)
lightgbm.basic.Booster.dump_model(self,num_iteration=None,start_iteration=0,importance_type='split',object_hook=None)
lightgbm.basic.Booster.eval(self,data,name,feval=None)
lightgbm.basic.Booster.eval_train(self,feval=None)
lightgbm.basic.Booster.eval_valid(self,feval=None)
lightgbm.basic.Booster.feature_importance(self,importance_type='split',iteration=None)
lightgbm.basic.Booster.feature_name(self)
lightgbm.basic.Booster.free_dataset(self)
lightgbm.basic.Booster.free_network(self)
lightgbm.basic.Booster.get_leaf_output(self,tree_id,leaf_id)
lightgbm.basic.Booster.get_split_value_histogram(self,feature,bins=None,xgboost_style=False)
lightgbm.basic.Booster.lower_bound(self)
lightgbm.basic.Booster.model_from_string(self,model_str,verbose='warn')
lightgbm.basic.Booster.model_to_string(self,num_iteration=None,start_iteration=0,importance_type='split')
lightgbm.basic.Booster.num_feature(self)
lightgbm.basic.Booster.num_model_per_iteration(self)
lightgbm.basic.Booster.num_trees(self)
lightgbm.basic.Booster.predict(self,data,start_iteration=0,num_iteration=None,raw_score=False,pred_leaf=False,pred_contrib=False,data_has_header=False,is_reshape=True,**kwargs)
lightgbm.basic.Booster.refit(self,data,label,decay_rate=0.9,**kwargs)
lightgbm.basic.Booster.reset_parameter(self,params)
lightgbm.basic.Booster.rollback_one_iter(self)
lightgbm.basic.Booster.save_model(self,filename,num_iteration=None,start_iteration=0,importance_type='split')
lightgbm.basic.Booster.set_attr(self,**kwargs)
lightgbm.basic.Booster.set_network(self,machines:Union[List[str],Set[str],str],local_listen_port:int=12400,listen_time_out:int=120,num_machines:int=1)->'Booster'
lightgbm.basic.Booster.set_train_data_name(self,name)
lightgbm.basic.Booster.shuffle_models(self,start_iteration=0,end_iteration=-1)
lightgbm.basic.Booster.trees_to_dataframe(self)
lightgbm.basic.Booster.update(self,train_set=None,fobj=None)
lightgbm.basic.Booster.upper_bound(self)
lightgbm.basic.Dataset(self,data,label=None,reference=None,weight=None,group=None,init_score=None,silent='warn',feature_name='auto',categorical_feature='auto',params=None,free_raw_data=True)
lightgbm.basic.Dataset.__del__(self)
lightgbm.basic.Dataset.__init__(self,data,label=None,reference=None,weight=None,group=None,init_score=None,silent='warn',feature_name='auto',categorical_feature='auto',params=None,free_raw_data=True)
lightgbm.basic.Dataset.__init_from_csc(self,csc,params_str,ref_dataset)
lightgbm.basic.Dataset.__init_from_csr(self,csr,params_str,ref_dataset)
lightgbm.basic.Dataset.__init_from_list_np2d(self,mats,params_str,ref_dataset)
lightgbm.basic.Dataset.__init_from_np2d(self,mat,params_str,ref_dataset)
lightgbm.basic.Dataset.__init_from_seqs(self,seqs:List[Sequence],ref_dataset:Optional['Dataset']=None)
lightgbm.basic.Dataset.__sample(self,seqs:List[Sequence],total_nrow:int)->Tuple[List[np.ndarray], List[np.ndarray]]
lightgbm.basic.Dataset._create_sample_indices(self,total_nrow:int)->np.ndarray
lightgbm.basic.Dataset._dump_text(self,filename)
lightgbm.basic.Dataset._free_handle(self)
lightgbm.basic.Dataset._init_from_ref_dataset(self,total_nrow:int,ref_dataset:'Dataset')->'Dataset'
lightgbm.basic.Dataset._init_from_sample(self,sample_data:List[np.ndarray],sample_indices:List[np.ndarray],sample_cnt:int,total_nrow:int)->'Dataset'
lightgbm.basic.Dataset._lazy_init(self,data,label=None,reference=None,weight=None,group=None,init_score=None,predictor=None,silent=False,feature_name='auto',categorical_feature='auto',params=None)
lightgbm.basic.Dataset._push_rows(self,data:np.ndarray)->'Dataset'
lightgbm.basic.Dataset._reverse_update_params(self)
lightgbm.basic.Dataset._set_init_score_by_predictor(self,predictor,data,used_indices=None)
lightgbm.basic.Dataset._set_predictor(self,predictor)
lightgbm.basic.Dataset._update_params(self,params)
lightgbm.basic.Dataset._yield_row_from_seqlist(seqs:List[Sequence],indices:Iterable[int])
lightgbm.basic.Dataset.add_features_from(self,other)
lightgbm.basic.Dataset.construct(self)
lightgbm.basic.Dataset.create_valid(self,data,label=None,weight=None,group=None,init_score=None,silent='warn',params=None)
lightgbm.basic.Dataset.get_data(self)
lightgbm.basic.Dataset.get_feature_name(self)
lightgbm.basic.Dataset.get_field(self,field_name)
lightgbm.basic.Dataset.get_group(self)
lightgbm.basic.Dataset.get_init_score(self)
lightgbm.basic.Dataset.get_label(self)
lightgbm.basic.Dataset.get_params(self)
lightgbm.basic.Dataset.get_ref_chain(self,ref_limit=100)
lightgbm.basic.Dataset.get_weight(self)
lightgbm.basic.Dataset.num_data(self)
lightgbm.basic.Dataset.num_feature(self)
lightgbm.basic.Dataset.save_binary(self,filename)
lightgbm.basic.Dataset.set_categorical_feature(self,categorical_feature)
lightgbm.basic.Dataset.set_feature_name(self,feature_name)
lightgbm.basic.Dataset.set_field(self,field_name,data)
lightgbm.basic.Dataset.set_group(self,group)
lightgbm.basic.Dataset.set_init_score(self,init_score)
lightgbm.basic.Dataset.set_label(self,label)
lightgbm.basic.Dataset.set_reference(self,reference)
lightgbm.basic.Dataset.set_weight(self,weight)
lightgbm.basic.Dataset.subset(self,used_indices,params=None)
lightgbm.basic.LGBMDeprecationWarning(UserWarning)
lightgbm.basic.LightGBMError(Exception)
lightgbm.basic.Sequence(abc.ABC)
lightgbm.basic.Sequence.__getitem__(self,idx:Union[int,slice,List[int]])->np.ndarray
lightgbm.basic.Sequence.__len__(self)->int
lightgbm.basic._ConfigAliases
lightgbm.basic._ConfigAliases.get(cls,*args)
lightgbm.basic._DummyLogger
lightgbm.basic._DummyLogger.info(self,msg:str)->None
lightgbm.basic._DummyLogger.warning(self,msg:str)->None
lightgbm.basic._InnerPredictor(self,model_file=None,booster_handle=None,pred_parameter=None)
lightgbm.basic._InnerPredictor.__create_sparse_native(self,cs,out_shape,out_ptr_indptr,out_ptr_indices,out_ptr_data,indptr_type,data_type,is_csr=True)
lightgbm.basic._InnerPredictor.__del__(self)
lightgbm.basic._InnerPredictor.__get_num_preds(self,start_iteration,num_iteration,nrow,predict_type)
lightgbm.basic._InnerPredictor.__getstate__(self)
lightgbm.basic._InnerPredictor.__init__(self,model_file=None,booster_handle=None,pred_parameter=None)
lightgbm.basic._InnerPredictor.__pred_for_csc(self,csc,start_iteration,num_iteration,predict_type)
lightgbm.basic._InnerPredictor.__pred_for_csr(self,csr,start_iteration,num_iteration,predict_type)
lightgbm.basic._InnerPredictor.__pred_for_np2d(self,mat,start_iteration,num_iteration,predict_type)
lightgbm.basic._InnerPredictor.current_iteration(self)
lightgbm.basic._InnerPredictor.predict(self,data,start_iteration=0,num_iteration=-1,raw_score=False,pred_leaf=False,pred_contrib=False,data_has_header=False,is_reshape=True)
lightgbm.basic._TempFile
lightgbm.basic._TempFile.__enter__(self)
lightgbm.basic._TempFile.__exit__(self,exc_type,exc_val,exc_tb)
lightgbm.basic._choose_param_value(main_param_name:str,params:Dict[str,Any],default_value:Any)->Dict[str, Any]
lightgbm.basic._data_from_pandas(data,feature_name,categorical_feature,pandas_categorical)
lightgbm.basic._data_to_2d_numpy(data:Any,dtype:type=np.float32,name:str='list')->np.ndarray
lightgbm.basic._dump_pandas_categorical(pandas_categorical,file_name=None)
lightgbm.basic._get_bad_pandas_dtypes(dtypes)
lightgbm.basic._get_sample_count(total_nrow:int,params:str)
lightgbm.basic._is_1d_collection(data:Any)->bool
lightgbm.basic._is_2d_collection(data:Any)->bool
lightgbm.basic._is_2d_list(data:Any)->bool
lightgbm.basic._is_numpy_2d_array(data:Any)->bool
lightgbm.basic._label_from_pandas(label)
lightgbm.basic._load_lib()
lightgbm.basic._load_pandas_categorical(file_name=None,model_str=None)
lightgbm.basic._log_callback(msg:bytes)->None
lightgbm.basic._log_info(msg:str)->None
lightgbm.basic._log_native(msg:str)->None
lightgbm.basic._log_warning(msg:str)->None
lightgbm.basic._normalize_native_string(func:Callable[[str],None])->Callable[[str], None]
lightgbm.basic._safe_call(ret:int)->None
lightgbm.basic.c_array(ctype,values)
lightgbm.basic.c_float_array(data)
lightgbm.basic.c_int_array(data)
lightgbm.basic.c_str(string)
lightgbm.basic.cast_numpy_array_to_dtype(array,dtype)
lightgbm.basic.cfloat32_array_to_numpy(cptr,length)
lightgbm.basic.cfloat64_array_to_numpy(cptr,length)
lightgbm.basic.cint32_array_to_numpy(cptr,length)
lightgbm.basic.cint64_array_to_numpy(cptr,length)
lightgbm.basic.convert_from_sliced_object(data)
lightgbm.basic.is_1d_list(data)
lightgbm.basic.is_numeric(obj)
lightgbm.basic.is_numpy_1d_array(data)
lightgbm.basic.is_numpy_column_array(data)
lightgbm.basic.json_default_with_numpy(obj)
lightgbm.basic.list_to_1d_numpy(data,dtype=np.float32,name='list')
lightgbm.basic.param_dict_to_str(data)
lightgbm.basic.register_logger(logger:Logger)->None
lightgbm.register_logger(logger:Logger)->None


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/compat.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/libpath.py----------------------------------------
A:lightgbm.libpath.dll_path_joined->'\n'.join(map(str, dll_path))
lightgbm.libpath.find_lib_path()->List[str]


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/callback.py----------------------------------------
A:lightgbm.callback.CallbackEnv->collections.namedtuple('CallbackEnv', ['model', 'params', 'iteration', 'begin_iteration', 'end_iteration', 'evaluation_result_list'])
A:lightgbm.callback.result->'\t'.join([_format_eval_result(x, show_stdv) for x in env.evaluation_result_list])
A:lightgbm.callback.new_param->value(env.iteration - env.begin_iteration)
A:lightgbm.callback.best_score_str->'\t'.join([_format_eval_result(x) for x in best_score_list[i]])
A:lightgbm.callback.eval_name_splitted->env.evaluation_result_list[i][1].split(' ')
A:lightgbm.callback.eval_result_str->'\t'.join([_format_eval_result(x) for x in best_score_list[i]])
lightgbm.callback.EarlyStopException(self,best_iteration:int,best_score:float)
lightgbm.callback.EarlyStopException.__init__(self,best_iteration:int,best_score:float)
lightgbm.callback._format_eval_result(value:list,show_stdv:bool=True)->str
lightgbm.callback.early_stopping(stopping_rounds:int,first_metric_only:bool=False,verbose:bool=True)->Callable
lightgbm.callback.log_evaluation(period:int=1,show_stdv:bool=True)->Callable
lightgbm.callback.print_evaluation(period:int=1,show_stdv:bool=True)->Callable
lightgbm.callback.record_evaluation(eval_result:Dict[str,Dict[str,List[Any]]])->Callable
lightgbm.callback.reset_parameter(**kwargs:Union[list,Callable])->Callable
lightgbm.early_stopping(stopping_rounds:int,first_metric_only:bool=False,verbose:bool=True)->Callable
lightgbm.log_evaluation(period:int=1,show_stdv:bool=True)->Callable
lightgbm.print_evaluation(period:int=1,show_stdv:bool=True)->Callable
lightgbm.record_evaluation(eval_result:Dict[str,Dict[str,List[Any]]])->Callable
lightgbm.reset_parameter(**kwargs:Union[list,Callable])->Callable


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm3.3.5/lib/python3.6/site-packages/lightgbm/plotting.py----------------------------------------
A:lightgbm.plotting.importance->booster.feature_importance(importance_type=importance_type)
A:lightgbm.plotting.feature_name->booster.feature_name()
A:lightgbm.plotting.tuples->sorted(zip(feature_name, importance), key=lambda x: x[1])
A:lightgbm.plotting.(labels, values)->zip(*tuples)
A:lightgbm.plotting.(_, ax)->matplotlib.pyplot.subplots(1, 1, figsize=figsize, dpi=dpi)
A:lightgbm.plotting.ylocs->numpy.arange(len(values))
A:lightgbm.plotting.xlabel->xlabel.replace('@importance_type@', importance_type).replace('@importance_type@', importance_type)
A:lightgbm.plotting.(hist, bins)->booster.get_split_value_histogram(feature=feature, bins=bins, xgboost_style=False)
A:lightgbm.plotting.title->title.replace('@index/name@', 'name' if isinstance(feature, str) else 'index').replace('@index/name@', 'name' if isinstance(feature, str) else 'index')
A:lightgbm.plotting.eval_results->deepcopy(booster)
A:lightgbm.plotting.num_data->len(eval_results)
A:lightgbm.plotting.dataset_names->iter(dataset_names)
A:lightgbm.plotting.name->next(dataset_names)
A:lightgbm.plotting.num_metric->len(metrics_for_one)
A:lightgbm.plotting.(metric, results)->metrics_for_one.popitem()
A:lightgbm.plotting.num_iteration->len(results)
A:lightgbm.plotting.max_result->max(max(results), max_result)
A:lightgbm.plotting.min_result->min(min(results), min_result)
A:lightgbm.plotting.x_->range(num_iteration)
A:lightgbm.plotting.ylabel->ylabel.replace('@metric@', metric).replace('@metric@', metric)
A:lightgbm.plotting.graph->create_tree_digraph(booster=booster, tree_index=tree_index, show_info=show_info, precision=precision, orientation=orientation, **kwargs)
A:lightgbm.plotting.model->booster.dump_model()
A:lightgbm.plotting.monotone_constraints->booster.dump_model().get('monotone_constraints', None)
A:lightgbm.plotting.s->BytesIO()
A:lightgbm.plotting.img->matplotlib.image.imread(s)
lightgbm.create_tree_digraph(booster:Union[Booster,LGBMModel],tree_index:int=0,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',**kwargs:Any)->Any
lightgbm.plot_importance(booster:Union[Booster,LGBMModel],ax=None,height:float=0.2,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Featureimportance',xlabel:Optional[str]='Featureimportance',ylabel:Optional[str]='Features',importance_type:str='auto',max_num_features:Optional[int]=None,ignore_zero:bool=True,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,precision:Optional[int]=3,**kwargs:Any)->Any
lightgbm.plot_metric(booster:Union[Dict,LGBMModel],metric:Optional[str]=None,dataset_names:Optional[List[str]]=None,ax=None,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Metricduringtraining',xlabel:Optional[str]='Iterations',ylabel:Optional[str]='@metric@',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True)->Any
lightgbm.plot_split_value_histogram(booster:Union[Booster,LGBMModel],feature:Union[int,str],bins:Union[int,str,None]=None,ax=None,width_coef:float=0.8,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Splitvaluehistogramforfeaturewith@index/name@@feature@',xlabel:Optional[str]='Featuresplitvalue',ylabel:Optional[str]='Count',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,**kwargs:Any)->Any
lightgbm.plot_tree(booster:Union[Booster,LGBMModel],ax=None,tree_index:int=0,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',**kwargs:Any)->Any
lightgbm.plotting._check_not_tuple_of_2_elements(obj:Any,obj_name:str='obj')->None
lightgbm.plotting._float2str(value:float,precision:Optional[int]=None)->str
lightgbm.plotting._to_graphviz(tree_info:Dict[str,Any],show_info:List[str],feature_names:Union[List[str],None],precision:Optional[int]=3,orientation:str='horizontal',constraints:Optional[List[int]]=None,**kwargs:Any)->Any
lightgbm.plotting.create_tree_digraph(booster:Union[Booster,LGBMModel],tree_index:int=0,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',**kwargs:Any)->Any
lightgbm.plotting.plot_importance(booster:Union[Booster,LGBMModel],ax=None,height:float=0.2,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Featureimportance',xlabel:Optional[str]='Featureimportance',ylabel:Optional[str]='Features',importance_type:str='auto',max_num_features:Optional[int]=None,ignore_zero:bool=True,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,precision:Optional[int]=3,**kwargs:Any)->Any
lightgbm.plotting.plot_metric(booster:Union[Dict,LGBMModel],metric:Optional[str]=None,dataset_names:Optional[List[str]]=None,ax=None,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Metricduringtraining',xlabel:Optional[str]='Iterations',ylabel:Optional[str]='@metric@',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True)->Any
lightgbm.plotting.plot_split_value_histogram(booster:Union[Booster,LGBMModel],feature:Union[int,str],bins:Union[int,str,None]=None,ax=None,width_coef:float=0.8,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Splitvaluehistogramforfeaturewith@index/name@@feature@',xlabel:Optional[str]='Featuresplitvalue',ylabel:Optional[str]='Count',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,**kwargs:Any)->Any
lightgbm.plotting.plot_tree(booster:Union[Booster,LGBMModel],ax=None,tree_index:int=0,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',**kwargs:Any)->Any

