
----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/__init__.py----------------------------------------
A:lightgbm.__init__.__version__->_version_path.read_text(encoding='utf-8').strip()


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/dask.py----------------------------------------
A:lightgbm.dask.self.socket->socket.socket(socket.AF_INET, socket.SOCK_STREAM)
A:lightgbm.dask.s->_RemoteSocket()
A:lightgbm.dask.port->_RemoteSocket().acquire()
A:lightgbm.dask.TRAINSET->auto()
A:lightgbm.dask.SAMPLE_WEIGHT->auto()
A:lightgbm.dask.INIT_SCORE->auto()
A:lightgbm.dask.GROUP->auto()
A:lightgbm.dask.worker_to_future[worker]->self.__dict__.pop('client', None).submit(_acquire_port, workers=[worker], allow_other_workers=False, pure=False)
A:lightgbm.dask.worker_to_socket_future[worker]->self.__dict__.pop('client', None).submit(operator.itemgetter(0), socket_future)
A:lightgbm.dask.worker_to_port_future[worker]->self.__dict__.pop('client', None).submit(operator.itemgetter(1), socket_future)
A:lightgbm.dask.worker_to_port->self.__dict__.pop('client', None).gather(worker_to_port_future)
A:lightgbm.dask.is_ranker->issubclass(model_factory, LGBMRanker)
A:lightgbm.dask.data->_concat([x['data'] for x in list_of_parts])
A:lightgbm.dask.label->_concat([x['label'] for x in list_of_parts])
A:lightgbm.dask.weight->_concat([x['weight'] for x in list_of_parts])
A:lightgbm.dask.group->_concat([x['group'] for x in list_of_parts])
A:lightgbm.dask.init_score->_concat([x['init_score'] for x in list_of_parts])
A:lightgbm.dask.n_evals->max((len(x.get('eval_set', [])) for x in list_of_parts))
A:lightgbm.dask.eval_names->kwargs.pop('eval_names', None)
A:lightgbm.dask.eval_class_weight->kwargs.get('eval_class_weight')
A:lightgbm.dask.has_eval_sample_weight->any((x.get('eval_sample_weight') is not None for x in list_of_parts))
A:lightgbm.dask.has_eval_init_score->any((x.get('eval_init_score') is not None for x in list_of_parts))
A:lightgbm.dask.eval_weight->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta).get('eval_sample_weight')
A:lightgbm.dask.eval_init_score->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta).get('eval_init_score')
A:lightgbm.dask.eval_group->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta).get('eval_group')
A:lightgbm.dask.(x_e, y_e, w_e, init_score_e, g_e)->_remove_list_padding(x_e, y_e, w_e, init_score_e, g_e)
A:lightgbm.dask.model->model_factory(**params)
A:lightgbm.dask.parts->self.__dict__.pop('client', None).compute(parts)
A:lightgbm.dask.machine_addresses->','.join([f'{urlparse(worker_address).hostname}:{port}' for (worker_address, port) in worker_address_to_port.items()]).split(',')
A:lightgbm.dask.machine_to_port->defaultdict(set)
A:lightgbm.dask.(host, port)->address.split(':')
A:lightgbm.dask.out[address]->machine_to_port[worker_host].pop()
A:lightgbm.dask.params->source.get_params()
A:lightgbm.dask.listen_port_in_params->any((alias in params for alias in _ConfigAliases.get('local_listen_port')))
A:lightgbm.dask.machines_in_params->any((alias in params for alias in _ConfigAliases.get('machines')))
A:lightgbm.dask.data_parts->_split_to_parts(data=data, is_matrix=True)
A:lightgbm.dask.label_parts->_split_to_parts(data=label, is_matrix=False)
A:lightgbm.dask.n_parts->len(parts)
A:lightgbm.dask.weight_parts->_split_to_parts(data=sample_weight, is_matrix=False)
A:lightgbm.dask.group_parts->_split_to_parts(data=group, is_matrix=False)
A:lightgbm.dask.init_score_parts->_split_to_parts(data=init_score, is_matrix=False)
A:lightgbm.dask.n_largest_eval_parts->max((x[0].npartitions for x in eval_set))
A:lightgbm.dask.eval_x_parts->_split_to_parts(data=X_eval, is_matrix=True)
A:lightgbm.dask.eval_y_parts->_split_to_parts(data=y_eval, is_matrix=False)
A:lightgbm.dask.eval_w_parts->_split_to_parts(data=eval_sample_weight[i], is_matrix=False)
A:lightgbm.dask.eval_init_score_parts->_split_to_parts(data=eval_init_score[i], is_matrix=False)
A:lightgbm.dask.eval_g_parts->_split_to_parts(data=eval_group[i], is_matrix=False)
A:lightgbm.dask.who_has->self.__dict__.pop('client', None).who_has(parts)
A:lightgbm.dask.worker_map->defaultdict(list)
A:lightgbm.dask.master_worker->next(iter(worker_map))
A:lightgbm.dask.worker_ncores->self.__dict__.pop('client', None).ncores()
A:lightgbm.dask.local_listen_port->source.get_params().pop('local_listen_port')
A:lightgbm.dask.machines->','.join([f'{urlparse(worker_address).hostname}:{port}' for (worker_address, port) in worker_address_to_port.items()])
A:lightgbm.dask.worker_addresses->defaultdict(list).keys()
A:lightgbm.dask.worker_address_to_port->_machines_to_worker_map(machines=machines, worker_addresses=worker_addresses)
A:lightgbm.dask.(worker_to_socket_future, worker_address_to_port)->_assign_open_ports_to_workers(client, list(worker_map.keys()))
A:lightgbm.dask.num_machines->len(worker_address_to_port)
A:lightgbm.dask.results->self.__dict__.pop('client', None).gather(futures_classifiers)
A:lightgbm.dask.result->pd_Series(result, index=part.index, name='predictions')
A:lightgbm.dask.predict_function->partial(_predict_part, model=model, raw_score=False, pred_proba=pred_proba, pred_leaf=False, pred_contrib=True, **kwargs)
A:lightgbm.dask.delayed_chunks->_concat([x['data'] for x in list_of_parts]).to_delayed()
A:lightgbm.dask.bag->dask_bag_from_delayed(delayed_chunks[:, 0])
A:lightgbm.dask.preds->dask_bag_from_delayed(delayed_chunks[:, 0]).map_partitions(predict_function)
A:lightgbm.dask.part->dask_array_from_delayed(value=_extract(partition, i), shape=(nrows_per_chunk[j], num_cols), meta=pred_meta)
A:lightgbm.dask.concat_fn->partial(ss.vstack, format='csc')
A:lightgbm.dask.data_row->self.__dict__.pop('client', None).compute(data[[0]]).result()
A:lightgbm.dask.predict_fn->partial(_predict_part, model=model, raw_score=raw_score, pred_proba=pred_proba, pred_leaf=pred_leaf, pred_contrib=pred_contrib, **kwargs)
A:lightgbm.dask.pred_row->predict_fn(data_row)
A:lightgbm.dask.client->self.__dict__.pop('client', None)
A:lightgbm.dask.out->deepcopy(self.__dict__)
A:lightgbm.dask.extra_param_names->set(attributes.keys()).difference(params.keys())
A:lightgbm.dask.(_before_kwargs, _kwargs, _after_kwargs)->sklearn._lgbmmodel_doc_fit.format(X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', y_shape='Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]', sample_weight_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', init_score_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', group_shape='Dask Array or Dask Series or None, optional (default=None)', eval_sample_weight_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_init_score_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_group_shape='list of Dask Array or Dask Series, or None, optional (default=None)').partition('**kwargs')
A:lightgbm.dask._base_doc->sklearn._lgbmmodel_doc_fit.format(X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', y_shape='Dask Array, Dask DataFrame or Dask Series of shape = [n_samples]', sample_weight_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', init_score_shape='Dask Array or Dask Series of shape = [n_samples] or None, optional (default=None)', group_shape='Dask Array or Dask Series or None, optional (default=None)', eval_sample_weight_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_init_score_shape='list of Dask Array or Dask Series, or None, optional (default=None)', eval_group_shape='list of Dask Array or Dask Series, or None, optional (default=None)')
A:lightgbm.dask.predict.__doc__->sklearn._lgbmmodel_doc_predict.format(description='Return the predicted value for each sample.', X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', output_name='predicted_result', predicted_result_shape='Dask Array of shape = [n_samples]', X_leaves_shape='Dask Array of shape = [n_samples, n_trees]', X_SHAP_values_shape='Dask Array of shape = [n_samples, n_features + 1]')
A:lightgbm.dask.predict_proba.__doc__->sklearn._lgbmmodel_doc_predict.format(description='Return the predicted probability for each class for each sample.', X_shape='Dask Array or Dask DataFrame of shape = [n_samples, n_features]', output_name='predicted_probability', predicted_result_shape='Dask Array of shape = [n_samples] or shape = [n_samples, n_classes]', X_leaves_shape='Dask Array of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]', X_SHAP_values_shape='Dask Array of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or (if multi-class and using sparse inputs) a list of ``n_classes`` Dask Arrays of shape = [n_samples, n_features + 1]')
lightgbm.DaskLGBMClassifier(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.DaskLGBMClassifier.__getstate__(self)->Dict[Any, Any]
lightgbm.DaskLGBMClassifier.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,**kwargs:Any)->'DaskLGBMClassifier'
lightgbm.DaskLGBMClassifier.predict(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMClassifier.predict_proba(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMClassifier.to_local(self)->LGBMClassifier
lightgbm.DaskLGBMRanker(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.DaskLGBMRanker.__getstate__(self)->Dict[Any, Any]
lightgbm.DaskLGBMRanker.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,eval_at:Union[List[int],Tuple[int,...]]=(1,2,3,4,5),**kwargs:Any)->'DaskLGBMRanker'
lightgbm.DaskLGBMRanker.predict(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMRanker.to_local(self)->LGBMRanker
lightgbm.DaskLGBMRegressor(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.DaskLGBMRegressor.__getstate__(self)->Dict[Any, Any]
lightgbm.DaskLGBMRegressor.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,**kwargs:Any)->'DaskLGBMRegressor'
lightgbm.DaskLGBMRegressor.predict(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.DaskLGBMRegressor.to_local(self)->LGBMRegressor
lightgbm.dask.DaskLGBMClassifier(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMClassifier.__getstate__(self)->Dict[Any, Any]
lightgbm.dask.DaskLGBMClassifier.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMClassifier.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,**kwargs:Any)->'DaskLGBMClassifier'
lightgbm.dask.DaskLGBMClassifier.predict(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMClassifier.predict_proba(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMClassifier.to_local(self)->LGBMClassifier
lightgbm.dask.DaskLGBMRanker(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRanker.__getstate__(self)->Dict[Any, Any]
lightgbm.dask.DaskLGBMRanker.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRanker.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,eval_at:Union[List[int],Tuple[int,...]]=(1,2,3,4,5),**kwargs:Any)->'DaskLGBMRanker'
lightgbm.dask.DaskLGBMRanker.predict(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMRanker.to_local(self)->LGBMRanker
lightgbm.dask.DaskLGBMRegressor(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRegressor.__getstate__(self)->Dict[Any, Any]
lightgbm.dask.DaskLGBMRegressor.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,'np.random.Generator']]=None,n_jobs:Optional[int]=None,importance_type:str='split',client:Optional[Client]=None,**kwargs:Any)
lightgbm.dask.DaskLGBMRegressor.fit(self,X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_init_score:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,**kwargs:Any)->'DaskLGBMRegressor'
lightgbm.dask.DaskLGBMRegressor.predict(self,X:_DaskMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)->dask_Array
lightgbm.dask.DaskLGBMRegressor.to_local(self)->LGBMRegressor
lightgbm.dask._DaskLGBMModel
lightgbm.dask._DaskLGBMModel._lgb_dask_copy_extra_params(source:Union['_DaskLGBMModel',LGBMModel],dest:Union['_DaskLGBMModel',LGBMModel])->None
lightgbm.dask._DaskLGBMModel._lgb_dask_fit(self,model_factory:Type[LGBMModel],X:_DaskMatrixLike,y:_DaskCollection,sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,eval_at:Optional[Union[List[int],Tuple[int,...]]]=None,**kwargs:Any)->'_DaskLGBMModel'
lightgbm.dask._DaskLGBMModel._lgb_dask_getstate(self)->Dict[Any, Any]
lightgbm.dask._DaskLGBMModel._lgb_dask_to_local(self,model_factory:Type[LGBMModel])->LGBMModel
lightgbm.dask._DaskLGBMModel.client_(self)->Client
lightgbm.dask._DatasetNames(Enum)
lightgbm.dask._RemoteSocket
lightgbm.dask._RemoteSocket.acquire(self)->int
lightgbm.dask._RemoteSocket.release(self)->None
lightgbm.dask._acquire_port()->Tuple[_RemoteSocket, int]
lightgbm.dask._assign_open_ports_to_workers(client:Client,workers:List[str])->Tuple[Dict[str, Future], Dict[str, int]]
lightgbm.dask._concat(seq:List[_DaskPart])->_DaskPart
lightgbm.dask._get_dask_client(client:Optional[Client])->Client
lightgbm.dask._machines_to_worker_map(machines:str,worker_addresses:Iterable[str])->Dict[str, int]
lightgbm.dask._pad_eval_names(lgbm_model:LGBMModel,required_names:List[str])->LGBMModel
lightgbm.dask._predict(model:LGBMModel,data:_DaskMatrixLike,client:Client,raw_score:bool=False,pred_proba:bool=False,pred_leaf:bool=False,pred_contrib:bool=False,dtype:_PredictionDtype=np.float32,**kwargs:Any)->Union[dask_Array, List[dask_Array]]
lightgbm.dask._predict_part(part:_DaskPart,model:LGBMModel,raw_score:bool,pred_proba:bool,pred_leaf:bool,pred_contrib:bool,**kwargs:Any)->_DaskPart
lightgbm.dask._remove_list_padding(*args:Any)->List[List[Any]]
lightgbm.dask._split_to_parts(data:_DaskCollection,is_matrix:bool)->List[_DaskPart]
lightgbm.dask._train(client:Client,data:_DaskMatrixLike,label:_DaskCollection,params:Dict[str,Any],model_factory:Type[LGBMModel],sample_weight:Optional[_DaskVectorLike]=None,init_score:Optional[_DaskCollection]=None,group:Optional[_DaskVectorLike]=None,eval_set:Optional[List[Tuple[_DaskMatrixLike,_DaskCollection]]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_DaskVectorLike]]=None,eval_class_weight:Optional[List[Union[dict,str]]]=None,eval_init_score:Optional[List[_DaskCollection]]=None,eval_group:Optional[List[_DaskVectorLike]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,eval_at:Optional[Union[List[int],Tuple[int,...]]]=None,**kwargs:Any)->LGBMModel
lightgbm.dask._train_part(params:Dict[str,Any],model_factory:Type[LGBMModel],list_of_parts:List[Dict[str,_DaskPart]],machines:str,local_listen_port:int,num_machines:int,return_model:bool,time_out:int,remote_socket:_RemoteSocket,**kwargs:Any)->Optional[LGBMModel]


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/engine.py----------------------------------------
A:lightgbm.engine.params->_choose_param_value(main_param_name='early_stopping_round', params=params, default_value=None)
A:lightgbm.engine.num_boost_round->_choose_param_value(main_param_name='early_stopping_round', params=params, default_value=None).pop(alias)
A:lightgbm.engine.first_metric_only->_choose_param_value(main_param_name='early_stopping_round', params=params, default_value=None).get('first_metric_only', False)
A:lightgbm.engine.predictor->basic._InnerPredictor.from_booster(booster=init_model, pred_parameter=dict(init_model.params, **params))
A:lightgbm.engine.init_iteration->basic._InnerPredictor.from_booster(booster=init_model, pred_parameter=dict(init_model.params, **params)).current_iteration()
A:lightgbm.engine.callbacks_set->set(callbacks)
A:lightgbm.engine.callbacks_before_iter->sorted(callbacks_before_iter_set, key=attrgetter('order'))
A:lightgbm.engine.callbacks_after_iter->sorted(callbacks_after_iter_set, key=attrgetter('order'))
A:lightgbm.engine.booster->Booster(params=params, train_set=train_set)
A:lightgbm.engine.booster.best_score->defaultdict(OrderedDict)
A:lightgbm.engine.full_data->full_data.construct().construct()
A:lightgbm.engine.num_data->full_data.construct().construct().num_data()
A:lightgbm.engine.group_info->numpy.asarray(full_data.get_group(), dtype=np.int32)
A:lightgbm.engine.flatted_group->numpy.repeat(range(len(group_info)), repeats=group_info)
A:lightgbm.engine.folds->zip(train_id, test_id)
A:lightgbm.engine.group_kfold->_LGBMGroupKFold(n_splits=nfold)
A:lightgbm.engine.skf->_LGBMStratifiedKFold(n_splits=nfold, shuffle=shuffle, random_state=seed)
A:lightgbm.engine.randidx->numpy.arange(num_data)
A:lightgbm.engine.kstep->int(num_data / nfold)
A:lightgbm.engine.ret->CVBooster()
A:lightgbm.engine.train_set->full_data.construct().construct().subset(sorted(train_idx))
A:lightgbm.engine.valid_set->full_data.construct().construct().subset(sorted(test_idx))
A:lightgbm.engine.(train_set, valid_set, tparam)->fpreproc(train_set, valid_set, params.copy())
A:lightgbm.engine.booster_for_fold->Booster(tparam, train_set)
A:lightgbm.engine.results->defaultdict(list)
A:lightgbm.engine.cvfolds->_make_n_folds(full_data=train_set, folds=folds, nfold=nfold, params=params, seed=seed, fpreproc=fpreproc, stratified=stratified, shuffle=shuffle, eval_train_metric=eval_train_metric)
A:lightgbm.engine.res->_agg_cv_result(cvfolds.eval_valid(feval))
lightgbm.CVBooster(self,model_file:Optional[Union[str,Path]]=None)
lightgbm.CVBooster.__getattr__(self,name:str)->Callable[[Any, Any], List[Any]]
lightgbm.CVBooster.__getstate__(self)->Dict[str, Any]
lightgbm.CVBooster.__setstate__(self,state:Dict[str,Any])->None
lightgbm.CVBooster._from_dict(self,models:Dict[str,Any])->None
lightgbm.CVBooster._to_dict(self,num_iteration:Optional[int],start_iteration:int,importance_type:str)->Dict[str, Any]
lightgbm.CVBooster.model_from_string(self,model_str:str)->'CVBooster'
lightgbm.CVBooster.model_to_string(self,num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->str
lightgbm.CVBooster.save_model(self,filename:Union[str,Path],num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->'CVBooster'
lightgbm.cv(params:Dict[str,Any],train_set:Dataset,num_boost_round:int=100,folds:Optional[Union[Iterable[Tuple[np.ndarray,np.ndarray]],_LGBMBaseCrossValidator]]=None,nfold:int=5,stratified:bool=True,shuffle:bool=True,metrics:Optional[Union[str,List[str]]]=None,feval:Optional[Union[_LGBM_CustomMetricFunction,List[_LGBM_CustomMetricFunction]]]=None,init_model:Optional[Union[str,Path,Booster]]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',fpreproc:Optional[_LGBM_PreprocFunction]=None,seed:int=0,callbacks:Optional[List[Callable]]=None,eval_train_metric:bool=False,return_cvbooster:bool=False)->Dict[str, Union[List[float], CVBooster]]
lightgbm.engine.CVBooster(self,model_file:Optional[Union[str,Path]]=None)
lightgbm.engine.CVBooster.__getattr__(self,name:str)->Callable[[Any, Any], List[Any]]
lightgbm.engine.CVBooster.__getstate__(self)->Dict[str, Any]
lightgbm.engine.CVBooster.__init__(self,model_file:Optional[Union[str,Path]]=None)
lightgbm.engine.CVBooster.__setstate__(self,state:Dict[str,Any])->None
lightgbm.engine.CVBooster._from_dict(self,models:Dict[str,Any])->None
lightgbm.engine.CVBooster._to_dict(self,num_iteration:Optional[int],start_iteration:int,importance_type:str)->Dict[str, Any]
lightgbm.engine.CVBooster.model_from_string(self,model_str:str)->'CVBooster'
lightgbm.engine.CVBooster.model_to_string(self,num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->str
lightgbm.engine.CVBooster.save_model(self,filename:Union[str,Path],num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->'CVBooster'
lightgbm.engine._agg_cv_result(raw_results:List[List[_LGBM_BoosterEvalMethodResultType]])->List[_LGBM_BoosterEvalMethodResultWithStandardDeviationType]
lightgbm.engine._emit_dataset_kwarg_warning(calling_function:str,argname:str)->None
lightgbm.engine._make_n_folds(full_data:Dataset,folds:Optional[Union[Iterable[Tuple[np.ndarray,np.ndarray]],_LGBMBaseCrossValidator]],nfold:int,params:Dict[str,Any],seed:int,fpreproc:Optional[_LGBM_PreprocFunction],stratified:bool,shuffle:bool,eval_train_metric:bool)->CVBooster
lightgbm.engine.cv(params:Dict[str,Any],train_set:Dataset,num_boost_round:int=100,folds:Optional[Union[Iterable[Tuple[np.ndarray,np.ndarray]],_LGBMBaseCrossValidator]]=None,nfold:int=5,stratified:bool=True,shuffle:bool=True,metrics:Optional[Union[str,List[str]]]=None,feval:Optional[Union[_LGBM_CustomMetricFunction,List[_LGBM_CustomMetricFunction]]]=None,init_model:Optional[Union[str,Path,Booster]]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',fpreproc:Optional[_LGBM_PreprocFunction]=None,seed:int=0,callbacks:Optional[List[Callable]]=None,eval_train_metric:bool=False,return_cvbooster:bool=False)->Dict[str, Union[List[float], CVBooster]]
lightgbm.engine.train(params:Dict[str,Any],train_set:Dataset,num_boost_round:int=100,valid_sets:Optional[List[Dataset]]=None,valid_names:Optional[List[str]]=None,feval:Optional[Union[_LGBM_CustomMetricFunction,List[_LGBM_CustomMetricFunction]]]=None,init_model:Optional[Union[str,Path,Booster]]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',keep_training_booster:bool=False,callbacks:Optional[List[Callable]]=None)->Booster
lightgbm.train(params:Dict[str,Any],train_set:Dataset,num_boost_round:int=100,valid_sets:Optional[List[Dataset]]=None,valid_names:Optional[List[str]]=None,feval:Optional[Union[_LGBM_CustomMetricFunction,List[_LGBM_CustomMetricFunction]]]=None,init_model:Optional[Union[str,Path,Booster]]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',keep_training_booster:bool=False,callbacks:Optional[List[Callable]]=None)->Booster


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/sklearn.py----------------------------------------
A:lightgbm.sklearn.group->_get_group_from_constructed_dataset(dataset)
A:lightgbm.sklearn.label->dataset.get_label()
A:lightgbm.sklearn.weight->_get_weight_from_constructed_dataset(dataset)
A:lightgbm.sklearn.labels->_get_label_from_constructed_dataset(dataset)
A:lightgbm.sklearn.argc->len(signature(self.func).parameters)
A:lightgbm.sklearn.(grad, hess)->self.func(labels, preds, weight)
A:lightgbm.sklearn.params->self._process_params(stage='fit')
A:lightgbm.sklearn.obj->self._process_params(stage='fit').pop(alias)
A:lightgbm.sklearn.params['objective']->_ObjectiveFunctionWrapper(self._objective)
A:lightgbm.sklearn.params['random_state']->int(params['random_state'].integers(np.iinfo(np.int32).max))
A:lightgbm.sklearn.eval_at->self._process_params(stage='fit').pop(alias)
A:lightgbm.sklearn.params['num_threads']->self._process_n_jobs(params['num_threads'])
A:lightgbm.sklearn.n_jobs->max(_LGBMCpuCount(only_physical_cores=False) + 1 + n_jobs, 1)
A:lightgbm.sklearn.eval_metric_list->copy.deepcopy(eval_metric)
A:lightgbm.sklearn.(_X, _y)->_LGBMCheckXY(X, y, accept_sparse=True, force_all_finite=False, ensure_min_samples=2)
A:lightgbm.sklearn.sample_weight->numpy.multiply(sample_weight, class_sample_weight)
A:lightgbm.sklearn.class_sample_weight->_LGBMComputeSampleWeight(self._class_weight, y)
A:lightgbm.sklearn.train_set->Dataset(data=_X, label=_y, weight=sample_weight, group=group, init_score=init_score, categorical_feature=categorical_feature, feature_name=feature_name, params=params)
A:lightgbm.sklearn.valid_weight->numpy.multiply(valid_weight, valid_class_sample_weight)
A:lightgbm.sklearn.valid_class_weight->_extract_evaluation_meta_data(collection=eval_class_weight, name='eval_class_weight', i=i)
A:lightgbm.sklearn.valid_class_sample_weight->_LGBMComputeSampleWeight(valid_class_weight, valid_data[1])
A:lightgbm.sklearn.valid_init_score->_extract_evaluation_meta_data(collection=eval_init_score, name='eval_init_score', i=i)
A:lightgbm.sklearn.valid_group->_extract_evaluation_meta_data(collection=eval_group, name='eval_group', i=i)
A:lightgbm.sklearn.valid_set->Dataset(data=valid_data[0], label=valid_data[1], weight=valid_weight, group=valid_group, init_score=valid_init_score, categorical_feature='auto', params=params)
A:lightgbm.sklearn.callbacks->copy.copy(callbacks)
A:lightgbm.sklearn.self._Booster->train(params=params, train_set=train_set, num_boost_round=self.n_estimators, valid_sets=valid_sets, valid_names=eval_names, feval=eval_metrics_callable, init_model=init_model, callbacks=callbacks)
A:lightgbm.sklearn.X->_LGBMCheckArray(X, accept_sparse=True, force_all_finite=False)
A:lightgbm.sklearn.predict_params->_choose_param_value('num_threads', predict_params, self.n_jobs)
A:lightgbm.sklearn.predict_params['num_threads']->self._process_n_jobs(predict_params['num_threads'])
A:lightgbm.sklearn.predict.__doc__->_lgbmmodel_doc_predict.format(description='Return the predicted value for each sample.', X_shape="numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]", output_name='predicted_result', predicted_result_shape='array-like of shape = [n_samples] or shape = [n_samples, n_classes]', X_leaves_shape='array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]', X_SHAP_values_shape='array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects')
A:lightgbm.sklearn._base_doc->LGBMModel.fit.__doc__.replace('self : LGBMModel', 'self : LGBMRanker')
A:lightgbm.sklearn.self._le->_LGBMLabelEncoder().fit(y)
A:lightgbm.sklearn._y->self._le.transform(y)
A:lightgbm.sklearn.self._class_map->dict(zip(self._le.classes_, self._le.transform(self._le.classes_)))
A:lightgbm.sklearn.self._n_classes->len(self._classes)
A:lightgbm.sklearn.result->super().predict(X=X, raw_score=raw_score, start_iteration=start_iteration, num_iteration=num_iteration, pred_leaf=pred_leaf, pred_contrib=pred_contrib, validate_features=validate_features, **kwargs)
A:lightgbm.sklearn.class_index->numpy.argmax(result, axis=1)
A:lightgbm.sklearn.predict_proba.__doc__->_lgbmmodel_doc_predict.format(description='Return the predicted probability for each class for each sample.', X_shape="numpy array, pandas DataFrame, H2O DataTable's Frame , scipy.sparse, list of lists of int or float of shape = [n_samples, n_features]", output_name='predicted_probability', predicted_result_shape='array-like of shape = [n_samples] or shape = [n_samples, n_classes]', X_leaves_shape='array-like of shape = [n_samples, n_trees] or shape = [n_samples, n_trees * n_classes]', X_SHAP_values_shape='array-like of shape = [n_samples, n_features + 1] or shape = [n_samples, (n_features + 1) * n_classes] or list with n_classes length of such objects')
A:lightgbm.sklearn.(_before_feature_name, _feature_name, _after_feature_name)->LGBMModel.fit.__doc__.replace('self : LGBMModel', 'self : LGBMRanker').partition('feature_name :')
lightgbm.LGBMClassifier(_LGBMClassifierBase,LGBMModel)
lightgbm.LGBMClassifier.__is_multiclass(self)->bool
lightgbm.LGBMClassifier.classes_(self)->np.ndarray
lightgbm.LGBMClassifier.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_class_weight:Optional[List[float]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,LGBMModel]]=None)->'LGBMClassifier'
lightgbm.LGBMClassifier.n_classes_(self)->int
lightgbm.LGBMClassifier.predict(self,X:_LGBM_ScikitMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)
lightgbm.LGBMClassifier.predict_proba(self,X:_LGBM_ScikitMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)
lightgbm.LGBMModel(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[Dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,np.random.Generator]]=None,n_jobs:Optional[int]=None,importance_type:str='split',**kwargs:Any)
lightgbm.LGBMModel.__sklearn_is_fitted__(self)->bool
lightgbm.LGBMModel._more_tags(self)->Dict[str, Any]
lightgbm.LGBMModel._process_n_jobs(self,n_jobs:Optional[int])->int
lightgbm.LGBMModel._process_params(self,stage:str)->Dict[str, Any]
lightgbm.LGBMModel.best_iteration_(self)->int
lightgbm.LGBMModel.best_score_(self)->_LGBM_BoosterBestScoreType
lightgbm.LGBMModel.booster_(self)->Booster
lightgbm.LGBMModel.evals_result_(self)->_EvalResultDict
lightgbm.LGBMModel.feature_importances_(self)->np.ndarray
lightgbm.LGBMModel.feature_name_(self)->List[str]
lightgbm.LGBMModel.feature_names_in_(self)->np.ndarray
lightgbm.LGBMModel.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,group:Optional[_LGBM_GroupType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_class_weight:Optional[List[float]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_group:Optional[List[_LGBM_GroupType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,'LGBMModel']]=None)->'LGBMModel'
lightgbm.LGBMModel.get_params(self,deep:bool=True)->Dict[str, Any]
lightgbm.LGBMModel.n_estimators_(self)->int
lightgbm.LGBMModel.n_features_(self)->int
lightgbm.LGBMModel.n_features_in_(self)->int
lightgbm.LGBMModel.n_iter_(self)->int
lightgbm.LGBMModel.objective_(self)->Union[str, _LGBM_ScikitCustomObjectiveFunction]
lightgbm.LGBMModel.predict(self,X:_LGBM_ScikitMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)
lightgbm.LGBMModel.set_params(self,**params:Any)->'LGBMModel'
lightgbm.LGBMRanker(LGBMModel)
lightgbm.LGBMRanker.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,group:Optional[_LGBM_GroupType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_group:Optional[List[_LGBM_GroupType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,eval_at:Union[List[int],Tuple[int,...]]=(1,2,3,4,5),feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,LGBMModel]]=None)->'LGBMRanker'
lightgbm.LGBMRegressor(_LGBMRegressorBase,LGBMModel)
lightgbm.LGBMRegressor.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,LGBMModel]]=None)->'LGBMRegressor'
lightgbm.sklearn.LGBMClassifier(_LGBMClassifierBase,LGBMModel)
lightgbm.sklearn.LGBMClassifier.__is_multiclass(self)->bool
lightgbm.sklearn.LGBMClassifier.classes_(self)->np.ndarray
lightgbm.sklearn.LGBMClassifier.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_class_weight:Optional[List[float]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,LGBMModel]]=None)->'LGBMClassifier'
lightgbm.sklearn.LGBMClassifier.n_classes_(self)->int
lightgbm.sklearn.LGBMClassifier.predict(self,X:_LGBM_ScikitMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)
lightgbm.sklearn.LGBMClassifier.predict_proba(self,X:_LGBM_ScikitMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)
lightgbm.sklearn.LGBMModel(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[Dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,np.random.Generator]]=None,n_jobs:Optional[int]=None,importance_type:str='split',**kwargs:Any)
lightgbm.sklearn.LGBMModel.__init__(self,boosting_type:str='gbdt',num_leaves:int=31,max_depth:int=-1,learning_rate:float=0.1,n_estimators:int=100,subsample_for_bin:int=200000,objective:Optional[Union[str,_LGBM_ScikitCustomObjectiveFunction]]=None,class_weight:Optional[Union[Dict,str]]=None,min_split_gain:float=0.0,min_child_weight:float=0.001,min_child_samples:int=20,subsample:float=1.0,subsample_freq:int=0,colsample_bytree:float=1.0,reg_alpha:float=0.0,reg_lambda:float=0.0,random_state:Optional[Union[int,np.random.RandomState,np.random.Generator]]=None,n_jobs:Optional[int]=None,importance_type:str='split',**kwargs:Any)
lightgbm.sklearn.LGBMModel.__sklearn_is_fitted__(self)->bool
lightgbm.sklearn.LGBMModel._more_tags(self)->Dict[str, Any]
lightgbm.sklearn.LGBMModel._process_n_jobs(self,n_jobs:Optional[int])->int
lightgbm.sklearn.LGBMModel._process_params(self,stage:str)->Dict[str, Any]
lightgbm.sklearn.LGBMModel.best_iteration_(self)->int
lightgbm.sklearn.LGBMModel.best_score_(self)->_LGBM_BoosterBestScoreType
lightgbm.sklearn.LGBMModel.booster_(self)->Booster
lightgbm.sklearn.LGBMModel.evals_result_(self)->_EvalResultDict
lightgbm.sklearn.LGBMModel.feature_importances_(self)->np.ndarray
lightgbm.sklearn.LGBMModel.feature_name_(self)->List[str]
lightgbm.sklearn.LGBMModel.feature_names_in_(self)->np.ndarray
lightgbm.sklearn.LGBMModel.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,group:Optional[_LGBM_GroupType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_class_weight:Optional[List[float]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_group:Optional[List[_LGBM_GroupType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,'LGBMModel']]=None)->'LGBMModel'
lightgbm.sklearn.LGBMModel.get_params(self,deep:bool=True)->Dict[str, Any]
lightgbm.sklearn.LGBMModel.n_estimators_(self)->int
lightgbm.sklearn.LGBMModel.n_features_(self)->int
lightgbm.sklearn.LGBMModel.n_features_in_(self)->int
lightgbm.sklearn.LGBMModel.n_iter_(self)->int
lightgbm.sklearn.LGBMModel.objective_(self)->Union[str, _LGBM_ScikitCustomObjectiveFunction]
lightgbm.sklearn.LGBMModel.predict(self,X:_LGBM_ScikitMatrixLike,raw_score:bool=False,start_iteration:int=0,num_iteration:Optional[int]=None,pred_leaf:bool=False,pred_contrib:bool=False,validate_features:bool=False,**kwargs:Any)
lightgbm.sklearn.LGBMModel.set_params(self,**params:Any)->'LGBMModel'
lightgbm.sklearn.LGBMRanker(LGBMModel)
lightgbm.sklearn.LGBMRanker.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,group:Optional[_LGBM_GroupType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_group:Optional[List[_LGBM_GroupType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,eval_at:Union[List[int],Tuple[int,...]]=(1,2,3,4,5),feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,LGBMModel]]=None)->'LGBMRanker'
lightgbm.sklearn.LGBMRegressor(_LGBMRegressorBase,LGBMModel)
lightgbm.sklearn.LGBMRegressor.fit(self,X:_LGBM_ScikitMatrixLike,y:_LGBM_LabelType,sample_weight:Optional[_LGBM_WeightType]=None,init_score:Optional[_LGBM_InitScoreType]=None,eval_set:Optional[List[_LGBM_ScikitValidSet]]=None,eval_names:Optional[List[str]]=None,eval_sample_weight:Optional[List[_LGBM_WeightType]]=None,eval_init_score:Optional[List[_LGBM_InitScoreType]]=None,eval_metric:Optional[_LGBM_ScikitEvalMetricType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',callbacks:Optional[List[Callable]]=None,init_model:Optional[Union[str,Path,Booster,LGBMModel]]=None)->'LGBMRegressor'
lightgbm.sklearn._EvalFunctionWrapper(self,func:_LGBM_ScikitCustomEvalFunction)
lightgbm.sklearn._EvalFunctionWrapper.__init__(self,func:_LGBM_ScikitCustomEvalFunction)
lightgbm.sklearn._ObjectiveFunctionWrapper(self,func:_LGBM_ScikitCustomObjectiveFunction)
lightgbm.sklearn._ObjectiveFunctionWrapper.__init__(self,func:_LGBM_ScikitCustomObjectiveFunction)
lightgbm.sklearn._extract_evaluation_meta_data(*,collection:Optional[Union[Dict[Any,Any],List[Any]]],name:str,i:int)->Optional[Any]
lightgbm.sklearn._get_group_from_constructed_dataset(dataset:Dataset)->Optional[np.ndarray]
lightgbm.sklearn._get_label_from_constructed_dataset(dataset:Dataset)->np.ndarray
lightgbm.sklearn._get_weight_from_constructed_dataset(dataset:Dataset)->Optional[np.ndarray]


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/basic.py----------------------------------------
A:lightgbm.basic.sample_cnt->_get_sample_count(total_nrow, param_str)
A:lightgbm.basic.msg->''.join(msg_normalized)
A:lightgbm.basic.lib_path->find_lib_path()
A:lightgbm.basic.lib->ctypes.cdll.LoadLibrary(lib_path[0])
A:lightgbm.basic.callback->ctypes.CFUNCTYPE(None, ctypes.c_char_p)
A:lightgbm.basic.lib.callback->callback(_log_callback)
A:lightgbm.basic._LIB->_load_lib()
A:lightgbm.basic.array->_list_to_1d_numpy(data, dtype=dtype, name=field_name).ravel()
A:lightgbm.basic.export_objects->_list_to_1d_numpy(data, dtype=dtype, name=field_name).to_batches()
A:lightgbm.basic.chunks->compat.arrow_cffi.new('struct ArrowArray[]', len(export_objects))
A:lightgbm.basic.schema->compat.arrow_cffi.new('struct ArrowSchema*')
A:lightgbm.basic.chunk_ptr->int(arrow_cffi.cast('uintptr_t', arrow_cffi.addressof(chunks[i])))
A:lightgbm.basic.schema_ptr->int(arrow_cffi.cast('uintptr_t', schema))
A:lightgbm.basic.val_list->','.join((str(val) for val in x))
A:lightgbm.basic.self.path->Path(self.name)
A:lightgbm.basic.tmp_out_len->ctypes.c_int(0)
A:lightgbm.basic.string_buffer->ctypes.create_string_buffer(actual_len)
A:lightgbm.basic.ptr_string_buffer->ctypes.c_char_p(ctypes.addressof(string_buffer))
A:lightgbm.basic.cls.aliases->cls._get_all_param_aliases()
A:lightgbm.basic.ret->numpy.column_stack((bin_edges[1:], hist))
A:lightgbm.basic.params->self._get_loaded_param()
A:lightgbm.basic.aliases->_ConfigAliases.get_sorted(main_param_name)
A:lightgbm.basic.data->_list_to_1d_numpy(data, dtype=dtype, name=field_name)
A:lightgbm.basic.ptr_data->(ctypes.POINTER(ctypes.c_float) * len(mats))()
A:lightgbm.basic.float128->getattr(np, 'float128', type(None))
A:lightgbm.basic.data[col]->data[col].cat.set_categories(category).cat.set_categories(category)
A:lightgbm.basic.data[cat_cols]->data[cat_cols].apply(lambda x: x.cat.codes).replace({-1: np.nan}).apply(lambda x: x.cat.codes).replace({-1: np.nan})
A:lightgbm.basic.target_dtype->numpy.result_type(*df_dtypes)
A:lightgbm.basic.categorical_json->json.dumps(pandas_categorical, default=_json_default_with_numpy)
A:lightgbm.basic.lines->f.readlines()
A:lightgbm.basic.last_line->model_str[idx:].strip()
A:lightgbm.basic.idx->state.get('_handle', state.get('handle', None)).rfind('\n', 0, offset)
A:lightgbm.basic.self.pred_parameter->_param_dict_to_str(pred_parameter)
A:lightgbm.basic.out_num_class->ctypes.c_int(0)
A:lightgbm.basic.out_cur_iter->ctypes.c_int(0)
A:lightgbm.basic.booster_handle->ctypes.c_void_p()
A:lightgbm.basic.out_num_iterations->ctypes.c_int(0)
A:lightgbm.basic.this->self.__dict__.copy()
A:lightgbm.basic.ptr_names->(ctypes.c_char_p * len(data_names))()
A:lightgbm.basic.preds->numpy.empty(n_preds, dtype=np.float64)
A:lightgbm.basic.(preds, nrow)->self.__pred_for_csr(csr=csr, start_iteration=start_iteration, num_iteration=num_iteration, predict_type=predict_type)
A:lightgbm.basic.csr->scipy.sparse.csr_matrix(data)
A:lightgbm.basic.is_sparse->isinstance(preds, (list, scipy.sparse.spmatrix))
A:lightgbm.basic.n_preds->self.__get_num_preds(start_iteration=start_iteration, num_iteration=num_iteration, nrow=table.num_rows, predict_type=predict_type)
A:lightgbm.basic.(ptr_data, type_ptr_data, _)->_c_float_array(csc.data)
A:lightgbm.basic.out_num_preds->ctypes.c_int64(0)
A:lightgbm.basic.sections->numpy.arange(start=_MAX_INT32, stop=nrow, step=_MAX_INT32)
A:lightgbm.basic.n_preds_sections->numpy.array([0] + n_preds, dtype=np.intp).cumsum()
A:lightgbm.basic.out_indptr->_cint64_array_to_numpy(cptr=out_ptr_indptr, length=indptr_len)
A:lightgbm.basic.out_data->_cfloat64_array_to_numpy(cptr=out_ptr_data, length=data_indices_len)
A:lightgbm.basic.out_indices->_cint32_array_to_numpy(cptr=out_ptr_indices, length=data_indices_len)
A:lightgbm.basic.out_indptr_arrays->numpy.split(out_indptr, out_indptr.shape[0] / per_class_indptr_shape)
A:lightgbm.basic.(ptr_indptr, type_ptr_indptr, _)->_c_int_array(csr.indptr)
A:lightgbm.basic.csr_indices->scipy.sparse.csr_matrix(data).indices.astype(np.int32, copy=False)
A:lightgbm.basic.(ptr_indptr, type_ptr_indptr, __)->_c_int_array(csc.indptr)
A:lightgbm.basic.out_ptr_indptr->ctypes.POINTER(ctypes.c_int64)()
A:lightgbm.basic.out_ptr_indices->ctypes.POINTER(ctypes.c_int32)()
A:lightgbm.basic.out_ptr_data->ctypes.POINTER(ctypes.c_double)()
A:lightgbm.basic.out_shape->numpy.empty(2, dtype=np.int64)
A:lightgbm.basic.matrices->self.__create_sparse_native(cs=csc, out_shape=out_shape, out_ptr_indptr=out_ptr_indptr, out_ptr_indices=out_ptr_indices, out_ptr_data=out_ptr_data, indptr_type=type_ptr_indptr, data_type=type_ptr_data, is_csr=False)
A:lightgbm.basic.csc_indices->csc.indices.astype(np.int32, copy=False)
A:lightgbm.basic.c_array->_export_arrow_to_c(data)
A:lightgbm.basic.self.params->deepcopy(self._params_back_up)
A:lightgbm.basic.param_str->_param_dict_to_str(self.get_params())
A:lightgbm.basic.indices->self._create_sample_indices(total_nrow)
A:lightgbm.basic.(ptr_data, _, _)->_c_int_array(leaf_preds)
A:lightgbm.basic.actual_sample_cnt->ctypes.c_int32(0)
A:lightgbm.basic.self._handle->ctypes.c_void_p()
A:lightgbm.basic.ncol->len(sample_indices)
A:lightgbm.basic.num_per_col->numpy.array([len(d) for d in sample_indices], dtype=np.int32)
A:lightgbm.basic.(num_per_col_ptr, _, _)->_c_int_array(num_per_col)
A:lightgbm.basic.params_str->_param_dict_to_str(params)
A:lightgbm.basic.(data_ptr, data_type, _)->_c_float_array(data)
A:lightgbm.basic.dataset_params->_ConfigAliases.get('bin_construct_sample_cnt', 'categorical_feature', 'data_random_seed', 'enable_bundle', 'feature_pre_filter', 'forcedbins_filename', 'group_column', 'header', 'ignore_column', 'is_enable_sparse', 'label_column', 'linear_tree', 'max_bin', 'max_bin_by_feature', 'min_data_in_bin', 'pre_partition', 'precise_float_parser', 'two_round', 'use_missing', 'weight_column', 'zero_as_missing')
A:lightgbm.basic.data_has_header->any((self.params.get(alias, False) for alias in _ConfigAliases.get('header')))
A:lightgbm.basic.num_data->self.num_data()
A:lightgbm.basic.init_score->numpy.full_like(self.init_score, fill_value=0.0, dtype=np.float64)
A:lightgbm.basic.sub_init_score->numpy.empty(num_data * predictor.num_class, dtype=np.float64)
A:lightgbm.basic.new_init_score->numpy.empty(init_score.size, dtype=np.float64)
A:lightgbm.basic.(data, feature_name, categorical_feature, self.pandas_categorical)->_data_from_pandas(data=data, feature_name=feature_name, categorical_feature=categorical_feature, pandas_categorical=self.pandas_categorical)
A:lightgbm.basic.args_names->inspect.signature(self.__class__._lazy_init).parameters.keys()
A:lightgbm.basic.categorical_indices->set()
A:lightgbm.basic.params['categorical_column']->sorted(categorical_indices)
A:lightgbm.basic.sampled->numpy.array(list(self._yield_row_from_seqlist(seqs, indices)))
A:lightgbm.basic.sampled_row_range->numpy.arange(len(indices), dtype=np.int32)
A:lightgbm.basic.total_nrow->sum((len(seq) for seq in seqs))
A:lightgbm.basic.(sample_data, col_indices)->self.__sample(seqs, total_nrow)
A:lightgbm.basic.nrow->numpy.empty((len(mats),), np.int32)
A:lightgbm.basic.end->min(start + batch_size, nrow)
A:lightgbm.basic.mats[i]->numpy.array(mat.reshape(mat.size), dtype=np.float32)
A:lightgbm.basic.(chunk_ptr_data, chunk_type_ptr_data, holder)->_c_float_array(mats[i])
A:lightgbm.basic.reference_params->self.reference.get_params()
A:lightgbm.basic.used_indices->_list_to_1d_numpy(self.used_indices, dtype=np.int32, name='used_indices')
A:lightgbm.basic.group_info->numpy.array(self.reference.group).astype(np.int32, copy=False)
A:lightgbm.basic.(_, self.group)->numpy.unique(np.repeat(range(len(group_info)), repeats=group_info)[self.used_indices], return_counts=True)
A:lightgbm.basic.self.feature_name->self.get_feature_name()
A:lightgbm.basic.ret.used_indices->sorted(used_indices)
A:lightgbm.basic.self._params_back_up->deepcopy(self.params)
A:lightgbm.basic.(ptr_data, type_data, _)->_c_int_array(data)
A:lightgbm.basic.out_type->ctypes.c_int(0)
A:lightgbm.basic.arr->arr.reshape((num_data, num_classes), order='F').reshape((num_data, num_classes), order='F')
A:lightgbm.basic.label_array->_list_to_1d_numpy(label, dtype=np.float32, name='label')
A:lightgbm.basic.self.label->self.get_field('label')
A:lightgbm.basic.weight->_list_to_1d_numpy(weight, dtype=np.float32, name='weight')
A:lightgbm.basic.self.weight->self.get_field('weight')
A:lightgbm.basic.self.init_score->self.get_field('init_score')
A:lightgbm.basic.group->_list_to_1d_numpy(group, dtype=np.int32, name='group')
A:lightgbm.basic.constructed_group->self.get_field('group')
A:lightgbm.basic.self.group->numpy.diff(self.group)
A:lightgbm.basic.position->_list_to_1d_numpy(position, dtype=np.int32, name='position')
A:lightgbm.basic.num_feature->self.num_feature()
A:lightgbm.basic.required_string_buffer_size->ctypes.c_size_t(0)
A:lightgbm.basic.ptr_string_buffers->(ctypes.c_char_p * self.__num_inner_eval)(*map(ctypes.addressof, string_buffers))
A:lightgbm.basic.self.data->dt_DataTable(np.hstack((self.data.to_numpy(), other.data.to_numpy())))
A:lightgbm.basic.self.position->self.get_field('position')
A:lightgbm.basic.feature_index->self.feature_name.index(feature)
A:lightgbm.basic.sparse_format->self.data.getformat()
A:lightgbm.basic.num_machines_from_machine_list->len(machines)
A:lightgbm.basic.machines->','.join(machines)
A:lightgbm.basic.self.pandas_categorical->_load_pandas_categorical(model_str=model_str)
A:lightgbm.basic.model_str->state.get('_handle', state.get('handle', None))
A:lightgbm.basic.this['_handle']->self.model_to_string(num_iteration=-1)
A:lightgbm.basic.handle->ctypes.c_void_p()
A:lightgbm.basic.is_split->_is_split_node(tree)
A:lightgbm.basic.node_num->tree.get('split_index' if is_split else 'leaf_index', 0)
A:lightgbm.basic.node['node_index']->_get_node_index(tree, tree_index)
A:lightgbm.basic.node['split_feature']->_get_split_feature(tree, feature_names)
A:lightgbm.basic.node['left_child']->_get_node_index(tree['left_child'], tree_index)
A:lightgbm.basic.node['right_child']->_get_node_index(tree['right_child'], tree_index)
A:lightgbm.basic.node->create_node_record(tree=tree, node_depth=node_depth, tree_index=tree_index, feature_names=feature_names, parent_node=parent_node)
A:lightgbm.basic.subtree_list->tree_dict_to_node_list(tree=tree[child], node_depth=node_depth + 1, tree_index=tree_index, feature_names=feature_names, parent_node=node['node_index'])
A:lightgbm.basic.model_dict->self.dump_model()
A:lightgbm.basic.is_finished->ctypes.c_int(0)
A:lightgbm.basic.(grad, hess)->fobj(self.__inner_predict(0), self.train_set)
A:lightgbm.basic.grad->_list_to_1d_numpy(grad, dtype=np.float32, name='gradient')
A:lightgbm.basic.hess->_list_to_1d_numpy(hess, dtype=np.float32, name='hessian')
A:lightgbm.basic.num_train_data->self.train_set.num_data()
A:lightgbm.basic.model_per_iter->ctypes.c_int(0)
A:lightgbm.basic.num_trees->ctypes.c_int(0)
A:lightgbm.basic.ret['pandas_categorical']->json.loads(json.dumps(self.pandas_categorical, default=_json_default_with_numpy))
A:lightgbm.basic.predictor->_InnerPredictor.from_booster(booster=self, pred_parameter=deepcopy(kwargs))
A:lightgbm.basic.out_is_linear->ctypes.c_int(0)
A:lightgbm.basic.new_params->_choose_param_value(main_param_name='linear_tree', params=self.params, default_value=None)
A:lightgbm.basic.new_params['linear_tree']->bool(out_is_linear.value)
A:lightgbm.basic.train_set->Dataset(data=data, label=label, reference=reference, weight=weight, group=group, init_score=init_score, feature_name=feature_name, categorical_feature=categorical_feature, params=new_params, free_raw_data=free_raw_data)
A:lightgbm.basic.new_booster->Booster(new_params, train_set)
A:lightgbm.basic.leaf_preds->leaf_preds.reshape(-1).reshape(-1)
A:lightgbm.basic.out_num_feature->ctypes.c_int(0)
A:lightgbm.basic.result->result.reshape(num_data, self.__num_class, order='F').reshape(num_data, self.__num_class, order='F')
A:lightgbm.basic.model->self.dump_model()
A:lightgbm.basic.feature_names->self.dump_model().get('feature_names')
A:lightgbm.basic.n_unique->len(np.unique(values))
A:lightgbm.basic.bins->max(min(n_unique, bins) if bins is not None else n_unique, 1)
A:lightgbm.basic.(hist, bin_edges)->numpy.histogram(values, bins=bins)
A:lightgbm.basic.feval_ret->eval_function(self.__inner_predict(data_idx), cur_data)
A:lightgbm.basic.self.__inner_predict_buffer[data_idx]->numpy.empty(n_preds, dtype=np.float64)
A:lightgbm.basic.data_ptr->self.__inner_predict_buffer[data_idx].ctypes.data_as(ctypes.POINTER(ctypes.c_double))
A:lightgbm.basic.out_num_eval->ctypes.c_int(0)
lightgbm.Booster(self,params:Optional[Dict[str,Any]]=None,train_set:Optional[Dataset]=None,model_file:Optional[Union[str,Path]]=None,model_str:Optional[str]=None)
lightgbm.Booster.__boost(self,grad:np.ndarray,hess:np.ndarray)->bool
lightgbm.Booster.__copy__(self)->'Booster'
lightgbm.Booster.__deepcopy__(self,*args:Any,**kwargs:Any)->'Booster'
lightgbm.Booster.__del__(self)->None
lightgbm.Booster.__get_eval_info(self)->None
lightgbm.Booster.__getstate__(self)->Dict[str, Any]
lightgbm.Booster.__inner_eval(self,data_name:str,data_idx:int,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]])->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.Booster.__inner_predict(self,data_idx:int)->np.ndarray
lightgbm.Booster.__setstate__(self,state:Dict[str,Any])->None
lightgbm.Booster._free_buffer(self)->'Booster'
lightgbm.Booster._get_loaded_param(self)->Dict[str, Any]
lightgbm.Booster.add_valid(self,data:Dataset,name:str)->'Booster'
lightgbm.Booster.current_iteration(self)->int
lightgbm.Booster.dump_model(self,num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split',object_hook:Optional[Callable[[Dict[str,Any]],Dict[str,Any]]]=None)->Dict[str, Any]
lightgbm.Booster.eval(self,data:Dataset,name:str,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]]=None)->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.Booster.eval_train(self,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]]=None)->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.Booster.eval_valid(self,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]]=None)->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.Booster.feature_importance(self,importance_type:str='split',iteration:Optional[int]=None)->np.ndarray
lightgbm.Booster.feature_name(self)->List[str]
lightgbm.Booster.free_dataset(self)->'Booster'
lightgbm.Booster.free_network(self)->'Booster'
lightgbm.Booster.get_leaf_output(self,tree_id:int,leaf_id:int)->float
lightgbm.Booster.get_split_value_histogram(self,feature:Union[int,str],bins:Optional[Union[int,str]]=None,xgboost_style:bool=False)->Union[Tuple[np.ndarray, np.ndarray], np.ndarray, pd_DataFrame]
lightgbm.Booster.lower_bound(self)->float
lightgbm.Booster.model_from_string(self,model_str:str)->'Booster'
lightgbm.Booster.model_to_string(self,num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->str
lightgbm.Booster.num_feature(self)->int
lightgbm.Booster.num_model_per_iteration(self)->int
lightgbm.Booster.num_trees(self)->int
lightgbm.Booster.predict(self,data:_LGBM_PredictDataType,start_iteration:int=0,num_iteration:Optional[int]=None,raw_score:bool=False,pred_leaf:bool=False,pred_contrib:bool=False,data_has_header:bool=False,validate_features:bool=False,**kwargs:Any)->Union[np.ndarray, scipy.sparse.spmatrix, List[scipy.sparse.spmatrix]]
lightgbm.Booster.refit(self,data:_LGBM_TrainDataType,label:_LGBM_LabelType,decay_rate:float=0.9,reference:Optional[Dataset]=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',dataset_params:Optional[Dict[str,Any]]=None,free_raw_data:bool=True,validate_features:bool=False,**kwargs:Any)->'Booster'
lightgbm.Booster.reset_parameter(self,params:Dict[str,Any])->'Booster'
lightgbm.Booster.rollback_one_iter(self)->'Booster'
lightgbm.Booster.save_model(self,filename:Union[str,Path],num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->'Booster'
lightgbm.Booster.set_leaf_output(self,tree_id:int,leaf_id:int,value:float)->'Booster'
lightgbm.Booster.set_network(self,machines:Union[List[str],Set[str],str],local_listen_port:int=12400,listen_time_out:int=120,num_machines:int=1)->'Booster'
lightgbm.Booster.set_train_data_name(self,name:str)->'Booster'
lightgbm.Booster.shuffle_models(self,start_iteration:int=0,end_iteration:int=-1)->'Booster'
lightgbm.Booster.trees_to_dataframe(self)->pd_DataFrame
lightgbm.Booster.update(self,train_set:Optional[Dataset]=None,fobj:Optional[_LGBM_CustomObjectiveFunction]=None)->bool
lightgbm.Booster.upper_bound(self)->float
lightgbm.Dataset(self,data:_LGBM_TrainDataType,label:Optional[_LGBM_LabelType]=None,reference:Optional['Dataset']=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',params:Optional[Dict[str,Any]]=None,free_raw_data:bool=True,position:Optional[_LGBM_PositionType]=None)
lightgbm.Dataset.__del__(self)->None
lightgbm.Dataset.__init_from_csc(self,csc:scipy.sparse.csc_matrix,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.Dataset.__init_from_csr(self,csr:scipy.sparse.csr_matrix,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.Dataset.__init_from_list_np2d(self,mats:List[np.ndarray],params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.Dataset.__init_from_np2d(self,mat:np.ndarray,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.Dataset.__init_from_pyarrow_table(self,table:pa_Table,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.Dataset.__init_from_seqs(self,seqs:List[Sequence],ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.Dataset.__sample(self,seqs:List[Sequence],total_nrow:int)->Tuple[List[np.ndarray], List[np.ndarray]]
lightgbm.Dataset._compare_params_for_warning(params:Dict[str,Any],other_params:Dict[str,Any],ignore_keys:Set[str])->bool
lightgbm.Dataset._create_sample_indices(self,total_nrow:int)->np.ndarray
lightgbm.Dataset._dump_text(self,filename:Union[str,Path])->'Dataset'
lightgbm.Dataset._free_handle(self)->'Dataset'
lightgbm.Dataset._init_from_ref_dataset(self,total_nrow:int,ref_dataset:_DatasetHandle)->'Dataset'
lightgbm.Dataset._init_from_sample(self,sample_data:List[np.ndarray],sample_indices:List[np.ndarray],sample_cnt:int,total_nrow:int)->'Dataset'
lightgbm.Dataset._lazy_init(self,data:Optional[_LGBM_TrainDataType],label:Optional[_LGBM_LabelType],reference:Optional['Dataset'],weight:Optional[_LGBM_WeightType],group:Optional[_LGBM_GroupType],init_score:Optional[_LGBM_InitScoreType],predictor:Optional[_InnerPredictor],feature_name:_LGBM_FeatureNameConfiguration,categorical_feature:_LGBM_CategoricalFeatureConfiguration,params:Optional[Dict[str,Any]],position:Optional[_LGBM_PositionType])->'Dataset'
lightgbm.Dataset._push_rows(self,data:np.ndarray)->'Dataset'
lightgbm.Dataset._reverse_update_params(self)->'Dataset'
lightgbm.Dataset._set_init_score_by_predictor(self,predictor:Optional[_InnerPredictor],data:_LGBM_TrainDataType,used_indices:Optional[Union[List[int],np.ndarray]])->'Dataset'
lightgbm.Dataset._set_predictor(self,predictor:Optional[_InnerPredictor])->'Dataset'
lightgbm.Dataset._update_params(self,params:Optional[Dict[str,Any]])->'Dataset'
lightgbm.Dataset._yield_row_from_seqlist(seqs:List[Sequence],indices:Iterable[int])->Iterator[np.ndarray]
lightgbm.Dataset.add_features_from(self,other:'Dataset')->'Dataset'
lightgbm.Dataset.construct(self)->'Dataset'
lightgbm.Dataset.create_valid(self,data:_LGBM_TrainDataType,label:Optional[_LGBM_LabelType]=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,params:Optional[Dict[str,Any]]=None,position:Optional[_LGBM_PositionType]=None)->'Dataset'
lightgbm.Dataset.feature_num_bin(self,feature:Union[int,str])->int
lightgbm.Dataset.get_data(self)->Optional[_LGBM_TrainDataType]
lightgbm.Dataset.get_feature_name(self)->List[str]
lightgbm.Dataset.get_field(self,field_name:str)->Optional[np.ndarray]
lightgbm.Dataset.get_group(self)->Optional[_LGBM_GroupType]
lightgbm.Dataset.get_init_score(self)->Optional[_LGBM_InitScoreType]
lightgbm.Dataset.get_label(self)->Optional[_LGBM_LabelType]
lightgbm.Dataset.get_params(self)->Dict[str, Any]
lightgbm.Dataset.get_position(self)->Optional[_LGBM_PositionType]
lightgbm.Dataset.get_ref_chain(self,ref_limit:int=100)->Set['Dataset']
lightgbm.Dataset.get_weight(self)->Optional[_LGBM_WeightType]
lightgbm.Dataset.num_data(self)->int
lightgbm.Dataset.num_feature(self)->int
lightgbm.Dataset.save_binary(self,filename:Union[str,Path])->'Dataset'
lightgbm.Dataset.set_categorical_feature(self,categorical_feature:_LGBM_CategoricalFeatureConfiguration)->'Dataset'
lightgbm.Dataset.set_feature_name(self,feature_name:_LGBM_FeatureNameConfiguration)->'Dataset'
lightgbm.Dataset.set_field(self,field_name:str,data:Optional[_LGBM_SetFieldType])->'Dataset'
lightgbm.Dataset.set_group(self,group:Optional[_LGBM_GroupType])->'Dataset'
lightgbm.Dataset.set_init_score(self,init_score:Optional[_LGBM_InitScoreType])->'Dataset'
lightgbm.Dataset.set_label(self,label:Optional[_LGBM_LabelType])->'Dataset'
lightgbm.Dataset.set_position(self,position:Optional[_LGBM_PositionType])->'Dataset'
lightgbm.Dataset.set_reference(self,reference:'Dataset')->'Dataset'
lightgbm.Dataset.set_weight(self,weight:Optional[_LGBM_WeightType])->'Dataset'
lightgbm.Dataset.subset(self,used_indices:List[int],params:Optional[Dict[str,Any]]=None)->'Dataset'
lightgbm.Sequence(abc.ABC)
lightgbm.Sequence.__getitem__(self,idx:Union[int,slice,List[int]])->np.ndarray
lightgbm.Sequence.__len__(self)->int
lightgbm.basic.Booster(self,params:Optional[Dict[str,Any]]=None,train_set:Optional[Dataset]=None,model_file:Optional[Union[str,Path]]=None,model_str:Optional[str]=None)
lightgbm.basic.Booster.__boost(self,grad:np.ndarray,hess:np.ndarray)->bool
lightgbm.basic.Booster.__copy__(self)->'Booster'
lightgbm.basic.Booster.__deepcopy__(self,*args:Any,**kwargs:Any)->'Booster'
lightgbm.basic.Booster.__del__(self)->None
lightgbm.basic.Booster.__get_eval_info(self)->None
lightgbm.basic.Booster.__getstate__(self)->Dict[str, Any]
lightgbm.basic.Booster.__init__(self,params:Optional[Dict[str,Any]]=None,train_set:Optional[Dataset]=None,model_file:Optional[Union[str,Path]]=None,model_str:Optional[str]=None)
lightgbm.basic.Booster.__inner_eval(self,data_name:str,data_idx:int,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]])->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.basic.Booster.__inner_predict(self,data_idx:int)->np.ndarray
lightgbm.basic.Booster.__setstate__(self,state:Dict[str,Any])->None
lightgbm.basic.Booster._free_buffer(self)->'Booster'
lightgbm.basic.Booster._get_loaded_param(self)->Dict[str, Any]
lightgbm.basic.Booster.add_valid(self,data:Dataset,name:str)->'Booster'
lightgbm.basic.Booster.current_iteration(self)->int
lightgbm.basic.Booster.dump_model(self,num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split',object_hook:Optional[Callable[[Dict[str,Any]],Dict[str,Any]]]=None)->Dict[str, Any]
lightgbm.basic.Booster.eval(self,data:Dataset,name:str,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]]=None)->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.basic.Booster.eval_train(self,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]]=None)->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.basic.Booster.eval_valid(self,feval:Optional[Union[_LGBM_CustomEvalFunction,List[_LGBM_CustomEvalFunction]]]=None)->List[_LGBM_BoosterEvalMethodResultType]
lightgbm.basic.Booster.feature_importance(self,importance_type:str='split',iteration:Optional[int]=None)->np.ndarray
lightgbm.basic.Booster.feature_name(self)->List[str]
lightgbm.basic.Booster.free_dataset(self)->'Booster'
lightgbm.basic.Booster.free_network(self)->'Booster'
lightgbm.basic.Booster.get_leaf_output(self,tree_id:int,leaf_id:int)->float
lightgbm.basic.Booster.get_split_value_histogram(self,feature:Union[int,str],bins:Optional[Union[int,str]]=None,xgboost_style:bool=False)->Union[Tuple[np.ndarray, np.ndarray], np.ndarray, pd_DataFrame]
lightgbm.basic.Booster.lower_bound(self)->float
lightgbm.basic.Booster.model_from_string(self,model_str:str)->'Booster'
lightgbm.basic.Booster.model_to_string(self,num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->str
lightgbm.basic.Booster.num_feature(self)->int
lightgbm.basic.Booster.num_model_per_iteration(self)->int
lightgbm.basic.Booster.num_trees(self)->int
lightgbm.basic.Booster.predict(self,data:_LGBM_PredictDataType,start_iteration:int=0,num_iteration:Optional[int]=None,raw_score:bool=False,pred_leaf:bool=False,pred_contrib:bool=False,data_has_header:bool=False,validate_features:bool=False,**kwargs:Any)->Union[np.ndarray, scipy.sparse.spmatrix, List[scipy.sparse.spmatrix]]
lightgbm.basic.Booster.refit(self,data:_LGBM_TrainDataType,label:_LGBM_LabelType,decay_rate:float=0.9,reference:Optional[Dataset]=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',dataset_params:Optional[Dict[str,Any]]=None,free_raw_data:bool=True,validate_features:bool=False,**kwargs:Any)->'Booster'
lightgbm.basic.Booster.reset_parameter(self,params:Dict[str,Any])->'Booster'
lightgbm.basic.Booster.rollback_one_iter(self)->'Booster'
lightgbm.basic.Booster.save_model(self,filename:Union[str,Path],num_iteration:Optional[int]=None,start_iteration:int=0,importance_type:str='split')->'Booster'
lightgbm.basic.Booster.set_leaf_output(self,tree_id:int,leaf_id:int,value:float)->'Booster'
lightgbm.basic.Booster.set_network(self,machines:Union[List[str],Set[str],str],local_listen_port:int=12400,listen_time_out:int=120,num_machines:int=1)->'Booster'
lightgbm.basic.Booster.set_train_data_name(self,name:str)->'Booster'
lightgbm.basic.Booster.shuffle_models(self,start_iteration:int=0,end_iteration:int=-1)->'Booster'
lightgbm.basic.Booster.trees_to_dataframe(self)->pd_DataFrame
lightgbm.basic.Booster.update(self,train_set:Optional[Dataset]=None,fobj:Optional[_LGBM_CustomObjectiveFunction]=None)->bool
lightgbm.basic.Booster.upper_bound(self)->float
lightgbm.basic.Dataset(self,data:_LGBM_TrainDataType,label:Optional[_LGBM_LabelType]=None,reference:Optional['Dataset']=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',params:Optional[Dict[str,Any]]=None,free_raw_data:bool=True,position:Optional[_LGBM_PositionType]=None)
lightgbm.basic.Dataset.__del__(self)->None
lightgbm.basic.Dataset.__init__(self,data:_LGBM_TrainDataType,label:Optional[_LGBM_LabelType]=None,reference:Optional['Dataset']=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,feature_name:_LGBM_FeatureNameConfiguration='auto',categorical_feature:_LGBM_CategoricalFeatureConfiguration='auto',params:Optional[Dict[str,Any]]=None,free_raw_data:bool=True,position:Optional[_LGBM_PositionType]=None)
lightgbm.basic.Dataset.__init_from_csc(self,csc:scipy.sparse.csc_matrix,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.basic.Dataset.__init_from_csr(self,csr:scipy.sparse.csr_matrix,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.basic.Dataset.__init_from_list_np2d(self,mats:List[np.ndarray],params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.basic.Dataset.__init_from_np2d(self,mat:np.ndarray,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.basic.Dataset.__init_from_pyarrow_table(self,table:pa_Table,params_str:str,ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.basic.Dataset.__init_from_seqs(self,seqs:List[Sequence],ref_dataset:Optional[_DatasetHandle])->'Dataset'
lightgbm.basic.Dataset.__sample(self,seqs:List[Sequence],total_nrow:int)->Tuple[List[np.ndarray], List[np.ndarray]]
lightgbm.basic.Dataset._compare_params_for_warning(params:Dict[str,Any],other_params:Dict[str,Any],ignore_keys:Set[str])->bool
lightgbm.basic.Dataset._create_sample_indices(self,total_nrow:int)->np.ndarray
lightgbm.basic.Dataset._dump_text(self,filename:Union[str,Path])->'Dataset'
lightgbm.basic.Dataset._free_handle(self)->'Dataset'
lightgbm.basic.Dataset._init_from_ref_dataset(self,total_nrow:int,ref_dataset:_DatasetHandle)->'Dataset'
lightgbm.basic.Dataset._init_from_sample(self,sample_data:List[np.ndarray],sample_indices:List[np.ndarray],sample_cnt:int,total_nrow:int)->'Dataset'
lightgbm.basic.Dataset._lazy_init(self,data:Optional[_LGBM_TrainDataType],label:Optional[_LGBM_LabelType],reference:Optional['Dataset'],weight:Optional[_LGBM_WeightType],group:Optional[_LGBM_GroupType],init_score:Optional[_LGBM_InitScoreType],predictor:Optional[_InnerPredictor],feature_name:_LGBM_FeatureNameConfiguration,categorical_feature:_LGBM_CategoricalFeatureConfiguration,params:Optional[Dict[str,Any]],position:Optional[_LGBM_PositionType])->'Dataset'
lightgbm.basic.Dataset._push_rows(self,data:np.ndarray)->'Dataset'
lightgbm.basic.Dataset._reverse_update_params(self)->'Dataset'
lightgbm.basic.Dataset._set_init_score_by_predictor(self,predictor:Optional[_InnerPredictor],data:_LGBM_TrainDataType,used_indices:Optional[Union[List[int],np.ndarray]])->'Dataset'
lightgbm.basic.Dataset._set_predictor(self,predictor:Optional[_InnerPredictor])->'Dataset'
lightgbm.basic.Dataset._update_params(self,params:Optional[Dict[str,Any]])->'Dataset'
lightgbm.basic.Dataset._yield_row_from_seqlist(seqs:List[Sequence],indices:Iterable[int])->Iterator[np.ndarray]
lightgbm.basic.Dataset.add_features_from(self,other:'Dataset')->'Dataset'
lightgbm.basic.Dataset.construct(self)->'Dataset'
lightgbm.basic.Dataset.create_valid(self,data:_LGBM_TrainDataType,label:Optional[_LGBM_LabelType]=None,weight:Optional[_LGBM_WeightType]=None,group:Optional[_LGBM_GroupType]=None,init_score:Optional[_LGBM_InitScoreType]=None,params:Optional[Dict[str,Any]]=None,position:Optional[_LGBM_PositionType]=None)->'Dataset'
lightgbm.basic.Dataset.feature_num_bin(self,feature:Union[int,str])->int
lightgbm.basic.Dataset.get_data(self)->Optional[_LGBM_TrainDataType]
lightgbm.basic.Dataset.get_feature_name(self)->List[str]
lightgbm.basic.Dataset.get_field(self,field_name:str)->Optional[np.ndarray]
lightgbm.basic.Dataset.get_group(self)->Optional[_LGBM_GroupType]
lightgbm.basic.Dataset.get_init_score(self)->Optional[_LGBM_InitScoreType]
lightgbm.basic.Dataset.get_label(self)->Optional[_LGBM_LabelType]
lightgbm.basic.Dataset.get_params(self)->Dict[str, Any]
lightgbm.basic.Dataset.get_position(self)->Optional[_LGBM_PositionType]
lightgbm.basic.Dataset.get_ref_chain(self,ref_limit:int=100)->Set['Dataset']
lightgbm.basic.Dataset.get_weight(self)->Optional[_LGBM_WeightType]
lightgbm.basic.Dataset.num_data(self)->int
lightgbm.basic.Dataset.num_feature(self)->int
lightgbm.basic.Dataset.save_binary(self,filename:Union[str,Path])->'Dataset'
lightgbm.basic.Dataset.set_categorical_feature(self,categorical_feature:_LGBM_CategoricalFeatureConfiguration)->'Dataset'
lightgbm.basic.Dataset.set_feature_name(self,feature_name:_LGBM_FeatureNameConfiguration)->'Dataset'
lightgbm.basic.Dataset.set_field(self,field_name:str,data:Optional[_LGBM_SetFieldType])->'Dataset'
lightgbm.basic.Dataset.set_group(self,group:Optional[_LGBM_GroupType])->'Dataset'
lightgbm.basic.Dataset.set_init_score(self,init_score:Optional[_LGBM_InitScoreType])->'Dataset'
lightgbm.basic.Dataset.set_label(self,label:Optional[_LGBM_LabelType])->'Dataset'
lightgbm.basic.Dataset.set_position(self,position:Optional[_LGBM_PositionType])->'Dataset'
lightgbm.basic.Dataset.set_reference(self,reference:'Dataset')->'Dataset'
lightgbm.basic.Dataset.set_weight(self,weight:Optional[_LGBM_WeightType])->'Dataset'
lightgbm.basic.Dataset.subset(self,used_indices:List[int],params:Optional[Dict[str,Any]]=None)->'Dataset'
lightgbm.basic.LGBMDeprecationWarning(FutureWarning)
lightgbm.basic.LightGBMError(Exception)
lightgbm.basic.Sequence(abc.ABC)
lightgbm.basic.Sequence.__getitem__(self,idx:Union[int,slice,List[int]])->np.ndarray
lightgbm.basic.Sequence.__len__(self)->int
lightgbm.basic._ArrowCArray(self,n_chunks:int,chunks:arrow_cffi.CData,schema:arrow_cffi.CData)
lightgbm.basic._ArrowCArray.__init__(self,n_chunks:int,chunks:arrow_cffi.CData,schema:arrow_cffi.CData)
lightgbm.basic._ArrowCArray.chunks_ptr(self)->int
lightgbm.basic._ArrowCArray.schema_ptr(self)->int
lightgbm.basic._ConfigAliases
lightgbm.basic._ConfigAliases._get_all_param_aliases()->Dict[str, List[str]]
lightgbm.basic._ConfigAliases.get(cls,*args:str)->Set[str]
lightgbm.basic._ConfigAliases.get_by_alias(cls,*args:str)->Set[str]
lightgbm.basic._ConfigAliases.get_sorted(cls,name:str)->List[str]
lightgbm.basic._DummyLogger
lightgbm.basic._DummyLogger.info(self,msg:str)->None
lightgbm.basic._DummyLogger.warning(self,msg:str)->None
lightgbm.basic._InnerPredictor(self,booster_handle:_BoosterHandle,pandas_categorical:Optional[List[List]],pred_parameter:Dict[str,Any],manage_handle:bool)
lightgbm.basic._InnerPredictor.__create_sparse_native(self,cs:Union[scipy.sparse.csc_matrix,scipy.sparse.csr_matrix],out_shape:np.ndarray,out_ptr_indptr:'ctypes._Pointer',out_ptr_indices:'ctypes._Pointer',out_ptr_data:'ctypes._Pointer',indptr_type:int,data_type:int,is_csr:bool)->Union[List[scipy.sparse.csc_matrix], List[scipy.sparse.csr_matrix]]
lightgbm.basic._InnerPredictor.__del__(self)->None
lightgbm.basic._InnerPredictor.__get_num_preds(self,start_iteration:int,num_iteration:int,nrow:int,predict_type:int)->int
lightgbm.basic._InnerPredictor.__getstate__(self)->Dict[str, Any]
lightgbm.basic._InnerPredictor.__init__(self,booster_handle:_BoosterHandle,pandas_categorical:Optional[List[List]],pred_parameter:Dict[str,Any],manage_handle:bool)
lightgbm.basic._InnerPredictor.__inner_predict_csr(self,csr:scipy.sparse.csr_matrix,start_iteration:int,num_iteration:int,predict_type:int,preds:Optional[np.ndarray])->Tuple[np.ndarray, int]
lightgbm.basic._InnerPredictor.__inner_predict_csr_sparse(self,csr:scipy.sparse.csr_matrix,start_iteration:int,num_iteration:int,predict_type:int)->Tuple[Union[List[scipy.sparse.csc_matrix], List[scipy.sparse.csr_matrix]], int]
lightgbm.basic._InnerPredictor.__inner_predict_np2d(self,mat:np.ndarray,start_iteration:int,num_iteration:int,predict_type:int,preds:Optional[np.ndarray])->Tuple[np.ndarray, int]
lightgbm.basic._InnerPredictor.__inner_predict_sparse_csc(self,csc:scipy.sparse.csc_matrix,start_iteration:int,num_iteration:int,predict_type:int)->Tuple[Union[List[scipy.sparse.csc_matrix], List[scipy.sparse.csr_matrix]], int]
lightgbm.basic._InnerPredictor.__pred_for_csc(self,csc:scipy.sparse.csc_matrix,start_iteration:int,num_iteration:int,predict_type:int)->Tuple[np.ndarray, int]
lightgbm.basic._InnerPredictor.__pred_for_csr(self,csr:scipy.sparse.csr_matrix,start_iteration:int,num_iteration:int,predict_type:int)->Tuple[np.ndarray, int]
lightgbm.basic._InnerPredictor.__pred_for_np2d(self,mat:np.ndarray,start_iteration:int,num_iteration:int,predict_type:int)->Tuple[np.ndarray, int]
lightgbm.basic._InnerPredictor.__pred_for_pyarrow_table(self,table:pa_Table,start_iteration:int,num_iteration:int,predict_type:int)->Tuple[np.ndarray, int]
lightgbm.basic._InnerPredictor.current_iteration(self)->int
lightgbm.basic._InnerPredictor.from_booster(cls,booster:'Booster',pred_parameter:Dict[str,Any])->'_InnerPredictor'
lightgbm.basic._InnerPredictor.from_model_file(cls,model_file:Union[str,Path],pred_parameter:Dict[str,Any])->'_InnerPredictor'
lightgbm.basic._InnerPredictor.predict(self,data:_LGBM_PredictDataType,start_iteration:int=0,num_iteration:int=-1,raw_score:bool=False,pred_leaf:bool=False,pred_contrib:bool=False,data_has_header:bool=False,validate_features:bool=False)->Union[np.ndarray, scipy.sparse.spmatrix, List[scipy.sparse.spmatrix]]
lightgbm.basic._MissingType(Enum)
lightgbm.basic._TempFile
lightgbm.basic._TempFile.__enter__(self)->'_TempFile'
lightgbm.basic._TempFile.__exit__(self,exc_type:Any,exc_val:Any,exc_tb:Any)->None
lightgbm.basic._c_array(ctype:type,values:List[Any])->ctypes.Array
lightgbm.basic._c_float_array(data:np.ndarray)->Tuple[_ctypes_float_ptr, int, np.ndarray]
lightgbm.basic._c_int_array(data:np.ndarray)->Tuple[_ctypes_int_ptr, int, np.ndarray]
lightgbm.basic._c_str(string:str)->ctypes.c_char_p
lightgbm.basic._cast_numpy_array_to_dtype(array:np.ndarray,dtype:'np.typing.DTypeLike')->np.ndarray
lightgbm.basic._cfloat32_array_to_numpy(*,cptr:'ctypes._Pointer',length:int)->np.ndarray
lightgbm.basic._cfloat64_array_to_numpy(*,cptr:'ctypes._Pointer',length:int)->np.ndarray
lightgbm.basic._check_for_bad_pandas_dtypes(pandas_dtypes_series:pd_Series)->None
lightgbm.basic._choose_param_value(main_param_name:str,params:Dict[str,Any],default_value:Any)->Dict[str, Any]
lightgbm.basic._cint32_array_to_numpy(*,cptr:'ctypes._Pointer',length:int)->np.ndarray
lightgbm.basic._cint64_array_to_numpy(*,cptr:'ctypes._Pointer',length:int)->np.ndarray
lightgbm.basic._convert_from_sliced_object(data:np.ndarray)->np.ndarray
lightgbm.basic._data_from_pandas(data:pd_DataFrame,feature_name:_LGBM_FeatureNameConfiguration,categorical_feature:_LGBM_CategoricalFeatureConfiguration,pandas_categorical:Optional[List[List]])->Tuple[np.ndarray, List[str], Union[List[str], List[int]], List[List]]
lightgbm.basic._data_to_2d_numpy(data:Any,dtype:'np.typing.DTypeLike',name:str)->np.ndarray
lightgbm.basic._dump_pandas_categorical(pandas_categorical:Optional[List[List]],file_name:Optional[Union[str,Path]]=None)->str
lightgbm.basic._export_arrow_to_c(data:pa_Table)->_ArrowCArray
lightgbm.basic._get_sample_count(total_nrow:int,params:str)->int
lightgbm.basic._has_method(logger:Any,method_name:str)->bool
lightgbm.basic._is_1d_collection(data:Any)->bool
lightgbm.basic._is_1d_list(data:Any)->bool
lightgbm.basic._is_2d_collection(data:Any)->bool
lightgbm.basic._is_2d_list(data:Any)->bool
lightgbm.basic._is_allowed_numpy_dtype(dtype:type)->bool
lightgbm.basic._is_list_of_numpy_arrays(data:Any)->'TypeGuard[List[np.ndarray]]'
lightgbm.basic._is_list_of_sequences(data:Any)->'TypeGuard[List[Sequence]]'
lightgbm.basic._is_numeric(obj:Any)->bool
lightgbm.basic._is_numpy_1d_array(data:Any)->bool
lightgbm.basic._is_numpy_2d_array(data:Any)->bool
lightgbm.basic._is_numpy_column_array(data:Any)->bool
lightgbm.basic._is_pyarrow_array(data:Any)->'TypeGuard[Union[pa_Array, pa_ChunkedArray]]'
lightgbm.basic._is_pyarrow_table(data:Any)->bool
lightgbm.basic._is_zero(x:float)->bool
lightgbm.basic._json_default_with_numpy(obj:Any)->Any
lightgbm.basic._list_to_1d_numpy(data:Any,dtype:'np.typing.DTypeLike',name:str)->np.ndarray
lightgbm.basic._load_lib()->ctypes.CDLL
lightgbm.basic._load_pandas_categorical(file_name:Optional[Union[str,Path]]=None,model_str:Optional[str]=None)->Optional[List[List]]
lightgbm.basic._log_callback(msg:bytes)->None
lightgbm.basic._log_info(msg:str)->None
lightgbm.basic._log_native(msg:str)->None
lightgbm.basic._log_warning(msg:str)->None
lightgbm.basic._normalize_native_string(func:Callable[[str],None])->Callable[[str], None]
lightgbm.basic._pandas_to_numpy(data:pd_DataFrame,target_dtype:'np.typing.DTypeLike')->np.ndarray
lightgbm.basic._param_dict_to_str(data:Optional[Dict[str,Any]])->str
lightgbm.basic._safe_call(ret:int)->None
lightgbm.basic._to_string(x:Union[int,float,str,List])->str
lightgbm.basic.register_logger(logger:Any,info_method_name:str='info',warning_method_name:str='warning')->None
lightgbm.register_logger(logger:Any,info_method_name:str='info',warning_method_name:str='warning')->None


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/compat.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/libpath.py----------------------------------------
A:lightgbm.libpath.curr_path->Path(__file__).absolute()
A:lightgbm.libpath.dll_path_joined->'\n'.join(map(str, dll_path))
lightgbm.libpath.find_lib_path()->List[str]


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/callback.py----------------------------------------
A:lightgbm.callback.result->'\t'.join([_format_eval_result(x, self.show_stdv) for x in env.evaluation_result_list])
A:lightgbm.callback.(data_name, eval_name)->item[1].split()
A:lightgbm.callback.new_param->value(env.iteration - env.begin_iteration)
A:lightgbm.callback.self.enabled->_should_enable_early_stopping(stopping_rounds)
A:lightgbm.callback.is_dart->any((env.params.get(alias, '') == 'dart' for alias in _ConfigAliases.get('boosting')))
A:lightgbm.callback.n_metrics->len({m[1] for m in env.evaluation_result_list})
A:lightgbm.callback.best_score_str->'\t'.join([_format_eval_result(x, show_stdv=True) for x in self.best_score_list[i]])
A:lightgbm.callback.eval_name_splitted->env.evaluation_result_list[i][1].split(' ')
A:lightgbm.callback.eval_result_str->'\t'.join([_format_eval_result(x, show_stdv=True) for x in self.best_score_list[i]])
lightgbm.EarlyStopException(self,best_iteration:int,best_score:_ListOfEvalResultTuples)
lightgbm.callback.CallbackEnv
lightgbm.callback.EarlyStopException(self,best_iteration:int,best_score:_ListOfEvalResultTuples)
lightgbm.callback.EarlyStopException.__init__(self,best_iteration:int,best_score:_ListOfEvalResultTuples)
lightgbm.callback._EarlyStoppingCallback(self,stopping_rounds:int,first_metric_only:bool=False,verbose:bool=True,min_delta:Union[float,List[float]]=0.0)
lightgbm.callback._EarlyStoppingCallback.__init__(self,stopping_rounds:int,first_metric_only:bool=False,verbose:bool=True,min_delta:Union[float,List[float]]=0.0)
lightgbm.callback._EarlyStoppingCallback._final_iteration_check(self,env:CallbackEnv,eval_name_splitted:List[str],i:int)->None
lightgbm.callback._EarlyStoppingCallback._gt_delta(self,curr_score:float,best_score:float,delta:float)->bool
lightgbm.callback._EarlyStoppingCallback._init(self,env:CallbackEnv)->None
lightgbm.callback._EarlyStoppingCallback._is_train_set(self,ds_name:str,eval_name:str,env:CallbackEnv)->bool
lightgbm.callback._EarlyStoppingCallback._lt_delta(self,curr_score:float,best_score:float,delta:float)->bool
lightgbm.callback._EarlyStoppingCallback._reset_storages(self)->None
lightgbm.callback._LogEvaluationCallback(self,period:int=1,show_stdv:bool=True)
lightgbm.callback._LogEvaluationCallback.__init__(self,period:int=1,show_stdv:bool=True)
lightgbm.callback._RecordEvaluationCallback(self,eval_result:_EvalResultDict)
lightgbm.callback._RecordEvaluationCallback.__init__(self,eval_result:_EvalResultDict)
lightgbm.callback._RecordEvaluationCallback._init(self,env:CallbackEnv)->None
lightgbm.callback._ResetParameterCallback(self,**kwargs:Union[list,Callable])
lightgbm.callback._ResetParameterCallback.__init__(self,**kwargs:Union[list,Callable])
lightgbm.callback._format_eval_result(value:_EvalResultTuple,show_stdv:bool)->str
lightgbm.callback._should_enable_early_stopping(stopping_rounds:Any)->bool
lightgbm.callback.early_stopping(stopping_rounds:int,first_metric_only:bool=False,verbose:bool=True,min_delta:Union[float,List[float]]=0.0)->_EarlyStoppingCallback
lightgbm.callback.log_evaluation(period:int=1,show_stdv:bool=True)->_LogEvaluationCallback
lightgbm.callback.record_evaluation(eval_result:Dict[str,Dict[str,List[Any]]])->Callable
lightgbm.callback.reset_parameter(**kwargs:Union[list,Callable])->Callable
lightgbm.early_stopping(stopping_rounds:int,first_metric_only:bool=False,verbose:bool=True,min_delta:Union[float,List[float]]=0.0)->_EarlyStoppingCallback
lightgbm.log_evaluation(period:int=1,show_stdv:bool=True)->_LogEvaluationCallback
lightgbm.record_evaluation(eval_result:Dict[str,Dict[str,List[Any]]])->Callable
lightgbm.reset_parameter(**kwargs:Union[list,Callable])->Callable


----------------------------------------/dataset/nuaa/anaconda3/envs/lightgbm4.5.0/lib/python3.9/site-packages/lightgbm/plotting.py----------------------------------------
A:lightgbm.plotting.importance->booster.feature_importance(importance_type=importance_type)
A:lightgbm.plotting.feature_name->booster.feature_name()
A:lightgbm.plotting.tuples->sorted(zip(feature_name, importance), key=lambda x: x[1])
A:lightgbm.plotting.(labels, values)->zip(*tuples)
A:lightgbm.plotting.(_, ax)->matplotlib.pyplot.subplots(1, 1, figsize=figsize, dpi=dpi)
A:lightgbm.plotting.ylocs->numpy.arange(len(values))
A:lightgbm.plotting.xlabel->xlabel.replace('@importance_type@', importance_type).replace('@importance_type@', importance_type)
A:lightgbm.plotting.(hist, split_bins)->booster.get_split_value_histogram(feature=feature, bins=bins, xgboost_style=False)
A:lightgbm.plotting.title->title.replace('@index/name@', 'name' if isinstance(feature, str) else 'index').replace('@index/name@', 'name' if isinstance(feature, str) else 'index')
A:lightgbm.plotting.eval_results->deepcopy(booster)
A:lightgbm.plotting.num_data->len(eval_results)
A:lightgbm.plotting.dataset_names_iter->iter(dataset_names)
A:lightgbm.plotting.name->next(dataset_names_iter)
A:lightgbm.plotting.num_metric->len(metrics_for_one)
A:lightgbm.plotting.(metric, results)->metrics_for_one.popitem()
A:lightgbm.plotting.num_iteration->len(results)
A:lightgbm.plotting.max_result->max(*results, max_result)
A:lightgbm.plotting.min_result->min(*results, min_result)
A:lightgbm.plotting.x_->range(num_iteration)
A:lightgbm.plotting.ylabel->ylabel.replace('@metric@', metric).replace('@metric@', metric)
A:lightgbm.plotting.missing_type->_MissingType(missing_type_str)
A:lightgbm.plotting.direction->_determine_direction_for_numeric_split(fval=example_case[split_feature], threshold=root['threshold'], missing_type_str=root['missing_type'], default_left=root['default_left'])
A:lightgbm.plotting.category_values->root['threshold'].split('||')
A:lightgbm.plotting.graph->create_tree_digraph(booster=booster, tree_index=tree_index, show_info=show_info, precision=precision, orientation=orientation, example_case=example_case, **kwargs)
A:lightgbm.plotting.model->booster.dump_model()
A:lightgbm.plotting.feature_names->booster.dump_model().get('feature_names', None)
A:lightgbm.plotting.monotone_constraints->booster.dump_model().get('monotone_constraints', None)
A:lightgbm.plotting.s->BytesIO()
A:lightgbm.plotting.img->matplotlib.image.imread(s)
lightgbm.create_tree_digraph(booster:Union[Booster,LGBMModel],tree_index:int=0,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',example_case:Optional[Union[np.ndarray,pd_DataFrame]]=None,max_category_values:int=10,**kwargs:Any)->Any
lightgbm.plot_importance(booster:Union[Booster,LGBMModel],ax:'Optional[matplotlib.axes.Axes]'=None,height:float=0.2,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Featureimportance',xlabel:Optional[str]='Featureimportance',ylabel:Optional[str]='Features',importance_type:str='auto',max_num_features:Optional[int]=None,ignore_zero:bool=True,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,precision:Optional[int]=3,**kwargs:Any)->Any
lightgbm.plot_metric(booster:Union[Dict,LGBMModel],metric:Optional[str]=None,dataset_names:Optional[List[str]]=None,ax:'Optional[matplotlib.axes.Axes]'=None,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Metricduringtraining',xlabel:Optional[str]='Iterations',ylabel:Optional[str]='@metric@',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True)->Any
lightgbm.plot_split_value_histogram(booster:Union[Booster,LGBMModel],feature:Union[int,str],bins:Union[int,str,None]=None,ax:'Optional[matplotlib.axes.Axes]'=None,width_coef:float=0.8,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Splitvaluehistogramforfeaturewith@index/name@@feature@',xlabel:Optional[str]='Featuresplitvalue',ylabel:Optional[str]='Count',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,**kwargs:Any)->Any
lightgbm.plot_tree(booster:Union[Booster,LGBMModel],ax:'Optional[matplotlib.axes.Axes]'=None,tree_index:int=0,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',example_case:Optional[Union[np.ndarray,pd_DataFrame]]=None,**kwargs:Any)->Any
lightgbm.plotting._check_not_tuple_of_2_elements(obj:Any,obj_name:str)->None
lightgbm.plotting._determine_direction_for_categorical_split(fval:float,thresholds:str)->str
lightgbm.plotting._determine_direction_for_numeric_split(fval:float,threshold:float,missing_type_str:str,default_left:bool)->str
lightgbm.plotting._float2str(value:float,precision:Optional[int])->str
lightgbm.plotting._to_graphviz(tree_info:Dict[str,Any],show_info:List[str],feature_names:Union[List[str],None],precision:Optional[int],orientation:str,constraints:Optional[List[int]],example_case:Optional[Union[np.ndarray,pd_DataFrame]],max_category_values:int,**kwargs:Any)->Any
lightgbm.plotting.create_tree_digraph(booster:Union[Booster,LGBMModel],tree_index:int=0,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',example_case:Optional[Union[np.ndarray,pd_DataFrame]]=None,max_category_values:int=10,**kwargs:Any)->Any
lightgbm.plotting.plot_importance(booster:Union[Booster,LGBMModel],ax:'Optional[matplotlib.axes.Axes]'=None,height:float=0.2,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Featureimportance',xlabel:Optional[str]='Featureimportance',ylabel:Optional[str]='Features',importance_type:str='auto',max_num_features:Optional[int]=None,ignore_zero:bool=True,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,precision:Optional[int]=3,**kwargs:Any)->Any
lightgbm.plotting.plot_metric(booster:Union[Dict,LGBMModel],metric:Optional[str]=None,dataset_names:Optional[List[str]]=None,ax:'Optional[matplotlib.axes.Axes]'=None,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Metricduringtraining',xlabel:Optional[str]='Iterations',ylabel:Optional[str]='@metric@',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True)->Any
lightgbm.plotting.plot_split_value_histogram(booster:Union[Booster,LGBMModel],feature:Union[int,str],bins:Union[int,str,None]=None,ax:'Optional[matplotlib.axes.Axes]'=None,width_coef:float=0.8,xlim:Optional[Tuple[float,float]]=None,ylim:Optional[Tuple[float,float]]=None,title:Optional[str]='Splitvaluehistogramforfeaturewith@index/name@@feature@',xlabel:Optional[str]='Featuresplitvalue',ylabel:Optional[str]='Count',figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,grid:bool=True,**kwargs:Any)->Any
lightgbm.plotting.plot_tree(booster:Union[Booster,LGBMModel],ax:'Optional[matplotlib.axes.Axes]'=None,tree_index:int=0,figsize:Optional[Tuple[float,float]]=None,dpi:Optional[int]=None,show_info:Optional[List[str]]=None,precision:Optional[int]=3,orientation:str='horizontal',example_case:Optional[Union[np.ndarray,pd_DataFrame]]=None,**kwargs:Any)->Any

