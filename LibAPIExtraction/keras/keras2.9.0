
----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/losses.py----------------------------------------
A:keras.losses.self._name_scope->self.name.strip('_')
A:keras.losses.graph_ctx->keras.utils.tf_utils.graph_context_for_symbolic_tensors(y_true, y_pred, sample_weight)
A:keras.losses.call_fn->tensorflow.compat.v2.__internal__.autograph.tf_convert(self.call, tf.__internal__.autograph.control_status_ctx())
A:keras.losses.losses->call_fn(y_true, y_pred)
A:keras.losses.(y_pred, y_true)->keras.utils.losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)
A:keras.losses.ag_fn->tensorflow.compat.v2.__internal__.autograph.tf_convert(self.fn, tf.__internal__.autograph.control_status_ctx())
A:keras.losses.base_config->super(BinaryFocalCrossentropy, self).get_config()
A:keras.losses.y_pred->tensorflow.compat.v2.linalg.l2_normalize(y_pred, axis=axis)
A:keras.losses.y_true->tensorflow.compat.v2.linalg.l2_normalize(y_true, axis=axis)
A:keras.losses.r->r.to_tensor().to_tensor()
A:keras.losses.spec->tensorflow.compat.v2.TensorSpec(shape=[], dtype=y_pred.dtype)
A:keras.losses.map_fn->functools.partial(_wrapper, ragged_output=len(lshape) > 1)
A:keras.losses.assertion_list->tensorflow.python.ops.ragged.ragged_util.assert_splits_match(nested_splits_list)
A:keras.losses.diff->tensorflow.compat.v2.abs((y_true - y_pred) / backend.maximum(tf.abs(y_true), backend.epsilon()))
A:keras.losses.first_log->tensorflow.compat.v2.math.log(backend.maximum(y_pred, backend.epsilon()) + 1.0)
A:keras.losses.second_log->tensorflow.compat.v2.math.log(backend.maximum(y_true, backend.epsilon()) + 1.0)
A:keras.losses.are_zeros->tensorflow.compat.v2.equal(y_true, 0)
A:keras.losses.are_ones->tensorflow.compat.v2.equal(y_true, 1)
A:keras.losses.is_binary->tensorflow.compat.v2.reduce_all(tf.logical_or(are_zeros, are_ones))
A:keras.losses.updated_y_true->tensorflow.compat.v2.__internal__.smart_cond.smart_cond(is_binary, _convert_binary_labels, lambda : y_true)
A:keras.losses.pos->tensorflow.compat.v2.reduce_sum(y_true * y_pred, axis=-1)
A:keras.losses.neg->tensorflow.compat.v2.reduce_max((1.0 - y_true) * y_pred, axis=-1)
A:keras.losses.zero->tensorflow.compat.v2.cast(0.0, y_pred.dtype)
A:keras.losses.delta->tensorflow.compat.v2.cast(delta, dtype=backend.floatx())
A:keras.losses.error->tensorflow.compat.v2.subtract(y_pred, y_true)
A:keras.losses.abs_error->tensorflow.compat.v2.abs(error)
A:keras.losses.half->tensorflow.compat.v2.convert_to_tensor(0.5, dtype=abs_error.dtype)
A:keras.losses.label_smoothing->tensorflow.compat.v2.convert_to_tensor(label_smoothing, dtype=y_pred.dtype)
A:keras.losses.num_classes->tensorflow.compat.v2.cast(tf.shape(y_true)[-1], y_pred.dtype)
A:keras.losses.fn->functools.partial(binary_focal_crossentropy, gamma=gamma, from_logits=from_logits, label_smoothing=label_smoothing, axis=axis)
A:keras.losses.identifier->str(identifier)
keras.losses.BinaryCrossentropy(self,from_logits=False,label_smoothing=0.0,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='binary_crossentropy')
keras.losses.BinaryCrossentropy.__init__(self,from_logits=False,label_smoothing=0.0,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='binary_crossentropy')
keras.losses.BinaryFocalCrossentropy(self,gamma=2.0,from_logits=False,label_smoothing=0.0,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='binary_focal_crossentropy')
keras.losses.BinaryFocalCrossentropy.__init__(self,gamma=2.0,from_logits=False,label_smoothing=0.0,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='binary_focal_crossentropy')
keras.losses.BinaryFocalCrossentropy.get_config(self)
keras.losses.CategoricalCrossentropy(self,from_logits=False,label_smoothing=0.0,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='categorical_crossentropy')
keras.losses.CategoricalCrossentropy.__init__(self,from_logits=False,label_smoothing=0.0,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='categorical_crossentropy')
keras.losses.CategoricalHinge(self,reduction=losses_utils.ReductionV2.AUTO,name='categorical_hinge')
keras.losses.CategoricalHinge.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='categorical_hinge')
keras.losses.CosineSimilarity(self,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='cosine_similarity')
keras.losses.CosineSimilarity.__init__(self,axis=-1,reduction=losses_utils.ReductionV2.AUTO,name='cosine_similarity')
keras.losses.Hinge(self,reduction=losses_utils.ReductionV2.AUTO,name='hinge')
keras.losses.Hinge.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='hinge')
keras.losses.Huber(self,delta=1.0,reduction=losses_utils.ReductionV2.AUTO,name='huber_loss')
keras.losses.Huber.__init__(self,delta=1.0,reduction=losses_utils.ReductionV2.AUTO,name='huber_loss')
keras.losses.KLDivergence(self,reduction=losses_utils.ReductionV2.AUTO,name='kl_divergence')
keras.losses.KLDivergence.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='kl_divergence')
keras.losses.LogCosh(self,reduction=losses_utils.ReductionV2.AUTO,name='log_cosh')
keras.losses.LogCosh.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='log_cosh')
keras.losses.Loss(self,reduction=losses_utils.ReductionV2.AUTO,name=None)
keras.losses.Loss.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name=None)
keras.losses.Loss._get_reduction(self)
keras.losses.Loss._set_name_scope(self)
keras.losses.Loss.call(self,y_true,y_pred)
keras.losses.Loss.from_config(cls,config)
keras.losses.Loss.get_config(self)
keras.losses.LossFunctionWrapper(self,fn,reduction=losses_utils.ReductionV2.AUTO,name=None,**kwargs)
keras.losses.LossFunctionWrapper.__init__(self,fn,reduction=losses_utils.ReductionV2.AUTO,name=None,**kwargs)
keras.losses.LossFunctionWrapper.call(self,y_true,y_pred)
keras.losses.LossFunctionWrapper.get_config(self)
keras.losses.MeanAbsoluteError(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_absolute_error')
keras.losses.MeanAbsoluteError.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_absolute_error')
keras.losses.MeanAbsolutePercentageError(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_absolute_percentage_error')
keras.losses.MeanAbsolutePercentageError.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_absolute_percentage_error')
keras.losses.MeanSquaredError(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_squared_error')
keras.losses.MeanSquaredError.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_squared_error')
keras.losses.MeanSquaredLogarithmicError(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_squared_logarithmic_error')
keras.losses.MeanSquaredLogarithmicError.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='mean_squared_logarithmic_error')
keras.losses.Poisson(self,reduction=losses_utils.ReductionV2.AUTO,name='poisson')
keras.losses.Poisson.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='poisson')
keras.losses.SparseCategoricalCrossentropy(self,from_logits=False,reduction=losses_utils.ReductionV2.AUTO,name='sparse_categorical_crossentropy')
keras.losses.SparseCategoricalCrossentropy.__init__(self,from_logits=False,reduction=losses_utils.ReductionV2.AUTO,name='sparse_categorical_crossentropy')
keras.losses.SquaredHinge(self,reduction=losses_utils.ReductionV2.AUTO,name='squared_hinge')
keras.losses.SquaredHinge.__init__(self,reduction=losses_utils.ReductionV2.AUTO,name='squared_hinge')
keras.losses._maybe_convert_labels(y_true)
keras.losses._ragged_tensor_apply_loss(loss_fn,y_true,y_pred,y_pred_extra_dim=False)
keras.losses._ragged_tensor_binary_crossentropy(y_true,y_pred,from_logits=False,label_smoothing=0.0,axis=-1)
keras.losses._ragged_tensor_binary_focal_crossentropy(y_true,y_pred,gamma=2.0,from_logits=False,label_smoothing=0.0,axis=-1)
keras.losses._ragged_tensor_categorical_crossentropy(y_true,y_pred,from_logits=False,label_smoothing=0.0,axis=-1)
keras.losses._ragged_tensor_mae(y_true,y_pred)
keras.losses._ragged_tensor_mape(y_true,y_pred)
keras.losses._ragged_tensor_mse(y_true,y_pred)
keras.losses._ragged_tensor_msle(y_true,y_pred)
keras.losses._ragged_tensor_sparse_categorical_crossentropy(y_true,y_pred,from_logits=False,axis=-1)
keras.losses.binary_crossentropy(y_true,y_pred,from_logits=False,label_smoothing=0.0,axis=-1)
keras.losses.binary_focal_crossentropy(y_true,y_pred,gamma=2.0,from_logits=False,label_smoothing=0.0,axis=-1)
keras.losses.categorical_crossentropy(y_true,y_pred,from_logits=False,label_smoothing=0.0,axis=-1)
keras.losses.categorical_hinge(y_true,y_pred)
keras.losses.cosine_similarity(y_true,y_pred,axis=-1)
keras.losses.deserialize(name,custom_objects=None)
keras.losses.get(identifier)
keras.losses.hinge(y_true,y_pred)
keras.losses.huber(y_true,y_pred,delta=1.0)
keras.losses.is_categorical_crossentropy(loss)
keras.losses.kl_divergence(y_true,y_pred)
keras.losses.log_cosh(y_true,y_pred)
keras.losses.mean_absolute_error(y_true,y_pred)
keras.losses.mean_absolute_percentage_error(y_true,y_pred)
keras.losses.mean_squared_error(y_true,y_pred)
keras.losses.mean_squared_logarithmic_error(y_true,y_pred)
keras.losses.poisson(y_true,y_pred)
keras.losses.serialize(loss)
keras.losses.sparse_categorical_crossentropy(y_true,y_pred,from_logits=False,axis=-1)
keras.losses.squared_hinge(y_true,y_pred)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/regularizers.py----------------------------------------
A:keras.regularizers.self.l1->keras.backend.cast_to_floatx(l1)
A:keras.regularizers.self.l2->keras.backend.cast_to_floatx(l2)
A:keras.regularizers.regularization->keras.backend.constant(0.0, dtype=x.dtype)
A:keras.regularizers.l1->kwargs.pop('l', l1)
A:keras.regularizers.l2->kwargs.pop('l', l2)
A:keras.regularizers.self.factor->keras.backend.cast_to_floatx(factor)
A:keras.regularizers.inputs->tensorflow.compat.v2.math.l2_normalize(inputs, axis=0)
A:keras.regularizers.product->tensorflow.compat.v2.matmul(tf.transpose(inputs), inputs)
keras.regularizers.L1(self,l1=0.01,**kwargs)
keras.regularizers.L1.__init__(self,l1=0.01,**kwargs)
keras.regularizers.L1.get_config(self)
keras.regularizers.L1L2(self,l1=0.0,l2=0.0)
keras.regularizers.L1L2.__init__(self,l1=0.0,l2=0.0)
keras.regularizers.L1L2.get_config(self)
keras.regularizers.L2(self,l2=0.01,**kwargs)
keras.regularizers.L2.__init__(self,l2=0.01,**kwargs)
keras.regularizers.L2.get_config(self)
keras.regularizers.OrthogonalRegularizer(self,factor=0.01,mode='rows')
keras.regularizers.OrthogonalRegularizer.__init__(self,factor=0.01,mode='rows')
keras.regularizers.OrthogonalRegularizer.get_config(self)
keras.regularizers.Regularizer(self,x)
keras.regularizers.Regularizer.__call__(self,x)
keras.regularizers.Regularizer.from_config(cls,config)
keras.regularizers.Regularizer.get_config(self)
keras.regularizers._check_penalty_number(x)
keras.regularizers._none_to_default(inputs,default)
keras.regularizers.deserialize(config,custom_objects=None)
keras.regularizers.get(identifier)
keras.regularizers.l1_l2(l1=0.01,l2=0.01)
keras.regularizers.serialize(regularizer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/backend_config.py----------------------------------------
A:keras.backend_config._FLOATX->str(value)
A:keras.backend_config._IMAGE_DATA_FORMAT->str(data_format)
keras.backend_config.epsilon()
keras.backend_config.floatx()
keras.backend_config.image_data_format()
keras.backend_config.set_epsilon(value)
keras.backend_config.set_floatx(value)
keras.backend_config.set_image_data_format(data_format)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/backend.py----------------------------------------
A:keras.backend._GRAPH->threading.local()
A:keras.backend._CURRENT_SCRATCH_GRAPH->threading.local()
A:keras.backend._SESSION->SessionLocal()
A:keras.backend.PER_GRAPH_OBJECT_NAME_UIDS->weakref.WeakKeyDictionary()
A:keras.backend.OBSERVED_NAMES->set()
A:keras.backend.self.key->_DummyEagerGraph._WeakReferencableClass()
A:keras.backend._DUMMY_EAGER_GRAPH->_DummyEagerGraph()
A:keras.backend.graph->get_graph()
A:keras.backend.PER_GRAPH_OBJECT_NAME_UIDS[graph]->collections.defaultdict(int)
A:keras.backend.phase->ContextValueCache(object_identity.ObjectIdentityWeakSet).get(graph, None)
A:keras.backend.learning_phase->symbolic_learning_phase()
A:keras.backend.value_ref->weakref.ref(value)
A:keras.backend.previous_eager_value->_internal_get_learning_phase(_DUMMY_EAGER_GRAPH.key)
A:keras.backend.previous_graph_value->_internal_get_learning_phase(get_graph())
A:keras.backend.global_learning_phase_was_set->global_learning_phase_is_set()
A:keras.backend.previous_value->learning_phase()
A:keras.backend.conv_fn->getattr(obj, '_as_graph_element', None)
A:keras.backend.original_graph->getattr(original_item, 'graph', None)
A:keras.backend.current_default_graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.backend.op_input_list->tuple(op_input_list)
A:keras.backend.graph_element->_as_graph_element(op_input)
A:keras.backend.default_session->tensorflow.compat.v2.compat.v1.get_default_session()
A:keras.backend._SESSION.session->tensorflow.compat.v2.compat.v1.Session(config=get_default_session_config())
A:keras.backend.session->tensorflow.compat.v2.compat.v1.Session(config=session_config)
A:keras.backend._GRAPH.graph->tensorflow.compat.v2.__internal__.FuncGraph('keras_graph')
A:keras.backend.scratch_graph->getattr(_CURRENT_SCRATCH_GRAPH, 'graph', None)
A:keras.backend.config->get_config()
A:keras.backend.name_uid_map->get_default_graph_uid_map()
A:keras.backend.device->_get_current_tf_device()
A:keras.backend.op->tensorflow.compat.v2.print(message, x, output_stream=sys.stdout, summarize=summarize)
A:keras.backend.device_type->device_type.upper().upper()
A:keras.backend._LOCAL_DEVICES->get_session().list_devices()
A:keras.backend.explicitly_on_cpu->_is_current_explicit_device('CPU')
A:keras.backend.gpus_available->bool(_get_available_gpus())
A:keras.backend.spec->tensorflow.compat.v2.TensorSpec(shape=shape, dtype=dtype, name=name)
A:keras.backend.dtype->floatx()
A:keras.backend.sparse_coo->self._get_recursive(key).tocoo()
A:keras.backend.indices->tensorflow.compat.v2.compat.v1.transpose(tf.reshape(concatenate([batch_ind, label_ind], axis=0), [2, -1]))
A:keras.backend.v->tensorflow.compat.v2.ones(shape=shape, dtype=tf_dtype, name=name)
A:keras.backend.v._keras_shape->int_shape(value)
A:keras.backend.avoid_names->set()
A:keras.backend.variables->_get_variables(get_graph())
A:keras.backend.is_initialized->tensorflow.compat.v2.compat.v1.Session(config=session_config).run([tf.compat.v1.is_variable_initialized(v) for v in candidate_vars])
A:keras.backend.x->tensorflow.compat.v2.compat.v1.transpose(x, (0, 4, 1, 2, 3))
A:keras.backend.type_spec->tensorflow.compat.v2.RaggedTensorSpec(shape=shape, dtype=dtype, ragged_rank=ragged_rank)
A:keras.backend.flat_components->tensorflow.compat.v2.nest.flatten(x, expand_composites=True)
A:keras.backend.shape->output_.shape.as_list()
A:keras.backend.tf_dtype->tensorflow.compat.v2.as_dtype(x.dtype.name.split('_')[0])
A:keras.backend._SEED_GENERATOR->threading.local()
A:keras.backend.self._generator->tensorflow.compat.v2.random.Generator.from_seed(seed)
A:keras.backend.seed->numpy.random.randint(10000000.0)
A:keras.backend.value->self._get_recursive(key)
A:keras.backend.momentum->tensorflow.compat.v2.cast(momentum, x.dtype)
A:keras.backend.x_shape->tensorflow.compat.v2.compat.v1.transpose(x, (0, 4, 1, 2, 3)).shape.as_list()
A:keras.backend.y_shape->shape(y)
A:keras.backend.y_permute_dim->list(range(ndim(y)))
A:keras.backend.xt->tensorflow.compat.v2.reshape(x, [-1, x_shape[-1]])
A:keras.backend.yt->tensorflow.compat.v2.reshape(tf.compat.v1.transpose(y, perm=y_permute_dim), [y_shape[-2], -1])
A:keras.backend.out->tensorflow.compat.v2.matmul(x, y)
A:keras.backend.x_ndim->len(x_shape)
A:keras.backend.y_ndim->len(y_shape)
A:keras.backend.axes->list(range(len(input_t.shape)))
A:keras.backend.y->tensorflow.compat.v2.cast(y, dtype=x.dtype)
A:keras.backend.pattern->tensorflow.compat.v2.stack([1, n, 1])
A:keras.backend.x_squashed_shape->tensorflow.compat.v2.stack([x_shape[0], -1, x_shape[-1]])
A:keras.backend.y_squashed_shape->tensorflow.compat.v2.stack([y_shape[0], y_shape[1], -1])
A:keras.backend.result->cast(result, dtype)
A:keras.backend.output_shape->tensorflow.compat.v2.stack(list(output_shape))
A:keras.backend.zero->_constant_to_tensor(0, x.dtype.base_dtype)
A:keras.backend.(mean, var)->tensorflow.compat.v2.compat.v1.nn.moments(x, reduction_axes, None, None, False)
A:keras.backend.normed->tensorflow.compat.v2.nn.batch_normalization(x, broadcast_mean, broadcast_var, broadcast_beta, broadcast_gamma, epsilon)
A:keras.backend.target_shape->tensorflow.compat.v2.stack(target_shape)
A:keras.backend.broadcast_mean->tensorflow.compat.v2.reshape(mean, target_shape)
A:keras.backend.broadcast_var->tensorflow.compat.v2.reshape(var, target_shape)
A:keras.backend.broadcast_gamma->tensorflow.compat.v2.reshape(gamma, target_shape)
A:keras.backend.broadcast_beta->tensorflow.compat.v2.reshape(beta, target_shape)
A:keras.backend.gamma->tensorflow.compat.v2.reshape(gamma, [-1])
A:keras.backend.beta->tensorflow.compat.v2.reshape(beta, [-1])
A:keras.backend.mean->tensorflow.compat.v2.reshape(mean, [-1])
A:keras.backend.var->tensorflow.compat.v2.reshape(var, [-1])
A:keras.backend.(y, _, _)->tensorflow.compat.v2.compat.v1.nn.fused_batch_norm(x, gamma, beta, epsilon=epsilon, mean=mean, variance=var, data_format=tf_data_format, is_training=False)
A:keras.backend.rank->ndim(tensors[0])
A:keras.backend.new_shape->tensorflow.compat.v2.constant(new_shape.as_list(), dtype='int32')
A:keras.backend.output->reverse(output, [1])
A:keras.backend.splits->tensorflow.compat.v2.split(value=x, num_or_size_splits=x_shape[axis], axis=axis)
A:keras.backend.x_rep->tensorflow.compat.v2.reshape(x_rep, x_shape)
A:keras.backend.reps->tensorflow.compat.v2.constant(reps, dtype='int32')
A:keras.backend.x_rep._keras_shape->tuple(x_shape)
A:keras.backend.data_format->image_data_format()
A:keras.backend.placeholder_shape->tensorflow.compat.v2.TensorShape([None] * value.ndim)
A:keras.backend.assign_placeholder->tensorflow.compat.v2.compat.v1.placeholder(tf_dtype, shape=placeholder_shape)
A:keras.backend.assign_op->tensorflow.compat.v2.compat.v1.transpose(x, (0, 4, 1, 2, 3)).assign(assign_placeholder)
A:keras.backend.get_value.__doc__->get_value.__doc__.format(snippet=_VALUE_SET_CODE_STRING)
A:keras.backend.set_value.__doc__->set_value.__doc__.format(snippet=_VALUE_SET_CODE_STRING)
A:keras.backend.self.inputs->tensorflow.compat.v2.nest.flatten(inputs, expand_composites=True)
A:keras.backend.self.outputs->cast_variables_to_tensor(tf.nest.flatten(outputs, expand_composites=True))
A:keras.backend.self.updates_op->tensorflow.compat.v2.group(*updates_ops)
A:keras.backend.self.feed_dict->session_kwargs.pop('feed_dict', None)
A:keras.backend.self.fetches->session_kwargs.pop('fetches', [])
A:keras.backend.self.run_options->session_kwargs.pop('options', None)
A:keras.backend.self.run_metadata->session_kwargs.pop('run_metadata', None)
A:keras.backend.callable_opts->tensorflow.core.protobuf.config_pb2.CallableOptions()
A:keras.backend.connection->tensorflow.core.protobuf.config_pb2.CallableOptions().tensor_connection.add()
A:keras.backend.from_tensor->_as_graph_element(y)
A:keras.backend.callable_fn->tensorflow.compat.v2.compat.v1.Session(config=session_config)._make_callable_from_options(callable_opts)
A:keras.backend.self._fetches->list(self.fetches)
A:keras.backend.inputs->tensorflow.compat.v2.nest.map_structure(_convert_ragged_input, inputs)
A:keras.backend.tensor_type->tensorflow.compat.v2.as_dtype(tensor.dtype)
A:keras.backend.fetched->self._callable_fn(*array_vals, run_metadata=self.run_metadata)
A:keras.backend.output_structure->tensorflow.compat.v2.nest.pack_sequence_as(self._outputs_structure, fetched[:len(self.outputs)], expand_composites=True)
A:keras.backend.model->keras.models.Model(inputs=inputs, outputs=outputs)
A:keras.backend.outs->model(model_inputs)
A:keras.backend.flatted_inputs->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.backend.mask->reverse(mask, 0)
A:keras.backend.mask_t->masking_fn(time)
A:keras.backend.states->tuple(initial_states)
A:keras.backend.input_t->tensorflow.compat.v2.unstack(input_t)
A:keras.backend.processed_input->tensorflow.compat.v2.nest.map_structure(_process_single_input_t, inputs)
A:keras.backend.mask_list->tensorflow.compat.v2.unstack(mask)
A:keras.backend.inp->_get_input_tensor(i)
A:keras.backend.(output, new_states)->step_function(current_input, tuple(states) + tuple(constants))
A:keras.backend.tiled_mask_t->tuple((_expand_mask(mask_t, o, fixed_dim=len(mask_t.shape)) for o in flat_out))
A:keras.backend.prev_output->zeros_like(output)
A:keras.backend.flat_states->tensorflow.compat.v2.nest.flatten(states)
A:keras.backend.flat_new_states->tensorflow.compat.v2.nest.flatten(new_states)
A:keras.backend.flat_final_states->tuple((tf.where(m, s, ps) for (m, s, ps) in zip(tiled_mask_t, flat_new_states, flat_states)))
A:keras.backend.outputs->tensorflow.compat.v2.nest.map_structure(swap_batch_timestep, outputs)
A:keras.backend.last_output->tensorflow.compat.v2.nest.pack_sequence_as(output_time_zero, last_output)
A:keras.backend.(output, states)->step_function(inp, tuple(states) + tuple(constants))
A:keras.backend.input_ta->tuple((ta.unstack(input_) if not go_backwards else ta.unstack(reverse(input_, 0)) for (ta, input_) in zip(input_ta, flatted_inputs)))
A:keras.backend.input_time_zero->tensorflow.compat.v2.nest.pack_sequence_as(inputs, [inp[0] for inp in flatted_inputs])
A:keras.backend.(output_time_zero, _)->step_function(input_time_zero, tuple(initial_states) + tuple(constants))
A:keras.backend.output_ta->tuple((tf.TensorArray(dtype=out.dtype, size=output_ta_size, element_shape=out.shape, tensor_array_name='output_ta_%s' % i) for (i, out) in enumerate(tf.nest.flatten(output_time_zero))))
A:keras.backend.time->tensorflow.compat.v2.constant(0, dtype='int32', name='time')
A:keras.backend.max_iterations->tensorflow.compat.v2.reduce_max(input_length)
A:keras.backend.mask_ta->mask_ta.unstack(mask).unstack(mask)
A:keras.backend.max_len->tensorflow.compat.v2.reduce_max(input_length, axis=0)
A:keras.backend.rev_input_length->tensorflow.compat.v2.subtract(max_len - 1, input_length)
A:keras.backend.flat_zero_output->tuple((tf.zeros_like(o) for o in tf.nest.flatten(output_time_zero)))
A:keras.backend.current_input->tensorflow.compat.v2.nest.pack_sequence_as(inputs, current_input)
A:keras.backend.flat_output->tensorflow.compat.v2.nest.flatten(output)
A:keras.backend.flat_new_output->compute_masked_output(mask_t, flat_output, flat_mask_output)
A:keras.backend.flat_state->tensorflow.compat.v2.nest.flatten(states)
A:keras.backend.flat_new_state->tensorflow.compat.v2.nest.flatten(new_states)
A:keras.backend.flat_final_state->compute_masked_output(mask_t, flat_new_state, flat_state)
A:keras.backend.new_states->tensorflow.compat.v2.nest.pack_sequence_as(initial_states, flat_new_state)
A:keras.backend.output_ta_t->tuple((ta.write(ta_index_to_write, out) for (ta, out) in zip(output_ta_t, flat_output)))
A:keras.backend.final_outputs->tensorflow.compat.v2.compat.v1.while_loop(body=_step, loop_vars=(time, output_ta) + states, **while_loop_kwargs)
A:keras.backend.condition->tensorflow.compat.v2.tile(condition, tile_shape)
A:keras.backend.cond_ndim->ndim(condition)
A:keras.backend.then_expression->then_expression()
A:keras.backend.else_expression->else_expression()
A:keras.backend.expr_ndim->ndim(then_expression)
A:keras.backend.cond_shape->tensorflow.compat.v2.concat([tf.shape(condition), [1] * ndim_diff], axis=0)
A:keras.backend.expr_shape->tensorflow.compat.v2.shape(then_expression)
A:keras.backend.tile_shape->tensorflow.compat.v2.where(shape_diff > 0, expr_shape, tf.ones_like(expr_shape))
A:keras.backend.training->learning_phase()
A:keras.backend.negative_part->tensorflow.compat.v2.nn.relu(-x)
A:keras.backend.max_value->_constant_to_tensor(max_value, x.dtype.base_dtype)
A:keras.backend.alpha->_to_tensor(alpha, x.dtype.base_dtype)
A:keras.backend.res->tensorflow.compat.v2.nn.sparse_softmax_cross_entropy_with_logits(labels=target, logits=output)
A:keras.backend.target->tensorflow.compat.v2.convert_to_tensor(target)
A:keras.backend.epsilon_->_constant_to_tensor(epsilon(), output.dtype.base_dtype)
A:keras.backend.output_rank->len(output.shape)
A:keras.backend.permutation->list(itertools.chain(range(axis), range(axis + 1, output_rank), [axis]))
A:keras.backend.sigmoidal->tensorflow.compat.v2.__internal__.smart_cond.smart_cond(from_logits, lambda : sigmoid(output), lambda : output)
A:keras.backend.focal_factor->tensorflow.compat.v2.pow(1.0 - p_t, gamma)
A:keras.backend.bce->binary_crossentropy(target=target, output=output, from_logits=from_logits)
A:keras.backend.bfce->binary_focal_crossentropy(target=target, output=output, gamma=gamma, from_logits=from_logits)
A:keras.backend.point_two->_constant_to_tensor(0.2, x.dtype.base_dtype)
A:keras.backend.point_five->_constant_to_tensor(0.5, x.dtype.base_dtype)
A:keras.backend.kernel_shape->int_shape(kernel)
A:keras.backend.padding->_preprocess_padding(padding)
A:keras.backend.(x, tf_data_format)->_preprocess_conv3d_input(x, data_format)
A:keras.backend.strides->tuple(strides)
A:keras.backend.depthwise_kernel->tensorflow.compat.v2.expand_dims(depthwise_kernel, 0)
A:keras.backend.pointwise_kernel->tensorflow.compat.v2.expand_dims(pointwise_kernel, 0)
A:keras.backend.ndims->len(output_shape)
A:keras.backend.spatial_dimensions->list(range(ndims))
A:keras.backend.x_aggregate->concatenate(xs, axis=0)
A:keras.backend.bias_shape->int_shape(bias)
A:keras.backend.label_shape->tensorflow.compat.v2.shape(labels)
A:keras.backend.num_batches_tns->tensorflow.compat.v2.stack([label_shape[0]])
A:keras.backend.max_num_labels_tns->tensorflow.compat.v2.stack([label_shape[1]])
A:keras.backend.init->tensorflow.compat.v2.cast(tf.fill([1, label_shape[1]], 0), tf.bool)
A:keras.backend.dense_mask->tensorflow.compat.v2.compat.v1.scan(range_less_than, label_lengths, initializer=init, parallel_iterations=1)
A:keras.backend.label_array->tensorflow.compat.v2.reshape(tf.tile(tf.range(0, label_shape[1]), num_batches_tns), label_shape)
A:keras.backend.label_ind->tensorflow.compat.v2.compat.v1.boolean_mask(label_array, dense_mask)
A:keras.backend.batch_array->tensorflow.compat.v2.compat.v1.transpose(tf.reshape(tf.tile(tf.range(0, label_shape[0]), max_num_labels_tns), reverse(label_shape, 0)))
A:keras.backend.batch_ind->tensorflow.compat.v2.compat.v1.boolean_mask(batch_array, dense_mask)
A:keras.backend.vals_sparse->tensorflow.compat.v2.compat.v1.gather_nd(labels, indices)
A:keras.backend.label_length->tensorflow.compat.v2.cast(tf.squeeze(label_length, axis=-1), tf.int32)
A:keras.backend.input_length->tensorflow.compat.v2.cast(input_length, tf.int32)
A:keras.backend.sparse_labels->tensorflow.compat.v2.cast(ctc_label_dense_to_sparse(y_true, label_length), tf.int32)
A:keras.backend.y_pred->tensorflow.compat.v2.math.log(tf.compat.v1.transpose(y_pred, perm=[1, 0, 2]) + epsilon())
A:keras.backend.input_shape->shape(y_pred)
A:keras.backend.(decoded, log_prob)->tensorflow.compat.v2.compat.v1.nn.ctc_beam_search_decoder(inputs=y_pred, sequence_length=input_length, beam_width=beam_width, top_paths=top_paths)
A:keras.backend.st->tensorflow.compat.v2.SparseTensor(st.indices, st.values, (num_samples, num_steps))
A:keras.backend._keras_dir->os.path.join(_keras_base_dir, '.keras')
A:keras.backend._keras_base_dir->os.path.expanduser('~')
A:keras.backend._config_path->os.path.expanduser(os.path.join(_keras_dir, 'keras.json'))
A:keras.backend._config->json.load(fh)
A:keras.backend._floatx->json.load(fh).get('floatx', floatx())
A:keras.backend._epsilon->json.load(fh).get('epsilon', epsilon())
A:keras.backend._image_data_format->json.load(fh).get('image_data_format', image_data_format())
A:keras.backend.session_config->get_default_session_config()
A:keras.backend.master->distribution_strategy.extended._tpu_cluster_resolver.master()
A:keras.backend.worker_context->keras.distribute.distribute_coordinator_utils.get_current_worker_context()
A:keras.backend.flat_inputs->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.backend.contains_ragged->py_any((isinstance(i, tf.RaggedTensor) for i in flat_inputs))
A:keras.backend.nested_row_lengths->tensorflow.compat.v2.cast(flat_inputs[0].nested_row_lengths()[0], 'int32')
A:keras.backend.ragged->tensorflow.compat.v2.RaggedTensor.from_tensor(output, nested_row_lengths)
A:keras.backend.key->self._key()
A:keras.backend.valueself[key]->self.default_factory()
A:keras.backend.default->self.default_factory(**kwargs)
A:keras.backend._GRAPH_LEARNING_PHASES->ContextValueCache(object_identity.ObjectIdentityWeakSet)
A:keras.backend._GRAPH_VARIABLES->ContextValueCache(object_identity.ObjectIdentityWeakSet)
A:keras.backend._GRAPH_TF_OPTIMIZERS->ContextValueCache(object_identity.ObjectIdentityWeakSet)
keras.backend.ContextValueCache(self,default_factory)
keras.backend.ContextValueCache.__getitem__(self,key)
keras.backend.ContextValueCache.__init__(self,default_factory)
keras.backend.ContextValueCache._get_parent_graph(self,graph)
keras.backend.ContextValueCache._get_recursive(self,key)
keras.backend.ContextValueCache._key(self)
keras.backend.ContextValueCache.setdefault(self,key=None,default=None,kwargs=None)
keras.backend.GraphExecutionFunction(self,inputs,outputs,updates=None,name=None,**session_kwargs)
keras.backend.GraphExecutionFunction.__init__(self,inputs,outputs,updates=None,name=None,**session_kwargs)
keras.backend.GraphExecutionFunction._call_fetch_callbacks(self,fetches_output)
keras.backend.GraphExecutionFunction._eval_if_composite(self,tensor)
keras.backend.GraphExecutionFunction._make_callable(self,feed_arrays,feed_symbols,symbol_vals,session)
keras.backend.RandomGenerator(self,seed=None,force_generator=False)
keras.backend.RandomGenerator.__init__(self,seed=None,force_generator=False)
keras.backend.RandomGenerator._maybe_init(self)
keras.backend.RandomGenerator.dropout(self,inputs,rate,noise_shape=None)
keras.backend.RandomGenerator.make_legacy_seed(self)
keras.backend.RandomGenerator.make_seed_for_stateless_op(self)
keras.backend.RandomGenerator.random_normal(self,shape,mean=0.0,stddev=1.0,dtype=None)
keras.backend.RandomGenerator.random_uniform(self,shape,minval=0.0,maxval=None,dtype=None)
keras.backend.RandomGenerator.truncated_normal(self,shape,mean=0.0,stddev=1.0,dtype=None)
keras.backend.SessionLocal(self)
keras.backend.SessionLocal.__init__(self)
keras.backend._DummyEagerGraph(self)
keras.backend._DummyEagerGraph._WeakReferencableClass
keras.backend._DummyEagerGraph.__init__(self)
keras.backend._TfDeviceCaptureOp(self)
keras.backend._TfDeviceCaptureOp.__init__(self)
keras.backend._TfDeviceCaptureOp._set_device(self,device)
keras.backend._TfDeviceCaptureOp._set_device_from_string(self,device_str)
keras.backend._as_graph_element(obj)
keras.backend._assert_same_graph(original_item,item)
keras.backend._broadcast_normalize_batch_in_training(x,gamma,beta,reduction_axes,epsilon=0.001)
keras.backend._constant_to_tensor(x,dtype)
keras.backend._current_graph(op_input_list,graph=None)
keras.backend._default_learning_phase()
keras.backend._fused_normalize_batch_in_training(x,gamma,beta,reduction_axes,epsilon=0.001)
keras.backend._get_available_gpus()
keras.backend._get_current_tf_device()
keras.backend._get_session(op_input_list=())
keras.backend._get_variables(graph=None)
keras.backend._has_nchw_support()
keras.backend._initialize_variables(session)
keras.backend._internal_get_learning_phase(graph)
keras.backend._internal_set_learning_phase(graph,value)
keras.backend._is_current_explicit_device(device_type)
keras.backend._is_symbolic_tensor(x)
keras.backend._is_tpu_strategy_class(clz)
keras.backend._mark_func_graph_as_unsaveable(graph,learning_phase)
keras.backend._preprocess_conv1d_input(x,data_format)
keras.backend._preprocess_conv2d_input(x,data_format,force_transpose=False)
keras.backend._preprocess_conv3d_input(x,data_format)
keras.backend._preprocess_padding(padding)
keras.backend._regular_normalize_batch_in_training(x,gamma,beta,reduction_axes,epsilon=0.001)
keras.backend._scratch_graph(graph=None)
keras.backend._to_tensor(x,dtype)
keras.backend.abs(x)
keras.backend.all(x,axis=None,keepdims=False)
keras.backend.any(x,axis=None,keepdims=False)
keras.backend.arange(start,stop=None,step=1,dtype='int32')
keras.backend.argmax(x,axis=-1)
keras.backend.argmin(x,axis=-1)
keras.backend.backend()
keras.backend.batch_dot(x,y,axes=None)
keras.backend.batch_flatten(x)
keras.backend.batch_get_value(tensors)
keras.backend.batch_normalization(x,mean,var,beta,gamma,axis=-1,epsilon=0.001)
keras.backend.batch_set_value(tuples)
keras.backend.bias_add(x,bias,data_format=None)
keras.backend.binary_crossentropy(target,output,from_logits=False)
keras.backend.binary_focal_crossentropy(target,output,gamma=2.0,from_logits=False)
keras.backend.binary_weighted_focal_crossentropy(target,output,alpha=0.25,gamma=2.0,from_logits=False)
keras.backend.cast(x,dtype)
keras.backend.cast_to_floatx(x)
keras.backend.cast_variables_to_tensor(tensors)
keras.backend.categorical_crossentropy(target,output,from_logits=False,axis=-1)
keras.backend.clear_session()
keras.backend.clip(x,min_value,max_value)
keras.backend.concatenate(tensors,axis=-1)
keras.backend.configure_and_create_distributed_session(distribution_strategy)
keras.backend.constant(value,dtype=None,shape=None,name=None)
keras.backend.conv1d(x,kernel,strides=1,padding='valid',data_format=None,dilation_rate=1)
keras.backend.conv2d(x,kernel,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1))
keras.backend.conv2d_transpose(x,kernel,output_shape,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1))
keras.backend.conv3d(x,kernel,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1))
keras.backend.conv3d_transpose(x,kernel,output_shape,strides=(1,1,1),padding='valid',data_format=None)
keras.backend.convert_inputs_if_ragged(inputs)
keras.backend.cos(x)
keras.backend.count_params(x)
keras.backend.ctc_batch_cost(y_true,y_pred,input_length,label_length)
keras.backend.ctc_decode(y_pred,input_length,greedy=True,beam_width=100,top_paths=1)
keras.backend.ctc_label_dense_to_sparse(labels,label_lengths)
keras.backend.cumprod(x,axis=0)
keras.backend.cumsum(x,axis=0)
keras.backend.deprecated_internal_learning_phase_scope(value)
keras.backend.deprecated_internal_set_learning_phase(value)
keras.backend.depthwise_conv2d(x,depthwise_kernel,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1))
keras.backend.disable_tf_random_generator()
keras.backend.dot(x,y)
keras.backend.dropout(x,level,noise_shape=None,seed=None)
keras.backend.dtype(x)
keras.backend.dtype_numpy(x)
keras.backend.eager_learning_phase_scope(value)
keras.backend.elu(x,alpha=1.0)
keras.backend.enable_tf_random_generator()
keras.backend.equal(x,y)
keras.backend.eval(x)
keras.backend.exp(x)
keras.backend.expand_dims(x,axis=-1)
keras.backend.eye(size,dtype=None,name=None)
keras.backend.flatten(x)
keras.backend.foldl(fn,elems,initializer=None,name=None)
keras.backend.foldr(fn,elems,initializer=None,name=None)
keras.backend.function(inputs,outputs,updates=None,name=None,**kwargs)
keras.backend.gather(reference,indices)
keras.backend.get_default_graph_uid_map()
keras.backend.get_default_session_config()
keras.backend.get_graph()
keras.backend.get_session(op_input_list=())
keras.backend.get_uid(prefix='')
keras.backend.get_value(x)
keras.backend.global_learning_phase_is_set()
keras.backend.gradients(loss,variables)
keras.backend.greater(x,y)
keras.backend.greater_equal(x,y)
keras.backend.hard_sigmoid(x)
keras.backend.identity(x,name=None)
keras.backend.in_test_phase(x,alt,training=None)
keras.backend.in_top_k(predictions,targets,k)
keras.backend.in_train_phase(x,alt,training=None)
keras.backend.int_shape(x)
keras.backend.is_keras_tensor(x)
keras.backend.is_placeholder(x)
keras.backend.is_sparse(tensor)
keras.backend.is_tf_random_generator_enabled()
keras.backend.is_tpu_strategy(strategy)
keras.backend.l2_normalize(x,axis=None)
keras.backend.learning_phase()
keras.backend.learning_phase_scope(value)
keras.backend.less(x,y)
keras.backend.less_equal(x,y)
keras.backend.local_conv(inputs,kernel,kernel_size,strides,output_shape,data_format=None)
keras.backend.local_conv1d(inputs,kernel,kernel_size,strides,data_format=None)
keras.backend.local_conv2d(inputs,kernel,kernel_size,strides,output_shape,data_format=None)
keras.backend.log(x)
keras.backend.logsumexp(x,axis=None,keepdims=False)
keras.backend.manual_variable_initialization(value)
keras.backend.map_fn(fn,elems,name=None,dtype=None)
keras.backend.max(x,axis=None,keepdims=False)
keras.backend.maximum(x,y)
keras.backend.maybe_convert_to_ragged(is_ragged_input,output,nested_row_lengths,go_backwards=False)
keras.backend.mean(x,axis=None,keepdims=False)
keras.backend.min(x,axis=None,keepdims=False)
keras.backend.minimum(x,y)
keras.backend.moving_average_update(x,value,momentum)
keras.backend.name_scope(name)
keras.backend.ndim(x)
keras.backend.normalize_batch_in_training(x,gamma,beta,reduction_axes,epsilon=0.001)
keras.backend.not_equal(x,y)
keras.backend.observe_object_name(name)
keras.backend.one_hot(indices,num_classes)
keras.backend.ones(shape,dtype=None,name=None)
keras.backend.ones_like(x,dtype=None,name=None)
keras.backend.permute_dimensions(x,pattern)
keras.backend.placeholder(shape=None,ndim=None,dtype=None,sparse=False,name=None,ragged=False)
keras.backend.pool2d(x,pool_size,strides=(1,1),padding='valid',data_format=None,pool_mode='max')
keras.backend.pool3d(x,pool_size,strides=(1,1,1),padding='valid',data_format=None,pool_mode='max')
keras.backend.pow(x,a)
keras.backend.print_tensor(x,message='',summarize=3)
keras.backend.prod(x,axis=None,keepdims=False)
keras.backend.random_bernoulli(shape,p=0.0,dtype=None,seed=None)
keras.backend.random_binomial(shape,p=0.0,dtype=None,seed=None)
keras.backend.random_normal(shape,mean=0.0,stddev=1.0,dtype=None,seed=None)
keras.backend.random_normal_variable(shape,mean,scale,dtype=None,name=None,seed=None)
keras.backend.random_uniform(shape,minval=0.0,maxval=1.0,dtype=None,seed=None)
keras.backend.random_uniform_variable(shape,low,high,dtype=None,name=None,seed=None)
keras.backend.relu(x,alpha=0.0,max_value=None,threshold=0.0)
keras.backend.repeat(x,n)
keras.backend.repeat_elements(x,rep,axis)
keras.backend.reset_uids()
keras.backend.reshape(x,shape)
keras.backend.resize_images(x,height_factor,width_factor,data_format,interpolation='nearest')
keras.backend.resize_volumes(x,depth_factor,height_factor,width_factor,data_format)
keras.backend.reverse(x,axes)
keras.backend.rnn(step_function,inputs,initial_states,go_backwards=False,mask=None,constants=None,unroll=False,input_length=None,time_major=False,zero_output_for_mask=False,return_all_outputs=True)
keras.backend.round(x)
keras.backend.separable_conv1d(x,depthwise_kernel,pointwise_kernel,strides=1,padding='valid',data_format=None,dilation_rate=1)
keras.backend.separable_conv2d(x,depthwise_kernel,pointwise_kernel,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1))
keras.backend.set_learning_phase(value)
keras.backend.set_session(session)
keras.backend.set_value(x,value)
keras.backend.shape(x)
keras.backend.sigmoid(x)
keras.backend.sign(x)
keras.backend.sin(x)
keras.backend.softmax(x,axis=-1)
keras.backend.softplus(x)
keras.backend.softsign(x)
keras.backend.sparse_categorical_crossentropy(target,output,from_logits=False,axis=-1)
keras.backend.spatial_2d_padding(x,padding=((1,1),(1,1)),data_format=None)
keras.backend.spatial_3d_padding(x,padding=((1,1),(1,1),(1,1)),data_format=None)
keras.backend.sqrt(x)
keras.backend.square(x)
keras.backend.squeeze(x,axis)
keras.backend.stack(x,axis=0)
keras.backend.std(x,axis=None,keepdims=False)
keras.backend.stop_gradient(variables)
keras.backend.sum(x,axis=None,keepdims=False)
keras.backend.switch(condition,then_expression,else_expression)
keras.backend.symbolic_learning_phase()
keras.backend.tanh(x)
keras.backend.temporal_padding(x,padding=(1,1))
keras.backend.tile(x,n)
keras.backend.to_dense(tensor)
keras.backend.track_tf_optimizer(tf_optimizer)
keras.backend.track_variable(v)
keras.backend.transpose(x)
keras.backend.truncated_normal(shape,mean=0.0,stddev=1.0,dtype=None,seed=None)
keras.backend.unique_object_name(name,name_uid_map=None,avoid_names=None,namespace='',zero_based=False,avoid_observed_names=False)
keras.backend.update(x,new_x)
keras.backend.update_add(x,increment)
keras.backend.update_sub(x,decrement)
keras.backend.var(x,axis=None,keepdims=False)
keras.backend.variable(value,dtype=None,name=None,constraint=None)
keras.backend.zeros(shape,dtype=None,name=None)
keras.backend.zeros_like(x,dtype=None,name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/callbacks.py----------------------------------------
A:keras.callbacks.model.history->History()
A:keras.callbacks.callback_list->CallbackList(callbacks)
A:keras.callbacks.callback_model->model._get_callback_model()
A:keras.callbacks.callback_metrics->copy.copy(metric_names)
A:keras.callbacks.self._supports_tf_logs->all((getattr(cb, '_supports_tf_logs', False) for cb in self.callbacks))
A:keras.callbacks.self._batch_hooks_support_tf_logs->all((getattr(cb, '_supports_tf_logs', False) for cb in self.callbacks if cb._implements_train_batch_hooks() or cb._implements_test_batch_hooks() or cb._implements_predict_batch_hooks()))
A:keras.callbacks.self._should_call_train_batch_hooks->any((cb._implements_train_batch_hooks() for cb in self.callbacks))
A:keras.callbacks.self._should_call_test_batch_hooks->any((cb._implements_test_batch_hooks() for cb in self.callbacks))
A:keras.callbacks.self._should_call_predict_batch_hooks->any((cb._implements_predict_batch_hooks() for cb in self.callbacks))
A:keras.callbacks.self._check_timing->any((cbk.__class__.__name__ not in globals() for cbk in self.callbacks))
A:keras.callbacks.self._history->History()
A:keras.callbacks.self._progbar->ProgbarLogger(count_mode='steps')
A:keras.callbacks.hook_name->'on_{mode}_batch_end'.format(mode=mode)
A:keras.callbacks.self._batch_start_time->time.time()
A:keras.callbacks.begin_hook_name->'on_{mode}_batch_begin'.format(mode=mode)
A:keras.callbacks.start_time->time.time()
A:keras.callbacks.logs->dict(((k, logs[k]) if k in logs else (k, 'NA') for k in self.keys))
A:keras.callbacks.hook->getattr(callback, hook_name)
A:keras.callbacks.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.callbacks.self.stateful_metrics->self.stateful_metrics.union(set((m.name for m in self.model.metrics)))
A:keras.callbacks.batch_size->dict(((k, logs[k]) if k in logs else (k, 'NA') for k in self.keys)).pop('size', 0)
A:keras.callbacks.num_steps->dict(((k, logs[k]) if k in logs else (k, 'NA') for k in self.keys)).pop('num_steps', 1)
A:keras.callbacks.loss->keras.utils.tf_utils.sync_to_numpy_or_python_type(loss)
A:keras.callbacks.self.progbar->Progbar(target=self.target, verbose=self.verbose, stateful_metrics=self.stateful_metrics, unit_name='step' if self.use_steps else 'sample')
A:keras.callbacks.counter->counter.numpy().numpy()
A:keras.callbacks.self.filepath->keras.utils.io_utils.path_to_string(filepath)
A:keras.callbacks.filepath_to_load->self._get_most_recently_modified_file_matching_pattern(self.filepath)
A:keras.callbacks.filepath->self._get_file_path(epoch, batch, logs)
A:keras.callbacks.current->dict(((k, logs[k]) if k in logs else (k, 'NA') for k in self.keys)).get(self.monitor)
A:keras.callbacks.file_path->os.path.join(dir_name, file_name)
A:keras.callbacks.self._write_filepath->keras.distribute.distributed_file_utils.write_filepath(file_path, self.model.distribute_strategy)
A:keras.callbacks.tf_saved_model_exists->tensorflow.compat.v2.io.gfile.exists(filepath)
A:keras.callbacks.tf_weights_only_checkpoint_exists->tensorflow.compat.v2.io.gfile.exists(filepath + '.index')
A:keras.callbacks.dir_name->os.path.dirname(pattern)
A:keras.callbacks.base_name->os.path.basename(pattern)
A:keras.callbacks.latest_tf_checkpoint->tensorflow.compat.v2.train.latest_checkpoint(dir_name)
A:keras.callbacks.mod_time->os.path.getmtime(file_path)
A:keras.callbacks.self.model._training_state->keras.distribute.worker_training_state.WorkerTrainingState(self.model, self.backup_dir)
A:keras.callbacks.self.min_delta->abs(min_delta)
A:keras.callbacks.self.best_weights->self.model.get_weights()
A:keras.callbacks.monitor_value->dict(((k, logs[k]) if k in logs else (k, 'NA') for k in self.keys)).get(self.monitor)
A:keras.callbacks.send[k]->v.item()
A:keras.callbacks.lr->self.schedule(epoch)
A:keras.callbacks.logs['lr']->keras.backend.get_value(self.model.optimizer.lr)
A:keras.callbacks.summary_metadata->tensorflow.compat.v2.compat.v1.SummaryMetadata()
A:keras.callbacks.json_string->data.to_json()
A:keras.callbacks.tensor->tensorflow.compat.v2.constant(json_string, dtype=tf.string)
A:keras.callbacks.self.log_dir->keras.utils.io_utils.path_to_string(log_dir)
A:keras.callbacks.self._log_write_dir->self._get_log_write_dir()
A:keras.callbacks.self._train_dir->os.path.join(self._log_write_dir, 'train')
A:keras.callbacks.self._val_dir->os.path.join(self._log_write_dir, 'validation')
A:keras.callbacks.self._writers['train']->tensorflow.compat.v2.summary.create_file_writer(self._train_dir)
A:keras.callbacks.self._writers['val']->tensorflow.compat.v2.summary.create_file_writer(self._val_dir)
A:keras.callbacks.config->keras.protobuf.projector_config_pb2.ProjectorConfig()
A:keras.callbacks.embedding->keras.protobuf.projector_config_pb2.ProjectorConfig().embeddings.add()
A:keras.callbacks.embedding.metadata_path->self.embeddings_metadata.pop(layer.name)
A:keras.callbacks.config_pbtxt->google.protobuf.text_format.MessageToString(config)
A:keras.callbacks.path->os.path.join(self._log_write_dir, 'projector_config.pbtxt')
A:keras.callbacks.previous_context->self._prev_summary_state.pop()
A:keras.callbacks.profile_batch->tensorflow.compat.v2.nest.map_structure(int, profile_batch)
A:keras.callbacks.self._previous_epoch_iterations->self.model.optimizer.iterations.numpy()
A:keras.callbacks.self._epoch_start_time->time.time()
A:keras.callbacks.lr_schedule->getattr(self.model.optimizer, 'lr', None)
A:keras.callbacks.logs['learning_rate']->lr_schedule(self.model.optimizer.iterations)
A:keras.callbacks.current_iteration->self.model.optimizer.iterations.numpy()
A:keras.callbacks.train_logs->self._collect_learning_rate(train_logs)
A:keras.callbacks.train_logs['steps_per_second']->self._compute_steps_per_second()
A:keras.callbacks.weight_name->weight.name.replace(':', '_')
A:keras.callbacks.w_img->tensorflow.compat.v2.reshape(w_img, [shape[0], shape[1], shape[2], 1])
A:keras.callbacks.shape->keras.backend.int_shape(w_img)
A:keras.callbacks.embeddings_ckpt->os.path.join(self._log_write_dir, 'train', 'keras_embedding.ckpt-{}'.format(epoch))
A:keras.callbacks.min_delta->kwargs.pop('epsilon')
A:keras.callbacks.old_lr->keras.backend.get_value(self.model.optimizer.lr)
A:keras.callbacks.new_lr->max(new_lr, self.min_lr)
A:keras.callbacks.self.filename->keras.utils.io_utils.path_to_string(filename)
A:keras.callbacks.self.csv_file->tensorflow.compat.v2.io.gfile.GFile(self.filename, mode)
A:keras.callbacks.self.keys->sorted(logs.keys())
A:keras.callbacks.self.writer->csv.DictWriter(self.csv_file, fieldnames=fieldnames, dialect=CustomDialect)
A:keras.callbacks.row_dict->collections.OrderedDict({'epoch': epoch})
keras.callbacks.BackupAndRestore(self,backup_dir)
keras.callbacks.BackupAndRestore.__init__(self,backup_dir)
keras.callbacks.BackupAndRestore.on_epoch_end(self,epoch,logs=None)
keras.callbacks.BackupAndRestore.on_train_begin(self,logs=None)
keras.callbacks.BackupAndRestore.on_train_end(self,logs=None)
keras.callbacks.BackupAndRestoreExperimental(self,*args,**kwargs)
keras.callbacks.BackupAndRestoreExperimental.__init__(self,*args,**kwargs)
keras.callbacks.BaseLogger(self,stateful_metrics=None)
keras.callbacks.BaseLogger.__init__(self,stateful_metrics=None)
keras.callbacks.BaseLogger.on_batch_end(self,batch,logs=None)
keras.callbacks.BaseLogger.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.BaseLogger.on_epoch_end(self,epoch,logs=None)
keras.callbacks.CSVLogger(self,filename,separator=',',append=False)
keras.callbacks.CSVLogger.__init__(self,filename,separator=',',append=False)
keras.callbacks.CSVLogger.on_epoch_end(self,epoch,logs=None)
keras.callbacks.CSVLogger.on_train_begin(self,logs=None)
keras.callbacks.CSVLogger.on_train_end(self,logs=None)
keras.callbacks.Callback(self)
keras.callbacks.Callback.__init__(self)
keras.callbacks.Callback._implements_predict_batch_hooks(self)
keras.callbacks.Callback._implements_test_batch_hooks(self)
keras.callbacks.Callback._implements_train_batch_hooks(self)
keras.callbacks.Callback.on_batch_begin(self,batch,logs=None)
keras.callbacks.Callback.on_batch_end(self,batch,logs=None)
keras.callbacks.Callback.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.Callback.on_epoch_end(self,epoch,logs=None)
keras.callbacks.Callback.on_predict_batch_begin(self,batch,logs=None)
keras.callbacks.Callback.on_predict_batch_end(self,batch,logs=None)
keras.callbacks.Callback.on_predict_begin(self,logs=None)
keras.callbacks.Callback.on_predict_end(self,logs=None)
keras.callbacks.Callback.on_test_batch_begin(self,batch,logs=None)
keras.callbacks.Callback.on_test_batch_end(self,batch,logs=None)
keras.callbacks.Callback.on_test_begin(self,logs=None)
keras.callbacks.Callback.on_test_end(self,logs=None)
keras.callbacks.Callback.on_train_batch_begin(self,batch,logs=None)
keras.callbacks.Callback.on_train_batch_end(self,batch,logs=None)
keras.callbacks.Callback.on_train_begin(self,logs=None)
keras.callbacks.Callback.on_train_end(self,logs=None)
keras.callbacks.Callback.set_model(self,model)
keras.callbacks.Callback.set_params(self,params)
keras.callbacks.CallbackList(self,callbacks=None,add_history=False,add_progbar=False,model=None,**params)
keras.callbacks.CallbackList.__init__(self,callbacks=None,add_history=False,add_progbar=False,model=None,**params)
keras.callbacks.CallbackList.__iter__(self)
keras.callbacks.CallbackList._add_default_callbacks(self,add_history,add_progbar)
keras.callbacks.CallbackList._call_batch_begin_hook(self,mode,batch,logs)
keras.callbacks.CallbackList._call_batch_end_hook(self,mode,batch,logs)
keras.callbacks.CallbackList._call_batch_hook(self,mode,hook,batch,logs=None)
keras.callbacks.CallbackList._call_batch_hook_helper(self,hook_name,batch,logs)
keras.callbacks.CallbackList._call_begin_hook(self,mode)
keras.callbacks.CallbackList._call_end_hook(self,mode)
keras.callbacks.CallbackList._disallow_batch_hooks_in_ps_strategy(self)
keras.callbacks.CallbackList._process_logs(self,logs,is_batch_hook=False)
keras.callbacks.CallbackList.append(self,callback)
keras.callbacks.CallbackList.on_batch_begin(self,batch,logs=None)
keras.callbacks.CallbackList.on_batch_end(self,batch,logs=None)
keras.callbacks.CallbackList.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.CallbackList.on_epoch_end(self,epoch,logs=None)
keras.callbacks.CallbackList.on_predict_batch_begin(self,batch,logs=None)
keras.callbacks.CallbackList.on_predict_batch_end(self,batch,logs=None)
keras.callbacks.CallbackList.on_predict_begin(self,logs=None)
keras.callbacks.CallbackList.on_predict_end(self,logs=None)
keras.callbacks.CallbackList.on_test_batch_begin(self,batch,logs=None)
keras.callbacks.CallbackList.on_test_batch_end(self,batch,logs=None)
keras.callbacks.CallbackList.on_test_begin(self,logs=None)
keras.callbacks.CallbackList.on_test_end(self,logs=None)
keras.callbacks.CallbackList.on_train_batch_begin(self,batch,logs=None)
keras.callbacks.CallbackList.on_train_batch_end(self,batch,logs=None)
keras.callbacks.CallbackList.on_train_begin(self,logs=None)
keras.callbacks.CallbackList.on_train_end(self,logs=None)
keras.callbacks.CallbackList.set_model(self,model)
keras.callbacks.CallbackList.set_params(self,params)
keras.callbacks.EarlyStopping(self,monitor='val_loss',min_delta=0,patience=0,verbose=0,mode='auto',baseline=None,restore_best_weights=False)
keras.callbacks.EarlyStopping.__init__(self,monitor='val_loss',min_delta=0,patience=0,verbose=0,mode='auto',baseline=None,restore_best_weights=False)
keras.callbacks.EarlyStopping._is_improvement(self,monitor_value,reference_value)
keras.callbacks.EarlyStopping.get_monitor_value(self,logs)
keras.callbacks.EarlyStopping.on_epoch_end(self,epoch,logs=None)
keras.callbacks.EarlyStopping.on_train_begin(self,logs=None)
keras.callbacks.EarlyStopping.on_train_end(self,logs=None)
keras.callbacks.History(self)
keras.callbacks.History.__init__(self)
keras.callbacks.History.on_epoch_end(self,epoch,logs=None)
keras.callbacks.History.on_train_begin(self,logs=None)
keras.callbacks.LambdaCallback(self,on_epoch_begin=None,on_epoch_end=None,on_batch_begin=None,on_batch_end=None,on_train_begin=None,on_train_end=None,**kwargs)
keras.callbacks.LambdaCallback.__init__(self,on_epoch_begin=None,on_epoch_end=None,on_batch_begin=None,on_batch_end=None,on_train_begin=None,on_train_end=None,**kwargs)
keras.callbacks.LearningRateScheduler(self,schedule,verbose=0)
keras.callbacks.LearningRateScheduler.__init__(self,schedule,verbose=0)
keras.callbacks.LearningRateScheduler.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.LearningRateScheduler.on_epoch_end(self,epoch,logs=None)
keras.callbacks.ModelCheckpoint(self,filepath,monitor='val_loss',verbose=0,save_best_only=False,save_weights_only=False,mode='auto',save_freq='epoch',options=None,initial_value_threshold=None,**kwargs)
keras.callbacks.ModelCheckpoint.__init__(self,filepath,monitor='val_loss',verbose=0,save_best_only=False,save_weights_only=False,mode='auto',save_freq='epoch',options=None,initial_value_threshold=None,**kwargs)
keras.callbacks.ModelCheckpoint._checkpoint_exists(self,filepath)
keras.callbacks.ModelCheckpoint._get_file_path(self,epoch,batch,logs)
keras.callbacks.ModelCheckpoint._get_most_recently_modified_file_matching_pattern(self,pattern)
keras.callbacks.ModelCheckpoint._implements_train_batch_hooks(self)
keras.callbacks.ModelCheckpoint._maybe_remove_file(self)
keras.callbacks.ModelCheckpoint._save_model(self,epoch,batch,logs)
keras.callbacks.ModelCheckpoint._should_save_on_batch(self,batch)
keras.callbacks.ModelCheckpoint.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.ModelCheckpoint.on_epoch_end(self,epoch,logs=None)
keras.callbacks.ModelCheckpoint.on_train_batch_end(self,batch,logs=None)
keras.callbacks.ModelCheckpoint.on_train_begin(self,logs=None)
keras.callbacks.ProgbarLogger(self,count_mode='samples',stateful_metrics=None)
keras.callbacks.ProgbarLogger.__init__(self,count_mode='samples',stateful_metrics=None)
keras.callbacks.ProgbarLogger._batch_update_progbar(self,batch,logs=None)
keras.callbacks.ProgbarLogger._finalize_progbar(self,logs,counter)
keras.callbacks.ProgbarLogger._implements_predict_batch_hooks(self)
keras.callbacks.ProgbarLogger._implements_test_batch_hooks(self)
keras.callbacks.ProgbarLogger._implements_train_batch_hooks(self)
keras.callbacks.ProgbarLogger._maybe_init_progbar(self)
keras.callbacks.ProgbarLogger._reset_progbar(self)
keras.callbacks.ProgbarLogger.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.ProgbarLogger.on_epoch_end(self,epoch,logs=None)
keras.callbacks.ProgbarLogger.on_predict_batch_end(self,batch,logs=None)
keras.callbacks.ProgbarLogger.on_predict_begin(self,logs=None)
keras.callbacks.ProgbarLogger.on_predict_end(self,logs=None)
keras.callbacks.ProgbarLogger.on_test_batch_end(self,batch,logs=None)
keras.callbacks.ProgbarLogger.on_test_begin(self,logs=None)
keras.callbacks.ProgbarLogger.on_test_end(self,logs=None)
keras.callbacks.ProgbarLogger.on_train_batch_end(self,batch,logs=None)
keras.callbacks.ProgbarLogger.on_train_begin(self,logs=None)
keras.callbacks.ProgbarLogger.set_params(self,params)
keras.callbacks.ReduceLROnPlateau(self,monitor='val_loss',factor=0.1,patience=10,verbose=0,mode='auto',min_delta=0.0001,cooldown=0,min_lr=0,**kwargs)
keras.callbacks.ReduceLROnPlateau.__init__(self,monitor='val_loss',factor=0.1,patience=10,verbose=0,mode='auto',min_delta=0.0001,cooldown=0,min_lr=0,**kwargs)
keras.callbacks.ReduceLROnPlateau._reset(self)
keras.callbacks.ReduceLROnPlateau.in_cooldown(self)
keras.callbacks.ReduceLROnPlateau.on_epoch_end(self,epoch,logs=None)
keras.callbacks.ReduceLROnPlateau.on_train_begin(self,logs=None)
keras.callbacks.RemoteMonitor(self,root='http://localhost:9000',path='/publish/epoch/end/',field='data',headers=None,send_as_json=False)
keras.callbacks.RemoteMonitor.__init__(self,root='http://localhost:9000',path='/publish/epoch/end/',field='data',headers=None,send_as_json=False)
keras.callbacks.RemoteMonitor.on_epoch_end(self,epoch,logs=None)
keras.callbacks.TensorBoard(self,log_dir='logs',histogram_freq=0,write_graph=True,write_images=False,write_steps_per_second=False,update_freq='epoch',profile_batch=0,embeddings_freq=0,embeddings_metadata=None,**kwargs)
keras.callbacks.TensorBoard.__init__(self,log_dir='logs',histogram_freq=0,write_graph=True,write_images=False,write_steps_per_second=False,update_freq='epoch',profile_batch=0,embeddings_freq=0,embeddings_metadata=None,**kwargs)
keras.callbacks.TensorBoard._close_writers(self)
keras.callbacks.TensorBoard._collect_learning_rate(self,logs)
keras.callbacks.TensorBoard._compute_steps_per_second(self)
keras.callbacks.TensorBoard._configure_embeddings(self)
keras.callbacks.TensorBoard._delete_tmp_write_dir(self)
keras.callbacks.TensorBoard._get_log_write_dir(self)
keras.callbacks.TensorBoard._implements_train_batch_hooks(self)
keras.callbacks.TensorBoard._init_profile_batch(self,profile_batch)
keras.callbacks.TensorBoard._log_embeddings(self,epoch)
keras.callbacks.TensorBoard._log_epoch_metrics(self,epoch,logs)
keras.callbacks.TensorBoard._log_weight_as_image(self,weight,weight_name,epoch)
keras.callbacks.TensorBoard._log_weights(self,epoch)
keras.callbacks.TensorBoard._pop_writer(self)
keras.callbacks.TensorBoard._push_writer(self,writer,step)
keras.callbacks.TensorBoard._start_profiler(self,logdir)
keras.callbacks.TensorBoard._start_trace(self)
keras.callbacks.TensorBoard._stop_profiler(self,save=True)
keras.callbacks.TensorBoard._stop_trace(self,batch=None)
keras.callbacks.TensorBoard._train_writer(self)
keras.callbacks.TensorBoard._val_writer(self)
keras.callbacks.TensorBoard._validate_kwargs(self,kwargs)
keras.callbacks.TensorBoard._write_keras_model_summary(self)
keras.callbacks.TensorBoard._write_keras_model_train_graph(self)
keras.callbacks.TensorBoard.on_epoch_begin(self,epoch,logs=None)
keras.callbacks.TensorBoard.on_epoch_end(self,epoch,logs=None)
keras.callbacks.TensorBoard.on_test_begin(self,logs=None)
keras.callbacks.TensorBoard.on_test_end(self,logs=None)
keras.callbacks.TensorBoard.on_train_batch_begin(self,batch,logs=None)
keras.callbacks.TensorBoard.on_train_batch_end(self,batch,logs=None)
keras.callbacks.TensorBoard.on_train_begin(self,logs=None)
keras.callbacks.TensorBoard.on_train_end(self,logs=None)
keras.callbacks.TensorBoard.set_model(self,model)
keras.callbacks.TerminateOnNaN(self)
keras.callbacks.TerminateOnNaN.__init__(self)
keras.callbacks.TerminateOnNaN.on_batch_end(self,batch,logs=None)
keras.callbacks._is_generator_like(data)
keras.callbacks.configure_callbacks(callbacks,model,do_validation=False,batch_size=None,epochs=None,steps_per_epoch=None,samples=None,verbose=1,count_mode='steps',mode=ModeKeys.TRAIN)
keras.callbacks.keras_model_summary(name,data,step=None)
keras.callbacks.make_logs(model,logs,outputs,mode,prefix='')
keras.callbacks.set_callback_parameters(callback_list,model,do_validation=False,batch_size=None,epochs=None,steps_per_epoch=None,samples=None,verbose=1,mode=ModeKeys.TRAIN)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/activations.py----------------------------------------
A:keras.activations.output->tensorflow.compat.v2.sigmoid(x)
A:keras.activations.e->tensorflow.compat.v2.exp(x - tf.reduce_max(x, axis=axis, keepdims=True))
A:keras.activations.s->tensorflow.compat.v2.reduce_sum(e, axis=axis, keepdims=True)
A:keras.activations.globs->globals()
A:keras.activations.activation_globs->keras.layers.activation.get_globals()
keras.activations.deserialize(name,custom_objects=None)
keras.activations.elu(x,alpha=1.0)
keras.activations.exponential(x)
keras.activations.gelu(x,approximate=False)
keras.activations.get(identifier)
keras.activations.hard_sigmoid(x)
keras.activations.linear(x)
keras.activations.relu(x,alpha=0.0,max_value=None,threshold=0.0)
keras.activations.selu(x)
keras.activations.serialize(activation)
keras.activations.sigmoid(x)
keras.activations.softmax(x,axis=-1)
keras.activations.softplus(x)
keras.activations.softsign(x)
keras.activations.swish(x)
keras.activations.tanh(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/callbacks_v1.py----------------------------------------
A:keras.callbacks_v1.self.writer->tensorflow.compat.v2.compat.v1.summary.FileWriter(self.log_dir)
A:keras.callbacks_v1.mapped_weight_name->weight.name.replace(':', '_')
A:keras.callbacks_v1.w_img->tensorflow.compat.v2.reshape(w_img, [1, shape[0], 1, 1])
A:keras.callbacks_v1.shape->tuple(w_img.shape)
A:keras.callbacks_v1.grads->model.optimizer.get_gradients(model.total_loss, weight)
A:keras.callbacks_v1.self.merged->tensorflow.compat.v2.compat.v1.summary.merge_all()
A:keras.callbacks_v1.self.embeddings_data->keras.engine.training_utils_v1.standardize_input_data(self.embeddings_data, model.input_names)
A:keras.callbacks_v1.self.batch_idbatch_id->tensorflow.compat.v2.compat.v1.placeholder(tf.int32)
A:keras.callbacks_v1.self.stepstep->tensorflow.compat.v2.compat.v1.placeholder(tf.int32)
A:keras.callbacks_v1.embedding_size->numpy.prod(embedding_input.shape[1:])
A:keras.callbacks_v1.embedding_input->tensorflow.compat.v2.reshape(embedding_input, (step, int(embedding_size)))
A:keras.callbacks_v1.embedding->tensorboard.plugins.projector.ProjectorConfig().embeddings.add()
A:keras.callbacks_v1.batch->slice(i, i + step)
A:keras.callbacks_v1.self.saver->tensorflow.compat.v2.compat.v1.train.Saver(list(embeddings_vars.values()))
A:keras.callbacks_v1.config->tensorboard.plugins.projector.ProjectorConfig()
A:keras.callbacks_v1.value->value.item().item()
A:keras.callbacks_v1.summary->tensorflow.compat.v2.compat.v1.Summary()
A:keras.callbacks_v1.summary_value->tensorflow.compat.v2.compat.v1.Summary().value.add()
A:keras.callbacks_v1.sess->keras.backend.get_session()
A:keras.callbacks_v1.step->min(self.batch_size, n_samples - i)
keras.callbacks_v1.TensorBoard(self,log_dir='./logs',histogram_freq=0,batch_size=32,write_graph=True,write_grads=False,write_images=False,embeddings_freq=0,embeddings_layer_names=None,embeddings_metadata=None,embeddings_data=None,update_freq='epoch',profile_batch=2)
keras.callbacks_v1.TensorBoard.__init__(self,log_dir='./logs',histogram_freq=0,batch_size=32,write_graph=True,write_grads=False,write_images=False,embeddings_freq=0,embeddings_layer_names=None,embeddings_metadata=None,embeddings_data=None,update_freq='epoch',profile_batch=2)
keras.callbacks_v1.TensorBoard._fetch_callback(self,summary)
keras.callbacks_v1.TensorBoard._init_writer(self,model)
keras.callbacks_v1.TensorBoard._make_histogram_ops(self,model)
keras.callbacks_v1.TensorBoard._start_profiler(self)
keras.callbacks_v1.TensorBoard._stop_profiler(self)
keras.callbacks_v1.TensorBoard._write_custom_summaries(self,step,logs=None)
keras.callbacks_v1.TensorBoard.on_batch_end(self,batch,logs=None)
keras.callbacks_v1.TensorBoard.on_epoch_begin(self,epoch,logs=None)
keras.callbacks_v1.TensorBoard.on_epoch_end(self,epoch,logs=None)
keras.callbacks_v1.TensorBoard.on_test_begin(self,logs=None)
keras.callbacks_v1.TensorBoard.on_test_end(self,logs=None)
keras.callbacks_v1.TensorBoard.on_train_batch_begin(self,batch,logs=None)
keras.callbacks_v1.TensorBoard.on_train_batch_end(self,batch,logs=None)
keras.callbacks_v1.TensorBoard.on_train_begin(self,logs=None)
keras.callbacks_v1.TensorBoard.on_train_end(self,logs=None)
keras.callbacks_v1.TensorBoard.set_model(self,model)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/constraints.py----------------------------------------
A:keras.constraints.norms->keras.backend.sqrt(tf.reduce_sum(tf.square(w), axis=self.axis, keepdims=True))
A:keras.constraints.desired->keras.backend.clip(norms, 0, self.max_value)
A:keras.constraints.w->keras.backend.map_fn(self._kernel_constraint, backend.stack(tf.unstack(w, axis=-1), axis=0))
A:keras.constraints.padding->keras.backend.constant([[1, 1], [1, 1]], dtype='int32')
A:keras.constraints.start->keras.backend.cast(kernel_shape / 2, 'int32')
A:keras.constraints.kernel_new->keras.backend.switch(backend.cast(tf.math.floormod(kernel_shape, 2), 'bool'), lambda : kernel[start - 1:start, start - 1:start], lambda : kernel[start - 1:start, start - 1:start] + backend.zeros((2, 2), dtype=kernel.dtype))
A:keras.constraints.index->keras.backend.switch(backend.cast(tf.math.floormod(kernel_shape, 2), 'bool'), lambda : backend.constant(0, dtype='int32'), lambda : backend.constant(1, dtype='int32'))
A:keras.constraints.(_, kernel_new)->tensorflow.compat.v2.compat.v1.while_loop(while_condition, body_fn, [index, kernel_new], shape_invariants=[index.get_shape(), tf.TensorShape([None, None])])
keras.constraints.Constraint(self,w)
keras.constraints.Constraint.__call__(self,w)
keras.constraints.Constraint.get_config(self)
keras.constraints.MaxNorm(self,max_value=2,axis=0)
keras.constraints.MaxNorm.__init__(self,max_value=2,axis=0)
keras.constraints.MaxNorm.get_config(self)
keras.constraints.MinMaxNorm(self,min_value=0.0,max_value=1.0,rate=1.0,axis=0)
keras.constraints.MinMaxNorm.__init__(self,min_value=0.0,max_value=1.0,rate=1.0,axis=0)
keras.constraints.MinMaxNorm.get_config(self)
keras.constraints.NonNeg(self,w)
keras.constraints.NonNeg.__call__(self,w)
keras.constraints.RadialConstraint(self,w)
keras.constraints.RadialConstraint.__call__(self,w)
keras.constraints.RadialConstraint._kernel_constraint(self,kernel)
keras.constraints.UnitNorm(self,axis=0)
keras.constraints.UnitNorm.__init__(self,axis=0)
keras.constraints.UnitNorm.get_config(self)
keras.constraints.deserialize(config,custom_objects=None)
keras.constraints.get(identifier)
keras.constraints.serialize(constraint)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/preprocessing/image.py----------------------------------------
A:keras.preprocessing.image.self.lock->threading.Lock()
A:keras.preprocessing.image.self.index_generator->self._flow_index()
A:keras.preprocessing.image.self.index_array->numpy.random.permutation(self.n)
A:keras.preprocessing.image.index_array->next(self.index_generator)
A:keras.preprocessing.image.dirname->os.path.basename(directory)
A:keras.preprocessing.image.all_files->list(_iter_valid_files(directory, white_list_formats, follow_links))
A:keras.preprocessing.image.num_files->len(df)
A:keras.preprocessing.image.valid_files->_iter_valid_files(directory, white_list_formats, follow_links)
A:keras.preprocessing.image.absolute_path->os.path.join(root, fname)
A:keras.preprocessing.image.relative_path->os.path.join(dirname, os.path.relpath(absolute_path, directory))
A:keras.preprocessing.image.self.target_size->tuple(target_size)
A:keras.preprocessing.image.batch_x->numpy.zeros(tuple([len(index_array)] + list(self.x.shape)[1:]), dtype=self.dtype)
A:keras.preprocessing.image.img->keras.utils.image_utils.array_to_img(batch_x[i], self.data_format, scale=True)
A:keras.preprocessing.image.x->numpy.rollaxis(x, 0, channel_axis + 1)
A:keras.preprocessing.image.params->self.get_random_transform(x.shape, seed)
A:keras.preprocessing.image.fname->'{prefix}_{index}_{hash}.{format}'.format(prefix=self.save_prefix, index=j, hash=np.random.randint(10000.0), format=self.save_format)
A:keras.preprocessing.image.batch_y->numpy.zeros((len(batch_x), len(self.class_indices)), dtype=self.dtype)
A:keras.preprocessing.image.data_format->keras.backend.image_data_format()
A:keras.preprocessing.image.dtype->keras.backend.floatx()
A:keras.preprocessing.image.self.num_classes->len(classes)
A:keras.preprocessing.image.self.class_indices->dict(zip(classes, range(len(classes))))
A:keras.preprocessing.image.pool->multiprocessing.pool.ThreadPool()
A:keras.preprocessing.image.(classes, filenames)->res.get()
A:keras.preprocessing.image.self.samples->len(self.filenames)
A:keras.preprocessing.image.self.classes->self.get_classes(df, y_col)
A:keras.preprocessing.image.split_idx->int(len(x) * image_data_generator._validation_split)
A:keras.preprocessing.image.self.x->numpy.asarray(x, dtype=self.dtype)
A:keras.preprocessing.image.self.y->numpy.asarray(y)
A:keras.preprocessing.image.self.sample_weight->numpy.asarray(sample_weight)
A:keras.preprocessing.image.df->df.copy().copy()
A:keras.preprocessing.image.(df, classes)->self._filter_classes(df, y_col, classes)
A:keras.preprocessing.image.num_classes->len(classes)
A:keras.preprocessing.image.start->int(self.split[0] * num_files)
A:keras.preprocessing.image.stop->int(self.split[1] * num_files)
A:keras.preprocessing.image.self.filenames->df[x_col].tolist()
A:keras.preprocessing.image.classes->sorted(classes)
A:keras.preprocessing.image.df[y_col]->df[y_col].apply(lambda x: remove_classes(x, classes)).apply(lambda x: remove_classes(x, classes))
A:keras.preprocessing.image.filepaths->df[x_col].map(lambda fname: os.path.join(self.directory, fname))
A:keras.preprocessing.image.mask->df[x_col].map(lambda fname: os.path.join(self.directory, fname)).apply(validate_filename, args=(self.white_list_formats,))
A:keras.preprocessing.image.n_invalid->(~mask).sum()
A:keras.preprocessing.image.flat_x->numpy.reshape(x, (n, -1))
A:keras.preprocessing.image.theta->numpy.deg2rad(theta)
A:keras.preprocessing.image.tx->numpy.random.uniform(-self.height_shift_range, self.height_shift_range)
A:keras.preprocessing.image.ty->numpy.random.uniform(-self.width_shift_range, self.width_shift_range)
A:keras.preprocessing.image.shear->numpy.deg2rad(shear)
A:keras.preprocessing.image.(zx, zy)->numpy.random.uniform(zoom_range[0], zoom_range[1], 2)
A:keras.preprocessing.image.channel_shift_intensity->numpy.random.uniform(-self.channel_shift_range, self.channel_shift_range)
A:keras.preprocessing.image.brightness->numpy.random.uniform(self.brightness_range[0], self.brightness_range[1])
A:keras.preprocessing.image.ax->numpy.zeros(tuple([rounds * x.shape[0]] + list(x.shape)[1:]), dtype=self.dtype)
A:keras.preprocessing.image.ax[i + r * x.shape[0]]->self.random_transform(x[i])
A:keras.preprocessing.image.self.mean->numpy.reshape(self.mean, broadcast_shape)
A:keras.preprocessing.image.self.std->numpy.reshape(self.std, broadcast_shape)
A:keras.preprocessing.image.n->len(x)
A:keras.preprocessing.image.(u, s, _)->numpy.linalg.svd(flat_x.T, full_matrices=False)
A:keras.preprocessing.image.self.zca_whitening_matrix->(u * s_inv).dot(u.T)
A:keras.preprocessing.image.intensity->numpy.random.uniform(-intensity_range, intensity_range)
A:keras.preprocessing.image.ximgenhancer_Brightness->PIL.ImageEnhance.Brightness(x)
A:keras.preprocessing.image.u->numpy.random.uniform(brightness_range[0], brightness_range[1])
A:keras.preprocessing.image.offset_matrix->numpy.array([[1, 0, o_x], [0, 1, o_y], [0, 0, 1]])
A:keras.preprocessing.image.reset_matrix->numpy.array([[1, 0, -o_x], [0, 1, -o_y], [0, 0, 1]])
A:keras.preprocessing.image.transform_matrix->transform_matrix_offset_center(transform_matrix, h, w)
A:keras.preprocessing.image.valid_indices->set([0, 1, 2])
A:keras.preprocessing.image.actual_indices->set([row_axis, col_axis, channel_axis])
A:keras.preprocessing.image.rotation_matrix->numpy.array([[np.cos(theta), -np.sin(theta), 0], [np.sin(theta), np.cos(theta), 0], [0, 0, 1]])
A:keras.preprocessing.image.shift_matrix->numpy.array([[1, 0, tx], [0, 1, ty], [0, 0, 1]])
A:keras.preprocessing.image.shear_matrix->numpy.array([[1, -np.sin(shear), 0], [0, np.cos(shear), 0], [0, 0, 1]])
A:keras.preprocessing.image.zoom_matrix->numpy.array([[zx, 0, 0], [0, zy, 0], [0, 0, 1]])
keras.preprocessing.image.BatchFromFilesMixin
keras.preprocessing.image.BatchFromFilesMixin._get_batches_of_transformed_samples(self,index_array)
keras.preprocessing.image.BatchFromFilesMixin.filepaths(self)
keras.preprocessing.image.BatchFromFilesMixin.labels(self)
keras.preprocessing.image.BatchFromFilesMixin.sample_weight(self)
keras.preprocessing.image.BatchFromFilesMixin.set_processing_attrs(self,image_data_generator,target_size,color_mode,data_format,save_to_dir,save_prefix,save_format,subset,interpolation,keep_aspect_ratio)
keras.preprocessing.image.DataFrameIterator(self,dataframe,directory=None,image_data_generator=None,x_col='filename',y_col='class',weight_col=None,target_size=(256,256),color_mode='rgb',classes=None,class_mode='categorical',batch_size=32,shuffle=True,seed=None,data_format='channels_last',save_to_dir=None,save_prefix='',save_format='png',subset=None,interpolation='nearest',keep_aspect_ratio=False,dtype='float32',validate_filenames=True)
keras.preprocessing.image.DataFrameIterator.__init__(self,dataframe,directory=None,image_data_generator=None,x_col='filename',y_col='class',weight_col=None,target_size=(256,256),color_mode='rgb',classes=None,class_mode='categorical',batch_size=32,shuffle=True,seed=None,data_format='channels_last',save_to_dir=None,save_prefix='',save_format='png',subset=None,interpolation='nearest',keep_aspect_ratio=False,dtype='float32',validate_filenames=True)
keras.preprocessing.image.DataFrameIterator._check_params(self,df,x_col,y_col,weight_col,classes)
keras.preprocessing.image.DataFrameIterator._filter_classes(df,y_col,classes)
keras.preprocessing.image.DataFrameIterator._filter_valid_filepaths(self,df,x_col)
keras.preprocessing.image.DataFrameIterator.filepaths(self)
keras.preprocessing.image.DataFrameIterator.get_classes(self,df,y_col)
keras.preprocessing.image.DataFrameIterator.labels(self)
keras.preprocessing.image.DataFrameIterator.sample_weight(self)
keras.preprocessing.image.DirectoryIterator(self,directory,image_data_generator,target_size=(256,256),color_mode='rgb',classes=None,class_mode='categorical',batch_size=32,shuffle=True,seed=None,data_format=None,save_to_dir=None,save_prefix='',save_format='png',follow_links=False,subset=None,interpolation='nearest',keep_aspect_ratio=False,dtype=None)
keras.preprocessing.image.DirectoryIterator.__init__(self,directory,image_data_generator,target_size=(256,256),color_mode='rgb',classes=None,class_mode='categorical',batch_size=32,shuffle=True,seed=None,data_format=None,save_to_dir=None,save_prefix='',save_format='png',follow_links=False,subset=None,interpolation='nearest',keep_aspect_ratio=False,dtype=None)
keras.preprocessing.image.DirectoryIterator.filepaths(self)
keras.preprocessing.image.DirectoryIterator.labels(self)
keras.preprocessing.image.DirectoryIterator.sample_weight(self)
keras.preprocessing.image.ImageDataGenerator(self,featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,samplewise_std_normalization=False,zca_whitening=False,zca_epsilon=1e-06,rotation_range=0,width_shift_range=0.0,height_shift_range=0.0,brightness_range=None,shear_range=0.0,zoom_range=0.0,channel_shift_range=0.0,fill_mode='nearest',cval=0.0,horizontal_flip=False,vertical_flip=False,rescale=None,preprocessing_function=None,data_format=None,validation_split=0.0,interpolation_order=1,dtype=None)
keras.preprocessing.image.ImageDataGenerator.__init__(self,featurewise_center=False,samplewise_center=False,featurewise_std_normalization=False,samplewise_std_normalization=False,zca_whitening=False,zca_epsilon=1e-06,rotation_range=0,width_shift_range=0.0,height_shift_range=0.0,brightness_range=None,shear_range=0.0,zoom_range=0.0,channel_shift_range=0.0,fill_mode='nearest',cval=0.0,horizontal_flip=False,vertical_flip=False,rescale=None,preprocessing_function=None,data_format=None,validation_split=0.0,interpolation_order=1,dtype=None)
keras.preprocessing.image.ImageDataGenerator.apply_transform(self,x,transform_parameters)
keras.preprocessing.image.ImageDataGenerator.fit(self,x,augment=False,rounds=1,seed=None)
keras.preprocessing.image.ImageDataGenerator.flow(self,x,y=None,batch_size=32,shuffle=True,sample_weight=None,seed=None,save_to_dir=None,save_prefix='',save_format='png',ignore_class_split=False,subset=None)
keras.preprocessing.image.ImageDataGenerator.flow_from_dataframe(self,dataframe,directory=None,x_col='filename',y_col='class',weight_col=None,target_size=(256,256),color_mode='rgb',classes=None,class_mode='categorical',batch_size=32,shuffle=True,seed=None,save_to_dir=None,save_prefix='',save_format='png',subset=None,interpolation='nearest',validate_filenames=True,**kwargs)
keras.preprocessing.image.ImageDataGenerator.flow_from_directory(self,directory,target_size=(256,256),color_mode='rgb',classes=None,class_mode='categorical',batch_size=32,shuffle=True,seed=None,save_to_dir=None,save_prefix='',save_format='png',follow_links=False,subset=None,interpolation='nearest',keep_aspect_ratio=False)
keras.preprocessing.image.ImageDataGenerator.get_random_transform(self,img_shape,seed=None)
keras.preprocessing.image.ImageDataGenerator.random_transform(self,x,seed=None)
keras.preprocessing.image.ImageDataGenerator.standardize(self,x)
keras.preprocessing.image.Iterator(self,n,batch_size,shuffle,seed)
keras.preprocessing.image.Iterator.__getitem__(self,idx)
keras.preprocessing.image.Iterator.__init__(self,n,batch_size,shuffle,seed)
keras.preprocessing.image.Iterator.__iter__(self)
keras.preprocessing.image.Iterator.__len__(self)
keras.preprocessing.image.Iterator.__next__(self,*args,**kwargs)
keras.preprocessing.image.Iterator._flow_index(self)
keras.preprocessing.image.Iterator._get_batches_of_transformed_samples(self,index_array)
keras.preprocessing.image.Iterator._set_index_array(self)
keras.preprocessing.image.Iterator.next(self)
keras.preprocessing.image.Iterator.on_epoch_end(self)
keras.preprocessing.image.Iterator.reset(self)
keras.preprocessing.image.NumpyArrayIterator(self,x,y,image_data_generator,batch_size=32,shuffle=False,sample_weight=None,seed=None,data_format=None,save_to_dir=None,save_prefix='',save_format='png',subset=None,ignore_class_split=False,dtype=None)
keras.preprocessing.image.NumpyArrayIterator.__init__(self,x,y,image_data_generator,batch_size=32,shuffle=False,sample_weight=None,seed=None,data_format=None,save_to_dir=None,save_prefix='',save_format='png',subset=None,ignore_class_split=False,dtype=None)
keras.preprocessing.image.NumpyArrayIterator._get_batches_of_transformed_samples(self,index_array)
keras.preprocessing.image._iter_valid_files(directory,white_list_formats,follow_links)
keras.preprocessing.image._list_valid_filenames_in_directory(directory,white_list_formats,split,class_indices,follow_links)
keras.preprocessing.image.apply_affine_transform(x,theta=0,tx=0,ty=0,shear=0,zx=1,zy=1,row_axis=1,col_axis=2,channel_axis=0,fill_mode='nearest',cval=0.0,order=1)
keras.preprocessing.image.apply_brightness_shift(x,brightness,scale=True)
keras.preprocessing.image.apply_channel_shift(x,intensity,channel_axis=0)
keras.preprocessing.image.flip_axis(x,axis)
keras.preprocessing.image.random_brightness(x,brightness_range,scale=True)
keras.preprocessing.image.random_channel_shift(x,intensity_range,channel_axis=0)
keras.preprocessing.image.random_rotation(x,rg,row_axis=1,col_axis=2,channel_axis=0,fill_mode='nearest',cval=0.0,interpolation_order=1)
keras.preprocessing.image.random_shear(x,intensity,row_axis=1,col_axis=2,channel_axis=0,fill_mode='nearest',cval=0.0,interpolation_order=1)
keras.preprocessing.image.random_shift(x,wrg,hrg,row_axis=1,col_axis=2,channel_axis=0,fill_mode='nearest',cval=0.0,interpolation_order=1)
keras.preprocessing.image.random_zoom(x,zoom_range,row_axis=1,col_axis=2,channel_axis=0,fill_mode='nearest',cval=0.0,interpolation_order=1)
keras.preprocessing.image.transform_matrix_offset_center(matrix,x,y)
keras.preprocessing.image.validate_filename(filename,white_list_formats)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/preprocessing/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/preprocessing/text.py----------------------------------------
A:keras.preprocessing.text.input_text->input_text.translate(translate_map).translate(translate_map)
A:keras.preprocessing.text.translate_map->str.maketrans(translate_dict)
A:keras.preprocessing.text.seq->self.analyzer(text)
A:keras.preprocessing.text.num_words->kwargs.pop('nb_words')
A:keras.preprocessing.text.document_count->kwargs.pop('document_count', 0)
A:keras.preprocessing.text.self.word_counts->collections.OrderedDict()
A:keras.preprocessing.text.self.word_docs->collections.defaultdict(int)
A:keras.preprocessing.text.self.index_docs->collections.defaultdict(int)
A:keras.preprocessing.text.text->text.lower().lower()
A:keras.preprocessing.text.wcounts->list(self.word_counts.items())
A:keras.preprocessing.text.self.word_index->dict(zip(sorted_voc, list(range(1, len(sorted_voc) + 1))))
A:keras.preprocessing.text.oov_token_index->self.word_index.get(self.oov_token)
A:keras.preprocessing.text.i->self.word_index.get(w)
A:keras.preprocessing.text.word->self.index_word.get(num)
A:keras.preprocessing.text.vect->' '.join(vect)
A:keras.preprocessing.text.sequences->self.texts_to_sequences(texts)
A:keras.preprocessing.text.x->numpy.zeros((len(sequences), num_words))
A:keras.preprocessing.text.counts->collections.defaultdict(int)
A:keras.preprocessing.text.idf->numpy.log(1 + self.document_count / (1 + self.index_docs.get(j, 0)))
A:keras.preprocessing.text.json_word_counts->json.dumps(self.word_counts)
A:keras.preprocessing.text.json_word_docs->json.dumps(self.word_docs)
A:keras.preprocessing.text.json_index_docs->json.dumps(self.index_docs)
A:keras.preprocessing.text.json_word_index->json.dumps(self.word_index)
A:keras.preprocessing.text.json_index_word->json.dumps(self.index_word)
A:keras.preprocessing.text.config->json.loads(json_string).get('config')
A:keras.preprocessing.text.tokenizer_config->json.loads(json_string)
A:keras.preprocessing.text.word_counts->json.loads(config.pop('word_counts'))
A:keras.preprocessing.text.word_docs->json.loads(config.pop('word_docs'))
A:keras.preprocessing.text.index_docs->json.loads(config.pop('index_docs'))
A:keras.preprocessing.text.index_word->json.loads(config.pop('index_word'))
A:keras.preprocessing.text.word_index->json.loads(config.pop('word_index'))
A:keras.preprocessing.text.tokenizer->Tokenizer(**config)
keras.preprocessing.text.Tokenizer(self,num_words=None,filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',lower=True,split='',char_level=False,oov_token=None,analyzer=None,**kwargs)
keras.preprocessing.text.Tokenizer.__init__(self,num_words=None,filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',lower=True,split='',char_level=False,oov_token=None,analyzer=None,**kwargs)
keras.preprocessing.text.Tokenizer.fit_on_sequences(self,sequences)
keras.preprocessing.text.Tokenizer.fit_on_texts(self,texts)
keras.preprocessing.text.Tokenizer.get_config(self)
keras.preprocessing.text.Tokenizer.sequences_to_matrix(self,sequences,mode='binary')
keras.preprocessing.text.Tokenizer.sequences_to_texts(self,sequences)
keras.preprocessing.text.Tokenizer.sequences_to_texts_generator(self,sequences)
keras.preprocessing.text.Tokenizer.texts_to_matrix(self,texts,mode='binary')
keras.preprocessing.text.Tokenizer.texts_to_sequences(self,texts)
keras.preprocessing.text.Tokenizer.texts_to_sequences_generator(self,texts)
keras.preprocessing.text.Tokenizer.to_json(self,**kwargs)
keras.preprocessing.text.hashing_trick(text,n,hash_function=None,filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',lower=True,split='',analyzer=None)
keras.preprocessing.text.one_hot(input_text,n,filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',lower=True,split='',analyzer=None)
keras.preprocessing.text.text_to_word_sequence(input_text,filters='!"#$%&()*+,-./:;<=>?@[\\]^_`{|}~\t\n',lower=True,split='')
keras.preprocessing.text.tokenizer_from_json(json_string)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/preprocessing/sequence.py----------------------------------------
A:keras.preprocessing.sequence.rows->numpy.arange(i, min(i + self.batch_size * self.stride, self.end_index + 1), self.stride)
A:keras.preprocessing.sequence.samples->numpy.array([self.data[row - self.length:row:self.sampling_rate] for row in rows])
A:keras.preprocessing.sequence.targets->self.targets.tolist()
A:keras.preprocessing.sequence.data->self.data.tolist()
A:keras.preprocessing.sequence.json_data->json.dumps(data)
A:keras.preprocessing.sequence.json_targets->json.dumps(targets)
A:keras.preprocessing.sequence.config->self.get_config()
A:keras.preprocessing.sequence.rank->numpy.arange(size)
A:keras.preprocessing.sequence.window_start->max(0, i - window_size)
A:keras.preprocessing.sequence.window_end->min(len(sequence), i + window_size + 1)
A:keras.preprocessing.sequence.num_negative_samples->int(len(labels) * negative_samples)
A:keras.preprocessing.sequence.seed->random.randint(0, 10000000.0)
keras.preprocessing.sequence.TimeseriesGenerator(self,data,targets,length,sampling_rate=1,stride=1,start_index=0,end_index=None,shuffle=False,reverse=False,batch_size=128)
keras.preprocessing.sequence.TimeseriesGenerator.__getitem__(self,index)
keras.preprocessing.sequence.TimeseriesGenerator.__init__(self,data,targets,length,sampling_rate=1,stride=1,start_index=0,end_index=None,shuffle=False,reverse=False,batch_size=128)
keras.preprocessing.sequence.TimeseriesGenerator.__len__(self)
keras.preprocessing.sequence.TimeseriesGenerator.get_config(self)
keras.preprocessing.sequence.TimeseriesGenerator.to_json(self,**kwargs)
keras.preprocessing.sequence._remove_long_seq(maxlen,seq,label)
keras.preprocessing.sequence.make_sampling_table(size,sampling_factor=1e-05)
keras.preprocessing.sequence.skipgrams(sequence,vocabulary_size,window_size=4,negative_samples=1.0,shuffle=True,categorical=False,sampling_table=None,seed=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/integration_test/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/integration_test/preprocessing_test_utils.py----------------------------------------
A:keras.integration_test.preprocessing_test_utils.floats->tensorflow.compat.v2.random.uniform((DS_SIZE, 1), maxval=10, dtype='float32')
A:keras.integration_test.preprocessing_test_utils.ints->tensorflow.compat.v2.random.uniform((DS_SIZE, 1), maxval=VOCAB_SIZE, dtype='int64')
A:keras.integration_test.preprocessing_test_utils.strings->tensorflow.compat.v2.strings.as_string(strings)
A:keras.integration_test.preprocessing_test_utils.labels->tensorflow.compat.v2.random.uniform((DS_SIZE, 1), maxval=2, dtype='int64')
A:keras.integration_test.preprocessing_test_utils.ds->make_dataset().batch(BATCH_SIZE)
A:keras.integration_test.preprocessing_test_utils.float_in->tensorflow.compat.v2.keras.Input(shape=(1,), dtype='float32', name='float_col')
A:keras.integration_test.preprocessing_test_utils.int_in->tensorflow.compat.v2.keras.Input(shape=(1,), dtype='int64', name='int_col')
A:keras.integration_test.preprocessing_test_utils.string_in->tensorflow.compat.v2.keras.Input(shape=(1,), dtype='int64', name='string_col')
A:keras.integration_test.preprocessing_test_utils.normalization->preprocessing.Normalization()
A:keras.integration_test.preprocessing_test_utils.float_out->normalization(float_in)
A:keras.integration_test.preprocessing_test_utils.int_lookup->preprocessing.IntegerLookup()
A:keras.integration_test.preprocessing_test_utils.int_out->tensorflow.compat.v2.keras.layers.Flatten()(int_out)
A:keras.integration_test.preprocessing_test_utils.string_vocab->list((str(i) for i in range(VOCAB_SIZE)))
A:keras.integration_test.preprocessing_test_utils.vocab_file->os.path.join(file_dir, 'vocab_file.txt')
A:keras.integration_test.preprocessing_test_utils.string_lookup->preprocessing.StringLookup(vocabulary=vocab_file)
A:keras.integration_test.preprocessing_test_utils.string_out->tensorflow.compat.v2.keras.layers.Flatten()(string_out)
A:keras.integration_test.preprocessing_test_utils.int_embedding->tensorflow.compat.v2.keras.layers.Embedding(VOCAB_SIZE + 1, 8, input_length=1)
A:keras.integration_test.preprocessing_test_utils.string_embedding->tensorflow.compat.v2.keras.layers.Embedding(VOCAB_SIZE + 1, 8, input_length=1)
A:keras.integration_test.preprocessing_test_utils.concatate->tensorflow.compat.v2.keras.layers.Concatenate()
A:keras.integration_test.preprocessing_test_utils.x->tensorflow.compat.v2.keras.layers.Dense(32, activation='relu')(x)
A:keras.integration_test.preprocessing_test_utils.outputs->tensorflow.compat.v2.keras.layers.Dense(1, activation='softmax')(x)
keras.integration_test.preprocessing_test_utils.make_dataset()
keras.integration_test.preprocessing_test_utils.make_preprocessing_model(file_dir)
keras.integration_test.preprocessing_test_utils.make_training_model()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/pickle_utils.py----------------------------------------
A:keras.saving.pickle_utils.b->io.BytesIO()
A:keras.saving.pickle_utils.dest_path->tensorflow.compat.v2.io.gfile.join(root, filename)
A:keras.saving.pickle_utils.member->archive.getmember(name)
A:keras.saving.pickle_utils.model->keras.saving.save.load_model(temp_dir)
A:keras.saving.pickle_utils.t->tarfile.TarInfo(dest_path)
A:keras.saving.pickle_utils.info->tarfile.TarInfo(name=os.path.relpath(dest_path, temp_dir))
A:keras.saving.pickle_utils.info.size->f.size()
keras.saving.pickle_utils.deserialize_model_from_bytecode(serialized_model)
keras.saving.pickle_utils.serialize_model_as_bytecode(model)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model_experimental.py----------------------------------------
A:keras.saving.saved_model_experimental.metrics_lib->LazyLoader('metrics_lib', globals(), 'keras.metrics')
A:keras.saving.saved_model_experimental.models_lib->LazyLoader('models_lib', globals(), 'keras.models')
A:keras.saving.saved_model_experimental.sequential->LazyLoader('sequential', globals(), 'keras.engine.sequential')
A:keras.saving.saved_model_experimental.model_json->f.read()
A:keras.saving.saved_model_experimental.model_json_filepath->tensorflow.compat.v2.io.gfile.join(tf.compat.as_bytes(saved_model_path), tf.compat.as_bytes(tf.saved_model.ASSETS_DIRECTORY), tf.compat.as_bytes(SAVED_MODEL_FILENAME_JSON))
A:keras.saving.saved_model_experimental.checkpoint_prefix->tensorflow.compat.v2.io.gfile.join(tf.compat.as_text(saved_model_path), tf.compat.as_text(tf.saved_model.VARIABLES_DIRECTORY), tf.compat.as_text(tf.saved_model.VARIABLES_FILENAME))
A:keras.saving.saved_model_experimental.builder->tensorflow.compat.v2.__internal__.saved_model.SavedModelBuilder(path)
A:keras.saving.saved_model_experimental.checkpoint_path->_export_model_variables(model, path)
A:keras.saving.saved_model_experimental.(var_list, _, _)->tensorflow.compat.v2.__internal__.tracking.ObjectGraphView(model).serialize_object_graph()
A:keras.saving.saved_model_experimental.model_graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.saving.saved_model_experimental.input_tensors->tensorflow.compat.v2.nest.map_structure(create_placeholder, input_signature)
A:keras.saving.saved_model_experimental.clone->LazyLoader('models_lib', globals(), 'keras.models').clone_and_build_model(model, input_tensors=input_tensors, custom_objects=custom_objects, compile_clone=compile_clone)
A:keras.saving.saved_model_experimental.clone_var_list->_get_var_list(clone)
A:keras.saving.saved_model_experimental.status->LazyLoader('models_lib', globals(), 'keras.models').clone_and_build_model(model, input_tensors=input_tensors, custom_objects=custom_objects, compile_clone=compile_clone).load_weights(checkpoint_path)
A:keras.saving.saved_model_experimental.metrics->keras.saving.saving_utils.extract_model_metrics(model)
A:keras.saving.saved_model_experimental.local_vars->set(tf.compat.v1.get_collection(tf.compat.v1.GraphKeys.LOCAL_VARIABLES))
A:keras.saving.saved_model_experimental.vars_to_add->vars_to_add.difference(local_vars).difference(local_vars)
A:keras.saving.saved_model_experimental.export_outputs->keras.saving.utils_v1.export_outputs_for_mode(mode, predictions=outputs_dict, loss=model.total_loss if model.optimizer else None, metrics=metrics)
A:keras.saving.saved_model_experimental.model->keras.saving.model_config.model_from_json(model_json, custom_objects=custom_objects)
A:keras.saving.saved_model_experimental.variables_dir->_get_variables_dir(export_dir)
A:keras.saving.saved_model_experimental.assets_destination_dir->_get_assets_dir(export_dir)
keras.saving.saved_model_experimental._assert_same_non_optimizer_objects(model,model_graph,clone,clone_graph)
keras.saving.saved_model_experimental._create_signature_def_map(model,mode)
keras.saving.saved_model_experimental._export_mode(mode,has_saved_vars,builder,model,custom_objects,checkpoint_path,input_signature)
keras.saving.saved_model_experimental._export_model_json(model,saved_model_path)
keras.saving.saved_model_experimental._export_model_variables(model,saved_model_path)
keras.saving.saved_model_experimental._get_assets_dir(export_dir)
keras.saving.saved_model_experimental._get_or_create_assets_dir(export_dir)
keras.saving.saved_model_experimental._get_or_create_variables_dir(export_dir)
keras.saving.saved_model_experimental._get_var_list(model)
keras.saving.saved_model_experimental._get_variables_dir(export_dir)
keras.saving.saved_model_experimental._get_variables_path(export_dir)
keras.saving.saved_model_experimental._save_v1_format(model,path,custom_objects,as_text,input_signature)
keras.saving.saved_model_experimental.create_placeholder(spec)
keras.saving.saved_model_experimental.export_saved_model(model,saved_model_path,custom_objects=None,as_text=False,input_signature=None,serving_only=False)
keras.saving.saved_model_experimental.load_from_saved_model(saved_model_path,custom_objects=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saving_utils.py----------------------------------------
A:keras.saving.saving_utils.input_specs->_enforce_names_consistency(input_specs)
A:keras.saving.saving_utils.(model_args, model_kwargs)->model_call_inputs(model)
A:keras.saving.saving_utils.outputs->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.saving.saving_utils.output_names->keras.engine.compile_utils.create_pseudo_output_names(outputs)
A:keras.saving.saving_utils.model_config['config']->model.get_config()
A:keras.saving.saving_utils.metadata->dict(keras_version=str(keras_version), backend=backend.backend(), model_config=model_config)
A:keras.saving.saving_utils.training_config->model._get_compile_args(user_metrics=False)
A:keras.saving.saving_utils.metadata['training_config']->_serialize_nested_config(training_config)
A:keras.saving.saving_utils.optimizer->keras.optimizers.deserialize(optimizer_config)
A:keras.saving.saving_utils.loss_config->model._get_compile_args(user_metrics=False).get('loss', None)
A:keras.saving.saving_utils.loss->_deserialize_nested_config(losses.deserialize, loss_config)
A:keras.saving.saving_utils.metrics_config->model._get_compile_args(user_metrics=False).get('metrics', None)
A:keras.saving.saving_utils.metrics->_deserialize_nested_config(_deserialize_metric, metrics_config)
A:keras.saving.saving_utils.weighted_metrics_config->model._get_compile_args(user_metrics=False).get('weighted_metrics', None)
A:keras.saving.saving_utils.weighted_metrics->_deserialize_nested_config(_deserialize_metric, weighted_metrics_config)
A:keras.saving.saving_utils.spec->copy.deepcopy(spec)
A:keras.saving.saving_utils.flat_specs->tensorflow.compat.v2.nest.flatten(specs)
A:keras.saving.saving_utils.specs->tensorflow.compat.v2.nest.map_structure(_clear_name, specs)
keras.saving.saving_utils._deserialize_metric(metric_config)
keras.saving.saving_utils._deserialize_nested_config(deserialize_fn,config)
keras.saving.saving_utils._enforce_names_consistency(specs)
keras.saving.saving_utils._serialize_nested_config(config)
keras.saving.saving_utils.compile_args_from_training_config(training_config,custom_objects=None)
keras.saving.saving_utils.extract_model_metrics(model)
keras.saving.saving_utils.is_hdf5_filepath(filepath)
keras.saving.saving_utils.model_call_inputs(model,keep_original_batch_size=False)
keras.saving.saving_utils.model_metadata(model,include_optimizer=True,require_config=True)
keras.saving.saving_utils.raise_model_input_error(model)
keras.saving.saving_utils.should_overwrite(filepath,overwrite)
keras.saving.saving_utils.trace_model_call(model,input_signature=None)
keras.saving.saving_utils.try_build_compiled_arguments(model)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/hdf5_format.py----------------------------------------
A:keras.saving.hdf5_format.sequential_lib->LazyLoader('sequential_lib', globals(), 'keras.engine.sequential')
A:keras.saving.hdf5_format.proceed->ask_to_proceed_with_overwrite(filepath)
A:keras.saving.hdf5_format.dirpath->os.path.dirname(filepath)
A:keras.saving.hdf5_format.f->h5py.File(filepath, mode='r')
A:keras.saving.hdf5_format.model_metadata->keras.saving.saving_utils.model_metadata(model, include_optimizer)
A:keras.saving.hdf5_format.f.attrs[k]->json.dumps(v, default=json_utils.get_json_type).encode('utf8')
A:keras.saving.hdf5_format.model_weights_group->h5py.File(filepath, mode='r').create_group('model_weights')
A:keras.saving.hdf5_format.model_config->keras.saving.saved_model.json_utils.decode(model_config)
A:keras.saving.hdf5_format.model->keras.saving.model_config.model_from_config(model_config, custom_objects=custom_objects)
A:keras.saving.hdf5_format.training_config->keras.saving.saved_model.json_utils.decode(training_config)
A:keras.saving.hdf5_format.optimizer_weight_values->load_optimizer_weights_from_hdf5_group(f)
A:keras.saving.hdf5_format.forward_weights->preprocess_weights_for_loading(layer.forward_layer, weights[:num_weights_per_layer], original_keras_version, original_backend)
A:keras.saving.hdf5_format.backward_weights->preprocess_weights_for_loading(layer.backward_layer, weights[num_weights_per_layer:], original_keras_version, original_backend)
A:keras.saving.hdf5_format.num_trainable_weights->len(sublayer.trainable_weights)
A:keras.saving.hdf5_format.num_non_trainable_weights->len(sublayer.non_trainable_weights)
A:keras.saving.hdf5_format.preprocessed->preprocess_weights_for_loading(layer=sublayer, weights=trainable_weights[:num_trainable_weights] + non_trainable_weights[:num_non_trainable_weights], original_keras_version=original_keras_version, original_backend=original_backend)
A:keras.saving.hdf5_format.weights->_legacy_weights(layer)
A:keras.saving.hdf5_format.weights[0]->numpy.transpose(weights[0], (3, 2, 0, 1))
A:keras.saving.hdf5_format.kernel->numpy.transpose(kernel, (2, 3, 1, 0))
A:keras.saving.hdf5_format.recurrent_kernel->numpy.transpose(recurrent_kernel, (2, 3, 1, 0))
A:keras.saving.hdf5_format.bias->numpy.concatenate([weights[2], weights[8], weights[5], weights[11]], axis=-1)
A:keras.saving.hdf5_format.weights[1]->numpy.transpose(weights[1], (3, 2, 0, 1))
A:keras.saving.hdf5_format.kernels->transform_kernels(weights[0], transpose_input(from_cudnn), n_gates)
A:keras.saving.hdf5_format.recurrent_kernels->transform_kernels(weights[1], lambda k: k.T, n_gates)
A:keras.saving.hdf5_format.biases->numpy.array(weights[2]).reshape((2, -1) if from_cudnn else -1)
A:keras.saving.hdf5_format.symbolic_weights->_legacy_weights(layer)
A:keras.saving.hdf5_format.weights_group->hdf5_group.create_group('optimizer_weights')
A:keras.saving.hdf5_format.weight_values->load_subset_weights_from_hdf5_group(f['top_level_model_weights'])
A:keras.saving.hdf5_format.param_dset->h5py.File(filepath, mode='r').create_dataset(name, val.shape, dtype=val.dtype)
A:keras.saving.hdf5_format.optimizer_weight_names->load_attributes_from_hdf5_group(weights_group, 'weight_names')
A:keras.saving.hdf5_format.f.attrs['backend']->keras.backend.backend().encode('utf8')
A:keras.saving.hdf5_format.f.attrs['keras_version']->str(keras_version).encode('utf8')
A:keras.saving.hdf5_format.g->h5py.File(filepath, mode='r').create_group('top_level_model_weights')
A:keras.saving.hdf5_format.weight_names->load_attributes_from_hdf5_group(g, 'weight_names')
A:keras.saving.hdf5_format.original_keras_version->original_keras_version.decode('utf8').decode('utf8')
A:keras.saving.hdf5_format.original_backend->original_backend.decode('utf8').decode('utf8')
A:keras.saving.hdf5_format.layer_names->load_attributes_from_hdf5_group(f, 'layer_names')
A:keras.saving.hdf5_format.expected_shape->keras.backend.int_shape(symbolic_weights[i])
A:keras.saving.hdf5_format.data_npy->numpy.asarray(data)
A:keras.saving.hdf5_format.chunked_data->numpy.array_split(data_npy, num_chunks)
keras.saving.hdf5_format._convert_rnn_weights(layer,weights)
keras.saving.hdf5_format._legacy_weights(layer)
keras.saving.hdf5_format.load_attributes_from_hdf5_group(group,name)
keras.saving.hdf5_format.load_model_from_hdf5(filepath,custom_objects=None,compile=True)
keras.saving.hdf5_format.load_optimizer_weights_from_hdf5_group(hdf5_group)
keras.saving.hdf5_format.load_subset_weights_from_hdf5_group(f)
keras.saving.hdf5_format.load_weights_from_hdf5_group(f,model)
keras.saving.hdf5_format.load_weights_from_hdf5_group_by_name(f,model,skip_mismatch=False)
keras.saving.hdf5_format.preprocess_weights_for_loading(layer,weights,original_keras_version=None,original_backend=None)
keras.saving.hdf5_format.save_attributes_to_hdf5_group(group,name,data)
keras.saving.hdf5_format.save_model_to_hdf5(model,filepath,overwrite=True,include_optimizer=True)
keras.saving.hdf5_format.save_optimizer_weights_to_hdf5_group(hdf5_group,optimizer)
keras.saving.hdf5_format.save_subset_weights_to_hdf5_group(f,weights)
keras.saving.hdf5_format.save_weights_to_hdf5_group(f,model)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/model_config.py----------------------------------------
keras.saving.model_config.model_from_config(config,custom_objects=None)
keras.saving.model_config.model_from_json(json_string,custom_objects=None)
keras.saving.model_config.model_from_yaml(yaml_string,custom_objects=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/save.py----------------------------------------
A:keras.saving.save.filepath->path_to_string(filepath)
A:keras.saving.save.filepath_str->path_to_string(filepath)
keras.saving.save.load_model(filepath,custom_objects=None,compile=True,options=None)
keras.saving.save.save_model(model,filepath,overwrite=True,include_optimizer=True,save_format=None,signatures=None,options=None,save_traces=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/utils_v1/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/utils_v1/mode_keys.py----------------------------------------
A:keras.saving.utils_v1.mode_keys.dict_key->self._get_internal_key(key)
keras.saving.utils_v1.mode_keys.EstimatorModeKeys
keras.saving.utils_v1.mode_keys.KerasModeKeys
keras.saving.utils_v1.mode_keys.ModeKeyMap(self,**kwargs)
keras.saving.utils_v1.mode_keys.ModeKeyMap.__getitem__(self,key)
keras.saving.utils_v1.mode_keys.ModeKeyMap.__init__(self,**kwargs)
keras.saving.utils_v1.mode_keys.ModeKeyMap.__iter__(self)
keras.saving.utils_v1.mode_keys.ModeKeyMap.__len__(self)
keras.saving.utils_v1.mode_keys.ModeKeyMap._get_internal_key(self,key)
keras.saving.utils_v1.mode_keys.is_eval(mode)
keras.saving.utils_v1.mode_keys.is_predict(mode)
keras.saving.utils_v1.mode_keys.is_train(mode)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/utils_v1/unexported_constants.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/utils_v1/export_utils.py----------------------------------------
A:keras.saving.utils_v1.export_utils.EXPORT_TAG_MAP->keras.saving.utils_v1.mode_keys.ModeKeyMap(**{ModeKeys.PREDICT: [tf.saved_model.SERVING], ModeKeys.TRAIN: [tf.saved_model.TRAINING], ModeKeys.TEST: [unexported_constants.EVAL]})
A:keras.saving.utils_v1.export_utils.SIGNATURE_KEY_MAP->keras.saving.utils_v1.mode_keys.ModeKeyMap(**{ModeKeys.PREDICT: tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY, ModeKeys.TRAIN: unexported_constants.DEFAULT_TRAIN_SIGNATURE_DEF_KEY, ModeKeys.TEST: unexported_constants.DEFAULT_EVAL_SIGNATURE_DEF_KEY})
A:keras.saving.utils_v1.export_utils.signature_name->'{}:{}'.format(receiver_name or 'None', output_key or 'None')
A:keras.saving.utils_v1.export_utils.signature->export_output.as_signature_def(receiver_tensors_alt)
A:keras.saving.utils_v1.export_utils.excluded_signatures[signature_name]->str(e)
A:keras.saving.utils_v1.export_utils.sig_names_by_method_name->collections.defaultdict(list)
A:keras.saving.utils_v1.export_utils.timestamp->int(time.time())
A:keras.saving.utils_v1.export_utils.result_dir->tensorflow.compat.v2.io.gfile.join(tf.compat.as_bytes(export_dir_base), tf.compat.as_bytes(str(timestamp)))
A:keras.saving.utils_v1.export_utils.(dirname, basename)->os.path.split(timestamped_export_dir)
A:keras.saving.utils_v1.export_utils.str_name->str(basename)
A:keras.saving.utils_v1.export_utils.temp_export_dir->tensorflow.compat.v2.io.gfile.join(tf.compat.as_bytes(dirname), tf.compat.as_bytes('temp-{}'.format(str_name)))
A:keras.saving.utils_v1.export_utils.default_output->keras.saving.utils_v1.export_output.PredictOutput(predictions)
A:keras.saving.utils_v1.export_utils.((key, value),)->export_outputs.items()
keras.saving.utils_v1.build_all_signature_defs(receiver_tensors,export_outputs,receiver_tensors_alternatives=None,serving_only=True)
keras.saving.utils_v1.export_outputs_for_mode(mode,serving_export_outputs=None,predictions=None,loss=None,metrics=None)
keras.saving.utils_v1.export_utils._log_signature_report(signature_def_map,excluded_signatures)
keras.saving.utils_v1.export_utils._maybe_add_default_serving_output(export_outputs)
keras.saving.utils_v1.export_utils.build_all_signature_defs(receiver_tensors,export_outputs,receiver_tensors_alternatives=None,serving_only=True)
keras.saving.utils_v1.export_utils.export_outputs_for_mode(mode,serving_export_outputs=None,predictions=None,loss=None,metrics=None)
keras.saving.utils_v1.export_utils.get_export_outputs(export_outputs,predictions)
keras.saving.utils_v1.export_utils.get_temp_export_dir(timestamped_export_dir)
keras.saving.utils_v1.export_utils.get_timestamped_export_dir(export_dir_base)
keras.saving.utils_v1.get_export_outputs(export_outputs,predictions)
keras.saving.utils_v1.get_temp_export_dir(timestamped_export_dir)
keras.saving.utils_v1.get_timestamped_export_dir(export_dir_base)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/utils_v1/export_output.py----------------------------------------
A:keras.saving.utils_v1.export_output.key->self._prefix_key(key, self.METRICS_NAME)
A:keras.saving.utils_v1.export_output.((_, examples),)->receiver_tensors.items()
A:keras.saving.utils_v1.export_output.self._outputs->self._wrap_and_check_outputs(outputs, self._SINGLE_OUTPUT_DEFAULT_NAME, error_label='Prediction')
A:keras.saving.utils_v1.export_output.loss_dict->self._wrap_and_check_outputs(loss, self.LOSS_NAME)
A:keras.saving.utils_v1.export_output.self._loss->self._prefix_output_keys(loss_dict, self.LOSS_NAME)
A:keras.saving.utils_v1.export_output.pred_dict->self._wrap_and_check_outputs(predictions, self.PREDICTIONS_NAME)
A:keras.saving.utils_v1.export_output.self._predictions->self._prefix_output_keys(pred_dict, self.PREDICTIONS_NAME)
A:keras.saving.utils_v1.export_output.self._metrics->self._wrap_and_check_metrics(metrics)
A:keras.saving.utils_v1.export_output.metric_val->value.result()
A:keras.saving.utils_v1.export_output.metric_op_tensor->tensorflow.compat.v2.constant([], name='metric_op_wrapper')
A:keras.saving.utils_v1.export_output.signature_def_fn->self._get_signature_def_fn()
keras.saving.utils_v1.ClassificationOutput(self,scores=None,classes=None)
keras.saving.utils_v1.ClassificationOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.ClassificationOutput.classes(self)
keras.saving.utils_v1.ClassificationOutput.scores(self)
keras.saving.utils_v1.EvalOutput(_SupervisedOutput)
keras.saving.utils_v1.EvalOutput._get_signature_def_fn(self)
keras.saving.utils_v1.ExportOutput
keras.saving.utils_v1.ExportOutput._check_output_key(self,key,error_label)
keras.saving.utils_v1.ExportOutput._wrap_and_check_outputs(self,outputs,single_output_default_name,error_label=None)
keras.saving.utils_v1.ExportOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.PredictOutput(self,outputs)
keras.saving.utils_v1.PredictOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.PredictOutput.outputs(self)
keras.saving.utils_v1.RegressionOutput(self,value)
keras.saving.utils_v1.RegressionOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.RegressionOutput.value(self)
keras.saving.utils_v1.TrainOutput(_SupervisedOutput)
keras.saving.utils_v1.TrainOutput._get_signature_def_fn(self)
keras.saving.utils_v1._SupervisedOutput(self,loss=None,predictions=None,metrics=None)
keras.saving.utils_v1._SupervisedOutput._get_signature_def_fn(self)
keras.saving.utils_v1._SupervisedOutput._prefix_key(self,key,output_name)
keras.saving.utils_v1._SupervisedOutput._prefix_output_keys(self,output_dict,output_name)
keras.saving.utils_v1._SupervisedOutput._wrap_and_check_metrics(self,metrics)
keras.saving.utils_v1._SupervisedOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1._SupervisedOutput.loss(self)
keras.saving.utils_v1._SupervisedOutput.metrics(self)
keras.saving.utils_v1._SupervisedOutput.predictions(self)
keras.saving.utils_v1.export_output.ClassificationOutput(self,scores=None,classes=None)
keras.saving.utils_v1.export_output.ClassificationOutput.__init__(self,scores=None,classes=None)
keras.saving.utils_v1.export_output.ClassificationOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.export_output.ClassificationOutput.classes(self)
keras.saving.utils_v1.export_output.ClassificationOutput.scores(self)
keras.saving.utils_v1.export_output.EvalOutput(_SupervisedOutput)
keras.saving.utils_v1.export_output.EvalOutput._get_signature_def_fn(self)
keras.saving.utils_v1.export_output.ExportOutput
keras.saving.utils_v1.export_output.ExportOutput._check_output_key(self,key,error_label)
keras.saving.utils_v1.export_output.ExportOutput._wrap_and_check_outputs(self,outputs,single_output_default_name,error_label=None)
keras.saving.utils_v1.export_output.ExportOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.export_output.PredictOutput(self,outputs)
keras.saving.utils_v1.export_output.PredictOutput.__init__(self,outputs)
keras.saving.utils_v1.export_output.PredictOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.export_output.PredictOutput.outputs(self)
keras.saving.utils_v1.export_output.RegressionOutput(self,value)
keras.saving.utils_v1.export_output.RegressionOutput.__init__(self,value)
keras.saving.utils_v1.export_output.RegressionOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.export_output.RegressionOutput.value(self)
keras.saving.utils_v1.export_output.TrainOutput(_SupervisedOutput)
keras.saving.utils_v1.export_output.TrainOutput._get_signature_def_fn(self)
keras.saving.utils_v1.export_output._SupervisedOutput(self,loss=None,predictions=None,metrics=None)
keras.saving.utils_v1.export_output._SupervisedOutput.__init__(self,loss=None,predictions=None,metrics=None)
keras.saving.utils_v1.export_output._SupervisedOutput._get_signature_def_fn(self)
keras.saving.utils_v1.export_output._SupervisedOutput._prefix_key(self,key,output_name)
keras.saving.utils_v1.export_output._SupervisedOutput._prefix_output_keys(self,output_dict,output_name)
keras.saving.utils_v1.export_output._SupervisedOutput._wrap_and_check_metrics(self,metrics)
keras.saving.utils_v1.export_output._SupervisedOutput.as_signature_def(self,receiver_tensors)
keras.saving.utils_v1.export_output._SupervisedOutput.loss(self)
keras.saving.utils_v1.export_output._SupervisedOutput.metrics(self)
keras.saving.utils_v1.export_output._SupervisedOutput.predictions(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/utils_v1/signature_def_utils.py----------------------------------------
A:keras.saving.utils_v1.signature_def_utils.signature_def->tensorflow.compat.v2.compat.v1.saved_model.build_signature_def(signature_inputs, signature_outputs, method_name)
keras.saving.utils_v1.signature_def_utils._supervised_signature_def(method_name,inputs,loss=None,predictions=None,metrics=None)
keras.saving.utils_v1.signature_def_utils.supervised_eval_signature_def(inputs,loss,predictions=None,metrics=None)
keras.saving.utils_v1.signature_def_utils.supervised_train_signature_def(inputs,loss,predictions=None,metrics=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/order_preserving_set.py----------------------------------------
A:keras.saving.saved_model.order_preserving_set.result->self._from_iterable((value for value in self))
keras.saving.saved_model.order_preserving_set.OrderPreservingSet(self,iterable=None)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__and__(self,other)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__contains__(self,value)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__eq__(self,other)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__ge__(self,other)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__init__(self,iterable=None)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__iter__(self)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__le__(self,other)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__len__(self)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.__or__(self,other)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.add(self,item)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.clear(self)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.discard(self,value)
keras.saving.saved_model.order_preserving_set.OrderPreservingSet.union(self,other)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/save_impl.py----------------------------------------
A:keras.saving.saved_model.save_impl.base_layer->LazyLoader('base_layer', globals(), 'keras.engine.base_layer')
A:keras.saving.saved_model.save_impl.metrics->LazyLoader('metrics', globals(), 'keras.metrics')
A:keras.saving.saved_model.save_impl.input_layer->LazyLoader('input_layer', globals(), 'keras.engine.input_layer')
A:keras.saving.saved_model.save_impl.training_lib->LazyLoader('training_lib', globals(), 'keras.engine.training')
A:keras.saving.saved_model.save_impl.sequential_lib->LazyLoader('sequential_lib', globals(), 'keras.engine.sequential')
A:keras.saving.saved_model.save_impl.keras_loss_cache->serialization_cache.setdefault('keras_losses', {})
A:keras.saving.saved_model.save_impl.wrapped_loss->_wrap_unconditional_loss(loss_fn, len(keras_loss_cache))
A:keras.saving.saved_model.save_impl.layer_metrics->tensorflow.compat.v2.__internal__.tracking.wrap({m.name: m for m in layer._metrics})
A:keras.saving.saved_model.save_impl.original_fns->_replace_child_layer_functions(layer, serialization_cache)
A:keras.saving.saved_model.save_impl.original_losses->_reset_layer_losses(layer)
A:keras.saving.saved_model.save_impl.call_collection->LayerCallCollection(layer)
A:keras.saving.saved_model.save_impl.call_fn_with_losses->LayerCallCollection(layer).add_function(_wrap_call_and_conditional_losses(layer), '{}_layer_call_and_return_conditional_losses'.format(layer.name), match_layer_training_arg=True)
A:keras.saving.saved_model.save_impl.call_fn->_get_layer_call_method(layer)
A:keras.saving.saved_model.save_impl.fns['activity_regularizer_fn']->_wrap_activity_regularizer(layer)
A:keras.saving.saved_model.save_impl.fns['call_and_return_all_conditional_losses']->LayerCallCollection(layer).add_function(_append_activity_regularizer_loss(layer, call_fn_with_losses, fns['activity_regularizer_fn']), '{}_layer_call_and_return_all_conditional_losses'.format(layer.name), match_layer_training_arg=False)
A:keras.saving.saved_model.save_impl.fn->tensorflow.compat.v2.__internal__.decorator.make_decorator(target=method, decorator_func=wrapper)
A:keras.saving.saved_model.save_impl.child_layer._activity_regularizer->serialized_fns.get('activity_regularizer_fn')
A:keras.saving.saved_model.save_impl.child_layer.call->keras.saving.saved_model.utils.use_wrapped_call(child_layer, serialized_fns['call_and_return_conditional_losses'], default_training_value=False)
A:keras.saving.saved_model.save_impl._thread_local_data->LayerTracingContext()
A:keras.saving.saved_model.save_impl.(fn, args, kwargs, training)->LayerTracingContext().trace_queue.pop()
A:keras.saving.saved_model.save_impl.self.layer_call_method->_get_layer_call_method(layer)
A:keras.saving.saved_model.save_impl.self._expects_training_arg->keras.saving.saved_model.utils.layer_uses_training_bool(layer)
A:keras.saving.saved_model.save_impl.self._training_arg_index->keras.saving.saved_model.utils.get_training_arg_index(self.layer_call_method)
A:keras.saving.saved_model.save_impl.self._layer_inputs->self._get_layer_inputs(layer)
A:keras.saving.saved_model.save_impl.self._functions->weakref.WeakValueDictionary()
A:keras.saving.saved_model.save_impl.arg_spec->keras.utils.tf_inspect.getfullargspec(call_fn)
A:keras.saving.saved_model.save_impl.spec->keras.engine.input_spec.to_tensor_spec(x, layer._compute_dtype)
A:keras.saving.saved_model.save_impl.args->list(args)
A:keras.saving.saved_model.save_impl.kwargs->kwargs.copy().copy()
A:keras.saving.saved_model.save_impl.defaults->list(arg_spec.defaults or [])
A:keras.saving.saved_model.save_impl.new_arg_spec->keras.utils.tf_inspect.FullArgSpec(args=args, varargs=arg_spec.varargs, varkw=arg_spec.varkw, defaults=defaults, kwonlyargs=arg_spec.kwonlyargs, kwonlydefaults=arg_spec.kwonlydefaults, annotations=arg_spec.annotations)
A:keras.saving.saved_model.save_impl.inputs->_filtered_inputs([args, kwargs])
A:keras.saving.saved_model.save_impl.training->LayerCallCollection(layer).get_training_arg_value(args, kwargs)
A:keras.saving.saved_model.save_impl.ret->method(*args, **kwargs)
A:keras.saving.saved_model.save_impl.self.wrapped_call->tensorflow.compat.v2.function(layer_call_wrapper(call_collection, call_fn, name))
A:keras.saving.saved_model.save_impl.layer_call->_get_layer_call_method(layer)
A:keras.saving.saved_model.save_impl.call_output->layer_call(*args, **kwargs)
A:keras.saving.saved_model.save_impl.conditional_losses->layer.get_losses_for(_filtered_inputs([args, kwargs]))
A:keras.saving.saved_model.save_impl.(outputs, losses)->call_fn_with_losses(inputs, *args, **kwargs)
A:keras.saving.saved_model.save_impl.(fn, arg_spec)->keras.saving.saved_model.utils.maybe_add_training_arg(call_fn, wrapped_call, layer._expects_training_arg, default_training_value=False)
keras.saving.saved_model.save_impl.LayerCall(self,call_collection,call_fn,name)
keras.saving.saved_model.save_impl.LayerCall.__init__(self,call_collection,call_fn,name)
keras.saving.saved_model.save_impl.LayerCall._maybe_trace(self,args,kwargs)
keras.saving.saved_model.save_impl.LayerCall.get_concrete_function(self,*args,**kwargs)
keras.saving.saved_model.save_impl.LayerCallCollection(self,layer)
keras.saving.saved_model.save_impl.LayerCallCollection.__init__(self,layer)
keras.saving.saved_model.save_impl.LayerCallCollection._get_layer_inputs(self,layer)
keras.saving.saved_model.save_impl.LayerCallCollection._maybe_wrap_with_training_arg(self,call_fn,match_layer_training_arg)
keras.saving.saved_model.save_impl.LayerCallCollection.add_function(self,call_fn,name,match_layer_training_arg)
keras.saving.saved_model.save_impl.LayerCallCollection.add_trace(self,*args,**kwargs)
keras.saving.saved_model.save_impl.LayerCallCollection.get_input_arg_value(self,args,kwargs)
keras.saving.saved_model.save_impl.LayerCallCollection.get_training_arg_value(self,args,kwargs)
keras.saving.saved_model.save_impl.LayerCallCollection.trace_with_input_signature(self)
keras.saving.saved_model.save_impl.LayerCallCollection.training_arg_was_passed(self,args,kwargs)
keras.saving.saved_model.save_impl.LayerTracingContext(self)
keras.saving.saved_model.save_impl.LayerTracingContext.__init__(self)
keras.saving.saved_model.save_impl._append_activity_regularizer_loss(layer,call_fn_with_losses,activity_regularizer_fn)
keras.saving.saved_model.save_impl._create_call_fn_decorator(layer,wrapped_call)
keras.saving.saved_model.save_impl._extract_outputs_from_fn(layer,call_and_return_conditional_losses)
keras.saving.saved_model.save_impl._filtered_inputs(inputs)
keras.saving.saved_model.save_impl._get_layer_call_method(layer)
keras.saving.saved_model.save_impl._replace_child_layer_functions(layer,serialization_cache)
keras.saving.saved_model.save_impl._reset_layer_losses(parent_layer)
keras.saving.saved_model.save_impl._restore_child_layer_functions(original_fns)
keras.saving.saved_model.save_impl._restore_layer_losses(losses_dict)
keras.saving.saved_model.save_impl._wrap_activity_regularizer(layer)
keras.saving.saved_model.save_impl._wrap_call_and_conditional_losses(layer)
keras.saving.saved_model.save_impl._wrap_unconditional_loss(loss_fn,index)
keras.saving.saved_model.save_impl.add_trace_to_queue(fn,args,kwargs,training=None)
keras.saving.saved_model.save_impl.default_save_signature(layer)
keras.saving.saved_model.save_impl.layer_call_wrapper(call_collection,method,name)
keras.saving.saved_model.save_impl.should_skip_serialization(layer)
keras.saving.saved_model.save_impl.tracing_enabled()
keras.saving.saved_model.save_impl.tracing_scope()
keras.saving.saved_model.save_impl.wrap_layer_functions(layer,serialization_cache)
keras.saving.saved_model.save_impl.wrap_layer_objects(layer,serialization_cache)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/utils.py----------------------------------------
A:keras.saving.saved_model.utils.training_lib->LazyLoader('training_lib', globals(), 'keras.engine.training')
A:keras.saving.saved_model.utils.expects_training_arg->layer_uses_training_bool(layer)
A:keras.saving.saved_model.utils.(fn, arg_spec)->maybe_add_training_arg(original_call, call_fn, expects_training_arg, default_training_value)
A:keras.saving.saved_model.utils.(outputs, losses)->fn(*args, **kwargs)
A:keras.saving.saved_model.utils.decorated->tensorflow.compat.v2.__internal__.decorator.make_decorator(target=call_fn, decorator_func=return_outputs_and_add_losses, decorator_argspec=arg_spec)
A:keras.saving.saved_model.utils.to_visit->list_all_layers(layer)
A:keras.saving.saved_model.utils.layer->list_all_layers(layer).pop()
A:keras.saving.saved_model.utils.s->set([obj])
A:keras.saving.saved_model.utils.training_arg_index->get_training_arg_index(original_call)
A:keras.saving.saved_model.utils.training->get_training_arg(training_arg_index, args, kwargs)
A:keras.saving.saved_model.utils.args->list(args)
A:keras.saving.saved_model.utils.kwargs->kwargs.copy().copy()
A:keras.saving.saved_model.utils.arg_spec->keras.utils.tf_inspect.getfullargspec(original_call)
A:keras.saving.saved_model.utils.index->keras.utils.tf_inspect.getfullargspec(original_call).args.index('training')
A:keras.saving.saved_model.utils.decorator_argspec->keras.utils.tf_inspect.FullArgSpec(args=arg_spec.args, varargs=arg_spec.varargs, varkw=arg_spec.varkw, defaults=defaults, kwonlyargs=kwonlyargs, kwonlydefaults=kwonlydefaults, annotations=arg_spec.annotations)
A:keras.saving.saved_model.utils.argspec->keras.utils.tf_inspect.getfullargspec(call_fn)
A:keras.saving.saved_model.utils._save_options_context->SaveOptionsContext()
A:keras.saving.saved_model.utils.previous_value->getattr(obj, '_setattr_tracking', True)
keras.saving.saved_model.utils.SaveOptionsContext(self)
keras.saving.saved_model.utils.SaveOptionsContext.__init__(self)
keras.saving.saved_model.utils.call_is_method(call_fn)
keras.saving.saved_model.utils.get_training_arg(index,args,kwargs)
keras.saving.saved_model.utils.get_training_arg_index(call_fn)
keras.saving.saved_model.utils.keras_option_scope(save_traces)
keras.saving.saved_model.utils.layer_uses_training_bool(layer)
keras.saving.saved_model.utils.list_all_layers(obj)
keras.saving.saved_model.utils.list_all_layers_and_sublayers(obj)
keras.saving.saved_model.utils.maybe_add_training_arg(original_call,wrapped_call,expects_training_arg,default_training_value)
keras.saving.saved_model.utils.no_automatic_dependency_tracking_scope(obj)
keras.saving.saved_model.utils.remove_training_arg(index,args,kwargs)
keras.saving.saved_model.utils.set_training_arg(training,index,args,kwargs)
keras.saving.saved_model.utils.should_save_traces()
keras.saving.saved_model.utils.use_wrapped_call(layer,call_fn,default_training_value=None,return_method=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/load.py----------------------------------------
A:keras.saving.saved_model.load.models_lib->LazyLoader('models_lib', globals(), 'keras.models')
A:keras.saving.saved_model.load.base_layer->LazyLoader('base_layer', globals(), 'keras.engine.base_layer')
A:keras.saving.saved_model.load.layers_module->LazyLoader('layers_module', globals(), 'keras.layers')
A:keras.saving.saved_model.load.input_layer->LazyLoader('input_layer', globals(), 'keras.engine.input_layer')
A:keras.saving.saved_model.load.functional_lib->LazyLoader('functional_lib', globals(), 'keras.engine.functional')
A:keras.saving.saved_model.load.training_lib->LazyLoader('training_lib', globals(), 'keras.engine.training')
A:keras.saving.saved_model.load.training_lib_v1->LazyLoader('training_lib_v1', globals(), 'keras.engine.training_v1')
A:keras.saving.saved_model.load.metrics->LazyLoader('metrics', globals(), 'keras.metrics')
A:keras.saving.saved_model.load.base_rnn->LazyLoader('base_rnn', globals(), 'keras.layers.rnn.base_rnn')
A:keras.saving.saved_model.load.PUBLIC_ATTRIBUTES->keras.saving.saved_model.serialized_attributes.CommonEndpoints.all_functions.union(CommonEndpoints.all_checkpointable_objects)
A:keras.saving.saved_model.load.metadata->keras.saving.saved_model.json_utils.decode(metadata)
A:keras.saving.saved_model.load.path_to_metadata_pb->tensorflow.compat.v2.io.gfile.join(path, constants.SAVED_METADATA_PATH)
A:keras.saving.saved_model.load.file_content->f.read()
A:keras.saving.saved_model.load.keras_loader->KerasObjectLoader(metadata, object_graph_def)
A:keras.saving.saved_model.load.loaded->tensorflow.compat.v2.__internal__.saved_model.load_partial(path, nodes_to_load, options=options)
A:keras.saving.saved_model.load.training_config->models_lib.Functional(inputs=[], outputs=[], name=config['name'])._serialized_attributes['metadata'].get('training_config', None)
A:keras.saving.saved_model.load.sess->keras.backend.get_session()
A:keras.saving.saved_model.load.node_metadata->keras.saving.saved_model.json_utils.decode(node.metadata)
A:keras.saving.saved_model.load.save_spec->keras.saving.saved_model.json_utils.decode(node.metadata).get('save_spec')
A:keras.saving.saved_model.load.node.metadata->keras.saving.saved_model.json_utils.Encoder().encode(node_metadata)
A:keras.saving.saved_model.load.node_paths->_generate_object_paths(object_graph_def)
A:keras.saving.saved_model.load.current_node->nodes_to_visit.pop()
A:keras.saving.saved_model.load.paths[reference.node_id]->'{}.{}'.format(current_path, reference.local_name)
A:keras.saving.saved_model.load.self._traversed_nodes_from_config->set()
A:keras.saving.saved_model.load.dependencies->list(node._self_unconditional_dependency_names)
A:keras.saving.saved_model.load.obj_child->metrics.deserialize(generic_utils.serialize_keras_class_and_config(class_name, config))._lookup_dependency(reference.local_name)
A:keras.saving.saved_model.load.metric_list_node_id->self._search_for_child_node(node_id, [constants.KERAS_ATTR, 'layer_metrics'])
A:keras.saving.saved_model.load.metric->obj_metrics.get(reference.local_name)
A:keras.saving.saved_model.load.metric_path->'{}.layer_metrics.{}'.format(constants.KERAS_ATTR, reference.local_name)
A:keras.saving.saved_model.load.setter->self._config_node_setter(_revive_setter)
A:keras.saving.saved_model.load.child_path->'{}.{}'.format(parent_path, child_name)
A:keras.saving.saved_model.load.self.loaded_nodes[node_metadata.node_id]->self._load_layer(node_metadata.node_id, node_metadata.identifier, node_metadata.metadata)
A:keras.saving.saved_model.load.config->keras.saving.saved_model.json_utils.decode(metadata).get('config')
A:keras.saving.saved_model.load.child_nodes->self._get_child_layer_node_ids(node_id)
A:keras.saving.saved_model.load.(obj, setter)->revive_custom_object(identifier, metadata)
A:keras.saving.saved_model.load.obj->LazyLoader('metrics', globals(), 'keras.metrics').deserialize(generic_utils.serialize_keras_class_and_config(class_name, config))
A:keras.saving.saved_model.load.class_name->tensorflow.compat.v2.compat.as_str(metadata['class_name'])
A:keras.saving.saved_model.load.model->LazyLoader('models_lib', globals(), 'keras.models').Functional(inputs=[], outputs=[], name=config['name'])
A:keras.saving.saved_model.load.layers->self._get_child_layer_node_ids(node_id)
A:keras.saving.saved_model.load.shared_object_id->keras.saving.saved_model.json_utils.decode(metadata).get('shared_object_id')
A:keras.saving.saved_model.load.must_restore_from_config->keras.saving.saved_model.json_utils.decode(metadata).get('must_restore_from_config')
A:keras.saving.saved_model.load.builtin_layer->LazyLoader('layers_module', globals(), 'keras.layers').get_builtin_layer(class_name)
A:keras.saving.saved_model.load.full_save_spec->keras.saving.saved_model.json_utils.decode(metadata).get('full_save_spec')
A:keras.saving.saved_model.load.inputs_spec->args_spec.pop(0)
A:keras.saving.saved_model.load.build_input_shape->self._infer_inputs(node_id, convert_to_shapes=True)
A:keras.saving.saved_model.load.built->self._try_build_layer(obj, node_id, build_input_shape)
A:keras.saving.saved_model.load.all_initialized_models->set()
A:keras.saving.saved_model.load.model_id->self._models_to_reconstruct.pop(0)
A:keras.saving.saved_model.load.input_specs->self._infer_inputs(first_layer)
A:keras.saving.saved_model.load.input_shapes->self._infer_inputs(first_layer, convert_to_shapes=True)
A:keras.saving.saved_model.load.(inputs, outputs, created_layers)->LazyLoader('functional_lib', globals(), 'keras.engine.functional').reconstruct_from_config(config, created_layers={layer.name: layer for layer in layers})
A:keras.saving.saved_model.load.pattern->re.compile('layer-(\\d+)')
A:keras.saving.saved_model.load.m->re.compile('layer-(\\d+)').match(child.local_name)
A:keras.saving.saved_model.load.layer_n->int(m.group(1))
A:keras.saving.saved_model.load.num_layers->max(layer_n + 1, num_layers)
A:keras.saving.saved_model.load.child->child_layers.get(n)
A:keras.saving.saved_model.load.call_fn_id->self._search_for_child_node(layer_node_id, ['call_and_return_all_conditional_losses'])
A:keras.saving.saved_model.load.structured_input_signature->tensorflow.compat.v2.__internal__.saved_model.decode_proto(call_fn_proto.canonicalized_input_signature)
A:keras.saving.saved_model.load.layer_call->getattr(_get_keras_attr(layer), 'call_and_return_conditional_losses', None)
A:keras.saving.saved_model.load.layer.call->types.MethodType(_unable_to_call_layer_due_to_serialization_issue, layer)
A:keras.saving.saved_model.load.(args, kwargs)->infer_inputs_from_restored_call_function(call_fn)
A:keras.saving.saved_model.load.args->list(args)
A:keras.saving.saved_model.load.inputs->list(args).pop(0)
A:keras.saving.saved_model.load.layer.states->getattr(_get_keras_attr(layer), 'states', None)
A:keras.saving.saved_model.load.metric.update_state->types.MethodType(metrics_utils.update_state_wrapper(metric.keras_api.update_state), metric)
A:keras.saving.saved_model.load.losses->layer._serialized_attributes.get('regularization_losses', [])
A:keras.saving.saved_model.load.activity_regularizer->getattr(_get_keras_attr(layer), 'activity_regularizer_fn', None)
A:keras.saving.saved_model.load.parent_classes->revived_classes.get(identifier, None)
A:keras.saving.saved_model.load.revived_cls->type(tf.compat.as_str(metadata['class_name']), parent_classes, {})
A:keras.saving.saved_model.load.metrics_list->getattr(_get_keras_attr(layer), 'layer_metrics', {})
A:keras.saving.saved_model.load.init_args->dict(name=metadata['name'], dtype=metadata['dtype'], sparse=metadata['sparse'], ragged=metadata['ragged'], batch_input_shape=metadata['batch_input_shape'])
A:keras.saving.saved_model.load.revived_obj->cls(name=metadata['name'])
A:keras.saving.saved_model.load.revived_obj.input_spec->recursively_deserialize_keras_object(metadata['input_spec'], module_objects={'InputSpec': input_spec.InputSpec})
A:keras.saving.saved_model.load.revived_obj.activity_regularizer->keras.regularizers.deserialize(metadata['activity_regularizer'])
A:keras.saving.saved_model.load.result->x._without_tensor_names().most_specific_common_supertype([y._without_tensor_names()])
A:keras.saving.saved_model.load.spec->tensorflow.compat.v2.nest.map_structure(common_spec, spec, spec2)
keras.saving.saved_model.load.KerasObjectLoader(self,metadata,object_graph_def)
keras.saving.saved_model.load.KerasObjectLoader.__init__(self,metadata,object_graph_def)
keras.saving.saved_model.load.KerasObjectLoader._add_children_recreated_from_config(self,obj,proto,node_id)
keras.saving.saved_model.load.KerasObjectLoader._config_node_setter(self,setter)
keras.saving.saved_model.load.KerasObjectLoader._get_child_layer_node_ids(self,node_id)
keras.saving.saved_model.load.KerasObjectLoader._infer_inputs(self,layer_node_id,convert_to_shapes=False)
keras.saving.saved_model.load.KerasObjectLoader._load_layer(self,node_id,identifier,metadata)
keras.saving.saved_model.load.KerasObjectLoader._reconstruct_all_models(self)
keras.saving.saved_model.load.KerasObjectLoader._reconstruct_model(self,model_id,model,layers)
keras.saving.saved_model.load.KerasObjectLoader._revive_from_config(self,identifier,metadata,node_id)
keras.saving.saved_model.load.KerasObjectLoader._revive_graph_network(self,identifier,metadata,node_id)
keras.saving.saved_model.load.KerasObjectLoader._revive_layer_or_model_from_config(self,metadata,node_id)
keras.saving.saved_model.load.KerasObjectLoader._revive_metric_from_config(self,metadata)
keras.saving.saved_model.load.KerasObjectLoader._search_for_child_node(self,parent_id,path_to_child)
keras.saving.saved_model.load.KerasObjectLoader._try_build_layer(self,obj,node_id,build_input_shape)
keras.saving.saved_model.load.KerasObjectLoader._unblock_model_reconstruction(self,layer_id,layer)
keras.saving.saved_model.load.KerasObjectLoader.del_tracking(self)
keras.saving.saved_model.load.KerasObjectLoader.finalize_objects(self)
keras.saving.saved_model.load.KerasObjectLoader.get_path(self,node_id)
keras.saving.saved_model.load.KerasObjectLoader.load_layers(self,compile=True)
keras.saving.saved_model.load.RevivedInputLayer
keras.saving.saved_model.load.RevivedInputLayer._init_from_metadata(cls,metadata)
keras.saving.saved_model.load.RevivedInputLayer.get_config(self)
keras.saving.saved_model.load.RevivedLayer
keras.saving.saved_model.load.RevivedLayer._init_from_metadata(cls,metadata)
keras.saving.saved_model.load.RevivedLayer.get_config(self)
keras.saving.saved_model.load.RevivedLayer.keras_api(self)
keras.saving.saved_model.load.RevivedNetwork(RevivedLayer)
keras.saving.saved_model.load.RevivedNetwork._init_from_metadata(cls,metadata)
keras.saving.saved_model.load._finalize_config_layers(layers)
keras.saving.saved_model.load._finalize_metric(metric)
keras.saving.saved_model.load._finalize_saved_model_layers(layers)
keras.saving.saved_model.load._generate_object_paths(object_graph_def)
keras.saving.saved_model.load._get_keras_attr(layer)
keras.saving.saved_model.load._is_graph_network(layer)
keras.saving.saved_model.load._maybe_add_serialized_attributes(layer,metadata)
keras.saving.saved_model.load._read_legacy_metadata(object_graph_def,metadata,path)
keras.saving.saved_model.load._restore_layer_activation_loss(layer)
keras.saving.saved_model.load._restore_layer_metrics(layer)
keras.saving.saved_model.load._restore_layer_unconditional_losses(layer)
keras.saving.saved_model.load._revive_setter(layer,name,value)
keras.saving.saved_model.load._set_network_attributes_from_metadata(revived_obj)
keras.saving.saved_model.load._unable_to_call_layer_due_to_serialization_issue(layer,*unused_args,**unused_kwargs)
keras.saving.saved_model.load._update_to_current_version(metadata)
keras.saving.saved_model.load.infer_inputs_from_restored_call_function(fn)
keras.saving.saved_model.load.load(path,compile=True,options=None)
keras.saving.saved_model.load.recursively_deserialize_keras_object(config,module_objects=None)
keras.saving.saved_model.load.revive_custom_object(identifier,metadata)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/load_context.py----------------------------------------
A:keras.saving.saved_model.load_context._load_context->LoadContext()
keras.saving.saved_model.load_context.LoadContext(self)
keras.saving.saved_model.load_context.LoadContext.__init__(self)
keras.saving.saved_model.load_context.LoadContext.clear_load_options(self)
keras.saving.saved_model.load_context.LoadContext.in_load_context(self)
keras.saving.saved_model.load_context.LoadContext.load_options(self)
keras.saving.saved_model.load_context.LoadContext.set_load_options(self,load_options)
keras.saving.saved_model.load_context.get_load_options()
keras.saving.saved_model.load_context.in_load_context()
keras.saving.saved_model.load_context.load_context(load_options)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/serialized_attributes.py----------------------------------------
A:keras.saving.saved_model.serialized_attributes.base_layer->LazyLoader('base_layer', globals(), 'keras.engine.base_layer')
A:keras.saving.saved_model.serialized_attributes.training_lib->LazyLoader('training_lib', globals(), 'keras.engine.training')
A:keras.saving.saved_model.serialized_attributes.metrics->LazyLoader('metrics', globals(), 'keras.metrics')
A:keras.saving.saved_model.serialized_attributes.base_rnn->LazyLoader('base_rnn', globals(), 'keras.layers.rnn.base_rnn')
A:keras.saving.saved_model.serialized_attributes.self._keras_trackable->tensorflow.compat.v2.__internal__.tracking.AutoTrackable()
keras.saving.saved_model.serialized_attributes.CommonEndpoints(SerializedAttributes.with_attributes('CommonEndpoints',checkpointable_objects=['variables','trainable_variables','regularization_losses'],functions=['__call__','call_and_return_all_conditional_losses','_default_save_signature']))
keras.saving.saved_model.serialized_attributes.LayerAttributes(SerializedAttributes.with_attributes('LayerAttributes',checkpointable_objects=['non_trainable_variables','layers','metrics','layer_regularization_losses','layer_metrics'],functions=['call_and_return_conditional_losses','activity_regularizer_fn'],copy_from=[CommonEndpoints]))
keras.saving.saved_model.serialized_attributes.MetricAttributes(SerializedAttributes.with_attributes('MetricAttributes',checkpointable_objects=['variables'],functions=[]))
keras.saving.saved_model.serialized_attributes.ModelAttributes(SerializedAttributes.with_attributes('ModelAttributes',copy_from=[LayerAttributes]))
keras.saving.saved_model.serialized_attributes.RNNAttributes(SerializedAttributes.with_attributes('RNNAttributes',checkpointable_objects=['states'],copy_from=[LayerAttributes]))
keras.saving.saved_model.serialized_attributes.SerializedAttributes(self)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.__init__(self)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.checkpointable_objects(self)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.functions(self)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.functions_to_serialize(self)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.new(obj)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.objects_to_serialize(self)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.set_and_validate_functions(self,function_dict)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.set_and_validate_objects(self,object_dict)
keras.saving.saved_model.serialized_attributes.SerializedAttributes.with_attributes(name,checkpointable_objects=None,functions=None,copy_from=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/json_utils.py----------------------------------------
A:keras.saving.saved_model.json_utils.serialized->keras.utils.generic_utils.serialize_keras_object(obj)
A:keras.saving.saved_model.json_utils.type_spec_name->tensorflow.python.framework.type_spec.get_name(type(obj))
A:keras.saving.saved_model.json_utils.spec->tensorflow.compat.v2.type_spec_from_value(obj)
keras.saving.saved_model.json_utils.Encoder(json.JSONEncoder)
keras.saving.saved_model.json_utils.Encoder.default(self,obj)
keras.saving.saved_model.json_utils.Encoder.encode(self,obj)
keras.saving.saved_model.json_utils._decode_helper(obj,deserialize=False,module_objects=None,custom_objects=None)
keras.saving.saved_model.json_utils._encode_tuple(x)
keras.saving.saved_model.json_utils.decode(json_string)
keras.saving.saved_model.json_utils.decode_and_deserialize(json_string,module_objects=None,custom_objects=None)
keras.saving.saved_model.json_utils.get_json_type(obj)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/base_serialization.py----------------------------------------
A:keras.saving.saved_model.base_serialization.children->self.objects_to_serialize(serialization_cache)
keras.saving.saved_model.base_serialization.SavedModelSaver(self,obj)
keras.saving.saved_model.base_serialization.SavedModelSaver.__init__(self,obj)
keras.saving.saved_model.base_serialization.SavedModelSaver.functions_to_serialize(self,serialization_cache)
keras.saving.saved_model.base_serialization.SavedModelSaver.object_identifier(self)
keras.saving.saved_model.base_serialization.SavedModelSaver.objects_to_serialize(self,serialization_cache)
keras.saving.saved_model.base_serialization.SavedModelSaver.python_properties(self)
keras.saving.saved_model.base_serialization.SavedModelSaver.trackable_children(self,serialization_cache)
keras.saving.saved_model.base_serialization.SavedModelSaver.tracking_metadata(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/constants.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/layer_serialization.py----------------------------------------
A:keras.saving.saved_model.layer_serialization.metadata->self._python_properties_internal()
A:keras.saving.saved_model.layer_serialization.metadata['input_spec']->tensorflow.compat.v2.nest.map_structure(lambda x: generic_utils.serialize_keras_object(x) if x else None, self.obj.input_spec)
A:keras.saving.saved_model.layer_serialization.metadata['activity_regularizer']->keras.utils.generic_utils.serialize_keras_object(self.obj.activity_regularizer)
A:keras.saving.saved_model.layer_serialization.keras_cache->serialization_cache.setdefault(constants.KERAS_CACHE_KEY, {})
A:keras.saving.saved_model.layer_serialization.serialized_attrkeras_cache[self.obj]->keras.saving.saved_model.serialized_attributes.SerializedAttributes.new(self.obj)
A:keras.saving.saved_model.layer_serialization.(object_dict, function_dict)->self._get_serialized_attributes_internal(serialization_cache)
A:keras.saving.saved_model.layer_serialization.objects->keras.saving.saved_model.save_impl.wrap_layer_objects(self.obj, serialization_cache)
A:keras.saving.saved_model.layer_serialization.functions->keras.saving.saved_model.save_impl.wrap_layer_functions(self.obj, serialization_cache)
A:keras.saving.saved_model.layer_serialization.(objects, functions)->super(RNNSavedModelSaver, self)._get_serialized_attributes_internal(serialization_cache)
A:keras.saving.saved_model.layer_serialization.states->tensorflow.compat.v2.__internal__.tracking.wrap(list(states))
keras.saving.saved_model.layer_serialization.InputLayerSavedModelSaver(base_serialization.SavedModelSaver)
keras.saving.saved_model.layer_serialization.InputLayerSavedModelSaver.functions_to_serialize(self,serialization_cache)
keras.saving.saved_model.layer_serialization.InputLayerSavedModelSaver.object_identifier(self)
keras.saving.saved_model.layer_serialization.InputLayerSavedModelSaver.objects_to_serialize(self,serialization_cache)
keras.saving.saved_model.layer_serialization.InputLayerSavedModelSaver.python_properties(self)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver(base_serialization.SavedModelSaver)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver._get_serialized_attributes(self,serialization_cache)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver._get_serialized_attributes_internal(self,serialization_cache)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver._python_properties_internal(self)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver.functions_to_serialize(self,serialization_cache)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver.object_identifier(self)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver.objects_to_serialize(self,serialization_cache)
keras.saving.saved_model.layer_serialization.LayerSavedModelSaver.python_properties(self)
keras.saving.saved_model.layer_serialization.RNNSavedModelSaver(LayerSavedModelSaver)
keras.saving.saved_model.layer_serialization.RNNSavedModelSaver._get_serialized_attributes_internal(self,serialization_cache)
keras.saving.saved_model.layer_serialization.RNNSavedModelSaver.object_identifier(self)
keras.saving.saved_model.layer_serialization.VocabularySavedModelSaver(LayerSavedModelSaver)
keras.saving.saved_model.layer_serialization.VocabularySavedModelSaver.python_properties(self)
keras.saving.saved_model.layer_serialization.get_serialized(obj)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/save.py----------------------------------------
A:keras.saving.saved_model.save.base_layer->LazyLoader('base_layer', globals(), 'keras.engine.base_layer')
A:keras.saving.saved_model.save.training_lib->LazyLoader('training_lib', globals(), 'keras.engine.training')
A:keras.saving.saved_model.save.proceed->ask_to_proceed_with_overwrite(filepath)
A:keras.saving.saved_model.save.(saved_nodes, node_paths)->tensorflow.python.saved_model.save.save_and_return_nodes(model, filepath, signatures, options)
A:keras.saving.saved_model.save.metadata->keras.protobuf.saved_metadata_pb2.SavedMetadata()
A:keras.saving.saved_model.save.node_path->'root.{}'.format('.'.join([ref.name for ref in path]))
A:keras.saving.saved_model.save.builtin_layer->keras.layers.serialization.get_builtin_layer(class_name)
keras.saving.saved_model.save.generate_keras_metadata(saved_nodes,node_paths)
keras.saving.saved_model.save.save(model,filepath,overwrite,include_optimizer,signatures=None,options=None,save_traces=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/network_serialization.py----------------------------------------
keras.saving.saved_model.network_serialization.NetworkSavedModelSaver(model_serialization.ModelSavedModelSaver)
keras.saving.saved_model.network_serialization.NetworkSavedModelSaver.object_identifier(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/model_serialization.py----------------------------------------
A:keras.saving.saved_model.model_serialization.metadata->super(ModelSavedModelSaver, self)._python_properties_internal()
A:keras.saving.saved_model.model_serialization.spec->self.obj.save_spec(dynamic_batch=False)
A:keras.saving.saved_model.model_serialization.default_signature->keras.saving.saved_model.save_impl.default_save_signature(self.obj)
A:keras.saving.saved_model.model_serialization.(objects, functions)->super(ModelSavedModelSaver, self)._get_serialized_attributes_internal(serialization_cache)
keras.saving.saved_model.model_serialization.ModelSavedModelSaver(layer_serialization.LayerSavedModelSaver)
keras.saving.saved_model.model_serialization.ModelSavedModelSaver._get_serialized_attributes_internal(self,serialization_cache)
keras.saving.saved_model.model_serialization.ModelSavedModelSaver._python_properties_internal(self)
keras.saving.saved_model.model_serialization.ModelSavedModelSaver.object_identifier(self)
keras.saving.saved_model.model_serialization.SequentialSavedModelSaver(ModelSavedModelSaver)
keras.saving.saved_model.model_serialization.SequentialSavedModelSaver.object_identifier(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/saving/saved_model/metric_serialization.py----------------------------------------
A:keras.saving.saved_model.metric_serialization.metadata->dict(class_name=generic_utils.get_registered_name(type(self.obj)), name=self.obj.name, dtype=self.obj.dtype)
keras.saving.saved_model.metric_serialization.MetricSavedModelSaver(layer_serialization.LayerSavedModelSaver)
keras.saving.saved_model.metric_serialization.MetricSavedModelSaver._get_serialized_attributes_internal(self,unused_serialization_cache)
keras.saving.saved_model.metric_serialization.MetricSavedModelSaver._python_properties_internal(self)
keras.saving.saved_model.metric_serialization.MetricSavedModelSaver.object_identifier(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/cifar.py----------------------------------------
A:keras.datasets.cifar.d->_pickle.load(f, encoding='bytes')
A:keras.datasets.cifar.data->data.reshape(data.shape[0], 3, 32, 32).reshape(data.shape[0], 3, 32, 32)
keras.datasets.cifar.load_batch(fpath,label_key='labels')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/reuters.py----------------------------------------
A:keras.datasets.reuters.num_words->max((max(x) for x in xs))
A:keras.datasets.reuters.path->get_file(path, origin=origin_folder + 'reuters_word_index.json', file_hash='4d44cc38712099c9e383dc6e5f11a921')
A:keras.datasets.reuters.rng->numpy.random.RandomState(seed)
A:keras.datasets.reuters.indices->numpy.arange(len(xs))
A:keras.datasets.reuters.(xs, labels)->_remove_long_seq(maxlen, xs, labels)
A:keras.datasets.reuters.idx->int(len(xs) * (1 - test_split))
keras.datasets.reuters.get_word_index(path='reuters_word_index.json')
keras.datasets.reuters.load_data(path='reuters.npz',num_words=None,skip_top=0,maxlen=None,test_split=0.2,seed=113,start_char=1,oov_char=2,index_from=3,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/fashion_mnist.py----------------------------------------
A:keras.datasets.fashion_mnist.dirname->os.path.join('datasets', 'fashion-mnist')
A:keras.datasets.fashion_mnist.y_train->numpy.frombuffer(lbpath.read(), np.uint8, offset=8)
A:keras.datasets.fashion_mnist.x_train->numpy.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(y_train), 28, 28)
A:keras.datasets.fashion_mnist.y_test->numpy.frombuffer(lbpath.read(), np.uint8, offset=8)
A:keras.datasets.fashion_mnist.x_test->numpy.frombuffer(imgpath.read(), np.uint8, offset=16).reshape(len(y_test), 28, 28)
keras.datasets.fashion_mnist.load_data()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/cifar100.py----------------------------------------
A:keras.datasets.cifar100.path->get_file(dirname, origin=origin, untar=True, file_hash='85cd44d02ba6437773c5bbd22e183051d648de2e7d6b014e1ef29b855ba677a7')
A:keras.datasets.cifar100.fpath->os.path.join(path, 'test')
A:keras.datasets.cifar100.(x_train, y_train)->load_batch(fpath, label_key=label_mode + '_labels')
A:keras.datasets.cifar100.(x_test, y_test)->load_batch(fpath, label_key=label_mode + '_labels')
A:keras.datasets.cifar100.y_train->numpy.reshape(y_train, (len(y_train), 1))
A:keras.datasets.cifar100.y_test->numpy.reshape(y_test, (len(y_test), 1))
A:keras.datasets.cifar100.x_train->x_train.transpose(0, 2, 3, 1).transpose(0, 2, 3, 1)
A:keras.datasets.cifar100.x_test->x_test.transpose(0, 2, 3, 1).transpose(0, 2, 3, 1)
keras.datasets.cifar100.load_data(label_mode='fine')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/mnist.py----------------------------------------
A:keras.datasets.mnist.path->get_file(path, origin=origin_folder + 'mnist.npz', file_hash='731c5ac602752760c8e48fbffcf8c3b850d9dc2a2aedcf2cc48468fc17b673d1')
keras.datasets.mnist.load_data(path='mnist.npz')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/boston_housing.py----------------------------------------
A:keras.datasets.boston_housing.path->get_file(path, origin=origin_folder + 'boston_housing.npz', file_hash='f553886a1f8d56431e820c5b82552d9d95cfcb96d1e678153f8839538947dff5')
A:keras.datasets.boston_housing.rng->numpy.random.RandomState(seed)
A:keras.datasets.boston_housing.indices->numpy.arange(len(x))
A:keras.datasets.boston_housing.x_train->numpy.array(x[:int(len(x) * (1 - test_split))])
A:keras.datasets.boston_housing.y_train->numpy.array(y[:int(len(x) * (1 - test_split))])
A:keras.datasets.boston_housing.x_test->numpy.array(x[int(len(x) * (1 - test_split)):])
A:keras.datasets.boston_housing.y_test->numpy.array(y[int(len(x) * (1 - test_split)):])
keras.datasets.boston_housing.load_data(path='boston_housing.npz',test_split=0.2,seed=113)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/imdb.py----------------------------------------
A:keras.datasets.imdb.num_words->max((max(x) for x in xs))
A:keras.datasets.imdb.path->get_file(path, origin=origin_folder + 'imdb_word_index.json', file_hash='bfafd718b763782e994055a2d397834f')
A:keras.datasets.imdb.rng->numpy.random.RandomState(seed)
A:keras.datasets.imdb.indices->numpy.arange(len(x_test))
A:keras.datasets.imdb.(x_train, labels_train)->_remove_long_seq(maxlen, x_train, labels_train)
A:keras.datasets.imdb.(x_test, labels_test)->_remove_long_seq(maxlen, x_test, labels_test)
A:keras.datasets.imdb.labels->numpy.concatenate([labels_train, labels_test])
A:keras.datasets.imdb.idx->len(x_train)
keras.datasets.imdb.get_word_index(path='imdb_word_index.json')
keras.datasets.imdb.load_data(path='imdb.npz',num_words=None,skip_top=0,maxlen=None,seed=113,start_char=1,oov_char=2,index_from=3,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/datasets/cifar10.py----------------------------------------
A:keras.datasets.cifar10.path->get_file(dirname, origin=origin, untar=True, file_hash='6d958be074577803d12ecdefd02955f39262c83c16fe9348329d7fe0b5c001ce')
A:keras.datasets.cifar10.x_train->x_train.transpose(0, 2, 3, 1).transpose(0, 2, 3, 1)
A:keras.datasets.cifar10.y_train->numpy.reshape(y_train, (len(y_train), 1))
A:keras.datasets.cifar10.fpath->os.path.join(path, 'test_batch')
A:keras.datasets.cifar10.(x_train[(i - 1) * 10000:i * 10000, :, :, :], y_train[(i - 1) * 10000:i * 10000])->load_batch(fpath)
A:keras.datasets.cifar10.(x_test, y_test)->load_batch(fpath)
A:keras.datasets.cifar10.y_test->y_test.astype(y_train.dtype).astype(y_train.dtype)
A:keras.datasets.cifar10.x_test->x_test.astype(x_train.dtype).astype(x_train.dtype)
keras.datasets.cifar10.load_data()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/metrics/__init__.py----------------------------------------
keras.metrics.__init__.deserialize(config,custom_objects=None)
keras.metrics.__init__.get(identifier)
keras.metrics.__init__.serialize(metric)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/metrics/metrics.py----------------------------------------
A:keras.metrics.metrics.normalizer->tensorflow.compat.v2.cast(normalizer, self._dtype)
A:keras.metrics.metrics.y_true->tensorflow.compat.v2.linalg.l2_normalize(y_true, axis=axis)
A:keras.metrics.metrics.y_pred->tensorflow.compat.v2.linalg.l2_normalize(y_pred, axis=axis)
A:keras.metrics.metrics.([y_pred, y_true], sample_weight)->keras.utils.metrics_utils.ragged_assert_compatible_and_get_flat_values([y_pred, y_true], sample_weight)
A:keras.metrics.metrics.(y_pred, y_true)->keras.utils.losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)
A:keras.metrics.metrics.(y_pred, self.normalizer)->keras.utils.losses_utils.remove_squeezable_dimensions(y_pred, self.normalizer)
A:keras.metrics.metrics.relative_errors->tensorflow.compat.v2.math.divide_no_nan(tf.abs(y_true - y_pred), self.normalizer)
A:keras.metrics.metrics.base_config->super(IoU, self).get_config()
A:keras.metrics.metrics.self.thresholds->keras.utils.metrics_utils.parse_init_thresholds(thresholds, default_threshold=default_threshold)
A:keras.metrics.metrics.self._thresholds_distributed_evenly->keras.utils.metrics_utils.is_evenly_distributed_thresholds(np.array([0.0] + thresholds + [1.0]))
A:keras.metrics.metrics.self.accumulator->self.add_weight('accumulator', shape=(len(self.thresholds),), initializer='zeros')
A:keras.metrics.metrics.self.true_positives->self.add_weight('true_positives', shape=variable_shape, initializer='zeros')
A:keras.metrics.metrics.self.false_positives->self.add_weight('false_positives', shape=variable_shape, initializer='zeros')
A:keras.metrics.metrics.result->tensorflow.compat.v2.math.divide_no_nan(self.true_positives, tf.math.add(self.true_positives, self.false_negatives))
A:keras.metrics.metrics.num_thresholds->len(self.thresholds)
A:keras.metrics.metrics.self.false_negatives->self.add_weight('false_negatives', shape=variable_shape, initializer='zeros')
A:keras.metrics.metrics.self.true_negatives->self.add_weight('true_negatives', shape=variable_shape, initializer='zeros')
A:keras.metrics.metrics.feasible->tensorflow.compat.v2.where(predicate(constrained, self.value))
A:keras.metrics.metrics.feasible_exists->tensorflow.compat.v2.greater(tf.size(feasible), 0)
A:keras.metrics.metrics.max_dependent->tensorflow.compat.v2.reduce_max(tf.gather(dependent, feasible))
A:keras.metrics.metrics.specificities->tensorflow.compat.v2.math.divide_no_nan(self.true_negatives, tf.math.add(self.true_negatives, self.false_positives))
A:keras.metrics.metrics.sensitivities->tensorflow.compat.v2.math.divide_no_nan(self.true_positives, tf.math.add(self.true_positives, self.false_negatives))
A:keras.metrics.metrics.recalls->tensorflow.compat.v2.math.divide_no_nan(self.true_positives, tf.math.add(self.true_positives, self.false_negatives))
A:keras.metrics.metrics.precisions->tensorflow.compat.v2.math.divide_no_nan(self.true_positives, tf.math.add(self.true_positives, self.false_positives))
A:keras.metrics.metrics.thresholds->sorted(thresholds)
A:keras.metrics.metrics.self._thresholds->numpy.array([0.0 - backend.epsilon()] + thresholds + [1.0 + backend.epsilon()])
A:keras.metrics.metrics.self.curve->keras.utils.metrics_utils.AUCCurve.from_str(curve)
A:keras.metrics.metrics.self.summation_method->keras.utils.metrics_utils.AUCSummationMethod.from_str(summation_method)
A:keras.metrics.metrics.label_weights->keras.backend.eval(self.label_weights)
A:keras.metrics.metrics.shape->tensorflow.compat.v2.TensorShape([None, num_labels])
A:keras.metrics.metrics.variable_shape->tensorflow.compat.v2.TensorShape([self.num_thresholds])
A:keras.metrics.metrics.p->tensorflow.compat.v2.math.add(self.true_positives, self.false_positives)
A:keras.metrics.metrics.prec_slope->tensorflow.compat.v2.math.divide_no_nan(dtp, tf.maximum(dp, 0), name='prec_slope')
A:keras.metrics.metrics.safe_p_ratio->tensorflow.compat.v2.where(tf.logical_and(p[:self.num_thresholds - 1] > 0, p[1:] > 0), tf.math.divide_no_nan(p[:self.num_thresholds - 1], tf.maximum(p[1:], 0), name='recall_relative_ratio'), tf.ones_like(p[1:]))
A:keras.metrics.metrics.pr_auc_increment->tensorflow.compat.v2.math.divide_no_nan(prec_slope * (dtp + intercept * tf.math.log(safe_p_ratio)), tf.maximum(self.true_positives[1:] + self.false_negatives[1:], 0), name='pr_auc_increment')
A:keras.metrics.metrics.by_label_auc->tensorflow.compat.v2.reduce_sum(riemann_terms, name=self.name + '_by_label', axis=0)
A:keras.metrics.metrics.recall->tensorflow.compat.v2.math.divide_no_nan(self.true_positives, tf.math.add(self.true_positives, self.false_negatives))
A:keras.metrics.metrics.fp_rate->tensorflow.compat.v2.math.divide_no_nan(self.false_positives, tf.math.add(self.false_positives, self.true_negatives))
A:keras.metrics.metrics.precision->tensorflow.compat.v2.math.divide_no_nan(self.true_positives, tf.math.add(self.true_positives, self.false_positives))
A:keras.metrics.metrics.heights->tensorflow.compat.v2.maximum(y[:self.num_thresholds - 1], y[1:])
A:keras.metrics.metrics.riemann_terms->tensorflow.compat.v2.multiply(x[:self.num_thresholds - 1] - x[1:], heights)
A:keras.metrics.metrics.error_sq->tensorflow.compat.v2.math.squared_difference(y_pred, y_true)
A:keras.metrics.metrics.self.total_cm->self.add_weight('total_confusion_matrix', shape=(num_classes, num_classes), initializer='zeros')
A:keras.metrics.metrics.sample_weight->tensorflow.compat.v2.reshape(sample_weight, [-1])
A:keras.metrics.metrics.current_cm->tensorflow.compat.v2.math.confusion_matrix(y_true, y_pred, self.num_classes, weights=sample_weight, dtype=self._dtype)
A:keras.metrics.metrics.self.target_class_ids->list(target_class_ids)
A:keras.metrics.metrics.sum_over_row->tensorflow.compat.v2.cast(tf.reduce_sum(self.total_cm, axis=0), dtype=self._dtype)
A:keras.metrics.metrics.sum_over_col->tensorflow.compat.v2.cast(tf.reduce_sum(self.total_cm, axis=1), dtype=self._dtype)
A:keras.metrics.metrics.true_positives->tensorflow.compat.v2.gather(true_positives, self.target_class_ids)
A:keras.metrics.metrics.denominator->tensorflow.compat.v2.gather(denominator, self.target_class_ids)
A:keras.metrics.metrics.num_valid_entries->tensorflow.compat.v2.reduce_sum(tf.cast(tf.not_equal(denominator, 0), dtype=self._dtype))
A:keras.metrics.metrics.iou->tensorflow.compat.v2.math.divide_no_nan(true_positives, denominator)
A:keras.metrics.metrics.target_class_ids->list(range(num_classes))
A:keras.metrics.metrics.([y_pred, y_true], _)->keras.utils.metrics_utils.ragged_assert_compatible_and_get_flat_values([y_pred, y_true])
A:keras.metrics.metrics.matches->tensorflow.compat.v2.squeeze(matches, [-1])
keras.metrics.AUC(self,num_thresholds=200,curve='ROC',summation_method='interpolation',name=None,dtype=None,thresholds=None,multi_label=False,num_labels=None,label_weights=None,from_logits=False)
keras.metrics.AUC._build(self,shape)
keras.metrics.AUC.get_config(self)
keras.metrics.AUC.interpolate_pr_auc(self)
keras.metrics.AUC.reset_state(self)
keras.metrics.AUC.result(self)
keras.metrics.AUC.thresholds(self)
keras.metrics.AUC.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.Accuracy(self,name='accuracy',dtype=None)
keras.metrics.BinaryAccuracy(self,name='binary_accuracy',dtype=None,threshold=0.5)
keras.metrics.BinaryCrossentropy(self,name='binary_crossentropy',dtype=None,from_logits=False,label_smoothing=0)
keras.metrics.BinaryIoU(self,target_class_ids:Union[List[int],Tuple[int,...]]=(0,1),threshold=0.5,name=None,dtype=None)
keras.metrics.BinaryIoU.get_config(self)
keras.metrics.BinaryIoU.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.CategoricalAccuracy(self,name='categorical_accuracy',dtype=None)
keras.metrics.CategoricalCrossentropy(self,name='categorical_crossentropy',dtype=None,from_logits=False,label_smoothing=0)
keras.metrics.CategoricalHinge(self,name='categorical_hinge',dtype=None)
keras.metrics.CosineSimilarity(self,name='cosine_similarity',dtype=None,axis=-1)
keras.metrics.FalseNegatives(self,thresholds=None,name=None,dtype=None)
keras.metrics.FalsePositives(self,thresholds=None,name=None,dtype=None)
keras.metrics.Hinge(self,name='hinge',dtype=None)
keras.metrics.IoU(self,num_classes:int,target_class_ids:Union[List[int],Tuple[int,...]],name=None,dtype=None)
keras.metrics.IoU.get_config(self)
keras.metrics.IoU.result(self)
keras.metrics.KLDivergence(self,name='kullback_leibler_divergence',dtype=None)
keras.metrics.LogCoshError(self,name='logcosh',dtype=None)
keras.metrics.MeanAbsoluteError(self,name='mean_absolute_error',dtype=None)
keras.metrics.MeanAbsolutePercentageError(self,name='mean_absolute_percentage_error',dtype=None)
keras.metrics.MeanIoU(self,num_classes,name=None,dtype=None)
keras.metrics.MeanIoU.get_config(self)
keras.metrics.MeanRelativeError(self,normalizer,name=None,dtype=None)
keras.metrics.MeanRelativeError.get_config(self)
keras.metrics.MeanRelativeError.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.MeanSquaredError(self,name='mean_squared_error',dtype=None)
keras.metrics.MeanSquaredLogarithmicError(self,name='mean_squared_logarithmic_error',dtype=None)
keras.metrics.OneHotIoU(self,num_classes:int,target_class_ids:Union[List[int],Tuple[int,...]],name=None,dtype=None)
keras.metrics.OneHotIoU.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.OneHotMeanIoU(self,num_classes:int,name=None,dtype=None)
keras.metrics.OneHotMeanIoU.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.Poisson(self,name='poisson',dtype=None)
keras.metrics.Precision(self,thresholds=None,top_k=None,class_id=None,name=None,dtype=None)
keras.metrics.Precision.get_config(self)
keras.metrics.Precision.reset_state(self)
keras.metrics.Precision.result(self)
keras.metrics.Precision.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.PrecisionAtRecall(self,recall,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.PrecisionAtRecall.get_config(self)
keras.metrics.PrecisionAtRecall.result(self)
keras.metrics.Recall(self,thresholds=None,top_k=None,class_id=None,name=None,dtype=None)
keras.metrics.Recall.get_config(self)
keras.metrics.Recall.reset_state(self)
keras.metrics.Recall.result(self)
keras.metrics.Recall.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.RecallAtPrecision(self,precision,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.RecallAtPrecision.get_config(self)
keras.metrics.RecallAtPrecision.result(self)
keras.metrics.RootMeanSquaredError(self,name='root_mean_squared_error',dtype=None)
keras.metrics.RootMeanSquaredError.result(self)
keras.metrics.RootMeanSquaredError.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.SensitivityAtSpecificity(self,specificity,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.SensitivityAtSpecificity.get_config(self)
keras.metrics.SensitivityAtSpecificity.result(self)
keras.metrics.SensitivitySpecificityBase(self,value,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.SensitivitySpecificityBase._find_max_under_constraint(self,constrained,dependent,predicate)
keras.metrics.SensitivitySpecificityBase.get_config(self)
keras.metrics.SensitivitySpecificityBase.reset_state(self)
keras.metrics.SensitivitySpecificityBase.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.SparseCategoricalAccuracy(self,name='sparse_categorical_accuracy',dtype=None)
keras.metrics.SparseCategoricalCrossentropy(self,name='sparse_categorical_crossentropy',dtype=None,from_logits=False,axis=-1)
keras.metrics.SparseTopKCategoricalAccuracy(self,k=5,name='sparse_top_k_categorical_accuracy',dtype=None)
keras.metrics.SpecificityAtSensitivity(self,sensitivity,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.SpecificityAtSensitivity.get_config(self)
keras.metrics.SpecificityAtSensitivity.result(self)
keras.metrics.SquaredHinge(self,name='squared_hinge',dtype=None)
keras.metrics.TopKCategoricalAccuracy(self,k=5,name='top_k_categorical_accuracy',dtype=None)
keras.metrics.TrueNegatives(self,thresholds=None,name=None,dtype=None)
keras.metrics.TruePositives(self,thresholds=None,name=None,dtype=None)
keras.metrics._ConfusionMatrixConditionCount(self,confusion_matrix_cond,thresholds=None,name=None,dtype=None)
keras.metrics._ConfusionMatrixConditionCount.get_config(self)
keras.metrics._ConfusionMatrixConditionCount.reset_state(self)
keras.metrics._ConfusionMatrixConditionCount.result(self)
keras.metrics._ConfusionMatrixConditionCount.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics._IoUBase(self,num_classes,name=None,dtype=None)
keras.metrics._IoUBase.reset_state(self)
keras.metrics._IoUBase.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.accuracy(y_true,y_pred)
keras.metrics.binary_accuracy(y_true,y_pred,threshold=0.5)
keras.metrics.categorical_accuracy(y_true,y_pred)
keras.metrics.cosine_similarity(y_true,y_pred,axis=-1)
keras.metrics.metrics.AUC(self,num_thresholds=200,curve='ROC',summation_method='interpolation',name=None,dtype=None,thresholds=None,multi_label=False,num_labels=None,label_weights=None,from_logits=False)
keras.metrics.metrics.AUC.__init__(self,num_thresholds=200,curve='ROC',summation_method='interpolation',name=None,dtype=None,thresholds=None,multi_label=False,num_labels=None,label_weights=None,from_logits=False)
keras.metrics.metrics.AUC._build(self,shape)
keras.metrics.metrics.AUC.get_config(self)
keras.metrics.metrics.AUC.interpolate_pr_auc(self)
keras.metrics.metrics.AUC.reset_state(self)
keras.metrics.metrics.AUC.result(self)
keras.metrics.metrics.AUC.thresholds(self)
keras.metrics.metrics.AUC.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.Accuracy(self,name='accuracy',dtype=None)
keras.metrics.metrics.Accuracy.__init__(self,name='accuracy',dtype=None)
keras.metrics.metrics.BinaryAccuracy(self,name='binary_accuracy',dtype=None,threshold=0.5)
keras.metrics.metrics.BinaryAccuracy.__init__(self,name='binary_accuracy',dtype=None,threshold=0.5)
keras.metrics.metrics.BinaryCrossentropy(self,name='binary_crossentropy',dtype=None,from_logits=False,label_smoothing=0)
keras.metrics.metrics.BinaryCrossentropy.__init__(self,name='binary_crossentropy',dtype=None,from_logits=False,label_smoothing=0)
keras.metrics.metrics.BinaryIoU(self,target_class_ids:Union[List[int],Tuple[int,...]]=(0,1),threshold=0.5,name=None,dtype=None)
keras.metrics.metrics.BinaryIoU.__init__(self,target_class_ids:Union[List[int],Tuple[int,...]]=(0,1),threshold=0.5,name=None,dtype=None)
keras.metrics.metrics.BinaryIoU.get_config(self)
keras.metrics.metrics.BinaryIoU.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.CategoricalAccuracy(self,name='categorical_accuracy',dtype=None)
keras.metrics.metrics.CategoricalAccuracy.__init__(self,name='categorical_accuracy',dtype=None)
keras.metrics.metrics.CategoricalCrossentropy(self,name='categorical_crossentropy',dtype=None,from_logits=False,label_smoothing=0)
keras.metrics.metrics.CategoricalCrossentropy.__init__(self,name='categorical_crossentropy',dtype=None,from_logits=False,label_smoothing=0)
keras.metrics.metrics.CategoricalHinge(self,name='categorical_hinge',dtype=None)
keras.metrics.metrics.CategoricalHinge.__init__(self,name='categorical_hinge',dtype=None)
keras.metrics.metrics.CosineSimilarity(self,name='cosine_similarity',dtype=None,axis=-1)
keras.metrics.metrics.CosineSimilarity.__init__(self,name='cosine_similarity',dtype=None,axis=-1)
keras.metrics.metrics.FalseNegatives(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.FalseNegatives.__init__(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.FalsePositives(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.FalsePositives.__init__(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.Hinge(self,name='hinge',dtype=None)
keras.metrics.metrics.Hinge.__init__(self,name='hinge',dtype=None)
keras.metrics.metrics.IoU(self,num_classes:int,target_class_ids:Union[List[int],Tuple[int,...]],name=None,dtype=None)
keras.metrics.metrics.IoU.__init__(self,num_classes:int,target_class_ids:Union[List[int],Tuple[int,...]],name=None,dtype=None)
keras.metrics.metrics.IoU.get_config(self)
keras.metrics.metrics.IoU.result(self)
keras.metrics.metrics.KLDivergence(self,name='kullback_leibler_divergence',dtype=None)
keras.metrics.metrics.KLDivergence.__init__(self,name='kullback_leibler_divergence',dtype=None)
keras.metrics.metrics.LogCoshError(self,name='logcosh',dtype=None)
keras.metrics.metrics.LogCoshError.__init__(self,name='logcosh',dtype=None)
keras.metrics.metrics.MeanAbsoluteError(self,name='mean_absolute_error',dtype=None)
keras.metrics.metrics.MeanAbsoluteError.__init__(self,name='mean_absolute_error',dtype=None)
keras.metrics.metrics.MeanAbsolutePercentageError(self,name='mean_absolute_percentage_error',dtype=None)
keras.metrics.metrics.MeanAbsolutePercentageError.__init__(self,name='mean_absolute_percentage_error',dtype=None)
keras.metrics.metrics.MeanIoU(self,num_classes,name=None,dtype=None)
keras.metrics.metrics.MeanIoU.__init__(self,num_classes,name=None,dtype=None)
keras.metrics.metrics.MeanIoU.get_config(self)
keras.metrics.metrics.MeanRelativeError(self,normalizer,name=None,dtype=None)
keras.metrics.metrics.MeanRelativeError.__init__(self,normalizer,name=None,dtype=None)
keras.metrics.metrics.MeanRelativeError.get_config(self)
keras.metrics.metrics.MeanRelativeError.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.MeanSquaredError(self,name='mean_squared_error',dtype=None)
keras.metrics.metrics.MeanSquaredError.__init__(self,name='mean_squared_error',dtype=None)
keras.metrics.metrics.MeanSquaredLogarithmicError(self,name='mean_squared_logarithmic_error',dtype=None)
keras.metrics.metrics.MeanSquaredLogarithmicError.__init__(self,name='mean_squared_logarithmic_error',dtype=None)
keras.metrics.metrics.OneHotIoU(self,num_classes:int,target_class_ids:Union[List[int],Tuple[int,...]],name=None,dtype=None)
keras.metrics.metrics.OneHotIoU.__init__(self,num_classes:int,target_class_ids:Union[List[int],Tuple[int,...]],name=None,dtype=None)
keras.metrics.metrics.OneHotIoU.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.OneHotMeanIoU(self,num_classes:int,name=None,dtype=None)
keras.metrics.metrics.OneHotMeanIoU.__init__(self,num_classes:int,name=None,dtype=None)
keras.metrics.metrics.OneHotMeanIoU.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.Poisson(self,name='poisson',dtype=None)
keras.metrics.metrics.Poisson.__init__(self,name='poisson',dtype=None)
keras.metrics.metrics.Precision(self,thresholds=None,top_k=None,class_id=None,name=None,dtype=None)
keras.metrics.metrics.Precision.__init__(self,thresholds=None,top_k=None,class_id=None,name=None,dtype=None)
keras.metrics.metrics.Precision.get_config(self)
keras.metrics.metrics.Precision.reset_state(self)
keras.metrics.metrics.Precision.result(self)
keras.metrics.metrics.Precision.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.PrecisionAtRecall(self,recall,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.PrecisionAtRecall.__init__(self,recall,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.PrecisionAtRecall.get_config(self)
keras.metrics.metrics.PrecisionAtRecall.result(self)
keras.metrics.metrics.Recall(self,thresholds=None,top_k=None,class_id=None,name=None,dtype=None)
keras.metrics.metrics.Recall.__init__(self,thresholds=None,top_k=None,class_id=None,name=None,dtype=None)
keras.metrics.metrics.Recall.get_config(self)
keras.metrics.metrics.Recall.reset_state(self)
keras.metrics.metrics.Recall.result(self)
keras.metrics.metrics.Recall.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.RecallAtPrecision(self,precision,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.RecallAtPrecision.__init__(self,precision,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.RecallAtPrecision.get_config(self)
keras.metrics.metrics.RecallAtPrecision.result(self)
keras.metrics.metrics.RootMeanSquaredError(self,name='root_mean_squared_error',dtype=None)
keras.metrics.metrics.RootMeanSquaredError.__init__(self,name='root_mean_squared_error',dtype=None)
keras.metrics.metrics.RootMeanSquaredError.result(self)
keras.metrics.metrics.RootMeanSquaredError.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.SensitivityAtSpecificity(self,specificity,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.SensitivityAtSpecificity.__init__(self,specificity,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.SensitivityAtSpecificity.get_config(self)
keras.metrics.metrics.SensitivityAtSpecificity.result(self)
keras.metrics.metrics.SensitivitySpecificityBase(self,value,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.SensitivitySpecificityBase.__init__(self,value,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.SensitivitySpecificityBase._find_max_under_constraint(self,constrained,dependent,predicate)
keras.metrics.metrics.SensitivitySpecificityBase.get_config(self)
keras.metrics.metrics.SensitivitySpecificityBase.reset_state(self)
keras.metrics.metrics.SensitivitySpecificityBase.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.SparseCategoricalAccuracy(self,name='sparse_categorical_accuracy',dtype=None)
keras.metrics.metrics.SparseCategoricalAccuracy.__init__(self,name='sparse_categorical_accuracy',dtype=None)
keras.metrics.metrics.SparseCategoricalCrossentropy(self,name='sparse_categorical_crossentropy',dtype=None,from_logits=False,axis=-1)
keras.metrics.metrics.SparseCategoricalCrossentropy.__init__(self,name='sparse_categorical_crossentropy',dtype=None,from_logits=False,axis=-1)
keras.metrics.metrics.SparseTopKCategoricalAccuracy(self,k=5,name='sparse_top_k_categorical_accuracy',dtype=None)
keras.metrics.metrics.SparseTopKCategoricalAccuracy.__init__(self,k=5,name='sparse_top_k_categorical_accuracy',dtype=None)
keras.metrics.metrics.SpecificityAtSensitivity(self,sensitivity,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.SpecificityAtSensitivity.__init__(self,sensitivity,num_thresholds=200,class_id=None,name=None,dtype=None)
keras.metrics.metrics.SpecificityAtSensitivity.get_config(self)
keras.metrics.metrics.SpecificityAtSensitivity.result(self)
keras.metrics.metrics.SquaredHinge(self,name='squared_hinge',dtype=None)
keras.metrics.metrics.SquaredHinge.__init__(self,name='squared_hinge',dtype=None)
keras.metrics.metrics.TopKCategoricalAccuracy(self,k=5,name='top_k_categorical_accuracy',dtype=None)
keras.metrics.metrics.TopKCategoricalAccuracy.__init__(self,k=5,name='top_k_categorical_accuracy',dtype=None)
keras.metrics.metrics.TrueNegatives(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.TrueNegatives.__init__(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.TruePositives(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics.TruePositives.__init__(self,thresholds=None,name=None,dtype=None)
keras.metrics.metrics._ConfusionMatrixConditionCount(self,confusion_matrix_cond,thresholds=None,name=None,dtype=None)
keras.metrics.metrics._ConfusionMatrixConditionCount.__init__(self,confusion_matrix_cond,thresholds=None,name=None,dtype=None)
keras.metrics.metrics._ConfusionMatrixConditionCount.get_config(self)
keras.metrics.metrics._ConfusionMatrixConditionCount.reset_state(self)
keras.metrics.metrics._ConfusionMatrixConditionCount.result(self)
keras.metrics.metrics._ConfusionMatrixConditionCount.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics._IoUBase(self,num_classes,name=None,dtype=None)
keras.metrics.metrics._IoUBase.__init__(self,num_classes,name=None,dtype=None)
keras.metrics.metrics._IoUBase.reset_state(self)
keras.metrics.metrics._IoUBase.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.metrics.accuracy(y_true,y_pred)
keras.metrics.metrics.binary_accuracy(y_true,y_pred,threshold=0.5)
keras.metrics.metrics.categorical_accuracy(y_true,y_pred)
keras.metrics.metrics.cosine_similarity(y_true,y_pred,axis=-1)
keras.metrics.metrics.sparse_categorical_accuracy(y_true,y_pred)
keras.metrics.metrics.sparse_top_k_categorical_accuracy(y_true,y_pred,k=5)
keras.metrics.metrics.top_k_categorical_accuracy(y_true,y_pred,k=5)
keras.metrics.sparse_categorical_accuracy(y_true,y_pred)
keras.metrics.sparse_top_k_categorical_accuracy(y_true,y_pred,k=5)
keras.metrics.top_k_categorical_accuracy(y_true,y_pred,k=5)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/metrics/base_metric.py----------------------------------------
A:keras.metrics.base_metric.obj->super(Metric, cls).__new__(cls)
A:keras.metrics.base_metric.control_status->tensorflow.compat.v2.__internal__.autograph.control_status_ctx()
A:keras.metrics.base_metric.ag_update_state->tensorflow.compat.v2.__internal__.autograph.tf_convert(obj_update_state, control_status)
A:keras.metrics.base_metric.update_state_fn->tensorflow.compat.v2.function(obj.update_state)
A:keras.metrics.base_metric.obj.update_state->types.MethodType(metrics_utils.update_state_wrapper(update_state_fn), obj)
A:keras.metrics.base_metric.ag_result->tensorflow.compat.v2.__internal__.autograph.tf_convert(obj_result, control_status)
A:keras.metrics.base_metric.obj.result->types.MethodType(metrics_utils.result_wrapper(result_fn), obj)
A:keras.metrics.base_metric.update_op->self.update_state(*args, **kwargs)
A:keras.metrics.base_metric.result_t->self.result()
A:keras.metrics.base_metric.args->','.join((f'{k}={v}' for (k, v) in self.get_config().items()))
A:keras.metrics.base_metric.result->type(self)(name=self.name, dtype=self.dtype)
A:keras.metrics.base_metric.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.metrics.base_metric.self.total->self.add_weight('total', initializer='zeros')
A:keras.metrics.base_metric.self.count->self.add_weight('count', initializer='zeros')
A:keras.metrics.base_metric.([values], sample_weight)->keras.utils.metrics_utils.ragged_assert_compatible_and_get_flat_values([values], sample_weight)
A:keras.metrics.base_metric.values->tensorflow.compat.v2.multiply(values, sample_weight)
A:keras.metrics.base_metric.sample_weight->tensorflow.compat.v2.__internal__.ops.broadcast_weights(sample_weight, values)
A:keras.metrics.base_metric.(values, _, sample_weight)->keras.utils.losses_utils.squeeze_or_expand_dimensions(values, sample_weight=sample_weight)
A:keras.metrics.base_metric.ndim->keras.backend.ndim(values)
A:keras.metrics.base_metric.weight_ndim->keras.backend.ndim(sample_weight)
A:keras.metrics.base_metric.value_sum->tensorflow.compat.v2.reduce_sum(values)
A:keras.metrics.base_metric.update_total_op->self._total.assign_add(values)
A:keras.metrics.base_metric.num_values->tensorflow.compat.v2.multiply(num_values, sample_weight)
A:keras.metrics.base_metric.y_true->tensorflow.compat.v2.cast(y_true, self._dtype)
A:keras.metrics.base_metric.y_pred->tensorflow.compat.v2.cast(y_pred, self._dtype)
A:keras.metrics.base_metric.([y_true, y_pred], sample_weight)->keras.utils.metrics_utils.ragged_assert_compatible_and_get_flat_values([y_true, y_pred], sample_weight)
A:keras.metrics.base_metric.(y_pred, y_true)->keras.utils.losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)
A:keras.metrics.base_metric.ag_fn->tensorflow.compat.v2.__internal__.autograph.tf_convert(self._fn, tf.__internal__.autograph.control_status_ctx())
A:keras.metrics.base_metric.matches->ag_fn(y_true, y_pred, **self._fn_kwargs)
A:keras.metrics.base_metric.base_config->super(SumOverBatchSizeMetricWrapper, self).get_config()
A:keras.metrics.base_metric.fn->config.pop('fn', None)
A:keras.metrics.base_metric.self._shape->tensorflow.compat.v2.TensorShape(shape)
A:keras.metrics.base_metric.self._total->self.add_weight(name='total', shape=shape, initializer='zeros')
A:keras.metrics.base_metric.self._count->self.add_weight(name='count', shape=shape, initializer='zeros')
keras.metrics.Mean(self,name='mean',dtype=None)
keras.metrics.MeanMetricWrapper(self,fn,name=None,dtype=None,**kwargs)
keras.metrics.MeanMetricWrapper.from_config(cls,config)
keras.metrics.MeanMetricWrapper.get_config(self)
keras.metrics.MeanMetricWrapper.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.MeanTensor(self,name='mean_tensor',dtype=None,shape=None)
keras.metrics.MeanTensor._build(self,shape)
keras.metrics.MeanTensor.count(self)
keras.metrics.MeanTensor.reset_state(self)
keras.metrics.MeanTensor.result(self)
keras.metrics.MeanTensor.total(self)
keras.metrics.MeanTensor.update_state(self,values,sample_weight=None)
keras.metrics.Metric(self,name=None,dtype=None,**kwargs)
keras.metrics.Metric.__deepcopy__(self,memo)
keras.metrics.Metric.__str__(self)
keras.metrics.Metric._trackable_saved_model_saver(self)
keras.metrics.Metric.add_weight(self,name,shape=(),aggregation=tf.VariableAggregation.SUM,synchronization=tf.VariableSynchronization.ON_READ,initializer=None,dtype=None)
keras.metrics.Metric.dtype(self)
keras.metrics.Metric.get_config(self)
keras.metrics.Metric.merge_state(self,metrics)
keras.metrics.Metric.non_trainable_weights(self)
keras.metrics.Metric.reset_state(self)
keras.metrics.Metric.reset_states(self)
keras.metrics.Metric.result(self)
keras.metrics.Metric.trainable_weights(self)
keras.metrics.Metric.update_state(self,*args,**kwargs)
keras.metrics.Reduce(self,reduction,name,dtype=None)
keras.metrics.Reduce.result(self)
keras.metrics.Reduce.update_state(self,values,sample_weight=None)
keras.metrics.Sum(self,name='sum',dtype=None)
keras.metrics.SumOverBatchSize(self,name='sum_over_batch_size',dtype=None)
keras.metrics.SumOverBatchSizeMetricWrapper(self,fn,name=None,dtype=None,**kwargs)
keras.metrics.SumOverBatchSizeMetricWrapper.get_config(self)
keras.metrics.SumOverBatchSizeMetricWrapper.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.base_metric.Mean(self,name='mean',dtype=None)
keras.metrics.base_metric.Mean.__init__(self,name='mean',dtype=None)
keras.metrics.base_metric.MeanMetricWrapper(self,fn,name=None,dtype=None,**kwargs)
keras.metrics.base_metric.MeanMetricWrapper.__init__(self,fn,name=None,dtype=None,**kwargs)
keras.metrics.base_metric.MeanMetricWrapper.from_config(cls,config)
keras.metrics.base_metric.MeanMetricWrapper.get_config(self)
keras.metrics.base_metric.MeanMetricWrapper.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.base_metric.MeanTensor(self,name='mean_tensor',dtype=None,shape=None)
keras.metrics.base_metric.MeanTensor.__init__(self,name='mean_tensor',dtype=None,shape=None)
keras.metrics.base_metric.MeanTensor._build(self,shape)
keras.metrics.base_metric.MeanTensor.count(self)
keras.metrics.base_metric.MeanTensor.reset_state(self)
keras.metrics.base_metric.MeanTensor.result(self)
keras.metrics.base_metric.MeanTensor.total(self)
keras.metrics.base_metric.MeanTensor.update_state(self,values,sample_weight=None)
keras.metrics.base_metric.Metric(self,name=None,dtype=None,**kwargs)
keras.metrics.base_metric.Metric.__deepcopy__(self,memo)
keras.metrics.base_metric.Metric.__init__(self,name=None,dtype=None,**kwargs)
keras.metrics.base_metric.Metric.__str__(self)
keras.metrics.base_metric.Metric._trackable_saved_model_saver(self)
keras.metrics.base_metric.Metric.add_weight(self,name,shape=(),aggregation=tf.VariableAggregation.SUM,synchronization=tf.VariableSynchronization.ON_READ,initializer=None,dtype=None)
keras.metrics.base_metric.Metric.dtype(self)
keras.metrics.base_metric.Metric.get_config(self)
keras.metrics.base_metric.Metric.merge_state(self,metrics)
keras.metrics.base_metric.Metric.non_trainable_weights(self)
keras.metrics.base_metric.Metric.reset_state(self)
keras.metrics.base_metric.Metric.reset_states(self)
keras.metrics.base_metric.Metric.result(self)
keras.metrics.base_metric.Metric.trainable_weights(self)
keras.metrics.base_metric.Metric.update_state(self,*args,**kwargs)
keras.metrics.base_metric.Reduce(self,reduction,name,dtype=None)
keras.metrics.base_metric.Reduce.__init__(self,reduction,name,dtype=None)
keras.metrics.base_metric.Reduce.result(self)
keras.metrics.base_metric.Reduce.update_state(self,values,sample_weight=None)
keras.metrics.base_metric.Sum(self,name='sum',dtype=None)
keras.metrics.base_metric.Sum.__init__(self,name='sum',dtype=None)
keras.metrics.base_metric.SumOverBatchSize(self,name='sum_over_batch_size',dtype=None)
keras.metrics.base_metric.SumOverBatchSize.__init__(self,name='sum_over_batch_size',dtype=None)
keras.metrics.base_metric.SumOverBatchSizeMetricWrapper(self,fn,name=None,dtype=None,**kwargs)
keras.metrics.base_metric.SumOverBatchSizeMetricWrapper.__init__(self,fn,name=None,dtype=None,**kwargs)
keras.metrics.base_metric.SumOverBatchSizeMetricWrapper.get_config(self)
keras.metrics.base_metric.SumOverBatchSizeMetricWrapper.update_state(self,y_true,y_pred,sample_weight=None)
keras.metrics.base_metric.clone_metric(metric)
keras.metrics.base_metric.clone_metrics(metrics)
keras.metrics.base_metric.is_built_in(cls)
keras.metrics.clone_metric(metric)
keras.metrics.clone_metrics(metrics)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/input_layer.py----------------------------------------
A:keras.engine.input_layer.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.input_layer.batch_input_shape->kwargs.pop('batch_input_shape', kwargs.pop('batch_shape', None))
A:keras.engine.input_layer.dtype->keras.backend.dtype(input_tensor)
A:keras.engine.input_layer.input_shape->tuple(input_shape.as_list())
A:keras.engine.input_layer.input_tensor->keras.engine.keras_tensor.keras_tensor_from_tensor(input_tensor)
A:keras.engine.input_layer.self._batch_input_shape->tuple(input_tensor.shape.as_list())
A:keras.engine.input_layer.graph->keras.backend.get_graph()
A:keras.engine.input_layer.self._type_spec->tensorflow.compat.v2.TensorSpec(shape=input_tensor.shape, dtype=input_tensor.dtype, name=self.name)
A:keras.engine.input_layer.input_layer->InputLayer(**input_layer_config)
keras.Input(shape=None,batch_size=None,name=None,dtype=None,sparse=None,tensor=None,ragged=None,type_spec=None,**kwargs)
keras.InputLayer(self,input_shape=None,batch_size=None,dtype=None,input_tensor=None,sparse=None,name=None,ragged=None,type_spec=None,**kwargs)
keras.InputLayer._trackable_saved_model_saver(self)
keras.InputLayer.get_config(self)
keras.engine.input_layer.Input(shape=None,batch_size=None,name=None,dtype=None,sparse=None,tensor=None,ragged=None,type_spec=None,**kwargs)
keras.engine.input_layer.InputLayer(self,input_shape=None,batch_size=None,dtype=None,input_tensor=None,sparse=None,name=None,ragged=None,type_spec=None,**kwargs)
keras.engine.input_layer.InputLayer.__init__(self,input_shape=None,batch_size=None,dtype=None,input_tensor=None,sparse=None,name=None,ragged=None,type_spec=None,**kwargs)
keras.engine.input_layer.InputLayer._trackable_saved_model_saver(self)
keras.engine.input_layer.InputLayer.get_config(self)
keras.engine.input_layer._assert_other_arg_none(arg_name,arg)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/functional.py----------------------------------------
A:keras.engine.functional._TF_MODULE_IGNORED_PROPERTIES->frozenset(itertools.chain(('_layer_call_argspecs', '_compiled_trainable_state', '_output_mask_cache', '_output_tensor_cache', '_output_shape_cache'), training_lib.Model._TF_MODULE_IGNORED_PROPERTIES))
A:keras.engine.functional.skip_init->_deserialize_keras_tensors(kwargs, created_layers).pop('skip_init', False)
A:keras.engine.functional.(inputs, outputs)->keras.engine.functional_utils.clone_graph_nodes(inputs, outputs)
A:keras.engine.functional.self.inputs->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.functional.self.outputs->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.functional.self._build_input_shape->tensorflow.compat.v2.nest.map_structure(lambda x: x.shape, inputs)
A:keras.engine.functional.(nodes, nodes_by_depth, layers, _)->_map_graph_network(self.inputs, self.outputs)
A:keras.engine.functional.self._layer_call_argspecs[layer]->keras.utils.tf_inspect.getfullargspec(layer.call)
A:keras.engine.functional.names->sorted(self._nested_inputs.keys())
A:keras.engine.functional.output_names->set()
A:keras.engine.functional.existing_count->prefix_count.get(layer.name, 1)
A:keras.engine.functional.proposal->'{}_{}'.format(layer.name, existing_count)
A:keras.engine.functional.dependencies->collections.OrderedDict()
A:keras.engine.functional.output_tensors->tensorflow.compat.v2.nest.pack_sequence_as(output_layers, output_tensors)
A:keras.engine.functional.input_shape->keras.utils.tf_utils.convert_shapes(input_shape, to_tuples=False)
A:keras.engine.functional.cache_key->tuple(tf_utils.convert_shapes(input_shape, to_tuples=True))
A:keras.engine.functional.depth_keys->list(nodes_by_depth.keys())
A:keras.engine.functional.layer_input_shapes->keras.utils.tf_utils.convert_shapes(layer_input_shapes, to_tuples=True)
A:keras.engine.functional.layer_output_shapes->keras.utils.tf_utils.convert_shapes(layer_output_shapes, to_tuples=False)
A:keras.engine.functional.node_index->get_node_index(layer, node_index)
A:keras.engine.functional.output_shapes->tensorflow.compat.v2.nest.pack_sequence_as(self._nested_outputs, output_shapes)
A:keras.engine.functional.self._name->keras.backend.unique_object_name(generic_utils.to_snake_case(cls_name), zero_based=zero_based)
A:keras.engine.functional.inputs->self._flatten_to_reference_inputs(inputs)
A:keras.engine.functional.masks->self._flatten_to_reference_inputs(mask)
A:keras.engine.functional.y->self._conform_to_reference_input(y, ref_input=x)
A:keras.engine.functional.x_id->str(id(x))
A:keras.engine.functional.(args, kwargs)->unprocessed_nodes.pop(0).map_arguments(tensor_dict)
A:keras.engine.functional.outputs->unprocessed_nodes.pop(0).layer(*args, **kwargs)
A:keras.engine.functional.ref_input_names->sorted(ref_inputs.keys())
A:keras.engine.functional.keras_history->getattr(tensor, '_keras_history', None)
A:keras.engine.functional.tensor->tensorflow.compat.v2.cast(tensor, dtype=ref_input_dtype)
A:keras.engine.functional.tensor_dtype->getattr(tensor, 'dtype', None)
A:keras.engine.functional.ref_input_dtype->getattr(ref_input, 'dtype', None)
A:keras.engine.functional.input_batch_sizes->set([training_utils.get_static_batch_size(x._keras_history.layer) for x in self.inputs])
A:keras.engine.functional.layers->tensorflow.compat.v2.nest.flatten(layers)
A:keras.engine.functional.relevant_nodes->tensorflow.compat.v2.nest.flatten([layer.inbound_nodes[1:] if _should_skip_first_node(layer) else layer.inbound_nodes for layer in created_layers.values()])
A:keras.engine.functional.network_nodes->set(relevant_nodes + list(node_to_depth.keys()))
A:keras.engine.functional.min_depth->min(min_depth, node_to_depth[inbound_node])
A:keras.engine.functional.unprocessed_nodes->collections.defaultdict(list)
A:keras.engine.functional.node->collections.defaultdict(list).pop(0)
A:keras.engine.functional.depth->max(depth, previous_depth)
A:keras.engine.functional.node_key->_make_node_key(layer.name, node_index)
A:keras.engine.functional.layer_set->set(self._self_tracked_trackables)
A:keras.engine.functional.tensor_usage_count->collections.Counter()
A:keras.engine.functional.available_tensors->set((str(id(tensor)) for tensor in self.inputs))
A:keras.engine.functional.(new_nodes, new_layers)->_map_subgraph_network(self.inputs, [value])
A:keras.engine.functional.add_loss_layer->keras.engine.base_layer.AddLoss(unconditional=False, dtype=symbolic_loss.dtype)
A:keras.engine.functional.add_metric_layer->keras.engine.base_layer.AddMetric(aggregation, name, dtype=value.dtype)
A:keras.engine.functional.(nodes_in_decreasing_depth, layer_indices)->_build_map(outputs)
A:keras.engine.functional.previous_depth->nodes_depths.get(node_dep, 0)
A:keras.engine.functional.nodes_depths[node_dep]->max(depth + 1, previous_depth)
A:keras.engine.functional.nodes_by_depth->collections.defaultdict(list)
A:keras.engine.functional.layers_by_depth->collections.defaultdict(list)
A:keras.engine.functional.computable_tensors->set()
A:keras.engine.functional.finished_nodes->set()
A:keras.engine.functional.nodes_in_progress->set()
A:keras.engine.functional.layer_indices[layer]->len(layer_indices)
A:keras.engine.functional.(_, nodes_by_depth, layers, _)->_map_graph_network(inputs, outputs)
A:keras.engine.functional.t->t.as_list().as_list()
A:keras.engine.functional.new_node_index->get_node_index(layer, node_index)
A:keras.engine.functional.kwargs->_deserialize_keras_tensors(kwargs, created_layers)
A:keras.engine.functional.input_data->input_data.as_list().as_list()
A:keras.engine.functional.inbound_node_index->get_node_index(inbound_layer, inbound_node_index)
A:keras.engine.functional.input_tensors->tensorflow.compat.v2.nest.pack_sequence_as(input_layers, input_tensors)
A:keras.engine.functional.layer->deserialize_layer(layer_data, custom_objects=custom_objects)
A:keras.engine.functional.node_count_by_layer[layer]->int(_should_skip_first_node(layer))
A:keras.engine.functional.inbound_nodes_data->keras.utils.tf_utils.convert_inner_node_data(inbound_nodes_data, wrap=True)
A:keras.engine.functional.layer_nodes->collections.defaultdict(list).pop(layer)
A:keras.engine.functional.input_layers->keras.utils.tf_utils.convert_inner_node_data(config['input_layers'], wrap=True)
A:keras.engine.functional.(layer_name, node_index, tensor_index)->layer_data.as_list()
A:keras.engine.functional.output_layers->keras.utils.tf_utils.convert_inner_node_data(config['output_layers'], wrap=True)
A:keras.engine.functional.node_data->collections.defaultdict(list).pop(0).serialize(_make_node_key, node_conversion_map)
A:keras.engine.functional.layer_config->serialize_layer_fn(layer)
A:keras.engine.functional.model_inputs->keras.utils.tf_utils.convert_inner_node_data(model_inputs)
A:keras.engine.functional.model_outputs->keras.utils.tf_utils.convert_inner_node_data(model_outputs)
A:keras.engine.functional.shape->x.shape.as_list()
A:keras.engine.functional.method->getattr(module, method_name)
A:keras.engine.functional.method_arg_spec->keras.utils.tf_inspect.getfullargspec(method)
keras.engine.functional.Functional(self,inputs,outputs,name=None,trainable=True,**kwargs)
keras.engine.functional.Functional.__init__(self,inputs,outputs,name=None,trainable=True,**kwargs)
keras.engine.functional.Functional._assert_weights_created(self)
keras.engine.functional.Functional._compute_tensor_usage_count(self)
keras.engine.functional.Functional._conform_to_reference_input(self,tensor,ref_input)
keras.engine.functional.Functional._flatten_to_reference_inputs(self,tensors)
keras.engine.functional.Functional._get_save_spec(self,dynamic_batch=True,inputs_only=True)
keras.engine.functional.Functional._graph_network_add_loss(self,symbolic_loss)
keras.engine.functional.Functional._graph_network_add_metric(self,value,aggregation,name)
keras.engine.functional.Functional._handle_deferred_layer_dependencies(self,layers)
keras.engine.functional.Functional._init_graph_network(self,inputs,outputs)
keras.engine.functional.Functional._init_set_name(self,name,zero_based=True)
keras.engine.functional.Functional._insert_layers(self,layers,relevant_nodes=None)
keras.engine.functional.Functional._layer_checkpoint_dependencies(self)
keras.engine.functional.Functional._lookup_dependency(self,name)
keras.engine.functional.Functional._run_internal_graph(self,inputs,training=None,mask=None)
keras.engine.functional.Functional._set_output_names(self)
keras.engine.functional.Functional._should_compute_mask(self)
keras.engine.functional.Functional._trackable_children(self,save_type='checkpoint',**kwargs)
keras.engine.functional.Functional._trackable_saved_model_saver(self)
keras.engine.functional.Functional._validate_graph_inputs_and_outputs(self)
keras.engine.functional.Functional.call(self,inputs,training=None,mask=None)
keras.engine.functional.Functional.compute_mask(self,inputs,mask)
keras.engine.functional.Functional.compute_output_shape(self,input_shape)
keras.engine.functional.Functional.get_config(self)
keras.engine.functional.Functional.input(self)
keras.engine.functional.Functional.input_shape(self)
keras.engine.functional.Functional.input_spec(self)
keras.engine.functional.Functional.input_spec(self,value)
keras.engine.functional.Functional.output(self)
keras.engine.functional.Functional.output_shape(self)
keras.engine.functional.ModuleWrapper(self,module,method_name=None,**kwargs)
keras.engine.functional.ModuleWrapper.__init__(self,module,method_name=None,**kwargs)
keras.engine.functional.ModuleWrapper.call(self,*args,**kwargs)
keras.engine.functional._build_map(outputs)
keras.engine.functional._build_map_helper(tensor,finished_nodes,nodes_in_progress,nodes_in_decreasing_depth,layer_indices)
keras.engine.functional._make_node_key(layer_name,node_index)
keras.engine.functional._map_graph_network(inputs,outputs)
keras.engine.functional._map_subgraph_network(inputs,outputs)
keras.engine.functional._should_skip_first_node(layer)
keras.engine.functional.connect_ancillary_layers(model,created_layers)
keras.engine.functional.get_network_config(network,serialize_layer_fn=None)
keras.engine.functional.reconstruct_from_config(config,custom_objects=None,created_layers=None)
keras.engine.functional.shape_with_no_batch_size(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/sequential.py----------------------------------------
A:keras.engine.sequential.self._created_nodes->set()
A:keras.engine.sequential.layer->keras.layers.deserialize(layer_config, custom_objects=custom_objects)
A:keras.engine.sequential.(batch_shape, dtype)->keras.engine.training_utils.get_input_shape_and_dtype(layer)
A:keras.engine.sequential.x->keras.engine.input_layer.Input(batch_shape=batch_shape, dtype=dtype, name=layer.name + '_input')
A:keras.engine.sequential.outputs->self.call(inputs, mask=mask)
A:keras.engine.sequential.self.inputs->keras.utils.layer_utils.get_source_inputs(self.outputs[0])
A:keras.engine.sequential.output_tensor->layer(self.outputs[0])
A:keras.engine.sequential.self._layer_call_argspecs[layer]->keras.utils.tf_inspect.getfullargspec(layer.call)
A:keras.engine.sequential.input_shape->tuple(input_shape)
A:keras.engine.sequential.new_shape->relax_input_shape(self._inferred_input_shape, input_shape)
A:keras.engine.sequential.inputs->keras.engine.input_layer.Input(batch_shape=new_shape, dtype=input_dtype, name=self.layers[0].name + '_input')
A:keras.engine.sequential.created_nodes->set()
A:keras.engine.sequential.layer_output->layer(layer_input)
A:keras.engine.sequential.self._build_input_shape->tensorflow.compat.v2.nest.map_structure(_get_shape_tuple, inputs)
A:keras.engine.sequential.mask->getattr(outputs, '_keras_mask', None)
A:keras.engine.sequential.shape->keras.layers.deserialize(layer_config, custom_objects=custom_objects).compute_output_shape(shape)
A:keras.engine.sequential.build_input_shape->config.get('build_input_shape')
A:keras.engine.sequential.model->cls(name=name)
keras.Sequential(self,layers=None,name=None)
keras.Sequential._assert_weights_created(self)
keras.Sequential._build_graph_network_for_inferred_shape(self,input_shape,input_dtype=None)
keras.Sequential._is_layer_name_unique(self,layer)
keras.Sequential._trackable_saved_model_saver(self)
keras.Sequential.add(self,layer)
keras.Sequential.build(self,input_shape=None)
keras.Sequential.call(self,inputs,training=None,mask=None)
keras.Sequential.compute_mask(self,inputs,mask)
keras.Sequential.compute_output_shape(self,input_shape)
keras.Sequential.from_config(cls,config,custom_objects=None)
keras.Sequential.get_config(self)
keras.Sequential.input_spec(self)
keras.Sequential.input_spec(self,value)
keras.Sequential.layers(self)
keras.Sequential.pop(self)
keras.engine.sequential.Sequential(self,layers=None,name=None)
keras.engine.sequential.Sequential.__init__(self,layers=None,name=None)
keras.engine.sequential.Sequential._assert_weights_created(self)
keras.engine.sequential.Sequential._build_graph_network_for_inferred_shape(self,input_shape,input_dtype=None)
keras.engine.sequential.Sequential._is_layer_name_unique(self,layer)
keras.engine.sequential.Sequential._trackable_saved_model_saver(self)
keras.engine.sequential.Sequential.add(self,layer)
keras.engine.sequential.Sequential.build(self,input_shape=None)
keras.engine.sequential.Sequential.call(self,inputs,training=None,mask=None)
keras.engine.sequential.Sequential.compute_mask(self,inputs,mask)
keras.engine.sequential.Sequential.compute_output_shape(self,input_shape)
keras.engine.sequential.Sequential.from_config(cls,config,custom_objects=None)
keras.engine.sequential.Sequential.get_config(self)
keras.engine.sequential.Sequential.input_spec(self)
keras.engine.sequential.Sequential.input_spec(self,value)
keras.engine.sequential.Sequential.layers(self)
keras.engine.sequential.Sequential.pop(self)
keras.engine.sequential._get_shape_tuple(t)
keras.engine.sequential.clear_previously_created_nodes(layer,created_nodes)
keras.engine.sequential.relax_input_shape(shape_1,shape_2)
keras.engine.sequential.track_nodes_created_by_last_call(layer,created_nodes)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_v1.py----------------------------------------
A:keras.engine.training_v1.self._experimental_run_tf_function->getattr(self, '_function_kwargs', {}).pop('experimental_run_tf_function', True)
A:keras.engine.training_v1.self._run_eagerly->getattr(self, '_function_kwargs', {}).pop('run_eagerly', None)
A:keras.engine.training_v1.self._from_serialized->getattr(self, '_function_kwargs', {}).pop('from_serialized', False)
A:keras.engine.training_v1.is_any_keras_optimizer_v1->any((isinstance(opt, optimizer_v1.Optimizer) and (not isinstance(opt, optimizer_v1.TFOptimizer)) for opt in tf.nest.flatten(self.optimizer)))
A:keras.engine.training_v1.self._distribution_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.training_v1.self._compiled_trainable_state->self._get_trainable_state()
A:keras.engine.training_v1.self.loss_functions->keras.engine.training_utils_v1.prepare_loss_functions(self.loss, self.output_names)
A:keras.engine.training_v1.target_tensors->self._process_target_tensor_for_compile(target_tensors)
A:keras.engine.training_v1.endpoint->_TrainingEndpoint(o, n, l)
A:keras.engine.training_v1.epochs->getattr(self, '_function_kwargs', {}).pop('nb_epoch')
A:keras.engine.training_v1.func->self._select_training_loop(x)
A:keras.engine.training_v1.metrics->self._get_training_eval_metrics()
A:keras.engine.training_v1.(x, y, sample_weights)->self._standardize_user_data(x, y, sample_weight=sample_weight, extract_tensors_from_dataset=True)
A:keras.engine.training_v1.output_dict->keras.engine.training_eager_v1.test_on_batch(self, x, y, sample_weights=sample_weights, output_loss_metrics=self._output_loss_metrics)
A:keras.engine.training_v1.x->dict(zip(feed_input_names, x))
A:keras.engine.training_v1.outputs->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.training_v1.(inputs, _, _)->self._standardize_user_data(x, extract_tensors_from_dataset=True)
A:keras.engine.training_v1.inputs->keras.engine.training_utils_v1.ModelInputs(inputs).get_symbolic_inputs()
A:keras.engine.training_v1.self.optimizer->keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer(self.optimizer)
A:keras.engine.training_v1.(val_x, val_y, val_sample_weights)->keras.engine.training_utils_v1.unpack_validation_data(validation_data)
A:keras.engine.training_v1.unexpected_target_tensor_names->set(target_tensors.keys()).difference(self.output_names)
A:keras.engine.training_v1.recompile->any((e.sample_weights_mismatch() for e in self._training_endpoints))
A:keras.engine.training_v1.masks->self._prepare_output_masks()
A:keras.engine.training_v1.self.total_loss->self._prepare_total_loss(masks)
A:keras.engine.training_v1.loss_name->_TrainingEndpoint(o, n, l).loss_name()
A:keras.engine.training_v1.mask->tensorflow.compat.v2.cast(mask, y_pred.dtype)
A:keras.engine.training_v1.(mask, _, sample_weight)->keras.utils.losses_utils.squeeze_or_expand_dimensions(mask, sample_weight=sample_weight)
A:keras.engine.training_v1.per_sample_losses->loss_fn.call(y_true, y_pred)
A:keras.engine.training_v1.weighted_losses->keras.utils.losses_utils.compute_weighted_loss(per_sample_losses, sample_weight=sample_weight, reduction=losses_utils.ReductionV2.NONE)
A:keras.engine.training_v1.output_loss->keras.utils.losses_utils.scale_loss_for_distribution(output_loss)
A:keras.engine.training_v1.total_custom_loss->tensorflow.compat.v2.add_n(losses_utils.cast_losses_to_common_dtype(custom_losses))
A:keras.engine.training_v1.loss_list->keras.utils.losses_utils.cast_losses_to_common_dtype(loss_list)
A:keras.engine.training_v1.total_loss->tensorflow.compat.v2.add_n(loss_list)
A:keras.engine.training_v1.self._replicated_model->DistributedCallbackModel(first_replicated_model)
A:keras.engine.training_v1.layers->keras.utils.layer_utils.filter_empty_layer_containers(layers)
A:keras.engine.training_v1.first_layer->next(layers, None)
A:keras.engine.training_v1.static_batch_size->keras.engine.training_utils.get_static_batch_size(first_layer)
A:keras.engine.training_v1.self._per_output_metrics->keras.engine.training_utils_v1.collect_per_output_metric_info(metrics, self.output_names, output_shapes, self.loss_functions, from_serialized=self._from_serialized)
A:keras.engine.training_v1.self._per_output_weighted_metrics->keras.engine.training_utils_v1.collect_per_output_metric_info(weighted_metrics, self.output_names, output_shapes, self.loss_functions, from_serialized=self._from_serialized, is_weighted=True)
A:keras.engine.training_v1.updated_metrics_dict->collections.OrderedDict()
A:keras.engine.training_v1.metric_name->self._add_unique_metric_name(metric_name, metric_fn, output_index)
A:keras.engine.training_v1.endpoint.output_loss_metric->keras.metrics.Mean(name=endpoint.loss_name())
A:keras.engine.training_v1.metric_result->keras.engine.training_utils_v1.call_metric_function(metric_fn, y_true, y_pred, weights=weights, mask=mask)
A:keras.engine.training_v1.has_recompiled->self._recompile_weights_loss_and_weighted_metrics()
A:keras.engine.training_v1.current_trainable_state->self._get_trainable_state()
A:keras.engine.training_v1.updates->self.optimizer.get_updates(params=self._collected_trainable_weights, loss=self.total_loss)
A:keras.engine.training_v1.fn->keras.backend.function(inputs, [self.total_loss] + metrics_tensors, updates=updates, name='test_function', **self._function_kwargs)
A:keras.engine.training_v1.kwargs->getattr(self, '_function_kwargs', {})
A:keras.engine.training_v1.self.predict_function->keras.backend.function(inputs, self.outputs, updates=self.state_updates, name='predict_function', **kwargs)
A:keras.engine.training_v1.session->keras.backend.get_session()
A:keras.engine.training_v1.y->keras.engine.training_utils_v1.standardize_input_data(y, feed_output_names, shapes=None, check_batch_axis=False, exception_prefix='target')
A:keras.engine.training_v1.sample_weight->keras.engine.training_utils.list_to_tuple(sample_weight)
A:keras.engine.training_v1.ds->ds.repeat(epochs).repeat(epochs)
A:keras.engine.training_v1.(x, y, sample_weight)->keras.engine.training_utils_v1.unpack_iterator_input(iterator)
A:keras.engine.training_v1.(all_inputs, y_input, dict_inputs)->self._build_model_with_inputs(x, y)
A:keras.engine.training_v1.dict_inputs->isinstance(self.inputs, dict)
A:keras.engine.training_v1.x_shapes->tensorflow.compat.v2.nest.map_structure(_type_spec_from_value, x)
A:keras.engine.training_v1.flat_inputs->tensorflow.compat.v2.nest.flatten(x_shapes, expand_composites=False)
A:keras.engine.training_v1.flat_expected_inputs->tensorflow.compat.v2.nest.flatten(self.inputs, expand_composites=False)
A:keras.engine.training_v1.sample_weights->keras.engine.training_utils_v1.standardize_sample_weights(sample_weight, feed_output_names)
A:keras.engine.training_v1.class_weights->keras.engine.training_utils_v1.standardize_class_weights(class_weight, feed_output_names)
A:keras.engine.training_v1.(sample_weights, _, _)->keras.engine.training_utils.handle_partial_sample_weights(y, sample_weights, feed_sample_weight_modes, check_all_flat=True)
A:keras.engine.training_v1.(inputs, targets, _)->keras.engine.training_utils_v1.extract_tensors_from_dataset(inputs)
A:keras.engine.training_v1.keys->sorted(inputs.keys())
A:keras.engine.training_v1.cast_inputs->keras.engine.training_utils_v1.cast_if_floating_dtype(inputs)
A:keras.engine.training_v1.target->keras.backend.placeholder(ndim=len(self.shape), name=self.output_name + '_target', sparse=backend.is_sparse(self.output), dtype=target_dtype)
A:keras.engine.training_v1.is_dataset->isinstance(orig_inputs, (tf.compat.v1.data.Dataset, tf.data.Dataset, tf.compat.v1.data.Iterator))
A:keras.engine.training_v1.training->keras.backend.learning_phase()
A:keras.engine.training_v1.model_inputs->keras.engine.training_utils_v1.ModelInputs(inputs)
A:keras.engine.training_v1.self.inputs->keras.engine.training_utils_v1.ModelInputs(inputs).get_symbolic_inputs(return_single_as_list=True)
A:keras.engine.training_v1.self.input_names->keras.engine.training_utils_v1.ModelInputs(inputs).get_input_names()
A:keras.engine.training_v1.self.output_names->keras.engine.training_utils_v1.generic_output_names(outputs)
A:keras.engine.training_v1.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.training_v1.distributed_model_weights->self.get_weights()
A:keras.engine.training_v1.orig_model_weights->self._original_model.get_weights()
A:keras.engine.training_v1.self.training_target->_TrainingTarget(target, feedable=feedable, skip_target_weights=skip_target_weights)
A:keras.engine.training_v1.target_dtype->keras.losses.LABEL_DTYPES_FOR_LOSSES.get(self.loss_fn, backend.dtype(self.output))
A:keras.engine.training_v1.self._sample_weight->tensorflow.compat.v2.compat.v1.placeholder_with_default(tf.constant(default_value, dtype=backend.floatx()), shape=shape, name=self.output_name + '_sample_weights')
A:keras.engine.training_v1.sparse_coo->value.tocoo()
A:keras.engine.training_v1.indices->numpy.concatenate((np.expand_dims(row, 1), np.expand_dims(col, 1)), 1)
A:keras.engine.training_v1.constant_value->tensorflow.compat.v2.get_static_value(v)
keras.engine.training_v1.DistributedCallbackModel(self,model)
keras.engine.training_v1.DistributedCallbackModel.__getattr__(self,item)
keras.engine.training_v1.DistributedCallbackModel.__init__(self,model)
keras.engine.training_v1.DistributedCallbackModel.load_weights(self,filepath,by_name=False)
keras.engine.training_v1.DistributedCallbackModel.save(self,filepath,overwrite=True,include_optimizer=True)
keras.engine.training_v1.DistributedCallbackModel.save_weights(self,filepath,overwrite=True,save_format=None)
keras.engine.training_v1.DistributedCallbackModel.set_original_model(self,orig_model)
keras.engine.training_v1.Model(self,*args,**kwargs)
keras.engine.training_v1.Model.__init__(self,*args,**kwargs)
keras.engine.training_v1.Model._add_unique_metric_name(self,metric_name,metric_fn,output_index)
keras.engine.training_v1.Model._assert_compile_was_called(self)
keras.engine.training_v1.Model._build_model_with_inputs(self,inputs,targets)
keras.engine.training_v1.Model._cache_output_metric_attributes(self,metrics,weighted_metrics)
keras.engine.training_v1.Model._check_call_args(self,method_name)
keras.engine.training_v1.Model._check_trainable_weights_consistency(self)
keras.engine.training_v1.Model._compile_eagerly(self,metrics,weighted_metrics,sample_weight_mode)
keras.engine.training_v1.Model._compile_from_inputs(self,all_inputs,target,orig_inputs,orig_target)
keras.engine.training_v1.Model._compile_was_called(self)
keras.engine.training_v1.Model._compile_weights_loss_and_weighted_metrics(self,sample_weights=None)
keras.engine.training_v1.Model._distribution_standardize_user_data(self,x,y=None,sample_weight=None,class_weight=None,batch_size=None,validation_split=0.0,shuffle=False,epochs=1,allow_partial_batch=False)
keras.engine.training_v1.Model._feed_loss_fns(self)
keras.engine.training_v1.Model._feed_output_names(self)
keras.engine.training_v1.Model._feed_output_shapes(self)
keras.engine.training_v1.Model._feed_sample_weights(self)
keras.engine.training_v1.Model._feed_targets(self)
keras.engine.training_v1.Model._get_callback_model(self)
keras.engine.training_v1.Model._get_compile_args(self,user_metrics=True)
keras.engine.training_v1.Model._get_training_eval_metrics(self)
keras.engine.training_v1.Model._handle_metrics(self,outputs,targets=None,skip_target_masks=None,sample_weights=None,masks=None,return_weighted_metrics=False,return_weighted_and_unweighted_metrics=False)
keras.engine.training_v1.Model._handle_per_output_metrics(self,metrics_dict,y_true,y_pred,mask,weights=None)
keras.engine.training_v1.Model._in_multi_worker_mode(self)
keras.engine.training_v1.Model._init_batch_counters(self)
keras.engine.training_v1.Model._init_distributed_function_cache_if_not_compiled(self)
keras.engine.training_v1.Model._init_metric_attributes(self)
keras.engine.training_v1.Model._loss_weights_list(self)
keras.engine.training_v1.Model._make_callback_model(self,grouped_model)
keras.engine.training_v1.Model._make_execution_function(self,mode)
keras.engine.training_v1.Model._make_predict_function(self)
keras.engine.training_v1.Model._make_test_function(self)
keras.engine.training_v1.Model._make_train_function(self)
keras.engine.training_v1.Model._maybe_load_initial_epoch_from_ckpt(self,initial_epoch,mode)
keras.engine.training_v1.Model._output_loss_metrics(self)
keras.engine.training_v1.Model._prepare_output_masks(self)
keras.engine.training_v1.Model._prepare_sample_weights(self,sample_weights=None)
keras.engine.training_v1.Model._prepare_skip_target_masks(self)
keras.engine.training_v1.Model._prepare_total_loss(self,masks)
keras.engine.training_v1.Model._prepare_validation_data(self,validation_data,batch_size,validation_steps)
keras.engine.training_v1.Model._process_target_tensor_for_compile(self,target_tensors)
keras.engine.training_v1.Model._recompile_weights_loss_and_weighted_metrics(self)
keras.engine.training_v1.Model._sample_weight_modes(self)
keras.engine.training_v1.Model._select_training_loop(self,inputs)
keras.engine.training_v1.Model._set_input_attrs(self,inputs)
keras.engine.training_v1.Model._set_inputs(self,inputs,outputs=None,training=None)
keras.engine.training_v1.Model._set_metric_attributes(self)
keras.engine.training_v1.Model._set_optimizer(self,optimizer)
keras.engine.training_v1.Model._set_output_attrs(self,outputs)
keras.engine.training_v1.Model._set_per_output_metric_attributes(self,metrics_dict,output_index)
keras.engine.training_v1.Model._set_strategy(self,strategy)
keras.engine.training_v1.Model._standardize_tensors(self,x,y,sample_weight,run_eagerly,dict_inputs,is_dataset,class_weight=None,batch_size=None)
keras.engine.training_v1.Model._standardize_user_data(self,x,y=None,sample_weight=None,class_weight=None,batch_size=None,check_steps=False,steps_name='steps',steps=None,validation_split=0.0,shuffle=False,extract_tensors_from_dataset=False)
keras.engine.training_v1.Model._targets(self)
keras.engine.training_v1.Model._trackable_saved_model_saver(self)
keras.engine.training_v1.Model._update_sample_weight_modes(self,sample_weights=None)
keras.engine.training_v1.Model._validate_compile_param_for_distribution_strategy(self,run_eagerly,sample_weight_mode,target_tensors,weighted_metrics)
keras.engine.training_v1.Model._validate_or_infer_batch_size(self,batch_size,steps,x)
keras.engine.training_v1.Model.compile(self,optimizer='rmsprop',loss=None,metrics=None,loss_weights=None,sample_weight_mode=None,weighted_metrics=None,target_tensors=None,distribute=None,**kwargs)
keras.engine.training_v1.Model.evaluate(self,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training_v1.Model.evaluate_generator(self,generator,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,verbose=0)
keras.engine.training_v1.Model.fit(self,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,max_queue_size=10,workers=1,use_multiprocessing=False,**kwargs)
keras.engine.training_v1.Model.fit_generator(self,generator,steps_per_epoch=None,epochs=1,verbose=1,callbacks=None,validation_data=None,validation_steps=None,validation_freq=1,class_weight=None,max_queue_size=10,workers=1,use_multiprocessing=False,shuffle=True,initial_epoch=0)
keras.engine.training_v1.Model.get_weights(self)
keras.engine.training_v1.Model.load_weights(self,filepath,by_name=False,skip_mismatch=False)
keras.engine.training_v1.Model.metrics(self)
keras.engine.training_v1.Model.metrics_names(self)
keras.engine.training_v1.Model.predict(self,x,batch_size=None,verbose=0,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training_v1.Model.predict_generator(self,generator,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,verbose=0)
keras.engine.training_v1.Model.predict_on_batch(self,x)
keras.engine.training_v1.Model.reset_metrics(self)
keras.engine.training_v1.Model.run_eagerly(self)
keras.engine.training_v1.Model.run_eagerly(self,value)
keras.engine.training_v1.Model.sample_weights(self)
keras.engine.training_v1.Model.test_on_batch(self,x,y=None,sample_weight=None,reset_metrics=True)
keras.engine.training_v1.Model.train_on_batch(self,x,y=None,sample_weight=None,class_weight=None,reset_metrics=True)
keras.engine.training_v1._TrainingEndpoint(self,output,output_name,loss_fn,loss_weight=None,training_target=None,output_loss_metric=None,sample_weight=None,sample_weight_mode=None)
keras.engine.training_v1._TrainingEndpoint.__init__(self,output,output_name,loss_fn,loss_weight=None,training_target=None,output_loss_metric=None,sample_weight=None,sample_weight_mode=None)
keras.engine.training_v1._TrainingEndpoint.create_training_target(self,target,run_eagerly=False)
keras.engine.training_v1._TrainingEndpoint.feed_output_shape(self)
keras.engine.training_v1._TrainingEndpoint.has_feedable_training_target(self)
keras.engine.training_v1._TrainingEndpoint.has_training_target(self)
keras.engine.training_v1._TrainingEndpoint.loss_fn(self)
keras.engine.training_v1._TrainingEndpoint.loss_name(self)
keras.engine.training_v1._TrainingEndpoint.loss_weight(self)
keras.engine.training_v1._TrainingEndpoint.loss_weight(self,value)
keras.engine.training_v1._TrainingEndpoint.output(self)
keras.engine.training_v1._TrainingEndpoint.output_loss_metric(self)
keras.engine.training_v1._TrainingEndpoint.output_loss_metric(self,value)
keras.engine.training_v1._TrainingEndpoint.output_name(self)
keras.engine.training_v1._TrainingEndpoint.populate_sample_weight(self,sample_weight,sample_weight_mode)
keras.engine.training_v1._TrainingEndpoint.sample_weight(self)
keras.engine.training_v1._TrainingEndpoint.sample_weight(self,value)
keras.engine.training_v1._TrainingEndpoint.sample_weight_mode(self)
keras.engine.training_v1._TrainingEndpoint.sample_weight_mode(self,value)
keras.engine.training_v1._TrainingEndpoint.sample_weights_mismatch(self)
keras.engine.training_v1._TrainingEndpoint.shape(self)
keras.engine.training_v1._TrainingEndpoint.should_skip_target(self)
keras.engine.training_v1._TrainingEndpoint.should_skip_target_weights(self)
keras.engine.training_v1._TrainingEndpoint.training_target(self)
keras.engine.training_v1._TrainingEndpoint.training_target(self,value)
keras.engine.training_v1._TrainingTarget(self,target,feedable=False,skip_target_weights=True)
keras.engine.training_v1._TrainingTarget.__init__(self,target,feedable=False,skip_target_weights=True)
keras.engine.training_v1._TrainingTarget.feedable(self)
keras.engine.training_v1._TrainingTarget.skip_target_weights(self)
keras.engine.training_v1._TrainingTarget.target(self)
keras.engine.training_v1._convert_scipy_sparse_tensor(value,expected_input)
keras.engine.training_v1._get_metrics_from_layers(layers)
keras.engine.training_v1._is_symbolic_tensor(x)
keras.engine.training_v1._non_none_constant_value(v)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_arrays_v1.py----------------------------------------
A:keras.engine.training_arrays_v1.steps_per_epoch->keras.engine.training_utils_v1.infer_steps_for_dataset(model, inputs, steps_per_epoch, epochs=epochs, steps_name=steps_name)
A:keras.engine.training_arrays_v1.is_dataset->isinstance(inputs, (tf.compat.v1.data.Dataset, tf.data.Dataset))
A:keras.engine.training_arrays_v1.input_iterator->_get_iterator(inputs, model._distribution_strategy)
A:keras.engine.training_arrays_v1.scope->keras.distribute.distributed_training_utils_v1.distributed_scope(strategy=model._distribution_strategy, learning_phase=1 if mode == ModeKeys.TRAIN else 0)
A:keras.engine.training_arrays_v1.ins->_prepare_feed_values(model, inputs, targets, sample_weights, mode)
A:keras.engine.training_arrays_v1.num_samples_or_steps->_get_num_samples_or_steps(ins, batch_size, steps_per_epoch)
A:keras.engine.training_arrays_v1.f->_make_execution_function(model, mode)
A:keras.engine.training_arrays_v1.validation_steps->keras.engine.training_utils_v1.infer_steps_for_dataset(model, val_inputs, validation_steps, epochs=epochs, steps_name='validation_steps')
A:keras.engine.training_arrays_v1.val_iterator->_get_iterator(val_inputs, model._distribution_strategy)
A:keras.engine.training_arrays_v1.val_inputs->_prepare_feed_values(model, val_iterator, val_targets, val_sample_weights, ModeKeys.TEST)
A:keras.engine.training_arrays_v1.callbacks->keras.callbacks.configure_callbacks(callbacks, model, do_validation=do_validation, batch_size=batch_size, epochs=epochs, steps_per_epoch=steps_per_epoch, samples=num_samples_or_steps, count_mode=count_mode, verbose=verbose, mode=mode)
A:keras.engine.training_arrays_v1.feed->_get_model_feed(model, mode)
A:keras.engine.training_arrays_v1.aggregator->keras.engine.training_utils_v1.MetricsAggregator(use_steps, num_samples=None if steps_per_epoch else num_samples_or_steps, steps=steps_per_epoch)
A:keras.engine.training_arrays_v1.initial_epoch->model._maybe_load_initial_epoch_from_ckpt(initial_epoch, mode)
A:keras.engine.training_arrays_v1.actual_inputs->ins()
A:keras.engine.training_arrays_v1.batch_outs->f(ins_batch)
A:keras.engine.training_arrays_v1.batch_logs->keras.callbacks.make_logs(model, batch_logs, batch_outs, mode)
A:keras.engine.training_arrays_v1.index_array->keras.engine.training_utils_v1.batch_shuffle(index_array, batch_size)
A:keras.engine.training_arrays_v1.batches->make_batches(num_samples_or_steps, batch_size)
A:keras.engine.training_arrays_v1.ins_batch->slice_arrays(ins, batch_ids)
A:keras.engine.training_arrays_v1.ins_batch[i]->ins_batch[i].toarray().toarray()
A:keras.engine.training_arrays_v1.epoch_logs->keras.callbacks.make_logs(model, epoch_logs, val_results, mode, prefix='val_')
A:keras.engine.training_arrays_v1.val_results->model_iteration(model, val_inputs, targets=val_targets, sample_weights=val_sample_weights, batch_size=batch_size, steps_per_epoch=validation_steps, callbacks=callbacks, verbose=0, mode=ModeKeys.TEST, validation_in_fit=True, prepared_feed_values_from_dataset=val_iterator is not None, steps_name='validation_steps')
A:keras.engine.training_arrays_v1.msg->'Train on {0} {increment}'.format(num_samples_or_steps, increment=increment)
A:keras.engine.training_arrays_v1.inputs->keras.engine.training_utils_v1.ModelInputs(inputs).as_list()
A:keras.engine.training_arrays_v1.(inputs, targets, sample_weights)->model._standardize_user_data(inputs, extract_tensors_from_dataset=True)
A:keras.engine.training_arrays_v1.targets->list(targets or [])
A:keras.engine.training_arrays_v1.sample_weights->list(sample_weights or [])
A:keras.engine.training_arrays_v1.fit_loop->functools.partial(model_iteration, mode=ModeKeys.TRAIN)
A:keras.engine.training_arrays_v1.test_loop->functools.partial(model_iteration, mode=ModeKeys.TEST, shuffle=False)
A:keras.engine.training_arrays_v1.predict_loop->functools.partial(model_iteration, mode=ModeKeys.PREDICT, shuffle=False)
A:keras.engine.training_arrays_v1.batch_size->model._validate_or_infer_batch_size(batch_size, steps, x)
A:keras.engine.training_arrays_v1.(x, y, sample_weights)->model._standardize_user_data(x, y, sample_weight=sample_weight, batch_size=batch_size, check_steps=True, steps_name='steps', steps=steps)
A:keras.engine.training_arrays_v1.(val_x, val_y, val_sample_weights)->model._prepare_validation_data(validation_data, batch_size, validation_steps)
A:keras.engine.training_arrays_v1.(x, y, sample_weights, val_x, val_y, val_sample_weights)->keras.engine.training_utils_v1.split_training_and_validation_data(x, y, sample_weights, validation_split)
A:keras.engine.training_arrays_v1.(x, _, _)->model._standardize_user_data(x, check_steps=True, steps_name='steps', steps=steps)
keras.engine.training_arrays_v1.ArrayLikeTrainingLoop(training_utils_v1.TrainingLoop)
keras.engine.training_arrays_v1.ArrayLikeTrainingLoop.evaluate(self,model,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,**kwargs)
keras.engine.training_arrays_v1.ArrayLikeTrainingLoop.fit(self,model,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,**kwargs)
keras.engine.training_arrays_v1.ArrayLikeTrainingLoop.predict(self,model,x,batch_size=None,verbose=0,steps=None,callbacks=None,**kwargs)
keras.engine.training_arrays_v1._get_iterator(inputs,distribution_strategy=None)
keras.engine.training_arrays_v1._get_model_feed(model,mode)
keras.engine.training_arrays_v1._get_num_samples_or_steps(ins,batch_size,steps_per_epoch)
keras.engine.training_arrays_v1._make_execution_function(model,mode)
keras.engine.training_arrays_v1._prepare_feed_values(model,inputs,targets,sample_weights,mode)
keras.engine.training_arrays_v1._print_train_info(num_samples_or_steps,val_samples_or_steps,is_dataset)
keras.engine.training_arrays_v1._reinitialize_iterator(iterator,distribution_strategy=None)
keras.engine.training_arrays_v1._update_sample_weight_mode(model,mode,inputs)
keras.engine.training_arrays_v1.model_iteration(model,inputs,targets=None,sample_weights=None,batch_size=None,epochs=1,verbose=1,callbacks=None,val_inputs=None,val_targets=None,val_sample_weights=None,shuffle=True,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,mode=ModeKeys.TRAIN,validation_in_fit=False,prepared_feed_values_from_dataset=False,steps_name='steps',**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_eager_v1.py----------------------------------------
A:keras.engine.training_eager_v1.loss->loss_fn(targets, outputs)
A:keras.engine.training_eager_v1.outputs->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.training_eager_v1.targets->tensorflow.compat.v2.nest.flatten(targets)
A:keras.engine.training_eager_v1.metric_results->model._handle_metrics(outputs, targets=targets, sample_weights=sample_weights, masks=masks, return_weighted_and_unweighted_metrics=True, skip_target_masks=model._prepare_skip_target_masks())
A:keras.engine.training_eager_v1.inputs->keras.engine.training_utils_v1.cast_to_model_input_dtypes(inputs, model)
A:keras.engine.training_eager_v1.outs->tensorflow.compat.v2.nest.flatten(outs)
A:keras.engine.training_eager_v1.mask->tensorflow.compat.v2.cast(mask, outs[i].dtype)
A:keras.engine.training_eager_v1.weights->tensorflow.compat.v2.cast(weights, outs[i].dtype)
A:keras.engine.training_eager_v1.(mask, _, weights)->keras.utils.losses_utils.squeeze_or_expand_dimensions(mask, sample_weight=weights)
A:keras.engine.training_eager_v1.per_sample_losses->loss_fn.call(targets[i], outs[i])
A:keras.engine.training_eager_v1.weighted_losses->keras.utils.losses_utils.compute_weighted_loss(per_sample_losses, sample_weight=weights, reduction=losses_utils.ReductionV2.NONE)
A:keras.engine.training_eager_v1.output_loss->keras.utils.losses_utils.scale_loss_for_distribution(output_loss)
A:keras.engine.training_eager_v1.(outs, total_loss, output_losses, masks)->_model_loss(model, inputs, targets, sample_weights=sample_weights, training=False, output_loss_metrics=output_loss_metrics)
A:keras.engine.training_eager_v1.scaled_total_loss->model.optimizer.get_scaled_loss(total_loss)
A:keras.engine.training_eager_v1.grads->model.optimizer.get_unscaled_gradients(grads)
A:keras.engine.training_eager_v1.metrics_results->_eager_metrics_fn(model, outs, targets, sample_weights=sample_weights, masks=masks)
A:keras.engine.training_eager_v1.total_loss->tensorflow.compat.v2.nest.flatten(total_loss)
keras.engine.training_eager_v1._eager_loss_fn(outputs,targets,loss_fn,output_name)
keras.engine.training_eager_v1._eager_metrics_fn(model,outputs,targets,sample_weights=None,masks=None)
keras.engine.training_eager_v1._model_loss(model,inputs,targets,output_loss_metrics=None,sample_weights=None,training=False)
keras.engine.training_eager_v1._process_single_batch(model,inputs,targets,output_loss_metrics=None,sample_weights=None,training=False)
keras.engine.training_eager_v1.test_on_batch(model,inputs,targets,sample_weights=None,output_loss_metrics=None)
keras.engine.training_eager_v1.train_on_batch(model,inputs,targets,sample_weights=None,output_loss_metrics=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/data_adapter.py----------------------------------------
A:keras.engine.data_adapter.keras_data_adapter_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/data_adapters', 'keras data adapter usage', 'method')
A:keras.engine.data_adapter.flat_inputs->tensorflow.compat.v2.nest.flatten(x)
A:keras.engine.data_adapter.tensor_types->_get_tensor_types()
A:keras.engine.data_adapter.(x, y, sample_weights)->_process_tensorlike((x, y, sample_weights))
A:keras.engine.data_adapter.sample_weight_modes->tensorflow.compat.v2.nest.pack_sequence_as(target_structure, tf.nest.flatten(sample_weight_modes))
A:keras.engine.data_adapter.(sample_weights, _, _)->keras.engine.training_utils.handle_partial_sample_weights(y, sample_weights, sample_weight_modes, check_all_flat=True)
A:keras.engine.data_adapter.inputs->tensorflow.compat.v2.nest.map_structure(_convert_single_tensor, inputs)
A:keras.engine.data_adapter.num_samples->set((int(i.shape[0]) for i in tf.nest.flatten(data)))
A:keras.engine.data_adapter.self._size->len(x)
A:keras.engine.data_adapter.num_full_batches->int(num_samples // batch_size)
A:keras.engine.data_adapter.shuffle->shuffle.lower().lower()
A:keras.engine.data_adapter.indices_dataset->indices_dataset.flat_map(slice_batch_indices).flat_map(slice_batch_indices)
A:keras.engine.data_adapter.indices->numpy.concatenate((np.expand_dims(row, axis=1), np.expand_dims(col, axis=1)), axis=1)
A:keras.engine.data_adapter.first_k_indices->tensorflow.compat.v2.reshape(first_k_indices, [num_full_batches, batch_size])
A:keras.engine.data_adapter.flat_dataset->flat_dataset.shuffle(1024).repeat(epochs).shuffle(1024).repeat(epochs)
A:keras.engine.data_adapter.index_remainder->tensorflow.compat.v2.data.Dataset.from_tensors(tf.slice(indices, [num_in_full_batch], [self._partial_batch_size]))
A:keras.engine.data_adapter.dataset->tensorflow.compat.v2.distribute.get_strategy().experimental_distribute_dataset(dataset)
A:keras.engine.data_adapter.options->tensorflow.compat.v2.data.Options()
A:keras.engine.data_adapter.shape->list(t.shape)
A:keras.engine.data_adapter.flat_out->tensorflow.compat.v2.py_function(py_method, [indices], flat_dtypes)
A:keras.engine.data_adapter.handles_x->ListsOfScalarsDataAdapter._is_list_of_scalars(x)
A:keras.engine.data_adapter.handles_y->ListsOfScalarsDataAdapter._is_list_of_scalars(y)
A:keras.engine.data_adapter.x->tensorflow.compat.v2.distribute.get_strategy().experimental_distribute_dataset(x)
A:keras.engine.data_adapter.y->numpy.asarray(y)
A:keras.engine.data_adapter.sample_weights->numpy.asarray(sample_weights)
A:keras.engine.data_adapter.self._internal_adapter->TensorLikeDataAdapter(x, y=y, sample_weights=sample_weights, sample_weight_modes=sample_weight_modes, batch_size=batch_size, shuffle=shuffle, **kwargs)
A:keras.engine.data_adapter.size->tensorflow.compat.v2.data.experimental.cardinality(dataset)
A:keras.engine.data_adapter.(peek, x)->self._peek_and_restore(x)
A:keras.engine.data_adapter.peek->next(x)
A:keras.engine.data_adapter.(concrete_x, _, _)->unpack_x_y_sample_weight(peek)
A:keras.engine.data_adapter.self._first_batch_size->int(tf.nest.flatten(peek)[0].shape[0])
A:keras.engine.data_adapter.output_signature->tensorflow.compat.v2.nest.map_structure(_get_tensor_spec, peek)
A:keras.engine.data_adapter.generator_fn->self._handle_multiprocessing(x, workers, use_multiprocessing, max_queue_size)
A:keras.engine.data_adapter.(x, y, sample_weight)->_process_tensorlike((x, y, sample_weight))
A:keras.engine.data_adapter.data->data.astype(backend.floatx()).astype(backend.floatx())
A:keras.engine.data_adapter.enqueuer->keras.utils.data_utils.GeneratorEnqueuer(x, use_multiprocessing=use_multiprocessing)
A:keras.engine.data_adapter.self._enqueuer->keras.utils.data_utils.OrderedEnqueuer(x, use_multiprocessing=use_multiprocessing, shuffle=self._shuffle_sequence)
A:keras.engine.data_adapter.order->list(order)
A:keras.engine.data_adapter.key_types->set((_type_name(key) for key in x.keys()))
A:keras.engine.data_adapter.val_types->set((_type_name(key) for key in x.values()))
A:keras.engine.data_adapter.types->set((_type_name(val) for val in x))
A:keras.engine.data_adapter.dtype->keras.backend.floatx()
A:keras.engine.data_adapter.target_str->str(tf.nest.map_structure(lambda _: '...', target_structure))
A:keras.engine.data_adapter.mode_str->str(tf.nest.map_structure(lambda _: '...', sample_weight_modes))
A:keras.engine.data_adapter.self._steps_per_execution->tensorflow.compat.v2.Variable(1)
A:keras.engine.data_adapter.adapter_cls->select_data_adapter(x, y)
A:keras.engine.data_adapter.self._adapter->adapter_cls(x, y, batch_size=batch_size, steps=steps_per_epoch, epochs=epochs - initial_epoch, sample_weights=sample_weight, shuffle=shuffle, max_queue_size=max_queue_size, workers=workers, use_multiprocessing=use_multiprocessing, distribution_strategy=tf.distribute.get_strategy(), model=model)
A:keras.engine.data_adapter.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.data_adapter.self._inferred_steps->self._infer_steps(steps_per_epoch, dataset)
A:keras.engine.data_adapter.data_iterator->iter(self._dataset)
A:keras.engine.data_adapter.original_value->self._steps_per_execution.numpy().item()
A:keras.engine.data_adapter.original_spe->self._steps_per_execution.numpy().item()
A:keras.engine.data_adapter.adapter_steps->self._adapter.get_size()
A:keras.engine.data_adapter.data_adapter_cls->select_data_adapter(x, y)
A:keras.engine.data_adapter.self._dataset->self._model._cluster_coordinator.create_per_worker_dataset(x)
A:keras.engine.data_adapter.class_ids->list(sorted(class_weight.keys()))
A:keras.engine.data_adapter.expected_class_ids->list(range(len(class_ids)))
A:keras.engine.data_adapter.error_msg->'Data is expected to be in format `x`, `(x,)`, `(x, y)`, or `(x, y, sample_weight)`, found: {}'.format(data)
A:keras.engine.data_adapter.class_weight_tensor->tensorflow.compat.v2.convert_to_tensor([class_weight[int(c)] for c in class_ids])
A:keras.engine.data_adapter.(x, y, sw)->unpack_x_y_sample_weight(data)
A:keras.engine.data_adapter.y_classes->tensorflow.compat.v2.__internal__.smart_cond.smart_cond(y.shape.rank == 2 and backend.shape(y)[1] > 1, lambda : backend.argmax(y, axis=1), lambda : tf.cast(backend.reshape(y, (-1,)), tf.int64))
A:keras.engine.data_adapter.cw->tensorflow.compat.v2.cast(cw, sw.dtype)
A:keras.engine.data_adapter.flat_arrays->tensorflow.compat.v2.nest.flatten(arrays)
A:keras.engine.data_adapter.batch_dim->int(first_non_none.shape[0])
A:keras.engine.data_adapter.split_at->int(math.floor(batch_dim * (1.0 - validation_split)))
A:keras.engine.data_adapter.train_arrays->tensorflow.compat.v2.nest.map_structure(functools.partial(_split, start=0, end=split_at), arrays)
A:keras.engine.data_adapter.val_arrays->tensorflow.compat.v2.nest.map_structure(functools.partial(_split, start=split_at, end=batch_dim), arrays)
A:keras.engine.data_adapter.sparse_coo->t.tocoo()
keras.engine.data_adapter.CompositeTensorDataAdapter(self,x,y=None,sample_weights=None,sample_weight_modes=None,batch_size=None,steps=None,shuffle=False,**kwargs)
keras.engine.data_adapter.CompositeTensorDataAdapter.__init__(self,x,y=None,sample_weights=None,sample_weight_modes=None,batch_size=None,steps=None,shuffle=False,**kwargs)
keras.engine.data_adapter.CompositeTensorDataAdapter.batch_size(self)
keras.engine.data_adapter.CompositeTensorDataAdapter.can_handle(x,y=None)
keras.engine.data_adapter.CompositeTensorDataAdapter.get_dataset(self)
keras.engine.data_adapter.CompositeTensorDataAdapter.get_size(self)
keras.engine.data_adapter.CompositeTensorDataAdapter.has_partial_batch(self)
keras.engine.data_adapter.CompositeTensorDataAdapter.partial_batch_size(self)
keras.engine.data_adapter.CompositeTensorDataAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.DataAdapter(self,x,y=None,**kwargs)
keras.engine.data_adapter.DataAdapter.__init__(self,x,y=None,**kwargs)
keras.engine.data_adapter.DataAdapter.batch_size(self)
keras.engine.data_adapter.DataAdapter.can_handle(x,y=None)
keras.engine.data_adapter.DataAdapter.get_dataset(self)
keras.engine.data_adapter.DataAdapter.get_samples(self)
keras.engine.data_adapter.DataAdapter.get_size(self)
keras.engine.data_adapter.DataAdapter.has_partial_batch(self)
keras.engine.data_adapter.DataAdapter.on_epoch_end(self)
keras.engine.data_adapter.DataAdapter.partial_batch_size(self)
keras.engine.data_adapter.DataAdapter.representative_batch_size(self)
keras.engine.data_adapter.DataAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.DataHandler(self,x,y=None,sample_weight=None,batch_size=None,steps_per_epoch=None,initial_epoch=0,epochs=1,shuffle=False,class_weight=None,max_queue_size=10,workers=1,use_multiprocessing=False,model=None,steps_per_execution=None,distribute=True)
keras.engine.data_adapter.DataHandler.__init__(self,x,y=None,sample_weight=None,batch_size=None,steps_per_epoch=None,initial_epoch=0,epochs=1,shuffle=False,class_weight=None,max_queue_size=10,workers=1,use_multiprocessing=False,model=None,steps_per_execution=None,distribute=True)
keras.engine.data_adapter.DataHandler._configure_dataset_and_inferred_steps(self,strategy,x,steps_per_epoch,class_weight,distribute)
keras.engine.data_adapter.DataHandler._infer_steps(self,steps,dataset)
keras.engine.data_adapter.DataHandler._log_indefinite_training_warning(self)
keras.engine.data_adapter.DataHandler._samples(self)
keras.engine.data_adapter.DataHandler._truncate_execution_to_epoch(self)
keras.engine.data_adapter.DataHandler._validate_data_handler(self)
keras.engine.data_adapter.DataHandler.catch_stop_iteration(self)
keras.engine.data_adapter.DataHandler.enumerate_epochs(self)
keras.engine.data_adapter.DataHandler.inferred_steps(self)
keras.engine.data_adapter.DataHandler.should_sync(self)
keras.engine.data_adapter.DataHandler.step_increment(self)
keras.engine.data_adapter.DataHandler.steps(self)
keras.engine.data_adapter.DataHandler.sync(self)
keras.engine.data_adapter.DatasetAdapter(self,x,y=None,sample_weights=None,steps=None,**kwargs)
keras.engine.data_adapter.DatasetAdapter.__init__(self,x,y=None,sample_weights=None,steps=None,**kwargs)
keras.engine.data_adapter.DatasetAdapter._validate_args(self,y,sample_weights,steps)
keras.engine.data_adapter.DatasetAdapter.batch_size(self)
keras.engine.data_adapter.DatasetAdapter.can_handle(x,y=None)
keras.engine.data_adapter.DatasetAdapter.get_dataset(self)
keras.engine.data_adapter.DatasetAdapter.get_size(self)
keras.engine.data_adapter.DatasetAdapter.has_partial_batch(self)
keras.engine.data_adapter.DatasetAdapter.partial_batch_size(self)
keras.engine.data_adapter.DatasetAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.DatasetCreatorAdapter(self,x,y,steps=None,distribution_strategy=None,**kwargs)
keras.engine.data_adapter.DatasetCreatorAdapter.__init__(self,x,y,steps=None,distribution_strategy=None,**kwargs)
keras.engine.data_adapter.DatasetCreatorAdapter.batch_size(self)
keras.engine.data_adapter.DatasetCreatorAdapter.can_handle(x,y=None)
keras.engine.data_adapter.DatasetCreatorAdapter.get_dataset(self)
keras.engine.data_adapter.DatasetCreatorAdapter.get_size(self)
keras.engine.data_adapter.DatasetCreatorAdapter.has_partial_batch(self)
keras.engine.data_adapter.DatasetCreatorAdapter.partial_batch_size(self)
keras.engine.data_adapter.DatasetCreatorAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.GeneratorDataAdapter(self,x,y=None,sample_weights=None,workers=1,use_multiprocessing=False,max_queue_size=10,model=None,**kwargs)
keras.engine.data_adapter.GeneratorDataAdapter.__init__(self,x,y=None,sample_weights=None,workers=1,use_multiprocessing=False,max_queue_size=10,model=None,**kwargs)
keras.engine.data_adapter.GeneratorDataAdapter._handle_multiprocessing(self,x,workers,use_multiprocessing,max_queue_size)
keras.engine.data_adapter.GeneratorDataAdapter._peek_and_restore(x)
keras.engine.data_adapter.GeneratorDataAdapter._standardize_batch(self,data)
keras.engine.data_adapter.GeneratorDataAdapter.batch_size(self)
keras.engine.data_adapter.GeneratorDataAdapter.can_handle(x,y=None)
keras.engine.data_adapter.GeneratorDataAdapter.get_dataset(self)
keras.engine.data_adapter.GeneratorDataAdapter.get_size(self)
keras.engine.data_adapter.GeneratorDataAdapter.has_partial_batch(self)
keras.engine.data_adapter.GeneratorDataAdapter.partial_batch_size(self)
keras.engine.data_adapter.GeneratorDataAdapter.representative_batch_size(self)
keras.engine.data_adapter.GeneratorDataAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.GenericArrayLikeDataAdapter(self,*args,**kwargs)
keras.engine.data_adapter.GenericArrayLikeDataAdapter.__init__(self,*args,**kwargs)
keras.engine.data_adapter.GenericArrayLikeDataAdapter.can_handle(x,y=None)
keras.engine.data_adapter.GenericArrayLikeDataAdapter.slice_inputs(self,indices_dataset,inputs)
keras.engine.data_adapter.KerasSequenceAdapter(self,x,y=None,sample_weights=None,shuffle=False,workers=1,use_multiprocessing=False,max_queue_size=10,model=None,**kwargs)
keras.engine.data_adapter.KerasSequenceAdapter.__init__(self,x,y=None,sample_weights=None,shuffle=False,workers=1,use_multiprocessing=False,max_queue_size=10,model=None,**kwargs)
keras.engine.data_adapter.KerasSequenceAdapter._handle_multiprocessing(self,x,workers,use_multiprocessing,max_queue_size)
keras.engine.data_adapter.KerasSequenceAdapter._peek_and_restore(x)
keras.engine.data_adapter.KerasSequenceAdapter.can_handle(x,y=None)
keras.engine.data_adapter.KerasSequenceAdapter.get_size(self)
keras.engine.data_adapter.KerasSequenceAdapter.on_epoch_end(self)
keras.engine.data_adapter.KerasSequenceAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.ListsOfScalarsDataAdapter(self,x,y=None,sample_weights=None,sample_weight_modes=None,batch_size=None,shuffle=False,**kwargs)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.__init__(self,x,y=None,sample_weights=None,sample_weight_modes=None,batch_size=None,shuffle=False,**kwargs)
keras.engine.data_adapter.ListsOfScalarsDataAdapter._is_list_of_scalars(inp)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.batch_size(self)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.can_handle(x,y=None)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.get_dataset(self)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.get_size(self)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.has_partial_batch(self)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.partial_batch_size(self)
keras.engine.data_adapter.ListsOfScalarsDataAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.TensorLikeDataAdapter(self,x,y=None,sample_weights=None,sample_weight_modes=None,batch_size=None,epochs=1,steps=None,shuffle=False,**kwargs)
keras.engine.data_adapter.TensorLikeDataAdapter.__init__(self,x,y=None,sample_weights=None,sample_weight_modes=None,batch_size=None,epochs=1,steps=None,shuffle=False,**kwargs)
keras.engine.data_adapter.TensorLikeDataAdapter.batch_size(self)
keras.engine.data_adapter.TensorLikeDataAdapter.can_handle(x,y=None)
keras.engine.data_adapter.TensorLikeDataAdapter.get_dataset(self)
keras.engine.data_adapter.TensorLikeDataAdapter.get_size(self)
keras.engine.data_adapter.TensorLikeDataAdapter.has_partial_batch(self)
keras.engine.data_adapter.TensorLikeDataAdapter.partial_batch_size(self)
keras.engine.data_adapter.TensorLikeDataAdapter.should_recreate_iterator(self)
keras.engine.data_adapter.TensorLikeDataAdapter.slice_inputs(self,indices_dataset,inputs)
keras.engine.data_adapter._ClusterCoordinatorDataHandler(self,x,y=None,**kwargs)
keras.engine.data_adapter._ClusterCoordinatorDataHandler.__init__(self,x,y=None,**kwargs)
keras.engine.data_adapter._ClusterCoordinatorDataHandler._configure_dataset_and_inferred_steps(self,strategy,x,steps_per_epoch,class_weight,distribute)
keras.engine.data_adapter._ClusterCoordinatorDataHandler._convert_to_dataset_creator(self,x,y,**kwargs)
keras.engine.data_adapter._ClusterCoordinatorDataHandler.sync(self)
keras.engine.data_adapter._check_data_cardinality(data)
keras.engine.data_adapter._get_tensor_types()
keras.engine.data_adapter._is_distributed_dataset(ds)
keras.engine.data_adapter._is_pandas_series(x)
keras.engine.data_adapter._is_scipy_sparse(x)
keras.engine.data_adapter._make_class_weight_map_fn(class_weight)
keras.engine.data_adapter._process_tensorlike(inputs)
keras.engine.data_adapter._scipy_sparse_to_sparse_tensor(t)
keras.engine.data_adapter._type_name(x)
keras.engine.data_adapter.broadcast_sample_weight_modes(target_structure,sample_weight_modes)
keras.engine.data_adapter.get_data_handler(*args,**kwargs)
keras.engine.data_adapter.is_none_or_empty(inputs)
keras.engine.data_adapter.pack_x_y_sample_weight(x,y=None,sample_weight=None)
keras.engine.data_adapter.select_data_adapter(x,y)
keras.engine.data_adapter.single_batch_iterator(strategy,x,y=None,sample_weight=None,class_weight=None)
keras.engine.data_adapter.train_validation_split(arrays,validation_split)
keras.engine.data_adapter.unpack_x_y_sample_weight(data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/base_preprocessing_layer.py----------------------------------------
A:keras.engine.base_preprocessing_layer.keras_kpl_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/layers/preprocessing', 'keras preprocessing layers usage', 'method')
A:keras.engine.base_preprocessing_layer.data->next(iterator)
A:keras.engine.base_preprocessing_layer.adapt_fn->tensorflow.compat.v2.function(adapt_fn)
A:keras.engine.base_preprocessing_layer.data_handler->keras.engine.data_adapter.DataHandler(data, batch_size=batch_size, steps_per_epoch=steps, epochs=1, steps_per_execution=self._steps_per_execution, distribute=False)
A:keras.engine.base_preprocessing_layer.self._adapt_function->self.make_adapt_function()
A:keras.engine.base_preprocessing_layer.self._steps_per_execution->tensorflow.compat.v2.Variable(steps_per_execution, dtype='int64', aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
A:keras.engine.base_preprocessing_layer.data_shape_nones->tuple([None] * len(data.shape))
A:keras.engine.base_preprocessing_layer.batch_input_shape->getattr(self, '_batch_input_shape', None)
A:keras.engine.base_preprocessing_layer.error_msg->'Detected a call to `PreprocessingLayer.{method_name}` inside a `tf.function`. `PreprocessingLayer.{method_name} is a high-level endpoint that manages its own `tf.function`. Please move the call to `PreprocessingLayer.{method_name}` outside of all enclosing `tf.function`s. Note that you can call a `PreprocessingLayer` directly on `Tensor`s inside a `tf.function` like: `layer(x)`, or update its state like: `layer.update_state(x)`.'.format(method_name=method_name)
keras.engine.base_preprocessing_layer.PreprocessingLayer(self,**kwargs)
keras.engine.base_preprocessing_layer.PreprocessingLayer.__init__(self,**kwargs)
keras.engine.base_preprocessing_layer.PreprocessingLayer._adapt_maybe_build(self,data)
keras.engine.base_preprocessing_layer.PreprocessingLayer._configure_steps_per_execution(self,steps_per_execution)
keras.engine.base_preprocessing_layer.PreprocessingLayer._reset_state_wrapper(self)
keras.engine.base_preprocessing_layer.PreprocessingLayer.adapt(self,data,batch_size=None,steps=None)
keras.engine.base_preprocessing_layer.PreprocessingLayer.compile(self,run_eagerly=None,steps_per_execution=None)
keras.engine.base_preprocessing_layer.PreprocessingLayer.finalize_state(self)
keras.engine.base_preprocessing_layer.PreprocessingLayer.is_adapted(self)
keras.engine.base_preprocessing_layer.PreprocessingLayer.make_adapt_function(self)
keras.engine.base_preprocessing_layer.PreprocessingLayer.reset_state(self)
keras.engine.base_preprocessing_layer.PreprocessingLayer.update_state(self,data)
keras.engine.base_preprocessing_layer._disallow_inside_tf_function(method_name)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training.py----------------------------------------
A:keras.engine.training._TF_MODULE_IGNORED_PROPERTIES->frozenset(itertools.chain(('_train_counter', '_test_counter', '_predict_counter', '_steps_per_execution'), base_layer.Layer._TF_MODULE_IGNORED_PROPERTIES))
A:keras.engine.training.self._distribution_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.training.self._checkpoint->tensorflow.compat.v2.train.Checkpoint(root=weakref.ref(self))
A:keras.engine.training.self._layout_map->keras.dtensor.layout_map.get_current_layout_map()
A:keras.engine.training.self._train_counter->tensorflow.compat.v2.Variable(0, dtype='int64', aggregation=agg)
A:keras.engine.training.self._test_counter->tensorflow.compat.v2.Variable(0, dtype='int64', aggregation=agg)
A:keras.engine.training.self._predict_counter->tensorflow.compat.v2.Variable(0, dtype='int64', aggregation=agg)
A:keras.engine.training.new->deserializer(*serialized)
A:keras.engine.training.(deserializer, serialized, *rest)->super(Model, self).__reduce__()
A:keras.engine.training.state->copy.deepcopy(rest[0], memo=memo)
A:keras.engine.training.graph->keras.backend.get_graph()
A:keras.engine.training.input_shape->tuple(input_shape)
A:keras.engine.training.x->x.with_options(options).with_options(options)
A:keras.engine.training.copied_args->tensorflow.compat.v2.nest.map_structure(_convert_to_graph_inputs, copied_args)
A:keras.engine.training.copied_kwargs->tensorflow.compat.v2.nest.map_structure(_convert_to_graph_inputs, copied_kwargs)
A:keras.engine.training.(inputs, copied_args, copied_kwargs)->self._split_out_first_arg(copied_args, copied_kwargs)
A:keras.engine.training.inputs->tensorflow.compat.v2.nest.map_structure(_convert_to_graph_inputs, inputs)
A:keras.engine.training.steps_per_execution->kwargs.pop('experimental_steps_per_execution')
A:keras.engine.training.from_serialized->kwargs.pop('from_serialized', False)
A:keras.engine.training.self.optimizer->self._get_optimizer(optimizer)
A:keras.engine.training.self.compiled_loss->keras.engine.compile_utils.LossesContainer(loss, loss_weights, output_names=self.output_names)
A:keras.engine.training.self.compiled_metrics->keras.engine.compile_utils.MetricsContainer(metrics, weighted_metrics, output_names=self.output_names, from_serialized=from_serialized)
A:keras.engine.training.opt->keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer(opt)
A:keras.engine.training.self._compiled_trainable_state->self._get_trainable_state()
A:keras.engine.training.self._steps_per_execution->tensorflow.compat.v2.Variable(steps_per_execution, dtype='int64', aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
A:keras.engine.training.(x, y, sample_weight)->keras.engine.data_adapter.unpack_x_y_sample_weight(data)
A:keras.engine.training.y_pred->self(x, training=False)
A:keras.engine.training.loss->self.compute_loss(x, y, y_pred, sample_weight)
A:keras.engine.training.result->metric.result()
A:keras.engine.training.outputs->tensorflow.compat.v2.nest.flatten(outputs, expand_composites=True)
A:keras.engine.training.run_step->tensorflow.compat.v2.function(run_step, jit_compile=True, reduce_retracing=True)
A:keras.engine.training.data->next(iterator)
A:keras.engine.training.train_function->tensorflow.compat.v2.function(train_function, reduce_retracing=True)
A:keras.engine.training.verbose->_get_verbosity(verbose, self.distribute_strategy)
A:keras.engine.training.((x, y, sample_weight), validation_data)->keras.engine.data_adapter.train_validation_split((x, y, sample_weight), validation_split=validation_split)
A:keras.engine.training.(val_x, val_y, val_sample_weight)->keras.engine.data_adapter.unpack_x_y_sample_weight(validation_data)
A:keras.engine.training.self._cluster_coordinator->tensorflow.compat.v2.distribute.experimental.coordinator.ClusterCoordinator(self.distribute_strategy)
A:keras.engine.training.data_handler->keras.engine.data_adapter.get_data_handler(x=x, batch_size=batch_size, steps_per_epoch=steps, initial_epoch=0, epochs=1, max_queue_size=max_queue_size, workers=workers, use_multiprocessing=use_multiprocessing, model=self, steps_per_execution=self._steps_per_execution)
A:keras.engine.training.callbacks->keras.callbacks.CallbackList(callbacks, add_history=True, add_progbar=verbose != 0, model=self, verbose=verbose, epochs=1, steps=data_handler.inferred_steps)
A:keras.engine.training.self.train_function->self.make_train_function()
A:keras.engine.training.data_handler._initial_epoch->self._maybe_load_initial_epoch_from_ckpt(initial_epoch)
A:keras.engine.training.data_handler._initial_step->self._maybe_load_initial_step_from_ckpt()
A:keras.engine.training.tmp_logs->self.test_function(iterator)
A:keras.engine.training.logs->keras.utils.tf_utils.sync_to_numpy_or_python_type(logs)
A:keras.engine.training.epoch_logs->copy.copy(logs)
A:keras.engine.training.self._eval_data_handler->keras.engine.data_adapter.get_data_handler(x=val_x, y=val_y, sample_weight=val_sample_weight, batch_size=validation_batch_size or batch_size, steps_per_epoch=validation_steps, initial_epoch=0, epochs=1, max_queue_size=max_queue_size, workers=workers, use_multiprocessing=use_multiprocessing, model=self, steps_per_execution=self._steps_per_execution)
A:keras.engine.training.val_logs->self.evaluate(x=val_x, y=val_y, sample_weight=val_sample_weight, batch_size=validation_batch_size or batch_size, steps=validation_steps, callbacks=callbacks, max_queue_size=max_queue_size, workers=workers, use_multiprocessing=use_multiprocessing, return_dict=True, _use_cached_eval_dataset=True)
A:keras.engine.training.test_function->tensorflow.compat.v2.function(test_function, reduce_retracing=True)
A:keras.engine.training.use_cached_eval_dataset->kwargs.pop('_use_cached_eval_dataset', False)
A:keras.engine.training.self.test_function->self.make_test_function()
A:keras.engine.training.(x, _, _)->keras.engine.data_adapter.unpack_x_y_sample_weight(data)
A:keras.engine.training.step_outputs->step_function(self, iterator)
A:keras.engine.training.predict_function->tensorflow.compat.v2.function(predict_function, reduce_retracing=True)
A:keras.engine.training.options->tensorflow.compat.v2.data.Options()
A:keras.engine.training.self.predict_function->self.make_predict_function()
A:keras.engine.training.tmp_batch_outputs->self.predict_function(iterator)
A:keras.engine.training.all_outputs->tensorflow.compat.v2.__internal__.nest.map_structure_up_to(batch_outputs, potentially_ragged_concat, outputs)
A:keras.engine.training.iterator->keras.engine.data_adapter.single_batch_iterator(self.distribute_strategy, x)
A:keras.engine.training.filepath->keras.utils.io_utils.path_to_string(filepath)
A:keras.engine.training.filepath_is_h5->keras.saving.saving_utils.is_hdf5_filepath(filepath)
A:keras.engine.training.user_format->save_format.lower().strip()
A:keras.engine.training.proceed->keras.utils.io_utils.ask_to_proceed_with_overwrite(check_filepath)
A:keras.engine.training.(filepath, save_format)->_detect_save_format(filepath)
A:keras.engine.training.status->self._checkpoint.read(filepath, options)
A:keras.engine.training.session->keras.backend.get_session()
A:keras.engine.training.config->self.get_config()
A:keras.engine.training.(inputs, outputs, layers)->keras.engine.functional.reconstruct_from_config(config, custom_objects)
A:keras.engine.training.model->cls(inputs=inputs, outputs=outputs, name=config.get('name'))
A:keras.engine.training.model_config->self._updated_config()
A:keras.engine.training.input_names->keras.engine.compile_utils.create_pseudo_input_names(inputs)
A:keras.engine.training.flat_inputs->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.training.inputs_spec->tensorflow.compat.v2.nest.pack_sequence_as(inputs, inputs_spec)
A:keras.engine.training.self._build_input_shape->tensorflow.compat.v2.nest.map_structure(lambda x: None if x is None else x.shape, inputs_spec)
A:keras.engine.training.distribute_arg->kwargs.pop('distribute', None)
A:keras.engine.training.target_tensor_arg->kwargs.pop('target_tensors', None)
A:keras.engine.training.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.training.children->super(Model, self)._trackable_children(save_type, **kwargs)
A:keras.engine.training.non_batch_shapes->tensorflow.compat.v2.stack([tf.shape(tensor)[1:] for tensor in tensors])
A:keras.engine.training.constant_dims->tensorflow.compat.v2.math.reduce_all(non_batch_shapes == non_batch_shapes[:1], axis=0)
A:keras.engine.training.constant_inner_dimensions->tensorflow.compat.v2.math.reduce_all(non_batch_shapes == non_batch_shapes[:1], axis=0).numpy().tolist()[::-1].index(False)
A:keras.engine.training.replicas->tensorflow.compat.v2.split(replicas, num_or_size_splits=all_shapes, num=strategy.num_replicas_in_sync)
A:keras.engine.training.shapes->tensorflow.compat.v2.concat([tf.expand_dims(tf.shape(single_value)[0], axis=0) for single_value in v.values], axis=0)
A:keras.engine.training.all_shapes->tensorflow.compat.v2.distribute.get_strategy().gather(tf.expand_dims(tf.shape(v)[0], axis=0), axis=0)
A:keras.engine.training.num_replicas_per_worker->len(strategy.extended.worker_devices)
A:keras.engine.training.error_msg->'Detected a call to `Model.{method_name}` inside a `tf.function`. `Model.{method_name} is a high-level endpoint that manages its own `tf.function`. Please move the call to `Model.{method_name}` outside of all enclosing `tf.function`s. Note that you can call a `Model` directly on `Tensor`s inside a `tf.function` like: `model(x)`.'.format(method_name=method_name)
A:keras.engine.training.ckpt_path->os.path.join(filepath, tf.saved_model.VARIABLES_DIRECTORY, tf.saved_model.VARIABLES_FILENAME)
A:keras.engine.training.cls.__bases__->tuple((inject_functional_model_class(base) for base in cls.__bases__))
keras.Model(self,*args,**kwargs)
keras.Model.__copy__(self)
keras.Model.__deepcopy__(self,memo)
keras.Model.__reduce__(self)
keras.Model.__setattr__(self,name,value)
keras.Model._assert_compile_was_called(self)
keras.Model._assert_weights_created(self)
keras.Model._check_call_args(self,method_name)
keras.Model._check_sample_weight_warning(self,x,sample_weight)
keras.Model._compile_was_called(self)
keras.Model._configure_steps_per_execution(self,steps_per_execution)
keras.Model._get_callback_model(self)
keras.Model._get_compile_args(self,user_metrics=True)
keras.Model._get_optimizer(self,optimizer)
keras.Model._in_multi_worker_mode(self)
keras.Model._init_batch_counters(self)
keras.Model._maybe_load_initial_epoch_from_ckpt(self,initial_epoch)
keras.Model._maybe_load_initial_step_from_ckpt(self)
keras.Model._reset_compile_cache(self)
keras.Model._set_inputs(self,inputs,outputs=None,training=None)
keras.Model._set_save_spec(self,inputs,args=None,kwargs=None)
keras.Model._should_compute_mask(self)
keras.Model._should_eval(self,epoch,validation_freq)
keras.Model._trackable_children(self,save_type='checkpoint',**kwargs)
keras.Model._trackable_saved_model_saver(self)
keras.Model._undeduplicated_weights(self)
keras.Model._updated_config(self)
keras.Model._validate_compile(self,optimizer,metrics,**kwargs)
keras.Model._validate_target_and_loss(self,y,loss)
keras.Model.build(self,input_shape)
keras.Model.call(self,inputs,training=None,mask=None)
keras.Model.compile(self,optimizer='rmsprop',loss=None,metrics=None,loss_weights=None,weighted_metrics=None,run_eagerly=None,steps_per_execution=None,jit_compile=None,**kwargs)
keras.Model.compute_loss(self,x=None,y=None,y_pred=None,sample_weight=None)
keras.Model.compute_metrics(self,x,y,y_pred,sample_weight)
keras.Model.distribute_strategy(self)
keras.Model.evaluate(self,x=None,y=None,batch_size=None,verbose='auto',sample_weight=None,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,return_dict=False,**kwargs)
keras.Model.evaluate_generator(self,generator,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,verbose=0)
keras.Model.fit(self,x=None,y=None,batch_size=None,epochs=1,verbose='auto',callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_batch_size=None,validation_freq=1,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.Model.fit_generator(self,generator,steps_per_epoch=None,epochs=1,verbose=1,callbacks=None,validation_data=None,validation_steps=None,validation_freq=1,class_weight=None,max_queue_size=10,workers=1,use_multiprocessing=False,shuffle=True,initial_epoch=0)
keras.Model.from_config(cls,config,custom_objects=None)
keras.Model.get_config(self)
keras.Model.get_layer(self,name=None,index=None)
keras.Model.get_weights(self)
keras.Model.layers(self)
keras.Model.layers(self,_)
keras.Model.load_weights(self,filepath,by_name=False,skip_mismatch=False,options=None)
keras.Model.make_predict_function(self,force=False)
keras.Model.make_test_function(self,force=False)
keras.Model.make_train_function(self,force=False)
keras.Model.metrics(self)
keras.Model.metrics_names(self)
keras.Model.non_trainable_weights(self)
keras.Model.predict(self,x,batch_size=None,verbose='auto',steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.Model.predict_generator(self,generator,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,verbose=0)
keras.Model.predict_on_batch(self,x)
keras.Model.predict_step(self,data)
keras.Model.reset_metrics(self)
keras.Model.reset_states(self)
keras.Model.run_eagerly(self)
keras.Model.run_eagerly(self,value)
keras.Model.save(self,filepath,overwrite=True,include_optimizer=True,save_format=None,signatures=None,options=None,save_traces=True)
keras.Model.save_spec(self,dynamic_batch=True)
keras.Model.save_weights(self,filepath,overwrite=True,save_format=None,options=None)
keras.Model.state_updates(self)
keras.Model.summary(self,line_length=None,positions=None,print_fn=None,expand_nested=False,show_trainable=False)
keras.Model.test_on_batch(self,x,y=None,sample_weight=None,reset_metrics=True,return_dict=False)
keras.Model.test_step(self,data)
keras.Model.to_json(self,**kwargs)
keras.Model.to_yaml(self,**kwargs)
keras.Model.train_on_batch(self,x,y=None,sample_weight=None,class_weight=None,reset_metrics=True,return_dict=False)
keras.Model.train_step(self,data)
keras.Model.trainable_weights(self)
keras.Model.weights(self)
keras.engine.training.Model(self,*args,**kwargs)
keras.engine.training.Model.__copy__(self)
keras.engine.training.Model.__deepcopy__(self,memo)
keras.engine.training.Model.__init__(self,*args,**kwargs)
keras.engine.training.Model.__reduce__(self)
keras.engine.training.Model.__setattr__(self,name,value)
keras.engine.training.Model._assert_compile_was_called(self)
keras.engine.training.Model._assert_weights_created(self)
keras.engine.training.Model._check_call_args(self,method_name)
keras.engine.training.Model._check_sample_weight_warning(self,x,sample_weight)
keras.engine.training.Model._compile_was_called(self)
keras.engine.training.Model._configure_steps_per_execution(self,steps_per_execution)
keras.engine.training.Model._get_callback_model(self)
keras.engine.training.Model._get_compile_args(self,user_metrics=True)
keras.engine.training.Model._get_optimizer(self,optimizer)
keras.engine.training.Model._in_multi_worker_mode(self)
keras.engine.training.Model._init_batch_counters(self)
keras.engine.training.Model._maybe_load_initial_epoch_from_ckpt(self,initial_epoch)
keras.engine.training.Model._maybe_load_initial_step_from_ckpt(self)
keras.engine.training.Model._reset_compile_cache(self)
keras.engine.training.Model._set_inputs(self,inputs,outputs=None,training=None)
keras.engine.training.Model._set_save_spec(self,inputs,args=None,kwargs=None)
keras.engine.training.Model._should_compute_mask(self)
keras.engine.training.Model._should_eval(self,epoch,validation_freq)
keras.engine.training.Model._trackable_children(self,save_type='checkpoint',**kwargs)
keras.engine.training.Model._trackable_saved_model_saver(self)
keras.engine.training.Model._undeduplicated_weights(self)
keras.engine.training.Model._updated_config(self)
keras.engine.training.Model._validate_compile(self,optimizer,metrics,**kwargs)
keras.engine.training.Model._validate_target_and_loss(self,y,loss)
keras.engine.training.Model.build(self,input_shape)
keras.engine.training.Model.call(self,inputs,training=None,mask=None)
keras.engine.training.Model.compile(self,optimizer='rmsprop',loss=None,metrics=None,loss_weights=None,weighted_metrics=None,run_eagerly=None,steps_per_execution=None,jit_compile=None,**kwargs)
keras.engine.training.Model.compute_loss(self,x=None,y=None,y_pred=None,sample_weight=None)
keras.engine.training.Model.compute_metrics(self,x,y,y_pred,sample_weight)
keras.engine.training.Model.distribute_strategy(self)
keras.engine.training.Model.evaluate(self,x=None,y=None,batch_size=None,verbose='auto',sample_weight=None,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,return_dict=False,**kwargs)
keras.engine.training.Model.evaluate_generator(self,generator,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,verbose=0)
keras.engine.training.Model.fit(self,x=None,y=None,batch_size=None,epochs=1,verbose='auto',callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_batch_size=None,validation_freq=1,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training.Model.fit_generator(self,generator,steps_per_epoch=None,epochs=1,verbose=1,callbacks=None,validation_data=None,validation_steps=None,validation_freq=1,class_weight=None,max_queue_size=10,workers=1,use_multiprocessing=False,shuffle=True,initial_epoch=0)
keras.engine.training.Model.from_config(cls,config,custom_objects=None)
keras.engine.training.Model.get_config(self)
keras.engine.training.Model.get_layer(self,name=None,index=None)
keras.engine.training.Model.get_weights(self)
keras.engine.training.Model.layers(self)
keras.engine.training.Model.layers(self,_)
keras.engine.training.Model.load_weights(self,filepath,by_name=False,skip_mismatch=False,options=None)
keras.engine.training.Model.make_predict_function(self,force=False)
keras.engine.training.Model.make_test_function(self,force=False)
keras.engine.training.Model.make_train_function(self,force=False)
keras.engine.training.Model.metrics(self)
keras.engine.training.Model.metrics_names(self)
keras.engine.training.Model.non_trainable_weights(self)
keras.engine.training.Model.predict(self,x,batch_size=None,verbose='auto',steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training.Model.predict_generator(self,generator,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False,verbose=0)
keras.engine.training.Model.predict_on_batch(self,x)
keras.engine.training.Model.predict_step(self,data)
keras.engine.training.Model.reset_metrics(self)
keras.engine.training.Model.reset_states(self)
keras.engine.training.Model.run_eagerly(self)
keras.engine.training.Model.run_eagerly(self,value)
keras.engine.training.Model.save(self,filepath,overwrite=True,include_optimizer=True,save_format=None,signatures=None,options=None,save_traces=True)
keras.engine.training.Model.save_spec(self,dynamic_batch=True)
keras.engine.training.Model.save_weights(self,filepath,overwrite=True,save_format=None,options=None)
keras.engine.training.Model.state_updates(self)
keras.engine.training.Model.summary(self,line_length=None,positions=None,print_fn=None,expand_nested=False,show_trainable=False)
keras.engine.training.Model.test_on_batch(self,x,y=None,sample_weight=None,reset_metrics=True,return_dict=False)
keras.engine.training.Model.test_step(self,data)
keras.engine.training.Model.to_json(self,**kwargs)
keras.engine.training.Model.to_yaml(self,**kwargs)
keras.engine.training.Model.train_on_batch(self,x,y=None,sample_weight=None,class_weight=None,reset_metrics=True,return_dict=False)
keras.engine.training.Model.train_step(self,data)
keras.engine.training.Model.trainable_weights(self)
keras.engine.training.Model.weights(self)
keras.engine.training._collective_all_reduce_multi_worker(strategy)
keras.engine.training._detect_save_format(filepath)
keras.engine.training._disallow_inside_tf_function(method_name)
keras.engine.training._get_verbosity(verbose,distribute_strategy)
keras.engine.training._is_per_replica_instance(obj)
keras.engine.training._is_readable_tf_checkpoint(filepath)
keras.engine.training._is_scalar(x)
keras.engine.training._is_tpu_multi_host(strategy)
keras.engine.training._minimum_control_deps(outputs)
keras.engine.training._multi_worker_concat(v,strategy)
keras.engine.training._tpu_multi_host_concat(v,strategy)
keras.engine.training.concat(tensors,axis=0)
keras.engine.training.disable_multi_worker(method)
keras.engine.training.flatten_metrics_in_order(logs,metrics_names)
keras.engine.training.inject_functional_model_class(cls)
keras.engine.training.is_functional_model_init_params(args,kwargs)
keras.engine.training.potentially_ragged_concat(tensors)
keras.engine.training.reduce_per_replica(values,strategy,reduction='first')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_distributed_v1.py----------------------------------------
A:keras.engine.training_distributed_v1.exec_func->model._make_execution_function(mode)
A:keras.engine.training_distributed_v1.(grouped_inputs, grouped_outputs, grouped_updates, grouped_session_args)->strategy.extended.call_for_each_replica(_per_replica_execution_function, args=(dist_utils.get_distributed_model(model, mode), mode))
A:keras.engine.training_distributed_v1.(all_inputs, all_outputs, all_updates, all_session_args)->keras.distribute.distributed_training_utils_v1.unwrap_values(strategy, grouped_inputs, grouped_outputs, grouped_updates, grouped_session_args)
A:keras.engine.training_distributed_v1.combined_fn->keras.backend.function(all_inputs, all_outputs, updates=all_updates, name='distributed_' + str(mode) + '_function', **all_session_args)
A:keras.engine.training_distributed_v1.iteration_value->min(steps_per_epoch, current_strategy.extended.steps_per_run)
A:keras.engine.training_distributed_v1.steps_per_run->keras.backend.variable(value=iteration_value, dtype='int32', name='steps_per_run')
A:keras.engine.training_distributed_v1.iterator->keras.distribute.distributed_training_utils_v1.get_iterator(dataset, current_strategy)
A:keras.engine.training_distributed_v1.scope->keras.distribute.distributed_training_utils_v1.distributed_scope(strategy=current_strategy, learning_phase=0)
A:keras.engine.training_distributed_v1.step_fn->_make_train_step_fn(model, ModeKeys.TRAIN, current_strategy, out_labels)
A:keras.engine.training_distributed_v1.initial_loop_values['loss']->tensorflow.compat.v2.constant(10000000.0)
A:keras.engine.training_distributed_v1.tensor->m.result()
A:keras.engine.training_distributed_v1.initial_loop_values[m.name]->tensorflow.compat.v2.zeros(tensor.shape, tensor.dtype)
A:keras.engine.training_distributed_v1.ctx->current_strategy.extended.experimental_run_steps_on_iterator(step_fn, iterator, iterations=steps_per_run, initial_loop_values=initial_loop_values)
A:keras.engine.training_distributed_v1.do_validation->bool(validation_steps)
A:keras.engine.training_distributed_v1.callbacks->kwargs.pop('callbacks', None)
A:keras.engine.training_distributed_v1.target_steps->len(steps_to_run)
A:keras.engine.training_distributed_v1.initial_epoch->model._maybe_load_initial_epoch_from_ckpt(initial_epoch, mode)
A:keras.engine.training_distributed_v1.(_, outputs)->keras.backend.batch_get_value([train_op, output_tensors])
A:keras.engine.training_distributed_v1.val_outs->experimental_tpu_test_loop(model, val_dataset, steps=validation_steps, verbose=verbose, callbacks=callbacks)
A:keras.engine.training_distributed_v1.(_, outputs, updates, _)->_per_replica_execution_function(dist_utils.get_distributed_model(model, mode), mode)
A:keras.engine.training_distributed_v1.test_input_data->keras.distribute.distributed_training_utils_v1.get_iterator(dataset, current_strategy).get_next()
A:keras.engine.training_distributed_v1.per_replica_outputs->current_strategy.run(_predict_step_fn, args=(predict_input_data,))
A:keras.engine.training_distributed_v1.output_tensors[label]->current_strategy.reduce(reduce_op, output, axis=None)
A:keras.engine.training_distributed_v1.test_op->tensorflow.compat.v2.group(list(output_tensors.values()))
A:keras.engine.training_distributed_v1.progbar->Progbar(target=steps)
A:keras.engine.training_distributed_v1.(_, batch_outs)->keras.backend.batch_get_value([predict_ops, output_tensors])
A:keras.engine.training_distributed_v1.warning_msg->'Make sure that your dataset can generate at least `steps` batches (in this case, {} batches).'.format(steps)
A:keras.engine.training_distributed_v1.batch_logs->keras.callbacks.make_logs(model, batch_logs, batch_outs, mode)
A:keras.engine.training_distributed_v1.dataset_fully_shaped->keras.distribute.distributed_training_utils_v1.is_dataset_shape_fully_defined(dataset)
A:keras.engine.training_distributed_v1.padding_handler->keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler(model._feed_output_shapes)
A:keras.engine.training_distributed_v1.(batch_size, _, prefetch_buffer)->tensorflow.python.distribute.input_lib._get_dataset_attributes(dataset)
A:keras.engine.training_distributed_v1.padding_handler.padding_mask->model._distribution_standardize_user_data(x, batch_size=batch_size, allow_partial_batch=True).reduce(padding_handler.padding_mask, padding_handler.update_mask)
A:keras.engine.training_distributed_v1.dataset->model._distribution_standardize_user_data(x, batch_size=batch_size, allow_partial_batch=True)
A:keras.engine.training_distributed_v1.predict_input_data->keras.distribute.distributed_training_utils_v1.get_iterator(dataset, current_strategy).get_next()
A:keras.engine.training_distributed_v1.output_tensors->keras.distribute.distributed_training_utils_v1.flatten_per_replica_values(current_strategy, per_replica_outputs)
A:keras.engine.training_distributed_v1.num_model_outputs->len(model.output_names)
A:keras.engine.training_distributed_v1.predict_ops->tensorflow.compat.v2.group(output_tensors)
A:keras.engine.training_distributed_v1.prediction_result->keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler(model._feed_output_shapes).apply_mask(prediction_result)
A:keras.engine.training_distributed_v1.(batch_size, steps_per_epoch)->keras.distribute.distributed_training_utils_v1.process_batch_and_step_size(model._distribution_strategy, x, batch_size, steps_per_epoch, ModeKeys.TRAIN, validation_split=validation_split)
A:keras.engine.training_distributed_v1.batch_size->model._validate_or_infer_batch_size(batch_size, steps, x)
A:keras.engine.training_distributed_v1.(dataset, _, _)->model._standardize_user_data(dataset, sample_weight=sample_weight, class_weight=class_weight, batch_size=batch_size, validation_split=validation_split, shuffle=shuffle)
A:keras.engine.training_distributed_v1.(val_x, val_y, val_sample_weights)->keras.engine.training_utils_v1.unpack_validation_data(validation_data)
A:keras.engine.training_distributed_v1.(_, validation_steps)->keras.distribute.distributed_training_utils_v1.process_batch_and_step_size(model._distribution_strategy, val_x, batch_size, validation_steps, ModeKeys.TEST)
A:keras.engine.training_distributed_v1.val_dataset->model._distribution_standardize_user_data(val_x, val_y, sample_weight=val_sample_weights, class_weight=None, batch_size=batch_size, validation_split=validation_split, shuffle=shuffle, allow_partial_batch=True)
A:keras.engine.training_distributed_v1.steps_per_epoch->keras.engine.training_utils_v1.infer_steps_for_dataset(model, dataset, steps_per_epoch, epochs, steps_name='steps_per_epoch')
A:keras.engine.training_distributed_v1.(batch_size, steps)->keras.distribute.distributed_training_utils_v1.process_batch_and_step_size(model._distribution_strategy, x, batch_size, steps, ModeKeys.PREDICT)
A:keras.engine.training_distributed_v1.steps->keras.engine.training_utils_v1.infer_steps_for_dataset(model, dataset, steps, steps_name='steps')
A:keras.engine.training_distributed_v1.filtered_callbacks->keras.distribute.distributed_training_utils_v1.filter_distributed_callbacks(callbacks, model)
keras.engine.training_distributed_v1.DistributionMultiWorkerTrainingLoop(self,single_worker_loop)
keras.engine.training_distributed_v1.DistributionMultiWorkerTrainingLoop.__init__(self,single_worker_loop)
keras.engine.training_distributed_v1.DistributionMultiWorkerTrainingLoop.evaluate(self,*args,**kwargs)
keras.engine.training_distributed_v1.DistributionMultiWorkerTrainingLoop.fit(self,*args,**kwargs)
keras.engine.training_distributed_v1.DistributionMultiWorkerTrainingLoop.predict(self,*args,**kwargs)
keras.engine.training_distributed_v1.DistributionSingleWorkerTrainingLoop(training_utils_v1.TrainingLoop)
keras.engine.training_distributed_v1.DistributionSingleWorkerTrainingLoop.evaluate(self,model,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,**kwargs)
keras.engine.training_distributed_v1.DistributionSingleWorkerTrainingLoop.fit(self,model,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,**kwargs)
keras.engine.training_distributed_v1.DistributionSingleWorkerTrainingLoop.predict(self,model,x,batch_size=None,verbose=0,steps=None,callbacks=None,**kwargs)
keras.engine.training_distributed_v1._build_model(strategy,model,mode,inputs,targets=None)
keras.engine.training_distributed_v1._make_train_step_fn(model,mode,strategy,output_labels)
keras.engine.training_distributed_v1._per_replica_execution_function(model,mode)
keras.engine.training_distributed_v1._train_with_multi_worker(method)
keras.engine.training_distributed_v1.experimental_tpu_fit_loop(model,dataset,epochs=100,verbose=1,callbacks=None,initial_epoch=0,steps_per_epoch=None,val_dataset=None,validation_steps=None,validation_freq=1)
keras.engine.training_distributed_v1.experimental_tpu_predict_loop(model,dataset,verbose=0,steps=None,callbacks=None)
keras.engine.training_distributed_v1.experimental_tpu_test_loop(model,dataset,verbose=0,steps=None,callbacks=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/input_spec.py----------------------------------------
A:keras.engine.input_spec.shape->tensorflow.compat.v2.TensorShape(x.shape)
A:keras.engine.input_spec.self.ndim->len(shape)
A:keras.engine.input_spec.max_axis->max(self.axes)
A:keras.engine.input_spec.input_spec->tensorflow.compat.v2.nest.flatten(input_spec)
A:keras.engine.input_spec.inputs->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.input_spec.shape_as_list->tensorflow.compat.v2.TensorShape(x.shape).as_list()
keras.engine.input_spec.InputSpec(self,dtype=None,shape=None,ndim=None,max_ndim=None,min_ndim=None,axes=None,allow_last_axis_squeeze=False,name=None)
keras.engine.input_spec.InputSpec.__init__(self,dtype=None,shape=None,ndim=None,max_ndim=None,min_ndim=None,axes=None,allow_last_axis_squeeze=False,name=None)
keras.engine.input_spec.InputSpec.__repr__(self)
keras.engine.input_spec.InputSpec.from_config(cls,config)
keras.engine.input_spec.InputSpec.get_config(self)
keras.engine.input_spec.assert_input_compatibility(input_spec,inputs,layer_name)
keras.engine.input_spec.display_shape(shape)
keras.engine.input_spec.to_tensor_shape(spec)
keras.engine.input_spec.to_tensor_spec(input_spec,default_dtype=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_utils.py----------------------------------------
A:keras.engine.training_utils.slices->keras.utils.generic_utils.slice_arrays(arrays, indices)
A:keras.engine.training_utils.as_numpy->isinstance(outputs[i], np.ndarray)
A:keras.engine.training_utils.self._current_trainable_state->self._model._get_trainable_state()
A:keras.engine.training_utils.(batch_input_shape, _)->get_input_shape_and_dtype(layer)
keras.engine.training_utils.RespectCompiledTrainableState(self,model)
keras.engine.training_utils.RespectCompiledTrainableState.__enter__(self)
keras.engine.training_utils.RespectCompiledTrainableState.__exit__(self,type_arg,value_arg,traceback_arg)
keras.engine.training_utils.RespectCompiledTrainableState.__init__(self,model)
keras.engine.training_utils.get_input_shape_and_dtype(layer)
keras.engine.training_utils.get_static_batch_size(layer)
keras.engine.training_utils.handle_partial_sample_weights(outputs,sample_weights,sample_weight_modes,check_all_flat=False)
keras.engine.training_utils.list_to_tuple(maybe_list)
keras.engine.training_utils.slice_arrays(arrays,indices,contiguous=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/base_layer_utils.py----------------------------------------
A:keras.engine.base_layer_utils._call_context->threading.local()
A:keras.engine.base_layer_utils.metric_obj->keras.metrics.Mean(name=name, dtype=value.dtype)
A:keras.engine.base_layer_utils.initializer->initializer()
A:keras.engine.base_layer_utils.init_val->functools.partial(initializer, shape, dtype=dtype)
A:keras.engine.base_layer_utils.variable_shape->tensorflow.compat.v2.TensorShape(shape)
A:keras.engine.base_layer_utils.(_, created_layers)->_create_keras_history_helper(tensors, set(), [])
A:keras.engine.base_layer_utils.tensor_list->tensorflow.compat.v2.nest.flatten(tensors)
A:keras.engine.base_layer_utils.op_inputs->list(op.inputs)
A:keras.engine.base_layer_utils.using_xla->keras.utils.control_flow_util.GraphOrParentsInXlaContext(tf.compat.v1.get_default_graph())
A:keras.engine.base_layer_utils.constants[i]->keras.backend.function([], op_input)([])
A:keras.engine.base_layer_utils.layer_inputs->unnest_if_single_tensor(layer_inputs)
A:keras.engine.base_layer_utils.(processed_ops, created_layers)->_create_keras_history_helper(layer_inputs, processed_ops, created_layers)
A:keras.engine.base_layer_utils.node_def->op.node_def.SerializeToString()
A:keras.engine.base_layer_utils.op_layer->keras.engine.base_layer.TensorFlowOpLayer(node_def, constants=constants, name=name)
A:keras.engine.base_layer_utils.flat_input_tensors->tensorflow.compat.v2.nest.flatten(input_tensors)
A:keras.engine.base_layer_utils.input_tensors->tensorflow.compat.v2.nest.flatten(tensors)
A:keras.engine.base_layer_utils.graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.engine.base_layer_utils.checked_tensors->set()
A:keras.engine.base_layer_utils.tensors_to_check->tensorflow.compat.v2.nest.flatten(tensors)
A:keras.engine.base_layer_utils.call_ctx->CallContext()
A:keras.engine.base_layer_utils.full_args->dict(zip(argspec.args[2:], args))
A:keras.engine.base_layer_utils.return_tensor->acd.mark_as_return(tensor)
A:keras.engine.base_layer_utils.return_tensor._keras_mask->acd.mark_as_return(tensor._keras_mask)
A:keras.engine.base_layer_utils.self._distribute_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.base_layer_utils.saveables->tensorflow.compat.v2.__internal__.tracking.saveable_objects_from_trackable(trackable).values()
A:keras.engine.base_layer_utils.self._num_tensors->len(self._saveable.specs)
A:keras.engine.base_layer_utils.self._saveable->saveable()
A:keras.engine.base_layer_utils.self._assign_op->self._saveable.restore(self._placeholder_tensors, None)
A:keras.engine.base_layer_utils.input_list->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.base_layer_utils.obj_type->type(obj)
keras.engine.base_layer_utils.CallContext(self)
keras.engine.base_layer_utils.CallContext.__init__(self)
keras.engine.base_layer_utils.CallContext.build_graph(self)
keras.engine.base_layer_utils.CallContext.enter(self,layer,inputs,build_graph,training,saving=None)
keras.engine.base_layer_utils.CallContext.frozen(self)
keras.engine.base_layer_utils.CallContext.in_keras_graph(self)
keras.engine.base_layer_utils.CallContext.inputs(self)
keras.engine.base_layer_utils.CallContext.layer(self)
keras.engine.base_layer_utils.CallContext.saving(self)
keras.engine.base_layer_utils.CallContext.training(self)
keras.engine.base_layer_utils.CallContextManager(self,call_ctx,state)
keras.engine.base_layer_utils.CallContextManager.__enter__(self)
keras.engine.base_layer_utils.CallContextManager.__exit__(self,*exc_info)
keras.engine.base_layer_utils.CallContextManager.__init__(self,call_ctx,state)
keras.engine.base_layer_utils.TrackableWeightHandler(self,trackable)
keras.engine.base_layer_utils.TrackableWeightHandler.__init__(self,trackable)
keras.engine.base_layer_utils.TrackableWeightHandler._set_weights_v1(self,weights)
keras.engine.base_layer_utils.TrackableWeightHandler.get_tensors(self)
keras.engine.base_layer_utils.TrackableWeightHandler.num_tensors(self)
keras.engine.base_layer_utils.TrackableWeightHandler.set_weights(self,weights)
keras.engine.base_layer_utils._create_keras_history_helper(tensors,processed_ops,created_layers)
keras.engine.base_layer_utils.call_context()
keras.engine.base_layer_utils.check_graph_consistency(tensor=None,method='add_loss',force_raise=False)
keras.engine.base_layer_utils.collect_previous_mask(input_tensors)
keras.engine.base_layer_utils.create_keras_history(tensors)
keras.engine.base_layer_utils.create_mean_metric(value,name=None)
keras.engine.base_layer_utils.disable_v2_dtype_behavior()
keras.engine.base_layer_utils.enable_v2_dtype_behavior()
keras.engine.base_layer_utils.from_saved_model(layer)
keras.engine.base_layer_utils.generate_placeholders_from_shape(shape)
keras.engine.base_layer_utils.has_weights(obj)
keras.engine.base_layer_utils.have_all_keras_metadata(tensors)
keras.engine.base_layer_utils.is_in_eager_or_tf_function()
keras.engine.base_layer_utils.is_in_keras_graph()
keras.engine.base_layer_utils.is_in_tf_function()
keras.engine.base_layer_utils.is_split_variable(v)
keras.engine.base_layer_utils.is_subclassed(layer)
keras.engine.base_layer_utils.make_variable(name,shape=None,dtype=tf.float32,initializer=None,trainable=None,caching_device=None,validate_shape=True,constraint=None,use_resource=None,collections=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.VariableAggregation.NONE,partitioner=None,layout=None)
keras.engine.base_layer_utils.mark_as_return(outputs,acd)
keras.engine.base_layer_utils.mark_checked(tensors)
keras.engine.base_layer_utils.needs_keras_history(tensors,ignore_call_context=False)
keras.engine.base_layer_utils.no_ragged_support(inputs,layer_name)
keras.engine.base_layer_utils.training_arg_passed_to_call(argspec,args,kwargs)
keras.engine.base_layer_utils.unnest_if_single_tensor(input_tensors)
keras.engine.base_layer_utils.uses_keras_history(tensors)
keras.engine.base_layer_utils.v2_dtype_behavior_enabled()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/keras_tensor.py----------------------------------------
A:keras.engine.keras_tensor.name->getattr(x, 'name', None)
A:keras.engine.keras_tensor.type_spec->UserRegisteredSpec(x.shape, x.dtype)
A:keras.engine.keras_tensor.inferred_value->tensorflow.compat.v2.shape(tf.compat.v1.placeholder(shape=self._inferred_value, dtype=tf.int32))
A:keras.engine.keras_tensor.shape->tensorflow.compat.v2.TensorShape(shape)
A:keras.engine.keras_tensor.self._type_spec->type_spec_with_shape(self._type_spec, shape)
A:keras.engine.keras_tensor.tensor_oper->getattr(tensor_oper, '__func__', tensor_oper)
A:keras.engine.keras_tensor.result->tensorflow.compat.v2.RaggedTensor.from_uniform_row_length(result, rowlen, validate=False)
A:keras.engine.keras_tensor.splits->tensorflow.compat.v2.compat.v1.placeholder(ragged_spec.row_splits_dtype, [num_splits])
A:keras.engine.keras_tensor.rowlen->tensorflow.compat.v2.constant(axis_size, ragged_spec.row_splits_dtype)
A:keras.engine.keras_tensor.out->keras_tensor_cls.from_tensor(tensor)
A:keras.engine.keras_tensor.out._keras_mask->keras_tensor_from_tensor(tensor._keras_mask)
keras.engine.keras_tensor.KerasTensor(self,type_spec,inferred_value=None,name=None)
keras.engine.keras_tensor.KerasTensor.__array__(self,dtype=None)
keras.engine.keras_tensor.KerasTensor.__hash__(self)
keras.engine.keras_tensor.KerasTensor.__init__(self,type_spec,inferred_value=None,name=None)
keras.engine.keras_tensor.KerasTensor.__iter__(self)
keras.engine.keras_tensor.KerasTensor.__len__(self)
keras.engine.keras_tensor.KerasTensor.__repr__(self)
keras.engine.keras_tensor.KerasTensor.__str__(self)
keras.engine.keras_tensor.KerasTensor._overload_all_operators(cls,tensor_class)
keras.engine.keras_tensor.KerasTensor._overload_operator(cls,tensor_class,operator)
keras.engine.keras_tensor.KerasTensor._to_placeholder(self)
keras.engine.keras_tensor.KerasTensor.dtype(self)
keras.engine.keras_tensor.KerasTensor.from_tensor(cls,tensor)
keras.engine.keras_tensor.KerasTensor.from_type_spec(cls,type_spec,name=None)
keras.engine.keras_tensor.KerasTensor.get_shape(self)
keras.engine.keras_tensor.KerasTensor.is_tensor_like(self)
keras.engine.keras_tensor.KerasTensor.name(self)
keras.engine.keras_tensor.KerasTensor.node(self)
keras.engine.keras_tensor.KerasTensor.op(self)
keras.engine.keras_tensor.KerasTensor.ref(self)
keras.engine.keras_tensor.KerasTensor.set_shape(self,shape)
keras.engine.keras_tensor.KerasTensor.shape(self)
keras.engine.keras_tensor.KerasTensor.type_spec(self)
keras.engine.keras_tensor.RaggedKerasTensor(KerasTensor)
keras.engine.keras_tensor.RaggedKerasTensor._to_placeholder(self)
keras.engine.keras_tensor.RaggedKerasTensor.ragged_rank(self)
keras.engine.keras_tensor.SparseKerasTensor(KerasTensor)
keras.engine.keras_tensor.SparseKerasTensor._to_placeholder(self)
keras.engine.keras_tensor.UserRegisteredSpec(self,shape,dtype)
keras.engine.keras_tensor.UserRegisteredSpec.__init__(self,shape,dtype)
keras.engine.keras_tensor.UserRegisteredSpec._component_specs(self)
keras.engine.keras_tensor.UserRegisteredSpec._from_components(self,components)
keras.engine.keras_tensor.UserRegisteredSpec._serialize(self)
keras.engine.keras_tensor.UserRegisteredSpec._to_components(self,value)
keras.engine.keras_tensor.UserRegisteredSpec.value_type(self)
keras.engine.keras_tensor.UserRegisteredTypeKerasTensor(self,user_registered_symbolic_object)
keras.engine.keras_tensor.UserRegisteredTypeKerasTensor.__init__(self,user_registered_symbolic_object)
keras.engine.keras_tensor.UserRegisteredTypeKerasTensor._to_placeholder(self)
keras.engine.keras_tensor.UserRegisteredTypeKerasTensor.from_tensor(cls,tensor)
keras.engine.keras_tensor.UserRegisteredTypeKerasTensor.from_type_spec(cls,type_spec,name=None)
keras.engine.keras_tensor._KerasTensorIterator(self,tensor,dim0)
keras.engine.keras_tensor._KerasTensorIterator.__init__(self,tensor,dim0)
keras.engine.keras_tensor._KerasTensorIterator.__iter__(self)
keras.engine.keras_tensor._KerasTensorIterator.__next__(self)
keras.engine.keras_tensor.keras_tensor_from_tensor(tensor)
keras.engine.keras_tensor.keras_tensor_from_type_spec(type_spec,name=None)
keras.engine.keras_tensor.keras_tensor_to_placeholder(x)
keras.engine.keras_tensor.register_keras_tensor_specialization(cls,keras_tensor_subclass)
keras.engine.keras_tensor.type_spec_with_shape(spec,shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_utils_v1.py----------------------------------------
A:keras.engine.training_utils_v1.max_dim0_value->max(max_dim0_value, index[0])
A:keras.engine.training_utils_v1.new_indices->numpy.append(new_indices, [index], axis=0)
A:keras.engine.training_utils_v1.new_values->numpy.concatenate((target.values, to_append.values), axis=0)
A:keras.engine.training_utils_v1.new_dense_shape->tuple(new_dense_shape)
A:keras.engine.training_utils_v1.new_row_splits->numpy.append(target.row_splits, adjusted_row_splits)
A:keras.engine.training_utils_v1.self.composite->is_composite_or_composite_value(batch_element)
A:keras.engine.training_utils_v1.results->_append_composite_tensor(results, r)
A:keras.engine.training_utils_v1.self.results->tensorflow.compat.v2.nest.pack_sequence_as(self._structure, self.results)
A:keras.engine.training_utils_v1._COPY_POOL->multiprocessing.pool.ThreadPool(_COPY_THREADS)
A:keras.engine.training_utils_v1.self._pool->get_copy_pool()
A:keras.engine.training_utils_v1.num_elements->numpy.prod(batch_element.shape)
A:keras.engine.training_utils_v1.is_finished->threading.Event()
A:keras.engine.training_utils_v1.start_time->time.time()
A:keras.engine.training_utils_v1.timeout->max([0.0, self._MAX_COPY_SECONDS - (time.time() - start_time)])
A:keras.engine.training_utils_v1.self._structure->tensorflow.compat.v2.__internal__.nest.get_traverse_shallow_structure(lambda x: not is_composite_or_composite_value(x), batch_outs)
A:keras.engine.training_utils_v1.batch_outs->tensorflow.compat.v2.__internal__.nest.flatten_up_to(self._structure, batch_outs)
A:keras.engine.training_utils_v1.stateful_metric_names->getattr(model, 'metrics_names', None)
A:keras.engine.training_utils_v1.x->tensorflow.compat.v2.convert_to_tensor(x)
A:keras.engine.training_utils_v1.data_len->len(data)
A:keras.engine.training_utils_v1.data_shape->tuple(tensorshape.as_list())
A:keras.engine.training_utils_v1.tensorshape->get_composite_shape(data[i])
A:keras.engine.training_utils_v1.set_x->set_of_lengths(inputs)
A:keras.engine.training_utils_v1.set_y->set_of_lengths(targets)
A:keras.engine.training_utils_v1.set_w->set_of_lengths(weights)
A:keras.engine.training_utils_v1.is_loss_wrapper->isinstance(loss, losses.LossFunctionWrapper)
A:keras.engine.training_utils_v1.any_sub_list->any((isinstance(m, list) for m in metrics))
A:keras.engine.training_utils_v1.output_metrics->keras.utils.generic_utils.to_list(metrics.get(name, []))
A:keras.engine.training_utils_v1.metrics_dict->collections.OrderedDict()
A:keras.engine.training_utils_v1.metric_name->get_metric_name(metric, is_weighted)
A:keras.engine.training_utils_v1.metric_fn->keras.metrics.get(metric)
A:keras.engine.training_utils_v1.batch_count->int(len(index_array) / batch_size)
A:keras.engine.training_utils_v1.index_array->index_array.flatten().flatten()
A:keras.engine.training_utils_v1.keys->numpy.array(sorted(class_weight.keys()))
A:keras.engine.training_utils_v1.values->numpy.array([class_weight[i] for i in keys])
A:keras.engine.training_utils_v1.weight_vector->numpy.zeros(np.max(keys) + 1)
A:keras.engine.training_utils_v1.y_classes->numpy.reshape(y, y.shape[0])
A:keras.engine.training_utils_v1.class_sample_weight->numpy.asarray([class_weight[cls] for cls in y_classes if cls in class_weight])
A:keras.engine.training_utils_v1.sample_weight->tensorflow.compat.v2.cast(tf.convert_to_tensor(sample_weight), backend.floatx())
A:keras.engine.training_utils_v1.existing_classes->set(y_classes)
A:keras.engine.training_utils_v1.existing_class_weight->set(class_weight.keys())
A:keras.engine.training_utils_v1.metric->keras.metrics.get(metric)
A:keras.engine.training_utils_v1.mask->tensorflow.compat.v2.cast(mask, y_pred.dtype)
A:keras.engine.training_utils_v1.weights->tensorflow.compat.v2.cast(weights, dtype=y_pred.dtype)
A:keras.engine.training_utils_v1.(mask, _, weights)->keras.utils.losses_utils.squeeze_or_expand_dimensions(mask, sample_weight=weights)
A:keras.engine.training_utils_v1.loss->keras.losses.get(loss)
A:keras.engine.training_utils_v1.loss_fn->keras.losses.get(loss)
A:keras.engine.training_utils_v1.is_x_iterator->isinstance(input_data, (tf.compat.v1.data.Iterator, tf.data.Iterator))
A:keras.engine.training_utils_v1.target->tensorflow.compat.v2.convert_to_tensor(target)
A:keras.engine.training_utils_v1.input_dtypes->tensorflow.compat.v2.nest.map_structure(lambda t: t.dtype, model.inputs)
A:keras.engine.training_utils_v1.end_point.sample_weight_mode->sample_weight_mode.get(end_point.output_name)
A:keras.engine.training_utils_v1.loss_functions->tensorflow.compat.v2.nest.map_structure(get_loss_function, loss)
A:keras.engine.training_utils_v1.e.loss_weight->loss_weights.get(e.output_name, 1.0)
A:keras.engine.training_utils_v1.graph_def_str->keras.backend.get_value(dataset._as_serialized_graph())
A:keras.engine.training_utils_v1.graph_def->get_dataset_graph_def(x)
A:keras.engine.training_utils_v1.iterator->get_iterator(dataset)
A:keras.engine.training_utils_v1.(inputs, targets, sample_weight)->unpack_iterator_input(iterator)
A:keras.engine.training_utils_v1.next_element->get_iterator(dataset).get_next()
A:keras.engine.training_utils_v1.size->keras.backend.get_value(tf.data.experimental.cardinality(dataset))
A:keras.engine.training_utils_v1.self._is_dict->isinstance(self._inputs, dict)
A:keras.engine.training_utils_v1.self._flattened_inputs->tensorflow.compat.v2.nest.flatten(self._inputs)
A:keras.engine.training_utils_v1.v->keras.backend.placeholder(shape=shape, name=k, dtype=v.dtype)
A:keras.engine.training_utils_v1.dtype->keras.backend.floatx()
A:keras.engine.training_utils_v1.split_at->int(len(x[0]) * (1.0 - validation_split))
keras.engine.training_utils_v1.Aggregator(self,use_steps,num_samples=None,steps=None,batch_size=None)
keras.engine.training_utils_v1.Aggregator.__init__(self,use_steps,num_samples=None,steps=None,batch_size=None)
keras.engine.training_utils_v1.Aggregator.aggregate(self,batch_outs,batch_start=None,batch_end=None)
keras.engine.training_utils_v1.Aggregator.create(self,batch_outs)
keras.engine.training_utils_v1.Aggregator.finalize(self)
keras.engine.training_utils_v1.ConcatAggregator(self,batch_size)
keras.engine.training_utils_v1.ConcatAggregator.__init__(self,batch_size)
keras.engine.training_utils_v1.ConcatAggregator.aggregate(self,batch_element,batch_start=None,batch_end=None)
keras.engine.training_utils_v1.ConcatAggregator.create(self,batch_element)
keras.engine.training_utils_v1.ConcatAggregator.finalize(self)
keras.engine.training_utils_v1.MetricsAggregator(self,use_steps,num_samples=None,steps=None)
keras.engine.training_utils_v1.MetricsAggregator.__init__(self,use_steps,num_samples=None,steps=None)
keras.engine.training_utils_v1.MetricsAggregator.aggregate(self,batch_outs,batch_start=None,batch_end=None)
keras.engine.training_utils_v1.MetricsAggregator.create(self,batch_outs)
keras.engine.training_utils_v1.MetricsAggregator.finalize(self)
keras.engine.training_utils_v1.ModelInputs(self,inputs)
keras.engine.training_utils_v1.ModelInputs.__init__(self,inputs)
keras.engine.training_utils_v1.ModelInputs.as_dict(self)
keras.engine.training_utils_v1.ModelInputs.as_list(self)
keras.engine.training_utils_v1.ModelInputs.get_input_names(self)
keras.engine.training_utils_v1.ModelInputs.get_symbolic_inputs(self,return_single_as_list=False)
keras.engine.training_utils_v1.OutputsAggregator(Aggregator)
keras.engine.training_utils_v1.OutputsAggregator.aggregate(self,batch_outs,batch_start=None,batch_end=None)
keras.engine.training_utils_v1.OutputsAggregator.create(self,batch_outs)
keras.engine.training_utils_v1.OutputsAggregator.finalize(self)
keras.engine.training_utils_v1.SliceAggregator(self,num_samples,batch_size)
keras.engine.training_utils_v1.SliceAggregator.__init__(self,num_samples,batch_size)
keras.engine.training_utils_v1.SliceAggregator._slice_assign(self,batch_element,batch_start,batch_end,is_finished)
keras.engine.training_utils_v1.SliceAggregator.aggregate(self,batch_element,batch_start,batch_end)
keras.engine.training_utils_v1.SliceAggregator.create(self,batch_element)
keras.engine.training_utils_v1.SliceAggregator.finalize(self)
keras.engine.training_utils_v1.TrainingLoop
keras.engine.training_utils_v1.TrainingLoop.evaluate(self,model,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,**kwargs)
keras.engine.training_utils_v1.TrainingLoop.fit(self,model,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,**kwargs)
keras.engine.training_utils_v1.TrainingLoop.predict(self,model,x,batch_size=None,verbose=0,steps=None,callbacks=None,**kwargs)
keras.engine.training_utils_v1._append_composite_tensor(target,to_append)
keras.engine.training_utils_v1._append_ragged_tensor_value(target,to_append)
keras.engine.training_utils_v1._append_sparse_tensor_value(target,to_append)
keras.engine.training_utils_v1.batch_shuffle(index_array,batch_size)
keras.engine.training_utils_v1.call_metric_function(metric_fn,y_true,y_pred=None,weights=None,mask=None)
keras.engine.training_utils_v1.cast_if_floating_dtype(x,dtype=None)
keras.engine.training_utils_v1.cast_if_floating_dtype_and_mismatch(targets,outputs)
keras.engine.training_utils_v1.cast_single_tensor(x,dtype=None)
keras.engine.training_utils_v1.cast_to_model_input_dtypes(x,model)
keras.engine.training_utils_v1.check_array_lengths(inputs,targets,weights=None)
keras.engine.training_utils_v1.check_generator_arguments(y=None,sample_weight=None,validation_split=None)
keras.engine.training_utils_v1.check_loss_and_target_compatibility(targets,loss_fns,output_shapes)
keras.engine.training_utils_v1.check_num_samples(ins,batch_size=None,steps=None,steps_name='steps')
keras.engine.training_utils_v1.check_steps_argument(input_data,steps,steps_name)
keras.engine.training_utils_v1.collect_per_output_metric_info(metrics,output_names,output_shapes,loss_fns,from_serialized=False,is_weighted=False)
keras.engine.training_utils_v1.extract_tensors_from_dataset(dataset)
keras.engine.training_utils_v1.generic_output_names(outputs_list)
keras.engine.training_utils_v1.get_composite_shape(tensor)
keras.engine.training_utils_v1.get_copy_pool()
keras.engine.training_utils_v1.get_dataset_graph_def(dataset)
keras.engine.training_utils_v1.get_iterator(dataset)
keras.engine.training_utils_v1.get_loss_function(loss)
keras.engine.training_utils_v1.get_metric_function(metric,output_shape=None,loss_fn=None)
keras.engine.training_utils_v1.get_metric_name(metric,weighted=False)
keras.engine.training_utils_v1.get_progbar(model,count_mode,include_metrics=True)
keras.engine.training_utils_v1.has_symbolic_tensors(ls)
keras.engine.training_utils_v1.has_tensors(ls)
keras.engine.training_utils_v1.infer_steps_for_dataset(model,dataset,steps,epochs=1,steps_name='steps')
keras.engine.training_utils_v1.initialize_iterator(iterator)
keras.engine.training_utils_v1.is_composite_or_composite_value(tensor)
keras.engine.training_utils_v1.is_dataset_or_iterator(data)
keras.engine.training_utils_v1.is_eager_dataset_or_iterator(data)
keras.engine.training_utils_v1.is_feature_layer(layer)
keras.engine.training_utils_v1.prepare_loss_functions(loss,output_names)
keras.engine.training_utils_v1.prepare_loss_weights(training_endpoints,loss_weights=None)
keras.engine.training_utils_v1.prepare_sample_weight_modes(training_endpoints,sample_weight_mode)
keras.engine.training_utils_v1.should_run_validation(validation_freq,epoch)
keras.engine.training_utils_v1.split_training_and_validation_data(x,y,sample_weights,validation_split)
keras.engine.training_utils_v1.standardize_class_weights(class_weight,output_names)
keras.engine.training_utils_v1.standardize_input_data(data,names,shapes=None,check_batch_axis=True,exception_prefix='')
keras.engine.training_utils_v1.standardize_sample_or_class_weights(x_weight,output_names,weight_type)
keras.engine.training_utils_v1.standardize_sample_weights(sample_weight,output_names)
keras.engine.training_utils_v1.standardize_single_array(x,expected_shape=None)
keras.engine.training_utils_v1.standardize_weights(y,sample_weight=None,class_weight=None,sample_weight_mode=None)
keras.engine.training_utils_v1.unpack_iterator_input(iterator)
keras.engine.training_utils_v1.unpack_validation_data(validation_data,raise_if_ambiguous=True)
keras.engine.training_utils_v1.validate_dataset_input(x,y,sample_weight,validation_split=None)
keras.engine.training_utils_v1.validate_input_types(inp,orig_inp,allow_dict=True,field_name='inputs')
keras.engine.training_utils_v1.verify_dataset_shuffled(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/saving.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/node.py----------------------------------------
A:keras.engine.node.call_args->tensorflow.compat.v2.nest.map_structure(lambda t: t, call_args)
A:keras.engine.node.call_kwargs->tensorflow.compat.v2.nest.map_structure(lambda t: t, call_kwargs)
A:keras.engine.node.self.outputs->tensorflow.compat.v2.nest.map_structure(lambda t: t, outputs)
A:keras.engine.node.self._flat_arguments->tensorflow.compat.v2.nest.flatten((self.call_args, self.call_kwargs))
A:keras.engine.node.kt_id->str(id(ele))
A:keras.engine.node.tensor._keras_history->KerasHistory(layer=layer, node_index=node_index, tensor_index=i)
A:keras.engine.node.flat_arguments->copy.copy(self._flat_arguments)
A:keras.engine.node.flat_arguments[kt_index]->tensor_dict[kt_id].pop()
A:keras.engine.node.(args, kwargs)->tensorflow.compat.v2.nest.pack_sequence_as((self.call_args, self.call_kwargs), flat_arguments)
A:keras.engine.node.(inputs, args, kwargs)->self.layer._split_out_first_arg(args, kwargs)
A:keras.engine.node.arguments->dict(zip(self.layer._call_fn_args[1:], args))
A:keras.engine.node.node_key->make_node_key(kh.layer.name, node_index)
A:keras.engine.node.new_node_index->node_conversion_map.get(node_key, 0)
A:keras.engine.node.kwargs->tensorflow.compat.v2.nest.map_structure(_serialize_keras_tensor, kwargs)
A:keras.engine.node.kwarg_types->tensorflow.compat.v2.nest.map_structure(type, kwargs)
A:keras.engine.node.data->keras.utils.tf_utils.convert_inner_node_data(data)
A:keras.engine.node.input_shapes->tensorflow.compat.v2.nest.map_structure(backend.int_shape, self.input_tensors)
A:keras.engine.node.inbound_layers->tensorflow.compat.v2.nest.map_structure(lambda t: t._keras_history.layer, tensor_call_args)
keras.engine.node.KerasHistory(collections.namedtuple('KerasHistory',['layer','node_index','tensor_index']))
keras.engine.node.Node(self,layer,call_args=None,call_kwargs=None,outputs=None)
keras.engine.node.Node.__init__(self,layer,call_args=None,call_kwargs=None,outputs=None)
keras.engine.node.Node.inbound_layers(self)
keras.engine.node.Node.input_shapes(self)
keras.engine.node.Node.input_tensors(self)
keras.engine.node.Node.iterate_inbound(self)
keras.engine.node.Node.keras_inputs(self)
keras.engine.node.Node.map_arguments(self,tensor_dict)
keras.engine.node.Node.outbound_layer(self)
keras.engine.node.Node.output_shapes(self)
keras.engine.node.Node.output_tensors(self)
keras.engine.node.Node.parent_nodes(self)
keras.engine.node.Node.serialize(self,make_node_key,node_conversion_map)
keras.engine.node.is_keras_tensor(obj)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/base_layer.py----------------------------------------
A:keras.engine.base_layer.metrics_mod->keras.utils.generic_utils.LazyLoader('metrics_mod', globals(), 'keras.metrics')
A:keras.engine.base_layer.keras_layers_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/layers', 'keras layers usage', 'method')
A:keras.engine.base_layer.keras_models_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/models', 'keras model usage', 'method')
A:keras.engine.base_layer.keras_api_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras', 'keras api usage', 'method')
A:keras.engine.base_layer.keras_premade_model_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/premade_models', 'premade keras model usage', 'type')
A:keras.engine.base_layer._name_scope_unnester_stack->threading.local()
A:keras.engine.base_layer.relative_name_scope->filter(None, [tf.get_current_name_scope(), relative_name_scope_on_declaration])
A:keras.engine.base_layer.self._activity_regularizer->keras.regularizers.get(kwargs.pop('activity_regularizer', None))
A:keras.engine.base_layer.self._thread_local->threading.local()
A:keras.engine.base_layer.self._metrics_lock->threading.Lock()
A:keras.engine.base_layer.self._autocast->copy.copy(kwargs).get('autocast', base_layer_utils.v2_dtype_behavior_enabled())
A:keras.engine.base_layer.batch_input_shape->tuple(kwargs['batch_input_shape'])
A:keras.engine.base_layer.self._initial_weights->copy.copy(kwargs).get('weights', None)
A:keras.engine.base_layer.self._name_scope_on_declaration->tensorflow.compat.v2.get_current_name_scope()
A:keras.engine.base_layer.collections_arg->copy.copy(kwargs).pop('collections', None)
A:keras.engine.base_layer.autocast->copy.copy(kwargs).pop('experimental_autocast', True)
A:keras.engine.base_layer.caching_device->copy.copy(kwargs).pop('caching_device', None)
A:keras.engine.base_layer.layout->getattr(self, name + '_layout', None)
A:keras.engine.base_layer.dtype->tensorflow.compat.v2.as_dtype(dtype)
A:keras.engine.base_layer.initializer->keras.initializers.get('zeros')
A:keras.engine.base_layer.regularizer->keras.regularizers.get(regularizer)
A:keras.engine.base_layer.constraint->keras.constraints.get(constraint)
A:keras.engine.base_layer.getter->functools.partial(getter, layout=layout)
A:keras.engine.base_layer.variable->self._add_variable_with_custom_getter(name=name, shape=shape, getter=getter, overwrite=True, initializer=initializer, dtype=dtype, constraint=constraint, trainable=trainable, use_resource=use_resource, collections=collections_arg, synchronization=synchronization, aggregation=aggregation, caching_device=caching_device)
A:keras.engine.base_layer.config['dtype']->keras.mixed_precision.policy.serialize(self._dtype_policy)
A:keras.engine.base_layer.expected_args->super(AddMetric, self).get_config().keys()
A:keras.engine.base_layer.input_shape->tensorflow.compat.v2.nest.map_structure(check_type_return_shape, input_signature)
A:keras.engine.base_layer.ph->keras.backend.placeholder(shape=shape, dtype=self.dtype)
A:keras.engine.base_layer.inputs->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.base_layer.outputs->tensorflow.compat.v2.nest.pack_sequence_as(outputs, outputs_copy)
A:keras.engine.base_layer.output_shape->self.compute_output_shape(input_shape)
A:keras.engine.base_layer.(inputs, args, kwargs)->self._split_out_first_arg(args, kwargs)
A:keras.engine.base_layer.input_list->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.base_layer.call_context->keras.engine.base_layer_utils.call_context()
A:keras.engine.base_layer.(input_masks, mask_is_implicit)->self._get_input_masks(inputs, input_list, args, kwargs)
A:keras.engine.base_layer.(args, kwargs, training_mode)->self._set_training_mode(args, kwargs, call_context)
A:keras.engine.base_layer.eager->tensorflow.compat.v2.executing_eagerly()
A:keras.engine.base_layer.name_scope->self._name_scope()
A:keras.engine.base_layer.call_fn->keras.utils.traceback_utils.inject_argument_info_in_traceback(call_fn, object_name=f'layer "{self.name}" (type {self.__class__.__name__})')
A:keras.engine.base_layer.children_weights->self._gather_children_attribute('variables')
A:keras.engine.base_layer.loss_tensor->regularizer()
A:keras.engine.base_layer.loss->tensorflow.compat.v2.convert_to_tensor(loss, dtype=backend.floatx())
A:keras.engine.base_layer.losses->tensorflow.compat.v2.nest.flatten(losses)
A:keras.engine.base_layer.kwargs_keys->list(kwargs.keys())
A:keras.engine.base_layer.from_metric_obj->hasattr(value, '_metric_obj')
A:keras.engine.base_layer.is_symbolic->isinstance(value, keras_tensor.KerasTensor)
A:keras.engine.base_layer.metric_obj->keras.utils.generic_utils.LazyLoader('metrics_mod', globals(), 'keras.metrics').Mean(name=name, dtype=getattr(value, 'dtype', None))
A:keras.engine.base_layer.match->self._get_existing_metric(name)
A:keras.engine.base_layer.output->self.get_output_at(node_index)
A:keras.engine.base_layer.all_input_shapes->set([str(node.input_shapes) for node in self._inbound_nodes])
A:keras.engine.base_layer.all_output_shapes->set([str(node.output_shapes) for node in self._inbound_nodes])
A:keras.engine.base_layer._TF_MODULE_IGNORED_PROPERTIES->frozenset(itertools.chain(('_obj_reference_counts_dict',), tf.Module._TF_MODULE_IGNORED_PROPERTIES))
A:keras.engine.base_layer.canonical_name->get_canonical_name_for_symbol(self.__class__, api_name='keras', add_prefix_to_v1_names=True)
A:keras.engine.base_layer.handler->keras.engine.base_layer_utils.TrackableWeightHandler(trackable_object)
A:keras.engine.base_layer.input_signature->tensorflow.compat.v2.nest.map_structure(lambda x: tf.TensorSpec(shape=x.shape, dtype=x.dtype), inputs)
A:keras.engine.base_layer.output_signature->self.compute_output_signature(input_signature)
A:keras.engine.base_layer.scratch_graph->tensorflow.compat.v2.__internal__.FuncGraph(str(self.name) + '_scratch_graph')
A:keras.engine.base_layer.args->list(args)
A:keras.engine.base_layer.kwargs->copy.copy(kwargs)
A:keras.engine.base_layer.input_masks->tensorflow.compat.v2.nest.pack_sequence_as(inputs, input_masks)
A:keras.engine.base_layer.training_value->bool(training_value)
A:keras.engine.base_layer.(args, kwargs)->self._set_call_arg_value('training', training_mode, args, kwargs)
A:keras.engine.base_layer.training_mode->copy.copy(kwargs).pop('training')
A:keras.engine.base_layer.self._dtype_policy->keras.mixed_precision.policy.global_policy()
A:keras.engine.base_layer.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.base_layer.self._compute_dtype_object->tensorflow.compat.v2.as_dtype(self._dtype_policy.compute_dtype)
A:keras.engine.base_layer.current_name_scope->tensorflow.compat.v2.__internal__.get_name_scope()
A:keras.engine.base_layer.self._name->keras.backend.unique_object_name(generic_utils.to_snake_case(self.__class__.__name__), zero_based=zero_based)
A:keras.engine.base_layer.regularization->regularizer(v)
A:keras.engine.base_layer.output_list->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.base_layer.activity_loss->self._activity_regularizer(output)
A:keras.engine.base_layer.batch_size->tensorflow.compat.v2.cast(tf.shape(output)[0], activity_loss.dtype)
A:keras.engine.base_layer.flat_outputs->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.base_layer.output_masks->self.compute_mask(inputs, previous_mask)
A:keras.engine.base_layer.flat_masks->tensorflow.compat.v2.nest.flatten(output_masks)
A:keras.engine.base_layer.args_dict->dict(zip(call_fn_args, args))
A:keras.engine.base_layer.arg_pos->self._call_fn_arg_positions.get(arg_name, None)
A:keras.engine.base_layer.flat_inputs->tensorflow.compat.v2.nest.flatten((args, kwargs))
A:keras.engine.base_layer.x->tensorflow.compat.v2.identity(x)
A:keras.engine.base_layer.values->getattr(self._inbound_nodes[node_index], attr)
A:keras.engine.base_layer.input_shapes->keras.utils.tf_utils.convert_shapes(inputs, to_tuples=False)
A:keras.engine.base_layer.trainable_state->weakref.WeakKeyDictionary()
A:keras.engine.base_layer.existing_value->getattr(self, name, None)
A:keras.engine.base_layer.value->tensorflow.compat.v2.get_static_value(constant)
A:keras.engine.base_layer.nested_layers->self._flatten_modules(include_self=False, recursive=False)
A:keras.engine.base_layer.trackables->getattr(self, '_self_tracked_trackables', None)
A:keras.engine.base_layer.seen_object_ids->set()
A:keras.engine.base_layer.deque->collections.deque(trackables)
A:keras.engine.base_layer.trackable_obj->collections.deque(trackables).popleft()
A:keras.engine.base_layer.trackable_id->id(trackable_obj)
A:keras.engine.base_layer.subtrackables->getattr(trackable_obj, '_self_tracked_trackables', None)
A:keras.engine.base_layer.call_fn_arg_defaults->self._call_fn_arg_defaults.copy()
A:keras.engine.base_layer.self._default_training_arg->self._call_fn_arg_defaults.copy().get('training')
A:keras.engine.base_layer.defaults->dict()
A:keras.engine.base_layer.call_fn_arg_positions->dict()
A:keras.engine.base_layer.inputs_spec->tensorflow.compat.v2.nest.map_structure(tf_utils.get_tensor_spec, inputs)
A:keras.engine.base_layer.flat_arg->tensorflow.compat.v2.nest.flatten(arg)
A:keras.engine.base_layer.flat_kwarg->tensorflow.compat.v2.nest.flatten(kwarg)
A:keras.engine.base_layer.kwargs_spec[key]->tensorflow.compat.v2.nest.pack_sequence_as(kwarg, flat_specs)
A:keras.engine.base_layer.spec->tensorflow.compat.v2.nest.map_structure(lambda t: tf_utils.get_tensor_spec(t, dynamic_batch=dynamic_batch), self._saved_model_arg_spec)
A:keras.engine.base_layer.children->self._trackable_saved_model_saver.trackable_children(cache)
A:keras.engine.base_layer.state->self.__dict__.copy()
A:keras.engine.base_layer.state['_thread_local']->threading.local()
A:keras.engine.base_layer.state['_metrics_lock']->threading.Lock()
A:keras.engine.base_layer.self.node_def->tensorflow.compat.v2.compat.v1.NodeDef.FromString(node_def)
A:keras.engine.base_layer.node_def->self._make_node_def(graph)
A:keras.engine.base_layer.node_def.name->graph.unique_name(node_def.name)
A:keras.engine.base_layer.constant->tensorflow.compat.v2.constant(value, name=node_def.input[index])
A:keras.engine.base_layer.c_op->tensorflow.compat.v2.__internal__.create_c_op(graph, node_def, inputs, control_inputs=[])
A:keras.engine.base_layer.op->graph._create_op_from_tf_operation(c_op)
A:keras.engine.base_layer.op_type->tensorflow.compat.v2.compat.as_str(op.op_def.name)
A:keras.engine.base_layer.attrs->tuple(attrs)
A:keras.engine.base_layer.config->super(AddMetric, self).get_config()
A:keras.engine.base_layer.self._random_generator->keras.backend.RandomGenerator(seed, force_generator=force_generator)
keras.engine.base_layer.AddLoss(self,unconditional,**kwargs)
keras.engine.base_layer.AddLoss.__init__(self,unconditional,**kwargs)
keras.engine.base_layer.AddLoss.call(self,inputs)
keras.engine.base_layer.AddLoss.get_config(self)
keras.engine.base_layer.AddMetric(self,aggregation=None,metric_name=None,**kwargs)
keras.engine.base_layer.AddMetric.__init__(self,aggregation=None,metric_name=None,**kwargs)
keras.engine.base_layer.AddMetric.call(self,inputs)
keras.engine.base_layer.AddMetric.get_config(self)
keras.engine.base_layer.BaseRandomLayer(self,seed=None,force_generator=False,**kwargs)
keras.engine.base_layer.BaseRandomLayer.__init__(self,seed=None,force_generator=False,**kwargs)
keras.engine.base_layer.BaseRandomLayer._trackable_children(self,save_type='checkpoint',**kwargs)
keras.engine.base_layer.Layer(self,trainable=True,name=None,dtype=None,dynamic=False,**kwargs)
keras.engine.base_layer.Layer.__delattr__(self,name)
keras.engine.base_layer.Layer.__getstate__(self)
keras.engine.base_layer.Layer.__init__(self,trainable=True,name=None,dtype=None,dynamic=False,**kwargs)
keras.engine.base_layer.Layer.__setattr__(self,name,value)
keras.engine.base_layer.Layer.__setstate__(self,state)
keras.engine.base_layer.Layer._add_trackable(self,trackable_object,trainable)
keras.engine.base_layer.Layer._autographed_call(self)
keras.engine.base_layer.Layer._call_accepts_kwargs(self)
keras.engine.base_layer.Layer._call_arg_was_passed(self,arg_name,args,kwargs,inputs_in_args=False)
keras.engine.base_layer.Layer._call_fn_arg_defaults(self)
keras.engine.base_layer.Layer._call_fn_arg_positions(self)
keras.engine.base_layer.Layer._call_fn_args(self)
keras.engine.base_layer.Layer._call_full_argspec(self)
keras.engine.base_layer.Layer._cast_single_input(self,x)
keras.engine.base_layer.Layer._clear_losses(self)
keras.engine.base_layer.Layer._compute_dtype(self)
keras.engine.base_layer.Layer._dedup_weights(self,weights)
keras.engine.base_layer.Layer._dtype(self)
keras.engine.base_layer.Layer._dtype(self,value)
keras.engine.base_layer.Layer._eager_losses(self)
keras.engine.base_layer.Layer._eager_losses(self,losses)
keras.engine.base_layer.Layer._flatten_layers(self,recursive=True,include_self=True)
keras.engine.base_layer.Layer._flatten_modules(self,recursive=True,include_self=True)
keras.engine.base_layer.Layer._functional_construction_call(self,inputs,args,kwargs,input_list)
keras.engine.base_layer.Layer._gather_children_attribute(self,attribute)
keras.engine.base_layer.Layer._get_call_arg_value(self,arg_name,args,kwargs,inputs_in_args=False)
keras.engine.base_layer.Layer._get_cell_name(self)
keras.engine.base_layer.Layer._get_existing_metric(self,name=None)
keras.engine.base_layer.Layer._get_input_masks(self,inputs,input_list,args,kwargs)
keras.engine.base_layer.Layer._get_node_attribute_at_index(self,node_index,attr,attr_name)
keras.engine.base_layer.Layer._get_save_spec(self,dynamic_batch=True,inputs_only=True)
keras.engine.base_layer.Layer._get_trainable_state(self)
keras.engine.base_layer.Layer._get_unnested_name_scope(self)
keras.engine.base_layer.Layer._handle_activity_regularization(self,inputs,outputs)
keras.engine.base_layer.Layer._handle_weight_regularization(self,name,variable,regularizer)
keras.engine.base_layer.Layer._inbound_nodes(self)
keras.engine.base_layer.Layer._inbound_nodes(self,value)
keras.engine.base_layer.Layer._infer_output_signature(self,inputs,args,kwargs,input_masks)
keras.engine.base_layer.Layer._init_call_fn_args(self,expects_training_arg=None)
keras.engine.base_layer.Layer._init_set_name(self,name,zero_based=True)
keras.engine.base_layer.Layer._instrument_layer_creation(self)
keras.engine.base_layer.Layer._is_layer(self)
keras.engine.base_layer.Layer._keras_tensor_symbolic_call(self,inputs,input_masks,args,kwargs)
keras.engine.base_layer.Layer._maybe_build(self,inputs)
keras.engine.base_layer.Layer._maybe_cast_inputs(self,inputs,input_list=None)
keras.engine.base_layer.Layer._maybe_create_attribute(self,name,default_value)
keras.engine.base_layer.Layer._name_scope(self)
keras.engine.base_layer.Layer._obj_reference_counts(self)
keras.engine.base_layer.Layer._object_identifier(self)
keras.engine.base_layer.Layer._outbound_nodes(self)
keras.engine.base_layer.Layer._outbound_nodes(self,value)
keras.engine.base_layer.Layer._set_call_arg_value(self,arg_name,new_value,args,kwargs,inputs_in_args=False,pop_kwarg_if_none=False)
keras.engine.base_layer.Layer._set_connectivity_metadata(self,args,kwargs,outputs)
keras.engine.base_layer.Layer._set_dtype_policy(self,dtype)
keras.engine.base_layer.Layer._set_mask_keras_history_checked(self,flat_outputs)
keras.engine.base_layer.Layer._set_mask_metadata(self,inputs,outputs,previous_mask,build_graph)
keras.engine.base_layer.Layer._set_save_spec(self,inputs,args=None,kwargs=None)
keras.engine.base_layer.Layer._set_trainable_state(self,trainable_state)
keras.engine.base_layer.Layer._set_training_mode(self,args,kwargs,call_context)
keras.engine.base_layer.Layer._should_cast_single_input(self,x)
keras.engine.base_layer.Layer._split_out_first_arg(self,args,kwargs)
keras.engine.base_layer.Layer._trackable_children(self,save_type='checkpoint',**kwargs)
keras.engine.base_layer.Layer._trackable_saved_model_saver(self)
keras.engine.base_layer.Layer._tracking_metadata(self)
keras.engine.base_layer.Layer._use_input_spec_as_call_signature(self)
keras.engine.base_layer.Layer.activity_regularizer(self)
keras.engine.base_layer.Layer.activity_regularizer(self,regularizer)
keras.engine.base_layer.Layer.add_loss(self,losses,**kwargs)
keras.engine.base_layer.Layer.add_metric(self,value,name=None,**kwargs)
keras.engine.base_layer.Layer.add_update(self,updates)
keras.engine.base_layer.Layer.add_variable(self,*args,**kwargs)
keras.engine.base_layer.Layer.add_weight(self,name=None,shape=None,dtype=None,initializer=None,regularizer=None,trainable=None,constraint=None,use_resource=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.VariableAggregation.NONE,**kwargs)
keras.engine.base_layer.Layer.build(self,input_shape)
keras.engine.base_layer.Layer.call(self,inputs,*args,**kwargs)
keras.engine.base_layer.Layer.compute_dtype(self)
keras.engine.base_layer.Layer.compute_mask(self,inputs,mask=None)
keras.engine.base_layer.Layer.compute_output_shape(self,input_shape)
keras.engine.base_layer.Layer.compute_output_signature(self,input_signature)
keras.engine.base_layer.Layer.count_params(self)
keras.engine.base_layer.Layer.dtype(self)
keras.engine.base_layer.Layer.dtype_policy(self)
keras.engine.base_layer.Layer.dynamic(self)
keras.engine.base_layer.Layer.finalize_state(self)
keras.engine.base_layer.Layer.from_config(cls,config)
keras.engine.base_layer.Layer.get_config(self)
keras.engine.base_layer.Layer.get_input_at(self,node_index)
keras.engine.base_layer.Layer.get_input_mask_at(self,node_index)
keras.engine.base_layer.Layer.get_input_shape_at(self,node_index)
keras.engine.base_layer.Layer.get_output_at(self,node_index)
keras.engine.base_layer.Layer.get_output_mask_at(self,node_index)
keras.engine.base_layer.Layer.get_output_shape_at(self,node_index)
keras.engine.base_layer.Layer.get_weights(self)
keras.engine.base_layer.Layer.inbound_nodes(self)
keras.engine.base_layer.Layer.input(self)
keras.engine.base_layer.Layer.input_mask(self)
keras.engine.base_layer.Layer.input_shape(self)
keras.engine.base_layer.Layer.input_spec(self)
keras.engine.base_layer.Layer.input_spec(self,value)
keras.engine.base_layer.Layer.losses(self)
keras.engine.base_layer.Layer.metrics(self)
keras.engine.base_layer.Layer.name(self)
keras.engine.base_layer.Layer.non_trainable_variables(self)
keras.engine.base_layer.Layer.non_trainable_weights(self)
keras.engine.base_layer.Layer.outbound_nodes(self)
keras.engine.base_layer.Layer.output(self)
keras.engine.base_layer.Layer.output_mask(self)
keras.engine.base_layer.Layer.output_shape(self)
keras.engine.base_layer.Layer.set_weights(self,weights)
keras.engine.base_layer.Layer.stateful(self)
keras.engine.base_layer.Layer.stateful(self,value)
keras.engine.base_layer.Layer.supports_masking(self)
keras.engine.base_layer.Layer.supports_masking(self,value)
keras.engine.base_layer.Layer.trainable(self)
keras.engine.base_layer.Layer.trainable(self,value)
keras.engine.base_layer.Layer.trainable_variables(self)
keras.engine.base_layer.Layer.trainable_weights(self)
keras.engine.base_layer.Layer.updates(self)
keras.engine.base_layer.Layer.variable_dtype(self)
keras.engine.base_layer.Layer.variables(self)
keras.engine.base_layer.Layer.weights(self)
keras.engine.base_layer.TensorFlowOpLayer(self,node_def,name,constants=None,trainable=True,dtype=None)
keras.engine.base_layer.TensorFlowOpLayer.__init__(self,node_def,name,constants=None,trainable=True,dtype=None)
keras.engine.base_layer.TensorFlowOpLayer._defun_call(self,inputs)
keras.engine.base_layer.TensorFlowOpLayer._make_node_def(self,graph)
keras.engine.base_layer.TensorFlowOpLayer._make_op(self,inputs)
keras.engine.base_layer.TensorFlowOpLayer.call(self,inputs)
keras.engine.base_layer.TensorFlowOpLayer.get_config(self)
keras.engine.base_layer._apply_name_scope_on_model_declaration(enable)
keras.engine.base_layer._convert_numpy_or_python_types(x)
keras.engine.base_layer._in_functional_construction_mode(layer,inputs,args,kwargs,input_list)
keras.engine.base_layer._name_scope_unnester(full_name_scope)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/base_layer_v1.py----------------------------------------
A:keras.engine.base_layer_v1._TF_MODULE_IGNORED_PROPERTIES->frozenset(itertools.chain(('_obj_reference_counts_dict',), tf.Module._TF_MODULE_IGNORED_PROPERTIES))
A:keras.engine.base_layer_v1.self._activity_regularizer->keras.regularizers.get(kwargs.pop('activity_regularizer', None))
A:keras.engine.base_layer_v1.self._thread_local->threading.local()
A:keras.engine.base_layer_v1.self._autocast->kwargs.get('autocast', base_layer_utils.v2_dtype_behavior_enabled())
A:keras.engine.base_layer_v1.batch_input_shape->tuple(kwargs['batch_input_shape'])
A:keras.engine.base_layer_v1.self._initial_weights->kwargs.get('weights', None)
A:keras.engine.base_layer_v1.handler->keras.engine.base_layer_utils.TrackableWeightHandler(trackable_object)
A:keras.engine.base_layer_v1.getter->kwargs.pop('getter', base_layer_utils.make_variable)
A:keras.engine.base_layer_v1.collections_arg->kwargs.pop('collections', None)
A:keras.engine.base_layer_v1.autocast->kwargs.pop('experimental_autocast', True)
A:keras.engine.base_layer_v1.caching_device->kwargs.pop('caching_device', None)
A:keras.engine.base_layer_v1.dtype->tensorflow.compat.v2.as_dtype(dtype)
A:keras.engine.base_layer_v1.initializer->tensorflow.compat.v2.compat.v1.zeros_initializer()
A:keras.engine.base_layer_v1.regularizer->keras.regularizers.get(regularizer)
A:keras.engine.base_layer_v1.constraint->keras.constraints.get(constraint)
A:keras.engine.base_layer_v1.variable->self._add_variable_with_custom_getter(name=name, shape=shape, getter=getter, overwrite=True, initializer=initializer, dtype=dtype, constraint=constraint, trainable=trainable, partitioner=partitioner, use_resource=use_resource, collections=collections_arg, synchronization=synchronization, aggregation=aggregation, caching_device=caching_device)
A:keras.engine.base_layer_v1.config['dtype']->keras.mixed_precision.policy.serialize(self._dtype_policy)
A:keras.engine.base_layer_v1.expected_args->config.keys()
A:keras.engine.base_layer_v1.graph->keras.backend.get_graph()
A:keras.engine.base_layer_v1.input_shape->tensorflow.compat.v2.nest.map_structure(check_type_return_shape, input_signature)
A:keras.engine.base_layer_v1.inputs->self.get_input_at(node_index)
A:keras.engine.base_layer_v1.outputs->self.call(cast_inputs, *args, **kwargs)
A:keras.engine.base_layer_v1.output_shape->self.compute_output_shape(input_shape)
A:keras.engine.base_layer_v1.call_context->keras.engine.base_layer_utils.call_context()
A:keras.engine.base_layer_v1.input_list->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.base_layer_v1.build_graph->keras.utils.tf_utils.are_all_symbolic_tensors(input_list)
A:keras.engine.base_layer_v1.input_masks->tensorflow.compat.v2.nest.map_structure(lambda t: getattr(t, '_keras_mask', None), inputs)
A:keras.engine.base_layer_v1.training_value->bool(training_value)
A:keras.engine.base_layer_v1.(args, kwargs)->self._set_call_arg_value('training', None, args, kwargs, pop_kwarg_if_none=True)
A:keras.engine.base_layer_v1.cast_inputs->self._maybe_cast_inputs(inputs)
A:keras.engine.base_layer_v1.call_fn->tensorflow.compat.v2.__internal__.autograph.tf_convert(self.call, tf.__internal__.autograph.control_status_ctx())
A:keras.engine.base_layer_v1.all_layers->self._flatten_layers()
A:keras.engine.base_layer_v1.u->u()
A:keras.engine.base_layer_v1.loss_tensor->regularizer()
A:keras.engine.base_layer_v1.loss->tensorflow.compat.v2.convert_to_tensor(loss, dtype=backend.floatx())
A:keras.engine.base_layer_v1.losses->tensorflow.compat.v2.nest.flatten(losses)
A:keras.engine.base_layer_v1.from_metric_obj->hasattr(value, '_metric_obj')
A:keras.engine.base_layer_v1.is_symbolic->keras.utils.tf_utils.is_symbolic_tensor(value)
A:keras.engine.base_layer_v1.updates->keras.utils.generic_utils.to_list(updates)
A:keras.engine.base_layer_v1.inbound_nodes->getattr(self, '_inbound_nodes', [])
A:keras.engine.base_layer_v1.update->tensorflow.compat.v2.convert_to_tensor(x)
A:keras.engine.base_layer_v1.reachable->keras.utils.tf_utils.get_reachable_from_inputs(inputs, losses)
A:keras.engine.base_layer_v1.output->self.get_output_at(node_index)
A:keras.engine.base_layer_v1.all_input_shapes->set([str(node.input_shapes) for node in self._inbound_nodes])
A:keras.engine.base_layer_v1.all_output_shapes->set([str(node.output_shapes) for node in self._inbound_nodes])
A:keras.engine.base_layer_v1.self._dtype_policy->keras.mixed_precision.policy.global_policy()
A:keras.engine.base_layer_v1.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.engine.base_layer_v1.self._compute_dtype_object->tensorflow.compat.v2.as_dtype(self._dtype_policy.compute_dtype)
A:keras.engine.base_layer_v1.self._name->keras.backend.unique_object_name(generic_utils.to_snake_case(self.__class__.__name__), zero_based=zero_based)
A:keras.engine.base_layer_v1.match->self._get_existing_metric(name)
A:keras.engine.base_layer_v1.result_tensor->match(value)
A:keras.engine.base_layer_v1.(metric_obj, result_tensor)->keras.engine.base_layer_utils.create_mean_metric(value, name)
A:keras.engine.base_layer_v1.regularization->regularizer(v)
A:keras.engine.base_layer_v1.output_list->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.base_layer_v1.activity_loss->self._activity_regularizer(output)
A:keras.engine.base_layer_v1.batch_size->tensorflow.compat.v2.cast(tf.compat.v1.shape(output)[0], activity_loss.dtype)
A:keras.engine.base_layer_v1.flat_outputs->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.base_layer_v1.output_masks->self.compute_mask(inputs, previous_mask)
A:keras.engine.base_layer_v1.flat_masks->tensorflow.compat.v2.nest.flatten(output_masks)
A:keras.engine.base_layer_v1.args_dict->dict(zip(call_fn_args, args))
A:keras.engine.base_layer_v1.arg_pos->self._call_fn_arg_positions.get(arg_name, None)
A:keras.engine.base_layer_v1.args->list(args)
A:keras.engine.base_layer_v1.values->getattr(self._inbound_nodes[node_index], attr)
A:keras.engine.base_layer_v1.input_shapes->tensorflow.compat.v2.nest.map_structure(lambda x: x.shape, inputs)
A:keras.engine.base_layer_v1.output_shapes->self.compute_output_shape(input_shapes)
A:keras.engine.base_layer_v1.ph->keras.backend.placeholder(shape=shape, dtype=self.dtype)
A:keras.engine.base_layer_v1.layers->self._flatten_layers(include_self=False, recursive=False)
A:keras.engine.base_layer_v1.existing_value->getattr(self, name, None)
A:keras.engine.base_layer_v1.value->tensorflow.compat.v2.__internal__.tracking.sticky_attribute_assignment(trackable=self, value=value, name=name)
A:keras.engine.base_layer_v1.call_fn_arg_positions->dict()
A:keras.engine.base_layer_v1.children->self._trackable_saved_model_saver.trackable_children(cache)
A:keras.engine.base_layer_v1.state->self.__dict__.copy()
A:keras.engine.base_layer_v1.state['_thread_local']->threading.local()
keras.engine.base_layer_v1.Layer(self,trainable=True,name=None,dtype=None,dynamic=False,**kwargs)
keras.engine.base_layer_v1.Layer.__delattr__(self,name)
keras.engine.base_layer_v1.Layer.__getstate__(self)
keras.engine.base_layer_v1.Layer.__init__(self,trainable=True,name=None,dtype=None,dynamic=False,**kwargs)
keras.engine.base_layer_v1.Layer.__setattr__(self,name,value)
keras.engine.base_layer_v1.Layer.__setstate__(self,state)
keras.engine.base_layer_v1.Layer._add_trackable(self,trackable_object,trainable)
keras.engine.base_layer_v1.Layer._assert_built_as_v1(self)
keras.engine.base_layer_v1.Layer._call_accepts_kwargs(self)
keras.engine.base_layer_v1.Layer._call_arg_was_passed(self,arg_name,args,kwargs,inputs_in_args=False)
keras.engine.base_layer_v1.Layer._call_fn_arg_positions(self)
keras.engine.base_layer_v1.Layer._call_fn_args(self)
keras.engine.base_layer_v1.Layer._call_full_argspec(self)
keras.engine.base_layer_v1.Layer._collect_input_masks(self,inputs,args,kwargs)
keras.engine.base_layer_v1.Layer._compute_dtype(self)
keras.engine.base_layer_v1.Layer._dedup_weights(self,weights)
keras.engine.base_layer_v1.Layer._dtype(self)
keras.engine.base_layer_v1.Layer._dtype(self,value)
keras.engine.base_layer_v1.Layer._get_call_arg_value(self,arg_name,args,kwargs,inputs_in_args=False)
keras.engine.base_layer_v1.Layer._get_existing_metric(self,name=None)
keras.engine.base_layer_v1.Layer._get_node_attribute_at_index(self,node_index,attr,attr_name)
keras.engine.base_layer_v1.Layer._get_trainable_state(self)
keras.engine.base_layer_v1.Layer._handle_activity_regularization(self,inputs,outputs)
keras.engine.base_layer_v1.Layer._handle_weight_regularization(self,name,variable,regularizer)
keras.engine.base_layer_v1.Layer._inbound_nodes(self)
keras.engine.base_layer_v1.Layer._inbound_nodes(self,value)
keras.engine.base_layer_v1.Layer._init_call_fn_args(self,expects_training_arg=None)
keras.engine.base_layer_v1.Layer._init_set_name(self,name,zero_based=True)
keras.engine.base_layer_v1.Layer._is_layer(self)
keras.engine.base_layer_v1.Layer._maybe_build(self,inputs)
keras.engine.base_layer_v1.Layer._maybe_cast_inputs(self,inputs)
keras.engine.base_layer_v1.Layer._maybe_create_attribute(self,name,default_value)
keras.engine.base_layer_v1.Layer._name_scope(self)
keras.engine.base_layer_v1.Layer._obj_reference_counts(self)
keras.engine.base_layer_v1.Layer._object_identifier(self)
keras.engine.base_layer_v1.Layer._outbound_nodes(self)
keras.engine.base_layer_v1.Layer._outbound_nodes(self,value)
keras.engine.base_layer_v1.Layer._set_call_arg_value(self,arg_name,new_value,args,kwargs,inputs_in_args=False,pop_kwarg_if_none=False)
keras.engine.base_layer_v1.Layer._set_dtype_policy(self,dtype)
keras.engine.base_layer_v1.Layer._set_mask_metadata(self,inputs,outputs,previous_mask)
keras.engine.base_layer_v1.Layer._set_trainable_state(self,trainable_state)
keras.engine.base_layer_v1.Layer._should_compute_mask(self)
keras.engine.base_layer_v1.Layer._symbolic_add_metric(self,value,aggregation=None,name=None)
keras.engine.base_layer_v1.Layer._symbolic_call(self,inputs)
keras.engine.base_layer_v1.Layer._trackable_children(self,save_type='checkpoint',**kwargs)
keras.engine.base_layer_v1.Layer._trackable_saved_model_saver(self)
keras.engine.base_layer_v1.Layer._tracking_metadata(self)
keras.engine.base_layer_v1.Layer.activity_regularizer(self)
keras.engine.base_layer_v1.Layer.activity_regularizer(self,regularizer)
keras.engine.base_layer_v1.Layer.add_loss(self,losses,inputs=None)
keras.engine.base_layer_v1.Layer.add_metric(self,value,aggregation=None,name=None)
keras.engine.base_layer_v1.Layer.add_update(self,updates)
keras.engine.base_layer_v1.Layer.add_weight(self,name=None,shape=None,dtype=None,initializer=None,regularizer=None,trainable=None,constraint=None,partitioner=None,use_resource=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.compat.v1.VariableAggregation.NONE,**kwargs)
keras.engine.base_layer_v1.Layer.build(self,input_shape)
keras.engine.base_layer_v1.Layer.call(self,inputs,**kwargs)
keras.engine.base_layer_v1.Layer.compute_mask(self,inputs,mask=None)
keras.engine.base_layer_v1.Layer.compute_output_shape(self,input_shape)
keras.engine.base_layer_v1.Layer.compute_output_signature(self,input_signature)
keras.engine.base_layer_v1.Layer.count_params(self)
keras.engine.base_layer_v1.Layer.dtype(self)
keras.engine.base_layer_v1.Layer.dynamic(self)
keras.engine.base_layer_v1.Layer.from_config(cls,config)
keras.engine.base_layer_v1.Layer.get_config(self)
keras.engine.base_layer_v1.Layer.get_input_at(self,node_index)
keras.engine.base_layer_v1.Layer.get_input_mask_at(self,node_index)
keras.engine.base_layer_v1.Layer.get_input_shape_at(self,node_index)
keras.engine.base_layer_v1.Layer.get_losses_for(self,inputs)
keras.engine.base_layer_v1.Layer.get_output_at(self,node_index)
keras.engine.base_layer_v1.Layer.get_output_mask_at(self,node_index)
keras.engine.base_layer_v1.Layer.get_output_shape_at(self,node_index)
keras.engine.base_layer_v1.Layer.get_updates_for(self,inputs)
keras.engine.base_layer_v1.Layer.get_weights(self)
keras.engine.base_layer_v1.Layer.inbound_nodes(self)
keras.engine.base_layer_v1.Layer.input(self)
keras.engine.base_layer_v1.Layer.input_mask(self)
keras.engine.base_layer_v1.Layer.input_shape(self)
keras.engine.base_layer_v1.Layer.input_spec(self)
keras.engine.base_layer_v1.Layer.input_spec(self,value)
keras.engine.base_layer_v1.Layer.losses(self)
keras.engine.base_layer_v1.Layer.metrics(self)
keras.engine.base_layer_v1.Layer.name(self)
keras.engine.base_layer_v1.Layer.non_trainable_variables(self)
keras.engine.base_layer_v1.Layer.outbound_nodes(self)
keras.engine.base_layer_v1.Layer.output(self)
keras.engine.base_layer_v1.Layer.output_mask(self)
keras.engine.base_layer_v1.Layer.output_shape(self)
keras.engine.base_layer_v1.Layer.set_weights(self,weights)
keras.engine.base_layer_v1.Layer.stateful(self)
keras.engine.base_layer_v1.Layer.stateful(self,value)
keras.engine.base_layer_v1.Layer.trainable(self)
keras.engine.base_layer_v1.Layer.trainable(self,value)
keras.engine.base_layer_v1.Layer.trainable_variables(self)
keras.engine.base_layer_v1.Layer.updates(self)
keras.engine.base_layer_v1.Layer.variables(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/functional_utils.py----------------------------------------
A:keras.engine.functional_utils.start_keras_tensors->tensorflow.compat.v2.nest.flatten(outputs)
A:keras.engine.functional_utils.end_keras_tensors->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.engine.functional_utils.end_ids->set([id(kt) for kt in end_keras_tensors])
A:keras.engine.functional_utils.end_ids_found->set()
A:keras.engine.functional_utils.node_id_visited->set()
A:keras.engine.functional_utils.node->nodes_to_visit.pop(0)
A:keras.engine.functional_utils.nodes_to_clone->find_nodes_by_inputs_and_outputs(inputs, outputs)
A:keras.engine.functional_utils.cpy->_clone_keras_tensor(obj)
A:keras.engine.functional_utils.cloned_input->keras.engine.input_layer.Input(tensor=cpy)
A:keras.engine.functional_utils.cloned_inputs->tensorflow.compat.v2.nest.pack_sequence_as(inputs, cloned_inputs)
A:keras.engine.functional_utils.cloned_outputs->tensorflow.compat.v2.nest.pack_sequence_as(outputs, cloned_outputs)
A:keras.engine.functional_utils.output_copy->clone_keras_tensors(node.output_tensors, kt_id_mapping)
A:keras.engine.functional_utils.call_args_copy->clone_keras_tensors(node.call_args, kt_id_mapping)
A:keras.engine.functional_utils.call_kwargs_copy->clone_keras_tensors(node.call_kwargs, kt_id_mapping)
A:keras.engine.functional_utils.placeholder->keras.engine.keras_tensor.keras_tensor_to_placeholder(kt)
keras.engine.functional_utils._clone_keras_tensor(kt)
keras.engine.functional_utils.clone_graph_nodes(inputs,outputs)
keras.engine.functional_utils.clone_keras_tensors(args,keras_tensor_mapping)
keras.engine.functional_utils.find_nodes_by_inputs_and_outputs(inputs,outputs)
keras.engine.functional_utils.is_input_keras_tensor(tensor)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/training_generator_v1.py----------------------------------------
A:keras.engine.training_generator_v1.is_dataset->isinstance(data, (tf.data.Dataset, tf.compat.v1.data.Dataset))
A:keras.engine.training_generator_v1.steps_per_epoch->int(math.ceil(num_samples / batch_size))
A:keras.engine.training_generator_v1.(generator, steps_per_epoch)->convert_to_generator_like(data, steps_per_epoch=steps_per_epoch, batch_size=batch_size, epochs=epochs - initial_epoch, shuffle=shuffle)
A:keras.engine.training_generator_v1.is_sequence->isinstance(generator, data_utils.Sequence)
A:keras.engine.training_generator_v1.batch_function->_make_execution_function(model, mode, class_weight=class_weight)
A:keras.engine.training_generator_v1.(generator, enqueuer)->_make_enqueued_generator(generator, workers=workers, use_multiprocessing=use_multiprocessing, max_queue_size=max_queue_size, shuffle=shuffle)
A:keras.engine.training_generator_v1.(num_samples_or_steps, use_steps)->_get_num_samples_or_steps(data, steps_per_epoch)
A:keras.engine.training_generator_v1.callbacks->keras.callbacks.configure_callbacks(callbacks, model, do_validation=do_validation, epochs=epochs, steps_per_epoch=steps_per_epoch, batch_size=batch_size, samples=num_samples_or_steps, count_mode=count_mode, verbose=verbose, mode=mode)
A:keras.engine.training_generator_v1.aggregator->keras.engine.training_utils_v1.MetricsAggregator(True, steps=steps_per_epoch)
A:keras.engine.training_generator_v1.learning_phase_scope->keras.backend.eager_learning_phase_scope(1 if mode == ModeKeys.TRAIN else 0)
A:keras.engine.training_generator_v1.initial_epoch->model._maybe_load_initial_epoch_from_ckpt(initial_epoch, mode)
A:keras.engine.training_generator_v1.batch_data->_get_next_batch(generator)
A:keras.engine.training_generator_v1.batch_size->model._validate_or_infer_batch_size(batch_size, steps, x)
A:keras.engine.training_generator_v1.batch_outs->batch_function(*batch_data)
A:keras.engine.training_generator_v1.batch_logs->keras.callbacks.make_logs(model, batch_logs, batch_outs, mode)
A:keras.engine.training_generator_v1.epoch_logs->keras.callbacks.make_logs(model, epoch_logs, val_results, mode, prefix='val_')
A:keras.engine.training_generator_v1.val_results->model_iteration(model, validation_data, steps_per_epoch=validation_steps, batch_size=batch_size, class_weight=class_weight, workers=workers, use_multiprocessing=use_multiprocessing, max_queue_size=max_queue_size, callbacks=callbacks, verbose=verbose, mode=ModeKeys.TEST, steps_name='validation_steps')
A:keras.engine.training_generator_v1.generator->tensorflow.compat.v2.compat.v1.data.make_one_shot_iterator(original_dataset)
A:keras.engine.training_generator_v1.fit_generator->functools.partial(model_iteration, mode=ModeKeys.TRAIN)
A:keras.engine.training_generator_v1.evaluate_generator->functools.partial(model_iteration, mode=ModeKeys.TEST, shuffle=False)
A:keras.engine.training_generator_v1.predict_generator->functools.partial(model_iteration, mode=ModeKeys.PREDICT, shuffle=False)
A:keras.engine.training_generator_v1.generator_output->next(generator)
A:keras.engine.training_generator_v1.data->tuple((ele for ele in data if not all((e is None for e in tf.nest.flatten(ele)))))
A:keras.engine.training_generator_v1.num_samples->int(tf.nest.flatten(data)[0].shape[0])
A:keras.engine.training_generator_v1.index_array->numpy.arange(num_samples)
A:keras.engine.training_generator_v1.batches->keras.utils.generic_utils.make_batches(num_samples, batch_size)
A:keras.engine.training_generator_v1.flat_batch_data->keras.engine.training_utils.slice_arrays(tf.nest.flatten(data), batch_ids, contiguous=not shuffle)
A:keras.engine.training_generator_v1.enqueuer->keras.utils.data_utils.GeneratorEnqueuer(generator, use_multiprocessing=use_multiprocessing)
A:keras.engine.training_generator_v1.output_generator->keras.utils.data_utils.iter_sequence_infinite(generator)
A:keras.engine.training_generator_v1.f->functools.partial(f, reset_metrics=False)
A:keras.engine.training_generator_v1.flat_inputs->tensorflow.compat.v2.nest.flatten(data)
A:keras.engine.training_generator_v1.(x, y, sample_weights)->model._standardize_user_data(x, y, sample_weight=sample_weight, batch_size=batch_size, check_steps=True, steps_name='steps', steps=steps)
A:keras.engine.training_generator_v1.validation_data->model._prepare_validation_data(validation_data, batch_size, validation_steps)
A:keras.engine.training_generator_v1.(x, y, sample_weights, val_x, val_y, val_sample_weights)->keras.engine.training_utils_v1.split_training_and_validation_data(x, y, sample_weights, validation_split)
A:keras.engine.training_generator_v1.(x, _, _)->model._standardize_user_data(x, check_steps=True, steps_name='steps', steps=steps)
keras.engine.training_generator_v1.EagerDatasetOrIteratorTrainingLoop(training_utils_v1.TrainingLoop)
keras.engine.training_generator_v1.EagerDatasetOrIteratorTrainingLoop.evaluate(self,model,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,**kwargs)
keras.engine.training_generator_v1.EagerDatasetOrIteratorTrainingLoop.fit(self,model,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,**kwargs)
keras.engine.training_generator_v1.EagerDatasetOrIteratorTrainingLoop.predict(self,model,x,batch_size=None,verbose=0,steps=None,callbacks=None,**kwargs)
keras.engine.training_generator_v1.GeneratorLikeTrainingLoop(training_utils_v1.TrainingLoop)
keras.engine.training_generator_v1.GeneratorLikeTrainingLoop.evaluate(self,model,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,**kwargs)
keras.engine.training_generator_v1.GeneratorLikeTrainingLoop.fit(self,model,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,**kwargs)
keras.engine.training_generator_v1.GeneratorLikeTrainingLoop.predict(self,model,x,batch_size=None,verbose=0,steps=None,callbacks=None,**kwargs)
keras.engine.training_generator_v1.GeneratorOrSequenceTrainingLoop(training_utils_v1.TrainingLoop)
keras.engine.training_generator_v1.GeneratorOrSequenceTrainingLoop.evaluate(self,model,x=None,y=None,batch_size=None,verbose=1,sample_weight=None,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training_generator_v1.GeneratorOrSequenceTrainingLoop.fit(self,model,x=None,y=None,batch_size=None,epochs=1,verbose=1,callbacks=None,validation_split=0.0,validation_data=None,shuffle=True,class_weight=None,sample_weight=None,initial_epoch=0,steps_per_epoch=None,validation_steps=None,validation_freq=1,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training_generator_v1.GeneratorOrSequenceTrainingLoop.predict(self,model,x,batch_size=None,verbose=0,steps=None,callbacks=None,max_queue_size=10,workers=1,use_multiprocessing=False)
keras.engine.training_generator_v1._get_next_batch(generator)
keras.engine.training_generator_v1._get_num_samples_or_steps(data,steps_per_epoch)
keras.engine.training_generator_v1._make_enqueued_generator(generator,workers=1,use_multiprocessing=False,max_queue_size=10,shuffle=False)
keras.engine.training_generator_v1._make_execution_function(model,mode,class_weight=None)
keras.engine.training_generator_v1._validate_arguments(is_sequence,is_dataset,use_multiprocessing,workers,steps_per_epoch,validation_data,validation_steps,mode,kwargs)
keras.engine.training_generator_v1.convert_to_generator_like(data,batch_size=None,steps_per_epoch=None,epochs=1,shuffle=False)
keras.engine.training_generator_v1.model_iteration(model,data,steps_per_epoch=None,epochs=1,verbose=1,callbacks=None,validation_data=None,validation_steps=None,validation_freq=1,class_weight=None,max_queue_size=10,workers=1,use_multiprocessing=False,shuffle=False,initial_epoch=0,mode=ModeKeys.TRAIN,batch_size=None,steps_name='steps',**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/partial_batch_padding_handler.py----------------------------------------
A:keras.engine.partial_batch_padding_handler.self.padding_mask->tensorflow.compat.v2.zeros(0)
A:keras.engine.partial_batch_padding_handler.original_batch_size->self.get_real_batch_size(dataset_batch)
A:keras.engine.partial_batch_padding_handler.mask->keras.backend.concatenate([tf.ones(original_batch_size), tf.zeros(missing_count)], axis=0)
A:keras.engine.partial_batch_padding_handler.padded_dict_batch[key]->_pad(value)
A:keras.engine.partial_batch_padding_handler.rank->len(batch.shape)
A:keras.engine.partial_batch_padding_handler.padding->keras.backend.stack([[0, missing_count]] + [[0, 0]] * (rank - 1))
A:keras.engine.partial_batch_padding_handler.padding_mask->keras.backend.get_value(self.padding_mask)
A:keras.engine.partial_batch_padding_handler.prediction->numpy.take(prediction, np.nonzero(padding_mask[:len(prediction)]), axis=0)
keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler(self,output_shape)
keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler.__init__(self,output_shape)
keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler.apply_mask(self,prediction_result)
keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler.get_real_batch_size(self,dataset_batch)
keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler.pad_batch(self,*dataset_batch_elements)
keras.engine.partial_batch_padding_handler.PartialBatchPaddingHandler.update_mask(self,padding_mask,dataset_batch)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/engine/compile_utils.py----------------------------------------
A:keras.engine.compile_utils.self._output_names->create_pseudo_output_names(y_pred)
A:keras.engine.compile_utils.struct->copy.copy(struct)
A:keras.engine.compile_utils.self._loss_metric->keras.metrics.Mean(name='loss')
A:keras.engine.compile_utils.self._losses->tensorflow.compat.v2.nest.flatten(self._losses)
A:keras.engine.compile_utils.self._loss_weights->tensorflow.compat.v2.nest.flatten(self._loss_weights)
A:keras.engine.compile_utils.y_true->self._conform_to_outputs(y_pred, y_true)
A:keras.engine.compile_utils.sample_weight->tensorflow.compat.v2.nest.flatten(sample_weight)
A:keras.engine.compile_utils.y_pred->tensorflow.compat.v2.nest.flatten(y_pred)
A:keras.engine.compile_utils.(y_t, y_p, sw)->match_dtype_and_rank(y_t, y_p, sw)
A:keras.engine.compile_utils.sw->tensorflow.compat.v2.cast(sw, y_p.dtype)
A:keras.engine.compile_utils.loss_value->keras.utils.losses_utils.scale_loss_for_distribution(loss_value)
A:keras.engine.compile_utils.batch_dim->tensorflow.compat.v2.cast(y_t, y_p.dtype).nrows()
A:keras.engine.compile_utils.regularization_losses->keras.utils.losses_utils.cast_losses_to_common_dtype(regularization_losses)
A:keras.engine.compile_utils.reg_loss->tensorflow.compat.v2.add_n(regularization_losses)
A:keras.engine.compile_utils.loss_metric_values->keras.utils.losses_utils.cast_losses_to_common_dtype(loss_metric_values)
A:keras.engine.compile_utils.total_loss_metric_value->tensorflow.compat.v2.add_n(loss_metric_values)
A:keras.engine.compile_utils.loss_values->keras.utils.losses_utils.cast_losses_to_common_dtype(loss_values)
A:keras.engine.compile_utils.total_loss->tensorflow.compat.v2.add_n(loss_values)
A:keras.engine.compile_utils.loss->keras.losses.LossFunctionWrapper(loss, name=loss_name)
A:keras.engine.compile_utils.loss_name->get_custom_object_name(loss)
A:keras.engine.compile_utils.seen->set()
A:keras.engine.compile_utils.self._metrics->tensorflow.compat.v2.__internal__.nest.flatten_up_to(y_pred, self._metrics, check_types=False)
A:keras.engine.compile_utils.self._weighted_metrics->tensorflow.compat.v2.__internal__.nest.flatten_up_to(y_pred, self._weighted_metrics, check_types=False)
A:keras.engine.compile_utils.metric_names->set()
A:keras.engine.compile_utils.mask->tensorflow.compat.v2.cast(mask, y_p.dtype)
A:keras.engine.compile_utils.metrics->tensorflow.compat.v2.nest.flatten(metrics)
A:keras.engine.compile_utils.metric_obj->keras.metrics.MeanMetricWrapper(metric_obj, name=metric_name)
A:keras.engine.compile_utils.y_t_rank->len(y_t.shape.as_list())
A:keras.engine.compile_utils.y_p_rank->len(y_p.shape.as_list())
A:keras.engine.compile_utils.metric_name->get_custom_object_name(metric)
A:keras.engine.compile_utils.flat_paths->tensorflow.compat.v2.nest.map_structure(one_index, flat_paths)
A:keras.engine.compile_utils.name->'_'.join((str(p) for p in path))
A:keras.engine.compile_utils.y_t->tensorflow.compat.v2.cast(y_t, y_p.dtype)
A:keras.engine.compile_utils.(mask, _, sw)->keras.utils.losses_utils.squeeze_or_expand_dimensions(mask, sample_weight=sw)
keras.engine.compile_utils.Container(self,output_names=None)
keras.engine.compile_utils.Container.__init__(self,output_names=None)
keras.engine.compile_utils.Container._conform_to_outputs(self,outputs,struct)
keras.engine.compile_utils.Container._copy_object(self,obj)
keras.engine.compile_utils.Container._maybe_broadcast_to_outputs(self,outputs,objects)
keras.engine.compile_utils.Container._should_broadcast(self,objects)
keras.engine.compile_utils.Container.build(self,y_pred)
keras.engine.compile_utils.LossesContainer(self,losses,loss_weights=None,output_names=None)
keras.engine.compile_utils.LossesContainer.__init__(self,losses,loss_weights=None,output_names=None)
keras.engine.compile_utils.LossesContainer._copy_object(self,obj)
keras.engine.compile_utils.LossesContainer._create_metrics(self)
keras.engine.compile_utils.LossesContainer._get_loss_object(self,loss)
keras.engine.compile_utils.LossesContainer._should_broadcast(self,obj)
keras.engine.compile_utils.LossesContainer.build(self,y_pred)
keras.engine.compile_utils.LossesContainer.built(self)
keras.engine.compile_utils.LossesContainer.metrics(self)
keras.engine.compile_utils.LossesContainer.reset_state(self)
keras.engine.compile_utils.MetricsContainer(self,metrics=None,weighted_metrics=None,output_names=None,from_serialized=False)
keras.engine.compile_utils.MetricsContainer.__init__(self,metrics=None,weighted_metrics=None,output_names=None,from_serialized=False)
keras.engine.compile_utils.MetricsContainer._check_duplicated_metrics(self,metrics,weighted_metrics)
keras.engine.compile_utils.MetricsContainer._copy_object(self,obj)
keras.engine.compile_utils.MetricsContainer._create_ordered_metrics(self)
keras.engine.compile_utils.MetricsContainer._get_metric_object(self,metric,y_t,y_p)
keras.engine.compile_utils.MetricsContainer._get_metric_objects(self,metrics,y_t,y_p)
keras.engine.compile_utils.MetricsContainer._set_metric_names(self)
keras.engine.compile_utils.MetricsContainer._should_broadcast(self,obj)
keras.engine.compile_utils.MetricsContainer.build(self,y_pred,y_true)
keras.engine.compile_utils.MetricsContainer.built(self)
keras.engine.compile_utils.MetricsContainer.metrics(self)
keras.engine.compile_utils.MetricsContainer.reset_state(self)
keras.engine.compile_utils.MetricsContainer.unweighted_metrics(self)
keras.engine.compile_utils.MetricsContainer.update_state(self,y_true,y_pred,sample_weight=None)
keras.engine.compile_utils.MetricsContainer.weighted_metrics(self)
keras.engine.compile_utils._create_pseudo_names(tensors,prefix)
keras.engine.compile_utils.apply_mask(y_p,sw,mask)
keras.engine.compile_utils.create_pseudo_input_names(inputs)
keras.engine.compile_utils.create_pseudo_output_names(outputs)
keras.engine.compile_utils.get_custom_object_name(obj)
keras.engine.compile_utils.get_mask(y_p)
keras.engine.compile_utils.map_missing_dict_keys(y_pred,struct)
keras.engine.compile_utils.map_to_output_names(y_pred,output_names,struct)
keras.engine.compile_utils.match_dtype_and_rank(y_t,y_p,sw)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/premade_models/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/premade_models/wide_deep.py----------------------------------------
A:keras.premade_models.wide_deep.self.activation->keras.activations.get(activation)
A:keras.premade_models.wide_deep.linear_output->self.linear_model(linear_inputs)
A:keras.premade_models.wide_deep.training->keras.backend.learning_phase()
A:keras.premade_models.wide_deep.dnn_output->self.dnn_model(dnn_inputs)
A:keras.premade_models.wide_deep.output->tensorflow.compat.v2.nest.map_structure(lambda x, y: x + y, linear_output, dnn_output)
A:keras.premade_models.wide_deep.(x, y, sample_weight)->keras.engine.data_adapter.unpack_x_y_sample_weight(data)
A:keras.premade_models.wide_deep.y_pred->self(x, training=True)
A:keras.premade_models.wide_deep.loss->self.compiled_loss(y, y_pred, sample_weight, regularization_losses=self.losses)
A:keras.premade_models.wide_deep.(linear_grads, dnn_grads)->tape.gradient(loss, (linear_vars, dnn_vars))
A:keras.premade_models.wide_deep.grads->tape.gradient(loss, trainable_variables)
A:keras.premade_models.wide_deep.has_recompiled->self._recompile_weights_loss_and_weighted_metrics()
A:keras.premade_models.wide_deep.current_trainable_state->self._get_trainable_state()
A:keras.premade_models.wide_deep.linear_updates->linear_optimizer.get_updates(params=self.linear_model.trainable_weights, loss=self.total_loss)
A:keras.premade_models.wide_deep.dnn_updates->dnn_optimizer.get_updates(params=self.dnn_model.trainable_weights, loss=self.total_loss)
A:keras.premade_models.wide_deep.metrics->self._get_training_eval_metrics()
A:keras.premade_models.wide_deep.fn->keras.backend.function(inputs, [self.total_loss] + metrics_tensors, updates=updates, name='train_function', **self._function_kwargs)
A:keras.premade_models.wide_deep.linear_config->config.pop('linear_model')
A:keras.premade_models.wide_deep.dnn_config->config.pop('dnn_model')
A:keras.premade_models.wide_deep.base_config->keras.engine.base_layer.Layer.get_config(self)
A:keras.premade_models.wide_deep.linear_model->keras.layers.deserialize(linear_config, custom_objects)
A:keras.premade_models.wide_deep.dnn_model->keras.layers.deserialize(dnn_config, custom_objects)
A:keras.premade_models.wide_deep.activation->keras.activations.deserialize(config.pop('activation', None), custom_objects=custom_objects)
keras.premade_models.wide_deep.WideDeepModel(self,linear_model,dnn_model,activation=None,**kwargs)
keras.premade_models.wide_deep.WideDeepModel.__init__(self,linear_model,dnn_model,activation=None,**kwargs)
keras.premade_models.wide_deep.WideDeepModel._make_train_function(self)
keras.premade_models.wide_deep.WideDeepModel.call(self,inputs,training=None)
keras.premade_models.wide_deep.WideDeepModel.from_config(cls,config,custom_objects=None)
keras.premade_models.wide_deep.WideDeepModel.get_config(self)
keras.premade_models.wide_deep.WideDeepModel.train_step(self,data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/premade_models/linear.py----------------------------------------
A:keras.premade_models.linear.self.activation->keras.activations.get(activation)
A:keras.premade_models.linear.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.premade_models.linear.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.premade_models.linear.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.premade_models.linear.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.premade_models.linear.names->sorted(list(input_shape.keys()))
A:keras.premade_models.linear.layer->keras.layers.core.Dense(units=self.units, use_bias=False, kernel_initializer=self.kernel_initializer, kernel_regularizer=self.kernel_regularizer)
A:keras.premade_models.linear.self.bias->self.add_weight('bias', shape=self.units, initializer=self.bias_initializer, regularizer=self.bias_regularizer, dtype=self.dtype, trainable=True)
A:keras.premade_models.linear.output->layer(inp)
A:keras.premade_models.linear.result->tensorflow.compat.v2.nn.bias_add(result, self.bias)
A:keras.premade_models.linear.base_config->keras.engine.base_layer.Layer.get_config(self)
keras.premade_models.linear.LinearModel(self,units=1,activation=None,use_bias=True,kernel_initializer='zeros',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,**kwargs)
keras.premade_models.linear.LinearModel.__init__(self,units=1,activation=None,use_bias=True,kernel_initializer='zeros',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,**kwargs)
keras.premade_models.linear.LinearModel.build(self,input_shape)
keras.premade_models.linear.LinearModel.call(self,inputs)
keras.premade_models.linear.LinearModel.from_config(cls,config,custom_objects=None)
keras.premade_models.linear.LinearModel.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/tests/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/tests/model_subclassing_test_util.py----------------------------------------
A:keras.tests.model_subclassing_test_util.self.conv1->keras.layers.Conv2D(32, (3, 3), activation='relu')
A:keras.tests.model_subclassing_test_util.self.flatten->keras.layers.Flatten()
A:keras.tests.model_subclassing_test_util.self.dense1->keras.layers.Dense(1)
A:keras.tests.model_subclassing_test_util.x->test_model(x)
A:keras.tests.model_subclassing_test_util.shared_layer->keras.layers.Dense(32, activation='relu')
A:keras.tests.model_subclassing_test_util.model->keras.testing_infra.test_utils._MultiIOSubclassModel(branch_a, branch_b, name='test_model')
A:keras.tests.model_subclassing_test_util.self.dense2->keras.layers.Dense(1, activation='softmax')
A:keras.tests.model_subclassing_test_util.self.bn->keras.layers.BatchNormalization()
A:keras.tests.model_subclassing_test_util.self.test_net->self.get_functional_graph_model(32, 4)
A:keras.tests.model_subclassing_test_util.self.bnself.bn->keras.layers.BatchNormalization()
A:keras.tests.model_subclassing_test_util.inputs->keras.Input(shape=(input_dim,))
A:keras.tests.model_subclassing_test_util.outputs->keras.layers.Dense(num_classes)(x)
A:keras.tests.model_subclassing_test_util.test_model->Inner()
keras.tests.model_subclassing_test_util.CustomCallModel(self)
keras.tests.model_subclassing_test_util.CustomCallModel.__init__(self)
keras.tests.model_subclassing_test_util.CustomCallModel.call(self,first,second,fiddle_with_output='no',training=True)
keras.tests.model_subclassing_test_util.NestedTestModel1(self,num_classes=2)
keras.tests.model_subclassing_test_util.NestedTestModel1.__init__(self,num_classes=2)
keras.tests.model_subclassing_test_util.NestedTestModel1.call(self,inputs)
keras.tests.model_subclassing_test_util.NestedTestModel2(self,num_classes=2)
keras.tests.model_subclassing_test_util.NestedTestModel2.__init__(self,num_classes=2)
keras.tests.model_subclassing_test_util.NestedTestModel2.call(self,inputs)
keras.tests.model_subclassing_test_util.NestedTestModel2.get_functional_graph_model(input_dim,num_classes)
keras.tests.model_subclassing_test_util.SimpleConvTestModel(self,num_classes=10)
keras.tests.model_subclassing_test_util.SimpleConvTestModel.__init__(self,num_classes=10)
keras.tests.model_subclassing_test_util.SimpleConvTestModel.call(self,x)
keras.tests.model_subclassing_test_util.TrainingMaskingModel(self)
keras.tests.model_subclassing_test_util.TrainingMaskingModel.__init__(self)
keras.tests.model_subclassing_test_util.TrainingMaskingModel.call(self,x,training=False,mask=None)
keras.tests.model_subclassing_test_util.TrainingNoDefaultModel(self)
keras.tests.model_subclassing_test_util.TrainingNoDefaultModel.__init__(self)
keras.tests.model_subclassing_test_util.TrainingNoDefaultModel.call(self,x,training)
keras.tests.model_subclassing_test_util.get_multi_io_subclass_model(use_bn=False,use_dp=False,num_classes=(2,3))
keras.tests.model_subclassing_test_util.get_nested_model_3(input_dim,num_classes)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/tests/model_architectures.py----------------------------------------
A:keras.tests.model_architectures.ModelFn->collections.namedtuple('ModelFn', ['model', 'input_shape', 'target_shape'])
A:keras.tests.model_architectures.model->keras.Model(inputs, outputs, name='m', trainable=False)
A:keras.tests.model_architectures.inputs->keras.Input(shape=(3,))
A:keras.tests.model_architectures.layer->keras.layers.RNN([keras.layers.LSTMCell(2) for _ in range(3)])
A:keras.tests.model_architectures.x->keras.layers.BatchNormalization()(x)
A:keras.tests.model_architectures.outputs->keras.layers.Dense(2)(x)
A:keras.tests.model_architectures.body_input->keras.Input(shape=(None,), name='body')
A:keras.tests.model_architectures.tags_input->keras.Input(shape=(2,), name='tags')
A:keras.tests.model_architectures.body_features->keras.layers.LSTM(5)(x)
A:keras.tests.model_architectures.pred_1->keras.layers.Dense(2, activation='sigmoid', name='priority')(x)
A:keras.tests.model_architectures.pred_2->keras.layers.Dense(3, activation='softmax', name='department')(x)
A:keras.tests.model_architectures.inner_model->keras.Sequential([keras.layers.Conv2D(2, 3, activation='relu'), keras.layers.Conv2D(2, 3, activation='relu')])
A:keras.tests.model_architectures.encoder_inputs->keras.Input(shape=(None, num_encoder_tokens))
A:keras.tests.model_architectures.encoder->keras.layers.LSTM(latent_dim, return_state=True)
A:keras.tests.model_architectures.(_, state_h, state_c)->encoder(encoder_inputs)
A:keras.tests.model_architectures.decoder_inputs->keras.Input(shape=(None, num_decoder_tokens))
A:keras.tests.model_architectures.decoder_lstm->keras.layers.LSTM(latent_dim, return_sequences=True, return_state=True)
A:keras.tests.model_architectures.(decoder_outputs, _, _)->decoder_lstm(decoder_inputs, initial_state=encoder_states)
A:keras.tests.model_architectures.decoder_dense->keras.layers.Dense(num_decoder_tokens, activation='softmax')
A:keras.tests.model_architectures.decoder_outputs->decoder_dense(decoder_outputs)
A:keras.tests.model_architectures.main_input->keras.Input(shape=(10,), dtype='int32', name='main_input')
A:keras.tests.model_architectures.lstm_out->keras.layers.LSTM(3)(x)
A:keras.tests.model_architectures.auxiliary_output->keras.layers.Dense(1, activation='sigmoid', name='aux_output')(lstm_out)
A:keras.tests.model_architectures.auxiliary_input->keras.Input(shape=(5,), name='aux_input')
A:keras.tests.model_architectures.main_output->keras.layers.Dense(1, activation='sigmoid', name='main_output')(x)
A:keras.tests.model_architectures.inputs_1->keras.Input((5, 5, 3))
A:keras.tests.model_architectures.inputs_2->keras.Input((5, 5, 3))
A:keras.tests.model_architectures.x1->inner_model(inputs_1)
A:keras.tests.model_architectures.x2->inner_model(inputs_2)
A:keras.tests.model_architectures.self.dense1->keras.layers.Dense(4, activation='relu')
A:keras.tests.model_architectures.self.dense2->keras.layers.Dense(2, activation='relu')
A:keras.tests.model_architectures.self.bn->keras.layers.BatchNormalization()
A:keras.tests.model_architectures.self.dp->keras.layers.Dropout(0.5)
A:keras.tests.model_architectures.self.inner_subclass_model->MySubclassModel()
A:keras.tests.model_architectures.inner_subclass_model->MySubclassModel()
A:keras.tests.model_architectures.self.inner_functional_model->get_functional_model()
A:keras.tests.model_architectures.self.dense->keras.layers.Dense(3, activation='relu')
keras.tests.model_architectures.MySubclassModel(self,input_dim=3)
keras.tests.model_architectures.MySubclassModel.__init__(self,input_dim=3)
keras.tests.model_architectures.MySubclassModel.call(self,inputs,**kwargs)
keras.tests.model_architectures.MySubclassModel.from_config(cls,config)
keras.tests.model_architectures.MySubclassModel.get_config(self)
keras.tests.model_architectures.basic_sequential()
keras.tests.model_architectures.basic_sequential_deferred()
keras.tests.model_architectures.functional_with_keyword_args()
keras.tests.model_architectures.get_models(exclude_models=None)
keras.tests.model_architectures.lstm()
keras.tests.model_architectures.multi_input_multi_output()
keras.tests.model_architectures.nested_functional_in_subclassed_model()
keras.tests.model_architectures.nested_sequential_in_functional()
keras.tests.model_architectures.nested_subclassed_in_functional_model()
keras.tests.model_architectures.nested_subclassed_model()
keras.tests.model_architectures.seq_to_seq()
keras.tests.model_architectures.shared_layer_functional()
keras.tests.model_architectures.shared_layer_subclassed_model()
keras.tests.model_architectures.shared_sequential()
keras.tests.model_architectures.stacked_rnn()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/inception_resnet_v2.py----------------------------------------
A:keras.applications.inception_resnet_v2.layers->VersionAwareLayers()
A:keras.applications.inception_resnet_v2.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=299, min_size=75, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.inception_resnet_v2.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.inception_resnet_v2.x->VersionAwareLayers().Activation(activation, name=block_name + '_ac')(x)
A:keras.applications.inception_resnet_v2.branch_0->conv2d_bn(x, 192, 1)
A:keras.applications.inception_resnet_v2.branch_1->conv2d_bn(branch_1, 256, [3, 1])
A:keras.applications.inception_resnet_v2.branch_2->conv2d_bn(branch_2, 64, 3)
A:keras.applications.inception_resnet_v2.branch_pool->VersionAwareLayers().MaxPooling2D(3, strides=2, padding='valid')(x)
A:keras.applications.inception_resnet_v2.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.inception_resnet_v2.model->keras.engine.training.Model(inputs, x, name='inception_resnet_v2')
A:keras.applications.inception_resnet_v2.weights_path->keras.utils.data_utils.get_file(fname, BASE_WEIGHT_URL + fname, cache_subdir='models', file_hash='d19885ff4a710c122648d3b5c3b684e4')
A:keras.applications.inception_resnet_v2.mixed->VersionAwareLayers().Concatenate(axis=channel_axis, name=block_name + '_mixed')(branches)
A:keras.applications.inception_resnet_v2.up->conv2d_bn(mixed, backend.int_shape(x)[channel_axis], 1, activation=None, use_bias=True, name=block_name + '_conv')
A:keras.applications.inception_resnet_v2.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.InceptionResNetV2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.inception_resnet_v2.InceptionResNetV2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.inception_resnet_v2.conv2d_bn(x,filters,kernel_size,strides=1,padding='same',activation='relu',use_bias=False,name=None)
keras.applications.inception_resnet_v2.decode_predictions(preds,top=5)
keras.applications.inception_resnet_v2.inception_resnet_block(x,scale,block_type,block_idx,activation='relu')
keras.applications.inception_resnet_v2.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/nasnet.py----------------------------------------
A:keras.applications.nasnet.layers->VersionAwareLayers()
A:keras.applications.nasnet.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=default_size, min_size=32, data_format=backend.image_data_format(), require_flatten=True, weights=weights)
A:keras.applications.nasnet.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.nasnet.x->VersionAwareLayers().concatenate([x2, x3, x4, x5], axis=channel_dim, name='reduction_concat_%s' % block_id)
A:keras.applications.nasnet.(x, p)->_normal_a_cell(x, p, filters * filter_multiplier ** 2, block_id='%d' % (2 * num_blocks + i + 1))
A:keras.applications.nasnet.(x, p0)->_reduction_a_cell(x, p, filters * filter_multiplier ** 2, block_id='reduce_%d' % (2 * num_blocks))
A:keras.applications.nasnet.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.nasnet.model->keras.engine.training.Model(inputs, x, name='NASNet')
A:keras.applications.nasnet.weights_path->keras.utils.data_utils.get_file('nasnet_large_no_top.h5', NASNET_LARGE_WEIGHT_PATH_NO_TOP, cache_subdir='models', file_hash='d81d89dc07e6e56530c4e77faddd61b5')
A:keras.applications.nasnet.ip_shape->keras.backend.int_shape(ip)
A:keras.applications.nasnet.p_shape->keras.backend.int_shape(p)
A:keras.applications.nasnet.p->_adjust_block(p, ip, filters, block_id)
A:keras.applications.nasnet.p1->VersionAwareLayers().Conv2D(filters // 2, (1, 1), padding='same', use_bias=False, name='adjust_conv_1_%s' % block_id, kernel_initializer='he_normal')(p1)
A:keras.applications.nasnet.p2->VersionAwareLayers().Conv2D(filters // 2, (1, 1), padding='same', use_bias=False, name='adjust_conv_2_%s' % block_id, kernel_initializer='he_normal')(p2)
A:keras.applications.nasnet.h->VersionAwareLayers().BatchNormalization(axis=channel_dim, momentum=0.9997, epsilon=0.001, name='reduction_bn_1_%s' % block_id)(h)
A:keras.applications.nasnet.x1_1->_separable_conv_block(h, filters, (5, 5), strides=(2, 2), block_id='reduction_left1_%s' % block_id)
A:keras.applications.nasnet.x1_2->_separable_conv_block(p, filters, (7, 7), strides=(2, 2), block_id='reduction_right1_%s' % block_id)
A:keras.applications.nasnet.x1->VersionAwareLayers().add([x1_1, x1_2], name='reduction_add_1_%s' % block_id)
A:keras.applications.nasnet.x2_1->VersionAwareLayers().MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='reduction_left2_%s' % block_id)(h3)
A:keras.applications.nasnet.x2_2->_separable_conv_block(p, filters, (7, 7), strides=(2, 2), block_id='reduction_right2_%s' % block_id)
A:keras.applications.nasnet.x2->VersionAwareLayers().add([x2_1, x2_2], name='reduction_add_2_%s' % block_id)
A:keras.applications.nasnet.x3->VersionAwareLayers().add([x3_1, x3_2], name='reduction_add3_%s' % block_id)
A:keras.applications.nasnet.x4_1->VersionAwareLayers().AveragePooling2D((3, 3), strides=(1, 1), padding='same', name='normal_left4_%s' % block_id)(p)
A:keras.applications.nasnet.x4_2->VersionAwareLayers().AveragePooling2D((3, 3), strides=(1, 1), padding='same', name='normal_right4_%s' % block_id)(p)
A:keras.applications.nasnet.x4->VersionAwareLayers().add([x2, x4])
A:keras.applications.nasnet.x5->VersionAwareLayers().add([x5_1, x5_2], name='reduction_add4_%s' % block_id)
A:keras.applications.nasnet.h3->VersionAwareLayers().ZeroPadding2D(padding=imagenet_utils.correct_pad(h, 3), name='reduction_pad_1_%s' % block_id)(h)
A:keras.applications.nasnet.x3_1->VersionAwareLayers().AveragePooling2D((3, 3), strides=(2, 2), padding='valid', name='reduction_left3_%s' % block_id)(h3)
A:keras.applications.nasnet.x3_2->_separable_conv_block(p, filters, (5, 5), strides=(2, 2), block_id='reduction_right3_%s' % block_id)
A:keras.applications.nasnet.x5_1->_separable_conv_block(x1, filters, (3, 3), block_id='reduction_left4_%s' % block_id)
A:keras.applications.nasnet.x5_2->VersionAwareLayers().MaxPooling2D((3, 3), strides=(2, 2), padding='valid', name='reduction_right5_%s' % block_id)(h3)
A:keras.applications.nasnet.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.NASNetLarge(input_shape=None,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.NASNetMobile(input_shape=None,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.nasnet.NASNet(input_shape=None,penultimate_filters=4032,num_blocks=6,stem_block_filters=96,skip_reduction=True,filter_multiplier=2,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,default_size=None,classifier_activation='softmax')
keras.applications.nasnet.NASNetLarge(input_shape=None,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.nasnet.NASNetMobile(input_shape=None,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.nasnet._adjust_block(p,ip,filters,block_id=None)
keras.applications.nasnet._normal_a_cell(ip,p,filters,block_id=None)
keras.applications.nasnet._reduction_a_cell(ip,p,filters,block_id=None)
keras.applications.nasnet._separable_conv_block(ip,filters,kernel_size=(3,3),strides=(1,1),block_id=None)
keras.applications.nasnet.decode_predictions(preds,top=5)
keras.applications.nasnet.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/mobilenet_v3.py----------------------------------------
A:keras.applications.mobilenet_v3.layers->VersionAwareLayers()
A:keras.applications.mobilenet_v3.is_input_t_tensor->keras.backend.is_keras_tensor(layer_utils.get_source_inputs(input_tensor))
A:keras.applications.mobilenet_v3.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.mobilenet_v3.x->VersionAwareLayers().Add(name=prefix + 'Add')([shortcut, x])
A:keras.applications.mobilenet_v3.last_conv_ch->_depth(backend.int_shape(x)[channel_axis] * 6)
A:keras.applications.mobilenet_v3.last_point_ch->_depth(last_point_ch * alpha)
A:keras.applications.mobilenet_v3.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.mobilenet_v3.model->keras.models.Model(inputs, x, name='MobilenetV3' + model_type)
A:keras.applications.mobilenet_v3.model_name->'{}{}_224_{}_float'.format(model_type, '_minimalistic' if minimalistic else '', str(alpha))
A:keras.applications.mobilenet_v3.weights_path->keras.utils.data_utils.get_file(file_name, BASE_WEIGHT_PATH + file_name, cache_subdir='models', file_hash=file_hash)
A:keras.applications.mobilenet_v3.MobileNetV3Small.__doc__->BASE_DOCSTRING.format(name='MobileNetV3Small')
A:keras.applications.mobilenet_v3.MobileNetV3Large.__doc__->BASE_DOCSTRING.format(name='MobileNetV3Large')
A:keras.applications.mobilenet_v3.new_v->max(min_value, int(v + divisor / 2) // divisor * divisor)
A:keras.applications.mobilenet_v3.prefix->'expanded_conv_{}/'.format(block_id)
keras.applications.MobileNetV3Large(input_shape=None,alpha=1.0,minimalistic=False,include_top=True,weights='imagenet',input_tensor=None,classes=1000,pooling=None,dropout_rate=0.2,classifier_activation='softmax',include_preprocessing=True)
keras.applications.MobileNetV3Small(input_shape=None,alpha=1.0,minimalistic=False,include_top=True,weights='imagenet',input_tensor=None,classes=1000,pooling=None,dropout_rate=0.2,classifier_activation='softmax',include_preprocessing=True)
keras.applications.mobilenet_v3.MobileNetV3(stack_fn,last_point_ch,input_shape=None,alpha=1.0,model_type='large',minimalistic=False,include_top=True,weights='imagenet',input_tensor=None,classes=1000,pooling=None,dropout_rate=0.2,classifier_activation='softmax',include_preprocessing=True)
keras.applications.mobilenet_v3.MobileNetV3Large(input_shape=None,alpha=1.0,minimalistic=False,include_top=True,weights='imagenet',input_tensor=None,classes=1000,pooling=None,dropout_rate=0.2,classifier_activation='softmax',include_preprocessing=True)
keras.applications.mobilenet_v3.MobileNetV3Small(input_shape=None,alpha=1.0,minimalistic=False,include_top=True,weights='imagenet',input_tensor=None,classes=1000,pooling=None,dropout_rate=0.2,classifier_activation='softmax',include_preprocessing=True)
keras.applications.mobilenet_v3._depth(v,divisor=8,min_value=None)
keras.applications.mobilenet_v3._inverted_res_block(x,expansion,filters,kernel_size,stride,se_ratio,activation,block_id)
keras.applications.mobilenet_v3._se_block(inputs,filters,se_ratio,prefix)
keras.applications.mobilenet_v3.decode_predictions(preds,top=5)
keras.applications.mobilenet_v3.hard_sigmoid(x)
keras.applications.mobilenet_v3.hard_swish(x)
keras.applications.mobilenet_v3.preprocess_input(x,data_format=None)
keras.applications.mobilenet_v3.relu(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/vgg16.py----------------------------------------
A:keras.applications.vgg16.layers->VersionAwareLayers()
A:keras.applications.vgg16.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=224, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.vgg16.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.vgg16.x->VersionAwareLayers().GlobalMaxPooling2D()(x)
A:keras.applications.vgg16.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.vgg16.model->keras.engine.training.Model(inputs, x, name='vgg16')
A:keras.applications.vgg16.weights_path->keras.utils.data_utils.get_file('vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', file_hash='6d6bbae143d832006294945121d1f1fc')
A:keras.applications.vgg16.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.VGG16(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.vgg16.VGG16(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.vgg16.decode_predictions(preds,top=5)
keras.applications.vgg16.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/efficientnet_v2.py----------------------------------------
A:keras.applications.efficientnet_v2.new_filters->max(minimum_depth, int(filters + depth_divisor / 2) // depth_divisor * depth_divisor)
A:keras.applications.efficientnet_v2.name->keras.backend.get_uid('block0')
A:keras.applications.efficientnet_v2.x->keras.layers.GlobalMaxPooling2D(name='max_pool')(x)
A:keras.applications.efficientnet_v2.filters_se->max(1, int(input_filters * se_ratio))
A:keras.applications.efficientnet_v2.se->keras.layers.Conv2D(filters, 1, padding='same', activation='sigmoid', kernel_initializer=CONV_KERNEL_INITIALIZER, name=name + 'se_expand')(se)
A:keras.applications.efficientnet_v2.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=default_size, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.efficientnet_v2.img_input->keras.layers.Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.efficientnet_v2.stem_filters->round_filters(filters=blocks_args[0]['input_filters'], width_coefficient=width_coefficient, min_depth=min_depth, depth_divisor=depth_divisor)
A:keras.applications.efficientnet_v2.blocks_args->copy.deepcopy(blocks_args)
A:keras.applications.efficientnet_v2.blocks->float(sum((args['num_repeat'] for args in blocks_args)))
A:keras.applications.efficientnet_v2.args['input_filters']->round_filters(filters=args['input_filters'], width_coefficient=width_coefficient, min_depth=min_depth, depth_divisor=depth_divisor)
A:keras.applications.efficientnet_v2.args['output_filters']->round_filters(filters=args['output_filters'], width_coefficient=width_coefficient, min_depth=min_depth, depth_divisor=depth_divisor)
A:keras.applications.efficientnet_v2.repeats->round_repeats(repeats=args.pop('num_repeat'), depth_coefficient=depth_coefficient)
A:keras.applications.efficientnet_v2.top_filters->round_filters(filters=1280, width_coefficient=width_coefficient, min_depth=min_depth, depth_divisor=depth_divisor)
A:keras.applications.efficientnet_v2.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.efficientnet_v2.model->keras.engine.training.Model(inputs, x, name=model_name)
A:keras.applications.efficientnet_v2.weights_path->keras.utils.data_utils.get_file(file_name, BASE_WEIGHTS_PATH + file_name, cache_subdir='models', file_hash=file_hash)
A:keras.applications.efficientnet_v2.EfficientNetV2B0.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2B0')
A:keras.applications.efficientnet_v2.EfficientNetV2B1.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2B1')
A:keras.applications.efficientnet_v2.EfficientNetV2B2.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2B2')
A:keras.applications.efficientnet_v2.EfficientNetV2B3.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2B3')
A:keras.applications.efficientnet_v2.EfficientNetV2S.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2S')
A:keras.applications.efficientnet_v2.EfficientNetV2M.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2M')
A:keras.applications.efficientnet_v2.EfficientNetV2L.__doc__->BASE_DOCSTRING.format(name='EfficientNetV2L')
keras.applications.EfficientNetV2B0(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.EfficientNetV2B1(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.EfficientNetV2B2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.EfficientNetV2B3(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.EfficientNetV2L(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.EfficientNetV2M(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.EfficientNetV2S(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2(width_coefficient,depth_coefficient,default_size,dropout_rate=0.2,drop_connect_rate=0.2,depth_divisor=8,min_depth=8,bn_momentum=0.9,activation='swish',blocks_args='default',model_name='efficientnetv2',include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2B0(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2B1(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2B2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2B3(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2L(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2M(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.EfficientNetV2S(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',include_preprocessing=True)
keras.applications.efficientnet_v2.FusedMBConvBlock(input_filters:int,output_filters:int,expand_ratio=1,kernel_size=3,strides=1,se_ratio=0.0,bn_momentum=0.9,activation='swish',survival_probability:float=0.8,name=None)
keras.applications.efficientnet_v2.MBConvBlock(input_filters:int,output_filters:int,expand_ratio=1,kernel_size=3,strides=1,se_ratio=0.0,bn_momentum=0.9,activation='swish',survival_probability:float=0.8,name=None)
keras.applications.efficientnet_v2.decode_predictions(preds,top=5)
keras.applications.efficientnet_v2.preprocess_input(x,data_format=None)
keras.applications.efficientnet_v2.round_filters(filters,width_coefficient,min_depth,depth_divisor)
keras.applications.efficientnet_v2.round_repeats(repeats,depth_coefficient)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/resnet.py----------------------------------------
A:keras.applications.resnet.layers->VersionAwareLayers()
A:keras.applications.resnet.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=224, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.resnet.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.resnet.x->stack1(x, 256, 36, name='conv4')
A:keras.applications.resnet.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.resnet.model->keras.engine.training.Model(inputs, x, name=model_name)
A:keras.applications.resnet.weights_path->keras.utils.data_utils.get_file(file_name, BASE_WEIGHTS_PATH + file_name, cache_subdir='models', file_hash=file_hash)
A:keras.applications.resnet.shortcut->VersionAwareLayers().BatchNormalization(axis=bn_axis, epsilon=1.001e-05, name=name + '_0_bn')(shortcut)
A:keras.applications.resnet.preact->VersionAwareLayers().Activation('relu', name=name + '_preact_relu')(preact)
A:keras.applications.resnet.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.ResNet101(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs)
keras.applications.ResNet152(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs)
keras.applications.ResNet50(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs)
keras.applications.resnet.ResNet(stack_fn,preact,use_bias,model_name='resnet',include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.resnet.ResNet101(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs)
keras.applications.resnet.ResNet152(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs)
keras.applications.resnet.ResNet50(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,**kwargs)
keras.applications.resnet.block1(x,filters,kernel_size=3,stride=1,conv_shortcut=True,name=None)
keras.applications.resnet.block2(x,filters,kernel_size=3,stride=1,conv_shortcut=False,name=None)
keras.applications.resnet.block3(x,filters,kernel_size=3,stride=1,groups=32,conv_shortcut=True,name=None)
keras.applications.resnet.decode_predictions(preds,top=5)
keras.applications.resnet.preprocess_input(x,data_format=None)
keras.applications.resnet.stack1(x,filters,blocks,stride1=2,name=None)
keras.applications.resnet.stack2(x,filters,blocks,stride1=2,name=None)
keras.applications.resnet.stack3(x,filters,blocks,stride1=2,groups=32,name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/imagenet_utils.py----------------------------------------
A:keras.applications.imagenet_utils.data_format->keras.backend.image_data_format()
A:keras.applications.imagenet_utils.preprocess_input.__doc__->PREPROCESS_INPUT_DOC.format(mode=PREPROCESS_INPUT_MODE_DOC, ret='', error=PREPROCESS_INPUT_DEFAULT_ERROR_DOC)
A:keras.applications.imagenet_utils.fpath->keras.utils.data_utils.get_file('imagenet_class_index.json', CLASS_INDEX_PATH, cache_subdir='models', file_hash='c2c37ea517e94d9795004a39431a14cb')
A:keras.applications.imagenet_utils.CLASS_INDEX->json.load(f)
A:keras.applications.imagenet_utils.x->keras.backend.bias_add(x, mean_tensor, data_format)
A:keras.applications.imagenet_utils.mean_tensor->keras.backend.constant(-np.array(mean))
A:keras.applications.imagenet_utils.std_tensor->keras.backend.reshape(std_tensor, (-1, 1, 1))
A:keras.applications.imagenet_utils.classifier_activation->keras.activations.get(classifier_activation)
keras.applications.imagenet_utils._preprocess_numpy_input(x,data_format,mode)
keras.applications.imagenet_utils._preprocess_symbolic_input(x,data_format,mode)
keras.applications.imagenet_utils.correct_pad(inputs,kernel_size)
keras.applications.imagenet_utils.decode_predictions(preds,top=5)
keras.applications.imagenet_utils.obtain_input_shape(input_shape,default_size,min_size,data_format,require_flatten,weights=None)
keras.applications.imagenet_utils.preprocess_input(x,data_format=None,mode='caffe')
keras.applications.imagenet_utils.validate_activation(classifier_activation,weights)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/mobilenet.py----------------------------------------
A:keras.applications.mobilenet.layers->VersionAwareLayers()
A:keras.applications.mobilenet.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=default_size, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.mobilenet.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.mobilenet.x->VersionAwareLayers().BatchNormalization(axis=channel_axis, name='conv_pw_%d_bn' % block_id)(x)
A:keras.applications.mobilenet.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.mobilenet.model->keras.engine.training.Model(inputs, x, name='mobilenet_%0.2f_%s' % (alpha, rows))
A:keras.applications.mobilenet.weights_path->keras.utils.data_utils.get_file(model_name, weight_path, cache_subdir='models')
A:keras.applications.mobilenet.filters->int(filters * alpha)
A:keras.applications.mobilenet.pointwise_conv_filters->int(pointwise_conv_filters * alpha)
A:keras.applications.mobilenet.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.MobileNet(input_shape=None,alpha=1.0,depth_multiplier=1,dropout=0.001,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.mobilenet.MobileNet(input_shape=None,alpha=1.0,depth_multiplier=1,dropout=0.001,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.mobilenet._conv_block(inputs,filters,alpha,kernel=(3,3),strides=(1,1))
keras.applications.mobilenet._depthwise_conv_block(inputs,pointwise_conv_filters,alpha,depth_multiplier=1,strides=(1,1),block_id=1)
keras.applications.mobilenet.decode_predictions(preds,top=5)
keras.applications.mobilenet.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/densenet.py----------------------------------------
A:keras.applications.densenet.layers->VersionAwareLayers()
A:keras.applications.densenet.x->VersionAwareLayers().GlobalMaxPooling2D(name='max_pool')(x)
A:keras.applications.densenet.x1->VersionAwareLayers().Conv2D(growth_rate, 3, padding='same', use_bias=False, name=name + '_2_conv')(x1)
A:keras.applications.densenet.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=224, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.densenet.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.densenet.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.densenet.model->keras.engine.training.Model(inputs, x, name='densenet')
A:keras.applications.densenet.weights_path->keras.utils.data_utils.get_file('densenet201_weights_tf_dim_ordering_tf_kernels_notop.h5', DENSENET201_WEIGHT_PATH_NO_TOP, cache_subdir='models', file_hash='c13680b51ded0fb44dff2d8f86ac8bb1')
A:keras.applications.densenet.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TORCH, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.DenseNet121(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.DenseNet169(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.DenseNet201(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.densenet.DenseNet(blocks,include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.densenet.DenseNet121(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.densenet.DenseNet169(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.densenet.DenseNet201(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.densenet.conv_block(x,growth_rate,name)
keras.applications.densenet.decode_predictions(preds,top=5)
keras.applications.densenet.dense_block(x,blocks,name)
keras.applications.densenet.preprocess_input(x,data_format=None)
keras.applications.densenet.transition_block(x,reduction,name)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/resnet_rs.py----------------------------------------
A:keras.applications.resnet_rs.counter->keras.backend.get_uid('block_group_')
A:keras.applications.resnet_rs.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.resnet_rs.x->keras.layers.GlobalMaxPooling2D(name='max_pool')(x)
A:keras.applications.resnet_rs.num_reduced_filters->max(1, int(in_filters * 4 * se_ratio))
A:keras.applications.resnet_rs.shortcut->keras.layers.BatchNormalization(axis=bn_axis, momentum=bn_momentum, epsilon=bn_epsilon, name=name + '_projection_batch_norm')(shortcut)
A:keras.applications.resnet_rs.current_limit->sys.getrecursionlimit()
A:keras.applications.resnet_rs.padded_inputs->keras.layers.ZeroPadding2D(padding=((pad_beg, pad_end), (pad_beg, pad_end)))(inputs)
A:keras.applications.resnet_rs.max_input_shape->max(available_weight_variants)
A:keras.applications.resnet_rs.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=224, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.resnet_rs.img_input->keras.layers.Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.resnet_rs.survival_probability->get_survival_probability(init_rate=drop_connect_rate, block_num=i + 2, total_blocks=len(block_args) + 1)
A:keras.applications.resnet_rs.model->keras.engine.training.Model(inputs, x, name=model_name)
A:keras.applications.resnet_rs.weights_path->keras.utils.data_utils.get_file(fname=filename, origin=download_url, cache_subdir='models', file_hash=WEIGHT_HASHES[filename])
A:keras.applications.resnet_rs.ResNetRS50.__doc__->BASE_DOCSTRING.format(name='ResNetRS50')
A:keras.applications.resnet_rs.ResNetRS152.__doc__->BASE_DOCSTRING.format(name='ResNetRS152')
A:keras.applications.resnet_rs.ResNetRS200.__doc__->BASE_DOCSTRING.format(name='ResNetRS200')
A:keras.applications.resnet_rs.ResNetRS270.__doc__->BASE_DOCSTRING.format(name='ResNetRS270')
A:keras.applications.resnet_rs.ResNetRS350.__doc__->BASE_DOCSTRING.format(name='ResNetRS350')
A:keras.applications.resnet_rs.ResNetRS420.__doc__->BASE_DOCSTRING.format(name='ResNetRS420')
keras.applications.ResNetRS101(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.ResNetRS152(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.ResNetRS200(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.ResNetRS270(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.ResNetRS350(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.ResNetRS420(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.ResNetRS50(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.BlockGroup(filters,strides,num_repeats,se_ratio:float=0.25,bn_epsilon:float=1e-05,bn_momentum:float=0.0,activation:str='relu',survival_probability:float=0.8,name=None)
keras.applications.resnet_rs.BottleneckBlock(filters:int,strides:int,use_projection:bool,bn_momentum:float=0.0,bn_epsilon:float=1e-05,activation:str='relu',se_ratio:float=0.25,survival_probability:float=0.8,name=None)
keras.applications.resnet_rs.Conv2DFixedPadding(filters,kernel_size,strides,name=None)
keras.applications.resnet_rs.ResNetRS(depth:int,input_shape=None,bn_momentum=0.0,bn_epsilon=1e-05,activation:str='relu',se_ratio=0.25,dropout_rate=0.25,drop_connect_rate=0.2,include_top=True,block_args:List[Dict[str,int]]=None,model_name='resnet-rs',pooling=None,weights='imagenet',input_tensor=None,classes=1000,classifier_activation:Union[str,Callable]='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS101(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS152(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS200(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS270(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS350(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS420(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.ResNetRS50(include_top=True,weights='imagenet',classes=1000,input_shape=None,input_tensor=None,pooling=None,classifier_activation='softmax',include_preprocessing=True)
keras.applications.resnet_rs.SE(in_filters:int,se_ratio:float=0.25,expand_ratio:int=1,name=None)
keras.applications.resnet_rs.STEM(bn_momentum:float=0.0,bn_epsilon:float=1e-05,activation:str='relu',name=None)
keras.applications.resnet_rs.allow_bigger_recursion(target_limit:int)
keras.applications.resnet_rs.decode_predictions(preds,top=5)
keras.applications.resnet_rs.fixed_padding(inputs,kernel_size)
keras.applications.resnet_rs.get_survival_probability(init_rate,block_num,total_blocks)
keras.applications.resnet_rs.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/efficientnet.py----------------------------------------
A:keras.applications.efficientnet.layers->VersionAwareLayers()
A:keras.applications.efficientnet.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=default_size, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.efficientnet.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.efficientnet.new_filters->max(divisor, int(filters + divisor / 2) // divisor * divisor)
A:keras.applications.efficientnet.x->VersionAwareLayers().add([x, inputs], name=name + 'add')
A:keras.applications.efficientnet.blocks_args->copy.deepcopy(blocks_args)
A:keras.applications.efficientnet.blocks->float(sum((round_repeats(args['repeats']) for args in blocks_args)))
A:keras.applications.efficientnet.args['filters_in']->round_filters(args['filters_in'])
A:keras.applications.efficientnet.args['filters_out']->round_filters(args['filters_out'])
A:keras.applications.efficientnet.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.efficientnet.model->keras.engine.training.Model(inputs, x, name=model_name)
A:keras.applications.efficientnet.weights_path->keras.utils.data_utils.get_file(file_name, BASE_WEIGHTS_PATH + file_name, cache_subdir='models', file_hash=file_hash)
A:keras.applications.efficientnet.filters_se->max(1, int(filters_in * se_ratio))
A:keras.applications.efficientnet.se->VersionAwareLayers().Conv2D(filters, 1, padding='same', activation='sigmoid', kernel_initializer=CONV_KERNEL_INITIALIZER, name=name + 'se_expand')(se)
A:keras.applications.efficientnet.EfficientNetB0.__doc__->BASE_DOCSTRING.format(name='EfficientNetB0')
A:keras.applications.efficientnet.EfficientNetB1.__doc__->BASE_DOCSTRING.format(name='EfficientNetB1')
A:keras.applications.efficientnet.EfficientNetB2.__doc__->BASE_DOCSTRING.format(name='EfficientNetB2')
A:keras.applications.efficientnet.EfficientNetB3.__doc__->BASE_DOCSTRING.format(name='EfficientNetB3')
A:keras.applications.efficientnet.EfficientNetB4.__doc__->BASE_DOCSTRING.format(name='EfficientNetB4')
A:keras.applications.efficientnet.EfficientNetB5.__doc__->BASE_DOCSTRING.format(name='EfficientNetB5')
A:keras.applications.efficientnet.EfficientNetB6.__doc__->BASE_DOCSTRING.format(name='EfficientNetB6')
A:keras.applications.efficientnet.EfficientNetB7.__doc__->BASE_DOCSTRING.format(name='EfficientNetB7')
keras.applications.EfficientNetB0(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB1(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB3(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB4(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB5(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB6(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.EfficientNetB7(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNet(width_coefficient,depth_coefficient,default_size,dropout_rate=0.2,drop_connect_rate=0.2,depth_divisor=8,activation='swish',blocks_args='default',model_name='efficientnet',include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.efficientnet.EfficientNetB0(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB1(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB3(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB4(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB5(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB6(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.EfficientNetB7(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.efficientnet.block(inputs,activation='swish',drop_rate=0.0,name='',filters_in=32,filters_out=16,kernel_size=3,strides=1,expand_ratio=1,se_ratio=0.0,id_skip=True)
keras.applications.efficientnet.decode_predictions(preds,top=5)
keras.applications.efficientnet.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/resnet_v2.py----------------------------------------
A:keras.applications.resnet_v2.x->keras.applications.resnet.stack2(x, 256, 36, name='conv4')
A:keras.applications.resnet_v2.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.ResNet101V2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.ResNet152V2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.ResNet50V2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.resnet_v2.ResNet101V2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.resnet_v2.ResNet152V2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.resnet_v2.ResNet50V2(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.resnet_v2.decode_predictions(preds,top=5)
keras.applications.resnet_v2.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/regnet.py----------------------------------------
A:keras.applications.regnet.x->keras.layers.GlobalMaxPooling2D()(x)
A:keras.applications.regnet.name->str(backend.get_uid('head'))
A:keras.applications.regnet.skip->keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-05, name=name + '_skip_bn')(skip)
A:keras.applications.regnet.se_filters->int(filters_in * squeeze_excite_ratio)
A:keras.applications.regnet.inv_btlneck_filters->int(filters_out / bottleneck_ratio)
A:keras.applications.regnet.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=default_size, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.regnet.img_input->keras.layers.Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.regnet.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.regnet.model->keras.engine.training.Model(inputs=inputs, outputs=x, name=model_name)
A:keras.applications.regnet.weights_path->keras.utils.data_utils.get_file(file_name, BASE_WEIGHTS_PATH + file_name, cache_subdir='models', file_hash=file_hash)
A:keras.applications.regnet.RegNetX002.__doc__->BASE_DOCSTRING.format(name='RegNetX002')
A:keras.applications.regnet.RegNetX004.__doc__->BASE_DOCSTRING.format(name='RegNetX004')
A:keras.applications.regnet.RegNetX006.__doc__->BASE_DOCSTRING.format(name='RegNetX006')
A:keras.applications.regnet.RegNetX008.__doc__->BASE_DOCSTRING.format(name='RegNetX008')
A:keras.applications.regnet.RegNetX016.__doc__->BASE_DOCSTRING.format(name='RegNetX016')
A:keras.applications.regnet.RegNetX032.__doc__->BASE_DOCSTRING.format(name='RegNetX032')
A:keras.applications.regnet.RegNetX040.__doc__->BASE_DOCSTRING.format(name='RegNetX040')
A:keras.applications.regnet.RegNetX064.__doc__->BASE_DOCSTRING.format(name='RegNetX064')
A:keras.applications.regnet.RegNetX080.__doc__->BASE_DOCSTRING.format(name='RegNetX080')
A:keras.applications.regnet.RegNetX120.__doc__->BASE_DOCSTRING.format(name='RegNetX120')
A:keras.applications.regnet.RegNetX160.__doc__->BASE_DOCSTRING.format(name='RegNetX160')
A:keras.applications.regnet.RegNetX320.__doc__->BASE_DOCSTRING.format(name='RegNetX320')
A:keras.applications.regnet.RegNetY002.__doc__->BASE_DOCSTRING.format(name='RegNetY002')
A:keras.applications.regnet.RegNetY004.__doc__->BASE_DOCSTRING.format(name='RegNetY004')
A:keras.applications.regnet.RegNetY006.__doc__->BASE_DOCSTRING.format(name='RegNetY006')
A:keras.applications.regnet.RegNetY008.__doc__->BASE_DOCSTRING.format(name='RegNetY008')
A:keras.applications.regnet.RegNetY016.__doc__->BASE_DOCSTRING.format(name='RegNetY016')
A:keras.applications.regnet.RegNetY032.__doc__->BASE_DOCSTRING.format(name='RegNetY032')
A:keras.applications.regnet.RegNetY040.__doc__->BASE_DOCSTRING.format(name='RegNetY040')
A:keras.applications.regnet.RegNetY064.__doc__->BASE_DOCSTRING.format(name='RegNetY064')
A:keras.applications.regnet.RegNetY080.__doc__->BASE_DOCSTRING.format(name='RegNetY080')
A:keras.applications.regnet.RegNetY120.__doc__->BASE_DOCSTRING.format(name='RegNetY120')
A:keras.applications.regnet.RegNetY160.__doc__->BASE_DOCSTRING.format(name='RegNetY160')
A:keras.applications.regnet.RegNetY320.__doc__->BASE_DOCSTRING.format(name='RegNetY320')
keras.applications.regnet.Head(num_classes=1000,name=None)
keras.applications.regnet.PreStem(name=None)
keras.applications.regnet.RegNet(depths,widths,group_width,block_type,default_size,model_name='regnet',include_preprocessing=True,include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX002(model_name='regnetx002',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX004(model_name='regnetx004',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX006(model_name='regnetx006',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX008(model_name='regnetx008',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX016(model_name='regnetx016',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX032(model_name='regnetx032',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX040(model_name='regnetx040',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX064(model_name='regnetx064',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX080(model_name='regnetx080',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX120(model_name='regnetx120',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX160(model_name='regnetx160',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetX320(model_name='regnetx320',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY002(model_name='regnety002',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY004(model_name='regnety004',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY006(model_name='regnety006',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY008(model_name='regnety008',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY016(model_name='regnety016',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY032(model_name='regnety032',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY040(model_name='regnety040',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY064(model_name='regnety064',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY080(model_name='regnety080',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY120(model_name='regnety120',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY160(model_name='regnety160',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.RegNetY320(model_name='regnety320',include_top=True,include_preprocessing=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.regnet.SqueezeAndExciteBlock(filters_in,se_filters,name=None)
keras.applications.regnet.Stage(block_type,depth,group_width,filters_in,filters_out,name=None)
keras.applications.regnet.Stem(name=None)
keras.applications.regnet.XBlock(filters_in,filters_out,group_width,stride=1,name=None)
keras.applications.regnet.YBlock(filters_in,filters_out,group_width,stride=1,squeeze_excite_ratio=0.25,name=None)
keras.applications.regnet.ZBlock(filters_in,filters_out,group_width,stride=1,squeeze_excite_ratio=0.25,bottleneck_ratio=0.25,name=None)
keras.applications.regnet.decode_predictions(preds,top=5)
keras.applications.regnet.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/mobilenet_v2.py----------------------------------------
A:keras.applications.mobilenet_v2.layers->VersionAwareLayers()
A:keras.applications.mobilenet_v2.is_input_t_tensor->keras.backend.is_keras_tensor(layer_utils.get_source_inputs(input_tensor))
A:keras.applications.mobilenet_v2.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=default_size, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.mobilenet_v2.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.mobilenet_v2.first_block_filters->_make_divisible(32 * alpha, 8)
A:keras.applications.mobilenet_v2.x->VersionAwareLayers().BatchNormalization(axis=channel_axis, epsilon=0.001, momentum=0.999, name=prefix + 'project_BN')(x)
A:keras.applications.mobilenet_v2.last_block_filters->_make_divisible(1280 * alpha, 8)
A:keras.applications.mobilenet_v2.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.mobilenet_v2.model->keras.engine.training.Model(inputs, x, name='mobilenetv2_%0.2f_%s' % (alpha, rows))
A:keras.applications.mobilenet_v2.weights_path->keras.utils.data_utils.get_file(model_name, weight_path, cache_subdir='models')
A:keras.applications.mobilenet_v2.pointwise_conv_filters->int(filters * alpha)
A:keras.applications.mobilenet_v2.pointwise_filters->_make_divisible(pointwise_conv_filters, 8)
A:keras.applications.mobilenet_v2.prefix->'block_{}_'.format(block_id)
A:keras.applications.mobilenet_v2.new_v->max(min_value, int(v + divisor / 2) // divisor * divisor)
A:keras.applications.mobilenet_v2.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.MobileNetV2(input_shape=None,alpha=1.0,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.mobilenet_v2.MobileNetV2(input_shape=None,alpha=1.0,include_top=True,weights='imagenet',input_tensor=None,pooling=None,classes=1000,classifier_activation='softmax',**kwargs)
keras.applications.mobilenet_v2._inverted_res_block(inputs,expansion,stride,alpha,filters,block_id)
keras.applications.mobilenet_v2._make_divisible(v,divisor,min_value=None)
keras.applications.mobilenet_v2.decode_predictions(preds,top=5)
keras.applications.mobilenet_v2.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/xception.py----------------------------------------
A:keras.applications.xception.layers->VersionAwareLayers()
A:keras.applications.xception.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=299, min_size=71, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.xception.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.xception.x->VersionAwareLayers().GlobalMaxPooling2D()(x)
A:keras.applications.xception.residual->VersionAwareLayers().BatchNormalization(axis=channel_axis)(residual)
A:keras.applications.xception.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.xception.model->keras.engine.training.Model(inputs, x, name='xception')
A:keras.applications.xception.weights_path->keras.utils.data_utils.get_file('xception_weights_tf_dim_ordering_tf_kernels_notop.h5', TF_WEIGHTS_PATH_NO_TOP, cache_subdir='models', file_hash='b0042744bf5b25fce3cb969f33bebb97')
A:keras.applications.xception.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.Xception(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.xception.Xception(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.xception.decode_predictions(preds,top=5)
keras.applications.xception.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/vgg19.py----------------------------------------
A:keras.applications.vgg19.layers->VersionAwareLayers()
A:keras.applications.vgg19.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=224, min_size=32, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.vgg19.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.vgg19.x->VersionAwareLayers().GlobalMaxPooling2D()(x)
A:keras.applications.vgg19.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.vgg19.model->keras.engine.training.Model(inputs, x, name='vgg19')
A:keras.applications.vgg19.weights_path->keras.utils.data_utils.get_file('vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', file_hash='253f8cb515780f3b799900260a226db6')
A:keras.applications.vgg19.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_CAFFE, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.VGG19(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.vgg19.VGG19(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.vgg19.decode_predictions(preds,top=5)
keras.applications.vgg19.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/applications/inception_v3.py----------------------------------------
A:keras.applications.inception_v3.layers->VersionAwareLayers()
A:keras.applications.inception_v3.input_shape->keras.applications.imagenet_utils.obtain_input_shape(input_shape, default_size=299, min_size=75, data_format=backend.image_data_format(), require_flatten=include_top, weights=weights)
A:keras.applications.inception_v3.img_input->VersionAwareLayers().Input(tensor=input_tensor, shape=input_shape)
A:keras.applications.inception_v3.x->VersionAwareLayers().Activation('relu', name=name)(x)
A:keras.applications.inception_v3.branch1x1->conv2d_bn(x, 320, 1, 1)
A:keras.applications.inception_v3.branch5x5->conv2d_bn(branch5x5, 64, 5, 5)
A:keras.applications.inception_v3.branch3x3dbl->VersionAwareLayers().concatenate([branch3x3dbl_1, branch3x3dbl_2], axis=channel_axis)
A:keras.applications.inception_v3.branch_pool->conv2d_bn(branch_pool, 192, 1, 1)
A:keras.applications.inception_v3.branch3x3->VersionAwareLayers().concatenate([branch3x3_1, branch3x3_2], axis=channel_axis, name='mixed9_' + str(i))
A:keras.applications.inception_v3.branch7x7->conv2d_bn(branch7x7, 192, 7, 1)
A:keras.applications.inception_v3.branch7x7dbl->conv2d_bn(branch7x7dbl, 192, 1, 7)
A:keras.applications.inception_v3.branch7x7x3->conv2d_bn(branch7x7x3, 192, 3, 3, strides=(2, 2), padding='valid')
A:keras.applications.inception_v3.branch3x3_1->conv2d_bn(branch3x3, 384, 1, 3)
A:keras.applications.inception_v3.branch3x3_2->conv2d_bn(branch3x3, 384, 3, 1)
A:keras.applications.inception_v3.branch3x3dbl_1->conv2d_bn(branch3x3dbl, 384, 1, 3)
A:keras.applications.inception_v3.branch3x3dbl_2->conv2d_bn(branch3x3dbl, 384, 3, 1)
A:keras.applications.inception_v3.inputs->keras.utils.layer_utils.get_source_inputs(input_tensor)
A:keras.applications.inception_v3.model->keras.engine.training.Model(inputs, x, name='inception_v3')
A:keras.applications.inception_v3.weights_path->keras.utils.data_utils.get_file('inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5', WEIGHTS_PATH_NO_TOP, cache_subdir='models', file_hash='bcbd6486424b2319ff4ef7d526e38f63')
A:keras.applications.inception_v3.preprocess_input.__doc__->keras.applications.imagenet_utils.PREPROCESS_INPUT_DOC.format(mode='', ret=imagenet_utils.PREPROCESS_INPUT_RET_DOC_TF, error=imagenet_utils.PREPROCESS_INPUT_ERROR_DOC)
keras.applications.InceptionV3(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.inception_v3.InceptionV3(include_top=True,weights='imagenet',input_tensor=None,input_shape=None,pooling=None,classes=1000,classifier_activation='softmax')
keras.applications.inception_v3.conv2d_bn(x,filters,num_row,num_col,padding='same',strides=(1,1),name=None)
keras.applications.inception_v3.decode_predictions(preds,top=5)
keras.applications.inception_v3.preprocess_input(x,data_format=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/estimator/__init__.py----------------------------------------
A:keras.estimator.__init__._model_to_estimator_usage_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/model_to_estimator', 'Whether tf.keras.estimator.model_to_estimator() is called.', 'version')
keras.estimator.__init__.model_to_estimator(keras_model=None,keras_model_path=None,custom_objects=None,model_dir=None,config=None,checkpoint_format='saver',metric_names_map=None,export_outputs=None)
keras.estimator.__init__.model_to_estimator_v2(keras_model=None,keras_model_path=None,custom_objects=None,model_dir=None,config=None,checkpoint_format='checkpoint',metric_names_map=None,export_outputs=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/feature_column/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/feature_column/sequence_feature_column.py----------------------------------------
A:keras.feature_column.sequence_feature_column.training->keras.backend.learning_phase()
A:keras.feature_column.sequence_feature_column.transformation_cache->tensorflow.compat.v2.__internal__.feature_column.FeatureTransformationCache(features)
A:keras.feature_column.sequence_feature_column.(dense_tensor, sequence_length)->column.get_sequence_dense_tensor(transformation_cache, self._state_manager)
A:keras.feature_column.sequence_feature_column.sequence_length->_assert_all_equal_and_return(sequence_lengths)
keras.feature_column.sequence_feature_column.SequenceFeatures(self,feature_columns,trainable=True,name=None,**kwargs)
keras.feature_column.sequence_feature_column.SequenceFeatures.__init__(self,feature_columns,trainable=True,name=None,**kwargs)
keras.feature_column.sequence_feature_column.SequenceFeatures._is_feature_layer(self)
keras.feature_column.sequence_feature_column.SequenceFeatures._target_shape(self,input_shape,total_elements)
keras.feature_column.sequence_feature_column.SequenceFeatures.call(self,features,training=None)
keras.feature_column.sequence_feature_column._assert_all_equal_and_return(tensors,name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/feature_column/dense_features_v2.py----------------------------------------
A:keras.feature_column.dense_features_v2.self._state_manager->_StateManagerImplV2(self, self.trainable)
A:keras.feature_column.dense_features_v2.var->self._layer.add_weight(name=name, shape=shape, dtype=dtype, initializer=initializer, trainable=self._trainable and trainable, use_resource=use_resource)
A:keras.feature_column.dense_features_v2.previous_value->getattr(obj, '_manual_tracking', True)
keras.feature_column.dense_features_v2.DenseFeatures(self,feature_columns,trainable=True,name=None,**kwargs)
keras.feature_column.dense_features_v2.DenseFeatures.__init__(self,feature_columns,trainable=True,name=None,**kwargs)
keras.feature_column.dense_features_v2.DenseFeatures.build(self,_)
keras.feature_column.dense_features_v2._StateManagerImplV2(tf.__internal__.feature_column.StateManager)
keras.feature_column.dense_features_v2._StateManagerImplV2.create_variable(self,feature_column,name,shape,dtype=None,trainable=True,use_resource=True,initializer=None)
keras.feature_column.dense_features_v2.no_manual_dependency_tracking_scope(obj)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/feature_column/base_feature_layer.py----------------------------------------
A:keras.feature_column.base_feature_layer.self._feature_columns->_normalize_feature_columns(feature_columns)
A:keras.feature_column.base_feature_layer.self._state_manager->tensorflow.compat.v2.__internal__.feature_column.StateManager(self, self.trainable)
A:keras.feature_column.base_feature_layer.num_elements->column.variable_shape.num_elements()
A:keras.feature_column.base_feature_layer.target_shape->self._target_shape(tf.shape(tensor), num_elements)
A:keras.feature_column.base_feature_layer.config['partitioner']->keras.utils.generic_utils.serialize_keras_object(self._partitioner)
A:keras.feature_column.base_feature_layer.base_config->super(_BaseFeaturesLayer, self).get_config()
A:keras.feature_column.base_feature_layer.config_cp->config.copy()
A:keras.feature_column.base_feature_layer.config_cp['partitioner']->keras.utils.generic_utils.deserialize_keras_object(config['partitioner'], custom_objects)
A:keras.feature_column.base_feature_layer.invalid_char->re.compile('[^A-Za-z0-9_.\\-]')
A:keras.feature_column.base_feature_layer.batch_size->tensorflow.compat.v2.compat.v1.Dimension(tf.compat.dimension_value(tensors[i].shape[0]))
A:keras.feature_column.base_feature_layer.feature_columns->list(feature_columns)
keras.feature_column.base_feature_layer._BaseFeaturesLayer(self,feature_columns,expected_column_type,trainable,name,partitioner=None,**kwargs)
keras.feature_column.base_feature_layer._BaseFeaturesLayer.__init__(self,feature_columns,expected_column_type,trainable,name,partitioner=None,**kwargs)
keras.feature_column.base_feature_layer._BaseFeaturesLayer._output_shape(self,input_shape,num_elements)
keras.feature_column.base_feature_layer._BaseFeaturesLayer._process_dense_tensor(self,column,tensor)
keras.feature_column.base_feature_layer._BaseFeaturesLayer._verify_and_concat_tensors(self,output_tensors)
keras.feature_column.base_feature_layer._BaseFeaturesLayer.build(self,_)
keras.feature_column.base_feature_layer._BaseFeaturesLayer.compute_output_shape(self,input_shape)
keras.feature_column.base_feature_layer._BaseFeaturesLayer.from_config(cls,config,custom_objects=None)
keras.feature_column.base_feature_layer._BaseFeaturesLayer.get_config(self)
keras.feature_column.base_feature_layer._normalize_feature_columns(feature_columns)
keras.feature_column.base_feature_layer._sanitize_column_name_for_variable_scope(name)
keras.feature_column.base_feature_layer._verify_static_batch_size_equality(tensors,columns)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/feature_column/dense_features.py----------------------------------------
A:keras.feature_column.dense_features.metadata->json.loads(super(DenseFeatures, self)._tracking_metadata)
A:keras.feature_column.dense_features.training->keras.backend.learning_phase()
A:keras.feature_column.dense_features.transformation_cache->tensorflow.compat.v2.__internal__.feature_column.FeatureTransformationCache(features)
A:keras.feature_column.dense_features.tensor->column.get_dense_tensor(transformation_cache, self._state_manager)
A:keras.feature_column.dense_features.processed_tensors->self._process_dense_tensor(column, tensor)
keras.feature_column.dense_features.DenseFeatures(self,feature_columns,trainable=True,name=None,partitioner=None,**kwargs)
keras.feature_column.dense_features.DenseFeatures.__init__(self,feature_columns,trainable=True,name=None,partitioner=None,**kwargs)
keras.feature_column.dense_features.DenseFeatures._is_feature_layer(self)
keras.feature_column.dense_features.DenseFeatures._target_shape(self,input_shape,total_elements)
keras.feature_column.dense_features.DenseFeatures._tracking_metadata(self)
keras.feature_column.dense_features.DenseFeatures.call(self,features,cols_to_output_tensors=None,training=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/wrappers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/wrappers/scikit_learn.py----------------------------------------
A:keras.wrappers.scikit_learn.res->self.sk_params.copy()
A:keras.wrappers.scikit_learn.self.model->self.build_fn(**self.filter_sk_params(self.build_fn))
A:keras.wrappers.scikit_learn.y->to_categorical(y)
A:keras.wrappers.scikit_learn.fit_args->copy.deepcopy(self.filter_sk_params(Sequential.fit))
A:keras.wrappers.scikit_learn.history->self.model.fit(x, y, **fit_args)
A:keras.wrappers.scikit_learn.self.classes_->numpy.unique(y)
A:keras.wrappers.scikit_learn.self.n_classes_->len(self.classes_)
A:keras.wrappers.scikit_learn.proba->self.model.predict(x, **kwargs)
A:keras.wrappers.scikit_learn.classes->(proba > 0.5).astype('int32')
A:keras.wrappers.scikit_learn.probs->numpy.hstack([1 - probs, probs])
A:keras.wrappers.scikit_learn.kwargs->self.filter_sk_params(Sequential.evaluate, kwargs)
A:keras.wrappers.scikit_learn.outputs->self.model.evaluate(x, y, **kwargs)
A:keras.wrappers.scikit_learn.loss->self.model.evaluate(x, y, **kwargs)
keras.wrappers.scikit_learn.BaseWrapper(self,build_fn=None,**sk_params)
keras.wrappers.scikit_learn.BaseWrapper.__init__(self,build_fn=None,**sk_params)
keras.wrappers.scikit_learn.BaseWrapper.check_params(self,params)
keras.wrappers.scikit_learn.BaseWrapper.filter_sk_params(self,fn,override=None)
keras.wrappers.scikit_learn.BaseWrapper.fit(self,x,y,**kwargs)
keras.wrappers.scikit_learn.BaseWrapper.get_params(self,**params)
keras.wrappers.scikit_learn.BaseWrapper.set_params(self,**params)
keras.wrappers.scikit_learn.KerasClassifier(self,build_fn=None,**sk_params)
keras.wrappers.scikit_learn.KerasClassifier.__init__(self,build_fn=None,**sk_params)
keras.wrappers.scikit_learn.KerasClassifier.fit(self,x,y,**kwargs)
keras.wrappers.scikit_learn.KerasClassifier.predict(self,x,**kwargs)
keras.wrappers.scikit_learn.KerasClassifier.predict_proba(self,x,**kwargs)
keras.wrappers.scikit_learn.KerasClassifier.score(self,x,y,**kwargs)
keras.wrappers.scikit_learn.KerasRegressor(self,build_fn=None,**sk_params)
keras.wrappers.scikit_learn.KerasRegressor.__init__(self,build_fn=None,**sk_params)
keras.wrappers.scikit_learn.KerasRegressor.predict(self,x,**kwargs)
keras.wrappers.scikit_learn.KerasRegressor.score(self,x,y,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/__init__.py----------------------------------------
A:keras.api.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], '', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/__init__.py----------------------------------------
A:keras.api._v1.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], '', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__init__.py----------------------------------------
A:keras.api._v1.keras.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/experimental/__init__.py----------------------------------------
A:keras.api._v1.keras.experimental.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.experimental', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/preprocessing/__init__.py----------------------------------------
A:keras.api._v1.keras.preprocessing.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/preprocessing/image/__init__.py----------------------------------------
A:keras.api._v1.keras.preprocessing.image.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing.image', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/preprocessing/text/__init__.py----------------------------------------
A:keras.api._v1.keras.preprocessing.text.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing.text', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/preprocessing/sequence/__init__.py----------------------------------------
A:keras.api._v1.keras.preprocessing.sequence.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing.sequence', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/cifar100/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.cifar100.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.cifar100', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/imdb/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.imdb.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.imdb', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/boston_housing/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.boston_housing.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.boston_housing', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/fashion_mnist/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.fashion_mnist.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.fashion_mnist', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/cifar10/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.cifar10.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.cifar10', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/reuters/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.reuters.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.reuters', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/datasets/mnist/__init__.py----------------------------------------
A:keras.api._v1.keras.datasets.mnist.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.mnist', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/metrics/__init__.py----------------------------------------
A:keras.api._v1.keras.metrics.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.metrics', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/mobilenet_v3/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.mobilenet_v3.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.mobilenet_v3', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/resnet/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.resnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/resnet_rs/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.resnet_rs.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet_rs', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/inception_v3/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.inception_v3.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.inception_v3', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/vgg19/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.vgg19.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.vgg19', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/resnet_v2/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.resnet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/inception_resnet_v2/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.inception_resnet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.inception_resnet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/efficientnet/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.efficientnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.efficientnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/efficientnet_v2/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.efficientnet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.efficientnet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/densenet/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.densenet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.densenet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/xception/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.xception.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.xception', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/imagenet_utils/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.imagenet_utils.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.imagenet_utils', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/resnet50/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.resnet50.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet50', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/regnet/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.regnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.regnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/vgg16/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.vgg16.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.vgg16', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/mobilenet_v2/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.mobilenet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.mobilenet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/nasnet/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.nasnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.nasnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/applications/mobilenet/__init__.py----------------------------------------
A:keras.api._v1.keras.applications.mobilenet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.mobilenet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/activations/__init__.py----------------------------------------
A:keras.api._v1.keras.activations.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.activations', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/estimator/__init__.py----------------------------------------
A:keras.api._v1.keras.estimator.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.estimator', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/backend/__init__.py----------------------------------------
A:keras.api._v1.keras.backend.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.backend', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/wrappers/__init__.py----------------------------------------
A:keras.api._v1.keras.wrappers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.wrappers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/wrappers/scikit_learn/__init__.py----------------------------------------
A:keras.api._v1.keras.wrappers.scikit_learn.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.wrappers.scikit_learn', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/initializers/__init__.py----------------------------------------
A:keras.api._v1.keras.initializers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.initializers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/optimizers/__init__.py----------------------------------------
A:keras.api._v1.keras.optimizers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.optimizers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/optimizers/schedules/__init__.py----------------------------------------
A:keras.api._v1.keras.optimizers.schedules.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.optimizers.schedules', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/optimizers/legacy/__init__.py----------------------------------------
A:keras.api._v1.keras.optimizers.legacy.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.optimizers.legacy', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__internal__/__init__.py----------------------------------------
A:keras.api._v1.keras.__internal__.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__internal__/legacy/__init__.py----------------------------------------
A:keras.api._v1.keras.__internal__.legacy.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__internal__/legacy/rnn_cell/__init__.py----------------------------------------
A:keras.api._v1.keras.__internal__.legacy.rnn_cell.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy.rnn_cell', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__internal__/legacy/layers/__init__.py----------------------------------------
A:keras.api._v1.keras.__internal__.legacy.layers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy.layers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__internal__/legacy/layers/experimental/__init__.py----------------------------------------
A:keras.api._v1.keras.__internal__.legacy.layers.experimental.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy.layers.experimental', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/__internal__/layers/__init__.py----------------------------------------
A:keras.api._v1.keras.__internal__.layers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.layers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/callbacks/__init__.py----------------------------------------
A:keras.api._v1.keras.callbacks.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.callbacks', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/callbacks/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/losses/__init__.py----------------------------------------
A:keras.api._v1.keras.losses.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.losses', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/constraints/__init__.py----------------------------------------
A:keras.api._v1.keras.constraints.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.constraints', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/models/__init__.py----------------------------------------
A:keras.api._v1.keras.models.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.models', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/regularizers/__init__.py----------------------------------------
A:keras.api._v1.keras.regularizers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.regularizers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/mixed_precision/__init__.py----------------------------------------
A:keras.api._v1.keras.mixed_precision.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.mixed_precision', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/utils/__init__.py----------------------------------------
A:keras.api._v1.keras.utils.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.utils', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/layers/__init__.py----------------------------------------
A:keras.api._v1.keras.layers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.layers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/layers/experimental/__init__.py----------------------------------------
A:keras.api._v1.keras.layers.experimental.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.layers.experimental', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/layers/experimental/preprocessing/__init__.py----------------------------------------
A:keras.api._v1.keras.layers.experimental.preprocessing.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.layers.experimental.preprocessing', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v1/keras/premade/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/preprocessing/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/preprocessing/image/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/preprocessing/text/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/preprocessing/sequence/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/cifar100/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/imdb/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/boston_housing/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/fashion_mnist/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/cifar10/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/reuters/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/datasets/mnist/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/metrics/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/mobilenet_v3/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/resnet/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/resnet_rs/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/inception_v3/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/vgg19/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/resnet_v2/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/inception_resnet_v2/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/efficientnet/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/efficientnet_v2/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/densenet/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/xception/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/imagenet_utils/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/resnet50/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/regnet/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/vgg16/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/mobilenet_v2/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/nasnet/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/applications/mobilenet/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/activations/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/estimator/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/backend/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/backend/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/wrappers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/wrappers/scikit_learn/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/initializers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/optimizers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/optimizers/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/optimizers/schedules/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/optimizers/legacy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__internal__/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__internal__/backend/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__internal__/losses/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__internal__/models/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__internal__/utils/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/__internal__/layers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/callbacks/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/callbacks/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/losses/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/dtensor/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/dtensor/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/dtensor/experimental/optimizers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/constraints/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/models/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/regularizers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/mixed_precision/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/utils/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/utils/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/layers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/layers/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/layers/experimental/preprocessing/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/_v2/keras/premade/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__init__.py----------------------------------------
A:keras.api.keras.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/experimental/__init__.py----------------------------------------
A:keras.api.keras.experimental.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.experimental', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/preprocessing/__init__.py----------------------------------------
A:keras.api.keras.preprocessing.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/preprocessing/image/__init__.py----------------------------------------
A:keras.api.keras.preprocessing.image.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing.image', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/preprocessing/text/__init__.py----------------------------------------
A:keras.api.keras.preprocessing.text.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing.text', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/preprocessing/sequence/__init__.py----------------------------------------
A:keras.api.keras.preprocessing.sequence.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.preprocessing.sequence', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/__init__.py----------------------------------------
A:keras.api.keras.datasets.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/cifar100/__init__.py----------------------------------------
A:keras.api.keras.datasets.cifar100.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.cifar100', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/imdb/__init__.py----------------------------------------
A:keras.api.keras.datasets.imdb.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.imdb', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/boston_housing/__init__.py----------------------------------------
A:keras.api.keras.datasets.boston_housing.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.boston_housing', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/fashion_mnist/__init__.py----------------------------------------
A:keras.api.keras.datasets.fashion_mnist.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.fashion_mnist', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/cifar10/__init__.py----------------------------------------
A:keras.api.keras.datasets.cifar10.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.cifar10', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/reuters/__init__.py----------------------------------------
A:keras.api.keras.datasets.reuters.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.reuters', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/datasets/mnist/__init__.py----------------------------------------
A:keras.api.keras.datasets.mnist.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.datasets.mnist', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/metrics/__init__.py----------------------------------------
A:keras.api.keras.metrics.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.metrics', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/__init__.py----------------------------------------
A:keras.api.keras.applications.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/mobilenet_v3/__init__.py----------------------------------------
A:keras.api.keras.applications.mobilenet_v3.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.mobilenet_v3', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/resnet/__init__.py----------------------------------------
A:keras.api.keras.applications.resnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/resnet_rs/__init__.py----------------------------------------
A:keras.api.keras.applications.resnet_rs.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet_rs', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/inception_v3/__init__.py----------------------------------------
A:keras.api.keras.applications.inception_v3.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.inception_v3', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/vgg19/__init__.py----------------------------------------
A:keras.api.keras.applications.vgg19.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.vgg19', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/resnet_v2/__init__.py----------------------------------------
A:keras.api.keras.applications.resnet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/inception_resnet_v2/__init__.py----------------------------------------
A:keras.api.keras.applications.inception_resnet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.inception_resnet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/efficientnet/__init__.py----------------------------------------
A:keras.api.keras.applications.efficientnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.efficientnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/efficientnet_v2/__init__.py----------------------------------------
A:keras.api.keras.applications.efficientnet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.efficientnet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/densenet/__init__.py----------------------------------------
A:keras.api.keras.applications.densenet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.densenet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/xception/__init__.py----------------------------------------
A:keras.api.keras.applications.xception.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.xception', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/imagenet_utils/__init__.py----------------------------------------
A:keras.api.keras.applications.imagenet_utils.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.imagenet_utils', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/resnet50/__init__.py----------------------------------------
A:keras.api.keras.applications.resnet50.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.resnet50', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/regnet/__init__.py----------------------------------------
A:keras.api.keras.applications.regnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.regnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/vgg16/__init__.py----------------------------------------
A:keras.api.keras.applications.vgg16.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.vgg16', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/mobilenet_v2/__init__.py----------------------------------------
A:keras.api.keras.applications.mobilenet_v2.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.mobilenet_v2', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/nasnet/__init__.py----------------------------------------
A:keras.api.keras.applications.nasnet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.nasnet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/applications/mobilenet/__init__.py----------------------------------------
A:keras.api.keras.applications.mobilenet.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.applications.mobilenet', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/activations/__init__.py----------------------------------------
A:keras.api.keras.activations.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.activations', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/estimator/__init__.py----------------------------------------
A:keras.api.keras.estimator.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.estimator', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/backend/__init__.py----------------------------------------
A:keras.api.keras.backend.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.backend', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/wrappers/__init__.py----------------------------------------
A:keras.api.keras.wrappers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.wrappers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/wrappers/scikit_learn/__init__.py----------------------------------------
A:keras.api.keras.wrappers.scikit_learn.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.wrappers.scikit_learn', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/initializers/__init__.py----------------------------------------
A:keras.api.keras.initializers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.initializers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/optimizers/__init__.py----------------------------------------
A:keras.api.keras.optimizers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.optimizers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/optimizers/schedules/__init__.py----------------------------------------
A:keras.api.keras.optimizers.schedules.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.optimizers.schedules', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/optimizers/legacy/__init__.py----------------------------------------
A:keras.api.keras.optimizers.legacy.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.optimizers.legacy', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__internal__/__init__.py----------------------------------------
A:keras.api.keras.__internal__.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__internal__/legacy/__init__.py----------------------------------------
A:keras.api.keras.__internal__.legacy.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__internal__/legacy/rnn_cell/__init__.py----------------------------------------
A:keras.api.keras.__internal__.legacy.rnn_cell.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy.rnn_cell', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__internal__/legacy/layers/__init__.py----------------------------------------
A:keras.api.keras.__internal__.legacy.layers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy.layers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__internal__/legacy/layers/experimental/__init__.py----------------------------------------
A:keras.api.keras.__internal__.legacy.layers.experimental.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.legacy.layers.experimental', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/__internal__/layers/__init__.py----------------------------------------
A:keras.api.keras.__internal__.layers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.__internal__.layers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/callbacks/__init__.py----------------------------------------
A:keras.api.keras.callbacks.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.callbacks', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/callbacks/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/losses/__init__.py----------------------------------------
A:keras.api.keras.losses.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.losses', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/constraints/__init__.py----------------------------------------
A:keras.api.keras.constraints.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.constraints', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/models/__init__.py----------------------------------------
A:keras.api.keras.models.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.models', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/regularizers/__init__.py----------------------------------------
A:keras.api.keras.regularizers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.regularizers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/mixed_precision/__init__.py----------------------------------------
A:keras.api.keras.mixed_precision.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.mixed_precision', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/utils/__init__.py----------------------------------------
A:keras.api.keras.utils.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.utils', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/layers/__init__.py----------------------------------------
A:keras.api.keras.layers.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.layers', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/layers/experimental/__init__.py----------------------------------------
A:keras.api.keras.layers.experimental.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.layers.experimental', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/layers/experimental/preprocessing/__init__.py----------------------------------------
A:keras.api.keras.layers.experimental.preprocessing.__init__._sys.modules[__name__]->tensorflow.python.util.module_wrapper.TFModuleWrapper(_sys.modules[__name__], 'keras.layers.experimental.preprocessing', public_apis=None, deprecation=True, has_lite=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/api/keras/premade/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/initializers/__init__.py----------------------------------------
A:keras.initializers.__init__.LOCAL->threading.local()
A:keras.initializers.__init__.LOCAL.GENERATED_WITH_V2->tensorflow.compat.v2.__internal__.tf2.enabled()
A:keras.initializers.__init__.identifier->identifier()
keras.initializers.__init__.deserialize(config,custom_objects=None)
keras.initializers.__init__.get(identifier)
keras.initializers.__init__.populate_deserializable_objects()
keras.initializers.__init__.serialize(initializer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/initializers/initializers_v2.py----------------------------------------
A:keras.initializers.initializers_v2.dtype->tensorflow.compat.v2.as_dtype(dtype)
A:keras.initializers.initializers_v2.layout->kwargs.pop('layout', None)
A:keras.initializers.initializers_v2.self._random_generator->keras.backend.RandomGenerator(seed)
A:keras.initializers.initializers_v2.distribution->distribution.lower().lower()
A:keras.initializers.initializers_v2.(fan_in, fan_out)->_compute_fans(shape)
A:keras.initializers.initializers_v2.stddev->math.sqrt(scale)
A:keras.initializers.initializers_v2.limit->math.sqrt(3.0 * scale)
A:keras.initializers.initializers_v2.a->self._random_generator.random_normal(flat_shape, dtype=dtype)
A:keras.initializers.initializers_v2.(q, r)->tensorflow.compat.v2.linalg.qr(a, full_matrices=False)
A:keras.initializers.initializers_v2.d->tensorflow.compat.v2.linalg.tensor_diag_part(r)
A:keras.initializers.initializers_v2.q->tensorflow.compat.v2.linalg.matrix_transpose(q)
A:keras.initializers.initializers_v2.initializer->tensorflow.compat.v2.eye(*shape, dtype=dtype)
keras.initializers.initializers_v2.Constant(self,value=0)
keras.initializers.initializers_v2.Constant.__init__(self,value=0)
keras.initializers.initializers_v2.Constant.get_config(self)
keras.initializers.initializers_v2.GlorotNormal(self,seed=None)
keras.initializers.initializers_v2.GlorotNormal.__init__(self,seed=None)
keras.initializers.initializers_v2.GlorotNormal.get_config(self)
keras.initializers.initializers_v2.GlorotUniform(self,seed=None)
keras.initializers.initializers_v2.GlorotUniform.__init__(self,seed=None)
keras.initializers.initializers_v2.GlorotUniform.get_config(self)
keras.initializers.initializers_v2.HeNormal(self,seed=None)
keras.initializers.initializers_v2.HeNormal.__init__(self,seed=None)
keras.initializers.initializers_v2.HeNormal.get_config(self)
keras.initializers.initializers_v2.HeUniform(self,seed=None)
keras.initializers.initializers_v2.HeUniform.__init__(self,seed=None)
keras.initializers.initializers_v2.HeUniform.get_config(self)
keras.initializers.initializers_v2.Identity(self,gain=1.0)
keras.initializers.initializers_v2.Identity.__init__(self,gain=1.0)
keras.initializers.initializers_v2.Identity._generate_init_val(self,shape,dtype)
keras.initializers.initializers_v2.Identity.get_config(self)
keras.initializers.initializers_v2.Initializer(self,shape,dtype=None,**kwargs)
keras.initializers.initializers_v2.Initializer.__call__(self,shape,dtype=None,**kwargs)
keras.initializers.initializers_v2.Initializer.from_config(cls,config)
keras.initializers.initializers_v2.Initializer.get_config(self)
keras.initializers.initializers_v2.LecunNormal(self,seed=None)
keras.initializers.initializers_v2.LecunNormal.__init__(self,seed=None)
keras.initializers.initializers_v2.LecunNormal.get_config(self)
keras.initializers.initializers_v2.LecunUniform(self,seed=None)
keras.initializers.initializers_v2.LecunUniform.__init__(self,seed=None)
keras.initializers.initializers_v2.LecunUniform.get_config(self)
keras.initializers.initializers_v2.Ones(self,shape,dtype=None,**kwargs)
keras.initializers.initializers_v2.Ones.__call__(self,shape,dtype=None,**kwargs)
keras.initializers.initializers_v2.Orthogonal(self,gain=1.0,seed=None)
keras.initializers.initializers_v2.Orthogonal.__init__(self,gain=1.0,seed=None)
keras.initializers.initializers_v2.Orthogonal._generate_init_val(self,shape,dtype)
keras.initializers.initializers_v2.Orthogonal.get_config(self)
keras.initializers.initializers_v2.RandomNormal(self,mean=0.0,stddev=0.05,seed=None)
keras.initializers.initializers_v2.RandomNormal.__init__(self,mean=0.0,stddev=0.05,seed=None)
keras.initializers.initializers_v2.RandomNormal.get_config(self)
keras.initializers.initializers_v2.RandomUniform(self,minval=-0.05,maxval=0.05,seed=None)
keras.initializers.initializers_v2.RandomUniform.__init__(self,minval=-0.05,maxval=0.05,seed=None)
keras.initializers.initializers_v2.RandomUniform.get_config(self)
keras.initializers.initializers_v2.TruncatedNormal(self,mean=0.0,stddev=0.05,seed=None)
keras.initializers.initializers_v2.TruncatedNormal.__init__(self,mean=0.0,stddev=0.05,seed=None)
keras.initializers.initializers_v2.TruncatedNormal.get_config(self)
keras.initializers.initializers_v2.VarianceScaling(self,scale=1.0,mode='fan_in',distribution='truncated_normal',seed=None)
keras.initializers.initializers_v2.VarianceScaling.__init__(self,scale=1.0,mode='fan_in',distribution='truncated_normal',seed=None)
keras.initializers.initializers_v2.VarianceScaling._generate_init_val(self,shape,dtype)
keras.initializers.initializers_v2.VarianceScaling.get_config(self)
keras.initializers.initializers_v2.Zeros(self,shape,dtype=None,**kwargs)
keras.initializers.initializers_v2.Zeros.__call__(self,shape,dtype=None,**kwargs)
keras.initializers.initializers_v2._assert_float_dtype(dtype)
keras.initializers.initializers_v2._compute_fans(shape)
keras.initializers.initializers_v2._ensure_keras_seeded()
keras.initializers.initializers_v2._get_dtype(dtype)
keras.initializers.initializers_v2._validate_kwargs(cls_name,kwargs,support_partition=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/initializers/initializers_v1.py----------------------------------------
keras.initializers.initializers_v1.HeNormal(self,seed=None)
keras.initializers.initializers_v1.HeNormal.__init__(self,seed=None)
keras.initializers.initializers_v1.HeNormal.get_config(self)
keras.initializers.initializers_v1.HeUniform(self,seed=None)
keras.initializers.initializers_v1.HeUniform.__init__(self,seed=None)
keras.initializers.initializers_v1.HeUniform.get_config(self)
keras.initializers.initializers_v1.LecunNormal(self,seed=None)
keras.initializers.initializers_v1.LecunNormal.__init__(self,seed=None)
keras.initializers.initializers_v1.LecunNormal.get_config(self)
keras.initializers.initializers_v1.LecunUniform(self,seed=None)
keras.initializers.initializers_v1.LecunUniform.__init__(self,seed=None)
keras.initializers.initializers_v1.LecunUniform.get_config(self)
keras.initializers.initializers_v1.RandomNormal(self,mean=0.0,stddev=0.05,seed=None,dtype=tf.float32)
keras.initializers.initializers_v1.RandomNormal.__init__(self,mean=0.0,stddev=0.05,seed=None,dtype=tf.float32)
keras.initializers.initializers_v1.RandomUniform(self,minval=-0.05,maxval=0.05,seed=None,dtype=tf.float32)
keras.initializers.initializers_v1.RandomUniform.__init__(self,minval=-0.05,maxval=0.05,seed=None,dtype=tf.float32)
keras.initializers.initializers_v1.TruncatedNormal(self,mean=0.0,stddev=0.05,seed=None,dtype=tf.float32)
keras.initializers.initializers_v1.TruncatedNormal.__init__(self,mean=0.0,stddev=0.05,seed=None,dtype=tf.float32)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/__init__.py----------------------------------------
A:keras.optimizers.__init__.config['class_name']->config['class_name'].lower().lower()
A:keras.optimizers.__init__.opt->TFOptimizer(identifier)
keras.optimizers.__init__.deserialize(config,custom_objects=None)
keras.optimizers.__init__.get(identifier)
keras.optimizers.__init__.serialize(optimizer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy_learning_rate_decay.py----------------------------------------
A:keras.optimizers.legacy_learning_rate_decay.decayed_lr->functools.partial(decayed_lr, global_step)
A:keras.optimizers.legacy_learning_rate_decay.boundaries->tensorflow.compat.v2.nest.map_structure(tf.convert_to_tensor, tf.nest.flatten(boundaries))
A:keras.optimizers.legacy_learning_rate_decay.values->tensorflow.compat.v2.nest.map_structure(tf.convert_to_tensor, tf.nest.flatten(values))
A:keras.optimizers.legacy_learning_rate_decay.x_recomp->tensorflow.compat.v2.convert_to_tensor(x)
A:keras.optimizers.legacy_learning_rate_decay.b->tensorflow.compat.v2.cast(b, x_recomp.dtype.base_dtype)
A:keras.optimizers.legacy_learning_rate_decay.natural_exp_rate->tensorflow.compat.v2.exp(tf.negative(decay_rate))
keras.optimizers.legacy_learning_rate_decay.cosine_decay(learning_rate,global_step,decay_steps,alpha=0.0,name=None)
keras.optimizers.legacy_learning_rate_decay.cosine_decay_restarts(learning_rate,global_step,first_decay_steps,t_mul=2.0,m_mul=1.0,alpha=0.0,name=None)
keras.optimizers.legacy_learning_rate_decay.exponential_decay(learning_rate,global_step,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.legacy_learning_rate_decay.inverse_time_decay(learning_rate,global_step,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.legacy_learning_rate_decay.linear_cosine_decay(learning_rate,global_step,decay_steps,num_periods=0.5,alpha=0.0,beta=0.001,name=None)
keras.optimizers.legacy_learning_rate_decay.natural_exp_decay(learning_rate,global_step,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.legacy_learning_rate_decay.noisy_linear_cosine_decay(learning_rate,global_step,decay_steps,initial_variance=1.0,variance_decay=0.55,num_periods=0.5,alpha=0.0,beta=0.001,name=None)
keras.optimizers.legacy_learning_rate_decay.piecewise_constant(x,boundaries,values,name=None)
keras.optimizers.legacy_learning_rate_decay.polynomial_decay(learning_rate,global_step,decay_steps,end_learning_rate=0.0001,power=1.0,cycle=False,name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v1.py----------------------------------------
A:keras.optimizers.optimizer_v1.grads->self.optimizer.compute_gradients(loss, params)
A:keras.optimizers.optimizer_v1.param_values->keras.backend.batch_get_value(params)
A:keras.optimizers.optimizer_v1.self.iterations->keras.backend.variable(0, dtype='int64', name='iterations')
A:keras.optimizers.optimizer_v1.self.lr->keras.backend.variable(lr, name='lr')
A:keras.optimizers.optimizer_v1.self.momentum->keras.backend.variable(momentum, name='momentum')
A:keras.optimizers.optimizer_v1.self.decay->keras.backend.variable(decay, name='decay')
A:keras.optimizers.optimizer_v1.moments->self._create_all_weights(params)
A:keras.optimizers.optimizer_v1.new_p->p.constraint(new_p)
A:keras.optimizers.optimizer_v1.base_config->super(Nadam, self).get_config()
A:keras.optimizers.optimizer_v1.self.rho->keras.backend.variable(rho, name='rho')
A:keras.optimizers.optimizer_v1.epsilon->keras.backend.epsilon()
A:keras.optimizers.optimizer_v1.accumulators->self._create_all_weights(params)
A:keras.optimizers.optimizer_v1.(accumulators, delta_accumulators)->self._create_all_weights(params)
A:keras.optimizers.optimizer_v1.self.beta_1->keras.backend.variable(beta_1, name='beta_1')
A:keras.optimizers.optimizer_v1.self.beta_2->keras.backend.variable(beta_2, name='beta_2')
A:keras.optimizers.optimizer_v1.t->tensorflow.compat.v2.cast(self.iterations, backend.floatx())
A:keras.optimizers.optimizer_v1.(ms, vs, vhats)->self._create_all_weights(params)
A:keras.optimizers.optimizer_v1.vhat_t->tensorflow.compat.v2.maximum(vhat, v_t)
A:keras.optimizers.optimizer_v1.(ms, us)->self._create_all_weights(params)
A:keras.optimizers.optimizer_v1.u_t->tensorflow.compat.v2.maximum(self.beta_2 * u, tf.abs(g))
A:keras.optimizers.optimizer_v1.self.m_schedule->keras.backend.variable(1.0, name='m_schedule')
A:keras.optimizers.optimizer_v1.(ms, vs)->self._create_all_weights(params)
A:keras.optimizers.optimizer_v1.loss->loss()
A:keras.optimizers.optimizer_v1.var_list->tensorflow.compat.v2.nest.flatten(var_list)
A:keras.optimizers.optimizer_v1.grads_and_vars->list(zip(grads, var_list))
A:keras.optimizers.optimizer_v1.global_step->tensorflow.compat.v2.compat.v1.train.get_global_step()
A:keras.optimizers.optimizer_v1.opt_update->self.optimizer.apply_gradients(grads, global_step=self.iterations)
keras.optimizers.Optimizer(self,**kwargs)
keras.optimizers.Optimizer._create_all_weights(self,params)
keras.optimizers.Optimizer.from_config(cls,config)
keras.optimizers.Optimizer.get_config(self)
keras.optimizers.Optimizer.get_gradients(self,loss,params)
keras.optimizers.Optimizer.get_updates(self,loss,params)
keras.optimizers.Optimizer.get_weights(self)
keras.optimizers.Optimizer.set_weights(self,weights)
keras.optimizers.TFOptimizer(self,optimizer,iterations=None)
keras.optimizers.TFOptimizer._clip_gradients(self,grads)
keras.optimizers.TFOptimizer.apply_gradients(self,grads_and_vars)
keras.optimizers.TFOptimizer.from_config(self,config)
keras.optimizers.TFOptimizer.get_config(self)
keras.optimizers.TFOptimizer.get_grads(self,loss,params)
keras.optimizers.TFOptimizer.get_updates(self,loss,params)
keras.optimizers.TFOptimizer.minimize(self,loss,var_list,grad_loss=None,tape=None)
keras.optimizers.TFOptimizer.weights(self)
keras.optimizers.optimizer_v1.Adadelta(self,lr=1.0,rho=0.95,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.Adadelta.__init__(self,lr=1.0,rho=0.95,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.Adadelta._create_all_weights(self,params)
keras.optimizers.optimizer_v1.Adadelta.get_config(self)
keras.optimizers.optimizer_v1.Adadelta.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.Adagrad(self,lr=0.01,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.Adagrad.__init__(self,lr=0.01,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.Adagrad._create_all_weights(self,params)
keras.optimizers.optimizer_v1.Adagrad.get_config(self)
keras.optimizers.optimizer_v1.Adagrad.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.Adam(self,lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=None,decay=0.0,amsgrad=False,**kwargs)
keras.optimizers.optimizer_v1.Adam.__init__(self,lr=0.001,beta_1=0.9,beta_2=0.999,epsilon=None,decay=0.0,amsgrad=False,**kwargs)
keras.optimizers.optimizer_v1.Adam._create_all_weights(self,params)
keras.optimizers.optimizer_v1.Adam.get_config(self)
keras.optimizers.optimizer_v1.Adam.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.Adamax(self,lr=0.002,beta_1=0.9,beta_2=0.999,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.Adamax.__init__(self,lr=0.002,beta_1=0.9,beta_2=0.999,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.Adamax._create_all_weights(self,params)
keras.optimizers.optimizer_v1.Adamax.get_config(self)
keras.optimizers.optimizer_v1.Adamax.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.Nadam(self,lr=0.002,beta_1=0.9,beta_2=0.999,epsilon=None,schedule_decay=0.004,**kwargs)
keras.optimizers.optimizer_v1.Nadam.__init__(self,lr=0.002,beta_1=0.9,beta_2=0.999,epsilon=None,schedule_decay=0.004,**kwargs)
keras.optimizers.optimizer_v1.Nadam._create_all_weights(self,params)
keras.optimizers.optimizer_v1.Nadam.get_config(self)
keras.optimizers.optimizer_v1.Nadam.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.Optimizer(self,**kwargs)
keras.optimizers.optimizer_v1.Optimizer.__init__(self,**kwargs)
keras.optimizers.optimizer_v1.Optimizer._create_all_weights(self,params)
keras.optimizers.optimizer_v1.Optimizer.from_config(cls,config)
keras.optimizers.optimizer_v1.Optimizer.get_config(self)
keras.optimizers.optimizer_v1.Optimizer.get_gradients(self,loss,params)
keras.optimizers.optimizer_v1.Optimizer.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.Optimizer.get_weights(self)
keras.optimizers.optimizer_v1.Optimizer.set_weights(self,weights)
keras.optimizers.optimizer_v1.RMSprop(self,lr=0.001,rho=0.9,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.RMSprop.__init__(self,lr=0.001,rho=0.9,epsilon=None,decay=0.0,**kwargs)
keras.optimizers.optimizer_v1.RMSprop._create_all_weights(self,params)
keras.optimizers.optimizer_v1.RMSprop.get_config(self)
keras.optimizers.optimizer_v1.RMSprop.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.SGD(self,lr=0.01,momentum=0.0,decay=0.0,nesterov=False,**kwargs)
keras.optimizers.optimizer_v1.SGD.__init__(self,lr=0.01,momentum=0.0,decay=0.0,nesterov=False,**kwargs)
keras.optimizers.optimizer_v1.SGD._create_all_weights(self,params)
keras.optimizers.optimizer_v1.SGD.get_config(self)
keras.optimizers.optimizer_v1.SGD.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.TFOptimizer(self,optimizer,iterations=None)
keras.optimizers.optimizer_v1.TFOptimizer.__init__(self,optimizer,iterations=None)
keras.optimizers.optimizer_v1.TFOptimizer._clip_gradients(self,grads)
keras.optimizers.optimizer_v1.TFOptimizer.apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_v1.TFOptimizer.from_config(self,config)
keras.optimizers.optimizer_v1.TFOptimizer.get_config(self)
keras.optimizers.optimizer_v1.TFOptimizer.get_grads(self,loss,params)
keras.optimizers.optimizer_v1.TFOptimizer.get_updates(self,loss,params)
keras.optimizers.optimizer_v1.TFOptimizer.minimize(self,loss,var_list,grad_loss=None,tape=None)
keras.optimizers.optimizer_v1.TFOptimizer.weights(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/schedules/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/schedules/learning_rate_schedule.py----------------------------------------
A:keras.optimizers.schedules.learning_rate_schedule.initial_learning_rate->tensorflow.compat.v2.convert_to_tensor(self.initial_learning_rate, name='initial_learning_rate')
A:keras.optimizers.schedules.learning_rate_schedule.decay_steps->tensorflow.compat.v2.cast(self.decay_steps, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.decay_rate->tensorflow.compat.v2.cast(self.decay_rate, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.global_step_recomp->tensorflow.compat.v2.minimum(global_step_recomp, decay_steps)
A:keras.optimizers.schedules.learning_rate_schedule.p->tensorflow.compat.v2.floor(p)
A:keras.optimizers.schedules.learning_rate_schedule.boundaries->tensorflow.compat.v2.nest.map_structure(tf.convert_to_tensor, tf.nest.flatten(self.boundaries))
A:keras.optimizers.schedules.learning_rate_schedule.values->tensorflow.compat.v2.nest.map_structure(tf.convert_to_tensor, tf.nest.flatten(self.values))
A:keras.optimizers.schedules.learning_rate_schedule.x_recomp->tensorflow.compat.v2.convert_to_tensor(step)
A:keras.optimizers.schedules.learning_rate_schedule.b->tensorflow.compat.v2.cast(b, x_recomp.dtype.base_dtype)
A:keras.optimizers.schedules.learning_rate_schedule.end_learning_rate->tensorflow.compat.v2.cast(self.end_learning_rate, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.power->tensorflow.compat.v2.cast(self.power, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.decay_steps_recomp->tensorflow.compat.v2.multiply(decay_steps_recomp, multiplier)
A:keras.optimizers.schedules.learning_rate_schedule.multiplier->tensorflow.compat.v2.where(tf.equal(global_step_recomp, 0), 1.0, tf.math.ceil(global_step_recomp / self.decay_steps))
A:keras.optimizers.schedules.learning_rate_schedule.const->tensorflow.compat.v2.cast(tf.constant(1), dtype)
A:keras.optimizers.schedules.learning_rate_schedule.denom->tensorflow.compat.v2.add(const, tf.multiply(decay_rate, p))
A:keras.optimizers.schedules.learning_rate_schedule.first_decay_steps->tensorflow.compat.v2.cast(self.first_decay_steps, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.alpha->tensorflow.compat.v2.cast(self.alpha, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.t_mul->tensorflow.compat.v2.cast(self._t_mul, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.m_mul->tensorflow.compat.v2.cast(self._m_mul, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.i_restart->tensorflow.compat.v2.floor(completed_fraction)
A:keras.optimizers.schedules.learning_rate_schedule.(i_restart, completed_fraction)->tensorflow.compat.v2.cond(tf.equal(t_mul, 1.0), lambda : compute_step(completed_fraction, geometric=False), lambda : compute_step(completed_fraction, geometric=True))
A:keras.optimizers.schedules.learning_rate_schedule.num_periods->tensorflow.compat.v2.cast(self.num_periods, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.beta->tensorflow.compat.v2.cast(self.beta, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.self._random_generator->keras.backend.RandomGenerator(seed)
A:keras.optimizers.schedules.learning_rate_schedule.initial_variance->tensorflow.compat.v2.cast(self.initial_variance, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.variance_decay->tensorflow.compat.v2.cast(self.variance_decay, dtype)
A:keras.optimizers.schedules.learning_rate_schedule.std->tensorflow.compat.v2.sqrt(variance)
keras.optimizers.schedules.learning_rate_schedule.CosineDecay(self,initial_learning_rate,decay_steps,alpha=0.0,name=None)
keras.optimizers.schedules.learning_rate_schedule.CosineDecay.__init__(self,initial_learning_rate,decay_steps,alpha=0.0,name=None)
keras.optimizers.schedules.learning_rate_schedule.CosineDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.CosineDecayRestarts(self,initial_learning_rate,first_decay_steps,t_mul=2.0,m_mul=1.0,alpha=0.0,name=None)
keras.optimizers.schedules.learning_rate_schedule.CosineDecayRestarts.__init__(self,initial_learning_rate,first_decay_steps,t_mul=2.0,m_mul=1.0,alpha=0.0,name=None)
keras.optimizers.schedules.learning_rate_schedule.CosineDecayRestarts.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay(self,initial_learning_rate,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay.__init__(self,initial_learning_rate,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.schedules.learning_rate_schedule.ExponentialDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.InverseTimeDecay(self,initial_learning_rate,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.schedules.learning_rate_schedule.InverseTimeDecay.__init__(self,initial_learning_rate,decay_steps,decay_rate,staircase=False,name=None)
keras.optimizers.schedules.learning_rate_schedule.InverseTimeDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule(self,step)
keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule.__call__(self,step)
keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule.from_config(cls,config)
keras.optimizers.schedules.learning_rate_schedule.LearningRateSchedule.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.LinearCosineDecay(self,initial_learning_rate,decay_steps,num_periods=0.5,alpha=0.0,beta=0.001,name=None)
keras.optimizers.schedules.learning_rate_schedule.LinearCosineDecay.__init__(self,initial_learning_rate,decay_steps,num_periods=0.5,alpha=0.0,beta=0.001,name=None)
keras.optimizers.schedules.learning_rate_schedule.LinearCosineDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.NoisyLinearCosineDecay(self,initial_learning_rate,decay_steps,initial_variance=1.0,variance_decay=0.55,num_periods=0.5,alpha=0.0,beta=0.001,seed=None,name=None)
keras.optimizers.schedules.learning_rate_schedule.NoisyLinearCosineDecay.__init__(self,initial_learning_rate,decay_steps,initial_variance=1.0,variance_decay=0.55,num_periods=0.5,alpha=0.0,beta=0.001,seed=None,name=None)
keras.optimizers.schedules.learning_rate_schedule.NoisyLinearCosineDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.PiecewiseConstantDecay(self,boundaries,values,name=None)
keras.optimizers.schedules.learning_rate_schedule.PiecewiseConstantDecay.__init__(self,boundaries,values,name=None)
keras.optimizers.schedules.learning_rate_schedule.PiecewiseConstantDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.PolynomialDecay(self,initial_learning_rate,decay_steps,end_learning_rate=0.0001,power=1.0,cycle=False,name=None)
keras.optimizers.schedules.learning_rate_schedule.PolynomialDecay.__init__(self,initial_learning_rate,decay_steps,end_learning_rate=0.0001,power=1.0,cycle=False,name=None)
keras.optimizers.schedules.learning_rate_schedule.PolynomialDecay.get_config(self)
keras.optimizers.schedules.learning_rate_schedule.deserialize(config,custom_objects=None)
keras.optimizers.schedules.learning_rate_schedule.serialize(learning_rate_schedule)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/optimizer.py----------------------------------------
keras.optimizers.legacy.optimizer.Optimizer(optimizer_v2.OptimizerV2)
keras.optimizers.optimizer_legacy.Optimizer(optimizer_v2.OptimizerV2)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/ftrl.py----------------------------------------
keras.optimizers.ftrl_legacy.Ftrl(ftrl.Ftrl)
keras.optimizers.legacy.ftrl.Ftrl(ftrl.Ftrl)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/adagrad.py----------------------------------------
keras.optimizers.adagrad_legacy.Adagrad(adagrad.Adagrad)
keras.optimizers.legacy.adagrad.Adagrad(adagrad.Adagrad)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/sgd.py----------------------------------------
keras.optimizers.legacy.sgd.SGD(gradient_descent.SGD)
keras.optimizers.sgd_legacy.SGD(gradient_descent.SGD)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/adamax.py----------------------------------------
keras.optimizers.adamax_legacy.Adamax(adamax.Adamax)
keras.optimizers.legacy.adamax.Adamax(adamax.Adamax)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/rmsprop.py----------------------------------------
keras.optimizers.legacy.rmsprop.RMSprop(rmsprop.RMSprop)
keras.optimizers.rmsprop_legacy.RMSprop(rmsprop.RMSprop)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/adadelta.py----------------------------------------
keras.optimizers.adadelta_legacy.Adadelta(adadelta.Adadelta)
keras.optimizers.legacy.adadelta.Adadelta(adadelta.Adadelta)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/adam.py----------------------------------------
keras.optimizers.adam_legacy.Adam(adam.Adam)
keras.optimizers.legacy.adam.Adam(adam.Adam)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/legacy/nadam.py----------------------------------------
keras.optimizers.legacy.nadam.Nadam(nadam.Nadam)
keras.optimizers.nadam_legacy.Nadam(nadam.Nadam)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/optimizer.py----------------------------------------
A:keras.optimizers.optimizer_experimental.optimizer.self._iterations->tensorflow.compat.v2.Variable(0, name='iteration', dtype=tf.int64, trainable=False)
A:keras.optimizers.optimizer_experimental.optimizer.tape->tensorflow.compat.v2.GradientTape()
A:keras.optimizers.optimizer_experimental.optimizer.loss->loss()
A:keras.optimizers.optimizer_experimental.optimizer.grads->self._clip_gradients(grads)
A:keras.optimizers.optimizer_experimental.optimizer.self._current_learning_rate->tensorflow.compat.v2.Variable(learning_rate(self.iterations), name='learning_rate', dtype=tf.float32, trainable=False)
A:keras.optimizers.optimizer_experimental.optimizer.var_key->self._var_key(var)
A:keras.optimizers.optimizer_experimental.optimizer.initializer->keras.initializers.get(initializer)
A:keras.optimizers.optimizer_experimental.optimizer.dtype->keras.backend.floatx()
A:keras.optimizers.optimizer_experimental.optimizer.initial_value->tensorflow.compat.v2.zeros(shape, dtype=model_variable.dtype)
A:keras.optimizers.optimizer_experimental.optimizer.grads_and_vars->self.aggregate_gradients(grads_and_vars)
A:keras.optimizers.optimizer_experimental.optimizer.(grads, trainable_variables)->zip(*grads_and_vars)
A:keras.optimizers.optimizer_experimental.optimizer.config['learning_rate']->keras.optimizers.schedules.learning_rate_schedule.deserialize(config['learning_rate'])
A:keras.optimizers.optimizer_experimental.optimizer.self._distribution_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.optimizers.optimizer_experimental.optimizer.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.optimizers.optimizer_experimental.optimizer.variable->variable._distributed_container()._distributed_container()
A:keras.optimizers.optimizer_experimental.optimizer.(_, var_list)->zip(*grads_and_vars)
A:keras.optimizers.optimizer_experimental.optimizer.Optimizer.__doc__->Optimizer.__doc__.replace('{{base_optimizer_keyword_args}}', base_optimizer_keyword_args)
keras.optimizers.optimizer_experimental.Optimizer(self,name,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,**kwargs)
keras.optimizers.optimizer_experimental.Optimizer._distributed_apply_gradients_fn(self,distribution,grads_and_vars,**kwargs)
keras.optimizers.optimizer_experimental.Optimizer._internal_apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental.Optimizer._overwrite_model_variables_with_average_value_helper(self,var_list)
keras.optimizers.optimizer_experimental.Optimizer._update_model_variables_moving_average(self,var_list)
keras.optimizers.optimizer_experimental.Optimizer._var_key(self,variable)
keras.optimizers.optimizer_experimental.Optimizer.add_variable_from_reference(self,model_variable,variable_name,shape=None,initial_value=None)
keras.optimizers.optimizer_experimental.Optimizer.aggregate_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental.Optimizer.apply_gradients(self,grads_and_vars,skip_gradients_aggregation=False)
keras.optimizers.optimizer_experimental.RestoredOptimizer(self)
keras.optimizers.optimizer_experimental.RestoredOptimizer.get_config(self)
keras.optimizers.optimizer_experimental._BaseOptimizer(self,name,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,**kwargs)
keras.optimizers.optimizer_experimental._BaseOptimizer._build_index_dict(self,var_list)
keras.optimizers.optimizer_experimental._BaseOptimizer._build_learning_rate(self,learning_rate)
keras.optimizers.optimizer_experimental._BaseOptimizer._clip_gradients(self,grads)
keras.optimizers.optimizer_experimental._BaseOptimizer._create_iteration_variable(self)
keras.optimizers.optimizer_experimental._BaseOptimizer._internal_apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental._BaseOptimizer._overwrite_model_variables_with_average_value(self,var_list)
keras.optimizers.optimizer_experimental._BaseOptimizer._overwrite_model_variables_with_average_value_helper(self,var_list)
keras.optimizers.optimizer_experimental._BaseOptimizer._process_kwargs(self,kwargs)
keras.optimizers.optimizer_experimental._BaseOptimizer._serialize_hyperparameter(self,hyperparameter)
keras.optimizers.optimizer_experimental._BaseOptimizer._update_model_variables_moving_average(self,var_list)
keras.optimizers.optimizer_experimental._BaseOptimizer._update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental._BaseOptimizer._update_step_xla(self,gradient,variable,key)
keras.optimizers.optimizer_experimental._BaseOptimizer._var_key(self,variable)
keras.optimizers.optimizer_experimental._BaseOptimizer.add_variable(self,shape,dtype=None,initializer='zeros',name=None)
keras.optimizers.optimizer_experimental._BaseOptimizer.add_variable_from_reference(self,model_variable,variable_name,shape=None,initial_value=None)
keras.optimizers.optimizer_experimental._BaseOptimizer.apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental._BaseOptimizer.build(self,var_list)
keras.optimizers.optimizer_experimental._BaseOptimizer.compute_gradients(self,loss,var_list,tape=None)
keras.optimizers.optimizer_experimental._BaseOptimizer.finalize_variable_values(self,var_list)
keras.optimizers.optimizer_experimental._BaseOptimizer.from_config(cls,config)
keras.optimizers.optimizer_experimental._BaseOptimizer.get_config(self)
keras.optimizers.optimizer_experimental._BaseOptimizer.iterations(self)
keras.optimizers.optimizer_experimental._BaseOptimizer.iterations(self,variable)
keras.optimizers.optimizer_experimental._BaseOptimizer.learning_rate(self)
keras.optimizers.optimizer_experimental._BaseOptimizer.learning_rate(self,learning_rate)
keras.optimizers.optimizer_experimental._BaseOptimizer.lr(self)
keras.optimizers.optimizer_experimental._BaseOptimizer.lr(self,learning_rate)
keras.optimizers.optimizer_experimental._BaseOptimizer.minimize(self,loss,var_list,tape=None)
keras.optimizers.optimizer_experimental._BaseOptimizer.update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.optimizer.Optimizer(self,name,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,**kwargs)
keras.optimizers.optimizer_experimental.optimizer.Optimizer.__init__(self,name,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,**kwargs)
keras.optimizers.optimizer_experimental.optimizer.Optimizer._distributed_apply_gradients_fn(self,distribution,grads_and_vars,**kwargs)
keras.optimizers.optimizer_experimental.optimizer.Optimizer._internal_apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental.optimizer.Optimizer._overwrite_model_variables_with_average_value_helper(self,var_list)
keras.optimizers.optimizer_experimental.optimizer.Optimizer._update_model_variables_moving_average(self,var_list)
keras.optimizers.optimizer_experimental.optimizer.Optimizer._var_key(self,variable)
keras.optimizers.optimizer_experimental.optimizer.Optimizer.add_variable_from_reference(self,model_variable,variable_name,shape=None,initial_value=None)
keras.optimizers.optimizer_experimental.optimizer.Optimizer.aggregate_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental.optimizer.Optimizer.apply_gradients(self,grads_and_vars,skip_gradients_aggregation=False)
keras.optimizers.optimizer_experimental.optimizer.RestoredOptimizer(self)
keras.optimizers.optimizer_experimental.optimizer.RestoredOptimizer.__init__(self)
keras.optimizers.optimizer_experimental.optimizer.RestoredOptimizer.get_config(self)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer(self,name,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,**kwargs)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.__init__(self,name,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,**kwargs)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._build_index_dict(self,var_list)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._build_learning_rate(self,learning_rate)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._clip_gradients(self,grads)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._create_iteration_variable(self)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._internal_apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._overwrite_model_variables_with_average_value(self,var_list)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._overwrite_model_variables_with_average_value_helper(self,var_list)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._process_kwargs(self,kwargs)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._serialize_hyperparameter(self,hyperparameter)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._update_model_variables_moving_average(self,var_list)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._update_step_xla(self,gradient,variable,key)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer._var_key(self,variable)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.add_variable(self,shape,dtype=None,initializer='zeros',name=None)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.add_variable_from_reference(self,model_variable,variable_name,shape=None,initial_value=None)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.apply_gradients(self,grads_and_vars)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.build(self,var_list)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.compute_gradients(self,loss,var_list,tape=None)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.finalize_variable_values(self,var_list)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.from_config(cls,config)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.get_config(self)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.iterations(self)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.iterations(self,variable)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.learning_rate(self)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.learning_rate(self,learning_rate)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.lr(self)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.lr(self,learning_rate)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.minimize(self,loss,var_list,tape=None)
keras.optimizers.optimizer_experimental.optimizer._BaseOptimizer.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/ftrl.py----------------------------------------
A:keras.optimizers.optimizer_experimental.ftrl.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.ftrl.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.ftrl.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.ftrl.linear_clipped->tensorflow.compat.v2.clip_by_value(linear, -self.l1_regularization_strength, self.l1_regularization_strength)
A:keras.optimizers.optimizer_experimental.ftrl.config->super().get_config()
A:keras.optimizers.optimizer_experimental.ftrl.Ftrl.__doc__->Ftrl.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.ftrl_experimental.Ftrl(self,learning_rate=0.001,learning_rate_power=-0.5,initial_accumulator_value=0.1,l1_regularization_strength=0.0,l2_regularization_strength=0.0,l2_shrinkage_regularization_strength=0.0,beta=0.0,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Ftrl',**kwargs)
keras.optimizers.ftrl_experimental.Ftrl.build(self,var_list)
keras.optimizers.ftrl_experimental.Ftrl.get_config(self)
keras.optimizers.ftrl_experimental.Ftrl.update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.ftrl.Ftrl(self,learning_rate=0.001,learning_rate_power=-0.5,initial_accumulator_value=0.1,l1_regularization_strength=0.0,l2_regularization_strength=0.0,l2_shrinkage_regularization_strength=0.0,beta=0.0,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Ftrl',**kwargs)
keras.optimizers.optimizer_experimental.ftrl.Ftrl.__init__(self,learning_rate=0.001,learning_rate_power=-0.5,initial_accumulator_value=0.1,l1_regularization_strength=0.0,l2_regularization_strength=0.0,l2_shrinkage_regularization_strength=0.0,beta=0.0,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Ftrl',**kwargs)
keras.optimizers.optimizer_experimental.ftrl.Ftrl.build(self,var_list)
keras.optimizers.optimizer_experimental.ftrl.Ftrl.get_config(self)
keras.optimizers.optimizer_experimental.ftrl.Ftrl.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/adagrad.py----------------------------------------
A:keras.optimizers.optimizer_experimental.adagrad.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.adagrad.initializer->keras.initializers.Constant(self.initial_accumulator_value)
A:keras.optimizers.optimizer_experimental.adagrad.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.adagrad.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.adagrad.config->super(Adagrad, self).get_config()
A:keras.optimizers.optimizer_experimental.adagrad.Adagrad.__doc__->Adagrad.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.adagrad_experimental.Adagrad(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adagrad',**kwargs)
keras.optimizers.adagrad_experimental.Adagrad.build(self,var_list)
keras.optimizers.adagrad_experimental.Adagrad.get_config(self)
keras.optimizers.adagrad_experimental.Adagrad.update_step(self,grad,variable)
keras.optimizers.optimizer_experimental.adagrad.Adagrad(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adagrad',**kwargs)
keras.optimizers.optimizer_experimental.adagrad.Adagrad.__init__(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adagrad',**kwargs)
keras.optimizers.optimizer_experimental.adagrad.Adagrad.build(self,var_list)
keras.optimizers.optimizer_experimental.adagrad.Adagrad.get_config(self)
keras.optimizers.optimizer_experimental.adagrad.Adagrad.update_step(self,grad,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/sgd.py----------------------------------------
A:keras.optimizers.optimizer_experimental.sgd.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.sgd.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.sgd.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.sgd.momentum->tensorflow.compat.v2.cast(self.momentum, variable.dtype)
A:keras.optimizers.optimizer_experimental.sgd.add_value->tensorflow.compat.v2.IndexedSlices(-gradient.values * lr, gradient.indices)
A:keras.optimizers.optimizer_experimental.sgd.config->super(SGD, self).get_config()
A:keras.optimizers.optimizer_experimental.sgd.SGD.__doc__->SGD.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.optimizer_experimental.sgd.SGD(self,learning_rate=0.01,momentum=0.0,nesterov=False,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='SGD',**kwargs)
keras.optimizers.optimizer_experimental.sgd.SGD.__init__(self,learning_rate=0.01,momentum=0.0,nesterov=False,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='SGD',**kwargs)
keras.optimizers.optimizer_experimental.sgd.SGD.build(self,var_list)
keras.optimizers.optimizer_experimental.sgd.SGD.get_config(self)
keras.optimizers.optimizer_experimental.sgd.SGD.update_step(self,gradient,variable)
keras.optimizers.sgd_experimental.SGD(self,learning_rate=0.01,momentum=0.0,nesterov=False,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='SGD',**kwargs)
keras.optimizers.sgd_experimental.SGD.build(self,var_list)
keras.optimizers.sgd_experimental.SGD.get_config(self)
keras.optimizers.sgd_experimental.SGD.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/adamax.py----------------------------------------
A:keras.optimizers.optimizer_experimental.adamax.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.adamax.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.adamax.local_step->tensorflow.compat.v2.cast(self.iterations + 1, variable.dtype)
A:keras.optimizers.optimizer_experimental.adamax.beta_1_power->tensorflow.compat.v2.pow(tf.cast(self.beta_1, variable.dtype), local_step)
A:keras.optimizers.optimizer_experimental.adamax.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.adamax.u_slice->tensorflow.compat.v2.gather(u, indices)
A:keras.optimizers.optimizer_experimental.adamax.config->super(Adamax, self).get_config()
A:keras.optimizers.optimizer_experimental.adamax.Adamax.__doc__->Adamax.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.adamax_experimental.Adamax(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adamax',**kwargs)
keras.optimizers.adamax_experimental.Adamax.build(self,var_list)
keras.optimizers.adamax_experimental.Adamax.get_config(self)
keras.optimizers.adamax_experimental.Adamax.update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.adamax.Adamax(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adamax',**kwargs)
keras.optimizers.optimizer_experimental.adamax.Adamax.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adamax',**kwargs)
keras.optimizers.optimizer_experimental.adamax.Adamax.build(self,var_list)
keras.optimizers.optimizer_experimental.adamax.Adamax.get_config(self)
keras.optimizers.optimizer_experimental.adamax.Adamax.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/adamw.py----------------------------------------
A:keras.optimizers.optimizer_experimental.adamw.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.adamw.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.adamw.local_step->tensorflow.compat.v2.cast(self.iterations + 1, variable.dtype)
A:keras.optimizers.optimizer_experimental.adamw.beta_1_power->tensorflow.compat.v2.pow(tf.cast(self.beta_1, variable.dtype), local_step)
A:keras.optimizers.optimizer_experimental.adamw.beta_2_power->tensorflow.compat.v2.pow(tf.cast(self.beta_2, variable.dtype), local_step)
A:keras.optimizers.optimizer_experimental.adamw.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.adamw.wd->tensorflow.compat.v2.cast(self.weight_decay, variable.dtype)
A:keras.optimizers.optimizer_experimental.adamw.config->super(AdamW, self).get_config()
A:keras.optimizers.optimizer_experimental.adamw.AdamW.__doc__->AdamW.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.adamw_experimental.AdamW(self,learning_rate=0.001,weight_decay=0.004,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='AdamW',**kwargs)
keras.optimizers.adamw_experimental.AdamW.build(self,var_list)
keras.optimizers.adamw_experimental.AdamW.get_config(self)
keras.optimizers.adamw_experimental.AdamW.update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.adamw.AdamW(self,learning_rate=0.001,weight_decay=0.004,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='AdamW',**kwargs)
keras.optimizers.optimizer_experimental.adamw.AdamW.__init__(self,learning_rate=0.001,weight_decay=0.004,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='AdamW',**kwargs)
keras.optimizers.optimizer_experimental.adamw.AdamW.build(self,var_list)
keras.optimizers.optimizer_experimental.adamw.AdamW.get_config(self)
keras.optimizers.optimizer_experimental.adamw.AdamW.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/rmsprop.py----------------------------------------
A:keras.optimizers.optimizer_experimental.rmsprop.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.rmsprop.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.rmsprop.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.rmsprop.velocity_value->tensorflow.compat.v2.gather(velocity, gradient.indices)
A:keras.optimizers.optimizer_experimental.rmsprop.transformed_grad->tensorflow.compat.v2.IndexedSlices(gradient.values / (tf.sqrt(velocity_value) + self.epsilon), gradient.indices)
A:keras.optimizers.optimizer_experimental.rmsprop.config->super(RMSprop, self).get_config()
A:keras.optimizers.optimizer_experimental.rmsprop.RMSprop.__doc__->RMSprop.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.optimizer_experimental.rmsprop.RMSprop(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=100,jit_compile=True,name='RMSprop',**kwargs)
keras.optimizers.optimizer_experimental.rmsprop.RMSprop.__init__(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=100,jit_compile=True,name='RMSprop',**kwargs)
keras.optimizers.optimizer_experimental.rmsprop.RMSprop.build(self,var_list)
keras.optimizers.optimizer_experimental.rmsprop.RMSprop.get_config(self)
keras.optimizers.optimizer_experimental.rmsprop.RMSprop.update_step(self,gradient,variable)
keras.optimizers.rmsprop_experimental.RMSprop(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=100,jit_compile=True,name='RMSprop',**kwargs)
keras.optimizers.rmsprop_experimental.RMSprop.build(self,var_list)
keras.optimizers.rmsprop_experimental.RMSprop.get_config(self)
keras.optimizers.rmsprop_experimental.RMSprop.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/adadelta.py----------------------------------------
A:keras.optimizers.optimizer_experimental.adadelta.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.adadelta.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.adadelta.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.adadelta.config->super(Adadelta, self).get_config()
A:keras.optimizers.optimizer_experimental.adadelta.Adadelta.__doc__->Adadelta.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.adadelta_experimental.Adadelta(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adadelta',**kwargs)
keras.optimizers.adadelta_experimental.Adadelta.build(self,var_list)
keras.optimizers.adadelta_experimental.Adadelta.get_config(self)
keras.optimizers.adadelta_experimental.Adadelta.update_step(self,grad,variable)
keras.optimizers.optimizer_experimental.adadelta.Adadelta(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adadelta',**kwargs)
keras.optimizers.optimizer_experimental.adadelta.Adadelta.__init__(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adadelta',**kwargs)
keras.optimizers.optimizer_experimental.adadelta.Adadelta.build(self,var_list)
keras.optimizers.optimizer_experimental.adadelta.Adadelta.get_config(self)
keras.optimizers.optimizer_experimental.adadelta.Adadelta.update_step(self,grad,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/adam.py----------------------------------------
A:keras.optimizers.optimizer_experimental.adam.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.adam.lr->tensorflow.compat.v2.cast(self.learning_rate, variable.dtype)
A:keras.optimizers.optimizer_experimental.adam.local_step->tensorflow.compat.v2.cast(self.iterations + 1, variable.dtype)
A:keras.optimizers.optimizer_experimental.adam.beta_1_power->tensorflow.compat.v2.pow(tf.cast(self.beta_1, variable.dtype), local_step)
A:keras.optimizers.optimizer_experimental.adam.beta_2_power->tensorflow.compat.v2.pow(tf.cast(self.beta_2, variable.dtype), local_step)
A:keras.optimizers.optimizer_experimental.adam.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.adam.config->super(Adam, self).get_config()
A:keras.optimizers.optimizer_experimental.adam.Adam.__doc__->Adam.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.adam_experimental.Adam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adam',**kwargs)
keras.optimizers.adam_experimental.Adam.build(self,var_list)
keras.optimizers.adam_experimental.Adam.get_config(self)
keras.optimizers.adam_experimental.Adam.update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.adam.Adam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adam',**kwargs)
keras.optimizers.optimizer_experimental.adam.Adam.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Adam',**kwargs)
keras.optimizers.optimizer_experimental.adam.Adam.build(self,var_list)
keras.optimizers.optimizer_experimental.adam.Adam.get_config(self)
keras.optimizers.optimizer_experimental.adam.Adam.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_experimental/nadam.py----------------------------------------
A:keras.optimizers.optimizer_experimental.nadam.self._learning_rate->self._build_learning_rate(learning_rate)
A:keras.optimizers.optimizer_experimental.nadam.self._u_product->tensorflow.compat.v2.Variable(1.0, dtype=var_list[0].dtype)
A:keras.optimizers.optimizer_experimental.nadam.lr->tensorflow.compat.v2.cast(self.learning_rate, var_dtype)
A:keras.optimizers.optimizer_experimental.nadam.local_step->tensorflow.compat.v2.cast(self.iterations + 1, var_dtype)
A:keras.optimizers.optimizer_experimental.nadam.next_step->tensorflow.compat.v2.cast(self.iterations + 2, var_dtype)
A:keras.optimizers.optimizer_experimental.nadam.decay->tensorflow.compat.v2.cast(0.96, var_dtype)
A:keras.optimizers.optimizer_experimental.nadam.beta_1->tensorflow.compat.v2.cast(self.beta_1, var_dtype)
A:keras.optimizers.optimizer_experimental.nadam.beta_2->tensorflow.compat.v2.cast(self.beta_2, var_dtype)
A:keras.optimizers.optimizer_experimental.nadam.u_product_t->tensorflow.compat.v2.cond(self._u_product_counter == self.iterations + 2, true_fn=get_cached_u_product, false_fn=compute_new_u_product)
A:keras.optimizers.optimizer_experimental.nadam.beta_2_power->tensorflow.compat.v2.pow(beta_2, local_step)
A:keras.optimizers.optimizer_experimental.nadam.var_key->self._var_key(variable)
A:keras.optimizers.optimizer_experimental.nadam.config->super().get_config()
A:keras.optimizers.optimizer_experimental.nadam.Nadam.__doc__->Nadam.__doc__.replace('{{base_optimizer_keyword_args}}', optimizer.base_optimizer_keyword_args)
keras.optimizers.nadam_experimental.Nadam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Nadam',**kwargs)
keras.optimizers.nadam_experimental.Nadam.build(self,var_list)
keras.optimizers.nadam_experimental.Nadam.get_config(self)
keras.optimizers.nadam_experimental.Nadam.update_step(self,gradient,variable)
keras.optimizers.optimizer_experimental.nadam.Nadam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Nadam',**kwargs)
keras.optimizers.optimizer_experimental.nadam.Nadam.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,clipnorm=None,clipvalue=None,global_clipnorm=None,use_ema=False,ema_momentum=0.99,ema_overwrite_frequency=None,jit_compile=True,name='Nadam',**kwargs)
keras.optimizers.optimizer_experimental.nadam.Nadam.build(self,var_list)
keras.optimizers.optimizer_experimental.nadam.Nadam.get_config(self)
keras.optimizers.optimizer_experimental.nadam.Nadam.update_step(self,gradient,variable)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/ftrl.py----------------------------------------
A:keras.optimizers.optimizer_v2.ftrl.init->tensorflow.compat.v2.compat.v1.constant_initializer(self._initial_accumulator_value, dtype=dtype)
A:keras.optimizers.optimizer_v2.ftrl.accum->self.get_slot(var, 'accumulator')
A:keras.optimizers.optimizer_v2.ftrl.linear->self.get_slot(var, 'linear')
A:keras.optimizers.optimizer_v2.ftrl.config->super(Ftrl, self).get_config()
keras.optimizers.ftrl.Ftrl(self,learning_rate=0.001,learning_rate_power=-0.5,initial_accumulator_value=0.1,l1_regularization_strength=0.0,l2_regularization_strength=0.0,name='Ftrl',l2_shrinkage_regularization_strength=0.0,beta=0.0,**kwargs)
keras.optimizers.ftrl.Ftrl._create_slots(self,var_list)
keras.optimizers.ftrl.Ftrl._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.ftrl.Ftrl._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.ftrl.Ftrl._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.ftrl.Ftrl.get_config(self)
keras.optimizers.optimizer_v2.ftrl.Ftrl(self,learning_rate=0.001,learning_rate_power=-0.5,initial_accumulator_value=0.1,l1_regularization_strength=0.0,l2_regularization_strength=0.0,name='Ftrl',l2_shrinkage_regularization_strength=0.0,beta=0.0,**kwargs)
keras.optimizers.optimizer_v2.ftrl.Ftrl.__init__(self,learning_rate=0.001,learning_rate_power=-0.5,initial_accumulator_value=0.1,l1_regularization_strength=0.0,l2_regularization_strength=0.0,name='Ftrl',l2_shrinkage_regularization_strength=0.0,beta=0.0,**kwargs)
keras.optimizers.optimizer_v2.ftrl.Ftrl._create_slots(self,var_list)
keras.optimizers.optimizer_v2.ftrl.Ftrl._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.ftrl.Ftrl._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.ftrl.Ftrl._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.ftrl.Ftrl.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/adagrad.py----------------------------------------
A:keras.optimizers.optimizer_v2.adagrad.epsilon->keras.backend_config.epsilon()
A:keras.optimizers.optimizer_v2.adagrad.init->tensorflow.compat.v2.compat.v1.constant_initializer(self._initial_accumulator_value, dtype=dtype)
A:keras.optimizers.optimizer_v2.adagrad.config['learning_rate']->super(Adagrad, self).get_config().pop('lr')
A:keras.optimizers.optimizer_v2.adagrad.acc->self.get_slot(var, 'accumulator')
A:keras.optimizers.optimizer_v2.adagrad.config->super(Adagrad, self).get_config()
keras.optimizers.adagrad_v2.Adagrad(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,name='Adagrad',**kwargs)
keras.optimizers.adagrad_v2.Adagrad._create_slots(self,var_list)
keras.optimizers.adagrad_v2.Adagrad._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.adagrad_v2.Adagrad._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.adagrad_v2.Adagrad._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.adagrad_v2.Adagrad.from_config(cls,config,custom_objects=None)
keras.optimizers.adagrad_v2.Adagrad.get_config(self)
keras.optimizers.adagrad_v2.Adagrad.set_weights(self,weights)
keras.optimizers.optimizer_v2.adagrad.Adagrad(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,name='Adagrad',**kwargs)
keras.optimizers.optimizer_v2.adagrad.Adagrad.__init__(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,name='Adagrad',**kwargs)
keras.optimizers.optimizer_v2.adagrad.Adagrad._create_slots(self,var_list)
keras.optimizers.optimizer_v2.adagrad.Adagrad._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.adagrad.Adagrad._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.adagrad.Adagrad._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.adagrad.Adagrad.from_config(cls,config,custom_objects=None)
keras.optimizers.optimizer_v2.adagrad.Adagrad.get_config(self)
keras.optimizers.optimizer_v2.adagrad.Adagrad.set_weights(self,weights)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/utils.py----------------------------------------
A:keras.optimizers.optimizer_v2.utils.grads_and_vars->tuple(grads_and_vars)
A:keras.optimizers.optimizer_v2.utils.filtered_grads_and_vars->filter_empty_gradients(grads_and_vars)
A:keras.optimizers.optimizer_v2.utils.reduced->tensorflow.compat.v2.distribute.get_replica_context().merge_call(_all_reduce_sum_fn, args=(filtered_grads_and_vars,))
A:keras.optimizers.optimizer_v2.utils.filtered->tuple(filtered)
A:keras.optimizers.optimizer_v2.utils.(grads, variables)->zip(*grads_and_vars)
A:keras.optimizers.optimizer_v2.utils.(clipped_grads, _)->tensorflow.compat.v2.clip_by_global_norm(grads, clipnorm)
A:keras.optimizers.optimizer_v2.utils.clipped_grads_and_vars->list(zip(clipped_grads, variables))
keras.optimizers.optimizer_v2.utils._all_reduce_sum_fn(distribution,grads_and_vars)
keras.optimizers.optimizer_v2.utils.all_reduce_sum_gradients(grads_and_vars)
keras.optimizers.optimizer_v2.utils.filter_empty_gradients(grads_and_vars)
keras.optimizers.optimizer_v2.utils.make_global_gradient_clipnorm_fn(clipnorm)
keras.optimizers.optimizer_v2.utils.make_gradient_clipnorm_fn(clipnorm)
keras.optimizers.optimizer_v2.utils.make_gradient_clipvalue_fn(clipvalue)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/optimizer_v2.py----------------------------------------
A:keras.optimizers.optimizer_v2.optimizer_v2.keras_optimizers_gauge->tensorflow.compat.v2.__internal__.monitoring.BoolGauge('/tensorflow/api/keras/optimizers', 'keras optimizer usage', 'method')
A:keras.optimizers.optimizer_v2.optimizer_v2._DEFAULT_VALID_DTYPES->frozenset([tf.float16, tf.bfloat16, tf.float32, tf.float64, tf.complex64, tf.complex128])
A:keras.optimizers.optimizer_v2.optimizer_v2.(unique_indices, new_index_positions)->tensorflow.compat.v2.unique(indices)
A:keras.optimizers.optimizer_v2.optimizer_v2.summed_values->tensorflow.compat.v2.math.unsorted_segment_sum(values, new_index_positions, tf.shape(unique_indices)[0])
A:keras.optimizers.optimizer_v2.optimizer_v2.decay->kwargs.pop('decay', 0.0)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._distribution_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.optimizers.optimizer_v2.optimizer_v2.self.clipnorm->kwargs.pop('clipnorm', None)
A:keras.optimizers.optimizer_v2.optimizer_v2.self.global_clipnorm->kwargs.pop('global_clipnorm', None)
A:keras.optimizers.optimizer_v2.optimizer_v2.self.clipvalue->kwargs.pop('clipvalue', None)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._clipnorm_fn->keras.optimizers.optimizer_v2.utils.make_gradient_clipnorm_fn(self._clipnorm)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._global_clipnorm_fn->keras.optimizers.optimizer_v2.utils.make_global_gradient_clipnorm_fn(self._global_clipnorm)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._clipvalue_fn->keras.optimizers.optimizer_v2.utils.make_gradient_clipvalue_fn(self._clipvalue)
A:keras.optimizers.optimizer_v2.optimizer_v2.grads->self.get_gradients(loss, params)
A:keras.optimizers.optimizer_v2.optimizer_v2.grads_and_vars->list(zip(grads, params))
A:keras.optimizers.optimizer_v2.optimizer_v2.loss->self._transform_loss(loss)
A:keras.optimizers.optimizer_v2.optimizer_v2.var_list->tensorflow.compat.v2.nest.flatten(var_list)
A:keras.optimizers.optimizer_v2.optimizer_v2.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.optimizers.optimizer_v2.optimizer_v2.apply_state->self._prepare(var_list)
A:keras.optimizers.optimizer_v2.optimizer_v2.update_op->distribution.extended.update(var, apply_grad_to_update_var, args=(grad,), group=False)
A:keras.optimizers.optimizer_v2.optimizer_v2.eagerly_outside_functions->tensorflow.compat.v2.compat.v1.executing_eagerly_outside_functions()
A:keras.optimizers.optimizer_v2.optimizer_v2.any_symbolic->any((isinstance(i, tf.Operation) or tf_utils.is_symbolic_tensor(i) for i in update_ops))
A:keras.optimizers.optimizer_v2.optimizer_v2.params->tensorflow.compat.v2.nest.flatten(params)
A:keras.optimizers.optimizer_v2.optimizer_v2.value->value()
A:keras.optimizers.optimizer_v2.optimizer_v2.sharded_vars->set()
A:keras.optimizers.optimizer_v2.optimizer_v2.sharded_key->_var_key(sharded_var)
A:keras.optimizers.optimizer_v2.optimizer_v2.result->set(super(OptimizerV2, self).__dir__())
A:keras.optimizers.optimizer_v2.optimizer_v2.var_key->_var_key(var)
A:keras.optimizers.optimizer_v2.optimizer_v2.slot_dict->self._slots.get(variable_key, {})
A:keras.optimizers.optimizer_v2.optimizer_v2.weight->tensorflow.compat.v2.Variable(name='%s/%s' % (var._shared_name, slot_name), dtype=var.dtype, trainable=False, initial_value=initial_value)
A:keras.optimizers.optimizer_v2.optimizer_v2.initializer->tensorflow.compat.v2.__internal__.tracking.CheckpointInitialValueCallable(checkpoint_position=slot_variable_position)
A:keras.optimizers.optimizer_v2.optimizer_v2.initial_value->functools.partial(initializer, shape=slot_shape, dtype=var.dtype)
A:keras.optimizers.optimizer_v2.optimizer_v2.slot_shard->self.get_slot(shard, slot_name)
A:keras.optimizers.optimizer_v2.optimizer_v2.slot_variable->self.add_slot(var=variable, initializer=initializer, slot_name=slot_name, shape=slot_variable_position.value_shape())
A:keras.optimizers.optimizer_v2.optimizer_v2.keys->set()
A:keras.optimizers.optimizer_v2.optimizer_v2.lr_t->tensorflow.compat.v2.cast(lr_t(local_step), var_dtype)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._hyper[name]->self.add_weight(name, shape=[], trainable=False, initializer=value, aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._iterations->self.add_weight('iter', shape=[], dtype=tf.int64, trainable=False, aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
A:keras.optimizers.optimizer_v2.optimizer_v2.local_step->tensorflow.compat.v2.cast(self.iterations, var_dtype)
A:keras.optimizers.optimizer_v2.optimizer_v2.decay_t->tensorflow.compat.v2.cast(self._initial_decay, var_dtype)
A:keras.optimizers.optimizer_v2.optimizer_v2.config['learning_rate']->keras.optimizers.schedules.learning_rate_schedule.deserialize(config['learning_rate'], custom_objects=custom_objects)
A:keras.optimizers.optimizer_v2.optimizer_v2.param_values->keras.backend.batch_get_value(params)
A:keras.optimizers.optimizer_v2.optimizer_v2.variable->self._add_variable_with_custom_getter(name=name, shape=shape, getter=base_layer_utils.make_variable, overwrite=True, initializer=initializer, dtype=dtype, trainable=trainable, use_resource=True, synchronization=synchronization, aggregation=aggregation)
A:keras.optimizers.optimizer_v2.optimizer_v2.self._name->keras.backend.unique_object_name(generic_utils.to_snake_case(self.__class__.__name__), zero_based=zero_based)
A:keras.optimizers.optimizer_v2.optimizer_v2.valid_dtypes->self._valid_dtypes()
A:keras.optimizers.optimizer_v2.optimizer_v2.(summed_grad, unique_indices)->_deduplicate_indexed_slices(values=grad, indices=indices)
A:keras.optimizers.optimizer_v2.optimizer_v2.variable_key->_var_key(variable)
A:keras.optimizers.optimizer_v2.optimizer_v2.deferred_restorations->self._deferred_slot_restorations.get(slot_name, {}).pop(variable_key, [])
A:keras.optimizers.optimizer_v2.optimizer_v2.var->var._distributed_container()._distributed_container()
A:keras.optimizers.optimizer_v2.optimizer_v2.name->_var_key(var)
keras.optimizers.base_optimizer_v2.NullContextmanager(self,*args,**kwargs)
keras.optimizers.base_optimizer_v2.NullContextmanager.__enter__(self)
keras.optimizers.base_optimizer_v2.NullContextmanager.__exit__(self,type_arg,value_arg,traceback_arg)
keras.optimizers.base_optimizer_v2.OptimizerV2(self,name,gradient_aggregator=None,gradient_transformers=None,**kwargs)
keras.optimizers.base_optimizer_v2.OptimizerV2.__dir__(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.__getattribute__(self,name)
keras.optimizers.base_optimizer_v2.OptimizerV2.__setattr__(self,name,value)
keras.optimizers.base_optimizer_v2.OptimizerV2._aggregate_gradients(self,grads_and_vars)
keras.optimizers.base_optimizer_v2.OptimizerV2._assert_valid_dtypes(self,tensors)
keras.optimizers.base_optimizer_v2.OptimizerV2._call_if_callable(self,param)
keras.optimizers.base_optimizer_v2.OptimizerV2._compute_gradients(self,loss,var_list,grad_loss=None,tape=None)
keras.optimizers.base_optimizer_v2.OptimizerV2._create_all_weights(self,var_list)
keras.optimizers.base_optimizer_v2.OptimizerV2._create_hypers(self)
keras.optimizers.base_optimizer_v2.OptimizerV2._create_or_restore_slot_variable(self,slot_variable_position,slot_name,variable)
keras.optimizers.base_optimizer_v2.OptimizerV2._create_slots(self,var_list)
keras.optimizers.base_optimizer_v2.OptimizerV2._create_slots_for_sharded_variables(self,var_list)
keras.optimizers.base_optimizer_v2.OptimizerV2._decayed_lr(self,var_dtype)
keras.optimizers.base_optimizer_v2.OptimizerV2._dense_apply_args(self)
keras.optimizers.base_optimizer_v2.OptimizerV2._distributed_apply(self,distribution,grads_and_vars,apply_state,name)
keras.optimizers.base_optimizer_v2.OptimizerV2._distribution_strategy_scope(self)
keras.optimizers.base_optimizer_v2.OptimizerV2._fallback_apply_state(self,var_device,var_dtype)
keras.optimizers.base_optimizer_v2.OptimizerV2._get_gradients(self,tape,loss,var_list,grad_loss=None)
keras.optimizers.base_optimizer_v2.OptimizerV2._get_hyper(self,name,dtype=None)
keras.optimizers.base_optimizer_v2.OptimizerV2._init_set_name(self,name,zero_based=True)
keras.optimizers.base_optimizer_v2.OptimizerV2._prepare(self,var_list)
keras.optimizers.base_optimizer_v2.OptimizerV2._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.base_optimizer_v2.OptimizerV2._resource_apply_dense(self,grad,handle,apply_state)
keras.optimizers.base_optimizer_v2.OptimizerV2._resource_apply_sparse(self,grad,handle,indices,apply_state)
keras.optimizers.base_optimizer_v2.OptimizerV2._resource_apply_sparse_duplicate_indices(self,grad,handle,indices,**kwargs)
keras.optimizers.base_optimizer_v2.OptimizerV2._resource_scatter_add(self,x,i,v)
keras.optimizers.base_optimizer_v2.OptimizerV2._resource_scatter_update(self,x,i,v)
keras.optimizers.base_optimizer_v2.OptimizerV2._restore_slot_variable(self,slot_name,variable,slot_variable)
keras.optimizers.base_optimizer_v2.OptimizerV2._serialize_hyperparameter(self,hyperparameter_name)
keras.optimizers.base_optimizer_v2.OptimizerV2._set_hyper(self,name,value)
keras.optimizers.base_optimizer_v2.OptimizerV2._sparse_apply_args(self)
keras.optimizers.base_optimizer_v2.OptimizerV2._transform_gradients(self,grads_and_vars)
keras.optimizers.base_optimizer_v2.OptimizerV2._transform_loss(self,loss)
keras.optimizers.base_optimizer_v2.OptimizerV2._transform_unaggregated_gradients(self,grads_and_vars)
keras.optimizers.base_optimizer_v2.OptimizerV2._valid_dtypes(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.add_slot(self,var,slot_name,initializer='zeros',shape=None)
keras.optimizers.base_optimizer_v2.OptimizerV2.add_weight(self,name,shape,dtype=None,initializer='zeros',trainable=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.VariableAggregation.NONE)
keras.optimizers.base_optimizer_v2.OptimizerV2.apply_gradients(self,grads_and_vars,name=None,experimental_aggregate_gradients=True)
keras.optimizers.base_optimizer_v2.OptimizerV2.clipnorm(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.clipnorm(self,val)
keras.optimizers.base_optimizer_v2.OptimizerV2.clipvalue(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.clipvalue(self,val)
keras.optimizers.base_optimizer_v2.OptimizerV2.from_config(cls,config,custom_objects=None)
keras.optimizers.base_optimizer_v2.OptimizerV2.get_config(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.get_gradients(self,loss,params)
keras.optimizers.base_optimizer_v2.OptimizerV2.get_slot(self,var,slot_name)
keras.optimizers.base_optimizer_v2.OptimizerV2.get_slot_names(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.get_updates(self,loss,params)
keras.optimizers.base_optimizer_v2.OptimizerV2.get_weights(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.global_clipnorm(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.global_clipnorm(self,val)
keras.optimizers.base_optimizer_v2.OptimizerV2.iterations(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.iterations(self,variable)
keras.optimizers.base_optimizer_v2.OptimizerV2.minimize(self,loss,var_list,grad_loss=None,name=None,tape=None)
keras.optimizers.base_optimizer_v2.OptimizerV2.set_weights(self,weights)
keras.optimizers.base_optimizer_v2.OptimizerV2.variables(self)
keras.optimizers.base_optimizer_v2.OptimizerV2.weights(self)
keras.optimizers.base_optimizer_v2.RestoredOptimizer(self)
keras.optimizers.base_optimizer_v2.RestoredOptimizer.get_config(self)
keras.optimizers.base_optimizer_v2._deduplicate_indexed_slices(values,indices)
keras.optimizers.base_optimizer_v2._get_slot_key_from_var(var,slot_name)
keras.optimizers.base_optimizer_v2._var_key(var)
keras.optimizers.base_optimizer_v2.name_scope_only_in_function_or_graph(name)
keras.optimizers.optimizer_v2.optimizer_v2.NullContextmanager(self,*args,**kwargs)
keras.optimizers.optimizer_v2.optimizer_v2.NullContextmanager.__enter__(self)
keras.optimizers.optimizer_v2.optimizer_v2.NullContextmanager.__exit__(self,type_arg,value_arg,traceback_arg)
keras.optimizers.optimizer_v2.optimizer_v2.NullContextmanager.__init__(self,*args,**kwargs)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2(self,name,gradient_aggregator=None,gradient_transformers=None,**kwargs)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.__dir__(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.__getattribute__(self,name)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.__init__(self,name,gradient_aggregator=None,gradient_transformers=None,**kwargs)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.__setattr__(self,name,value)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._aggregate_gradients(self,grads_and_vars)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._assert_valid_dtypes(self,tensors)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._call_if_callable(self,param)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._compute_gradients(self,loss,var_list,grad_loss=None,tape=None)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._create_all_weights(self,var_list)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._create_hypers(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._create_or_restore_slot_variable(self,slot_variable_position,slot_name,variable)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._create_slots(self,var_list)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._create_slots_for_sharded_variables(self,var_list)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._decayed_lr(self,var_dtype)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._dense_apply_args(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._distributed_apply(self,distribution,grads_and_vars,apply_state,name)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._distribution_strategy_scope(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._fallback_apply_state(self,var_device,var_dtype)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._get_gradients(self,tape,loss,var_list,grad_loss=None)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._get_hyper(self,name,dtype=None)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._init_set_name(self,name,zero_based=True)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._prepare(self,var_list)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._resource_apply_dense(self,grad,handle,apply_state)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._resource_apply_sparse(self,grad,handle,indices,apply_state)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._resource_apply_sparse_duplicate_indices(self,grad,handle,indices,**kwargs)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._resource_scatter_add(self,x,i,v)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._resource_scatter_update(self,x,i,v)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._restore_slot_variable(self,slot_name,variable,slot_variable)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._serialize_hyperparameter(self,hyperparameter_name)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._set_hyper(self,name,value)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._sparse_apply_args(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._transform_gradients(self,grads_and_vars)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._transform_loss(self,loss)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._transform_unaggregated_gradients(self,grads_and_vars)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2._valid_dtypes(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.add_slot(self,var,slot_name,initializer='zeros',shape=None)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.add_weight(self,name,shape,dtype=None,initializer='zeros',trainable=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.VariableAggregation.NONE)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.apply_gradients(self,grads_and_vars,name=None,experimental_aggregate_gradients=True)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.clipnorm(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.clipnorm(self,val)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.clipvalue(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.clipvalue(self,val)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.from_config(cls,config,custom_objects=None)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.get_config(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.get_gradients(self,loss,params)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.get_slot(self,var,slot_name)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.get_slot_names(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.get_updates(self,loss,params)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.get_weights(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.global_clipnorm(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.global_clipnorm(self,val)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.iterations(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.iterations(self,variable)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.minimize(self,loss,var_list,grad_loss=None,name=None,tape=None)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.set_weights(self,weights)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.variables(self)
keras.optimizers.optimizer_v2.optimizer_v2.OptimizerV2.weights(self)
keras.optimizers.optimizer_v2.optimizer_v2.RestoredOptimizer(self)
keras.optimizers.optimizer_v2.optimizer_v2.RestoredOptimizer.__init__(self)
keras.optimizers.optimizer_v2.optimizer_v2.RestoredOptimizer.get_config(self)
keras.optimizers.optimizer_v2.optimizer_v2._deduplicate_indexed_slices(values,indices)
keras.optimizers.optimizer_v2.optimizer_v2._get_slot_key_from_var(var,slot_name)
keras.optimizers.optimizer_v2.optimizer_v2._var_key(var)
keras.optimizers.optimizer_v2.optimizer_v2.name_scope_only_in_function_or_graph(name)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/gradient_descent.py----------------------------------------
A:keras.optimizers.optimizer_v2.gradient_descent.apply_state[var_device, var_dtype]['momentum']->tensorflow.compat.v2.identity(self._get_hyper('momentum', var_dtype))
A:keras.optimizers.optimizer_v2.gradient_descent.momentum_var->self.get_slot(var, 'momentum')
A:keras.optimizers.optimizer_v2.gradient_descent.config->super(SGD, self).get_config()
keras.optimizers.gradient_descent_v2.SGD(self,learning_rate=0.01,momentum=0.0,nesterov=False,name='SGD',**kwargs)
keras.optimizers.gradient_descent_v2.SGD._create_slots(self,var_list)
keras.optimizers.gradient_descent_v2.SGD._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.gradient_descent_v2.SGD._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.gradient_descent_v2.SGD._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.gradient_descent_v2.SGD._resource_apply_sparse_duplicate_indices(self,grad,var,indices,**kwargs)
keras.optimizers.gradient_descent_v2.SGD.get_config(self)
keras.optimizers.optimizer_v2.gradient_descent.SGD(self,learning_rate=0.01,momentum=0.0,nesterov=False,name='SGD',**kwargs)
keras.optimizers.optimizer_v2.gradient_descent.SGD.__init__(self,learning_rate=0.01,momentum=0.0,nesterov=False,name='SGD',**kwargs)
keras.optimizers.optimizer_v2.gradient_descent.SGD._create_slots(self,var_list)
keras.optimizers.optimizer_v2.gradient_descent.SGD._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.gradient_descent.SGD._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.gradient_descent.SGD._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.gradient_descent.SGD._resource_apply_sparse_duplicate_indices(self,grad,var,indices,**kwargs)
keras.optimizers.optimizer_v2.gradient_descent.SGD.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/adamax.py----------------------------------------
A:keras.optimizers.optimizer_v2.adamax.local_step->tensorflow.compat.v2.cast(self.iterations + 1, var_dtype)
A:keras.optimizers.optimizer_v2.adamax.beta_1_t->tensorflow.compat.v2.identity(self._get_hyper('beta_1', var_dtype))
A:keras.optimizers.optimizer_v2.adamax.beta_2_t->tensorflow.compat.v2.identity(self._get_hyper('beta_2', var_dtype))
A:keras.optimizers.optimizer_v2.adamax.beta_1_power->tensorflow.compat.v2.pow(beta_1_t, local_step)
A:keras.optimizers.optimizer_v2.adamax.m->self.get_slot(var, 'm')
A:keras.optimizers.optimizer_v2.adamax.v->self.get_slot(var, 'v')
A:keras.optimizers.optimizer_v2.adamax.m_slice->tensorflow.compat.v2.gather(m, indices, axis=coefficients['zero'])
A:keras.optimizers.optimizer_v2.adamax.m_t->self._resource_scatter_update(m, indices, m_t_slice)
A:keras.optimizers.optimizer_v2.adamax.v_slice->tensorflow.compat.v2.gather(v, indices, axis=coefficients['zero'])
A:keras.optimizers.optimizer_v2.adamax.v_t_slice->tensorflow.compat.v2.maximum(v_slice * coefficients['beta_2_t'], tf.abs(grad))
A:keras.optimizers.optimizer_v2.adamax.v_t->self._resource_scatter_update(v, indices, v_t_slice)
A:keras.optimizers.optimizer_v2.adamax.var_update->self._resource_scatter_add(var, indices, var_slice)
A:keras.optimizers.optimizer_v2.adamax.config->super(Adamax, self).get_config()
keras.optimizers.adamax_v2.Adamax(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,name='Adamax',**kwargs)
keras.optimizers.adamax_v2.Adamax._create_slots(self,var_list)
keras.optimizers.adamax_v2.Adamax._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.adamax_v2.Adamax._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.adamax_v2.Adamax._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.adamax_v2.Adamax.get_config(self)
keras.optimizers.optimizer_v2.adamax.Adamax(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,name='Adamax',**kwargs)
keras.optimizers.optimizer_v2.adamax.Adamax.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,name='Adamax',**kwargs)
keras.optimizers.optimizer_v2.adamax.Adamax._create_slots(self,var_list)
keras.optimizers.optimizer_v2.adamax.Adamax._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.adamax.Adamax._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.adamax.Adamax._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.adamax.Adamax.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/rmsprop.py----------------------------------------
A:keras.optimizers.optimizer_v2.rmsprop.rho->tensorflow.compat.v2.identity(self._get_hyper('rho', var_dtype))
A:keras.optimizers.optimizer_v2.rmsprop.rms->self.get_slot(var, 'rms')
A:keras.optimizers.optimizer_v2.rmsprop.mom->self.get_slot(var, 'momentum')
A:keras.optimizers.optimizer_v2.rmsprop.mg->self.get_slot(var, 'mg')
A:keras.optimizers.optimizer_v2.rmsprop.rms_t->self._resource_scatter_add(rms, indices, rms_scaled_g_values)
A:keras.optimizers.optimizer_v2.rmsprop.mg_t->self._resource_scatter_add(mg, indices, mg_scaled_g_values)
A:keras.optimizers.optimizer_v2.rmsprop.rms_slice->tensorflow.compat.v2.gather(rms_t, indices)
A:keras.optimizers.optimizer_v2.rmsprop.mg_slice->tensorflow.compat.v2.gather(mg_t, indices)
A:keras.optimizers.optimizer_v2.rmsprop.var_update->self._resource_scatter_add(var, indices, coefficients['neg_lr_t'] * grad / (tf.sqrt(denom_slice) + coefficients['epsilon']))
A:keras.optimizers.optimizer_v2.rmsprop.config->super(RMSprop, self).get_config()
keras.optimizers.optimizer_v2.rmsprop.RMSprop(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,name='RMSprop',**kwargs)
keras.optimizers.optimizer_v2.rmsprop.RMSprop.__init__(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,name='RMSprop',**kwargs)
keras.optimizers.optimizer_v2.rmsprop.RMSprop._create_slots(self,var_list)
keras.optimizers.optimizer_v2.rmsprop.RMSprop._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.rmsprop.RMSprop._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.rmsprop.RMSprop._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.rmsprop.RMSprop.get_config(self)
keras.optimizers.optimizer_v2.rmsprop.RMSprop.set_weights(self,weights)
keras.optimizers.rmsprop_v2.RMSprop(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,name='RMSprop',**kwargs)
keras.optimizers.rmsprop_v2.RMSprop._create_slots(self,var_list)
keras.optimizers.rmsprop_v2.RMSprop._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.rmsprop_v2.RMSprop._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.rmsprop_v2.RMSprop._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.rmsprop_v2.RMSprop.get_config(self)
keras.optimizers.rmsprop_v2.RMSprop.set_weights(self,weights)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/adadelta.py----------------------------------------
A:keras.optimizers.optimizer_v2.adadelta.accum_grad->self.get_slot(var, 'accum_grad')
A:keras.optimizers.optimizer_v2.adadelta.accum_var->self.get_slot(var, 'accum_var')
A:keras.optimizers.optimizer_v2.adadelta.config->super(Adadelta, self).get_config()
keras.optimizers.adadelta_v2.Adadelta(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,name='Adadelta',**kwargs)
keras.optimizers.adadelta_v2.Adadelta._create_slots(self,var_list)
keras.optimizers.adadelta_v2.Adadelta._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.adadelta_v2.Adadelta._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.adadelta_v2.Adadelta._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.adadelta_v2.Adadelta.get_config(self)
keras.optimizers.adadelta_v2.Adadelta.set_weights(self,weights)
keras.optimizers.optimizer_v2.adadelta.Adadelta(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,name='Adadelta',**kwargs)
keras.optimizers.optimizer_v2.adadelta.Adadelta.__init__(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,name='Adadelta',**kwargs)
keras.optimizers.optimizer_v2.adadelta.Adadelta._create_slots(self,var_list)
keras.optimizers.optimizer_v2.adadelta.Adadelta._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.adadelta.Adadelta._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.adadelta.Adadelta._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.adadelta.Adadelta.get_config(self)
keras.optimizers.optimizer_v2.adadelta.Adadelta.set_weights(self,weights)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/adam.py----------------------------------------
A:keras.optimizers.optimizer_v2.adam.local_step->tensorflow.compat.v2.cast(self.iterations + 1, var_dtype)
A:keras.optimizers.optimizer_v2.adam.beta_1_t->tensorflow.compat.v2.identity(self._get_hyper('beta_1', var_dtype))
A:keras.optimizers.optimizer_v2.adam.beta_2_t->tensorflow.compat.v2.identity(self._get_hyper('beta_2', var_dtype))
A:keras.optimizers.optimizer_v2.adam.beta_1_power->tensorflow.compat.v2.pow(beta_1_t, local_step)
A:keras.optimizers.optimizer_v2.adam.beta_2_power->tensorflow.compat.v2.pow(beta_2_t, local_step)
A:keras.optimizers.optimizer_v2.adam.num_vars->int((len(params) - 1) / 2)
A:keras.optimizers.optimizer_v2.adam.m->self.get_slot(var, 'm')
A:keras.optimizers.optimizer_v2.adam.v->self.get_slot(var, 'v')
A:keras.optimizers.optimizer_v2.adam.vhat->self.get_slot(var, 'vhat')
A:keras.optimizers.optimizer_v2.adam.m_t->self._resource_scatter_add(m, indices, m_scaled_g_values)
A:keras.optimizers.optimizer_v2.adam.v_t->self._resource_scatter_add(v, indices, v_scaled_g_values)
A:keras.optimizers.optimizer_v2.adam.v_sqrt->tensorflow.compat.v2.sqrt(v_t)
A:keras.optimizers.optimizer_v2.adam.var_update->tensorflow.compat.v2.compat.v1.assign_sub(var, coefficients['lr'] * m_t / (v_hat_sqrt + coefficients['epsilon']), use_locking=self._use_locking)
A:keras.optimizers.optimizer_v2.adam.v_hat->self.get_slot(var, 'vhat')
A:keras.optimizers.optimizer_v2.adam.v_hat_t->tensorflow.compat.v2.compat.v1.assign(v_hat, v_hat_t, use_locking=self._use_locking)
A:keras.optimizers.optimizer_v2.adam.v_hat_sqrt->tensorflow.compat.v2.sqrt(v_hat_t)
A:keras.optimizers.optimizer_v2.adam.config->super(NonFusedAdam, self).get_config()
keras.optimizers.adam_v2.Adam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam',**kwargs)
keras.optimizers.adam_v2.Adam._create_slots(self,var_list)
keras.optimizers.adam_v2.Adam._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.adam_v2.Adam._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.adam_v2.Adam._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.adam_v2.Adam.get_config(self)
keras.optimizers.adam_v2.Adam.set_weights(self,weights)
keras.optimizers.adam_v2.NonFusedAdam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam',**kwargs)
keras.optimizers.adam_v2.NonFusedAdam._create_slots(self,var_list)
keras.optimizers.adam_v2.NonFusedAdam._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.adam_v2.NonFusedAdam._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.adam_v2.NonFusedAdam._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.adam_v2.NonFusedAdam.get_config(self)
keras.optimizers.adam_v2.NonFusedAdam.set_weights(self,weights)
keras.optimizers.optimizer_v2.adam.Adam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam',**kwargs)
keras.optimizers.optimizer_v2.adam.Adam.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam',**kwargs)
keras.optimizers.optimizer_v2.adam.Adam._create_slots(self,var_list)
keras.optimizers.optimizer_v2.adam.Adam._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.adam.Adam._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.adam.Adam._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.adam.Adam.get_config(self)
keras.optimizers.optimizer_v2.adam.Adam.set_weights(self,weights)
keras.optimizers.optimizer_v2.adam.NonFusedAdam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam',**kwargs)
keras.optimizers.optimizer_v2.adam.NonFusedAdam.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,name='Adam',**kwargs)
keras.optimizers.optimizer_v2.adam.NonFusedAdam._create_slots(self,var_list)
keras.optimizers.optimizer_v2.adam.NonFusedAdam._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.adam.NonFusedAdam._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.adam.NonFusedAdam._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.adam.NonFusedAdam.get_config(self)
keras.optimizers.optimizer_v2.adam.NonFusedAdam.set_weights(self,weights)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/optimizers/optimizer_v2/nadam.py----------------------------------------
A:keras.optimizers.optimizer_v2.nadam.kwargs['decay']->kwargs.pop('schedule_decay', 0.004)
A:keras.optimizers.optimizer_v2.nadam.learning_rate->kwargs.get('lr', learning_rate)
A:keras.optimizers.optimizer_v2.nadam.self._m_cache->self.add_weight('momentum_cache', shape=[], dtype=var_dtype, initializer='ones', trainable=False, aggregation=tf.VariableAggregation.ONLY_FIRST_REPLICA)
A:keras.optimizers.optimizer_v2.nadam.lr_t->tensorflow.compat.v2.identity(self._get_hyper('learning_rate', var_dtype))
A:keras.optimizers.optimizer_v2.nadam.beta_1_t->tensorflow.compat.v2.identity(self._get_hyper('beta_1', var_dtype))
A:keras.optimizers.optimizer_v2.nadam.beta_2_t->tensorflow.compat.v2.identity(self._get_hyper('beta_2', var_dtype))
A:keras.optimizers.optimizer_v2.nadam.local_step->tensorflow.compat.v2.cast(self.iterations + 1, var_dtype)
A:keras.optimizers.optimizer_v2.nadam.next_step->tensorflow.compat.v2.cast(self.iterations + 2, var_dtype)
A:keras.optimizers.optimizer_v2.nadam.decay_base->tensorflow.compat.v2.cast(0.96, var_dtype)
A:keras.optimizers.optimizer_v2.nadam.m_schedule_new->tensorflow.compat.v2.identity(tf.compat.v1.assign(self._m_cache, m_schedule_new, use_locking=self._use_locking))
A:keras.optimizers.optimizer_v2.nadam.apply_state[var_device, var_dtype]->dict(lr_t=lr_t, neg_lr_t=-lr_t, epsilon=tf.convert_to_tensor(self.epsilon, var_dtype), beta_1_t=beta_1_t, beta_2_t=beta_2_t, m_t=m_t, m_t_1=m_t_1, one_minus_beta_1_t=1 - beta_1_t, one_minus_beta_2_t=1 - beta_2_t, one_minus_m_t=1.0 - m_t, one_minus_m_schedule_new=1.0 - m_schedule_new, one_minus_m_schedule_next=1.0 - m_schedule_next, v_t_prime_denominator=1.0 - tf.pow(beta_2_t, local_step))
A:keras.optimizers.optimizer_v2.nadam.self._m_cache_read->tensorflow.compat.v2.identity(self._m_cache)
A:keras.optimizers.optimizer_v2.nadam.m->self.get_slot(var, 'm')
A:keras.optimizers.optimizer_v2.nadam.v->self.get_slot(var, 'v')
A:keras.optimizers.optimizer_v2.nadam.m_t->self._resource_scatter_add(m, indices, m_scaled_g_values)
A:keras.optimizers.optimizer_v2.nadam.v_t->self._resource_scatter_add(v, indices, v_scaled_g_values)
A:keras.optimizers.optimizer_v2.nadam.m_t_slice->tensorflow.compat.v2.gather(m_t, indices)
A:keras.optimizers.optimizer_v2.nadam.v_t_slice->tensorflow.compat.v2.gather(v_t, indices)
A:keras.optimizers.optimizer_v2.nadam.var_update->self._resource_scatter_add(var, indices, coefficients['neg_lr_t'] * m_t_bar / v_prime_sqrt_plus_eps)
A:keras.optimizers.optimizer_v2.nadam.config->super(Nadam, self).get_config()
keras.optimizers.nadam_v2.Nadam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,name='Nadam',**kwargs)
keras.optimizers.nadam_v2.Nadam._create_slots(self,var_list)
keras.optimizers.nadam_v2.Nadam._prepare(self,var_list)
keras.optimizers.nadam_v2.Nadam._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.nadam_v2.Nadam._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.nadam_v2.Nadam._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.nadam_v2.Nadam.get_config(self)
keras.optimizers.optimizer_v2.nadam.Nadam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,name='Nadam',**kwargs)
keras.optimizers.optimizer_v2.nadam.Nadam.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,name='Nadam',**kwargs)
keras.optimizers.optimizer_v2.nadam.Nadam._create_slots(self,var_list)
keras.optimizers.optimizer_v2.nadam.Nadam._prepare(self,var_list)
keras.optimizers.optimizer_v2.nadam.Nadam._prepare_local(self,var_device,var_dtype,apply_state)
keras.optimizers.optimizer_v2.nadam.Nadam._resource_apply_dense(self,grad,var,apply_state=None)
keras.optimizers.optimizer_v2.nadam.Nadam._resource_apply_sparse(self,grad,var,indices,apply_state=None)
keras.optimizers.optimizer_v2.nadam.Nadam.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/migration_utils.py----------------------------------------
A:keras.legacy_tf_layers.migration_utils.self._observed_seeds->set()
keras.legacy_tf_layers.migration_utils.DeterministicRandomTestTool(self,seed:int=42,mode='constant')
keras.legacy_tf_layers.migration_utils.DeterministicRandomTestTool.__init__(self,seed:int=42,mode='constant')
keras.legacy_tf_layers.migration_utils.DeterministicRandomTestTool.operation_seed(self)
keras.legacy_tf_layers.migration_utils.DeterministicRandomTestTool.operation_seed(self,value)
keras.legacy_tf_layers.migration_utils.DeterministicRandomTestTool.scope(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/core.py----------------------------------------
A:keras.legacy_tf_layers.core.layer->Flatten(name=name, data_format=data_format)
keras.legacy_tf_layers.core.Dense(self,units,activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.core.Dense.__init__(self,units,activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.core.Dropout(self,rate=0.5,noise_shape=None,seed=None,name=None,**kwargs)
keras.legacy_tf_layers.core.Dropout.__init__(self,rate=0.5,noise_shape=None,seed=None,name=None,**kwargs)
keras.legacy_tf_layers.core.Dropout.call(self,inputs,training=False)
keras.legacy_tf_layers.core.Flatten(keras_layers.Flatten,base.Layer)
keras.legacy_tf_layers.core.dense(inputs,units,activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.core.dropout(inputs,rate=0.5,noise_shape=None,seed=None,training=False,name=None)
keras.legacy_tf_layers.core.flatten(inputs,name=None,data_format='channels_last')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/pooling.py----------------------------------------
A:keras.legacy_tf_layers.pooling.layer->MaxPooling3D(pool_size=pool_size, strides=strides, padding=padding, data_format=data_format, name=name)
keras.legacy_tf_layers.pooling.AveragePooling1D(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.AveragePooling1D.__init__(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.AveragePooling2D(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.AveragePooling2D.__init__(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.AveragePooling3D(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.AveragePooling3D.__init__(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.MaxPooling1D(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.MaxPooling1D.__init__(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.MaxPooling2D(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.MaxPooling2D.__init__(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.MaxPooling3D(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.MaxPooling3D.__init__(self,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.legacy_tf_layers.pooling.average_pooling1d(inputs,pool_size,strides,padding='valid',data_format='channels_last',name=None)
keras.legacy_tf_layers.pooling.average_pooling2d(inputs,pool_size,strides,padding='valid',data_format='channels_last',name=None)
keras.legacy_tf_layers.pooling.average_pooling3d(inputs,pool_size,strides,padding='valid',data_format='channels_last',name=None)
keras.legacy_tf_layers.pooling.max_pooling1d(inputs,pool_size,strides,padding='valid',data_format='channels_last',name=None)
keras.legacy_tf_layers.pooling.max_pooling2d(inputs,pool_size,strides,padding='valid',data_format='channels_last',name=None)
keras.legacy_tf_layers.pooling.max_pooling3d(inputs,pool_size,strides,padding='valid',data_format='channels_last',name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/convolutional.py----------------------------------------
A:keras.legacy_tf_layers.convolutional.layer->Conv3DTranspose(filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, data_format=data_format, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, bias_regularizer=bias_regularizer, activity_regularizer=activity_regularizer, kernel_constraint=kernel_constraint, bias_constraint=bias_constraint, trainable=trainable, name=name, _reuse=reuse, _scope=name)
keras.legacy_tf_layers.convolutional.Conv1D(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv1D.__init__(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv2D.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv2DTranspose(self,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv2DTranspose.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv3D(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1,1),activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv3D.__init__(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1,1),activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv3DTranspose(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format='channels_last',activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.Conv3DTranspose.__init__(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format='channels_last',activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.SeparableConv1D(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer=None,pointwise_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.SeparableConv1D.__init__(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer=None,pointwise_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.SeparableConv2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1),depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer=None,pointwise_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.SeparableConv2D.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1),depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer=None,pointwise_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.legacy_tf_layers.convolutional.conv1d(inputs,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.convolutional.conv2d(inputs,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.convolutional.conv2d_transpose(inputs,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.convolutional.conv3d(inputs,filters,kernel_size,strides=(1,1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1,1),activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.convolutional.conv3d_transpose(inputs,filters,kernel_size,strides=(1,1,1),padding='valid',data_format='channels_last',activation=None,use_bias=True,kernel_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.convolutional.separable_conv1d(inputs,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer=None,pointwise_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)
keras.legacy_tf_layers.convolutional.separable_conv2d(inputs,filters,kernel_size,strides=(1,1),padding='valid',data_format='channels_last',dilation_rate=(1,1),depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer=None,pointwise_initializer=None,bias_initializer=tf.compat.v1.zeros_initializer(),depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,reuse=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/normalization.py----------------------------------------
A:keras.legacy_tf_layers.normalization.layer->BatchNormalization(axis=axis, momentum=momentum, epsilon=epsilon, center=center, scale=scale, beta_initializer=beta_initializer, gamma_initializer=gamma_initializer, moving_mean_initializer=moving_mean_initializer, moving_variance_initializer=moving_variance_initializer, beta_regularizer=beta_regularizer, gamma_regularizer=gamma_regularizer, beta_constraint=beta_constraint, gamma_constraint=gamma_constraint, renorm=renorm, renorm_clipping=renorm_clipping, renorm_momentum=renorm_momentum, fused=fused, trainable=trainable, virtual_batch_size=virtual_batch_size, adjustment=adjustment, name=name, _reuse=reuse, _scope=name)
keras.legacy_tf_layers.normalization.BatchNormalization(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer=tf.compat.v1.zeros_initializer(),gamma_initializer=tf.compat.v1.ones_initializer(),moving_mean_initializer=tf.compat.v1.zeros_initializer(),moving_variance_initializer=tf.compat.v1.ones_initializer(),beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,renorm=False,renorm_clipping=None,renorm_momentum=0.99,fused=None,trainable=True,virtual_batch_size=None,adjustment=None,name=None,**kwargs)
keras.legacy_tf_layers.normalization.BatchNormalization.__init__(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer=tf.compat.v1.zeros_initializer(),gamma_initializer=tf.compat.v1.ones_initializer(),moving_mean_initializer=tf.compat.v1.zeros_initializer(),moving_variance_initializer=tf.compat.v1.ones_initializer(),beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,renorm=False,renorm_clipping=None,renorm_momentum=0.99,fused=None,trainable=True,virtual_batch_size=None,adjustment=None,name=None,**kwargs)
keras.legacy_tf_layers.normalization.BatchNormalization.call(self,inputs,training=False)
keras.legacy_tf_layers.normalization.batch_normalization(inputs,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer=tf.compat.v1.zeros_initializer(),gamma_initializer=tf.compat.v1.ones_initializer(),moving_mean_initializer=tf.compat.v1.zeros_initializer(),moving_variance_initializer=tf.compat.v1.ones_initializer(),beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,training=False,trainable=True,name=None,reuse=None,renorm=False,renorm_clipping=None,renorm_momentum=0.99,fused=None,virtual_batch_size=None,adjustment=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/variable_scope_shim.py----------------------------------------
A:keras.legacy_tf_layers.variable_scope_shim.args->fn_args(fn.func)
A:keras.legacy_tf_layers.variable_scope_shim.(_, fn)->tensorflow.compat.v2.__internal__.decorator.unwrap(fn)
A:keras.legacy_tf_layers.variable_scope_shim.aggregation->tensorflow.compat.v2.VariableAggregation(aggregation)
A:keras.legacy_tf_layers.variable_scope_shim.synchronization->tensorflow.compat.v2.VariableSynchronization(synchronization)
A:keras.legacy_tf_layers.variable_scope_shim.(synchronization, aggregation, trainable)->validate_synchronization_aggregation_trainable(synchronization, aggregation, trainable, name)
A:keras.legacy_tf_layers.variable_scope_shim.dtype->tensorflow.compat.v2.as_dtype(dtype)
A:keras.legacy_tf_layers.variable_scope_shim.shape->as_shape(shape)
A:keras.legacy_tf_layers.variable_scope_shim.(initializer, initializing_from_value)->self._get_default_initializer(name=name, shape=shape, dtype=dtype)
A:keras.legacy_tf_layers.variable_scope_shim.initializer->tensorflow.compat.v2.compat.v1.zeros_initializer()
A:keras.legacy_tf_layers.variable_scope_shim.init_val->functools.partial(initializer, shape.as_list(), dtype=dtype)
A:keras.legacy_tf_layers.variable_scope_shim.v->tensorflow.compat.v2.Variable(initial_value=init_val, name=name, trainable=trainable, caching_device=caching_device, dtype=variable_dtype, validate_shape=validate_shape, constraint=constraint, synchronization=synchronization, aggregation=aggregation)
A:keras.legacy_tf_layers.variable_scope_shim.layer->create_layer_method()
A:keras.legacy_tf_layers.variable_scope_shim.self._regularizers[var.name]->functools.partial(regularizer, var)
A:keras.legacy_tf_layers.variable_scope_shim.var_store->_EagerVariableStore()
A:keras.legacy_tf_layers.variable_scope_shim.existing_regularized_variables->set(var_store._regularizers.keys())
A:keras.legacy_tf_layers.variable_scope_shim.out->method(self, *args, **kwargs)
A:keras.legacy_tf_layers.variable_scope_shim.store->tensorflow.python.ops.variable_scope._get_default_variable_store()
keras.legacy_tf_layers.variable_scope_shim.VariableScopeLayer(base_layer.Layer)
keras.legacy_tf_layers.variable_scope_shim.VariableScopeLayer._call_full_argspec(self)
keras.legacy_tf_layers.variable_scope_shim.VariableScopeLayer.call(self,*args,**kwargs)
keras.legacy_tf_layers.variable_scope_shim.VariableScopeLayer.forward_pass(self,*args,**kwargs)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore(self)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore.__init__(self)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore._get_default_initializer(self,name,shape=None,dtype=tf.float32)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore._get_single_variable(self,name,shape=None,dtype=tf.float32,initializer=None,regularizer=None,partition_info=None,reuse=None,trainable=None,caching_device=None,validate_shape=True,constraint=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.compat.v1.VariableAggregation.NONE)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore.add_regularizer(self,var,regularizer)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore.get_or_create_layer(self,name,create_layer_method)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore.get_variable(self,name,shape=None,dtype=tf.float32,initializer=None,regularizer=None,reuse=None,trainable=None,collections=None,caching_device=None,partitioner=None,validate_shape=True,use_resource=None,custom_getter=None,constraint=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.compat.v1.VariableAggregation.NONE)
keras.legacy_tf_layers.variable_scope_shim._EagerVariableStore.scope(self)
keras.legacy_tf_layers.variable_scope_shim._has_kwargs(fn)
keras.legacy_tf_layers.variable_scope_shim._is_bound_method(fn)
keras.legacy_tf_layers.variable_scope_shim._is_callable_object(obj)
keras.legacy_tf_layers.variable_scope_shim.as_shape(shape)
keras.legacy_tf_layers.variable_scope_shim.fn_args(fn)
keras.legacy_tf_layers.variable_scope_shim.get_or_create_layer(name,create_layer_method)
keras.legacy_tf_layers.variable_scope_shim.track_tf1_style_variables(method)
keras.legacy_tf_layers.variable_scope_shim.validate_synchronization_aggregation_trainable(synchronization,aggregation,trainable,name)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/legacy_tf_layers/base.py----------------------------------------
A:keras.legacy_tf_layers.base.scope->kwargs.pop('scope', None)
A:keras.legacy_tf_layers.base.self._reuse->kwargs.pop('_reuse', None)
A:keras.legacy_tf_layers.base.dtype->keras.mixed_precision.policy.Policy('_infer')
A:keras.legacy_tf_layers.base.(self._name, _)->self._make_unique_name()
A:keras.legacy_tf_layers.base.(self._name, base_name)->self._make_unique_name()
A:keras.legacy_tf_layers.base.base_name->keras.engine.base_layer_v1.to_snake_case(self.__class__.__name__)
A:keras.legacy_tf_layers.base.name->keras.backend.unique_object_name(base_name, name_uid_map=name_uid_map, avoid_names=avoid_names, namespace=namespace, zero_based=zero_based)
A:keras.legacy_tf_layers.base.previous_losses_length->len(self._losses)
A:keras.legacy_tf_layers.base.previous_callable_losses_length->len(self._callable_losses)
A:keras.legacy_tf_layers.base.loss_tensor->regularizer()
A:keras.legacy_tf_layers.base.default_graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.legacy_tf_layers.base.init_graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.legacy_tf_layers.base.existing_variables->set(tf.compat.v1.global_variables())
A:keras.legacy_tf_layers.base.prev_len_trainable->len(self._trainable_weights)
A:keras.legacy_tf_layers.base.variable->super(Layer, self).add_weight(name, shape, dtype=tf.as_dtype(dtype), initializer=initializer, trainable=trainable and self.trainable, constraint=constraint, partitioner=partitioner, use_resource=use_resource, synchronization=synchronization, aggregation=aggregation, getter=tf.compat.v1.get_variable, **kwargs)
A:keras.legacy_tf_layers.base.var_store->tensorflow.python.ops.variable_scope._get_default_variable_store()
A:keras.legacy_tf_layers.base.trainable_variables->tensorflow.compat.v2.compat.v1.trainable_variables()
A:keras.legacy_tf_layers.base.scope_context_manager->tensorflow.compat.v2.compat.v1.variable_scope(self._scope, reuse=self._reuse, auxiliary_name_scope=False)
A:keras.legacy_tf_layers.base.self._call_fn_args->keras.legacy_tf_layers.variable_scope_shim.fn_args(self.call)
A:keras.legacy_tf_layers.base.outputs->super(Layer, self).__call__(inputs, *args, **kwargs)
A:keras.legacy_tf_layers.base.no_copy->set(['_graph', '_thread_local', '_metrics_lock'])
A:keras.legacy_tf_layers.base.shallow_copy->set(['_scope', '_always_reuse_variable_scope'])
A:keras.legacy_tf_layers.base.result->cls.__new__(cls)
A:keras.legacy_tf_layers.base.elements->tensorflow.compat.v2.nest.flatten(elements)
A:keras.legacy_tf_layers.base.collection_list->tensorflow.compat.v2.nest.flatten(collection_list)
A:keras.legacy_tf_layers.base.collection->tensorflow.compat.v2.compat.v1.get_collection_ref(name)
keras.legacy_tf_layers.base.Layer(self,trainable=True,name=None,dtype=None,**kwargs)
keras.legacy_tf_layers.base.Layer.__deepcopy__(self,memo)
keras.legacy_tf_layers.base.Layer.__init__(self,trainable=True,name=None,dtype=None,**kwargs)
keras.legacy_tf_layers.base.Layer.__setattr__(self,value,name)
keras.legacy_tf_layers.base.Layer._init_set_name(self,name)
keras.legacy_tf_layers.base.Layer._is_legacy_layer(self)
keras.legacy_tf_layers.base.Layer._make_unique_name(self,name_uid_map=None,avoid_names=None,namespace='',zero_based=False)
keras.legacy_tf_layers.base.Layer._name_scope(self)
keras.legacy_tf_layers.base.Layer._set_scope(self,scope=None)
keras.legacy_tf_layers.base.Layer.add_loss(self,losses,inputs=None)
keras.legacy_tf_layers.base.Layer.add_weight(self,name,shape,dtype=None,initializer=None,regularizer=None,trainable=None,constraint=None,use_resource=None,synchronization=tf.VariableSynchronization.AUTO,aggregation=tf.compat.v1.VariableAggregation.NONE,partitioner=None,**kwargs)
keras.legacy_tf_layers.base.Layer.apply(self,*args,**kwargs)
keras.legacy_tf_layers.base.Layer.graph(self)
keras.legacy_tf_layers.base.Layer.scope_name(self)
keras.legacy_tf_layers.base._add_elements_to_collection(elements,collection_list)
keras.legacy_tf_layers.base._is_in_keras_style_scope()
keras.legacy_tf_layers.base.keras_style_scope()
keras.legacy_tf_layers.base.set_keras_style()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/optimizers.py----------------------------------------
A:keras.dtensor.optimizers.init_val->keras.dtensor.dtensor_api.copy_to_mesh(init_val, dtensor.Layout.replicated(self._mesh, rank=0))
A:keras.dtensor.optimizers.self._iterations->keras.dtensor.dtensor_api.DVariable(init_val, name='iteration')
A:keras.dtensor.optimizers.initial_value->keras.dtensor.dtensor_api.copy_to_mesh(initial_value, dtensor.Layout.replicated(self._mesh, rank=initial_value.shape.rank))
A:keras.dtensor.optimizers.self._current_learning_rate->keras.dtensor.dtensor_api.DVariable(learning_rate(self.iterations), name='learning_rate', dtype=tf.float32)
A:keras.dtensor.optimizers.self._learning_rate->self._build_learning_rate(learning_rate)
keras.dtensor.optimizers.Adadelta(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,gradients_clip_option=None,ema_option=None,name='Adadelta',mesh=None)
keras.dtensor.optimizers.Adadelta.__init__(self,learning_rate=0.001,rho=0.95,epsilon=1e-07,gradients_clip_option=None,ema_option=None,name='Adadelta',mesh=None)
keras.dtensor.optimizers.Adagrad(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,gradients_clip_option=None,ema_option=None,name='Adagrad',mesh=None)
keras.dtensor.optimizers.Adagrad.__init__(self,learning_rate=0.001,initial_accumulator_value=0.1,epsilon=1e-07,gradients_clip_option=None,ema_option=None,name='Adagrad',mesh=None)
keras.dtensor.optimizers.Adam(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,gradients_clip_option=None,ema_option=None,name='Adam',mesh=None)
keras.dtensor.optimizers.Adam.__init__(self,learning_rate=0.001,beta_1=0.9,beta_2=0.999,epsilon=1e-07,amsgrad=False,gradients_clip_option=None,ema_option=None,name='Adam',mesh=None)
keras.dtensor.optimizers.Optimizer(self,name,mesh=None)
keras.dtensor.optimizers.Optimizer.__init__(self,name,mesh=None)
keras.dtensor.optimizers.Optimizer._build_learning_rate(self,learning_rate)
keras.dtensor.optimizers.Optimizer._create_iteration_variable(self)
keras.dtensor.optimizers.Optimizer._internal_apply_gradients(self,grads_and_vars)
keras.dtensor.optimizers.Optimizer._overwrite_model_variables_with_average_value_helper(self,var_list)
keras.dtensor.optimizers.Optimizer._var_key(self,variable)
keras.dtensor.optimizers.Optimizer.add_variable_from_reference(self,model_variable,variable_name,initial_value=None)
keras.dtensor.optimizers.Optimizer.aggregate_gradients(self,grads_and_vars)
keras.dtensor.optimizers.Optimizer.apply_gradients(self,grads_and_vars)
keras.dtensor.optimizers.RMSprop(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,gradients_clip_option=None,ema_option=None,jit_compile=False,name='RMSprop',mesh=None)
keras.dtensor.optimizers.RMSprop.__init__(self,learning_rate=0.001,rho=0.9,momentum=0.0,epsilon=1e-07,centered=False,gradients_clip_option=None,ema_option=None,jit_compile=False,name='RMSprop',mesh=None)
keras.dtensor.optimizers.SGD(self,learning_rate=0.01,momentum=0.0,nesterov=False,amsgrad=False,gradients_clip_option=None,ema_option=None,jit_compile=False,name='SGD',mesh=None)
keras.dtensor.optimizers.SGD.__init__(self,learning_rate=0.01,momentum=0.0,nesterov=False,amsgrad=False,gradients_clip_option=None,ema_option=None,jit_compile=False,name='SGD',mesh=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/utils.py----------------------------------------
A:keras.dtensor.utils.signature->inspect.signature(init_method)
A:keras.dtensor.utils.layout->kwargs.pop(variable_name + '_layout', None)
A:keras.dtensor.utils.mesh->kwargs.pop('mesh', None)
A:keras.dtensor.utils.result->fn(*args, **kwargs)
keras.dtensor.utils.allow_initializer_layout(init_method)
keras.dtensor.utils.call_with_layout(fn,layout,*args,**kwargs)
keras.dtensor.utils.inject_mesh(init_method)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/layout_map.py----------------------------------------
A:keras.dtensor.layout_map._LAYOUT_MAP->threading.local()
A:keras.dtensor.layout_map.self._layout_map->collections.OrderedDict()
A:keras.dtensor.layout_map.previous_layout_map->get_current_layout_map()
A:keras.dtensor.layout_map.object_path->'.'.join([str(item) for item in path])
A:keras.dtensor.layout_map.new_variable->keras.dtensor.dtensor_api.DVariable(init_val, trainable=variable.trainable, name=variable_name)
A:keras.dtensor.layout_map.keras_generator._generator._state_var->_create_dvariable(layout_map, '', keras_generator._generator._state_var)
A:keras.dtensor.layout_map.layout->keras.dtensor.dtensor_api.Layout.replicated(mesh=layout_map.get_default_mesh(), rank=variable_rank)
A:keras.dtensor.layout_map.init_val->keras.dtensor.dtensor_api.copy_to_mesh(init_val, layout)
A:keras.dtensor.layout_map.object_to_set->getattr(object_to_set, attr_name)
keras.dtensor.layout_map.LayoutMap(self,mesh=None)
keras.dtensor.layout_map.LayoutMap.__delitem__(self,key)
keras.dtensor.layout_map.LayoutMap.__getitem__(self,key)
keras.dtensor.layout_map.LayoutMap.__init__(self,mesh=None)
keras.dtensor.layout_map.LayoutMap.__iter__(self)
keras.dtensor.layout_map.LayoutMap.__len__(self)
keras.dtensor.layout_map.LayoutMap.__setitem__(self,key,layout)
keras.dtensor.layout_map.LayoutMap.get_default_mesh(self)
keras.dtensor.layout_map._config_dvariable_regularization(layer,lazy_init_variable_to_tf_variable_map)
keras.dtensor.layout_map._create_dvariable(layout_map,object_path,variable)
keras.dtensor.layout_map._init_state_variable_for_rng(model,layout_map)
keras.dtensor.layout_map._is_lazy_init_variable(obj)
keras.dtensor.layout_map._map_functional_model_variable(model,layout_map)
keras.dtensor.layout_map._map_subclass_model_variable(model,layout_map)
keras.dtensor.layout_map._set_object_by_path(object_to_set,path,value)
keras.dtensor.layout_map.get_current_layout_map()
keras.dtensor.layout_map.layout_map_scope(layout_map)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/lazy_variable.py----------------------------------------
A:keras.dtensor.lazy_variable._DISABLE_LAZY_VARIABLE_INIT->threading.local()
A:keras.dtensor.lazy_variable.handle_name->tensorflow.python.framework.ops.name_from_scope_name(name)
A:keras.dtensor.lazy_variable.attr->tensorflow.core.framework.attr_value_pb2.AttrValue(list=attr_value_pb2.AttrValue.ListValue(s=[compat.as_bytes('loc:@%s' % handle_name)]))
A:keras.dtensor.lazy_variable.initial_value->self._initial_value()
A:keras.dtensor.lazy_variable.handle->tensorflow.python.ops.resource_variable_ops._variable_handle_from_shape_and_dtype(shape=shape, dtype=dtype, shared_name=None, name=name, graph_mode=False, initial_value=None)
A:keras.dtensor.lazy_variable.(initial_value, shape, dtype, handle, handle_name, unique_id)->_infer_shape_dtype_and_create_handle(initial_value, self._shape, self._dtype, self._name)
A:keras.dtensor.lazy_variable.existing_value->getattr(_DISABLE_LAZY_VARIABLE_INIT, 'disabled', False)
keras.dtensor.lazy_variable.LazyInitVariable(self,initial_value=None,trainable=None,collections=None,validate_shape=True,caching_device=None,name=None,dtype=None,variable_def=None,import_scope=None,constraint=None,distribute_strategy=None,synchronization=None,aggregation=None,shape=None,**kwargs)
keras.dtensor.lazy_variable.LazyInitVariable.__init__(self,initial_value=None,trainable=None,collections=None,validate_shape=True,caching_device=None,name=None,dtype=None,variable_def=None,import_scope=None,constraint=None,distribute_strategy=None,synchronization=None,aggregation=None,shape=None,**kwargs)
keras.dtensor.lazy_variable.LazyInitVariable.create_and_initialize(self)
keras.dtensor.lazy_variable.LazyInitVariable.initialize(self)
keras.dtensor.lazy_variable._infer_shape_dtype_and_create_handle(initial_value,shape,dtype,name)
keras.dtensor.lazy_variable._lazy_init_variable_creator(next_creator,**kwargs)
keras.dtensor.lazy_variable.disable_init_variable_creator()
keras.dtensor.lazy_variable.lazy_init_scope()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/test_util.py----------------------------------------
A:keras.dtensor.test_util.mesh->get_mesh('CPU')
A:keras.dtensor.test_util.device_count->numpy.prod(shape)
A:keras.dtensor.test_util.devices->tensorflow.compat.v2.config.list_physical_devices(device_type)
keras.dtensor.test_util.DTensorBaseTest(tf.test.TestCase,parameterized.TestCase)
keras.dtensor.test_util.DTensorBaseTest.configTestMesh(device_type_mesh_map)
keras.dtensor.test_util.DTensorBaseTest.setUpClass(cls)
keras.dtensor.test_util.DTensorBaseTest.tearDown(self)
keras.dtensor.test_util.create_device_array(shape,device_type)
keras.dtensor.test_util.create_device_ids_array(shape)
keras.dtensor.test_util.create_device_list(shape,device_type)
keras.dtensor.test_util.reset_context()
keras.dtensor.test_util.reset_dtensor()
keras.dtensor.test_util.reset_logical_devices(device_type,count)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/dtensor/integration_test_utils.py----------------------------------------
A:keras.dtensor.integration_test_utils.model->keras.models.Sequential()
A:keras.dtensor.integration_test_utils.layout_map->keras.dtensor.layout_map.LayoutMap(mesh=mesh)
A:keras.dtensor.integration_test_utils.layout_4d->keras.dtensor.dtensor_api.Layout.replicated(mesh, rank=4)
A:keras.dtensor.integration_test_utils.layout_2d->keras.dtensor.dtensor_api.Layout.replicated(mesh, rank=2)
A:keras.dtensor.integration_test_utils.layout_1d->keras.dtensor.dtensor_api.Layout.replicated(mesh, rank=1)
A:keras.dtensor.integration_test_utils.((x_train, y_train), (x_test, y_test))->keras.datasets.mnist.load_data()
A:keras.dtensor.integration_test_utils.x_train->numpy.expand_dims(x_train, axis=-1).astype('float32')
A:keras.dtensor.integration_test_utils.x_test->numpy.expand_dims(x_test, axis=-1).astype('float32')
A:keras.dtensor.integration_test_utils.y_train->keras.utils.np_utils.to_categorical(y_train, num_class)
A:keras.dtensor.integration_test_utils.y_test->keras.utils.np_utils.to_categorical(y_test, num_class)
A:keras.dtensor.integration_test_utils.train_ds->tensorflow.compat.v2.data.Dataset.from_tensor_slices((x_train, y_train)).repeat().batch(batch_size, drop_remainder=True)
A:keras.dtensor.integration_test_utils.eval_ds->tensorflow.compat.v2.data.Dataset.from_tensor_slices((x_test, y_test)).repeat().batch(batch_size, drop_remainder=True)
A:keras.dtensor.integration_test_utils.(dataset, _)->get_mnist_datasets(NUM_CLASS, global_batch_size)
A:keras.dtensor.integration_test_utils.input_image_layout->keras.dtensor.dtensor_api.Layout.batch_sharded(mesh, 'batch', rank=4)
A:keras.dtensor.integration_test_utils.input_label_layout->keras.dtensor.dtensor_api.Layout.batch_sharded(mesh, 'batch', rank=2)
A:keras.dtensor.integration_test_utils.loss_obj->keras.losses.CategoricalCrossentropy()
A:keras.dtensor.integration_test_utils.num_local_devices->mesh.num_local_devices()
A:keras.dtensor.integration_test_utils.iterator->iter(dataset)
A:keras.dtensor.integration_test_utils.(images, labels)->next(iterator)
A:keras.dtensor.integration_test_utils.images->tensorflow.compat.v2.split(images, num_local_devices)
A:keras.dtensor.integration_test_utils.labels->tensorflow.compat.v2.split(labels, num_local_devices)
A:keras.dtensor.integration_test_utils.d_images->keras.dtensor.dtensor_api.pack(images, input_image_layout)
A:keras.dtensor.integration_test_utils.d_labels->keras.dtensor.dtensor_api.pack(labels, input_label_layout)
A:keras.dtensor.integration_test_utils.train_loss->tensorflow.compat.v2.reduce_mean(total_loss / steps_per_epoch)
A:keras.dtensor.integration_test_utils.predict->model(feature, training=True)
A:keras.dtensor.integration_test_utils.loss->loss_obj(label, predict)
A:keras.dtensor.integration_test_utils.gradients->tape.gradient(loss, model.trainable_variables)
keras.dtensor.integration_test_utils.get_all_replicated_layout_map(mesh)
keras.dtensor.integration_test_utils.get_mnist_datasets(num_class,batch_size)
keras.dtensor.integration_test_utils.get_model_with_layout_map(layout_map)
keras.dtensor.integration_test_utils.train_mnist_model_batch_sharded(model,optimizer,mesh,num_epochs,steps_per_epoch,global_batch_size)
keras.dtensor.integration_test_utils.train_step(model,feature,label,loss_obj,optimizer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_image_model_correctness_test.py----------------------------------------
A:keras.distribute.keras_image_model_correctness_test.image->keras.layers.Input(shape=(28, 28, 3), name='image')
A:keras.distribute.keras_image_model_correctness_test.c1->keras.layers.MaxPooling2D(pool_size=(2, 2))(c1)
A:keras.distribute.keras_image_model_correctness_test.bn1->keras.layers.SyncBatchNormalization(name='bn1')(c1)
A:keras.distribute.keras_image_model_correctness_test.bn2->keras.layers.SyncBatchNormalization(name='bn2')(c1)
A:keras.distribute.keras_image_model_correctness_test.logits->keras.layers.Dense(10, activation='softmax', name='pred')(keras.layers.Flatten()(c1))
A:keras.distribute.keras_image_model_correctness_test.model->keras.Model(inputs=[image], outputs=[logits])
A:keras.distribute.keras_image_model_correctness_test.centers->numpy.random.randn(num_classes, *shape)
A:keras.distribute.keras_image_model_correctness_test.offset->offset.reshape(shape).reshape(shape)
A:keras.distribute.keras_image_model_correctness_test.x->numpy.asarray(features, dtype=np.float32)
A:keras.distribute.keras_image_model_correctness_test.y->numpy.asarray(labels, dtype=np.float32).reshape((count, 1))
A:keras.distribute.keras_image_model_correctness_test.(x_train, y_train)->self._get_data(count=1280)
A:keras.distribute.keras_image_model_correctness_test.(x_eval, y_eval)->self._get_data(count=1000)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest(keras_correctness_test_base.TestDistributionStrategyCorrectnessBase)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest._get_data(self,count,shape=(28,28,3),num_classes=10)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.get_data(self)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.get_data_with_partial_last_batch_eval(self)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.get_model(self,initial_weights=None,distribution=None,input_shapes=None)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.test_cnn_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.test_cnn_correctness_with_partial_last_batch_eval(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.test_cnn_with_batch_norm_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.test_cnn_with_batch_norm_correctness_and_partial_last_batch_eval(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_image_model_correctness_test.DistributionStrategyCnnCorrectnessTest.test_cnn_with_sync_batch_norm_correctness(self,distribution,use_numpy,use_validation_data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/sidecar_evaluator.py----------------------------------------
A:keras.distribute.sidecar_evaluator.reader->tensorflow.compat.v2.train.load_checkpoint(ckpt_dir_or_file)
A:keras.distribute.sidecar_evaluator.variable_map->tensorflow.compat.v2.train.load_checkpoint(ckpt_dir_or_file).get_variable_to_shape_map()
A:keras.distribute.sidecar_evaluator.self._iterations->tensorflow.compat.v2.Variable(name='iterations', initial_value=_ITERATIONS_UNINITIALIZED, dtype=tf.int64)
A:keras.distribute.sidecar_evaluator.optimizer_checkpoint->tensorflow.compat.v2.train.Checkpoint(iter=self._iterations)
A:keras.distribute.sidecar_evaluator.checkpoint->tensorflow.compat.v2.train.Checkpoint(model=self.model, optimizer=optimizer_checkpoint)
A:keras.distribute.sidecar_evaluator.checkpoint_attributes->list_checkpoint_attributes(latest_checkpoint)
A:keras.distribute.sidecar_evaluator.result->metric.result()
keras.distribute.sidecar_evaluator.SidecarEvaluator(self,model,data,checkpoint_dir,steps=None,max_evaluations=None,callbacks=None)
keras.distribute.sidecar_evaluator.SidecarEvaluator.__init__(self,model,data,checkpoint_dir,steps=None,max_evaluations=None,callbacks=None)
keras.distribute.sidecar_evaluator.SidecarEvaluator._timeout_fn(self)
keras.distribute.sidecar_evaluator.SidecarEvaluator.start(self)
keras.distribute.sidecar_evaluator.SidecarEvaluatorExperimental(self,*args,**kwargs)
keras.distribute.sidecar_evaluator.SidecarEvaluatorExperimental.__init__(self,*args,**kwargs)
keras.distribute.sidecar_evaluator.list_checkpoint_attributes(ckpt_dir_or_file)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/distribute_coordinator_utils.py----------------------------------------
A:keras.distribute.distribute_coordinator_utils._worker_context->threading.local()
A:keras.distribute.distribute_coordinator_utils._thread_local->threading.local()
A:keras.distribute.distribute_coordinator_utils.self._master_target->self._get_master_target()
A:keras.distribute.distribute_coordinator_utils.self._num_workers->_get_num_workers(cluster_spec)
A:keras.distribute.distribute_coordinator_utils.self._is_chief_node->self._is_chief()
A:keras.distribute.distribute_coordinator_utils.old_context->get_current_worker_context()
A:keras.distribute.distribute_coordinator_utils.session_config->copy.deepcopy(session_config)
A:keras.distribute.distribute_coordinator_utils.strategy->copy.deepcopy(strategy)
A:keras.distribute.distribute_coordinator_utils.context->_WorkerContext(strategy, cluster_spec, task_type, task_id)
A:keras.distribute.distribute_coordinator_utils.new_cluster_spec->normalize_cluster_spec(cluster_spec).as_dict()
A:keras.distribute.distribute_coordinator_utils._thread_local.session_config_str->repr(session_config)
A:keras.distribute.distribute_coordinator_utils.target->cluster_resolver.cluster_spec().task_address(task_type, task_id)
A:keras.distribute.distribute_coordinator_utils.server->_run_std_server(cluster_spec=cluster_spec, task_type=task_type, task_id=task_id, session_config=session_config, rpc_layer=rpc_layer, environment=environment)
A:keras.distribute.distribute_coordinator_utils.cluster_spec->cluster_resolver.cluster_spec()
A:keras.distribute.distribute_coordinator_utils.tf_config->json.loads(os.environ.get('TF_CONFIG', '{}'))
A:keras.distribute.distribute_coordinator_utils.rpc_layer->json.loads(os.environ.get('TF_CONFIG', '{}')).get('rpc_layer', rpc_layer)
A:keras.distribute.distribute_coordinator_utils.environment->json.loads(os.environ.get('TF_CONFIG', '{}')).get('environment', None)
A:keras.distribute.distribute_coordinator_utils.task_env->json.loads(os.environ.get('TF_CONFIG', '{}')).get('task', {})
A:keras.distribute.distribute_coordinator_utils.task_type->json.loads(os.environ.get('TF_CONFIG', '{}')).get('task', {}).get('type', task_type)
A:keras.distribute.distribute_coordinator_utils.task_id->int(task_env.get('index', task_id))
keras.distribute.distribute_coordinator_utils._TaskType
keras.distribute.distribute_coordinator_utils._WorkerContext(self,strategy,cluster_spec,task_type,task_id,session_config=None,rpc_layer='grpc',worker_barrier=None)
keras.distribute.distribute_coordinator_utils._WorkerContext.__enter__(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.__exit__(self,unused_exception_type,unused_exception_value,unused_traceback)
keras.distribute.distribute_coordinator_utils._WorkerContext.__init__(self,strategy,cluster_spec,task_type,task_id,session_config=None,rpc_layer='grpc',worker_barrier=None)
keras.distribute.distribute_coordinator_utils._WorkerContext._debug_message(self)
keras.distribute.distribute_coordinator_utils._WorkerContext._get_master_target(self)
keras.distribute.distribute_coordinator_utils._WorkerContext._is_chief(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.cluster_spec(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.distributed_mode(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.experimental_should_init(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.has_barrier(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.is_chief(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.master_target(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.num_workers(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.session_config(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.session_creator(self,scaffold=None,config=None,checkpoint_dir=None,checkpoint_filename_with_path=None,max_wait_secs=7200)
keras.distribute.distribute_coordinator_utils._WorkerContext.should_checkpoint(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.should_save_summary(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.task_id(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.task_type(self)
keras.distribute.distribute_coordinator_utils._WorkerContext.wait_for_other_workers(self)
keras.distribute.distribute_coordinator_utils._configure_session_config_for_std_servers(strategy,eval_strategy,session_config,cluster_spec,task_type,task_id)
keras.distribute.distribute_coordinator_utils._get_num_workers(cluster_spec)
keras.distribute.distribute_coordinator_utils._run_single_worker(worker_fn,strategy,cluster_spec,task_type,task_id,session_config,rpc_layer='',worker_barrier=None,coord=None)
keras.distribute.distribute_coordinator_utils._run_std_server(cluster_spec=None,task_type=None,task_id=None,session_config=None,rpc_layer=None,environment=None)
keras.distribute.distribute_coordinator_utils._split_cluster_for_evaluator(cluster_spec,task_type)
keras.distribute.distribute_coordinator_utils.get_current_worker_context()
keras.distribute.distribute_coordinator_utils.normalize_cluster_spec(cluster_spec)
keras.distribute.distribute_coordinator_utils.run_distribute_coordinator(worker_fn,strategy,eval_fn=None,eval_strategy=None,cluster_spec=None,task_type=None,task_id=None,session_config=None,rpc_layer='grpc')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/distributed_training_utils.py----------------------------------------
A:keras.distribute.distributed_training_utils.strategy->tensorflow.compat.v2.distribute.OneDeviceStrategy('/gpu:0')
A:keras.distribute.distributed_training_utils.is_tpu->keras.backend.is_tpu_strategy(strategy)
A:keras.distribute.distributed_training_utils.cluster_resolver->tensorflow.compat.v2.distribute.cluster_resolver.TFConfigClusterResolver()
keras.distribute.distributed_training_utils.call_replica_local_fn(fn,*args,**kwargs)
keras.distribute.distributed_training_utils.get_strategy()
keras.distribute.distributed_training_utils.global_batch_size_supported(distribution_strategy)
keras.distribute.distributed_training_utils.is_distributed_variable(v)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/distribute_strategy_test.py----------------------------------------
A:keras.distribute.distribute_strategy_test.model->create_model()
A:keras.distribute.distribute_strategy_test.self.dense->keras.layers.Dense(num_labels)
A:keras.distribute.distribute_strategy_test.input_a->keras.layers.Input(shape=(16,), name='z_input_sorted_last')
A:keras.distribute.distribute_strategy_test.input_b->keras.layers.Input(shape=(32,), name='a_input_sorted_first')
A:keras.distribute.distribute_strategy_test.merged->keras.layers.Add()([intermediate_a, intermediate_b])
A:keras.distribute.distribute_strategy_test.output_c->keras.layers.Dense(3, activation='softmax', name='dense_2')(merged)
A:keras.distribute.distribute_strategy_test.output_d->keras.layers.Dense(2, activation='softmax', name='dense_3')(merged)
A:keras.distribute.distribute_strategy_test.((a_train, c_train), (a_test, c_test))->keras.testing_infra.test_utils.get_test_data(train_samples=_TRAIN_SIZE, test_samples=50, input_shape=(16,), num_classes=3, random_seed=_RANDOM_SEED)
A:keras.distribute.distribute_strategy_test.((b_train, d_train), (b_test, d_test))->keras.testing_infra.test_utils.get_test_data(train_samples=_TRAIN_SIZE, test_samples=50, input_shape=(16,), num_classes=2, random_seed=_RANDOM_SEED)
A:keras.distribute.distribute_strategy_test.((m_train, _), (m_test, _))->keras.testing_infra.test_utils.get_test_data(train_samples=_TRAIN_SIZE, test_samples=50, input_shape=(8,), num_classes=2, random_seed=_RANDOM_SEED)
A:keras.distribute.distribute_strategy_test.c_train->keras.utils.np_utils.to_categorical(c_train)
A:keras.distribute.distribute_strategy_test.c_test->keras.utils.np_utils.to_categorical(c_test)
A:keras.distribute.distribute_strategy_test.d_train->keras.utils.np_utils.to_categorical(d_train)
A:keras.distribute.distribute_strategy_test.d_test->keras.utils.np_utils.to_categorical(d_test)
A:keras.distribute.distribute_strategy_test.dataset->dataset.batch(8 * distribution.num_replicas_in_sync).batch(8 * distribution.num_replicas_in_sync)
A:keras.distribute.distribute_strategy_test.x->create_model().get_layer('embedding').get_output_at(-1)
A:keras.distribute.distribute_strategy_test.y->keras.layers.Dense(1)(x)
A:keras.distribute.distribute_strategy_test.inputs->keras.Input(input_shape, name='images')
A:keras.distribute.distribute_strategy_test.targets->numpy.zeros((64, 4), dtype=np.float32)
A:keras.distribute.distribute_strategy_test.original_dataset->tensorflow.compat.v2.data.Dataset.from_tensor_slices(input_slices)
A:keras.distribute.distribute_strategy_test.ds_with_unknown_cardinality->tensorflow.compat.v2.data.Dataset.from_tensor_slices(input_slices).filter(dummy_op).batch(10, drop_remainder=True)
A:keras.distribute.distribute_strategy_test.a->keras.layers.Input(shape=(3,), name='input_a')
A:keras.distribute.distribute_strategy_test.b->keras.layers.Input(shape=(5,), name='input_b')
A:keras.distribute.distribute_strategy_test.dense_1->keras.layers.Dense(7, name='dense_1')
A:keras.distribute.distribute_strategy_test.dense_2->keras.layers.Dense(7, name='dense_2')
A:keras.distribute.distribute_strategy_test.c->dense_1(a)
A:keras.distribute.distribute_strategy_test.d->keras.layers.Dense(1, kernel_initializer='zeros')
A:keras.distribute.distribute_strategy_test.e->keras.layers.Dropout(0.5, name='dropout')(c)
A:keras.distribute.distribute_strategy_test.non_tpu_strategies->tensorflow.compat.v2.__internal__.test.combinations.times(strategy_minus_tpu_combinations(), tf.__internal__.test.combinations.combine(optimizer=[optimizer_combinations.adagrad_optimizer_v1_fn, optimizer_combinations.adam_optimizer_v1_fn, optimizer_combinations.gradient_descent_optimizer_v1_fn, optimizer_combinations.rmsprop_optimizer_v1_fn, optimizer_combinations.adadelta_optimizer_keras_v2_fn, optimizer_combinations.adagrad_optimizer_keras_v2_fn, optimizer_combinations.adam_optimizer_keras_v2_fn, optimizer_combinations.adamax_optimizer_keras_v2_fn, optimizer_combinations.gradient_descent_optimizer_keras_v2_fn, optimizer_combinations.nadam_optimizer_keras_v2_fn, optimizer_combinations.rmsprop_optimizer_keras_v2_fn, optimizer_combinations.ftrl_optimizer_keras_v2_fn]))
A:keras.distribute.distribute_strategy_test.tpu_strategies_graph->tensorflow.compat.v2.__internal__.test.combinations.combine(distribution=tpu_strategies, mode=['graph'], optimizer=[optimizer_combinations.adagrad_optimizer_v1_fn, optimizer_combinations.adam_optimizer_v1_fn, optimizer_combinations.gradient_descent_optimizer_v1_fn, optimizer_combinations.rmsprop_optimizer_v1_fn, optimizer_combinations.adagrad_optimizer_keras_v2_fn, optimizer_combinations.adam_optimizer_keras_v2_fn, optimizer_combinations.gradient_descent_optimizer_keras_v2_fn, optimizer_combinations.rmsprop_optimizer_keras_v2_fn])
A:keras.distribute.distribute_strategy_test.tpu_strategies_eager->tensorflow.compat.v2.__internal__.test.combinations.combine(distribution=tpu_strategies, mode=['eager'], optimizer=[optimizer_combinations.adagrad_optimizer_keras_v2_fn, optimizer_combinations.adam_optimizer_keras_v2_fn, optimizer_combinations.gradient_descent_optimizer_keras_v2_fn, optimizer_combinations.rmsprop_optimizer_keras_v2_fn])
A:keras.distribute.distribute_strategy_test.multi_worker_eager->tensorflow.compat.v2.__internal__.test.combinations.combine(distribution=multi_worker_mirrored_strategies, mode=['eager'], optimizer=[optimizer_combinations.adadelta_optimizer_keras_v2_fn, optimizer_combinations.adagrad_optimizer_keras_v2_fn, optimizer_combinations.adam_optimizer_keras_v2_fn, optimizer_combinations.adamax_optimizer_keras_v2_fn, optimizer_combinations.gradient_descent_optimizer_keras_v2_fn, optimizer_combinations.nadam_optimizer_keras_v2_fn, optimizer_combinations.rmsprop_optimizer_keras_v2_fn, optimizer_combinations.ftrl_optimizer_keras_v2_fn])
A:keras.distribute.distribute_strategy_test.(steps, batch_size)->keras.distribute.distributed_training_utils_v1.get_input_params(distribution, 64, steps=5, batch_size=3)
A:keras.distribute.distribute_strategy_test.optimizer->keras.optimizers.adam_v2.Adam(0.0001)
A:keras.distribute.distribute_strategy_test.self.v1->tensorflow.compat.v2.Variable(1.0)
A:keras.distribute.distribute_strategy_test.self.v2->tensorflow.compat.v2.Variable(-1.0)
A:keras.distribute.distribute_strategy_test.layer->MyLayer()
A:keras.distribute.distribute_strategy_test.(grad_v1, grad_v2)->tensorflow.compat.v2.compat.v1.distribute.experimental.ParameterServerStrategy(cluster_resolver).run(run_fn)
A:keras.distribute.distribute_strategy_test.run_fn->tensorflow.compat.v2.function(run_fn)
A:keras.distribute.distribute_strategy_test.gradients->tape.gradient(y, model.trainable_variables)
A:keras.distribute.distribute_strategy_test.input_a_np->numpy.random.random((10, 3)).astype('float32')
A:keras.distribute.distribute_strategy_test.input_b_np->numpy.random.random((10, 5)).astype('float32')
A:keras.distribute.distribute_strategy_test.output_d_np->numpy.random.random((10, 7)).astype('float32')
A:keras.distribute.distribute_strategy_test.output_e_np->numpy.random.random((10, 7)).astype('float32')
A:keras.distribute.distribute_strategy_test.sample_weights->numpy.array([0.25, 0.5, 0.75, 1], np.float32)
A:keras.distribute.distribute_strategy_test.result->create_model().evaluate(ds, verbose=1)
A:keras.distribute.distribute_strategy_test.outs->create_model().predict(inputs)
A:keras.distribute.distribute_strategy_test.model_with_ds_strategy->simple_multi_inputs_multi_outputs_model()
A:keras.distribute.distribute_strategy_test.cpu_model->simple_multi_inputs_multi_outputs_model()
A:keras.distribute.distribute_strategy_test.evaluate_ground_truth->simple_multi_inputs_multi_outputs_model().evaluate(x, y)
A:keras.distribute.distribute_strategy_test.steps->numpy.ceil(10.0 / batch_size)
A:keras.distribute.distribute_strategy_test.predict_ground_truth->simple_multi_inputs_multi_outputs_model().predict(inputs)
A:keras.distribute.distribute_strategy_test.(input_data, _)->get_multi_inputs_multi_outputs_data()
A:keras.distribute.distribute_strategy_test.self.extra_weight_1->self.add_weight('extra_weight_1', shape=(), initializer='ones')
A:keras.distribute.distribute_strategy_test.self.extra_weight_2->self.add_weight('extra_weight_2', shape=(), initializer='ones')
A:keras.distribute.distribute_strategy_test.user_controlled_model->get_model()
A:keras.distribute.distribute_strategy_test.interleaved_model->get_model()
A:keras.distribute.distribute_strategy_test.interleaved_output->get_model().fit(dataset, epochs=2, steps_per_epoch=2, verbose=1, validation_data=dataset, validation_steps=2, shuffle=False)
A:keras.distribute.distribute_strategy_test.val_mean_absolute_error->get_model().fit(dataset, epochs=2, steps_per_epoch=2, verbose=1, validation_data=dataset, validation_steps=2, shuffle=False).history.get('val_mean_absolute_error')
A:keras.distribute.distribute_strategy_test.dataset_tuple->dataset_tuple.batch(10).batch(10)
A:keras.distribute.distribute_strategy_test.dataset_dict->dataset_dict.batch(10).batch(10)
A:keras.distribute.distribute_strategy_test.bce->keras.losses.binary_crossentropy(label, predict)
A:keras.distribute.distribute_strategy_test.input_img->keras.layers.Input([64, 64, 3], name='img')
A:keras.distribute.distribute_strategy_test.input_lbl->keras.layers.Input([64, 64, 1], name='lbl')
A:keras.distribute.distribute_strategy_test.input_weight->keras.layers.Input([64, 64], name='weight')
A:keras.distribute.distribute_strategy_test.predict->keras.layers.Conv2D(2, [1, 1], padding='same')(input_img)
A:keras.distribute.distribute_strategy_test.loss_lambda->keras.layers.Lambda(lambda x: custom_loss(*x), name='my_loss')
A:keras.distribute.distribute_strategy_test.my_loss->loss_lambda([predict, input_lbl, input_weight])
A:keras.distribute.distribute_strategy_test.fake_imgs->numpy.ones([50, 64, 64, 3], dtype=np.float32)
A:keras.distribute.distribute_strategy_test.fake_lbls->numpy.ones([50, 64, 64, 1], dtype=np.float32)
A:keras.distribute.distribute_strategy_test.fake_weights->numpy.ones([50, 64, 64], dtype=np.float32)
A:keras.distribute.distribute_strategy_test.data->tensorflow.compat.v2.data.Dataset.from_tensor_slices((fake_imgs, fake_lbls, fake_weights)).map(map_fn).batch(10)
A:keras.distribute.distribute_strategy_test.eval_with_numpy->create_model().evaluate(inputs, targets, batch_size=10)
A:keras.distribute.distribute_strategy_test.predict_with_numpy->create_model().predict(inputs, batch_size=10)
A:keras.distribute.distribute_strategy_test.eval_with_ds->create_model().evaluate(dataset, steps=100)
A:keras.distribute.distribute_strategy_test.predict_dataset->predict_dataset.repeat().batch(batch_size).repeat().batch(batch_size)
A:keras.distribute.distribute_strategy_test.predict_with_ds->create_model().predict(predict_dataset, steps=100)
A:keras.distribute.distribute_strategy_test.z->keras.layers.Dropout(0.9999)(y)
A:keras.distribute.distribute_strategy_test.initial_weights->create_model().get_weights()
A:keras.distribute.distribute_strategy_test.hist->create_model().fit(dataset, epochs=1, steps_per_epoch=20, verbose=1)
A:keras.distribute.distribute_strategy_test.output->create_model().predict(input_data, batch_size=2)
A:keras.distribute.distribute_strategy_test.ref_output->numpy.ones((160, 1), dtype=np.float32)
A:keras.distribute.distribute_strategy_test.dataset_with_partial_batch->dataset.batch(8 * distribution.num_replicas_in_sync).batch(8 * distribution.num_replicas_in_sync).batch(18)
A:keras.distribute.distribute_strategy_test.intermediate_a->keras.layers.Dense(10)(input_a)
A:keras.distribute.distribute_strategy_test.intermediate_b->keras.layers.Dense(10)(input_b)
A:keras.distribute.distribute_strategy_test.target->numpy.ones((32, 2), dtype=np.float32)
A:keras.distribute.distribute_strategy_test.(input_a, input_b, output)->_create_model_input_output_tensors()
A:keras.distribute.distribute_strategy_test.model_with_array_input->keras.models.Model(inputs=[input_a, input_b], outputs=output)
A:keras.distribute.distribute_strategy_test.model_weights->keras.models.Model(inputs=[input_a, input_b], outputs=output).get_weights()
A:keras.distribute.distribute_strategy_test.model_with_dict_input->keras.models.Model(inputs={'z_input_sorted_last': input_a, 'a_input_sorted_first': input_b}, outputs=output)
A:keras.distribute.distribute_strategy_test.ds->ds.filter(lambda *args, **kwargs: True).filter(lambda *args, **kwargs: True)
A:keras.distribute.distribute_strategy_test.self.input_file_name->os.path.join(self.get_temp_dir(), 'input.tfrecord')
A:keras.distribute.distribute_strategy_test.input_dataset->input_dataset.map(tf.io.serialize_tensor).map(tf.io.serialize_tensor)
A:keras.distribute.distribute_strategy_test.writer->tensorflow.compat.v2.data.experimental.TFRecordWriter(self.input_file_name)
A:keras.distribute.distribute_strategy_test.options->tensorflow.compat.v2.data.Options()
A:keras.distribute.distribute_strategy_test.self.v->self.add_weight('v', (), initializer='ones', regularizer=TestRegularizerLoss.IdentityRegularizer())
A:keras.distribute.distribute_strategy_test.opt->keras.optimizers.optimizer_v2.gradient_descent.SGD(1.0)
A:keras.distribute.distribute_strategy_test.cb_counter->CBCounter()
A:keras.distribute.distribute_strategy_test.val_ds->tensorflow.compat.v2.compat.v1.distribute.experimental.ParameterServerStrategy(cluster_resolver).distribute_datasets_from_function(make_dataset)
A:keras.distribute.distribute_strategy_test.outputs->keras.layers.Dense(num_classes, name='logits')(x)
A:keras.distribute.distribute_strategy_test.bc->BatchCountingCB()
A:keras.distribute.distribute_strategy_test.train_ds->ds.filter(lambda *args, **kwargs: True).filter(lambda *args, **kwargs: True).repeat(2)
A:keras.distribute.distribute_strategy_test.test_ds->ds.filter(lambda *args, **kwargs: True).filter(lambda *args, **kwargs: True).repeat(2)
A:keras.distribute.distribute_strategy_test.predict_ds->ds.filter(lambda *args, **kwargs: True).filter(lambda *args, **kwargs: True).repeat(2)
A:keras.distribute.distribute_strategy_test.inp->keras.layers.Input(shape=(10,))
A:keras.distribute.distribute_strategy_test.out->keras.layers.Dense(3, activation='softmax')(inp)
A:keras.distribute.distribute_strategy_test.x1->keras.layers.Dense(10, kernel_initializer='zeros')(inputs)
A:keras.distribute.distribute_strategy_test.x2->Bias()(x1)
A:keras.distribute.distribute_strategy_test.history->create_model().fit(x, y, validation_data=(x, y), validation_steps=2, epochs=2)
A:keras.distribute.distribute_strategy_test.ds_model->_make_model_with_add_metric()
A:keras.distribute.distribute_strategy_test.ds_history->_make_model_with_add_metric().fit(x, y, validation_data=(x, y), validation_steps=2, epochs=2)
A:keras.distribute.distribute_strategy_test.self.bias->self.add_weight(name='bias', initializer='zeros', shape=())
A:keras.distribute.distribute_strategy_test.self.mean->keras.metrics.Mean(name='mean')
A:keras.distribute.distribute_strategy_test.indices->tensorflow.compat.v2.where(tf.not_equal(inputs, 0))
A:keras.distribute.distribute_strategy_test.values->tensorflow.compat.v2.gather_nd(inputs, indices)
A:keras.distribute.distribute_strategy_test.shape->tensorflow.compat.v2.shape(inputs, out_type='int64')
A:keras.distribute.distribute_strategy_test.input_data->numpy.array([[1, 0, 0], [2, 3, 0]])
A:keras.distribute.distribute_strategy_test.expected_indices->numpy.array([[0, 0], [1, 0], [1, 1]])
A:keras.distribute.distribute_strategy_test.expected_values->numpy.array([1, 2, 3])
A:keras.distribute.distribute_strategy_test.expected_dense_shape->numpy.array([2, 3])
A:keras.distribute.distribute_strategy_test.labels->keras.layers.Input(shape=(1,))
A:keras.distribute.distribute_strategy_test.x_train->x_train.astype('float32').astype('float32')
A:keras.distribute.distribute_strategy_test.y_train->y_train.astype('float32').astype('float32')
A:keras.distribute.distribute_strategy_test.logits->base_model(inputs)
A:keras.distribute.distribute_strategy_test.loss->tensorflow.compat.v2.nn.compute_average_loss(loss, global_batch_size=batch_size)
A:keras.distribute.distribute_strategy_test.grads->tape.gradient(loss, model.trainable_variables)
A:keras.distribute.distribute_strategy_test.per_replica_losses->tensorflow.compat.v2.compat.v1.distribute.experimental.ParameterServerStrategy(cluster_resolver).run(step_fn, args=(dist_inputs,))
A:keras.distribute.distribute_strategy_test.cluster_spec->keras.distribute.multi_worker_testing_utils.create_in_process_cluster(num_workers=3, num_ps=2)
A:keras.distribute.distribute_strategy_test.cluster_resolver->SimpleClusterResolver(cluster_spec=tf.train.ClusterSpec(cluster_spec), task_type='worker', task_id=1, num_accelerators={'GPU': 0})
A:keras.distribute.distribute_strategy_test.distribution->tensorflow.compat.v2.compat.v1.distribute.experimental.ParameterServerStrategy(cluster_resolver)
A:keras.distribute.distribute_strategy_test.l2_loss->tensorflow.compat.v2.reduce_mean(tf.reduce_sum(tf.square(logits - zero_logits), -1))
A:keras.distribute.distribute_strategy_test.l1_loss->tensorflow.compat.v2.reduce_mean(tf.reduce_sum(tf.abs(logits - one_logits), -1))
A:keras.distribute.distribute_strategy_test.base_model->keras.Sequential([keras.layers.Conv2D(32, kernel_size=5, activation='relu', input_shape=input_shape), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Conv2D(64, kernel_size=5, activation='relu'), keras.layers.MaxPooling2D(pool_size=2), keras.layers.Flatten(), keras.layers.Dense(1024, activation='relu'), keras.layers.Dense(num_classes, name='logits')])
A:keras.distribute.distribute_strategy_test.zero_logits->base_model(tf.zeros_like(inputs))
A:keras.distribute.distribute_strategy_test.one_logits->base_model(tf.ones_like(inputs))
A:keras.distribute.distribute_strategy_test.results->dict(zip(model.metrics_names, results))
A:keras.distribute.distribute_strategy_test.self.x->tensorflow.compat.v2.Variable(tf.ones(shape=()))
A:keras.distribute.distribute_strategy_test.active_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.distribute.distribute_strategy_test.metric_vars->tensorflow.compat.v2.nest.flatten([metric.variables for metric in model.metrics])
A:keras.distribute.distribute_strategy_test.metric->keras.metrics.BinaryAccuracy()
A:keras.distribute.distribute_strategy_test.temp_dir->os.path.join(self.get_temp_dir(), 'ckpt')
A:keras.distribute.distribute_strategy_test.xy->tensorflow.compat.v2.ones(shape=(1, 1))
keras.distribute.distribute_strategy_test.BatchCountingCB(self)
keras.distribute.distribute_strategy_test.BatchCountingCB.__init__(self)
keras.distribute.distribute_strategy_test.BatchCountingCB.on_predict_batch_begin(self,batch,logs=None)
keras.distribute.distribute_strategy_test.BatchCountingCB.on_predict_batch_end(self,batch,logs=None)
keras.distribute.distribute_strategy_test.BatchCountingCB.on_test_batch_begin(self,batch,logs=None)
keras.distribute.distribute_strategy_test.BatchCountingCB.on_test_batch_end(self,batch,logs=None)
keras.distribute.distribute_strategy_test.BatchCountingCB.on_train_batch_begin(self,batch,logs=None)
keras.distribute.distribute_strategy_test.BatchCountingCB.on_train_batch_end(self,batch,logs=None)
keras.distribute.distribute_strategy_test.DeterministicModel(self,strategy)
keras.distribute.distribute_strategy_test.DeterministicModel.__init__(self,strategy)
keras.distribute.distribute_strategy_test.DeterministicModel.build(self,input_shape)
keras.distribute.distribute_strategy_test.DeterministicModel.call(self,inputs,training=None,mask=None)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.testOptimizerWithCallbacks(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_calling_model_on_same_dataset(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_dataset_external_batch_input_validation(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_dataset_with_sample_weights(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_dataset_wrong_input_shape(self,distribution,mode)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_evaluate_with_dataset_with_partial_batch(self,distribution,batch_size)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_fit_eval_and_predict_methods_on_dataset(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_fit_eval_and_predict_methods_on_dataset_without_steps(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_fit_eval_and_predict_with_optimizer(self,distribution,optimizer)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_fit_with_dictionary_in_the_dataset_b135161171(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_fit_with_tuple_and_dict_dataset_inputs(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_learning_phase_value(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_match_model_input_matches_with_dataset_tensors(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_model_interleaved_eval_same_as_direct_eval(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_on_dataset_with_unknown_cardinality(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_on_dataset_with_unknown_cardinality_without_steps(self,distribution,mode)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_predict_multi_output_model_with_dataset_with_partial_batch(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_predict_on_dataset_with_unknown_cardinality_without_steps(self,distribution,mode)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasets.test_predict_with_dataset_with_partial_batch(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasetsFile(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasetsFile.setUp(self)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithDatasetsFile.test_predict_on_dataset_shard_options_file_multi_worker_mirrored(self,distribution,mode)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.DISABLED_test_distribution_strategy_with_callable_add_loss(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_correctness_of_add_loss_with_merge_call(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_custom_gradient_transformation(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distributed_dataset(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distributed_datasets_from_function(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_on_functional_model(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_on_sequential_model(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_one_dimensional(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_with_add_metric_in_call(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_with_add_metric_object(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_with_add_metric_outside_call(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_with_loss_reduction_types(self,distribution,reduction)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_distribution_strategy_with_symbolic_add_loss(self,mode,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_gradient_clipping(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_host_training_loop(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_host_training_loop_dataset_unknown_size(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_host_training_loop_last_partial_execution(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_host_training_loop_truncate_to_epoch(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_ragged_tensor_outputs(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_sparse_tensor_outputs(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithKerasModels.test_unimplemented_parameter_server_strategy(self)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithMultipleAddLossAndMetricCalls(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithMultipleAddLossAndMetricCalls.test_fit_and_evaluate(self,distribution,model_fn,l1,l2)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calculating_input_params_no_steps_no_batch_size(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calculating_input_params_no_steps_with_batch_size(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calculating_input_params_with_steps_no_batch_size(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calculating_input_params_with_steps_with_batch_size(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calling_model_with_mixed_precision(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calling_model_with_nested_numpy_arrays(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_calling_model_with_numpy_arrays(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_evaluate_with_partial_batch(self,distribution,batch_size)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_flatten_predict_outputs(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_gradients_are_none(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_no_target_model(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_numpy_with_sample_weights(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_operator_overload_mixed_precision(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_optimizer_in_cross_replica_context_raises_error(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_predict_multi_output_model_with_partial_batch(self,distribution)
keras.distribute.distribute_strategy_test.TestDistributionStrategyWithNumpyArrays.test_predict_with_partial_batch(self,distribution)
keras.distribute.distribute_strategy_test.TestModelCapturesStrategy(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestModelCapturesStrategy.test_fit_and_evaluate(self,distribution)
keras.distribute.distribute_strategy_test.TestModelCapturesStrategy.test_optimizer(self,distribution)
keras.distribute.distribute_strategy_test.TestRegularizerLoss(tf.test.TestCase,parameterized.TestCase)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.AddLayer(keras.layers.Layer)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.AddLayer.build(self,_)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.AddLayer.call(self,inputs)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.IdentityRegularizer(self,x)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.IdentityRegularizer.__call__(self,x)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.loss_fn(_,y_pred)
keras.distribute.distribute_strategy_test.TestRegularizerLoss.test_regularizer_loss(self,distribution)
keras.distribute.distribute_strategy_test._functional_with_add_loss_and_metric(input_shape,num_classes,l1,l2)
keras.distribute.distribute_strategy_test._functional_with_layer_reuse(input_shape,num_classes,l1,l2)
keras.distribute.distribute_strategy_test._sequential_with_add_loss_and_metric(input_shape,num_classes,l1,l2)
keras.distribute.distribute_strategy_test.all_strategy_combinations()
keras.distribute.distribute_strategy_test.all_strategy_combinations_minus_default()
keras.distribute.distribute_strategy_test.all_strategy_minus_default_and_tpu_combinations()
keras.distribute.distribute_strategy_test.batch_wrapper(dataset,batch_size,distribution,repeat=None)
keras.distribute.distribute_strategy_test.convert_numpy_to_dataset_with_unknown_cardinality(inputs,targets=None)
keras.distribute.distribute_strategy_test.get_dataset(distribution)
keras.distribute.distribute_strategy_test.get_model()
keras.distribute.distribute_strategy_test.get_multi_inputs_multi_outputs_data()
keras.distribute.distribute_strategy_test.get_predict_dataset(distribution)
keras.distribute.distribute_strategy_test.get_sample_weights_model()
keras.distribute.distribute_strategy_test.multi_input_output_model()
keras.distribute.distribute_strategy_test.multi_worker_strategy_combinations_eager_only()
keras.distribute.distribute_strategy_test.simple_multi_inputs_multi_outputs_model()
keras.distribute.distribute_strategy_test.simple_sequential_model()
keras.distribute.distribute_strategy_test.simple_subclassed_model(num_labels=_NUM_CLASS)
keras.distribute.distribute_strategy_test.strategy_and_optimizer_combinations()
keras.distribute.distribute_strategy_test.strategy_minus_tpu_combinations()
keras.distribute.distribute_strategy_test.tpu_strategy_combinations()
keras.distribute.distribute_strategy_test.tpu_strategy_combinations_graph_only()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/strategy_combinations.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_embedding_model_correctness_test.py----------------------------------------
A:keras.distribute.keras_embedding_model_correctness_test.word_ids->keras.layers.Input(shape=(max_words,), dtype=np.int32, name='words')
A:keras.distribute.keras_embedding_model_correctness_test.word_embed->keras.layers.Embedding(input_dim=20, output_dim=10, input_length=max_words, embeddings_initializer=keras.initializers.RandomUniform(0, 1))
A:keras.distribute.keras_embedding_model_correctness_test.avg->keras.layers.GlobalAveragePooling1D()(word_embed)
A:keras.distribute.keras_embedding_model_correctness_test.preds->keras.layers.Dense(2, activation='softmax')(avg)
A:keras.distribute.keras_embedding_model_correctness_test.model->keras.Model(inputs=[word_ids_a, word_ids_b], outputs=[sim])
A:keras.distribute.keras_embedding_model_correctness_test.word_ids_a->keras.layers.Input(shape=(max_words,), dtype=np.int32, name='words_a')
A:keras.distribute.keras_embedding_model_correctness_test.word_ids_b->keras.layers.Input(shape=(max_words,), dtype=np.int32, name='words_b')
A:keras.distribute.keras_embedding_model_correctness_test.rep->keras.layers.GlobalAveragePooling1D()(word_embed)
A:keras.distribute.keras_embedding_model_correctness_test.sim->keras.layers.Dot(axes=1, normalize=True)([a_rep, b_rep])
A:keras.distribute.keras_embedding_model_correctness_test.(features_a, labels_a, _)->super(DistributionStrategySiameseEmbeddingModelCorrectnessTest, self).get_data(count, min_words, max_words, max_word_id, num_classes)
A:keras.distribute.keras_embedding_model_correctness_test.(features_b, labels_b, _)->super(DistributionStrategySiameseEmbeddingModelCorrectnessTest, self).get_data(count, min_words, max_words, max_word_id, num_classes)
A:keras.distribute.keras_embedding_model_correctness_test.y_train->numpy.zeros((count, 1), dtype=np.float32)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategyEmbeddingModelCorrectnessTest(keras_correctness_test_base.TestDistributionStrategyEmbeddingModelCorrectnessBase)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategyEmbeddingModelCorrectnessTest.get_model(self,max_words=10,initial_weights=None,distribution=None,input_shapes=None)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategyEmbeddingModelCorrectnessTest.test_embedding_model_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategyEmbeddingModelCorrectnessTest.test_embedding_time_distributed_model_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategySiameseEmbeddingModelCorrectnessTest(keras_correctness_test_base.TestDistributionStrategyEmbeddingModelCorrectnessBase)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategySiameseEmbeddingModelCorrectnessTest.get_data(self,count=keras_correctness_test_base._GLOBAL_BATCH_SIZE*keras_correctness_test_base._EVAL_STEPS,min_words=5,max_words=10,max_word_id=19,num_classes=2)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategySiameseEmbeddingModelCorrectnessTest.get_model(self,max_words=10,initial_weights=None,distribution=None,input_shapes=None)
keras.distribute.keras_embedding_model_correctness_test.DistributionStrategySiameseEmbeddingModelCorrectnessTest.test_siamese_embedding_model_correctness(self,distribution,use_numpy,use_validation_data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/optimizer_combinations.py----------------------------------------
A:keras.distribute.optimizer_combinations.gradient_descent_optimizer_v1_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('GradientDescentV1', lambda : tf.compat.v1.train.GradientDescentOptimizer(0.001))
A:keras.distribute.optimizer_combinations.adagrad_optimizer_v1_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdagradV1', lambda : tf.compat.v1.train.AdagradOptimizer(0.001))
A:keras.distribute.optimizer_combinations.adam_optimizer_v1_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdamV1', lambda : tf.compat.v1.train.AdamOptimizer(0.001, epsilon=1))
A:keras.distribute.optimizer_combinations.ftrl_optimizer_v1_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('FtrlV1', lambda : tf.compat.v1.train.FtrlOptimizer(0.001))
A:keras.distribute.optimizer_combinations.rmsprop_optimizer_v1_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('RmsPropV1', lambda : tf.compat.v1.train.RMSPropOptimizer(0.001))
A:keras.distribute.optimizer_combinations.adadelta_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdadeltaKerasV2', lambda : adadelta_keras_v2.Adadelta(0.001))
A:keras.distribute.optimizer_combinations.adagrad_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdagradKerasV2', lambda : adagrad_keras_v2.Adagrad(0.001))
A:keras.distribute.optimizer_combinations.adam_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdamKerasV2', lambda : adam_keras_v2.Adam(0.001, epsilon=1.0))
A:keras.distribute.optimizer_combinations.adam_experimental_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdamExperimental', lambda : adam_experimental.Adam(0.001))
A:keras.distribute.optimizer_combinations.adamax_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('AdamaxKerasV2', lambda : adamax_keras_v2.Adamax(0.001, epsilon=1.0))
A:keras.distribute.optimizer_combinations.nadam_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('NadamKerasV2', lambda : nadam_keras_v2.Nadam(0.001, epsilon=1.0))
A:keras.distribute.optimizer_combinations.ftrl_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('FtrlKerasV2', lambda : ftrl_keras_v2.Ftrl(0.001))
A:keras.distribute.optimizer_combinations.gradient_descent_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('GradientDescentKerasV2', lambda : gradient_descent_keras_v2.SGD(0.001))
A:keras.distribute.optimizer_combinations.rmsprop_optimizer_keras_v2_fn->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('RmsPropKerasV2', lambda : rmsprop_keras_v2.RMSprop(0.001))
keras.distribute.optimizer_combinations.distributions_and_v1_and_v2_optimizers()
keras.distribute.optimizer_combinations.distributions_and_v1_optimizers()
keras.distribute.optimizer_combinations.distributions_and_v2_optimizers()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/multi_worker_testing_utils.py----------------------------------------
A:keras.distribute.multi_worker_testing_utils.ASSIGNED_PORTS->set()
A:keras.distribute.multi_worker_testing_utils.lock->threading.Lock()
A:keras.distribute.multi_worker_testing_utils.x_train->tensorflow.compat.v2.ones([batch_size * steps_per_epoch, 28, 28, 1], dtype=tf.float32)
A:keras.distribute.multi_worker_testing_utils.y_train->tensorflow.compat.v2.ones([batch_size * steps_per_epoch, 1], dtype=tf.int32)
A:keras.distribute.multi_worker_testing_utils.train_ds->train_ds.batch(64, drop_remainder=True).batch(64, drop_remainder=True)
A:keras.distribute.multi_worker_testing_utils.x_test->tensorflow.compat.v2.random.uniform([10000, 28, 28, 1], dtype=tf.float32)
A:keras.distribute.multi_worker_testing_utils.y_test->tensorflow.compat.v2.random.uniform([10000, 1], minval=0, maxval=9, dtype=tf.int32)
A:keras.distribute.multi_worker_testing_utils.eval_ds->eval_ds.batch(64, drop_remainder=True).batch(64, drop_remainder=True)
A:keras.distribute.multi_worker_testing_utils.inputs->keras.Input(shape=input_shape)
A:keras.distribute.multi_worker_testing_utils.x->keras.layers.Dense(10, activation='softmax', kernel_initializer=keras.initializers.TruncatedNormal(seed=99))(x)
A:keras.distribute.multi_worker_testing_utils.model->keras.Model(inputs=inputs, outputs=x)
A:keras.distribute.multi_worker_testing_utils.cluster_def->create_in_process_cluster(num_workers=num_workers, num_ps=num_ps, rpc_layer='grpc')
A:keras.distribute.multi_worker_testing_utils.port->portpicker.pick_unused_port()
A:keras.distribute.multi_worker_testing_utils.cs->tensorflow.compat.v2.train.ClusterSpec(cluster_dict)
A:keras.distribute.multi_worker_testing_utils.worker_config->tensorflow.compat.v2.compat.v1.ConfigProto()
A:keras.distribute.multi_worker_testing_utils.ps_config->tensorflow.compat.v2.compat.v1.ConfigProto()
A:keras.distribute.multi_worker_testing_utils.eval_config->tensorflow.compat.v2.compat.v1.ConfigProto()
A:keras.distribute.multi_worker_testing_utils.cluster->_create_cluster(num_workers, num_ps=num_ps, has_chief=has_chief, has_eval=has_eval, worker_config=worker_config, ps_config=ps_config, eval_config=eval_config, protocol=rpc_layer)
keras.distribute.multi_worker_testing_utils._create_cluster(num_workers,num_ps,has_chief=False,has_eval=False,protocol='grpc',worker_config=None,ps_config=None,eval_config=None,worker_name='worker',ps_name='ps',chief_name='chief')
keras.distribute.multi_worker_testing_utils.create_in_process_cluster(num_workers,num_ps,has_chief=False,has_eval=False,rpc_layer='grpc')
keras.distribute.multi_worker_testing_utils.get_mnist_model(input_shape)
keras.distribute.multi_worker_testing_utils.make_parameter_server_cluster(num_workers,num_ps)
keras.distribute.multi_worker_testing_utils.mnist_synthetic_dataset(batch_size,steps_per_epoch)
keras.distribute.multi_worker_testing_utils.pick_unused_port()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/test_example.py----------------------------------------
A:keras.distribute.test_example.dataset->tensorflow.compat.v2.data.Dataset.from_tensors([[1.0]]).repeat()
A:keras.distribute.test_example.layer->keras.legacy_tf_layers.core.Dense(1, use_bias=False)
A:keras.distribute.test_example.optimizer->optimizer_fn()
A:keras.distribute.test_example.batchnorm->keras.legacy_tf_layers.normalization.BatchNormalization(renorm=renorm, momentum=momentum, fused=False)
A:keras.distribute.test_example.y->batchnorm(x, training=True)
A:keras.distribute.test_example.loss->tensorflow.compat.v2.reduce_mean(tf.reduce_sum(layer(y)) - tf.constant(1.0))
keras.distribute.test_example.batchnorm_example(optimizer_fn,batch_per_epoch=1,momentum=0.9,renorm=False,update_ops_in_replica_mode=False)
keras.distribute.test_example.minimize_loss_example(optimizer,use_bias=False,use_callable_loss=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/distributed_training_utils_v1.py----------------------------------------
A:keras.distribute.distributed_training_utils_v1.num_param->len(layer.weights)
A:keras.distribute.distributed_training_utils_v1.all_inputs->flatten_per_replica_values(distribution_strategy, grouped_inputs)
A:keras.distribute.distributed_training_utils_v1.all_outputs->unwrap_outputs(strategy, outputs, with_loss_tensor=mode != ModeKeys.PREDICT)
A:keras.distribute.distributed_training_utils_v1.all_updates->flatten_per_replica_values(distribution_strategy, grouped_updates)
A:keras.distribute.distributed_training_utils_v1.grouped_feed_dict->grouped_session_args.get('feed_dict')
A:keras.distribute.distributed_training_utils_v1.all_session_args['feed_dict']->flatten_per_replica_values(distribution_strategy, grouped_feed_dict)
A:keras.distribute.distributed_training_utils_v1.grouped_fetches->grouped_session_args.get('fetches')
A:keras.distribute.distributed_training_utils_v1.all_session_args['fetches']->flatten_per_replica_values(distribution_strategy, grouped_fetches)
A:keras.distribute.distributed_training_utils_v1.total_loss->strategy.reduce(tf.distribute.ReduceOp.SUM, grouped_outputs['total_loss'][0], axis=None)
A:keras.distribute.distributed_training_utils_v1.output_losses->flatten_per_replica_values(strategy, grouped_outputs['output_losses'])
A:keras.distribute.distributed_training_utils_v1.metrics->flatten_per_replica_values(strategy, grouped_outputs['metrics'])
A:keras.distribute.distributed_training_utils_v1.batch_size->strategy.reduce(tf.distribute.ReduceOp.SUM, grouped_outputs['batch_size'], axis=None)
A:keras.distribute.distributed_training_utils_v1.loss->distribution_strategy.reduce(tf.distribute.ReduceOp.SUM, grouped_outputs[0], axis=None)
A:keras.distribute.distributed_training_utils_v1.x_values_list->validate_per_replica_inputs(distribution_strategy, x)
A:keras.distribute.distributed_training_utils_v1.y_values_list->validate_per_replica_inputs(distribution_strategy, y)
A:keras.distribute.distributed_training_utils_v1.sample_weights_list->validate_per_replica_inputs(distribution_strategy, sample_weights)
A:keras.distribute.distributed_training_utils_v1.per_replica_list->tensorflow.compat.v2.nest.flatten(x, expand_composites=True)
A:keras.distribute.distributed_training_utils_v1.x_values->distribution_strategy.unwrap(x)
A:keras.distribute.distributed_training_utils_v1.x_shape->x_values[0].shape.as_list()
A:keras.distribute.distributed_training_utils_v1.all_variables->keras.backend._get_variables(backend.get_graph())
A:keras.distribute.distributed_training_utils_v1.is_initialized->session.run([tf.compat.v1.is_variable_initialized(v) for v in candidate_vars])
A:keras.distribute.distributed_training_utils_v1.shapes->tensorflow.compat.v2.nest.flatten(tf.compat.v1.data.get_output_shapes(iterator))
A:keras.distribute.distributed_training_utils_v1.num_samples->int(num_samples * (1 - validation_split))
A:keras.distribute.distributed_training_utils_v1.(steps_per_epoch, batch_size)->get_input_params(strategy, num_samples, steps_per_epoch, batch_size, mode=mode)
A:keras.distribute.distributed_training_utils_v1.global_batch_size->min(num_samples, 32)
A:keras.distribute.distributed_training_utils_v1.steps->numpy.ceil(num_samples / global_batch_size).astype(int)
A:keras.distribute.distributed_training_utils_v1.iterator->distribution_strategy.make_dataset_iterator(dataset)
A:keras.distribute.distributed_training_utils_v1.init_op->tensorflow.compat.v2.group(iterator.initializer)
A:keras.distribute.distributed_training_utils_v1.next_element->distribution_strategy.make_dataset_iterator(dataset).get_next()
A:keras.distribute.distributed_training_utils_v1.(inputs, targets, sample_weights)->_get_input_from_iterator(inputs, model)
A:keras.distribute.distributed_training_utils_v1.inputs->keras.engine.training_utils_v1.ModelInputs(inputs).as_list()
A:keras.distribute.distributed_training_utils_v1.targets->tensorflow.compat.v2.nest.flatten(targets)
A:keras.distribute.distributed_training_utils_v1.(inputs, targets)->tensorflow.compat.v2.nest.map_structure(training_utils_v1.standardize_single_array, (inputs, targets))
A:keras.distribute.distributed_training_utils_v1.sample_weights->flatten_per_replica_values(strategy, sample_weights)
A:keras.distribute.distributed_training_utils_v1.updated_model->keras.models._clone_functional_model(model, input_tensors=inputs, layer_fn=models.share_weights)
A:keras.distribute.distributed_training_utils_v1.distributed_model->get_distributed_model(model, mode)
A:keras.distribute.distributed_training_utils_v1.cloned_model->keras.models.clone_model(model, input_tensors=inputs)
A:keras.distribute.distributed_training_utils_v1.optimizer_config->model.optimizer.get_config()
A:keras.distribute.distributed_training_utils_v1.optimizer->model.optimizer.__class__.from_config(optimizer_config)
A:keras.distribute.distributed_training_utils_v1.distributed_function->_make_graph_execution_function(model, mode)
A:keras.distribute.distributed_training_utils_v1.distribution_function->_make_execution_function_without_cloning(model, mode)
A:keras.distribute.distributed_training_utils_v1.per_replica_function->_make_replica_execution_function(model, mode)
A:keras.distribute.distributed_training_utils_v1.(x, y, sample_weights)->input_fn()
A:keras.distribute.distributed_training_utils_v1.outputs->strategy.run(per_replica_function, args=(x, y, sample_weights))
A:keras.distribute.distributed_training_utils_v1.func->functools.partial(func, reset_metrics=False)
A:keras.distribute.distributed_training_utils_v1.f->model._make_execution_function(mode)
A:keras.distribute.distributed_training_utils_v1.(grouped_inputs, grouped_outputs, grouped_updates, grouped_session_args)->strategy.extended.call_for_each_replica(_per_replica_function, args=(get_distributed_model(model, mode),))
A:keras.distribute.distributed_training_utils_v1.(all_inputs, all_outputs, all_updates, all_session_args)->unwrap_values(strategy, grouped_inputs, grouped_outputs, grouped_updates, grouped_session_args, with_loss_tensor=mode != ModeKeys.PREDICT)
A:keras.distribute.distributed_training_utils_v1.global_graph->keras.backend.get_graph()
A:keras.distribute.distributed_training_utils_v1.grouped->strategy.extended.call_for_each_replica(_per_replica_function, args=(get_distributed_model(model, mode),))
A:keras.distribute.distributed_training_utils_v1.(all_inputs, all_outputs, _, _)->unwrap_values(strategy, grouped_inputs, grouped_outputs, with_loss_tensor=mode != ModeKeys.PREDICT)
A:keras.distribute.distributed_training_utils_v1.orig_model_weights->original_model.get_weights()
A:keras.distribute.distributed_training_utils_v1.updated_weights->model._distribution_strategy.unwrap(distributed_model)[0].get_weights()
A:keras.distribute.distributed_training_utils_v1.key->hash(mode)
A:keras.distribute.distributed_training_utils_v1.distributed_model._recompile_exec_function->any([e.sample_weights_mismatch() for e in model._training_endpoints])
A:keras.distribute.distributed_training_utils_v1.distributed_models->flatten_per_replica_values(model._distribution_strategy, distributed_model)
keras.distribute.distributed_training_utils_v1._build_distributed_network(model,strategy,mode,inputs=None,targets=None)
keras.distribute.distributed_training_utils_v1._build_network_on_replica(model,mode,inputs=None,targets=None)
keras.distribute.distributed_training_utils_v1._clone_and_build_model(model,mode,inputs=None,targets=None)
keras.distribute.distributed_training_utils_v1._copy_weights_to_distributed_model(original_model,mode)
keras.distribute.distributed_training_utils_v1._copy_weights_to_original_model(model,mode)
keras.distribute.distributed_training_utils_v1._custom_compile_for_predict(model)
keras.distribute.distributed_training_utils_v1._generate_cache_key(mode)
keras.distribute.distributed_training_utils_v1._get_input_from_iterator(iterator,model)
keras.distribute.distributed_training_utils_v1._make_eager_execution_function(model,mode)
keras.distribute.distributed_training_utils_v1._make_execution_function(model,mode)
keras.distribute.distributed_training_utils_v1._make_execution_function_with_cloning(model,mode)
keras.distribute.distributed_training_utils_v1._make_execution_function_without_cloning(model,mode)
keras.distribute.distributed_training_utils_v1._make_graph_execution_function(model,mode)
keras.distribute.distributed_training_utils_v1._make_replica_execution_function(model,mode)
keras.distribute.distributed_training_utils_v1._make_replicated_models_with_cloning(model,mode)
keras.distribute.distributed_training_utils_v1._per_replica_aggregate_batch(strategy,batch_outs,model,mode)
keras.distribute.distributed_training_utils_v1._prepare_feed_values(model,inputs,targets,sample_weights,mode)
keras.distribute.distributed_training_utils_v1._reset_metrics(model)
keras.distribute.distributed_training_utils_v1._update_sample_weight_modes(model,mode,sample_weights)
keras.distribute.distributed_training_utils_v1._wait_for_variable_initialization(session)
keras.distribute.distributed_training_utils_v1.clone_model_on_replicas(model,strategy,mode,inputs=None,targets=None)
keras.distribute.distributed_training_utils_v1.concat_along_batch_dimension(outputs)
keras.distribute.distributed_training_utils_v1.distributed_scope(strategy,learning_phase)
keras.distribute.distributed_training_utils_v1.filter_distributed_callbacks(callbacks_list,model)
keras.distribute.distributed_training_utils_v1.flatten_per_replica_values(distribution_strategy,per_replica_values)
keras.distribute.distributed_training_utils_v1.get_batch_dimension(iterator)
keras.distribute.distributed_training_utils_v1.get_distributed_function(model,mode)
keras.distribute.distributed_training_utils_v1.get_distributed_model(model,mode)
keras.distribute.distributed_training_utils_v1.get_input_params(distribution_strategy,num_samples,steps,batch_size,mode=None)
keras.distribute.distributed_training_utils_v1.get_iterator(dataset,distribution_strategy)
keras.distribute.distributed_training_utils_v1.init_restore_or_wait_for_variables()
keras.distribute.distributed_training_utils_v1.initialize_iterator(iterator,distribution_strategy)
keras.distribute.distributed_training_utils_v1.is_current_worker_chief()
keras.distribute.distributed_training_utils_v1.is_dataset_shape_fully_defined(dataset)
keras.distribute.distributed_training_utils_v1.is_distributing_by_cloning(model)
keras.distribute.distributed_training_utils_v1.process_batch_and_step_size(strategy,inputs,batch_size,steps_per_epoch,mode,validation_split=0.0)
keras.distribute.distributed_training_utils_v1.set_distributed_function(model,mode,distributed_function)
keras.distribute.distributed_training_utils_v1.set_distributed_model(model,mode,distributed_model)
keras.distribute.distributed_training_utils_v1.set_weights(distribution_strategy,dist_model,weights)
keras.distribute.distributed_training_utils_v1.unwrap_output_dict(strategy,grouped_outputs,mode)
keras.distribute.distributed_training_utils_v1.unwrap_outputs(distribution_strategy,grouped_outputs,with_loss_tensor=False)
keras.distribute.distributed_training_utils_v1.unwrap_values(distribution_strategy,grouped_inputs,grouped_outputs,grouped_updates=None,grouped_session_args=None,with_loss_tensor=False)
keras.distribute.distributed_training_utils_v1.validate_all_tensor_shapes(x,x_values)
keras.distribute.distributed_training_utils_v1.validate_all_tensor_types(x,x_values)
keras.distribute.distributed_training_utils_v1.validate_callbacks(input_callbacks,optimizer)
keras.distribute.distributed_training_utils_v1.validate_distributed_dataset_inputs(distribution_strategy,x,y,sample_weights=None)
keras.distribute.distributed_training_utils_v1.validate_inputs(x,y)
keras.distribute.distributed_training_utils_v1.validate_per_replica_inputs(distribution_strategy,x)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_utils_test.py----------------------------------------
A:keras.distribute.keras_utils_test.self.method_counts->collections.defaultdict(int)
A:keras.distribute.keras_utils_test.model->keras.Model(x, y)
A:keras.distribute.keras_utils_test.dataset->dataset.batch(10, drop_remainder=True).batch(10, drop_remainder=True)
A:keras.distribute.keras_utils_test.counter->Counter()
A:keras.distribute.keras_utils_test.a->tensorflow.compat.v2.constant([1, 2], shape=(1, 2), dtype=tf.int32)
A:keras.distribute.keras_utils_test.b->tensorflow.compat.v2.constant([1, 2], shape=(1, 2), dtype=tf.float64)
A:keras.distribute.keras_utils_test.x->keras.layers.Input(shape=(3,), batch_size=10, name='input')
A:keras.distribute.keras_utils_test.y->keras.layers.Dense(4, name='dense')(x)
A:keras.distribute.keras_utils_test.optimizer->tensorflow.compat.v2.compat.v1.train.GradientDescentOptimizer(0.001)
A:keras.distribute.keras_utils_test.sample_weight->numpy.random.random((10,))
A:keras.distribute.keras_utils_test.self.dense->keras.layers.Dense(num_labels)
A:keras.distribute.keras_utils_test.loss_object->keras.losses.MeanSquaredError()
A:keras.distribute.keras_utils_test.hist->keras.Model(x, y).fit(x=dataset, epochs=1, steps_per_epoch=2)
A:keras.distribute.keras_utils_test.norm->keras.layers.BatchNormalization(input_shape=(10, 20, 30), momentum=0.8, fused=False, renorm=True)
A:keras.distribute.keras_utils_test.predict_dataset->keras.distribute.distribute_strategy_test.batch_wrapper(predict_dataset, 32, distribution)
A:keras.distribute.keras_utils_test.out->keras.Model(x, y).predict(predict_dataset, steps=2)
A:keras.distribute.keras_utils_test.weights_file->tempfile.mktemp()
A:keras.distribute.keras_utils_test.model_2->keras.distribute.distribute_strategy_test.get_model()
A:keras.distribute.keras_utils_test.inputs->numpy.zeros((10, 3), dtype=np.float32)
A:keras.distribute.keras_utils_test.targets->numpy.zeros((10, 4), dtype=np.float32)
keras.distribute.keras_utils_test.Counter(self)
keras.distribute.keras_utils_test.Counter.__init__(self)
keras.distribute.keras_utils_test.Counter.wrap_with_counts(self,method_name,method)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases.test_distribution_strategy_on_deferred_sequential_model(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases.test_distribution_strategy_on_subclassed_model(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases.test_standalone_loss_without_loss_reduction(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases.test_unsupported_features(self,distribution,mode)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases.test_validating_dataset_input_tensors_with_dtype_mismatch(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyErrorCases.test_validating_dataset_input_tensors_with_shape_mismatch(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategySaveLoadWeights(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategySaveLoadWeights.test_save_load_h5(self,distribution,optimizer)
keras.distribute.keras_utils_test.TestDistributionStrategySaveLoadWeights.test_save_load_trackable(self,distribution,optimizer)
keras.distribute.keras_utils_test.TestDistributionStrategyValidation(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategyValidation.test_layer_outside_scope(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyValidation.test_model_outside_scope(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyWithCallbacks(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategyWithCallbacks.test_callbacks_in_eval(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyWithCallbacks.test_callbacks_in_fit(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyWithCallbacks.test_callbacks_in_predict(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyWithLossMasking(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategyWithLossMasking.test_masking(self,distribution,optimizer)
keras.distribute.keras_utils_test.TestDistributionStrategyWithNormalizationLayer(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategyWithNormalizationLayer.test_batchnorm_correctness(self,distribution,fused,optimizer)
keras.distribute.keras_utils_test.TestDistributionStrategyWithNormalizationLayer.test_batchnorm_correctness_with_renorm(self,distribution,optimizer)
keras.distribute.keras_utils_test.TestDistributionStrategyWithStaticShapes(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_utils_test.TestDistributionStrategyWithStaticShapes.test_input_batch_size_not_divisible_by_num_replicas(self,distribution)
keras.distribute.keras_utils_test.TestDistributionStrategyWithStaticShapes.test_static_input_batch_size(self,distribution)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/model_combinations.py----------------------------------------
A:keras.distribute.model_combinations.simple_functional_model->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('SimpleFunctionalModel', simple_models.SimpleFunctionalModel())
A:keras.distribute.model_combinations.simple_sequential_model->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('SimpleSequentialModel', simple_models.SimpleSequentialModel())
A:keras.distribute.model_combinations.simple_subclass_model->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('SimpleSubclassModel', simple_models.SimpleSubclassModel())
A:keras.distribute.model_combinations.simple_tfmodule_model->tensorflow.compat.v2.__internal__.test.combinations.NamedObject('SimpleTFModuleModel', simple_models.SimpleTFModuleModel())


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_dnn_correctness_test.py----------------------------------------
A:keras.distribute.keras_dnn_correctness_test.model->SubclassedModel(initial_weights, input_shapes)
A:keras.distribute.keras_dnn_correctness_test.x_train->numpy.random.rand(9984, 1).astype('float32')
A:keras.distribute.keras_dnn_correctness_test.x_predict->numpy.array([[1.0], [2.0], [3.0], [4.0]], dtype=np.float32)
A:keras.distribute.keras_dnn_correctness_test.x_eval->numpy.random.rand(10000, 1).astype('float32')
A:keras.distribute.keras_dnn_correctness_test.(x_train, y_train, _)->self.get_data()
A:keras.distribute.keras_dnn_correctness_test.batch_size->keras.distribute.keras_correctness_test_base.get_batch_size(batch_size, distribution)
A:keras.distribute.keras_dnn_correctness_test.train_dataset->keras.distribute.keras_correctness_test_base.batch_wrapper(train_dataset, batch_size)
A:keras.distribute.keras_dnn_correctness_test.history->SubclassedModel(initial_weights, input_shapes).fit(x=train_dataset, epochs=2, steps_per_epoch=10)
A:keras.distribute.keras_dnn_correctness_test.x->self.dense3(x)
A:keras.distribute.keras_dnn_correctness_test.y->numpy.zeros((100, 1)).astype('float32')
A:keras.distribute.keras_dnn_correctness_test.dataset->keras.distribute.keras_correctness_test_base.batch_wrapper(dataset, 4)
A:keras.distribute.keras_dnn_correctness_test.outs->SubclassedModel(initial_weights, input_shapes).evaluate(dataset, steps=10)
A:keras.distribute.keras_dnn_correctness_test.self.dense1->keras.layers.Dense(10, activation='relu', input_shape=(1,))
A:keras.distribute.keras_dnn_correctness_test.self.dense2->keras.layers.Dense(10, activation='relu', kernel_regularizer=keras.regularizers.l2(0.0001))
A:keras.distribute.keras_dnn_correctness_test.self.dense3->keras.layers.Dense(10, activation='relu')
A:keras.distribute.keras_dnn_correctness_test.self.dense4->keras.layers.Dense(1)
keras.distribute.keras_dnn_correctness_test.SubclassedModel(self,initial_weights,input_shapes)
keras.distribute.keras_dnn_correctness_test.SubclassedModel.__init__(self,initial_weights,input_shapes)
keras.distribute.keras_dnn_correctness_test.SubclassedModel.call(self,inputs)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness(keras_correctness_test_base.TestDistributionStrategyCorrectnessBase)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.get_data(self)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.get_data_with_partial_last_batch(self)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.get_data_with_partial_last_batch_eval(self)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.get_model(self,initial_weights=None,distribution=None,input_shapes=None)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.test_dnn_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.test_dnn_correctness_with_partial_last_batch(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.test_dnn_correctness_with_partial_last_batch_eval(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectness.test_dnn_with_dynamic_learning_rate(self,distribution)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectnessWithSubclassedModel(TestDistributionStrategyDnnCorrectness)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectnessWithSubclassedModel.get_model(self,initial_weights=None,distribution=None,input_shapes=None)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectnessWithSubclassedModel.test_dnn_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectnessWithSubclassedModel.test_dnn_correctness_with_partial_last_batch_eval(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnCorrectnessWithSubclassedModel.test_dnn_with_dynamic_learning_rate(self,distribution)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricCorrectness(keras_correctness_test_base.TestDistributionStrategyCorrectnessBase)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricCorrectness.get_model(self,distribution=None,input_shapes=None)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricCorrectness.run_metric_correctness_test(self,distribution)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricCorrectness.test_simple_dnn_metric_correctness(self,distribution)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricEvalCorrectness(keras_correctness_test_base.TestDistributionStrategyCorrectnessBase)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricEvalCorrectness.get_model(self,distribution=None,input_shapes=None)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricEvalCorrectness.run_eval_metrics_correctness_test(self,distribution)
keras.distribute.keras_dnn_correctness_test.TestDistributionStrategyDnnMetricEvalCorrectness.test_identity_model_metric_eval_correctness(self,distribution)
keras.distribute.keras_dnn_correctness_test.all_strategy_combinations_with_eager_and_graph_modes()
keras.distribute.keras_dnn_correctness_test.all_strategy_combinations_with_graph_mode()
keras.distribute.keras_dnn_correctness_test.is_default_strategy(strategy)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_correctness_test_base.py----------------------------------------
A:keras.distribute.keras_correctness_test_base.self._scope->self._distribution.scope()
A:keras.distribute.keras_correctness_test_base.dataset->dataset.repeat(repeat).repeat(repeat)
A:keras.distribute.keras_correctness_test_base.shapes->tensorflow.compat.v2.nest.map_structure(lambda x: x.shape, data)
A:keras.distribute.keras_correctness_test_base.batch_size->get_batch_size(global_batch_size, with_distribution)
A:keras.distribute.keras_correctness_test_base.training_data_size->get_data_size(x_train)
A:keras.distribute.keras_correctness_test_base.train_dataset->tensorflow.compat.v2.data.Dataset.from_tensor_slices((x_train, y_train))
A:keras.distribute.keras_correctness_test_base.x->batch_wrapper(eval_dataset, batch_size)
A:keras.distribute.keras_correctness_test_base.steps_per_epoch->int(np.ceil(1.0 * training_data_size / global_batch_size))
A:keras.distribute.keras_correctness_test_base.eval_dataset->tensorflow.compat.v2.data.Dataset.from_tensor_slices((x_eval, y_eval))
A:keras.distribute.keras_correctness_test_base.eval_steps->int(np.ceil(1.0 * get_data_size(x_eval) / global_batch_size))
A:keras.distribute.keras_correctness_test_base.predict_batch_size->get_batch_size(get_data_size(x_predict), with_distribution)
A:keras.distribute.keras_correctness_test_base.predict_dataset->batch_wrapper(predict_dataset, predict_batch_size)
A:keras.distribute.keras_correctness_test_base.(training_inputs, eval_inputs, predict_inputs)->input_fn()
A:keras.distribute.keras_correctness_test_base.model->self.get_model(input_shapes=get_shapes(x_train))
A:keras.distribute.keras_correctness_test_base.result['eval_result_1']->self.get_model(input_shapes=get_shapes(x_train)).evaluate(**eval_inputs)
A:keras.distribute.keras_correctness_test_base.result['weights_1']->self.get_model(input_shapes=get_shapes(x_train)).get_weights()
A:keras.distribute.keras_correctness_test_base.result_key->'predict_result_{}'.format(i)
A:keras.distribute.keras_correctness_test_base.result[result_key]->self.get_model(input_shapes=get_shapes(x_train)).predict(**predict_inputs)
A:keras.distribute.keras_correctness_test_base.result['eval_result_2']->self.get_model(input_shapes=get_shapes(x_train)).evaluate(**eval_inputs)
A:keras.distribute.keras_correctness_test_base.result['weights_2']->self.get_model(input_shapes=get_shapes(x_train)).get_weights()
A:keras.distribute.keras_correctness_test_base.tolerance->_get_compare_result_tolerance(key)
A:keras.distribute.keras_correctness_test_base.x_train->numpy.asarray(features, dtype=np.float32)
A:keras.distribute.keras_correctness_test_base.(x_train, y_train, x_eval, y_eval, x_predict)->self.get_data_with_partial_last_batch()
A:keras.distribute.keras_correctness_test_base.(x_train, y_train, x_predict)->self.get_data()
A:keras.distribute.keras_correctness_test_base.initial_weights->self.get_model(input_shapes=get_shapes(x_train)).get_weights()
A:keras.distribute.keras_correctness_test_base.ds_input_fn->functools.partial(self.get_input_for_dynamic_lr_test, x=x_train, y=y_train, batch_size=ds_batch_size, shuffle=False, epochs=training_epochs, callbacks=[LearningRateBatchScheduler(update_freq)], validation_data=(x_train, y_train))
A:keras.distribute.keras_correctness_test_base.nods_input_fn->functools.partial(self.get_input_for_dynamic_lr_test, x=x_train, y=y_train, batch_size=nods_batch_size, shuffle=False, epochs=training_epochs, callbacks=[LearningRateBatchScheduler(update_freq)], validation_data=(x_train, y_train))
A:keras.distribute.keras_correctness_test_base.results_with_ds->fit_eval_and_predict(initial_weights, input_fn=ds_input_fn, model_fn=self.get_model, distribution=distribution)
A:keras.distribute.keras_correctness_test_base.results_without_ds->fit_eval_and_predict(initial_weights, input_fn=nods_input_fn, model_fn=self.get_model, distribution=None)
A:keras.distribute.keras_correctness_test_base.(x_train, y_train, _)->self.get_data()
A:keras.distribute.keras_correctness_test_base.ds_batch_size->get_batch_size(global_batch_size, distribution)
A:keras.distribute.keras_correctness_test_base.nods_batch_size->get_batch_size(global_batch_size, None)
A:keras.distribute.keras_correctness_test_base.dist->numpy.abs(np.random.randn(max_word_id))
A:keras.distribute.keras_correctness_test_base.word_ids->numpy.random.choice(max_word_id, size=num_words, replace=True, p=distribution[label])
A:keras.distribute.keras_correctness_test_base.features->keras.utils.data_utils.pad_sequences(features, maxlen=max_words)
A:keras.distribute.keras_correctness_test_base.y_train->numpy.asarray(labels, dtype=np.int32).reshape((count, 1))
keras.distribute.keras_correctness_test_base.LearningRateBatchScheduler(self,update_freq=None)
keras.distribute.keras_correctness_test_base.LearningRateBatchScheduler.__init__(self,update_freq=None)
keras.distribute.keras_correctness_test_base.LearningRateBatchScheduler.on_batch_begin(self,batch,logs=None)
keras.distribute.keras_correctness_test_base.MaybeDistributionScope(self,distribution)
keras.distribute.keras_correctness_test_base.MaybeDistributionScope.__enter__(self)
keras.distribute.keras_correctness_test_base.MaybeDistributionScope.__exit__(self,exc_type,value,traceback)
keras.distribute.keras_correctness_test_base.MaybeDistributionScope.__init__(self,distribution)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase(tf.test.TestCase,parameterized.TestCase)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.get_data(self)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.get_data_with_partial_last_batch(self)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.get_data_with_partial_last_batch_eval(self)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.get_input_for_correctness_test(self,**kwargs)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.get_input_for_dynamic_lr_test(self,**kwargs)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.get_model(self,distribution=None,input_shapes=None)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.run_correctness_test(self,distribution,use_numpy,use_validation_data,with_batch_norm=None,is_stateful_model=False,partial_last_batch=None,training_epochs=2)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.run_dynamic_lr_test(self,distribution)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyCorrectnessBase.set_up_test_config(self,use_numpy=False,use_validation_data=False,with_batch_norm=None)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyEmbeddingModelCorrectnessBase(TestDistributionStrategyCorrectnessBase)
keras.distribute.keras_correctness_test_base.TestDistributionStrategyEmbeddingModelCorrectnessBase.get_data(self,count=_GLOBAL_BATCH_SIZE*_EVAL_STEPS,min_words=5,max_words=10,max_word_id=19,num_classes=2)
keras.distribute.keras_correctness_test_base.all_strategy_and_input_config_combinations()
keras.distribute.keras_correctness_test_base.all_strategy_and_input_config_combinations_eager()
keras.distribute.keras_correctness_test_base.batch_wrapper(dataset,batch_size,repeat=None)
keras.distribute.keras_correctness_test_base.compare_results(results_with_ds,results_without_ds,distribution,testcase,partial_last_batch=None)
keras.distribute.keras_correctness_test_base.eager_mode_test_configuration()
keras.distribute.keras_correctness_test_base.fit_eval_and_predict(initial_weights,input_fn,model_fn,distribution=None,is_stateful_model=False)
keras.distribute.keras_correctness_test_base.get_batch_size(global_batch_size,distribution)
keras.distribute.keras_correctness_test_base.get_correctness_test_inputs(use_numpy,use_validation_data,with_distribution,x_train,y_train,x_eval,y_eval,x_predict,training_epochs)
keras.distribute.keras_correctness_test_base.get_data_size(data)
keras.distribute.keras_correctness_test_base.get_shapes(data)
keras.distribute.keras_correctness_test_base.graph_mode_test_configuration()
keras.distribute.keras_correctness_test_base.multi_worker_mirrored_eager()
keras.distribute.keras_correctness_test_base.multi_worker_mirrored_eager_and_graph()
keras.distribute.keras_correctness_test_base.should_skip_tpu_with_eager(distribution)
keras.distribute.keras_correctness_test_base.strategies_for_embedding_models()
keras.distribute.keras_correctness_test_base.strategy_minus_tpu_and_input_config_combinations_eager()
keras.distribute.keras_correctness_test_base.test_combinations_for_embedding_model()
keras.distribute.keras_correctness_test_base.test_combinations_with_tpu_strategies_graph()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/simple_models.py----------------------------------------
A:keras.distribute.simple_models.x_train->tensorflow.compat.v2.constant(np.random.rand(1000, 3), dtype=tf.float32)
A:keras.distribute.simple_models.y_train->tensorflow.compat.v2.constant(np.random.rand(1000, 5), dtype=tf.float32)
A:keras.distribute.simple_models.x_predict->tensorflow.compat.v2.constant(np.random.rand(1000, 3), dtype=tf.float32)
A:keras.distribute.simple_models.x->keras.layers.Input(shape=(3,), dtype=tf.float32)
A:keras.distribute.simple_models.y->keras.layers.Dense(5, dtype=tf.float32, name=output_name, input_dim=3)
A:keras.distribute.simple_models.model->_SimpleModule()
A:keras.distribute.simple_models.optimizer->keras.optimizers.optimizer_v2.gradient_descent.SGD(learning_rate=0.001)
A:keras.distribute.simple_models.self._dense_layer->keras.layers.Dense(5, dtype=tf.float32)
A:keras.distribute.simple_models.self.v->tensorflow.compat.v2.Variable(3.0)
keras.distribute.simple_models.SimpleFunctionalModel(model_collection_base.ModelAndInput)
keras.distribute.simple_models.SimpleFunctionalModel.get_batch_size(self)
keras.distribute.simple_models.SimpleFunctionalModel.get_data(self)
keras.distribute.simple_models.SimpleFunctionalModel.get_model(self,**kwargs)
keras.distribute.simple_models.SimpleSequentialModel(model_collection_base.ModelAndInput)
keras.distribute.simple_models.SimpleSequentialModel.get_batch_size(self)
keras.distribute.simple_models.SimpleSequentialModel.get_data(self)
keras.distribute.simple_models.SimpleSequentialModel.get_model(self,**kwargs)
keras.distribute.simple_models.SimpleSubclassModel(model_collection_base.ModelAndInput)
keras.distribute.simple_models.SimpleSubclassModel.get_batch_size(self)
keras.distribute.simple_models.SimpleSubclassModel.get_data(self)
keras.distribute.simple_models.SimpleSubclassModel.get_model(self,**kwargs)
keras.distribute.simple_models.SimpleTFModuleModel(model_collection_base.ModelAndInput)
keras.distribute.simple_models.SimpleTFModuleModel.get_batch_size(self)
keras.distribute.simple_models.SimpleTFModuleModel.get_data(self)
keras.distribute.simple_models.SimpleTFModuleModel.get_model(self,**kwargs)
keras.distribute.simple_models._SimpleModel(self)
keras.distribute.simple_models._SimpleModel.__init__(self)
keras.distribute.simple_models._SimpleModel.call(self,inputs)
keras.distribute.simple_models._SimpleModule(self)
keras.distribute.simple_models._SimpleModule.__init__(self)
keras.distribute.simple_models._get_data_for_simple_models()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/worker_training_state.py----------------------------------------
A:keras.distribute.worker_training_state.self._ckpt_saved_epoch->tensorflow.compat.v2.Variable(initial_value=tf.constant(CKPT_SAVED_EPOCH_UNUSED_VALUE, dtype=tf.int64), name='ckpt_saved_epoch')
A:keras.distribute.worker_training_state.checkpoint->tensorflow.compat.v2.train.Checkpoint(model=self._model, ckpt_saved_epoch=self._ckpt_saved_epoch, train_counter=self._model._train_counter)
A:keras.distribute.worker_training_state.self.read_checkpoint_manager->tensorflow.compat.v2.train.CheckpointManager(checkpoint, directory=os.path.join(checkpoint_dir, 'chief'), max_to_keep=1)
A:keras.distribute.worker_training_state.write_checkpoint_dir->keras.distribute.distributed_file_utils.write_dirpath(checkpoint_dir, self._model.distribute_strategy)
A:keras.distribute.worker_training_state.self.write_checkpoint_manager->tensorflow.compat.v2.train.CheckpointManager(checkpoint, directory=write_checkpoint_dir, max_to_keep=1)
A:keras.distribute.worker_training_state.epoch->keras.backend.eval(self._ckpt_saved_epoch)
keras.distribute.worker_training_state.WorkerTrainingState(self,model,checkpoint_dir)
keras.distribute.worker_training_state.WorkerTrainingState.__init__(self,model,checkpoint_dir)
keras.distribute.worker_training_state.WorkerTrainingState.back_up(self,epoch)
keras.distribute.worker_training_state.WorkerTrainingState.delete_backup(self)
keras.distribute.worker_training_state.WorkerTrainingState.maybe_load_initial_epoch_from_ckpt(self,initial_epoch,mode)
keras.distribute.worker_training_state.WorkerTrainingState.restore(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/distributed_file_utils.py----------------------------------------
A:keras.distribute.distributed_file_utils.temp_dir->os.path.join(dirpath, _get_base_dirpath(strategy))
A:keras.distribute.distributed_file_utils.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.distribute.distributed_file_utils.dirpath->os.path.dirname(filepath)
A:keras.distribute.distributed_file_utils.base->os.path.basename(filepath)
keras.distribute.distributed_file_utils._get_base_dirpath(strategy)
keras.distribute.distributed_file_utils._get_temp_dir(dirpath,strategy)
keras.distribute.distributed_file_utils._is_temp_dir(dirpath,strategy)
keras.distribute.distributed_file_utils.remove_temp_dir_with_filepath(filepath,strategy)
keras.distribute.distributed_file_utils.remove_temp_dirpath(dirpath,strategy)
keras.distribute.distributed_file_utils.write_dirpath(dirpath,strategy)
keras.distribute.distributed_file_utils.write_filepath(filepath,strategy)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_stateful_lstm_model_correctness_test.py----------------------------------------
A:keras.distribute.keras_stateful_lstm_model_correctness_test.word_ids->keras.layers.Input(shape=(max_words,), batch_size=batch_size, dtype=np.int32, name='words')
A:keras.distribute.keras_stateful_lstm_model_correctness_test.word_embed->keras.layers.Embedding(input_dim=20, output_dim=10)(word_ids)
A:keras.distribute.keras_stateful_lstm_model_correctness_test.lstm_embed->keras.layers.LSTM(units=4, return_sequences=False, stateful=True)(word_embed)
A:keras.distribute.keras_stateful_lstm_model_correctness_test.preds->keras.layers.Dense(2, activation='softmax')(lstm_embed)
A:keras.distribute.keras_stateful_lstm_model_correctness_test.model->keras.Model(inputs=[word_ids], outputs=[preds])
keras.distribute.keras_stateful_lstm_model_correctness_test.DistributionStrategyStatefulLstmModelCorrectnessTest(keras_correctness_test_base.TestDistributionStrategyEmbeddingModelCorrectnessBase)
keras.distribute.keras_stateful_lstm_model_correctness_test.DistributionStrategyStatefulLstmModelCorrectnessTest.disabled_test_stateful_lstm_model_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_stateful_lstm_model_correctness_test.DistributionStrategyStatefulLstmModelCorrectnessTest.get_model(self,max_words=10,initial_weights=None,distribution=None,input_shapes=None)
keras.distribute.keras_stateful_lstm_model_correctness_test.DistributionStrategyStatefulLstmModelCorrectnessTest.test_incorrectly_use_multiple_cores_for_stateful_lstm_model(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_stateful_lstm_model_correctness_test.strategies_for_stateful_embedding_model()
keras.distribute.keras_stateful_lstm_model_correctness_test.test_combinations_for_stateful_embedding_model()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/dataset_creator_model_fit_test_base.py----------------------------------------
A:keras.distribute.dataset_creator_model_fit_test_base.filepath->os.path.join(self.get_temp_dir(), 'vocab')
A:keras.distribute.dataset_creator_model_fit_test_base.lookup_layer->keras.layers.preprocessing.string_lookup.StringLookup(num_oov_indices=1, vocabulary=filepath)
A:keras.distribute.dataset_creator_model_fit_test_base.x->tensorflow.compat.v2.constant([[1.0], [2.0], [3.0], [1.0], [5.0], [1.0]])
A:keras.distribute.dataset_creator_model_fit_test_base.y->tensorflow.compat.v2.random.uniform((10, 1))
A:keras.distribute.dataset_creator_model_fit_test_base.model->keras.engine.sequential.Sequential([core_layers.Dense(10)])
A:keras.distribute.dataset_creator_model_fit_test_base.norm->keras.layers.BatchNormalization(axis=-1, input_shape=(4, 4, 3), momentum=0.8)
A:keras.distribute.dataset_creator_model_fit_test_base.self._accuracy_metric->keras.metrics.Accuracy()
A:keras.distribute.dataset_creator_model_fit_test_base.(model, default_callbacks)->self._model_compile(strategy, steps_per_execution, with_normalization_layer=with_normalization_layer)
A:keras.distribute.dataset_creator_model_fit_test_base.validation_data->self._get_dataset_fn(use_lookup_layer)(None)
A:keras.distribute.dataset_creator_model_fit_test_base.test_data->create_test_data()
A:keras.distribute.dataset_creator_model_fit_test_base.predictions->numpy.around(predictions, 4)
keras.distribute.dataset_creator_model_fit_test_base.DatasetCreatorModelFitTestBase(tf.test.TestCase,parameterized.TestCase)
keras.distribute.dataset_creator_model_fit_test_base.DatasetCreatorModelFitTestBase._get_dataset_fn(self,use_lookup_layer)
keras.distribute.dataset_creator_model_fit_test_base.DatasetCreatorModelFitTestBase._model_compile(self,strategy,steps_per_execution=1,run_eagerly=False,with_normalization_layer=False,jit_compile=None)
keras.distribute.dataset_creator_model_fit_test_base.DatasetCreatorModelFitTestBase._model_evaluate(self,strategy,steps_per_execution=1,x=None,y=None,batch_size=None,steps=10,run_eagerly=False,with_normalization_layer=False,callbacks=None,use_dataset_creator=True)
keras.distribute.dataset_creator_model_fit_test_base.DatasetCreatorModelFitTestBase._model_fit(self,strategy,steps_per_execution=1,validation_data=None,x=None,y=None,shuffle=True,batch_size=None,steps_per_epoch=10,run_eagerly=False,with_normalization_layer=False,callbacks=None,use_lookup_layer=False,use_dataset_creator=True,verbose='auto',jit_compile=None)
keras.distribute.dataset_creator_model_fit_test_base.DatasetCreatorModelFitTestBase._model_predict(self,strategy,model=None,steps_per_execution=1,test_data=None,steps=10,with_normalization_layer=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/saved_model_test_base.py----------------------------------------
A:keras.distribute.saved_model_test_base.func->tensorflow.compat.v2.saved_model.load(saved_dir)
A:keras.distribute.saved_model_test_base.dist_predict_dataset->distribution.experimental_distribute_dataset(predict_dataset)
A:keras.distribute.saved_model_test_base.per_replica_predict_data->next(iter(dist_predict_dataset))
A:keras.distribute.saved_model_test_base.result->tensorflow.compat.v2.saved_model.load(saved_dir).signatures[_DEFAULT_FUNCTION_KEY](next(iter(predict_dataset)))
A:keras.distribute.saved_model_test_base.reduced->distribution.experimental_local_results(result)
A:keras.distribute.saved_model_test_base.concat->tensorflow.compat.v2.concat(reduced, 0)
A:keras.distribute.saved_model_test_base.training_dataset->training_dataset.batch(batch_size).batch(batch_size)
A:keras.distribute.saved_model_test_base.predict_dataset->self._get_predict_dataset(x_predict, batch_size)
A:keras.distribute.saved_model_test_base.saved_dir->os.path.join(self.get_temp_dir(), '3')
A:keras.distribute.saved_model_test_base.model->model_and_input.get_model()
A:keras.distribute.saved_model_test_base.(x_train, y_train, x_predict)->model_and_input.get_data()
A:keras.distribute.saved_model_test_base.batch_size->model_and_input.get_batch_size()
A:keras.distribute.saved_model_test_base.result_before_save->self._predict_with_model(distribution_for_saving, model, predict_dataset)
A:keras.distribute.saved_model_test_base.result_after_save->self._load_and_run_model(distribution=distribution, saved_dir=saved_dir, predict_dataset=predict_dataset)
A:keras.distribute.saved_model_test_base.load_result->self._load_and_run_model(distribution=distribution_for_restoring, saved_dir=saved_dir, predict_dataset=predict_dataset)
A:keras.distribute.saved_model_test_base.(x_train, y_train, _)->model_and_input.get_data()
keras.distribute.saved_model_test_base.TestSavedModelBase(tf.test.TestCase,parameterized.TestCase)
keras.distribute.saved_model_test_base.TestSavedModelBase._get_predict_dataset(self,x_predict,batch_size)
keras.distribute.saved_model_test_base.TestSavedModelBase._load_and_run_model(self,distribution,saved_dir,predict_dataset,output_name='output_1')
keras.distribute.saved_model_test_base.TestSavedModelBase._predict_with_model(self,distribution,model,predict_dataset)
keras.distribute.saved_model_test_base.TestSavedModelBase._save_model(self,model,saved_dir)
keras.distribute.saved_model_test_base.TestSavedModelBase._train_model(self,model,x_train,y_train,batch_size)
keras.distribute.saved_model_test_base.TestSavedModelBase.run_test_save_no_strategy_restore_strategy(self,model_and_input,distribution)
keras.distribute.saved_model_test_base.TestSavedModelBase.run_test_save_strategy(self,model_and_input,distribution,save_in_scope)
keras.distribute.saved_model_test_base.TestSavedModelBase.run_test_save_strategy_restore_no_strategy(self,model_and_input,distribution,save_in_scope)
keras.distribute.saved_model_test_base.TestSavedModelBase.run_test_save_strategy_restore_strategy(self,model_and_input,distribution_for_saving,distribution_for_restoring,save_in_scope)
keras.distribute.saved_model_test_base.TestSavedModelBase.setUp(self)
keras.distribute.saved_model_test_base.load_and_run_with_saved_model_api(distribution,saved_dir,predict_dataset,output_name)
keras.distribute.saved_model_test_base.simple_models_with_strategies()
keras.distribute.saved_model_test_base.simple_models_with_strategy_pairs()
keras.distribute.saved_model_test_base.tfmodule_models_with_strategies()
keras.distribute.saved_model_test_base.tfmodule_models_with_strategy_pairs()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/keras_rnn_model_correctness_test.py----------------------------------------
A:keras.distribute.keras_rnn_model_correctness_test.rnn_cls->self._get_layer_class()
A:keras.distribute.keras_rnn_model_correctness_test.word_ids->keras.layers.Input(shape=(max_words,), dtype=np.int32, name='words')
A:keras.distribute.keras_rnn_model_correctness_test.word_embed->keras.layers.Embedding(input_dim=20, output_dim=10)(word_ids)
A:keras.distribute.keras_rnn_model_correctness_test.rnn_embed->rnn_cls(units=4, return_sequences=False)(word_embed)
A:keras.distribute.keras_rnn_model_correctness_test.dense_output->keras.layers.Dense(2)(rnn_embed)
A:keras.distribute.keras_rnn_model_correctness_test.preds->keras.layers.Softmax(dtype='float32')(dense_output)
A:keras.distribute.keras_rnn_model_correctness_test.model->keras.Model(inputs=[word_ids], outputs=[preds])
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyGruModelCorrectnessTest(_DistributionStrategyRnnModelCorrectnessTest)
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyGruModelCorrectnessTest._get_layer_class(self)
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyGruModelCorrectnessTest.test_gru_model_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyLstmModelCorrectnessTest(_DistributionStrategyRnnModelCorrectnessTest)
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyLstmModelCorrectnessTest._get_layer_class(self)
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyLstmModelCorrectnessTest.test_lstm_model_correctness(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_rnn_model_correctness_test.DistributionStrategyLstmModelCorrectnessTest.test_lstm_model_correctness_mixed_precision(self,distribution,use_numpy,use_validation_data)
keras.distribute.keras_rnn_model_correctness_test._DistributionStrategyRnnModelCorrectnessTest(keras_correctness_test_base.TestDistributionStrategyEmbeddingModelCorrectnessBase)
keras.distribute.keras_rnn_model_correctness_test._DistributionStrategyRnnModelCorrectnessTest._get_layer_class(self)
keras.distribute.keras_rnn_model_correctness_test._DistributionStrategyRnnModelCorrectnessTest.get_model(self,max_words=10,initial_weights=None,distribution=None,input_shapes=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/distribute/model_collection_base.py----------------------------------------
keras.distribute.model_collection_base.ModelAndInput
keras.distribute.model_collection_base.ModelAndInput.get_batch_size(self)
keras.distribute.model_collection_base.ModelAndInput.get_data(self)
keras.distribute.model_collection_base.ModelAndInput.get_model(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/models/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/models/cloning.py----------------------------------------
A:keras.models.cloning.new_nodes->_make_new_nodes({depth: nodes for (depth, nodes) in model._nodes_by_depth.items() if depth < 0}, layer_fn, layer_map, tensor_map)
A:keras.models.cloning.depth_keys->list(nodes_by_depth.keys())
A:keras.models.cloning.new_layer->layer_fn(layer)
A:keras.models.cloning.args->tensorflow.compat.v2.nest.map_structure(lambda t: tensor_map.get(t, t), node.call_args)
A:keras.models.cloning.kwargs->tensorflow.compat.v2.nest.map_structure(lambda t: tensor_map.get(t, t), node.call_kwargs)
A:keras.models.cloning.output_tensors->layer(*args, **kwargs)
A:keras.models.cloning.input_tensors->list(input_tensors)
A:keras.models.cloning.input_tensor->Input(tensor=x, name='input_wrapper_for_' + str(x.name))
A:keras.models.cloning.(model_configs, created_layers)->_clone_layers_and_model_config(model, new_input_layers, layer_fn)
A:keras.models.cloning.(input_tensors, output_tensors, created_layers)->keras.engine.functional.reconstruct_from_config(model_configs, created_layers=created_layers)
A:keras.models.cloning.model->Model(input_tensors, output_tensors, name=model.name)
A:keras.models.cloning.created_layers[layer.name]->layer_fn(layer)
A:keras.models.cloning.config->layer.get_config()
A:keras.models.cloning.(layers, ancillary_layers)->_remove_ancillary_layers(model, layer_map, layers)
A:keras.models.cloning.cloned_model->Sequential(layers=[input_layer] + layers, name=model.name)
A:keras.models.cloning.value->getattr(model, name)
A:keras.models.cloning.original_layers->list(model._flatten_layers(include_self=False, recursive=False))
A:keras.models.cloning.fresh_layer->layer.__class__.from_config(config)
A:keras.models.cloning.attributes_cache[name]->getattr(model, name)
A:keras.models.cloning.compile_args->Model(input_tensors, output_tensors, name=model.name)._get_compile_args()
A:keras.models.cloning.clone->Model(input_tensors, output_tensors, name=model.name).__class__.from_config(model.get_config())
A:keras.models.cloning.optimizer->keras.optimizers.optimizer_v1.TFOptimizer(orig_optimizer.optimizer, optimizer_iterations)
A:keras.models.cloning.compile_args['metrics']->keras.metrics.clone_metrics(compile_args['metrics'])
A:keras.models.cloning.compile_args['weighted_metrics']->keras.metrics.clone_metrics(compile_args['weighted_metrics'])
keras.models._clone_functional_model(model,input_tensors=None,layer_fn=_clone_layer)
keras.models._clone_layer(layer)
keras.models._clone_layers_and_model_config(model,input_layers,layer_fn)
keras.models._clone_sequential_model(model,input_tensors=None,layer_fn=_clone_layer)
keras.models.clone_and_build_model(model,input_tensors=None,target_tensors=None,custom_objects=None,compile_clone=True,in_place_reset=False,optimizer_iterations=None,optimizer_config=None)
keras.models.clone_model(model,input_tensors=None,clone_function=None)
keras.models.cloning._clone_functional_model(model,input_tensors=None,layer_fn=_clone_layer)
keras.models.cloning._clone_layer(layer)
keras.models.cloning._clone_layers_and_model_config(model,input_layers,layer_fn)
keras.models.cloning._clone_sequential_model(model,input_tensors=None,layer_fn=_clone_layer)
keras.models.cloning._in_place_subclassed_model_reset(model)
keras.models.cloning._insert_ancillary_layers(model,ancillary_layers,metrics_names,new_nodes)
keras.models.cloning._make_new_nodes(nodes_by_depth,layer_fn,layer_map,tensor_map)
keras.models.cloning._remove_ancillary_layers(model,layer_map,layers)
keras.models.cloning._reset_build_compile_trackers(model)
keras.models.cloning.clone_and_build_model(model,input_tensors=None,target_tensors=None,custom_objects=None,compile_clone=True,in_place_reset=False,optimizer_iterations=None,optimizer_config=None)
keras.models.cloning.clone_model(model,input_tensors=None,clone_function=None)
keras.models.cloning.in_place_subclassed_model_state_restoration(model)
keras.models.cloning.share_weights(layer)
keras.models.share_weights(layer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/models/sharpness_aware_minimization.py----------------------------------------
A:keras.models.sharpness_aware_minimization.(x, y, sample_weight)->keras.engine.data_adapter.unpack_x_y_sample_weight(data)
A:keras.models.sharpness_aware_minimization.pred->self(x)
A:keras.models.sharpness_aware_minimization.loss->self.compiled_loss(y, pred)
A:keras.models.sharpness_aware_minimization.gradients->tape.gradient(loss, trainable_variables)
A:keras.models.sharpness_aware_minimization.gradients_order2_norm->self._gradients_order2_norm(gradients)
A:keras.models.sharpness_aware_minimization.config->copy.deepcopy(config)
A:keras.models.sharpness_aware_minimization.model->deserialize_layer(config.pop('model'), custom_objects=custom_objects)
A:keras.models.sharpness_aware_minimization.norm->tensorflow.compat.v2.norm(tf.stack([tf.norm(grad) for grad in gradients if grad is not None]))
keras.models.SharpnessAwareMinimization(self,model,rho=0.05,name=None)
keras.models.SharpnessAwareMinimization._gradients_order2_norm(self,gradients)
keras.models.SharpnessAwareMinimization.call(self,inputs)
keras.models.SharpnessAwareMinimization.from_config(cls,config,custom_objects=None)
keras.models.SharpnessAwareMinimization.get_config(self)
keras.models.SharpnessAwareMinimization.train_step(self,data)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization(self,model,rho=0.05,name=None)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization.__init__(self,model,rho=0.05,name=None)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization._gradients_order2_norm(self,gradients)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization.call(self,inputs)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization.from_config(cls,config,custom_objects=None)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization.get_config(self)
keras.models.sharpness_aware_minimization.SharpnessAwareMinimization.train_step(self,data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/mixed_precision/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/mixed_precision/loss_scale_optimizer.py----------------------------------------
A:keras.mixed_precision.loss_scale_optimizer.self._initial_loss_scale->float(initial_loss_scale)
A:keras.mixed_precision.loss_scale_optimizer.self._growth_steps->int(growth_steps)
A:keras.mixed_precision.loss_scale_optimizer.self._multiplier->float(multiplier)
A:keras.mixed_precision.loss_scale_optimizer.self._current_loss_scale->self._add_weight(name='current_loss_scale', dtype=tf.float32, initial_value=self._initial_loss_scale)
A:keras.mixed_precision.loss_scale_optimizer.self._counter->self._add_weight(name='good_steps', dtype=tf.int64, initial_value=0)
A:keras.mixed_precision.loss_scale_optimizer.variable->tensorflow.compat.v2.Variable(initial_value=initial_value, name=name, dtype=dtype, trainable=False, synchronization=tf.VariableSynchronization.AUTO, aggregation=tf.VariableAggregation.NONE)
A:keras.mixed_precision.loss_scale_optimizer.graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.mixed_precision.loss_scale_optimizer.unconditional->super(_DynamicLossScaleState, self)._lookup_dependency(name)
A:keras.mixed_precision.loss_scale_optimizer.grads->self._optimizer.get_gradients(loss, params)
A:keras.mixed_precision.loss_scale_optimizer.distribution->tensorflow.compat.v2.distribute.get_strategy()
A:keras.mixed_precision.loss_scale_optimizer.is_finite_per_replica->tensorflow.compat.v2.distribute.get_strategy().extended.call_for_each_replica(_is_all_finite, args=(grads,))
A:keras.mixed_precision.loss_scale_optimizer.is_finite->_is_all_finite(grads)
A:keras.mixed_precision.loss_scale_optimizer.new_loss_scale->tensorflow.compat.v2.maximum(self.current_loss_scale / self.multiplier, 1)
A:keras.mixed_precision.loss_scale_optimizer.update_op->tensorflow.compat.v2.cond(is_finite, update_if_finite_grads, update_if_not_finite_grads)
A:keras.mixed_precision.loss_scale_optimizer.self._loss_scale->float(initial_scale)
A:keras.mixed_precision.loss_scale_optimizer.loss_val->loss()
A:keras.mixed_precision.loss_scale_optimizer.loss->self.get_scaled_loss(loss)
A:keras.mixed_precision.loss_scale_optimizer.grads_and_vars->tuple(grads_and_vars)
A:keras.mixed_precision.loss_scale_optimizer.unscaled_grads->self.get_unscaled_gradients(grads)
A:keras.mixed_precision.loss_scale_optimizer.wrapped_vars->_UnwrapPreventer([v for (_, v) in grads_and_vars])
A:keras.mixed_precision.loss_scale_optimizer.(loss_scale_update_op, should_apply_grads)->_if_should_apply_grads(grads)
A:keras.mixed_precision.loss_scale_optimizer.maybe_apply_op->tensorflow.compat.v2.__internal__.smart_cond.smart_cond(should_apply_grads, apply_fn, do_not_apply_fn)
A:keras.mixed_precision.loss_scale_optimizer.serialized_optimizer->keras.optimizers.serialize(self._optimizer)
A:keras.mixed_precision.loss_scale_optimizer.config->config.copy().copy()
A:keras.mixed_precision.loss_scale_optimizer.loss_scale->keras.utils.generic_utils.deserialize_keras_object(config.pop('loss_scale'), module_objects={'FixedLossScale': tf.compat.v1.mixed_precision.FixedLossScale, 'DynamicLossScale': tf.compat.v1.mixed_precision.DynamicLossScale}, printable_module_name='loss scale')
A:keras.mixed_precision.loss_scale_optimizer.config['inner_optimizer']->config.copy().copy().pop('optimizer')
A:keras.mixed_precision.loss_scale_optimizer.inner_optimizer->keras.optimizers.deserialize(config['inner_optimizer'], custom_objects=custom_objects)
A:keras.mixed_precision.loss_scale_optimizer.result->set(super(LossScaleOptimizer, self).__dir__())
A:keras.mixed_precision.loss_scale_optimizer.(_, should_apply_grad)->self._loss_scale.update(grads)
A:keras.mixed_precision.loss_scale_optimizer.should_apply_grads->_if_should_apply_grads(grads)
A:keras.mixed_precision.loss_scale_optimizer.scale->tensorflow.compat.v2.cast(scale, gradient.dtype)
A:keras.mixed_precision.loss_scale_optimizer.strategy->tensorflow.compat.v2.distribute.get_strategy()
keras.mixed_precision.LossScaleOptimizer(self,inner_optimizer,dynamic=True,initial_scale=None,dynamic_growth_steps=None)
keras.mixed_precision.LossScaleOptimizer.__dir__(self)
keras.mixed_precision.LossScaleOptimizer.__getattribute__(self,name)
keras.mixed_precision.LossScaleOptimizer.__setattr__(self,name,value)
keras.mixed_precision.LossScaleOptimizer._aggregate_gradients(self,grads_and_vars)
keras.mixed_precision.LossScaleOptimizer._apply_gradients(self,grads,wrapped_vars,name)
keras.mixed_precision.LossScaleOptimizer._compute_gradients(self,loss,var_list,grad_loss=None,tape=None)
keras.mixed_precision.LossScaleOptimizer._create_all_weights(self,var_list)
keras.mixed_precision.LossScaleOptimizer._create_or_restore_slot_variable(self,slot_variable_position,slot_name,variable)
keras.mixed_precision.LossScaleOptimizer._restore_slot_variable(self,slot_name,variable,slot_variable)
keras.mixed_precision.LossScaleOptimizer.add_slot(self,var,slot_name,initializer='zeros')
keras.mixed_precision.LossScaleOptimizer.apply_gradients(self,grads_and_vars,name=None,experimental_aggregate_gradients=True)
keras.mixed_precision.LossScaleOptimizer.clipnorm(self)
keras.mixed_precision.LossScaleOptimizer.clipnorm(self,val)
keras.mixed_precision.LossScaleOptimizer.clipvalue(self)
keras.mixed_precision.LossScaleOptimizer.clipvalue(self,val)
keras.mixed_precision.LossScaleOptimizer.dynamic(self)
keras.mixed_precision.LossScaleOptimizer.dynamic_counter(self)
keras.mixed_precision.LossScaleOptimizer.dynamic_growth_steps(self)
keras.mixed_precision.LossScaleOptimizer.from_config(cls,config,custom_objects=None)
keras.mixed_precision.LossScaleOptimizer.get_config(self)
keras.mixed_precision.LossScaleOptimizer.get_gradients(self,loss,params)
keras.mixed_precision.LossScaleOptimizer.get_scaled_loss(self,loss)
keras.mixed_precision.LossScaleOptimizer.get_slot(self,var,slot_name)
keras.mixed_precision.LossScaleOptimizer.get_slot_names(self)
keras.mixed_precision.LossScaleOptimizer.get_unscaled_gradients(self,grads)
keras.mixed_precision.LossScaleOptimizer.get_weights(self)
keras.mixed_precision.LossScaleOptimizer.global_clipnorm(self)
keras.mixed_precision.LossScaleOptimizer.global_clipnorm(self,val)
keras.mixed_precision.LossScaleOptimizer.initial_scale(self)
keras.mixed_precision.LossScaleOptimizer.inner_optimizer(self)
keras.mixed_precision.LossScaleOptimizer.iterations(self)
keras.mixed_precision.LossScaleOptimizer.iterations(self,variable)
keras.mixed_precision.LossScaleOptimizer.learning_rate(self)
keras.mixed_precision.LossScaleOptimizer.learning_rate(self,value)
keras.mixed_precision.LossScaleOptimizer.loss_scale(self)
keras.mixed_precision.LossScaleOptimizer.lr(self)
keras.mixed_precision.LossScaleOptimizer.lr(self,value)
keras.mixed_precision.LossScaleOptimizer.set_weights(self,weights)
keras.mixed_precision.LossScaleOptimizer.variables(self)
keras.mixed_precision.LossScaleOptimizer.weights(self)
keras.mixed_precision.LossScaleOptimizerMetaclass(cls,inner_optimizer,*args,**kwargs)
keras.mixed_precision.LossScaleOptimizerV3(self,inner_optimizer,dynamic=True,initial_scale=None,dynamic_growth_steps=None)
keras.mixed_precision.LossScaleOptimizerV3._apply_gradients(self,grads,wrapped_vars)
keras.mixed_precision.LossScaleOptimizerV3.apply_gradients(self,grads_and_vars,skip_gradients_aggregation=False)
keras.mixed_precision.LossScaleOptimizerV3.compute_gradients(self,loss,var_list,tape=None)
keras.mixed_precision.LossScaleOptimizerV3.dynamic(self)
keras.mixed_precision.LossScaleOptimizerV3.dynamic_counter(self)
keras.mixed_precision.LossScaleOptimizerV3.dynamic_growth_steps(self)
keras.mixed_precision.LossScaleOptimizerV3.from_config(cls,config,custom_objects=None)
keras.mixed_precision.LossScaleOptimizerV3.get_config(self)
keras.mixed_precision.LossScaleOptimizerV3.get_scaled_loss(self,loss)
keras.mixed_precision.LossScaleOptimizerV3.get_unscaled_gradients(self,grads)
keras.mixed_precision.LossScaleOptimizerV3.initial_scale(self)
keras.mixed_precision.LossScaleOptimizerV3.inner_optimizer(self)
keras.mixed_precision.LossScaleOptimizerV3.iterations(self)
keras.mixed_precision.LossScaleOptimizerV3.learning_rate(self)
keras.mixed_precision.LossScaleOptimizerV3.learning_rate(self,learning_rate)
keras.mixed_precision.LossScaleOptimizerV3.loss_scale(self)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer(metaclass=LossScaleOptimizerMetaclass)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.dynamic(self)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.dynamic_counter(self)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.dynamic_growth_steps(self)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.get_scaled_loss(self,loss)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.get_unscaled_gradients(self,grads)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.initial_scale(self)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.inner_optimizer(self)
keras.mixed_precision.loss_scale_optimizer.BaseLossScaleOptimizer.loss_scale(self)
keras.mixed_precision.loss_scale_optimizer.FakeOptimizerForRestoration(self,optimizer)
keras.mixed_precision.loss_scale_optimizer.FakeOptimizerForRestoration.__init__(self,optimizer)
keras.mixed_precision.loss_scale_optimizer.FakeOptimizerForRestoration._create_or_restore_slot_variable(self,slot_variable_position,slot_name,variable)
keras.mixed_precision.loss_scale_optimizer.FakeOptimizerForRestoration.get_slot_names(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer(self,inner_optimizer,dynamic=True,initial_scale=None,dynamic_growth_steps=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.__dir__(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.__getattribute__(self,name)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.__init__(self,inner_optimizer,dynamic=True,initial_scale=None,dynamic_growth_steps=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.__setattr__(self,name,value)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer._aggregate_gradients(self,grads_and_vars)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer._apply_gradients(self,grads,wrapped_vars,name)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer._compute_gradients(self,loss,var_list,grad_loss=None,tape=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer._create_all_weights(self,var_list)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer._create_or_restore_slot_variable(self,slot_variable_position,slot_name,variable)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer._restore_slot_variable(self,slot_name,variable,slot_variable)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.add_slot(self,var,slot_name,initializer='zeros')
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.apply_gradients(self,grads_and_vars,name=None,experimental_aggregate_gradients=True)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.clipnorm(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.clipnorm(self,val)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.clipvalue(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.clipvalue(self,val)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.dynamic(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.dynamic_counter(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.dynamic_growth_steps(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.from_config(cls,config,custom_objects=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_config(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_gradients(self,loss,params)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_scaled_loss(self,loss)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_slot(self,var,slot_name)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_slot_names(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_unscaled_gradients(self,grads)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.get_weights(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.global_clipnorm(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.global_clipnorm(self,val)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.initial_scale(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.inner_optimizer(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.iterations(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.iterations(self,variable)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.learning_rate(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.learning_rate(self,value)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.loss_scale(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.lr(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.lr(self,value)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.set_weights(self,weights)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.variables(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizer.weights(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerMetaclass(cls,inner_optimizer,*args,**kwargs)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerMetaclass.__call__(cls,inner_optimizer,*args,**kwargs)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3(self,inner_optimizer,dynamic=True,initial_scale=None,dynamic_growth_steps=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.__init__(self,inner_optimizer,dynamic=True,initial_scale=None,dynamic_growth_steps=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3._apply_gradients(self,grads,wrapped_vars)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.apply_gradients(self,grads_and_vars,skip_gradients_aggregation=False)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.compute_gradients(self,loss,var_list,tape=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.dynamic(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.dynamic_counter(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.dynamic_growth_steps(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.from_config(cls,config,custom_objects=None)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.get_config(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.get_scaled_loss(self,loss)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.get_unscaled_gradients(self,grads)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.initial_scale(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.inner_optimizer(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.iterations(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.learning_rate(self)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.learning_rate(self,learning_rate)
keras.mixed_precision.loss_scale_optimizer.LossScaleOptimizerV3.loss_scale(self)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState(self,initial_loss_scale,growth_steps,multiplier)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.__init__(self,initial_loss_scale,growth_steps,multiplier)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState._add_weight(self,name,initial_value,dtype=None)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState._lookup_dependency(self,name)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState._trackable_children(self,save_type='checkpoint',**kwargs)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.counter(self)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.current_loss_scale(self)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.growth_steps(self)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.initial_loss_scale(self)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.multiplier(self)
keras.mixed_precision.loss_scale_optimizer._DynamicLossScaleState.update(self,grads)
keras.mixed_precision.loss_scale_optimizer._UnwrapPreventer(self,value)
keras.mixed_precision.loss_scale_optimizer._UnwrapPreventer.__init__(self,value)
keras.mixed_precision.loss_scale_optimizer._assign_if_finite(var,value)
keras.mixed_precision.loss_scale_optimizer._create_loss_scale_optimizer_from_v1_loss_scale(optimizer,loss_scale)
keras.mixed_precision.loss_scale_optimizer._is_all_finite(grads)
keras.mixed_precision.loss_scale_optimizer._maybe_warn_about_scaling(loss_has_been_scaled,gradients_have_been_unscaled)
keras.mixed_precision.loss_scale_optimizer._multiply_gradient(gradient,scale)
keras.mixed_precision.loss_scale_optimizer._op_in_graph_mode(tensor)
keras.mixed_precision.loss_scale_optimizer._raise_if_strategy_unsupported()
keras.mixed_precision.loss_scale_optimizer.strategy_supports_loss_scaling()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/mixed_precision/device_compatibility_check.py----------------------------------------
A:keras.mixed_precision.device_compatibility_check.num->len(list(vals))
A:keras.mixed_precision.device_compatibility_check.name->details.get('device_name', 'Unknown GPU')
A:keras.mixed_precision.device_compatibility_check.cc->details.get('compute_capability')
A:keras.mixed_precision.device_compatibility_check.gpus->tensorflow.compat.v2.config.list_physical_devices('GPU')
keras.mixed_precision.device_compatibility_check._dedup_strings(device_strs)
keras.mixed_precision.device_compatibility_check._log_device_compatibility_check(policy_name,gpu_details_list)
keras.mixed_precision.device_compatibility_check.log_device_compatibility_check(policy_name)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/mixed_precision/test_util.py----------------------------------------
A:keras.mixed_precision.test_util.x->tensorflow.compat.v2.identity(x)
A:keras.mixed_precision.test_util.expected_tensor->tensorflow.compat.v2.convert_to_tensor(expected_gradient, dtype=dx.dtype, name='expected_gradient')
A:keras.mixed_precision.test_util.assert_op->tensorflow.compat.v2.compat.v1.assert_equal(dx, expected_tensor)
A:keras.mixed_precision.test_util.dx->tensorflow.compat.v2.identity(dx)
A:keras.mixed_precision.test_util.inputs_flattened->tensorflow.compat.v2.nest.flatten(inputs)
A:keras.mixed_precision.test_util.self._regularizer->keras.regularizers.deserialize(regularizer, custom_objects=globals())
A:keras.mixed_precision.test_util.self._activity_regularizer->keras.regularizers.deserialize(activity_regularizer, custom_objects=globals())
A:keras.mixed_precision.test_util.self.v->self.add_weight('v', (), initializer='ones', dtype=dtype, experimental_autocast=False, regularizer=self._regularizer)
A:keras.mixed_precision.test_util.config->super(MultiplyLayer, self).get_config()
A:keras.mixed_precision.test_util.config['regularizer']->keras.regularizers.serialize(self._regularizer)
A:keras.mixed_precision.test_util.config['activity_regularizer']->keras.regularizers.serialize(self._activity_regularizer)
keras.mixed_precision.test_util.AssertTypeLayer(self,assert_type=None,**kwargs)
keras.mixed_precision.test_util.AssertTypeLayer.__init__(self,assert_type=None,**kwargs)
keras.mixed_precision.test_util.AssertTypeLayer.assert_input_types(self,inputs)
keras.mixed_precision.test_util.IdentityRegularizer(self,x)
keras.mixed_precision.test_util.IdentityRegularizer.__call__(self,x)
keras.mixed_precision.test_util.IdentityRegularizer.get_config(self)
keras.mixed_precision.test_util.MultiplyLayer(self,regularizer=None,activity_regularizer=None,use_operator=False,var_name='v',**kwargs)
keras.mixed_precision.test_util.MultiplyLayer.__init__(self,regularizer=None,activity_regularizer=None,use_operator=False,var_name='v',**kwargs)
keras.mixed_precision.test_util.MultiplyLayer._multiply(self,x,y)
keras.mixed_precision.test_util.MultiplyLayer.build(self,_)
keras.mixed_precision.test_util.MultiplyLayer.call(self,inputs)
keras.mixed_precision.test_util.MultiplyLayer.get_config(self)
keras.mixed_precision.test_util.MultiplyLayerWithoutAutoCast(MultiplyLayer)
keras.mixed_precision.test_util.MultiplyLayerWithoutAutoCast.build(self,_)
keras.mixed_precision.test_util.MultiplyLayerWithoutAutoCast.call(self,inputs)
keras.mixed_precision.test_util.ReduceSumRegularizer(self,x)
keras.mixed_precision.test_util.ReduceSumRegularizer.__call__(self,x)
keras.mixed_precision.test_util.ReduceSumRegularizer.get_config(self)
keras.mixed_precision.test_util.create_identity_with_grad_check_fn(expected_gradient,expected_dtype=None)
keras.mixed_precision.test_util.create_identity_with_nan_gradients_fn(have_nan_gradients)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/mixed_precision/policy.py----------------------------------------
A:keras.mixed_precision.policy.(self._compute_dtype, self._variable_dtype)->self._parse_name(name)
A:keras.mixed_precision.policy.config->config.copy().copy()
A:keras.mixed_precision.policy.policy->Policy(policy)
keras.mixed_precision.Policy(self,name)
keras.mixed_precision.Policy.__repr__(self)
keras.mixed_precision.Policy._parse_name(self,name)
keras.mixed_precision.Policy.compute_dtype(self)
keras.mixed_precision.Policy.from_config(cls,config,custom_objects=None)
keras.mixed_precision.Policy.get_config(self)
keras.mixed_precision.Policy.name(self)
keras.mixed_precision.Policy.variable_dtype(self)
keras.mixed_precision.global_policy()
keras.mixed_precision.policy.Policy(self,name)
keras.mixed_precision.policy.Policy.__init__(self,name)
keras.mixed_precision.policy.Policy.__repr__(self)
keras.mixed_precision.policy.Policy._parse_name(self,name)
keras.mixed_precision.policy.Policy.compute_dtype(self)
keras.mixed_precision.policy.Policy.from_config(cls,config,custom_objects=None)
keras.mixed_precision.policy.Policy.get_config(self)
keras.mixed_precision.policy.Policy.name(self)
keras.mixed_precision.policy.Policy.variable_dtype(self)
keras.mixed_precision.policy._check_if_mixed_precision_graph_rewrite_is_enabled(policy)
keras.mixed_precision.policy._is_convertible_to_dtype(dtype)
keras.mixed_precision.policy._policy_equivalent_to_dtype(policy)
keras.mixed_precision.policy.deserialize(config,custom_objects=None)
keras.mixed_precision.policy.global_policy()
keras.mixed_precision.policy.policy_scope(policy)
keras.mixed_precision.policy.serialize(policy)
keras.mixed_precision.policy.set_global_policy(policy)
keras.mixed_precision.set_global_policy(policy)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/mixed_precision/autocast_variable.py----------------------------------------
A:keras.mixed_precision.autocast_variable._autocast_dtype->threading.local()
A:keras.mixed_precision.autocast_variable.autocast_dtype->getattr(_autocast_dtype, 'dtype', None)
A:keras.mixed_precision.autocast_variable.dtype->getattr(_autocast_dtype, 'dtype', None)
A:keras.mixed_precision.autocast_variable.val->tensorflow.compat.v2.convert_to_tensor(self._variable, dtype=self._variable.dtype, name=name)
A:keras.mixed_precision.autocast_variable.assign_op->update_fn(value, use_locking, name, False)
A:keras.mixed_precision.autocast_variable.var->create_autocast_variable(self._variable)
A:keras.mixed_precision.autocast_variable.assign_var->update_fn(value, use_locking, name, read_value)
A:keras.mixed_precision.autocast_variable.update_var->update_fn(*args, **kwargs)
A:keras.mixed_precision.autocast_variable.graph_element->self._variable._as_graph_element()
A:keras.mixed_precision.autocast_variable.(obj_map, resource_map)->self._variable._map_resources(save_options)
A:keras.mixed_precision.autocast_variable.self._prev_dtype->getattr(_autocast_dtype, 'dtype', None)
keras.mixed_precision.autocast_variable.AutoCastVariable(self,variable)
keras.mixed_precision.autocast_variable.AutoCastVariable.__abs__(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.__add__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__div__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__floordiv__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__ge__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__getattr__(self,name)
keras.mixed_precision.autocast_variable.AutoCastVariable.__getitem__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__gt__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__init__(self,variable)
keras.mixed_precision.autocast_variable.AutoCastVariable.__le__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__lt__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__matmul__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__mod__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__mul__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__neg__(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.__pow__(self,o,modulo=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.__radd__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rdiv__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__repr__(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rfloordiv__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rmatmul__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rmod__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rmul__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rpow__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rsub__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__rtruediv__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__sub__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable.__truediv__(self,o)
keras.mixed_precision.autocast_variable.AutoCastVariable._apply_assign_update(self,update_fn,value,use_locking=None,name=None,read_value=True)
keras.mixed_precision.autocast_variable.AutoCastVariable._apply_update(self,update_fn,*args,**kwargs)
keras.mixed_precision.autocast_variable.AutoCastVariable._as_graph_element(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._cast_dtype(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._dense_var_to_tensor(self,dtype=None,name=None,as_ref=False)
keras.mixed_precision.autocast_variable.AutoCastVariable._gather_saveables_for_checkpoint(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._handle_name(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._handle_name(self,handle_name)
keras.mixed_precision.autocast_variable.AutoCastVariable._initializer_op(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._initializer_op(self,initializer_op)
keras.mixed_precision.autocast_variable.AutoCastVariable._map_resources(self,save_options)
keras.mixed_precision.autocast_variable.AutoCastVariable._shared_name(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._should_act_as_resource_variable(self)
keras.mixed_precision.autocast_variable.AutoCastVariable._should_cast(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.aggregation(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.assign(self,value,use_locking=None,name=None,read_value=True)
keras.mixed_precision.autocast_variable.AutoCastVariable.assign_add(self,delta,use_locking=None,name=None,read_value=True)
keras.mixed_precision.autocast_variable.AutoCastVariable.assign_sub(self,delta,use_locking=None,name=None,read_value=True)
keras.mixed_precision.autocast_variable.AutoCastVariable.batch_scatter_update(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.constraint(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.device(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.dtype(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.eval(self,session=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.from_proto(self,variable_def,import_scope=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.gather_nd(self,indices,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.get_shape(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.graph(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.initial_value(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.initialized_value(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.initializer(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.load(self,value,session=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.name(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.op(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.read_value(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_add(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_div(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_max(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_min(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_mul(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_nd_add(self,indices,updates,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_nd_sub(self,indices,updates,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_nd_update(self,indices,updates,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_sub(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.scatter_update(self,sparse_delta,use_locking=False,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.set_shape(self,shape)
keras.mixed_precision.autocast_variable.AutoCastVariable.shape(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.sparse_read(self,indices,name=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.synchronization(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.to_proto(self,export_scope=None)
keras.mixed_precision.autocast_variable.AutoCastVariable.trainable(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.true_dtype(self)
keras.mixed_precision.autocast_variable.AutoCastVariable.value(self)
keras.mixed_precision.autocast_variable.create_autocast_variable(variable)
keras.mixed_precision.autocast_variable.enable_auto_cast_variables(self,dtype)
keras.mixed_precision.autocast_variable.enable_auto_cast_variables.__enter__(self)
keras.mixed_precision.autocast_variable.enable_auto_cast_variables.__exit__(self,type_arg,value_arg,traceback_arg)
keras.mixed_precision.autocast_variable.enable_auto_cast_variables.__init__(self,dtype)
keras.mixed_precision.autocast_variable.numpy_text(tensor,is_repr=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/kernelized_utils.py----------------------------------------
A:keras.utils.kernelized_utils.u_rank->len(u.shape)
A:keras.utils.kernelized_utils.x_matrix->_to_matrix(x)
A:keras.utils.kernelized_utils.y_matrix->_to_matrix(y)
A:keras.utils.kernelized_utils.x_tile->tensorflow.compat.v2.tile(tf.expand_dims(x_matrix, 1), [1, y_shape[0], 1])
A:keras.utils.kernelized_utils.y_tile->tensorflow.compat.v2.tile(tf.expand_dims(y_matrix, 0), [x_shape[0], 1, 1])
A:keras.utils.kernelized_utils.u->_to_matrix(u)
A:keras.utils.kernelized_utils.v->_to_matrix(v)
A:keras.utils.kernelized_utils.(x_aligned, y_aligned)->_align_matrices(x, y)
A:keras.utils.kernelized_utils.diff_squared_l2_norm->tensorflow.compat.v2.reduce_sum(tf.math.squared_difference(x_aligned, y_aligned), 2)
A:keras.utils.kernelized_utils.diff_l1_norm->tensorflow.compat.v2.reduce_sum(tf.abs(tf.subtract(x_aligned, y_aligned)), 2)
keras.utils.kernelized_utils._align_matrices(x,y)
keras.utils.kernelized_utils._to_matrix(u)
keras.utils.kernelized_utils.exact_gaussian_kernel(x,y,stddev)
keras.utils.kernelized_utils.exact_laplacian_kernel(x,y,stddev)
keras.utils.kernelized_utils.inner_product(u,v)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/mode_keys.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/vis_utils.py----------------------------------------
A:keras.utils.vis_utils.dot->model_to_dot(model, show_shapes=show_shapes, show_dtype=show_dtype, show_layer_names=show_layer_names, rankdir=rankdir, expand_nested=expand_nested, dpi=dpi, layer_range=layer_range, show_layer_activations=show_layer_activations)
A:keras.utils.vis_utils.layer_range->get_layer_index_bound_by_layer_name(model, layer_range)
A:keras.utils.vis_utils.node->pydot.Node(layer_id, label=label)
A:keras.utils.vis_utils.layer_id->str(id(layer))
A:keras.utils.vis_utils.submodel_wrapper->model_to_dot(layer.layer, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, subgraph=True)
A:keras.utils.vis_utils.sub_w_nodes->model_to_dot(layer.layer, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, subgraph=True).get_nodes()
A:keras.utils.vis_utils.layer_name->'{}({})'.format(layer_name, layer.layer.name)
A:keras.utils.vis_utils.class_name->'{}({})'.format(class_name, child_class_name)
A:keras.utils.vis_utils.submodel_not_wrapper->model_to_dot(layer, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, subgraph=True)
A:keras.utils.vis_utils.sub_n_nodes->model_to_dot(layer, show_shapes, show_dtype, show_layer_names, rankdir, expand_nested, subgraph=True).get_nodes()
A:keras.utils.vis_utils.activation_name->str(layer.activation)
A:keras.utils.vis_utils.outputlabels->format_shape(layer.output_shape)
A:keras.utils.vis_utils.inputlabels->', '.join([format_shape(ishape) for ishape in layer.input_shapes])
A:keras.utils.vis_utils.inbound_layer_id->str(id(inbound_layer))
A:keras.utils.vis_utils.name->sub_n_last_node[inbound_layer.name].get_name()
A:keras.utils.vis_utils.output_name->sub_n_first_node[layer.name].get_name()
A:keras.utils.vis_utils.to_file->keras.utils.io_utils.path_to_string(to_file)
A:keras.utils.vis_utils.(_, extension)->os.path.splitext(to_file)
keras.utils.model_to_dot(model,show_shapes=False,show_dtype=False,show_layer_names=True,rankdir='TB',expand_nested=False,dpi=96,subgraph=False,layer_range=None,show_layer_activations=False)
keras.utils.plot_model(model,to_file='model.png',show_shapes=False,show_dtype=False,show_layer_names=True,rankdir='TB',expand_nested=False,dpi=96,layer_range=None,show_layer_activations=False)
keras.utils.vis_utils.add_edge(dot,src,dst)
keras.utils.vis_utils.check_pydot()
keras.utils.vis_utils.get_layer_index_bound_by_layer_name(model,layer_names)
keras.utils.vis_utils.is_wrapped_model(layer)
keras.utils.vis_utils.model_to_dot(model,show_shapes=False,show_dtype=False,show_layer_names=True,rankdir='TB',expand_nested=False,dpi=96,subgraph=False,layer_range=None,show_layer_activations=False)
keras.utils.vis_utils.plot_model(model,to_file='model.png',show_shapes=False,show_dtype=False,show_layer_names=True,rankdir='TB',expand_nested=False,dpi=96,layer_range=None,show_layer_activations=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/keras_logging.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/object_identity.py----------------------------------------
A:keras.utils.object_identity.unwrapped->property()
A:keras.utils.object_identity.keys->list(self._storage)
A:keras.utils.object_identity.self._storage->set((self._wrap_key(obj) for obj in list(*args)))
A:keras.utils.object_identity.result->ObjectIdentitySet()
keras.utils.object_identity.ObjectIdentityDictionary(self)
keras.utils.object_identity.ObjectIdentityDictionary.__delitem__(self,key)
keras.utils.object_identity.ObjectIdentityDictionary.__getitem__(self,key)
keras.utils.object_identity.ObjectIdentityDictionary.__init__(self)
keras.utils.object_identity.ObjectIdentityDictionary.__iter__(self)
keras.utils.object_identity.ObjectIdentityDictionary.__len__(self)
keras.utils.object_identity.ObjectIdentityDictionary.__repr__(self)
keras.utils.object_identity.ObjectIdentityDictionary.__setitem__(self,key,value)
keras.utils.object_identity.ObjectIdentityDictionary._wrap_key(self,key)
keras.utils.object_identity.ObjectIdentitySet(self,*args)
keras.utils.object_identity.ObjectIdentitySet.__contains__(self,key)
keras.utils.object_identity.ObjectIdentitySet.__init__(self,*args)
keras.utils.object_identity.ObjectIdentitySet.__iter__(self)
keras.utils.object_identity.ObjectIdentitySet.__len__(self)
keras.utils.object_identity.ObjectIdentitySet._from_storage(storage)
keras.utils.object_identity.ObjectIdentitySet._wrap_key(self,key)
keras.utils.object_identity.ObjectIdentitySet.add(self,key)
keras.utils.object_identity.ObjectIdentitySet.clear(self)
keras.utils.object_identity.ObjectIdentitySet.difference(self,items)
keras.utils.object_identity.ObjectIdentitySet.discard(self,key)
keras.utils.object_identity.ObjectIdentitySet.intersection(self,items)
keras.utils.object_identity.ObjectIdentitySet.update(self,items)
keras.utils.object_identity.ObjectIdentityWeakKeyDictionary(ObjectIdentityDictionary)
keras.utils.object_identity.ObjectIdentityWeakKeyDictionary.__iter__(self)
keras.utils.object_identity.ObjectIdentityWeakKeyDictionary.__len__(self)
keras.utils.object_identity.ObjectIdentityWeakKeyDictionary._wrap_key(self,key)
keras.utils.object_identity.ObjectIdentityWeakSet(ObjectIdentitySet)
keras.utils.object_identity.ObjectIdentityWeakSet.__iter__(self)
keras.utils.object_identity.ObjectIdentityWeakSet.__len__(self)
keras.utils.object_identity.ObjectIdentityWeakSet._wrap_key(self,key)
keras.utils.object_identity.Reference(_ObjectIdentityWrapper)
keras.utils.object_identity.Reference.deref(self)
keras.utils.object_identity._ObjectIdentityWrapper(self,wrapped)
keras.utils.object_identity._ObjectIdentityWrapper.__eq__(self,other)
keras.utils.object_identity._ObjectIdentityWrapper.__gt__(self,other)
keras.utils.object_identity._ObjectIdentityWrapper.__hash__(self)
keras.utils.object_identity._ObjectIdentityWrapper.__init__(self,wrapped)
keras.utils.object_identity._ObjectIdentityWrapper.__lt__(self,other)
keras.utils.object_identity._ObjectIdentityWrapper.__ne__(self,other)
keras.utils.object_identity._ObjectIdentityWrapper.__repr__(self)
keras.utils.object_identity._ObjectIdentityWrapper._assert_type(self,other)
keras.utils.object_identity._ObjectIdentityWrapper.unwrapped(self)
keras.utils.object_identity._WeakObjectIdentityWrapper(self,wrapped)
keras.utils.object_identity._WeakObjectIdentityWrapper.__init__(self,wrapped)
keras.utils.object_identity._WeakObjectIdentityWrapper.unwrapped(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/generic_utils.py----------------------------------------
A:keras.utils.generic_utils.self.backup->_GLOBAL_CUSTOM_OBJECTS.copy()
A:keras.utils.generic_utils.SHARED_OBJECT_DISABLED->threading.local()
A:keras.utils.generic_utils.SHARED_OBJECT_LOADING->threading.local()
A:keras.utils.generic_utils.SHARED_OBJECT_SAVING->threading.local()
A:keras.utils.generic_utils.self._orig_loading_scope->_shared_object_loading_scope()
A:keras.utils.generic_utils.self._orig_saving_scope->_shared_object_saving_scope()
A:keras.utils.generic_utils.SHARED_OBJECT_LOADING.scope->NoopLoadingScope()
A:keras.utils.generic_utils.self._shared_objects_config->weakref.WeakKeyDictionary()
A:keras.utils.generic_utils.shared_object_config->_shared_object_saving_scope().get_config(obj)
A:keras.utils.generic_utils.(_, instance)->tensorflow.compat.v2.__internal__.decorator.unwrap(instance)
A:keras.utils.generic_utils.name->get_registered_name(instance.__class__)
A:keras.utils.generic_utils.config->instance.get_config()
A:keras.utils.generic_utils.serialized_item->serialize_keras_object(item)
A:keras.utils.generic_utils.cls->get_registered_object(class_name, custom_objects, module_objects)
A:keras.utils.generic_utils.deserialized_objects[key]->get_registered_object(item, custom_objects)
A:keras.utils.generic_utils.(cls, cls_config)->class_and_config_for_serialized_keras_object(config, module_objects, custom_objects, printable_module_name)
A:keras.utils.generic_utils.shared_object_id->instance.get_config().get(SHARED_OBJECT_KEY)
A:keras.utils.generic_utils.shared_object->_shared_object_loading_scope().get(shared_object_id)
A:keras.utils.generic_utils.arg_spec->keras.utils.tf_inspect.getfullargspec(fn)
A:keras.utils.generic_utils.deserialized_obj->cls(**cls_config)
A:keras.utils.generic_utils.obj->getattr(module, name)
A:keras.utils.generic_utils.raw_code->marshal.loads(raw_code).encode('raw_unicode_escape')
A:keras.utils.generic_utils.code->marshal.loads(raw_code)
A:keras.utils.generic_utils.closure->tuple((ensure_value_to_cell(_) for _ in closure))
A:keras.utils.generic_utils.defaults->tuple(defaults)
A:keras.utils.generic_utils.globs->globals()
A:keras.utils.generic_utils.self.stateful_metrics->self.stateful_metrics.union(stateful_metrics)
A:keras.utils.generic_utils.self._start->time.time()
A:keras.utils.generic_utils.value_base->max(current - self._seen_so_far, 1)
A:keras.utils.generic_utils.now->time.time()
A:keras.utils.generic_utils.prog_width->int(self.width * prog)
A:keras.utils.generic_utils.self._total_width->len(bar)
A:keras.utils.generic_utils.time_per_unit->self._estimate_step_duration(current, now)
A:keras.utils.generic_utils.avg->numpy.mean(self._values[k][0] / max(1, self._values[k][1]))
A:keras.utils.generic_utils.num_batches->int(np.ceil(size / float(batch_size)))
A:keras.utils.generic_utils.start->start.tolist().tolist()
A:keras.utils.generic_utils.intermediate->re.sub('(.)([A-Z][a-z]+)', '\\1_\\2', name)
A:keras.utils.generic_utils.insecure->re.sub('([a-z])([A-Z])', '\\1_\\2', intermediate).lower()
A:keras.utils.generic_utils.iterable->tensorflow.compat.v2.nest.flatten(structure)
A:keras.utils.generic_utils.unknown->set(input_dict.keys()).difference(expected_values)
A:keras.utils.generic_utils.module->self._load()
keras.utils.CustomObjectScope(self,*args)
keras.utils.CustomObjectScope.__enter__(self)
keras.utils.CustomObjectScope.__exit__(self,*args,**kwargs)
keras.utils.Progbar(self,target,width=30,verbose=1,interval=0.05,stateful_metrics=None,unit_name='step')
keras.utils.Progbar._estimate_step_duration(self,current,now)
keras.utils.Progbar._format_time(self,time_per_unit,unit_name)
keras.utils.Progbar._update_stateful_metrics(self,stateful_metrics)
keras.utils.Progbar.add(self,n,values=None)
keras.utils.Progbar.update(self,current,values=None,finalize=None)
keras.utils.deserialize_keras_object(identifier,module_objects=None,custom_objects=None,printable_module_name='object')
keras.utils.generic_utils.CustomMaskWarning(Warning)
keras.utils.generic_utils.CustomObjectScope(self,*args)
keras.utils.generic_utils.CustomObjectScope.__enter__(self)
keras.utils.generic_utils.CustomObjectScope.__exit__(self,*args,**kwargs)
keras.utils.generic_utils.CustomObjectScope.__init__(self,*args)
keras.utils.generic_utils.DisableSharedObjectScope
keras.utils.generic_utils.DisableSharedObjectScope.__enter__(self)
keras.utils.generic_utils.DisableSharedObjectScope.__exit__(self,*args,**kwargs)
keras.utils.generic_utils.LazyLoader(self,local_name,parent_module_globals,name)
keras.utils.generic_utils.LazyLoader.__getattr__(self,item)
keras.utils.generic_utils.LazyLoader.__init__(self,local_name,parent_module_globals,name)
keras.utils.generic_utils.LazyLoader._load(self)
keras.utils.generic_utils.NoopLoadingScope
keras.utils.generic_utils.NoopLoadingScope.get(self,unused_object_id)
keras.utils.generic_utils.NoopLoadingScope.set(self,object_id,obj)
keras.utils.generic_utils.Progbar(self,target,width=30,verbose=1,interval=0.05,stateful_metrics=None,unit_name='step')
keras.utils.generic_utils.Progbar.__init__(self,target,width=30,verbose=1,interval=0.05,stateful_metrics=None,unit_name='step')
keras.utils.generic_utils.Progbar._estimate_step_duration(self,current,now)
keras.utils.generic_utils.Progbar._format_time(self,time_per_unit,unit_name)
keras.utils.generic_utils.Progbar._update_stateful_metrics(self,stateful_metrics)
keras.utils.generic_utils.Progbar.add(self,n,values=None)
keras.utils.generic_utils.Progbar.update(self,current,values=None,finalize=None)
keras.utils.generic_utils.SharedObjectConfig(self,base_config,object_id,**kwargs)
keras.utils.generic_utils.SharedObjectConfig.__init__(self,base_config,object_id,**kwargs)
keras.utils.generic_utils.SharedObjectConfig.increment_ref_count(self)
keras.utils.generic_utils.SharedObjectLoadingScope
keras.utils.generic_utils.SharedObjectLoadingScope.__enter__(self)
keras.utils.generic_utils.SharedObjectLoadingScope.__exit__(self,*args,**kwargs)
keras.utils.generic_utils.SharedObjectLoadingScope.get(self,object_id)
keras.utils.generic_utils.SharedObjectLoadingScope.set(self,object_id,obj)
keras.utils.generic_utils.SharedObjectSavingScope
keras.utils.generic_utils.SharedObjectSavingScope.__enter__(self)
keras.utils.generic_utils.SharedObjectSavingScope.__exit__(self,*args,**kwargs)
keras.utils.generic_utils.SharedObjectSavingScope.create_config(self,base_config,obj)
keras.utils.generic_utils.SharedObjectSavingScope.get_config(self,obj)
keras.utils.generic_utils._shared_object_disabled()
keras.utils.generic_utils._shared_object_loading_scope()
keras.utils.generic_utils._shared_object_saving_scope()
keras.utils.generic_utils.check_for_unexpected_keys(name,input_dict,expected_values)
keras.utils.generic_utils.class_and_config_for_serialized_keras_object(config,module_objects=None,custom_objects=None,printable_module_name='object')
keras.utils.generic_utils.default(method)
keras.utils.generic_utils.deserialize_keras_object(identifier,module_objects=None,custom_objects=None,printable_module_name='object')
keras.utils.generic_utils.func_dump(func)
keras.utils.generic_utils.func_load(code,defaults=None,closure=None,globs=None)
keras.utils.generic_utils.get_custom_objects()
keras.utils.generic_utils.get_custom_objects_by_name(item,custom_objects=None)
keras.utils.generic_utils.get_registered_name(obj)
keras.utils.generic_utils.get_registered_object(name,custom_objects=None,module_objects=None)
keras.utils.generic_utils.has_arg(fn,name,accept_all=False)
keras.utils.generic_utils.is_all_none(structure)
keras.utils.generic_utils.is_default(method)
keras.utils.generic_utils.make_batches(size,batch_size)
keras.utils.generic_utils.populate_dict_with_module_objects(target_dict,modules,obj_filter)
keras.utils.generic_utils.register_keras_serializable(package='Custom',name=None)
keras.utils.generic_utils.serialize_keras_class_and_config(cls_name,cls_config,obj=None,shared_object_id=None)
keras.utils.generic_utils.serialize_keras_object(instance)
keras.utils.generic_utils.skip_failed_serialization()
keras.utils.generic_utils.slice_arrays(arrays,start=None,stop=None)
keras.utils.generic_utils.to_list(x)
keras.utils.generic_utils.to_snake_case(name)
keras.utils.generic_utils.validate_config(config)
keras.utils.generic_utils.validate_kwargs(kwargs,allowed_kwargs,error_message='Keywordargumentnotunderstood:')
keras.utils.get_custom_objects()
keras.utils.get_custom_objects_by_name(item,custom_objects=None)
keras.utils.serialize_keras_object(instance)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/io_utils.py----------------------------------------
A:keras.utils.io_utils.INTERACTIVE_LOGGING->threading.local()
A:keras.utils.io_utils.overwrite->input('Enter "y" (overwrite) or "n" (cancel).').strip().lower()
keras.utils.io_utils.ask_to_proceed_with_overwrite(filepath)
keras.utils.io_utils.disable_interactive_logging()
keras.utils.io_utils.enable_interactive_logging()
keras.utils.io_utils.is_interactive_logging_enabled()
keras.utils.io_utils.path_to_string(path)
keras.utils.io_utils.print_msg(message,line_break=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/image_utils.py----------------------------------------
A:keras.utils.image_utils.img->img.resize(width_height_tuple, resample).resize(width_height_tuple, resample)
A:keras.utils.image_utils.shape->tensorflow.compat.v2.shape(img)
A:keras.utils.image_utils.crop_height->min(height, crop_height)
A:keras.utils.image_utils.crop_width->min(width, crop_width)
A:keras.utils.image_utils.crop_box_hstart->tensorflow.compat.v2.cast(tf.cast(height - crop_height, 'float32') / 2, 'int32')
A:keras.utils.image_utils.crop_box_wstart->tensorflow.compat.v2.cast(tf.cast(width - crop_width, 'float32') / 2, 'int32')
A:keras.utils.image_utils.crop_box_start->tensorflow.compat.v2.stack([crop_box_hstart, crop_box_wstart, 0])
A:keras.utils.image_utils.crop_box_size->tensorflow.compat.v2.stack([crop_height, crop_width, -1])
A:keras.utils.image_utils.interpolation->interpolation.lower().lower()
A:keras.utils.image_utils.data_format->keras.backend.image_data_format()
A:keras.utils.image_utils.dtype->keras.backend.floatx()
A:keras.utils.image_utils.x->x.reshape((x.shape[0], x.shape[1], 1)).reshape((x.shape[0], x.shape[1], 1))
A:keras.utils.image_utils.x_max->numpy.max(x)
A:keras.utils.image_utils.path->str(path.resolve())
keras.utils.array_to_img(x,data_format=None,scale=True,dtype=None)
keras.utils.image_utils.array_to_img(x,data_format=None,scale=True,dtype=None)
keras.utils.image_utils.get_interpolation(interpolation)
keras.utils.image_utils.img_to_array(img,data_format=None,dtype=None)
keras.utils.image_utils.load_img(path,grayscale=False,color_mode='rgb',target_size=None,interpolation='nearest',keep_aspect_ratio=False)
keras.utils.image_utils.save_img(path,x,data_format=None,file_format=None,scale=True,**kwargs)
keras.utils.image_utils.smart_resize(x,size,interpolation='bilinear')
keras.utils.img_to_array(img,data_format=None,dtype=None)
keras.utils.load_img(path,grayscale=False,color_mode='rgb',target_size=None,interpolation='nearest',keep_aspect_ratio=False)
keras.utils.save_img(path,x,data_format=None,file_format=None,scale=True,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/layer_utils.py----------------------------------------
A:keras.utils.layer_utils.previous_sources->get_source_inputs(tensor, layer, node_index)
A:keras.utils.layer_utils.unique_weights->{id(w): w for w in weights}.values()
A:keras.utils.layer_utils.nodes_by_depth->model._nodes_by_depth.values()
A:keras.utils.layer_utils.cutoff->min(candidate_cutoffs)
A:keras.utils.layer_utils.params->layer.count_params()
A:keras.utils.layer_utils.trainable_count->count_params(model.trainable_weights)
A:keras.utils.layer_utils.non_trainable_count->count_params(model.non_trainable_weights)
A:keras.utils.layer_utils.(kernel, bias)->dense.get_weights()
A:keras.utils.layer_utils.ki->numpy.transpose(ki, (1, 2, 0))
A:keras.utils.layer_utils.kernel[:, i]->numpy.reshape(ki, (np.prod(previous_feature_map_shape),))
A:keras.utils.layer_utils.cache->weakref.WeakKeyDictionary()
A:keras.utils.layer_utils.output->weakref.WeakKeyDictionary().get(item)
A:keras.utils.layer_utils.cache[item]output->f(item)
A:keras.utils.layer_utils.existing->set()
A:keras.utils.layer_utils.obj->to_visit.pop()
keras.utils.get_source_inputs(tensor,layer=None,node_index=None)
keras.utils.layer_utils.cached_per_instance(f)
keras.utils.layer_utils.convert_dense_weights_data_format(dense,previous_feature_map_shape,target_data_format='channels_first')
keras.utils.layer_utils.count_params(weights)
keras.utils.layer_utils.filter_empty_layer_containers(layer_list)
keras.utils.layer_utils.get_source_inputs(tensor,layer=None,node_index=None)
keras.utils.layer_utils.is_builtin_layer(layer)
keras.utils.layer_utils.print_summary(model,line_length=None,positions=None,print_fn=None,expand_nested=False,show_trainable=False)
keras.utils.layer_utils.validate_string_arg(input_data,allowable_strings,layer_name,arg_name,allow_none=False,allow_callables=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/data_utils.py----------------------------------------
A:keras.utils.data_utils.content_type->urlopen(url, data).info().get('Content-Length')
A:keras.utils.data_utils.total_size->int(content_type.strip())
A:keras.utils.data_utils.chunk->urlopen(url, data).read(chunk_size)
A:keras.utils.data_utils.response->urlopen(url, data)
A:keras.utils.data_utils.file_path->keras.utils.io_utils.path_to_string(file_path)
A:keras.utils.data_utils.path->keras.utils.io_utils.path_to_string(path)
A:keras.utils.data_utils.cache_dir->os.path.join(os.path.expanduser('~'), '.keras')
A:keras.utils.data_utils.datadir_base->os.path.join('/tmp', '.keras')
A:keras.utils.data_utils.datadir->os.path.join(datadir_base, cache_subdir)
A:keras.utils.data_utils.fname->str(fname)
A:keras.utils.data_utils.untar_fpath->os.path.join(datadir, fname)
A:keras.utils.data_utils.fpath->os.path.join(datadir, fname)
A:keras.utils.data_utils.self.progbar->Progbar(total_size)
A:keras.utils.data_utils.hasher->_resolve_hasher(algorithm, file_hash)
A:keras.utils.data_utils.self.lock->threading.Lock()
A:keras.utils.data_utils._DATA_POOLS->weakref.WeakSet()
A:keras.utils.data_utils._WORKER_IDS->set()
A:keras.utils.data_utils._FORCE_THREADPOOL_LOCK->threading.RLock()
A:keras.utils.data_utils.out->f(*args, **kwargs)
A:keras.utils.data_utils._WORKER_ID_QUEUE->multiprocessing.Queue()
A:keras.utils.data_utils._SEQUENCE_COUNTER->multiprocessing.Value('i', 0)
A:keras.utils.data_utils.self.executor_fn->self._get_executor_init(workers)
A:keras.utils.data_utils.self.queue->queue.Queue(max_queue_size)
A:keras.utils.data_utils.self.stop_signal->threading.Event()
A:keras.utils.data_utils.self.run_thread->threading.Thread(target=self._run)
A:keras.utils.data_utils.pool->get_pool_class(True)(workers, initializer=init_pool_generator, initargs=(seqs, self.random_seed, get_worker_id_queue()))
A:keras.utils.data_utils.sequence->list(range(len(self.sequence)))
A:keras.utils.data_utils.inputs->self.queue.get(block=True).get()
A:keras.utils.data_utils.worker_proc->multiprocessing.current_process()
A:keras.utils.data_utils.worker_proc.name->'Keras_worker_{}'.format(worker_proc.name)
A:keras.utils.data_utils.num_samples->len(sequences)
A:keras.utils.data_utils.maxlen->numpy.max(lengths)
A:keras.utils.data_utils.x->numpy.full((num_samples, maxlen) + sample_shape, value, dtype=dtype)
A:keras.utils.data_utils.trunc->numpy.asarray(trunc, dtype=dtype)
keras.utils.GeneratorEnqueuer(self,generator,use_multiprocessing=False,random_seed=None)
keras.utils.GeneratorEnqueuer._get_executor_init(self,workers)
keras.utils.GeneratorEnqueuer._run(self)
keras.utils.GeneratorEnqueuer.get(self)
keras.utils.OrderedEnqueuer(self,sequence,use_multiprocessing=False,shuffle=False)
keras.utils.OrderedEnqueuer._get_executor_init(self,workers)
keras.utils.OrderedEnqueuer._run(self)
keras.utils.OrderedEnqueuer._wait_queue(self)
keras.utils.OrderedEnqueuer.get(self)
keras.utils.Sequence
keras.utils.Sequence.__getitem__(self,index)
keras.utils.Sequence.__iter__(self)
keras.utils.Sequence.__len__(self)
keras.utils.Sequence.on_epoch_end(self)
keras.utils.SequenceEnqueuer(self,sequence,use_multiprocessing=False)
keras.utils.SequenceEnqueuer.__del__(self)
keras.utils.SequenceEnqueuer._get_executor_init(self,workers)
keras.utils.SequenceEnqueuer._run(self)
keras.utils.SequenceEnqueuer._send_sequence(self)
keras.utils.SequenceEnqueuer.get(self)
keras.utils.SequenceEnqueuer.is_running(self)
keras.utils.SequenceEnqueuer.start(self,workers=1,max_queue_size=10)
keras.utils.SequenceEnqueuer.stop(self,timeout=None)
keras.utils.data_utils.GeneratorEnqueuer(self,generator,use_multiprocessing=False,random_seed=None)
keras.utils.data_utils.GeneratorEnqueuer.__init__(self,generator,use_multiprocessing=False,random_seed=None)
keras.utils.data_utils.GeneratorEnqueuer._get_executor_init(self,workers)
keras.utils.data_utils.GeneratorEnqueuer._run(self)
keras.utils.data_utils.GeneratorEnqueuer.get(self)
keras.utils.data_utils.OrderedEnqueuer(self,sequence,use_multiprocessing=False,shuffle=False)
keras.utils.data_utils.OrderedEnqueuer.__init__(self,sequence,use_multiprocessing=False,shuffle=False)
keras.utils.data_utils.OrderedEnqueuer._get_executor_init(self,workers)
keras.utils.data_utils.OrderedEnqueuer._run(self)
keras.utils.data_utils.OrderedEnqueuer._wait_queue(self)
keras.utils.data_utils.OrderedEnqueuer.get(self)
keras.utils.data_utils.Sequence
keras.utils.data_utils.Sequence.__getitem__(self,index)
keras.utils.data_utils.Sequence.__iter__(self)
keras.utils.data_utils.Sequence.__len__(self)
keras.utils.data_utils.Sequence.on_epoch_end(self)
keras.utils.data_utils.SequenceEnqueuer(self,sequence,use_multiprocessing=False)
keras.utils.data_utils.SequenceEnqueuer.__del__(self)
keras.utils.data_utils.SequenceEnqueuer.__init__(self,sequence,use_multiprocessing=False)
keras.utils.data_utils.SequenceEnqueuer._get_executor_init(self,workers)
keras.utils.data_utils.SequenceEnqueuer._run(self)
keras.utils.data_utils.SequenceEnqueuer._send_sequence(self)
keras.utils.data_utils.SequenceEnqueuer.get(self)
keras.utils.data_utils.SequenceEnqueuer.is_running(self)
keras.utils.data_utils.SequenceEnqueuer.start(self,workers=1,max_queue_size=10)
keras.utils.data_utils.SequenceEnqueuer.stop(self,timeout=None)
keras.utils.data_utils.ThreadsafeIter(self,it)
keras.utils.data_utils.ThreadsafeIter.__init__(self,it)
keras.utils.data_utils.ThreadsafeIter.__iter__(self)
keras.utils.data_utils.ThreadsafeIter.__next__(self)
keras.utils.data_utils.ThreadsafeIter.next(self)
keras.utils.data_utils._extract_archive(file_path,path='.',archive_format='auto')
keras.utils.data_utils._hash_file(fpath,algorithm='sha256',chunk_size=65535)
keras.utils.data_utils._makedirs_exist_ok(datadir)
keras.utils.data_utils._resolve_hasher(algorithm,file_hash=None)
keras.utils.data_utils.dont_use_multiprocessing_pool(f)
keras.utils.data_utils.get_file(fname=None,origin=None,untar=False,md5_hash=None,file_hash=None,cache_subdir='datasets',hash_algorithm='auto',extract=False,archive_format='auto',cache_dir=None)
keras.utils.data_utils.get_index(uid,i)
keras.utils.data_utils.get_pool_class(use_multiprocessing)
keras.utils.data_utils.get_worker_id_queue()
keras.utils.data_utils.init_pool(seqs)
keras.utils.data_utils.init_pool_generator(gens,random_seed=None,id_queue=None)
keras.utils.data_utils.is_generator_or_sequence(x)
keras.utils.data_utils.iter_sequence_infinite(seq)
keras.utils.data_utils.next_sample(uid)
keras.utils.data_utils.pad_sequences(sequences,maxlen=None,dtype='int32',padding='pre',truncating='pre',value=0.0)
keras.utils.data_utils.threadsafe_generator(f)
keras.utils.data_utils.validate_file(fpath,file_hash,algorithm='auto',chunk_size=65535)
keras.utils.get_file(fname=None,origin=None,untar=False,md5_hash=None,file_hash=None,cache_subdir='datasets',hash_algorithm='auto',extract=False,archive_format='auto',cache_dir=None)
keras.utils.pad_sequences(sequences,maxlen=None,dtype='int32',padding='pre',truncating='pre',value=0.0)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/control_flow_util.py----------------------------------------
A:keras.utils.control_flow_util.ctxt->op._get_control_flow_context()
keras.utils.control_flow_util.GetContainingWhileContext(ctxt,stop_ctxt=None)
keras.utils.control_flow_util.GetContainingXLAContext(ctxt)
keras.utils.control_flow_util.GraphOrParentsInXlaContext(graph)
keras.utils.control_flow_util.InXlaContext(graph)
keras.utils.control_flow_util.IsInWhileLoop(op)
keras.utils.control_flow_util.constant_value(pred)
keras.utils.control_flow_util.smart_cond(pred,true_fn=None,false_fn=None,name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/traceback_utils.py----------------------------------------
A:keras.utils.traceback_utils.tb_list->list(traceback.walk_tb(tb))
A:keras.utils.traceback_utils.last_tb->types.TracebackType(last_tb, f, f.f_lasti, line_no)
A:keras.utils.traceback_utils.filtered_tb->_process_traceback_frames(e.__traceback__)
A:keras.utils.traceback_utils.signature->inspect.signature(fn)
A:keras.utils.traceback_utils.bound_signature->inspect.signature(fn).bind(*args, **kwargs)
A:keras.utils.traceback_utils.value->tensorflow.compat.v2.nest.map_structure(format_argument_value, bound_signature.arguments[arg.name])
A:keras.utils.traceback_utils.arguments_context->'\n'.join(arguments_context)
A:keras.utils.traceback_utils.new_e->RuntimeError(message)
keras.utils.traceback_utils._process_traceback_frames(tb)
keras.utils.traceback_utils.filter_traceback(fn)
keras.utils.traceback_utils.format_argument_value(value)
keras.utils.traceback_utils.include_frame(fname)
keras.utils.traceback_utils.inject_argument_info_in_traceback(fn,object_name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/metrics_utils.py----------------------------------------
A:keras.utils.metrics_utils.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.utils.metrics_utils.update_op->update_state_fn(*args, **kwargs)
A:keras.utils.metrics_utils.replica_context->tensorflow.compat.v2.distribute.get_replica_context()
A:keras.utils.metrics_utils.raw_result->result_fn(*args)
A:keras.utils.metrics_utils.result_t->tensorflow.compat.v2.distribute.get_replica_context().merge_call(merge_fn_wrapper, args=(result_fn,) + args)
A:keras.utils.metrics_utils.result->distribution.experimental_local_results(merge_fn)[0](*args)
A:keras.utils.metrics_utils.instance_ref->weakref.ref(method.im_self)
A:keras.utils.metrics_utils.thresholds->tensorflow.compat.v2.convert_to_tensor(thresholds, dtype=variable_dtype)
A:keras.utils.metrics_utils.sample_weights->tensorflow.compat.v2.reshape(sample_weights, [-1])
A:keras.utils.metrics_utils.label_weights->tensorflow.compat.v2.__internal__.ops.broadcast_weights(label_weights, y_pred)
A:keras.utils.metrics_utils.weights->tensorflow.compat.v2.multiply(sample_weights, label_weights)
A:keras.utils.metrics_utils.y_pred->tensorflow.compat.v2.reshape(y_pred, [-1, y_pred.shape[-1]])
A:keras.utils.metrics_utils.y_true->tensorflow.compat.v2.reshape(y_true, [-1])
A:keras.utils.metrics_utils.true_labels->tensorflow.compat.v2.transpose(true_labels)
A:keras.utils.metrics_utils.false_labels->tensorflow.compat.v2.transpose(false_labels)
A:keras.utils.metrics_utils.bucket_indices->tensorflow.compat.v2.transpose(bucket_indices)
A:keras.utils.metrics_utils.tp_bucket_v->tensorflow.compat.v2.math.unsorted_segment_sum(data=true_labels, segment_ids=bucket_indices, num_segments=num_thresholds)
A:keras.utils.metrics_utils.fp_bucket_v->tensorflow.compat.v2.math.unsorted_segment_sum(data=false_labels, segment_ids=bucket_indices, num_segments=num_thresholds)
A:keras.utils.metrics_utils.tp->tensorflow.compat.v2.cumsum(tp_bucket_v, reverse=True)
A:keras.utils.metrics_utils.fp->tensorflow.compat.v2.cumsum(fp_bucket_v, reverse=True)
A:keras.utils.metrics_utils.total_true_labels->tensorflow.compat.v2.reduce_sum(true_labels)
A:keras.utils.metrics_utils.total_false_labels->tensorflow.compat.v2.reduce_sum(false_labels)
A:keras.utils.metrics_utils.num_thresholds->len(thresholds)
A:keras.utils.metrics_utils.one_thresh->tensorflow.compat.v2.cast(True, dtype=tf.bool)
A:keras.utils.metrics_utils.([y_pred, y_true], _)->ragged_assert_compatible_and_get_flat_values([y_pred, y_true], sample_weight)
A:keras.utils.metrics_utils.(y_pred, y_true)->keras.utils.losses_utils.squeeze_or_expand_dimensions(y_pred, y_true)
A:keras.utils.metrics_utils.sample_weight->tensorflow.compat.v2.__internal__.ops.broadcast_weights(tf.cast(sample_weight, dtype=variable_dtype), y_pred)
A:keras.utils.metrics_utils.(y_pred, y_true, sample_weight)->keras.utils.losses_utils.squeeze_or_expand_dimensions(y_pred, y_true, sample_weight=sample_weight)
A:keras.utils.metrics_utils.pred_shape->tensorflow.compat.v2.shape(y_pred)
A:keras.utils.metrics_utils.num_labels->tensorflow.compat.v2.math.reduce_prod(pred_shape[1:], axis=0)
A:keras.utils.metrics_utils.thresh_label_tile->tensorflow.compat.v2.where(one_thresh, num_labels, tf.ones([], dtype=tf.int32))
A:keras.utils.metrics_utils.predictions_extra_dim->tensorflow.compat.v2.reshape(y_pred, [1, -1])
A:keras.utils.metrics_utils.labels_extra_dim->tensorflow.compat.v2.reshape(tf.cast(y_true, dtype=tf.bool), [1, -1])
A:keras.utils.metrics_utils.thresh_tiled->tensorflow.compat.v2.tile(tf.reshape(thresholds, thresh_pretile_shape), tf.stack(thresh_tiles))
A:keras.utils.metrics_utils.preds_tiled->tensorflow.compat.v2.tile(predictions_extra_dim, data_tiles)
A:keras.utils.metrics_utils.pred_is_pos->tensorflow.compat.v2.greater(preds_tiled, thresh_tiled)
A:keras.utils.metrics_utils.label_is_pos->tensorflow.compat.v2.tile(labels_extra_dim, data_tiles)
A:keras.utils.metrics_utils.weights_tiled->tensorflow.compat.v2.multiply(weights_tiled, label_weights_tiled)
A:keras.utils.metrics_utils.label_weights_tiled->tensorflow.compat.v2.tile(tf.reshape(label_weights, thresh_tiles), data_tiles)
A:keras.utils.metrics_utils.label_and_pred->tensorflow.compat.v2.cast(tf.logical_and(label, pred), dtype=var.dtype)
A:keras.utils.metrics_utils.pred_is_neg->tensorflow.compat.v2.logical_not(pred_is_pos)
A:keras.utils.metrics_utils.label_is_neg->tensorflow.compat.v2.logical_not(label_is_pos)
A:keras.utils.metrics_utils.(_, top_k_idx)->tensorflow.compat.v2.math.top_k(x, k, sorted=False)
A:keras.utils.metrics_utils.top_k_mask->tensorflow.compat.v2.reduce_sum(tf.one_hot(top_k_idx, tf.shape(x)[-1], axis=-1), axis=-2)
A:keras.utils.metrics_utils.is_all_ragged->isinstance(values, tf.RaggedTensor)
A:keras.utils.metrics_utils.is_any_ragged->any((isinstance(rt, tf.RaggedTensor) for rt in values))
A:keras.utils.metrics_utils.assertion_list->_assert_splits_match(nested_row_split_list)
A:keras.utils.metrics_utils.assertion_list_for_mask->_assert_splits_match([nested_row_split_list[0], mask.nested_row_splits])
A:keras.utils.metrics_utils.mask->tensorflow.compat.v2.expand_dims(mask.flat_values, -1)
A:keras.utils.metrics_utils.threshold->tensorflow.compat.v2.cast(threshold, y_pred.dtype)
A:keras.utils.metrics_utils.y_true_org_shape->tensorflow.compat.v2.shape(y_true)
A:keras.utils.metrics_utils.matches->tensorflow.compat.v2.cast(tf.math.in_top_k(predictions=y_pred, targets=tf.cast(y_true, 'int32'), k=k), dtype=backend.floatx())
keras.utils.metrics_utils.AUCCurve(Enum)
keras.utils.metrics_utils.AUCCurve.from_str(key)
keras.utils.metrics_utils.AUCSummationMethod(Enum)
keras.utils.metrics_utils.AUCSummationMethod.from_str(key)
keras.utils.metrics_utils.ConfusionMatrix(Enum)
keras.utils.metrics_utils.Reduction(Enum)
keras.utils.metrics_utils._assert_splits_match(nested_splits_lists)
keras.utils.metrics_utils._filter_top_k(x,k)
keras.utils.metrics_utils._update_confusion_matrix_variables_optimized(variables_to_update,y_true,y_pred,thresholds,multi_label=False,sample_weights=None,label_weights=None,thresholds_with_epsilon=False)
keras.utils.metrics_utils.assert_thresholds_range(thresholds)
keras.utils.metrics_utils.binary_matches(y_true,y_pred,threshold=0.5)
keras.utils.metrics_utils.is_evenly_distributed_thresholds(thresholds)
keras.utils.metrics_utils.parse_init_thresholds(thresholds,default_threshold=0.5)
keras.utils.metrics_utils.ragged_assert_compatible_and_get_flat_values(values,mask=None)
keras.utils.metrics_utils.result_wrapper(result_fn)
keras.utils.metrics_utils.sparse_categorical_matches(y_true,y_pred)
keras.utils.metrics_utils.sparse_top_k_categorical_matches(y_true,y_pred,k=5)
keras.utils.metrics_utils.update_confusion_matrix_variables(variables_to_update,y_true,y_pred,thresholds,top_k=None,class_id=None,sample_weight=None,multi_label=False,label_weights=None,thresholds_distributed_evenly=False)
keras.utils.metrics_utils.update_state_wrapper(update_state_fn)
keras.utils.metrics_utils.weakmethod(method)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/dataset_utils.py----------------------------------------
A:keras.utils.dataset_utils.class_indices->dict(zip(class_names, range(len(class_names))))
A:keras.utils.dataset_utils.pool->multiprocessing.pool.ThreadPool()
A:keras.utils.dataset_utils.(partial_filenames, partial_labels)->res.get()
A:keras.utils.dataset_utils.labels->numpy.zeros((len(filenames),), dtype='int32')
A:keras.utils.dataset_utils.seed->numpy.random.randint(1000000.0)
A:keras.utils.dataset_utils.rng->numpy.random.RandomState(seed)
A:keras.utils.dataset_utils.walk->os.walk(directory, followlinks=follow_links)
A:keras.utils.dataset_utils.dirname->os.path.basename(directory)
A:keras.utils.dataset_utils.valid_files->iter_valid_files(directory, follow_links, formats)
A:keras.utils.dataset_utils.absolute_path->tensorflow.compat.v2.io.gfile.join(root, fname)
A:keras.utils.dataset_utils.relative_path->tensorflow.compat.v2.io.gfile.join(dirname, os.path.relpath(absolute_path, directory))
A:keras.utils.dataset_utils.num_val_samples->int(validation_split * len(samples))
A:keras.utils.dataset_utils.label_ds->label_ds.map(lambda x: tf.one_hot(x, num_classes), num_parallel_calls=tf.data.AUTOTUNE).map(lambda x: tf.one_hot(x, num_classes), num_parallel_calls=tf.data.AUTOTUNE)
keras.utils.dataset_utils.check_validation_split_arg(validation_split,subset,shuffle,seed)
keras.utils.dataset_utils.get_training_or_validation_split(samples,labels,validation_split,subset)
keras.utils.dataset_utils.index_directory(directory,labels,formats,class_names=None,shuffle=True,seed=None,follow_links=False)
keras.utils.dataset_utils.index_subdirectory(directory,class_indices,follow_links,formats)
keras.utils.dataset_utils.iter_valid_files(directory,follow_links,formats)
keras.utils.dataset_utils.labels_to_dataset(labels,label_mode,num_classes)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/conv_utils.py----------------------------------------
A:keras.utils.conv_utils.value_tuple->tuple(value)
A:keras.utils.conv_utils.value->keras.backend.image_data_format()
A:keras.utils.conv_utils.data_format->keras.backend.image_data_format().lower()
A:keras.utils.conv_utils.padding->keras.backend.image_data_format().lower()
A:keras.utils.conv_utils.in_dims->len(input_shape)
A:keras.utils.conv_utils.kernel_dims->len(kernel_shape)
A:keras.utils.conv_utils.stride_dims->len(strides)
A:keras.utils.conv_utils.output_shape->tuple([0 if input_shape[d] == 0 else output_shape[d] for d in dims])
A:keras.utils.conv_utils.mask->numpy.zeros(mask_shape, np.bool)
A:keras.utils.conv_utils.input_axes_ticks->conv_connected_inputs(input_shape, kernel_shape, output_position, strides, padding)
A:keras.utils.conv_utils.out_idx->numpy.ravel_multi_index(multi_index=concat_idxs(output_position, f_out), dims=concat_idxs(output_shape, filters_out))
A:keras.utils.conv_utils.in_idx->numpy.ravel_multi_index(multi_index=concat_idxs(input_position, f_in), dims=concat_idxs(input_shape, filters_in))
A:keras.utils.conv_utils.ndims->len(input_shape)
A:keras.utils.conv_utils.left_shift->int(kernel_shape[d] / 2)
A:keras.utils.conv_utils.start->max(0, center - left_shift)
A:keras.utils.conv_utils.end->min(input_shape[d], center + right_shift)
A:keras.utils.conv_utils.dims->range(len(kernel_shape))
A:keras.utils.conv_utils.inp_reshaped->tensorflow.compat.v2.reshape(inp, tf.concat(([-1], inner_shape), axis=-1))
A:keras.utils.conv_utils.out_reshaped->op(inp_reshaped)
A:keras.utils.conv_utils.out->tensorflow.compat.v2.reshape(out_reshaped, tf.concat((batch_shape, out_inner_shape), axis=-1))
keras.utils.conv_utils.conv_connected_inputs(input_shape,kernel_shape,output_position,strides,padding)
keras.utils.conv_utils.conv_input_length(output_length,filter_size,padding,stride)
keras.utils.conv_utils.conv_kernel_idxs(input_shape,kernel_shape,strides,padding,filters_in,filters_out,data_format)
keras.utils.conv_utils.conv_kernel_mask(input_shape,kernel_shape,strides,padding)
keras.utils.conv_utils.conv_output_length(input_length,filter_size,padding,stride,dilation=1)
keras.utils.conv_utils.conv_output_shape(input_shape,kernel_shape,strides,padding)
keras.utils.conv_utils.convert_data_format(data_format,ndim)
keras.utils.conv_utils.deconv_output_length(input_length,filter_size,padding,output_padding=None,stride=0,dilation=1)
keras.utils.conv_utils.normalize_data_format(value)
keras.utils.conv_utils.normalize_padding(value)
keras.utils.conv_utils.normalize_tuple(value,n,name,allow_zero=False)
keras.utils.conv_utils.squeeze_batch_dims(inp,op,inner_rank)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/version_utils.py----------------------------------------
A:keras.utils.version_utils.training->LazyLoader('training', globals(), 'keras.engine.training')
A:keras.utils.version_utils.training_v1->LazyLoader('training_v1', globals(), 'keras.engine.training_v1')
A:keras.utils.version_utils.base_layer->LazyLoader('base_layer', globals(), 'keras.engine.base_layer')
A:keras.utils.version_utils.base_layer_v1->LazyLoader('base_layer_v1', globals(), 'keras.engine.base_layer_v1')
A:keras.utils.version_utils.callbacks->LazyLoader('callbacks', globals(), 'keras.callbacks')
A:keras.utils.version_utils.callbacks_v1->LazyLoader('callbacks_v1', globals(), 'keras.callbacks_v1')
A:keras.utils.version_utils.use_v2->should_use_v2()
A:keras.utils.version_utils.cls->swap_class(start_cls, callbacks.TensorBoard, callbacks_v1.TensorBoard, use_v2)
A:keras.utils.version_utils.graph->tensorflow.compat.v2.compat.v1.get_default_graph()
A:keras.utils.version_utils.new_base->swap_class(base, v2_cls, v1_cls, use_v2)
A:keras.utils.version_utils.cls.__bases__->tuple(new_bases)
keras.utils.version_utils.LayerVersionSelector(cls,*args,**kwargs)
keras.utils.version_utils.LayerVersionSelector.__new__(cls,*args,**kwargs)
keras.utils.version_utils.ModelVersionSelector(cls,*args,**kwargs)
keras.utils.version_utils.ModelVersionSelector.__new__(cls,*args,**kwargs)
keras.utils.version_utils.TensorBoardVersionSelector(cls,*args,**kwargs)
keras.utils.version_utils.TensorBoardVersionSelector.__new__(cls,*args,**kwargs)
keras.utils.version_utils.disallow_legacy_graph(cls_name,method_name)
keras.utils.version_utils.is_v1_layer_or_model(obj)
keras.utils.version_utils.should_use_v2()
keras.utils.version_utils.swap_class(cls,v2_cls,v1_cls,use_v2)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/tf_utils.py----------------------------------------
A:keras.utils.tf_utils.backend._SEED_GENERATOR.generator->random.Random(seed)
A:keras.utils.tf_utils.v->tensorflow.compat.v2.nest.flatten(v)
A:keras.utils.tf_utils.inputs->tensorflow.compat.v2.nest.flatten(inputs, expand_composites=True)
A:keras.utils.tf_utils.reachable->keras.utils.object_identity.ObjectIdentitySet(inputs)
A:keras.utils.tf_utils.remaining_targets->keras.utils.object_identity.ObjectIdentitySet(tf.nest.flatten(targets))
A:keras.utils.tf_utils.queue->collections.deque(inputs)
A:keras.utils.tf_utils.x->collections.deque(inputs).pop()
A:keras.utils.tf_utils.outputs->collections.deque(inputs).pop().consumers()
A:keras.utils.tf_utils.values->_astuple(nested)
A:keras.utils.tf_utils.input_shape->convert_shapes(input_shape, to_tuples=True)
A:keras.utils.tf_utils.axis->list(axis)
A:keras.utils.tf_utils.output_shape->convert_shapes(output_shape, to_tuples=False)
A:keras.utils.tf_utils._user_convertible_tensor_types->set()
A:keras.utils.tf_utils.component_tensors->tensorflow.compat.v2.nest.flatten(tensor, expand_composites=True)
A:keras.utils.tf_utils.tensor->tensorflow.python.framework.ops.convert_to_tensor_or_composite(tensor)
A:keras.utils.tf_utils.layer_str->'\n'.join(('  ' + str(l) for l in legacy_layers))
A:keras.utils.tf_utils.dataset_size->keras.backend.get_session().run(tf.data.experimental.cardinality(dataset))
A:keras.utils.tf_utils.spec->copy.deepcopy(spec)
A:keras.utils.tf_utils.shape_list->shape.as_list()
A:keras.utils.tf_utils.tensors->tensors.fetch().fetch()
A:keras.utils.tf_utils.t->t.numpy().numpy()
A:keras.utils.tf_utils.cls->type(attrs)
A:keras.utils.tf_utils.fields->getattr(cls, '__attrs_attrs__', None)
keras.utils.set_random_seed(seed)
keras.utils.tf_utils.ListWrapper(self,list_to_wrap)
keras.utils.tf_utils.ListWrapper.__init__(self,list_to_wrap)
keras.utils.tf_utils.ListWrapper.as_list(self)
keras.utils.tf_utils._astuple(attrs)
keras.utils.tf_utils.are_all_symbolic_tensors(tensors)
keras.utils.tf_utils.assert_no_legacy_layers(layers)
keras.utils.tf_utils.convert_inner_node_data(nested,wrap=False)
keras.utils.tf_utils.convert_shapes(input_shape,to_tuples=True)
keras.utils.tf_utils.dataset_is_infinite(dataset)
keras.utils.tf_utils.get_reachable_from_inputs(inputs,targets=None)
keras.utils.tf_utils.get_shapes(tensors)
keras.utils.tf_utils.get_tensor_spec(t,dynamic_batch=False,name=None)
keras.utils.tf_utils.graph_context_for_symbolic_tensors(*args,**kwargs)
keras.utils.tf_utils.is_extension_type(tensor)
keras.utils.tf_utils.is_ragged(tensor)
keras.utils.tf_utils.is_sparse(tensor)
keras.utils.tf_utils.is_symbolic_tensor(tensor)
keras.utils.tf_utils.is_tensor_or_extension_type(x)
keras.utils.tf_utils.is_tensor_or_tensor_list(v)
keras.utils.tf_utils.is_tensor_or_variable(x)
keras.utils.tf_utils.map_structure_with_atomic(is_atomic_fn,map_fn,nested)
keras.utils.tf_utils.maybe_init_scope(layer)
keras.utils.tf_utils.register_symbolic_tensor_type(cls)
keras.utils.tf_utils.set_random_seed(seed)
keras.utils.tf_utils.shape_type_conversion(fn)
keras.utils.tf_utils.sync_to_numpy_or_python_type(tensors)
keras.utils.tf_utils.type_spec_from_value(value)
keras.utils.tf_utils.validate_axis(axis,input_shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/dataset_creator.py----------------------------------------
A:keras.utils.dataset_creator.dataset->self.dataset_fn(*args, **kwargs)
keras.utils.dataset_creator.DatasetCreator(self,dataset_fn,input_options=None)
keras.utils.dataset_creator.DatasetCreator.__init__(self,dataset_fn,input_options=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/image_dataset.py----------------------------------------
A:keras.utils.image_dataset.crop_to_aspect_ratio->kwargs.pop('smart_resize')
A:keras.utils.image_dataset.interpolation->keras.utils.image_utils.get_interpolation(interpolation)
A:keras.utils.image_dataset.seed->numpy.random.randint(1000000.0)
A:keras.utils.image_dataset.(image_paths, labels, class_names)->keras.utils.dataset_utils.index_directory(directory, labels, formats=ALLOWLIST_FORMATS, class_names=class_names, shuffle=shuffle, seed=seed, follow_links=follow_links)
A:keras.utils.image_dataset.(image_paths, labels)->keras.utils.dataset_utils.get_training_or_validation_split(image_paths, labels, validation_split, subset)
A:keras.utils.image_dataset.dataset->dataset.shuffle(buffer_size=1024, seed=seed).shuffle(buffer_size=1024, seed=seed)
A:keras.utils.image_dataset.path_ds->tensorflow.compat.v2.data.Dataset.from_tensor_slices(image_paths)
A:keras.utils.image_dataset.img_ds->tensorflow.compat.v2.data.Dataset.zip((img_ds, label_ds))
A:keras.utils.image_dataset.label_ds->keras.utils.dataset_utils.labels_to_dataset(labels, label_mode, num_classes)
A:keras.utils.image_dataset.img->tensorflow.compat.v2.image.resize(img, image_size, method=interpolation)
keras.utils.image_dataset.image_dataset_from_directory(directory,labels='inferred',label_mode='int',class_names=None,color_mode='rgb',batch_size=32,image_size=(256,256),shuffle=True,seed=None,validation_split=None,subset=None,interpolation='bilinear',follow_links=False,crop_to_aspect_ratio=False,**kwargs)
keras.utils.image_dataset.load_image(path,image_size,num_channels,interpolation,crop_to_aspect_ratio=False)
keras.utils.image_dataset.paths_and_labels_to_dataset(image_paths,image_size,num_channels,labels,label_mode,num_classes,interpolation,crop_to_aspect_ratio=False)
keras.utils.image_dataset_from_directory(directory,labels='inferred',label_mode='int',class_names=None,color_mode='rgb',batch_size=32,image_size=(256,256),shuffle=True,seed=None,validation_split=None,subset=None,interpolation='bilinear',follow_links=False,crop_to_aspect_ratio=False,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/losses_utils.py----------------------------------------
A:keras.utils.losses_utils.predictions->tensorflow.compat.v2.cond(tf.equal(expected_rank_diff + 1, rank_diff), lambda : tf.squeeze(predictions, [-1]), lambda : predictions)
A:keras.utils.losses_utils.labels->tensorflow.compat.v2.cond(tf.equal(expected_rank_diff - 1, rank_diff), lambda : tf.squeeze(labels, [-1]), lambda : labels)
A:keras.utils.losses_utils.(y_true, y_pred)->tensorflow.compat.v2.cond(tf.equal(1, rank_diff), maybe_squeeze_dims, squeeze_dims)
A:keras.utils.losses_utils.is_last_dim_1->tensorflow.compat.v2.equal(1, tf.shape(y_pred)[-1])
A:keras.utils.losses_utils.sample_weight->tensorflow.compat.v2.cast(sample_weight, losses.dtype)
A:keras.utils.losses_utils.weights_rank_tensor->tensorflow.compat.v2.rank(sample_weight)
A:keras.utils.losses_utils.total_loss->tensorflow.compat.v2.reduce_sum(losses)
A:keras.utils.losses_utils.loss->tensorflow.compat.v2.cast(loss, input_dtype)
A:keras.utils.losses_utils.losses->tensorflow.compat.v2.cast(losses, 'float32')
A:keras.utils.losses_utils.(losses, _, sample_weight)->squeeze_or_expand_dimensions(losses, None, sample_weight)
A:keras.utils.losses_utils.weighted_losses->tensorflow.compat.v2.multiply(losses, sample_weight)
keras.utils.losses_utils.ReductionV2
keras.utils.losses_utils.ReductionV2.all(cls)
keras.utils.losses_utils.ReductionV2.validate(cls,key)
keras.utils.losses_utils._num_elements(losses)
keras.utils.losses_utils._safe_mean(losses,num_present)
keras.utils.losses_utils.cast_losses_to_common_dtype(losses)
keras.utils.losses_utils.compute_weighted_loss(losses,sample_weight=None,reduction=ReductionV2.SUM_OVER_BATCH_SIZE,name=None)
keras.utils.losses_utils.reduce_weighted_loss(weighted_losses,reduction=ReductionV2.SUM_OVER_BATCH_SIZE)
keras.utils.losses_utils.remove_squeezable_dimensions(labels,predictions,expected_rank_diff=0,name=None)
keras.utils.losses_utils.scale_loss_for_distribution(loss_value)
keras.utils.losses_utils.squeeze_or_expand_dimensions(y_pred,y_true=None,sample_weight=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/timeseries_dataset.py----------------------------------------
A:keras.utils.timeseries_dataset.end_index->len(data)
A:keras.utils.timeseries_dataset.num_seqs->min(num_seqs, len(targets))
A:keras.utils.timeseries_dataset.start_positions->numpy.arange(0, num_seqs, sequence_stride, dtype=index_dtype)
A:keras.utils.timeseries_dataset.seed->numpy.random.randint(1000000.0)
A:keras.utils.timeseries_dataset.rng->numpy.random.RandomState(seed)
A:keras.utils.timeseries_dataset.sequence_length->tensorflow.compat.v2.cast(sequence_length, dtype=index_dtype)
A:keras.utils.timeseries_dataset.sampling_rate->tensorflow.compat.v2.cast(sampling_rate, dtype=index_dtype)
A:keras.utils.timeseries_dataset.positions_ds->tensorflow.compat.v2.data.Dataset.from_tensors(start_positions).repeat()
A:keras.utils.timeseries_dataset.indices->tensorflow.compat.v2.data.Dataset.zip((tf.data.Dataset.range(len(start_positions)), positions_ds)).map(lambda i, positions: positions[i], num_parallel_calls=tf.data.AUTOTUNE)
A:keras.utils.timeseries_dataset.dataset->tensorflow.compat.v2.data.Dataset.zip((dataset.repeat(), indices_ds)).map(lambda steps, inds: tf.gather(steps, inds), num_parallel_calls=tf.data.AUTOTUNE)
A:keras.utils.timeseries_dataset.target_ds->sequences_from_indices(targets, indices, start_index, end_index)
keras.utils.timeseries_dataset.sequences_from_indices(array,indices_ds,start_index,end_index)
keras.utils.timeseries_dataset.timeseries_dataset_from_array(data,targets,sequence_length,sequence_stride=1,sampling_rate=1,batch_size=128,shuffle=False,seed=None,start_index=None,end_index=None)
keras.utils.timeseries_dataset_from_array(data,targets,sequence_length,sequence_stride=1,sampling_rate=1,batch_size=128,shuffle=False,seed=None,start_index=None,end_index=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/np_utils.py----------------------------------------
A:keras.utils.np_utils.y->y.ravel().ravel()
A:keras.utils.np_utils.input_shape->tuple(input_shape[:-1])
A:keras.utils.np_utils.categorical->numpy.reshape(categorical, output_shape)
A:keras.utils.np_utils.l2->numpy.atleast_1d(np.linalg.norm(x, order, axis))
keras.utils.normalize(x,axis=-1,order=2)
keras.utils.np_utils.normalize(x,axis=-1,order=2)
keras.utils.np_utils.to_categorical(y,num_classes=None,dtype='float32')
keras.utils.to_categorical(y,num_classes=None,dtype='float32')


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/kpl_test_utils.py----------------------------------------
A:keras.utils.kpl_test_utils.feature_lookup_layer->keras.layers.preprocessing.string_lookup.StringLookup(vocabulary=self.FEATURE_VOCAB, num_oov_indices=1)
A:keras.utils.kpl_test_utils.label_lookup_layer->keras.layers.preprocessing.string_lookup.StringLookup(vocabulary=self.LABEL_VOCAB, num_oov_indices=0, mask_token=None)
A:keras.utils.kpl_test_utils.raw_feature_input->keras.layers.Input(shape=(3,), dtype=tf.string, name='feature', ragged=True)
A:keras.utils.kpl_test_utils.feature_id_input->feature_lookup_layer(raw_feature_input)
A:keras.utils.kpl_test_utils.feature_mapper->keras.Model({'features': raw_feature_input}, feature_id_input)
A:keras.utils.kpl_test_utils.raw_label_input->keras.layers.Input(shape=(1,), dtype=tf.string, name='label')
A:keras.utils.kpl_test_utils.label_id_input->label_lookup_layer(raw_label_input)
A:keras.utils.kpl_test_utils.label_mapper->keras.Model({'label': raw_label_input}, label_id_input)
A:keras.utils.kpl_test_utils.features->random.sample(self.FEATURE_VOCAB, 3)
A:keras.utils.kpl_test_utils.raw_dataset->tensorflow.compat.v2.data.Dataset.from_generator(feature_and_label_gen, output_signature={'features': tf.TensorSpec([3], tf.string), 'label': tf.TensorSpec([1], tf.string)}).shuffle(100).batch(32)
A:keras.utils.kpl_test_utils.train_dataset->tensorflow.compat.v2.data.Dataset.from_generator(feature_and_label_gen, output_signature={'features': tf.TensorSpec([3], tf.string), 'label': tf.TensorSpec([1], tf.string)}).shuffle(100).batch(32).map(lambda x: ({'features': feature_mapper(x['features'])}, label_mapper(x['label'])))
A:keras.utils.kpl_test_utils.model_input->keras.layers.Input(shape=(3,), dtype=tf.int64, name='model_input')
A:keras.utils.kpl_test_utils.emb_output->tensorflow.compat.v2.reduce_mean(emb_output, axis=1)
A:keras.utils.kpl_test_utils.dense_output->keras.layers.Dense(units=1, activation='sigmoid')(emb_output)
A:keras.utils.kpl_test_utils.model->keras.Model({'features': model_input}, dense_output)
A:keras.utils.kpl_test_utils.label_inverse_lookup_layer->keras.layers.preprocessing.string_lookup.StringLookup(num_oov_indices=0, mask_token=None, vocabulary=self.LABEL_VOCAB, invert=True)
A:keras.utils.kpl_test_utils.raw_features->tensorflow.compat.v2.expand_dims(raw_features, axis=0)
A:keras.utils.kpl_test_utils.transformed_features->keras.Model({'features': model_input}, dense_output).feature_mapper(raw_features)
A:keras.utils.kpl_test_utils.outputs->tensorflow.compat.v2.cast(tf.greater(outputs, 0.5), tf.int64)
A:keras.utils.kpl_test_utils.decoded_outputs->keras.Model({'features': model_input}, dense_output).label_inverse_lookup_layer(outputs)
A:keras.utils.kpl_test_utils.serving_fn->self.create_serving_signature(model, feature_mapper, label_inverse_lookup_layer)
A:keras.utils.kpl_test_utils.saved_model_dir->tempfile.mkdtemp(dir=self.get_temp_dir())
keras.utils.kpl_test_utils.DistributeKplTestUtils(tf.test.TestCase)
keras.utils.kpl_test_utils.DistributeKplTestUtils.create_serving_signature(self,model,feature_mapper,label_inverse_lookup_layer)
keras.utils.kpl_test_utils.DistributeKplTestUtils.dataset_fn(self,feature_mapper,label_mapper)
keras.utils.kpl_test_utils.DistributeKplTestUtils.define_kpls_for_training(self,use_adapt)
keras.utils.kpl_test_utils.DistributeKplTestUtils.define_model(self)
keras.utils.kpl_test_utils.DistributeKplTestUtils.define_reverse_lookup_layer(self)
keras.utils.kpl_test_utils.DistributeKplTestUtils.test_save_load_serving_model(self,model,feature_mapper,label_inverse_lookup_layer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/text_dataset.py----------------------------------------
A:keras.utils.text_dataset.seed->numpy.random.randint(1000000.0)
A:keras.utils.text_dataset.(file_paths, labels, class_names)->keras.utils.dataset_utils.index_directory(directory, labels, formats=('.txt',), class_names=class_names, shuffle=shuffle, seed=seed, follow_links=follow_links)
A:keras.utils.text_dataset.(file_paths, labels)->keras.utils.dataset_utils.get_training_or_validation_split(file_paths, labels, validation_split, subset)
A:keras.utils.text_dataset.dataset->dataset.shuffle(buffer_size=1024, seed=seed).shuffle(buffer_size=1024, seed=seed)
A:keras.utils.text_dataset.path_ds->tensorflow.compat.v2.data.Dataset.from_tensor_slices(file_paths)
A:keras.utils.text_dataset.string_ds->tensorflow.compat.v2.data.Dataset.zip((string_ds, label_ds))
A:keras.utils.text_dataset.label_ds->keras.utils.dataset_utils.labels_to_dataset(labels, label_mode, num_classes)
A:keras.utils.text_dataset.txt->tensorflow.compat.v2.compat.v1.strings.substr(txt, 0, max_length)
keras.utils.text_dataset.path_to_string_content(path,max_length)
keras.utils.text_dataset.paths_and_labels_to_dataset(file_paths,labels,label_mode,num_classes,max_length)
keras.utils.text_dataset.text_dataset_from_directory(directory,labels='inferred',label_mode='int',class_names=None,batch_size=32,max_length=None,shuffle=True,seed=None,validation_split=None,subset=None,follow_links=False)
keras.utils.text_dataset_from_directory(directory,labels='inferred',label_mode='int',class_names=None,batch_size=32,max_length=None,shuffle=True,seed=None,validation_split=None,subset=None,follow_links=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/tf_contextlib.py----------------------------------------
A:keras.utils.tf_contextlib.context_manager->contextlib.contextmanager(target)
keras.utils.tf_contextlib.contextmanager(target)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/utils/tf_inspect.py----------------------------------------
A:keras.utils.tf_inspect.FullArgSpec->collections.namedtuple('FullArgSpec', ['args', 'varargs', 'varkw', 'defaults', 'kwonlyargs', 'kwonlydefaults', 'annotations'])
A:keras.utils.tf_inspect.fullargspecs->getfullargspec(target)
A:keras.utils.tf_inspect.argspecs->ArgSpec(args=fullargspecs.args, varargs=fullargspecs.varargs, keywords=fullargspecs.varkw, defaults=fullargspecs.defaults)
A:keras.utils.tf_inspect.(decorators, target)->tensorflow.compat.v2.__internal__.decorator.unwrap(obj)
A:keras.utils.tf_inspect.spec->next((d.decorator_argspec for d in decorators if d.decorator_argspec is not None), None)
A:keras.utils.tf_inspect.n_prune_args->len(obj.args)
A:keras.utils.tf_inspect.(args, varargs, keywords, defaults)->getargspec(obj.func)
A:keras.utils.tf_inspect.no_default->object()
A:keras.utils.tf_inspect.idx->args.index(kw)
A:keras.utils.tf_inspect.first_default->next((idx for (idx, x) in enumerate(all_defaults) if x is not no_default), None)
A:keras.utils.tf_inspect.argspec->getfullargspec(func)
A:keras.utils.tf_inspect.call_args->named.copy()
keras.utils.tf_inspect._convert_maybe_argspec_to_fullargspec(argspec)
keras.utils.tf_inspect._get_argspec_for_partial(obj)
keras.utils.tf_inspect.currentframe()
keras.utils.tf_inspect.getargspec(obj)
keras.utils.tf_inspect.getcallargs(*func_and_positional,**named)
keras.utils.tf_inspect.getdoc(obj)
keras.utils.tf_inspect.getfile(obj)
keras.utils.tf_inspect.getframeinfo(*args,**kwargs)
keras.utils.tf_inspect.getfullargspec(obj)
keras.utils.tf_inspect.getmembers(obj,predicate=None)
keras.utils.tf_inspect.getmodule(obj)
keras.utils.tf_inspect.getmro(cls)
keras.utils.tf_inspect.getsource(obj)
keras.utils.tf_inspect.getsourcefile(obj)
keras.utils.tf_inspect.getsourcelines(obj)
keras.utils.tf_inspect.isbuiltin(obj)
keras.utils.tf_inspect.isclass(obj)
keras.utils.tf_inspect.isframe(obj)
keras.utils.tf_inspect.isfunction(obj)
keras.utils.tf_inspect.isgenerator(obj)
keras.utils.tf_inspect.isgeneratorfunction(obj)
keras.utils.tf_inspect.ismethod(obj)
keras.utils.tf_inspect.ismodule(obj)
keras.utils.tf_inspect.isroutine(obj)
keras.utils.tf_inspect.stack(context=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/protobuf/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/protobuf/saved_metadata_pb2.py----------------------------------------
A:keras.protobuf.saved_metadata_pb2._sym_db->google.protobuf.symbol_database.Default()
A:keras.protobuf.saved_metadata_pb2.DESCRIPTOR->google.protobuf.descriptor.FileDescriptor(name='keras/protobuf/saved_metadata.proto', package='third_party.py.keras.protobuf', syntax='proto3', serialized_options=None, serialized_pb=_b('\n#keras/protobuf/saved_metadata.proto\x12\x1dthird_party.py.keras.protobuf\x1a\x1dkeras/protobuf/versions.proto"J\n\rSavedMetadata\x129\n\x05nodes\x18\x01 \x03(\x0b2*.third_party.py.keras.protobuf.SavedObject"\x99\x01\n\x0bSavedObject\x12\x0f\n\x07node_id\x18\x02 \x01(\x05\x12\x11\n\tnode_path\x18\x03 \x01(\t\x12\x12\n\nidentifier\x18\x04 \x01(\t\x12\x10\n\x08metadata\x18\x05 \x01(\t\x12:\n\x07version\x18\x06 \x01(\x0b2).third_party.py.keras.protobuf.VersionDefJ\x04\x08\x01\x10\x02b\x06proto3'), dependencies=[keras_dot_protobuf_dot_versions__pb2.DESCRIPTOR])
A:keras.protobuf.saved_metadata_pb2._SAVEDMETADATA->google.protobuf.descriptor.Descriptor(name='SavedMetadata', full_name='third_party.py.keras.protobuf.SavedMetadata', filename=None, file=DESCRIPTOR, containing_type=None, fields=[_descriptor.FieldDescriptor(name='nodes', full_name='third_party.py.keras.protobuf.SavedMetadata.nodes', index=0, number=1, type=11, cpp_type=10, label=3, has_default_value=False, default_value=[], message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR)], extensions=[], nested_types=[], enum_types=[], serialized_options=None, is_extendable=False, syntax='proto3', extension_ranges=[], oneofs=[], serialized_start=101, serialized_end=175)
A:keras.protobuf.saved_metadata_pb2._SAVEDOBJECT->google.protobuf.descriptor.Descriptor(name='SavedObject', full_name='third_party.py.keras.protobuf.SavedObject', filename=None, file=DESCRIPTOR, containing_type=None, fields=[_descriptor.FieldDescriptor(name='node_id', full_name='third_party.py.keras.protobuf.SavedObject.node_id', index=0, number=2, type=5, cpp_type=1, label=1, has_default_value=False, default_value=0, message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='node_path', full_name='third_party.py.keras.protobuf.SavedObject.node_path', index=1, number=3, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='identifier', full_name='third_party.py.keras.protobuf.SavedObject.identifier', index=2, number=4, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='metadata', full_name='third_party.py.keras.protobuf.SavedObject.metadata', index=3, number=5, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='version', full_name='third_party.py.keras.protobuf.SavedObject.version', index=4, number=6, type=11, cpp_type=10, label=1, has_default_value=False, default_value=None, message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR)], extensions=[], nested_types=[], enum_types=[], serialized_options=None, is_extendable=False, syntax='proto3', extension_ranges=[], oneofs=[], serialized_start=178, serialized_end=331)
A:keras.protobuf.saved_metadata_pb2.SavedMetadata->google.protobuf.reflection.GeneratedProtocolMessageType('SavedMetadata', (_message.Message,), {'DESCRIPTOR': _SAVEDMETADATA, '__module__': 'keras.protobuf.saved_metadata_pb2'})
A:keras.protobuf.saved_metadata_pb2.SavedObject->google.protobuf.reflection.GeneratedProtocolMessageType('SavedObject', (_message.Message,), {'DESCRIPTOR': _SAVEDOBJECT, '__module__': 'keras.protobuf.saved_metadata_pb2'})


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/protobuf/versions_pb2.py----------------------------------------
A:keras.protobuf.versions_pb2._sym_db->google.protobuf.symbol_database.Default()
A:keras.protobuf.versions_pb2.DESCRIPTOR->google.protobuf.descriptor.FileDescriptor(name='keras/protobuf/versions.proto', package='third_party.py.keras.protobuf', syntax='proto3', serialized_options=None, serialized_pb=_b('\n\x1dkeras/protobuf/versions.proto\x12\x1dthird_party.py.keras.protobuf"K\n\nVersionDef\x12\x10\n\x08producer\x18\x01 \x01(\x05\x12\x14\n\x0cmin_consumer\x18\x02 \x01(\x05\x12\x15\n\rbad_consumers\x18\x03 \x03(\x05b\x06proto3'))
A:keras.protobuf.versions_pb2._VERSIONDEF->google.protobuf.descriptor.Descriptor(name='VersionDef', full_name='third_party.py.keras.protobuf.VersionDef', filename=None, file=DESCRIPTOR, containing_type=None, fields=[_descriptor.FieldDescriptor(name='producer', full_name='third_party.py.keras.protobuf.VersionDef.producer', index=0, number=1, type=5, cpp_type=1, label=1, has_default_value=False, default_value=0, message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='min_consumer', full_name='third_party.py.keras.protobuf.VersionDef.min_consumer', index=1, number=2, type=5, cpp_type=1, label=1, has_default_value=False, default_value=0, message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='bad_consumers', full_name='third_party.py.keras.protobuf.VersionDef.bad_consumers', index=2, number=3, type=5, cpp_type=1, label=3, has_default_value=False, default_value=[], message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR)], extensions=[], nested_types=[], enum_types=[], serialized_options=None, is_extendable=False, syntax='proto3', extension_ranges=[], oneofs=[], serialized_start=64, serialized_end=139)
A:keras.protobuf.versions_pb2.VersionDef->google.protobuf.reflection.GeneratedProtocolMessageType('VersionDef', (_message.Message,), {'DESCRIPTOR': _VERSIONDEF, '__module__': 'keras.protobuf.versions_pb2'})


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/protobuf/projector_config_pb2.py----------------------------------------
A:keras.protobuf.projector_config_pb2._sym_db->google.protobuf.symbol_database.Default()
A:keras.protobuf.projector_config_pb2.DESCRIPTOR->google.protobuf.descriptor.FileDescriptor(name='keras/protobuf/projector_config.proto', package='third_party.py.keras.protobuf', syntax='proto3', serialized_options=None, serialized_pb=_b('\n%keras/protobuf/projector_config.proto\x12\x1dthird_party.py.keras.protobuf">\n\x0eSpriteMetadata\x12\x12\n\nimage_path\x18\x01 \x01(\t\x12\x18\n\x10single_image_dim\x18\x02 \x03(\r"½\x01\n\rEmbeddingInfo\x12\x13\n\x0btensor_name\x18\x01 \x01(\t\x12\x15\n\rmetadata_path\x18\x02 \x01(\t\x12\x16\n\x0ebookmarks_path\x18\x03 \x01(\t\x12\x14\n\x0ctensor_shape\x18\x04 \x03(\r\x12=\n\x06sprite\x18\x05 \x01(\x0b2-.third_party.py.keras.protobuf.SpriteMetadata\x12\x13\n\x0btensor_path\x18\x06 \x01(\t"\x90\x01\n\x0fProjectorConfig\x12\x1d\n\x15model_checkpoint_path\x18\x01 \x01(\t\x12@\n\nembeddings\x18\x02 \x03(\x0b2,.third_party.py.keras.protobuf.EmbeddingInfo\x12\x1c\n\x14model_checkpoint_dir\x18\x03 \x01(\tb\x06proto3'))
A:keras.protobuf.projector_config_pb2._SPRITEMETADATA->google.protobuf.descriptor.Descriptor(name='SpriteMetadata', full_name='third_party.py.keras.protobuf.SpriteMetadata', filename=None, file=DESCRIPTOR, containing_type=None, fields=[_descriptor.FieldDescriptor(name='image_path', full_name='third_party.py.keras.protobuf.SpriteMetadata.image_path', index=0, number=1, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='single_image_dim', full_name='third_party.py.keras.protobuf.SpriteMetadata.single_image_dim', index=1, number=2, type=13, cpp_type=3, label=3, has_default_value=False, default_value=[], message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR)], extensions=[], nested_types=[], enum_types=[], serialized_options=None, is_extendable=False, syntax='proto3', extension_ranges=[], oneofs=[], serialized_start=72, serialized_end=134)
A:keras.protobuf.projector_config_pb2._EMBEDDINGINFO->google.protobuf.descriptor.Descriptor(name='EmbeddingInfo', full_name='third_party.py.keras.protobuf.EmbeddingInfo', filename=None, file=DESCRIPTOR, containing_type=None, fields=[_descriptor.FieldDescriptor(name='tensor_name', full_name='third_party.py.keras.protobuf.EmbeddingInfo.tensor_name', index=0, number=1, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='metadata_path', full_name='third_party.py.keras.protobuf.EmbeddingInfo.metadata_path', index=1, number=2, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='bookmarks_path', full_name='third_party.py.keras.protobuf.EmbeddingInfo.bookmarks_path', index=2, number=3, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='tensor_shape', full_name='third_party.py.keras.protobuf.EmbeddingInfo.tensor_shape', index=3, number=4, type=13, cpp_type=3, label=3, has_default_value=False, default_value=[], message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='sprite', full_name='third_party.py.keras.protobuf.EmbeddingInfo.sprite', index=4, number=5, type=11, cpp_type=10, label=1, has_default_value=False, default_value=None, message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='tensor_path', full_name='third_party.py.keras.protobuf.EmbeddingInfo.tensor_path', index=5, number=6, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR)], extensions=[], nested_types=[], enum_types=[], serialized_options=None, is_extendable=False, syntax='proto3', extension_ranges=[], oneofs=[], serialized_start=137, serialized_end=326)
A:keras.protobuf.projector_config_pb2._PROJECTORCONFIG->google.protobuf.descriptor.Descriptor(name='ProjectorConfig', full_name='third_party.py.keras.protobuf.ProjectorConfig', filename=None, file=DESCRIPTOR, containing_type=None, fields=[_descriptor.FieldDescriptor(name='model_checkpoint_path', full_name='third_party.py.keras.protobuf.ProjectorConfig.model_checkpoint_path', index=0, number=1, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='embeddings', full_name='third_party.py.keras.protobuf.ProjectorConfig.embeddings', index=1, number=2, type=11, cpp_type=10, label=3, has_default_value=False, default_value=[], message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR), _descriptor.FieldDescriptor(name='model_checkpoint_dir', full_name='third_party.py.keras.protobuf.ProjectorConfig.model_checkpoint_dir', index=2, number=3, type=9, cpp_type=9, label=1, has_default_value=False, default_value=_b('').decode('utf-8'), message_type=None, enum_type=None, containing_type=None, is_extension=False, extension_scope=None, serialized_options=None, file=DESCRIPTOR)], extensions=[], nested_types=[], enum_types=[], serialized_options=None, is_extendable=False, syntax='proto3', extension_ranges=[], oneofs=[], serialized_start=329, serialized_end=473)
A:keras.protobuf.projector_config_pb2.SpriteMetadata->google.protobuf.reflection.GeneratedProtocolMessageType('SpriteMetadata', (_message.Message,), {'DESCRIPTOR': _SPRITEMETADATA, '__module__': 'keras.protobuf.projector_config_pb2'})
A:keras.protobuf.projector_config_pb2.EmbeddingInfo->google.protobuf.reflection.GeneratedProtocolMessageType('EmbeddingInfo', (_message.Message,), {'DESCRIPTOR': _EMBEDDINGINFO, '__module__': 'keras.protobuf.projector_config_pb2'})
A:keras.protobuf.projector_config_pb2.ProjectorConfig->google.protobuf.reflection.GeneratedProtocolMessageType('ProjectorConfig', (_message.Message,), {'DESCRIPTOR': _PROJECTORCONFIG, '__module__': 'keras.protobuf.projector_config_pb2'})


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/testing_infra/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/testing_infra/test_combinations.py----------------------------------------
A:keras.testing_infra.test_combinations.cls->type(cls).__new__(type(cls), cls.__name__, cls.__bases__, cls.__dict__.copy())
A:keras.testing_infra.test_combinations.run_eagerly->kwargs.pop('run_eagerly', None)
A:keras.testing_infra.test_combinations.model_type->kwargs.pop('model_type', None)
A:keras.testing_infra.test_combinations.generate->functools.partial(tf.__internal__.test.combinations.generate, test_combinations=_defaults + (KerasModeCombination(), KerasModelTypeCombination()))
keras.testing_infra.test_combinations.KerasModeCombination(tf.__internal__.test.combinations.TestCombination)
keras.testing_infra.test_combinations.KerasModeCombination.context_managers(self,kwargs)
keras.testing_infra.test_combinations.KerasModeCombination.parameter_modifiers(self)
keras.testing_infra.test_combinations.KerasModelTypeCombination(tf.__internal__.test.combinations.TestCombination)
keras.testing_infra.test_combinations.KerasModelTypeCombination.context_managers(self,kwargs)
keras.testing_infra.test_combinations.KerasModelTypeCombination.parameter_modifiers(self)
keras.testing_infra.test_combinations.TestCase(tf.test.TestCase,parameterized.TestCase)
keras.testing_infra.test_combinations.TestCase.tearDown(self)
keras.testing_infra.test_combinations._test_functional_model_type(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._test_h5_saved_model_format(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._test_or_class_decorator(test_or_class,single_method_decorator)
keras.testing_infra.test_combinations._test_sequential_model_type(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._test_subclass_model_type(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._test_tf_saved_model_format(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._test_tf_saved_model_format_no_traces(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._v1_session_test(f,test_or_class,config,*args,**kwargs)
keras.testing_infra.test_combinations._v2_eager_test(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations._v2_function_test(f,test_or_class,*args,**kwargs)
keras.testing_infra.test_combinations.keras_mode_combinations(mode=None,run_eagerly=None)
keras.testing_infra.test_combinations.keras_model_type_combinations()
keras.testing_infra.test_combinations.run_all_keras_modes(test_or_class=None,config=None,always_skip_v1=False,always_skip_eager=False,**kwargs)
keras.testing_infra.test_combinations.run_with_all_model_types(test_or_class=None,exclude_models=None)
keras.testing_infra.test_combinations.run_with_all_saved_model_formats(test_or_class=None,exclude_formats=None)
keras.testing_infra.test_combinations.run_with_all_weight_formats(test_or_class=None,exclude_formats=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/testing_infra/keras_doctest_lib.py----------------------------------------
A:keras.testing_infra.keras_doctest_lib._FLOAT_RE->re.compile('\n      (                          # Captures the float value.\n        (?:\n           [-+]|                 # Start with a sign is okay anywhere.\n           (?:                   # Otherwise:\n               ^|                # Start after the start of string\n               (?<=[^\\w.])       # Not after a word char, or a .\n           )\n        )\n        (?:                      # Digits and exponent - something like:\n          {digits_dot_maybe_digits}{exponent}?|   # "1.0" "1." "1.0e3", "1.e3"\n          {dot_digits}{exponent}?|                # ".1" ".1e3"\n          {digits}{exponent}|                     # "1e3"\n          {digits}(?=j)                           # "300j"\n        )\n      )\n      j?                         # Optional j for cplx numbers, not captured.\n      (?=                        # Only accept the match if\n        $|                       # * At the end of the string, or\n        [^\\w.]                   # * Next char is not a word char or "."\n      )\n      '.format(digits_dot_maybe_digits='(?:[0-9]+\\.(?:[0-9]*))', dot_digits='(?:\\.[0-9]+)', digits='(?:[0-9]+)', exponent='(?:[eE][-+]?[0-9]+)'), re.VERBOSE)
A:keras.testing_infra.keras_doctest_lib.self.extract_floats->_FloatExtractor()
A:keras.testing_infra.keras_doctest_lib._ADDRESS_RE->re.compile('\\bat 0x[0-9a-f]*?>')
A:keras.testing_infra.keras_doctest_lib._NUMPY_OUTPUT_RE->re.compile('<tf.Tensor.*?numpy=(.*?)>', re.DOTALL)
A:keras.testing_infra.keras_doctest_lib.modified_string->self._NUMPY_OUTPUT_RE.sub('\\1', string)
A:keras.testing_infra.keras_doctest_lib.MESSAGE->textwrap.dedent('\n\n        #############################################################\n        Check the documentation (go/testable-docstrings) on how to\n        write testable docstrings.\n        #############################################################')
A:keras.testing_infra.keras_doctest_lib.want->self._ADDRESS_RE.sub('at ...>', want)
A:keras.testing_infra.keras_doctest_lib.(want, want_changed)->self._tf_tensor_numpy_output(want)
A:keras.testing_infra.keras_doctest_lib.(got, _)->self._tf_tensor_numpy_output(got)
A:keras.testing_infra.keras_doctest_lib.(want_text_parts, self.want_floats)->self.extract_floats(want)
A:keras.testing_infra.keras_doctest_lib.want_text_wild->'...'.join(want_text_parts)
A:keras.testing_infra.keras_doctest_lib.(_, self.got_floats)->self.extract_floats(got)
A:keras.testing_infra.keras_doctest_lib.self.text_good->super().check_output(want=want_text_wild, got=got, optionflags=optionflags)
A:keras.testing_infra.keras_doctest_lib.got->'\n'.join(got)
keras.testing_infra.keras_doctest_lib.KerasDoctestOutputChecker(self,*args,**kwargs)
keras.testing_infra.keras_doctest_lib.KerasDoctestOutputChecker.__init__(self,*args,**kwargs)
keras.testing_infra.keras_doctest_lib.KerasDoctestOutputChecker._allclose(self,want,got,rtol=0.001,atol=0.001)
keras.testing_infra.keras_doctest_lib.KerasDoctestOutputChecker._tf_tensor_numpy_output(self,string)
keras.testing_infra.keras_doctest_lib.KerasDoctestOutputChecker.check_output(self,want,got,optionflags)
keras.testing_infra.keras_doctest_lib.KerasDoctestOutputChecker.output_difference(self,example,got,optionflags)
keras.testing_infra.keras_doctest_lib._FloatExtractor(self,string)
keras.testing_infra.keras_doctest_lib._FloatExtractor.__call__(self,string)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/testing_infra/test_utils.py----------------------------------------
A:keras.testing_infra.test_utils.y->layer(x)
A:keras.testing_infra.test_utils.x->layer(x)
A:keras.testing_infra.test_utils.input_data_shape->list(input_shape)
A:keras.testing_infra.test_utils.input_data_shape[i]->numpy.random.randint(1, 4)
A:keras.testing_infra.test_utils.input_data->input_data.astype(input_dtype).astype(input_dtype)
A:keras.testing_infra.test_utils.layer->getattr(self, self._layer_name_for_i(i))
A:keras.testing_infra.test_utils.weights->keras.models.Sequential(name=name).get_weights()
A:keras.testing_infra.test_utils.model->keras.models.Sequential(name=name)
A:keras.testing_infra.test_utils.computed_output_shape->tuple(layer.compute_output_shape(tf.TensorShape(input_shape)).as_list())
A:keras.testing_infra.test_utils.computed_output_signature->getattr(self, self._layer_name_for_i(i)).compute_output_signature(tf.TensorSpec(shape=input_shape, dtype=input_dtype))
A:keras.testing_infra.test_utils.actual_output->keras.models.Sequential(name=name).predict(input_data)
A:keras.testing_infra.test_utils.model_config->keras.models.Sequential(name=name).get_config()
A:keras.testing_infra.test_utils.recovered_model->keras.models.Sequential.from_config(model_config, custom_objects)
A:keras.testing_infra.test_utils.output->keras.models.Sequential.from_config(model_config, custom_objects).predict(input_data)
A:keras.testing_infra.test_utils.layer_weights->getattr(self, self._layer_name_for_i(i)).get_weights()
A:keras.testing_infra.test_utils.layer_config->getattr(self, self._layer_name_for_i(i)).get_config()
A:keras.testing_infra.test_utils._thread_local_data->threading.local()
A:keras.testing_infra.test_utils.inputs->layer(inputs)
A:keras.testing_infra.test_utils.outputs->layer(outputs)
A:keras.testing_infra.test_utils.self.layer_a->keras.layers.Dense(self.num_hidden, activation='relu')
A:keras.testing_infra.test_utils.self.layer_b->keras.layers.Dense(self.num_classes, activation=activation)
A:keras.testing_infra.test_utils.self.dp->keras.layers.Dropout(0.5)
A:keras.testing_infra.test_utils.self.bn->keras.layers.BatchNormalization(axis=-1)
A:keras.testing_infra.test_utils.model_type->get_model_type()
A:keras.testing_infra.test_utils.self.num_layers->len(model_layers)
A:keras.testing_infra.test_utils.self.bias->self.add_weight('bias', (1,), initializer='zeros')
A:keras.testing_infra.test_utils.a->layer(a)
A:keras.testing_infra.test_utils.b->layer(b)
A:keras.testing_infra.test_utils.outs->layer(outs)
A:keras.testing_infra.test_utils.self._shared_input_branch->self._shared_input_branch_func()
A:keras.testing_infra.test_utils.self._branch_a->self._branch_a_func()
A:keras.testing_infra.test_utils.self._branch_b->self._branch_b_func()
A:keras.testing_infra.test_utils.self._shared_output_branch->self._shared_output_branch_func()
A:keras.testing_infra.test_utils.a_and_b->layer(a_and_b)
A:keras.testing_infra.test_utils.value->getattr(cls, name)
A:keras.testing_infra.test_utils.allowed->tensorflow.compat.v2.config.experimental.tensor_float_32_execution_enabled()
A:keras.testing_infra.test_utils.name->''.join(['_{}_{}'.format(''.join(filter(str.isalnum, key)), ''.join(filter(str.isalnum, str(value)))) for (key, value) in combination.items()])
keras.testing_infra.test_utils.Bias(layers.Layer)
keras.testing_infra.test_utils.Bias.build(self,input_shape)
keras.testing_infra.test_utils.Bias.call(self,inputs)
keras.testing_infra.test_utils.SmallSubclassMLP(self,num_hidden,num_classes,use_bn=False,use_dp=False,**kwargs)
keras.testing_infra.test_utils.SmallSubclassMLP.__init__(self,num_hidden,num_classes,use_bn=False,use_dp=False,**kwargs)
keras.testing_infra.test_utils.SmallSubclassMLP.call(self,inputs,**kwargs)
keras.testing_infra.test_utils._MultiIOSubclassModel(self,branch_a,branch_b,shared_input_branch=None,shared_output_branch=None,name=None)
keras.testing_infra.test_utils._MultiIOSubclassModel.__init__(self,branch_a,branch_b,shared_input_branch=None,shared_output_branch=None,name=None)
keras.testing_infra.test_utils._MultiIOSubclassModel.call(self,inputs,**kwargs)
keras.testing_infra.test_utils._MultiIOSubclassModelCustomBuild(self,branch_a_func,branch_b_func,shared_input_branch_func=None,shared_output_branch_func=None)
keras.testing_infra.test_utils._MultiIOSubclassModelCustomBuild.__init__(self,branch_a_func,branch_b_func,shared_input_branch_func=None,shared_output_branch_func=None)
keras.testing_infra.test_utils._MultiIOSubclassModelCustomBuild.build(self,input_shape)
keras.testing_infra.test_utils._MultiIOSubclassModelCustomBuild.call(self,inputs,**kwargs)
keras.testing_infra.test_utils._SmallSubclassMLPCustomBuild(self,num_hidden,num_classes)
keras.testing_infra.test_utils._SmallSubclassMLPCustomBuild.__init__(self,num_hidden,num_classes)
keras.testing_infra.test_utils._SmallSubclassMLPCustomBuild.build(self,input_shape)
keras.testing_infra.test_utils._SmallSubclassMLPCustomBuild.call(self,inputs,**kwargs)
keras.testing_infra.test_utils._SubclassModel(self,model_layers,*args,**kwargs)
keras.testing_infra.test_utils._SubclassModel.__init__(self,model_layers,*args,**kwargs)
keras.testing_infra.test_utils._SubclassModel._layer_name_for_i(self,i)
keras.testing_infra.test_utils._SubclassModel.call(self,inputs,**kwargs)
keras.testing_infra.test_utils._SubclassModel.get_config(self)
keras.testing_infra.test_utils._SubclassModelCustomBuild(self,layer_generating_func,*args,**kwargs)
keras.testing_infra.test_utils._SubclassModelCustomBuild.__init__(self,layer_generating_func,*args,**kwargs)
keras.testing_infra.test_utils._SubclassModelCustomBuild.build(self,input_shape)
keras.testing_infra.test_utils._SubclassModelCustomBuild.call(self,inputs,**kwargs)
keras.testing_infra.test_utils._set_v2_dtype_behavior(fn,enabled)
keras.testing_infra.test_utils.device(should_use_gpu)
keras.testing_infra.test_utils.disable_v2_dtype_behavior(fn)
keras.testing_infra.test_utils.enable_v2_dtype_behavior(fn)
keras.testing_infra.test_utils.for_all_test_methods(decorator,*args,**kwargs)
keras.testing_infra.test_utils.generate_combinations_with_testcase_name(**kwargs)
keras.testing_infra.test_utils.get_expected_metric_variable_names(var_names,name_suffix='')
keras.testing_infra.test_utils.get_model_from_layers(model_layers,input_shape=None,input_dtype=None,name=None,input_ragged=None,input_sparse=None,model_type=None)
keras.testing_infra.test_utils.get_model_type()
keras.testing_infra.test_utils.get_multi_io_model(branch_a,branch_b,shared_input_branch=None,shared_output_branch=None)
keras.testing_infra.test_utils.get_save_format()
keras.testing_infra.test_utils.get_save_kwargs()
keras.testing_infra.test_utils.get_small_functional_mlp(num_hidden,num_classes,input_dim)
keras.testing_infra.test_utils.get_small_mlp(num_hidden,num_classes,input_dim)
keras.testing_infra.test_utils.get_small_sequential_mlp(num_hidden,num_classes,input_dim=None)
keras.testing_infra.test_utils.get_small_subclass_mlp(num_hidden,num_classes)
keras.testing_infra.test_utils.get_small_subclass_mlp_with_custom_build(num_hidden,num_classes)
keras.testing_infra.test_utils.get_test_data(train_samples,test_samples,input_shape,num_classes,random_seed=None)
keras.testing_infra.test_utils.get_v2_optimizer(name,**kwargs)
keras.testing_infra.test_utils.layer_test(layer_cls,kwargs=None,input_shape=None,input_dtype=None,input_data=None,expected_output=None,expected_output_dtype=None,expected_output_shape=None,validate_training=True,adapt_data=None,custom_objects=None,test_harness=None,supports_masking=None)
keras.testing_infra.test_utils.model_type_scope(value)
keras.testing_infra.test_utils.numeric_test(actual,expected)
keras.testing_infra.test_utils.run_all_without_tensor_float_32(description)
keras.testing_infra.test_utils.run_eagerly_scope(value)
keras.testing_infra.test_utils.run_v2_only(obj=None)
keras.testing_infra.test_utils.run_without_tensor_float_32(description)
keras.testing_infra.test_utils.saved_model_format_scope(value,**kwargs)
keras.testing_infra.test_utils.should_run_eagerly()
keras.testing_infra.test_utils.string_test(actual,expected)
keras.testing_infra.test_utils.use_gpu()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/__init__.py----------------------------------------
keras.layers.__init__.VersionAwareLayers
keras.layers.__init__.VersionAwareLayers.__getattr__(self,name)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/noise.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/serialization.py----------------------------------------
A:keras.layers.serialization.LOCAL->threading.local()
A:keras.layers.serialization.LOCAL.GENERATED_WITH_V2->tensorflow.compat.v2.__internal__.tf2.enabled()
A:keras.layers.serialization.config->keras.saving.saved_model.json_utils.decode_and_deserialize(json_string, module_objects=LOCAL.ALL_OBJECTS, custom_objects=custom_objects)
keras.layers.deserialize(config,custom_objects=None)
keras.layers.deserialize_from_json(json_string,custom_objects=None)
keras.layers.get_builtin_layer(class_name)
keras.layers.serialization.deserialize(config,custom_objects=None)
keras.layers.serialization.deserialize_from_json(json_string,custom_objects=None)
keras.layers.serialization.get_builtin_layer(class_name)
keras.layers.serialization.populate_deserializable_objects()
keras.layers.serialization.serialize(layer)
keras.layers.serialize(layer)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/kernelized.py----------------------------------------
A:keras.layers.kernelized.input_shape->input_shape.with_rank(2).with_rank(2)
A:keras.layers.kernelized.self.input_spec->keras.engine.input_spec.InputSpec(ndim=2, axes={1: input_shape.dims[1].value})
A:keras.layers.kernelized.kernel_initializer->keras.initializers.serialize(kernel_initializer)
A:keras.layers.kernelized.self.unscaled_kernel->self.add_weight(name='unscaled_kernel', shape=(input_dim, self.output_dim), dtype=tf.float32, initializer=kernel_initializer, trainable=False)
A:keras.layers.kernelized.self.bias->self.add_weight(name='bias', shape=(self.output_dim,), dtype=tf.float32, initializer=initializers.RandomUniform(minval=0.0, maxval=2 * np.pi), trainable=False)
A:keras.layers.kernelized.self.scale->_get_default_scale(self.kernel_initializer, input_dim)
A:keras.layers.kernelized.self.kernel_scale->self.add_weight(name='kernel_scale', shape=(1,), dtype=tf.float32, initializer=tf.compat.v1.constant_initializer(self.scale), trainable=True, constraint='NonNeg')
A:keras.layers.kernelized.inputs->tensorflow.compat.v2.cast(inputs, tf.float32)
A:keras.layers.kernelized.outputs->tensorflow.compat.v2.nn.bias_add(outputs, self.bias)
A:keras.layers.kernelized.base_config->super(RandomFourierFeatures, self).get_config()
A:keras.layers.kernelized.probs->numpy.random.uniform(low=0.0, high=1.0, size=shape)
A:keras.layers.kernelized.random_features_initializer->keras.initializers.Constant(_get_cauchy_samples(loc=0.0, scale=1.0, shape=shape))
keras.layers.RandomFourierFeatures(self,output_dim,kernel_initializer='gaussian',scale=None,trainable=False,name=None,**kwargs)
keras.layers.RandomFourierFeatures.build(self,input_shape)
keras.layers.RandomFourierFeatures.call(self,inputs)
keras.layers.RandomFourierFeatures.compute_output_shape(self,input_shape)
keras.layers.RandomFourierFeatures.get_config(self)
keras.layers.kernelized.RandomFourierFeatures(self,output_dim,kernel_initializer='gaussian',scale=None,trainable=False,name=None,**kwargs)
keras.layers.kernelized.RandomFourierFeatures.__init__(self,output_dim,kernel_initializer='gaussian',scale=None,trainable=False,name=None,**kwargs)
keras.layers.kernelized.RandomFourierFeatures.build(self,input_shape)
keras.layers.kernelized.RandomFourierFeatures.call(self,inputs)
keras.layers.kernelized.RandomFourierFeatures.compute_output_shape(self,input_shape)
keras.layers.kernelized.RandomFourierFeatures.get_config(self)
keras.layers.kernelized._get_default_scale(initializer,input_dim)
keras.layers.kernelized._get_random_features_initializer(initializer,shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/einsum_dense.py----------------------------------------
A:keras.layers.einsum_dense.self.partial_output_shape->list(output_shape)
A:keras.layers.einsum_dense.self.activation->keras.activations.get(activation)
A:keras.layers.einsum_dense.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.einsum_dense.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.einsum_dense.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.einsum_dense.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.einsum_dense.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.einsum_dense.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.einsum_dense.input_shape->tensorflow.compat.v2.TensorShape(input_shape)
A:keras.layers.einsum_dense.shape_data->_analyze_einsum_string(self.equation, self.bias_axes, input_shape, self.partial_output_shape)
A:keras.layers.einsum_dense.self.kernel->self.add_weight('kernel', shape=kernel_shape, initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, dtype=self.dtype, trainable=True)
A:keras.layers.einsum_dense.self.bias->self.add_weight('bias', shape=bias_shape, initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, dtype=self.dtype, trainable=True)
A:keras.layers.einsum_dense.base_config->super(EinsumDense, self).get_config()
A:keras.layers.einsum_dense.ret->self.activation(ret)
A:keras.layers.einsum_dense.dot_replaced_string->re.sub('\\.\\.\\.', '0', equation)
A:keras.layers.einsum_dense.split_string->re.match('([a-zA-Z]{2,})0,([a-zA-Z]+)->([a-zA-Z]+)0', dot_replaced_string)
A:keras.layers.einsum_dense.input_spec->re.match('([a-zA-Z]{2,})0,([a-zA-Z]+)->([a-zA-Z]+)0', dot_replaced_string).group(1)
A:keras.layers.einsum_dense.weight_spec->re.match('([a-zA-Z]{2,})0,([a-zA-Z]+)->([a-zA-Z]+)0', dot_replaced_string).group(2)
A:keras.layers.einsum_dense.output_spec->re.match('([a-zA-Z]{2,})0,([a-zA-Z]+)->([a-zA-Z]+)0', dot_replaced_string).group(3)
A:keras.layers.einsum_dense.output_shape->list(output_shape)
A:keras.layers.einsum_dense.first_bias_location->min([output_spec.find(char) for char in bias_axes])
keras.layers.EinsumDense(self,equation,output_shape,activation=None,bias_axes=None,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.EinsumDense.build(self,input_shape)
keras.layers.EinsumDense.call(self,inputs)
keras.layers.EinsumDense.compute_output_shape(self,_)
keras.layers.EinsumDense.get_config(self)
keras.layers.einsum_dense.EinsumDense(self,equation,output_shape,activation=None,bias_axes=None,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.einsum_dense.EinsumDense.__init__(self,equation,output_shape,activation=None,bias_axes=None,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.einsum_dense.EinsumDense.build(self,input_shape)
keras.layers.einsum_dense.EinsumDense.call(self,inputs)
keras.layers.einsum_dense.EinsumDense.compute_output_shape(self,_)
keras.layers.einsum_dense.EinsumDense.get_config(self)
keras.layers.einsum_dense._analyze_einsum_string(equation,bias_axes,input_shape,output_shape)
keras.layers.einsum_dense._analyze_split_string(split_string,bias_axes,input_shape,output_shape,left_elided=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/dense.py----------------------------------------
A:keras.layers.core.dense.self.activation->keras.activations.get(activation)
A:keras.layers.core.dense.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.core.dense.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.core.dense.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.core.dense.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.core.dense.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.core.dense.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.core.dense.self.input_spec->InputSpec(min_ndim=2, axes={-1: last_dim})
A:keras.layers.core.dense.dtype->tensorflow.compat.v2.as_dtype(self.dtype or backend.floatx())
A:keras.layers.core.dense.input_shape->input_shape.with_rank_at_least(2).with_rank_at_least(2)
A:keras.layers.core.dense.last_dim->tensorflow.compat.v2.compat.dimension_value(input_shape[-1])
A:keras.layers.core.dense.self.kernel->self.add_weight('kernel', shape=[last_dim, self.units], initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, dtype=self.dtype, trainable=True)
A:keras.layers.core.dense.self.bias->self.add_weight('bias', shape=[self.units], initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, dtype=self.dtype, trainable=True)
A:keras.layers.core.dense.inputs->inputs.to_tensor().to_tensor()
A:keras.layers.core.dense.is_ragged->isinstance(inputs, tf.RaggedTensor)
A:keras.layers.core.dense.original_inputs->tensorflow.compat.v2.RaggedTensor.from_nested_row_splits(inputs, original_inputs.nested_row_splits[:-1])
A:keras.layers.core.dense.(inputs, _)->tensorflow.compat.v2.sparse.fill_empty_rows(inputs, 0)
A:keras.layers.core.dense.ids->tensorflow.compat.v2.SparseTensor(indices=inputs.indices, values=inputs.indices[:, 1], dense_shape=inputs.dense_shape)
A:keras.layers.core.dense.outputs->tensorflow.compat.v2.RaggedTensor.from_nested_row_splits(inputs, original_inputs.nested_row_splits[:-1]).with_flat_values(outputs)
A:keras.layers.core.dense.shape->inputs.to_tensor().to_tensor().shape.as_list()
A:keras.layers.core.dense.config->super(Dense, self).get_config()
keras.layers.core.Dense(self,units,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.core.Dense.build(self,input_shape)
keras.layers.core.Dense.call(self,inputs)
keras.layers.core.Dense.compute_output_shape(self,input_shape)
keras.layers.core.Dense.get_config(self)
keras.layers.core.dense.Dense(self,units,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.core.dense.Dense.__init__(self,units,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.core.dense.Dense.build(self,input_shape)
keras.layers.core.dense.Dense.call(self,inputs)
keras.layers.core.dense.Dense.compute_output_shape(self,input_shape)
keras.layers.core.dense.Dense.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/masking.py----------------------------------------
A:keras.layers.core.masking.boolean_mask->tensorflow.compat.v2.reduce_any(tf.not_equal(inputs, self.mask_value), axis=-1, keepdims=True)
A:keras.layers.core.masking.outputs._keras_mask->tensorflow.compat.v2.squeeze(boolean_mask, axis=-1)
A:keras.layers.core.masking.base_config->super(Masking, self).get_config()
keras.layers.core.Masking(self,mask_value=0.0,**kwargs)
keras.layers.core.Masking.call(self,inputs)
keras.layers.core.Masking.compute_mask(self,inputs,mask=None)
keras.layers.core.Masking.compute_output_shape(self,input_shape)
keras.layers.core.Masking.get_config(self)
keras.layers.core.masking.Masking(self,mask_value=0.0,**kwargs)
keras.layers.core.masking.Masking.__init__(self,mask_value=0.0,**kwargs)
keras.layers.core.masking.Masking.call(self,inputs)
keras.layers.core.masking.Masking.compute_mask(self,inputs,mask=None)
keras.layers.core.masking.Masking.compute_output_shape(self,input_shape)
keras.layers.core.masking.Masking.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/tf_op_layer.py----------------------------------------
A:keras.layers.core.tf_op_layer.kwargs['name']->keras.backend.unique_object_name(name, zero_based=True, avoid_observed_names=True)
A:keras.layers.core.tf_op_layer.base_config->super(TFOpLambda, self).get_config()
A:keras.layers.core.tf_op_layer.config->config.copy().copy()
A:keras.layers.core.tf_op_layer.symbol_name->config.copy().copy().pop('cls_symbol')
A:keras.layers.core.tf_op_layer.cls_ref->get_symbol_from_name(symbol_name)
A:keras.layers.core.tf_op_layer.method->getattr(obj, self.attr_name)
A:keras.layers.core.tf_op_layer.self.call->tensorflow.compat.v2.__internal__.decorator.make_decorator(original_call, _call_wrapper)
A:keras.layers.core.tf_op_layer.var->next_creator(**creator_kwargs)
A:keras.layers.core.tf_op_layer.result->self.function(*args, **kwargs)
A:keras.layers.core.tf_op_layer.tracked_weights->set((v.ref() for v in self.weights))
A:keras.layers.core.tf_op_layer.variable_str->'\n'.join(('  {}'.format(i) for i in untracked_used_vars))
A:keras.layers.core.tf_op_layer.function->get_symbol_from_name(symbol_name)
A:keras.layers.core.tf_op_layer.property_access->property(lambda self: InstanceProperty(property_name)(self))
A:keras.layers.core.tf_op_layer.arg->_dict_to_slice(arg)
A:keras.layers.core.tf_op_layer.value->_dict_to_slice(value)
A:keras.layers.core.tf_op_layer.args->tensorflow.compat.v2.nest.map_structure(_slice_to_dict, args)
A:keras.layers.core.tf_op_layer.kwargs->tensorflow.compat.v2.nest.map_structure(_slice_to_dict, kwargs)
keras.layers.core.ClassMethod(self,cls_ref,method_name,**kwargs)
keras.layers.core.ClassMethod.call(self,args,kwargs)
keras.layers.core.ClassMethod.from_config(cls,config,custom_objects=None)
keras.layers.core.ClassMethod.get_config(self)
keras.layers.core.InstanceMethod(InstanceProperty)
keras.layers.core.InstanceMethod.call(self,obj,args,kwargs)
keras.layers.core.InstanceProperty(self,attr_name,**kwargs)
keras.layers.core.InstanceProperty.call(self,obj)
keras.layers.core.InstanceProperty.from_config(cls,config,custom_objects=None)
keras.layers.core.InstanceProperty.get_config(self)
keras.layers.core.SlicingOpLambda(self,function,**kwargs)
keras.layers.core.TFOpLambda(self,function,**kwargs)
keras.layers.core.TFOpLambda._call_wrapper(self,*args,**kwargs)
keras.layers.core.TFOpLambda._check_variables(self,created_variables,accessed_variables)
keras.layers.core.TFOpLambda._warn(self,msg)
keras.layers.core.TFOpLambda.from_config(cls,config,custom_objects=None)
keras.layers.core.TFOpLambda.get_config(self)
keras.layers.core._delegate_method(keras_tensor_cls,method_name)
keras.layers.core._delegate_property(keras_tensor_cls,property_name)
keras.layers.core.tf_op_layer.ClassMethod(self,cls_ref,method_name,**kwargs)
keras.layers.core.tf_op_layer.ClassMethod.__init__(self,cls_ref,method_name,**kwargs)
keras.layers.core.tf_op_layer.ClassMethod.call(self,args,kwargs)
keras.layers.core.tf_op_layer.ClassMethod.from_config(cls,config,custom_objects=None)
keras.layers.core.tf_op_layer.ClassMethod.get_config(self)
keras.layers.core.tf_op_layer.InstanceMethod(InstanceProperty)
keras.layers.core.tf_op_layer.InstanceMethod.call(self,obj,args,kwargs)
keras.layers.core.tf_op_layer.InstanceProperty(self,attr_name,**kwargs)
keras.layers.core.tf_op_layer.InstanceProperty.__init__(self,attr_name,**kwargs)
keras.layers.core.tf_op_layer.InstanceProperty.call(self,obj)
keras.layers.core.tf_op_layer.InstanceProperty.from_config(cls,config,custom_objects=None)
keras.layers.core.tf_op_layer.InstanceProperty.get_config(self)
keras.layers.core.tf_op_layer.KerasOpDispatcher(tf.__internal__.dispatch.GlobalOpDispatcher)
keras.layers.core.tf_op_layer.KerasOpDispatcher.handle(self,op,args,kwargs)
keras.layers.core.tf_op_layer.SlicingOpLambda(self,function,**kwargs)
keras.layers.core.tf_op_layer.SlicingOpLambda.__init__(self,function,**kwargs)
keras.layers.core.tf_op_layer.TFClassMethodDispatcher(self,cls,method_name)
keras.layers.core.tf_op_layer.TFClassMethodDispatcher.__init__(self,cls,method_name)
keras.layers.core.tf_op_layer.TFClassMethodDispatcher.handle(self,args,kwargs)
keras.layers.core.tf_op_layer.TFOpLambda(self,function,**kwargs)
keras.layers.core.tf_op_layer.TFOpLambda.__init__(self,function,**kwargs)
keras.layers.core.tf_op_layer.TFOpLambda._call_wrapper(self,*args,**kwargs)
keras.layers.core.tf_op_layer.TFOpLambda._check_variables(self,created_variables,accessed_variables)
keras.layers.core.tf_op_layer.TFOpLambda._warn(self,msg)
keras.layers.core.tf_op_layer.TFOpLambda.from_config(cls,config,custom_objects=None)
keras.layers.core.tf_op_layer.TFOpLambda.get_config(self)
keras.layers.core.tf_op_layer.TFSlicingOpDispatcher(self,op)
keras.layers.core.tf_op_layer.TFSlicingOpDispatcher.__init__(self,op)
keras.layers.core.tf_op_layer.TFSlicingOpDispatcher.handle(self,args,kwargs)
keras.layers.core.tf_op_layer._delegate_method(keras_tensor_cls,method_name)
keras.layers.core.tf_op_layer._delegate_property(keras_tensor_cls,property_name)
keras.layers.core.tf_op_layer._dict_to_slice(x)
keras.layers.core.tf_op_layer._slice_to_dict(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/lambda_layer.py----------------------------------------
A:keras.layers.core.lambda_layer.output_shapes->keras.utils.tf_utils.convert_shapes(self._output_shape, to_tuples=False)
A:keras.layers.core.lambda_layer.input_tensor_shape->keras.utils.tf_utils.convert_shapes(input_shape, to_tuples=False)
A:keras.layers.core.lambda_layer.var->next_creator(**kwargs)
A:keras.layers.core.lambda_layer.result->self.function(inputs, **kwargs)
A:keras.layers.core.lambda_layer.tracked_weights->set((v.ref() for v in self.weights))
A:keras.layers.core.lambda_layer.variable_str->'\n'.join(('  {}'.format(i) for i in untracked_used_vars))
A:keras.layers.core.lambda_layer.error_str->textwrap.dedent('\n          The following Variables were created within a Lambda layer ({name})\n          but are not tracked by said layer:\n          {variable_str}\n          The layer cannot safely ensure proper Variable reuse across multiple\n          calls, and consequently this behavior is disallowed for safety. Lambda\n          layers are not well suited to stateful computation; instead, writing a\n          subclassed Layer is the recommend way to define layers with\n          Variables.').format(name=self.name, variable_str=variable_str)
A:keras.layers.core.lambda_layer.function_config->self._serialize_function_to_config(self.function)
A:keras.layers.core.lambda_layer.output_shape_config->self._serialize_function_to_config(self._output_shape, allow_raw=True)
A:keras.layers.core.lambda_layer.mask_config->self._serialize_function_to_config(self.mask)
A:keras.layers.core.lambda_layer.base_config->super(Lambda, self).get_config()
A:keras.layers.core.lambda_layer.output->keras.utils.generic_utils.func_dump(inputs)
A:keras.layers.core.lambda_layer.config->config.copy().copy()
A:keras.layers.core.lambda_layer.function->keras.utils.generic_utils.func_load(config[func_attr_name], globs=globs)
A:keras.layers.core.lambda_layer.output_shape->cls._parse_function_from_config(config, custom_objects, 'output_shape', 'output_shape_module', 'output_shape_type')
A:keras.layers.core.lambda_layer.mask->cls._parse_function_from_config(config, custom_objects, 'mask', 'mask_module', 'mask_type')
A:keras.layers.core.lambda_layer.config['arguments'][key]->numpy.array(arg_dict['value'])
A:keras.layers.core.lambda_layer.globs->globals().copy()
A:keras.layers.core.lambda_layer.module->config.copy().copy().pop(module_attr_name, None)
A:keras.layers.core.lambda_layer.function_type->config.copy().copy().pop(func_type_attr_name)
keras.layers.core.Lambda(self,function,output_shape=None,mask=None,arguments=None,**kwargs)
keras.layers.core.Lambda._check_variables(self,created_variables,accessed_variables)
keras.layers.core.Lambda._parse_function_from_config(cls,config,custom_objects,func_attr_name,module_attr_name,func_type_attr_name)
keras.layers.core.Lambda._serialize_function_to_config(self,inputs,allow_raw=False)
keras.layers.core.Lambda._warn(self,msg)
keras.layers.core.Lambda.call(self,inputs,mask=None,training=None)
keras.layers.core.Lambda.compute_mask(self,inputs,mask=None)
keras.layers.core.Lambda.compute_output_shape(self,input_shape)
keras.layers.core.Lambda.from_config(cls,config,custom_objects=None)
keras.layers.core.Lambda.get_config(self)
keras.layers.core.lambda_layer.Lambda(self,function,output_shape=None,mask=None,arguments=None,**kwargs)
keras.layers.core.lambda_layer.Lambda.__init__(self,function,output_shape=None,mask=None,arguments=None,**kwargs)
keras.layers.core.lambda_layer.Lambda._check_variables(self,created_variables,accessed_variables)
keras.layers.core.lambda_layer.Lambda._parse_function_from_config(cls,config,custom_objects,func_attr_name,module_attr_name,func_type_attr_name)
keras.layers.core.lambda_layer.Lambda._serialize_function_to_config(self,inputs,allow_raw=False)
keras.layers.core.lambda_layer.Lambda._warn(self,msg)
keras.layers.core.lambda_layer.Lambda.call(self,inputs,mask=None,training=None)
keras.layers.core.lambda_layer.Lambda.compute_mask(self,inputs,mask=None)
keras.layers.core.lambda_layer.Lambda.compute_output_shape(self,input_shape)
keras.layers.core.lambda_layer.Lambda.from_config(cls,config,custom_objects=None)
keras.layers.core.lambda_layer.Lambda.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/activation.py----------------------------------------
A:keras.layers.core.activation.self.activation->keras.activations.get(activation)
A:keras.layers.core.activation.base_config->super(Activation, self).get_config()
keras.layers.core.Activation(self,activation,**kwargs)
keras.layers.core.Activation.call(self,inputs)
keras.layers.core.Activation.compute_output_shape(self,input_shape)
keras.layers.core.Activation.get_config(self)
keras.layers.core.activation.Activation(self,activation,**kwargs)
keras.layers.core.activation.Activation.__init__(self,activation,**kwargs)
keras.layers.core.activation.Activation.call(self,inputs)
keras.layers.core.activation.Activation.compute_output_shape(self,input_shape)
keras.layers.core.activation.Activation.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/core/embedding.py----------------------------------------
A:keras.layers.core.embedding.kwargs['dtype']->keras.backend.floatx()
A:keras.layers.core.embedding.self.embeddings_initializer->keras.initializers.get(embeddings_initializer)
A:keras.layers.core.embedding.self.embeddings_regularizer->keras.regularizers.get(embeddings_regularizer)
A:keras.layers.core.embedding.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.core.embedding.self.embeddings_constraint->keras.constraints.get(embeddings_constraint)
A:keras.layers.core.embedding.self.embeddings->self.add_weight(shape=(self.input_dim, self.output_dim), initializer=self.embeddings_initializer, name='embeddings', regularizer=self.embeddings_regularizer, constraint=self.embeddings_constraint, experimental_autocast=False)
A:keras.layers.core.embedding.in_lens->list(self.input_length)
A:keras.layers.core.embedding.dtype->keras.backend.dtype(inputs)
A:keras.layers.core.embedding.inputs->tensorflow.compat.v2.cast(inputs, 'int32')
A:keras.layers.core.embedding.out->tensorflow.compat.v2.cast(out, self._dtype_policy.compute_dtype)
A:keras.layers.core.embedding.base_config->super(Embedding, self).get_config()
keras.layers.core.Embedding(self,input_dim,output_dim,embeddings_initializer='uniform',embeddings_regularizer=None,activity_regularizer=None,embeddings_constraint=None,mask_zero=False,input_length=None,**kwargs)
keras.layers.core.Embedding.build(self,input_shape=None)
keras.layers.core.Embedding.call(self,inputs)
keras.layers.core.Embedding.compute_mask(self,inputs,mask=None)
keras.layers.core.Embedding.compute_output_shape(self,input_shape)
keras.layers.core.Embedding.get_config(self)
keras.layers.core.embedding.Embedding(self,input_dim,output_dim,embeddings_initializer='uniform',embeddings_regularizer=None,activity_regularizer=None,embeddings_constraint=None,mask_zero=False,input_length=None,**kwargs)
keras.layers.core.embedding.Embedding.__init__(self,input_dim,output_dim,embeddings_initializer='uniform',embeddings_regularizer=None,activity_regularizer=None,embeddings_constraint=None,mask_zero=False,input_length=None,**kwargs)
keras.layers.core.embedding.Embedding.build(self,input_shape=None)
keras.layers.core.embedding.Embedding.call(self,inputs)
keras.layers.core.embedding.Embedding.compute_mask(self,inputs,mask=None)
keras.layers.core.embedding.Embedding.compute_output_shape(self,input_shape)
keras.layers.core.embedding.Embedding.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/__init__.py----------------------------------------
keras.layers.activation.__init__.get_globals()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/elu.py----------------------------------------
A:keras.layers.activation.elu.self.alpha->keras.backend.cast_to_floatx(alpha)
A:keras.layers.activation.elu.base_config->super(ELU, self).get_config()
keras.layers.activation.ELU(self,alpha=1.0,**kwargs)
keras.layers.activation.ELU.call(self,inputs)
keras.layers.activation.ELU.compute_output_shape(self,input_shape)
keras.layers.activation.ELU.get_config(self)
keras.layers.activation.elu.ELU(self,alpha=1.0,**kwargs)
keras.layers.activation.elu.ELU.__init__(self,alpha=1.0,**kwargs)
keras.layers.activation.elu.ELU.call(self,inputs)
keras.layers.activation.elu.ELU.compute_output_shape(self,input_shape)
keras.layers.activation.elu.ELU.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/softmax.py----------------------------------------
A:keras.layers.activation.softmax.base_config->super(Softmax, self).get_config()
keras.layers.activation.Softmax(self,axis=-1,**kwargs)
keras.layers.activation.Softmax.call(self,inputs,mask=None)
keras.layers.activation.Softmax.compute_output_shape(self,input_shape)
keras.layers.activation.Softmax.get_config(self)
keras.layers.activation.softmax.Softmax(self,axis=-1,**kwargs)
keras.layers.activation.softmax.Softmax.__init__(self,axis=-1,**kwargs)
keras.layers.activation.softmax.Softmax.call(self,inputs,mask=None)
keras.layers.activation.softmax.Softmax.compute_output_shape(self,input_shape)
keras.layers.activation.softmax.Softmax.get_config(self)
keras.layers.activation.softmax._large_compatible_negative(tensor_type)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/thresholded_relu.py----------------------------------------
A:keras.layers.activation.thresholded_relu.self.theta->keras.backend.cast_to_floatx(theta)
A:keras.layers.activation.thresholded_relu.base_config->super(ThresholdedReLU, self).get_config()
keras.layers.activation.ThresholdedReLU(self,theta=1.0,**kwargs)
keras.layers.activation.ThresholdedReLU.call(self,inputs)
keras.layers.activation.ThresholdedReLU.compute_output_shape(self,input_shape)
keras.layers.activation.ThresholdedReLU.get_config(self)
keras.layers.activation.thresholded_relu.ThresholdedReLU(self,theta=1.0,**kwargs)
keras.layers.activation.thresholded_relu.ThresholdedReLU.__init__(self,theta=1.0,**kwargs)
keras.layers.activation.thresholded_relu.ThresholdedReLU.call(self,inputs)
keras.layers.activation.thresholded_relu.ThresholdedReLU.compute_output_shape(self,input_shape)
keras.layers.activation.thresholded_relu.ThresholdedReLU.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/relu.py----------------------------------------
A:keras.layers.activation.relu.max_value->keras.backend.cast_to_floatx(max_value)
A:keras.layers.activation.relu.self.negative_slope->keras.backend.cast_to_floatx(negative_slope)
A:keras.layers.activation.relu.self.threshold->keras.backend.cast_to_floatx(threshold)
A:keras.layers.activation.relu.base_config->super(ReLU, self).get_config()
keras.layers.activation.ReLU(self,max_value=None,negative_slope=0.0,threshold=0.0,**kwargs)
keras.layers.activation.ReLU.call(self,inputs)
keras.layers.activation.ReLU.compute_output_shape(self,input_shape)
keras.layers.activation.ReLU.get_config(self)
keras.layers.activation.relu.ReLU(self,max_value=None,negative_slope=0.0,threshold=0.0,**kwargs)
keras.layers.activation.relu.ReLU.__init__(self,max_value=None,negative_slope=0.0,threshold=0.0,**kwargs)
keras.layers.activation.relu.ReLU.call(self,inputs)
keras.layers.activation.relu.ReLU.compute_output_shape(self,input_shape)
keras.layers.activation.relu.ReLU.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/prelu.py----------------------------------------
A:keras.layers.activation.prelu.self.alpha_initializer->keras.initializers.get(alpha_initializer)
A:keras.layers.activation.prelu.self.alpha_regularizer->keras.regularizers.get(alpha_regularizer)
A:keras.layers.activation.prelu.self.alpha_constraint->keras.constraints.get(alpha_constraint)
A:keras.layers.activation.prelu.self.shared_axes->list(shared_axes)
A:keras.layers.activation.prelu.param_shape->list(input_shape[1:])
A:keras.layers.activation.prelu.self.alpha->self.add_weight(shape=param_shape, name='alpha', initializer=self.alpha_initializer, regularizer=self.alpha_regularizer, constraint=self.alpha_constraint)
A:keras.layers.activation.prelu.self.input_spec->InputSpec(ndim=len(input_shape), axes=axes)
A:keras.layers.activation.prelu.pos->keras.backend.relu(inputs)
A:keras.layers.activation.prelu.base_config->super(PReLU, self).get_config()
keras.layers.activation.PReLU(self,alpha_initializer='zeros',alpha_regularizer=None,alpha_constraint=None,shared_axes=None,**kwargs)
keras.layers.activation.PReLU.build(self,input_shape)
keras.layers.activation.PReLU.call(self,inputs)
keras.layers.activation.PReLU.compute_output_shape(self,input_shape)
keras.layers.activation.PReLU.get_config(self)
keras.layers.activation.prelu.PReLU(self,alpha_initializer='zeros',alpha_regularizer=None,alpha_constraint=None,shared_axes=None,**kwargs)
keras.layers.activation.prelu.PReLU.__init__(self,alpha_initializer='zeros',alpha_regularizer=None,alpha_constraint=None,shared_axes=None,**kwargs)
keras.layers.activation.prelu.PReLU.build(self,input_shape)
keras.layers.activation.prelu.PReLU.call(self,inputs)
keras.layers.activation.prelu.PReLU.compute_output_shape(self,input_shape)
keras.layers.activation.prelu.PReLU.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/activation/leaky_relu.py----------------------------------------
A:keras.layers.activation.leaky_relu.self.alpha->keras.backend.cast_to_floatx(alpha)
A:keras.layers.activation.leaky_relu.base_config->super(LeakyReLU, self).get_config()
keras.layers.activation.LeakyReLU(self,alpha=0.3,**kwargs)
keras.layers.activation.LeakyReLU.call(self,inputs)
keras.layers.activation.LeakyReLU.compute_output_shape(self,input_shape)
keras.layers.activation.LeakyReLU.get_config(self)
keras.layers.activation.leaky_relu.LeakyReLU(self,alpha=0.3,**kwargs)
keras.layers.activation.leaky_relu.LeakyReLU.__init__(self,alpha=0.3,**kwargs)
keras.layers.activation.leaky_relu.LeakyReLU.call(self,inputs)
keras.layers.activation.leaky_relu.LeakyReLU.compute_output_shape(self,input_shape)
keras.layers.activation.leaky_relu.LeakyReLU.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/image_preprocessing.py----------------------------------------
A:keras.layers.preprocessing.image_preprocessing.self._interpolation_method->keras.utils.image_utils.get_interpolation(interpolation)
A:keras.layers.preprocessing.image_preprocessing.inputs->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(inputs)
A:keras.layers.preprocessing.image_preprocessing.x->x.to_tensor().to_tensor()
A:keras.layers.preprocessing.image_preprocessing.size_as_shape->tensorflow.compat.v2.TensorShape(size)
A:keras.layers.preprocessing.image_preprocessing.spec->tensorflow.compat.v2.TensorSpec(shape, input_dtype)
A:keras.layers.preprocessing.image_preprocessing.outputs->keras.utils.image_utils.smart_resize(inputs, [self.height, self.width])
A:keras.layers.preprocessing.image_preprocessing.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.preprocessing.image_preprocessing.base_config->super(RandomWidth, self).get_config()
A:keras.layers.preprocessing.image_preprocessing.h_start->tensorflow.compat.v2.cast(h_diff / 2, tf.int32)
A:keras.layers.preprocessing.image_preprocessing.w_start->tensorflow.compat.v2.cast(w_diff / 2, tf.int32)
A:keras.layers.preprocessing.image_preprocessing.(inputs, is_dict)->self._format_inputs(inputs)
A:keras.layers.preprocessing.image_preprocessing.image->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(image, self.compute_dtype)
A:keras.layers.preprocessing.image_preprocessing.label->self.augment_label(label, transformation=transformation)
A:keras.layers.preprocessing.image_preprocessing.bounding_box->self.augment_bounding_box(bounding_box, transformation=transformation)
A:keras.layers.preprocessing.image_preprocessing.transformation->self.get_random_transformation(image=image)
A:keras.layers.preprocessing.image_preprocessing.inputs['images']->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(inputs['images'], self.compute_dtype)
A:keras.layers.preprocessing.image_preprocessing.rands->self._random_generator.random_uniform([2], 0, dtype.max, dtype)
A:keras.layers.preprocessing.image_preprocessing.scale->tensorflow.compat.v2.cast(self.scale, dtype)
A:keras.layers.preprocessing.image_preprocessing.offset->tensorflow.compat.v2.cast(self.offset, dtype)
A:keras.layers.preprocessing.image_preprocessing.seed->self._random_generator.make_seed_for_stateless_op()
A:keras.layers.preprocessing.image_preprocessing.flipped_outputs->tensorflow.compat.v2.image.random_flip_up_down(flipped_outputs, self._random_generator.make_legacy_seed())
A:keras.layers.preprocessing.image_preprocessing.inputs_shape->tensorflow.compat.v2.shape(inputs)
A:keras.layers.preprocessing.image_preprocessing.img_hd->tensorflow.compat.v2.cast(inputs_shape[H_AXIS], tf.float32)
A:keras.layers.preprocessing.image_preprocessing.img_wd->tensorflow.compat.v2.cast(inputs_shape[W_AXIS], tf.float32)
A:keras.layers.preprocessing.image_preprocessing.translations->tensorflow.compat.v2.cast(tf.concat([width_translation, height_translation], axis=1), dtype=tf.float32)
A:keras.layers.preprocessing.image_preprocessing.output->tensorflow.compat.v2.cast(output, self.compute_dtype)
A:keras.layers.preprocessing.image_preprocessing.height_translation->self._random_generator.random_uniform(shape=[batch_size, 1], minval=self.height_lower, maxval=self.height_upper, dtype=tf.float32)
A:keras.layers.preprocessing.image_preprocessing.width_translation->self._random_generator.random_uniform(shape=[batch_size, 1], minval=self.width_lower, maxval=self.width_upper, dtype=tf.float32)
A:keras.layers.preprocessing.image_preprocessing.output_shape_value->tensorflow.compat.v2.get_static_value(output_shape)
A:keras.layers.preprocessing.image_preprocessing.output_shape->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(inputs).shape.as_list()
A:keras.layers.preprocessing.image_preprocessing.fill_value->tensorflow.compat.v2.convert_to_tensor(fill_value, tf.float32, name='fill_value')
A:keras.layers.preprocessing.image_preprocessing.angles->self._random_generator.random_uniform(shape=[batch_size], minval=min_angle, maxval=max_angle)
A:keras.layers.preprocessing.image_preprocessing.height_zoom->self._random_generator.random_uniform(shape=[batch_size, 1], minval=1.0 + self.height_lower, maxval=1.0 + self.height_upper)
A:keras.layers.preprocessing.image_preprocessing.width_zoom->self._random_generator.random_uniform(shape=[batch_size, 1], minval=1.0 + self.width_lower, maxval=1.0 + self.width_upper)
A:keras.layers.preprocessing.image_preprocessing.zooms->tensorflow.compat.v2.cast(tf.concat([width_zoom, height_zoom], axis=1), dtype=tf.float32)
A:keras.layers.preprocessing.image_preprocessing.random_seed->self._random_generator.make_seed_for_stateless_op()
A:keras.layers.preprocessing.image_preprocessing.contrast_factor->tensorflow.python.ops.stateless_random_ops.stateless_random_uniform(shape=[], minval=lower, maxval=upper, seed=random_seed)
A:keras.layers.preprocessing.image_preprocessing.random_rgb_delta->self._random_generator.random_uniform(shape=rgb_delta_shape, minval=self._factor[0], maxval=self._factor[1])
A:keras.layers.preprocessing.image_preprocessing.self._value_range->sorted(value_range)
A:keras.layers.preprocessing.image_preprocessing.self._factor->sorted(factor)
A:keras.layers.preprocessing.image_preprocessing.factor->abs(factor)
A:keras.layers.preprocessing.image_preprocessing.rgb_delta->tensorflow.compat.v2.cast(rgb_delta, image.dtype)
A:keras.layers.preprocessing.image_preprocessing.height_factor->self._random_generator.random_uniform(shape=[], minval=1.0 + self.height_lower, maxval=1.0 + self.height_upper)
A:keras.layers.preprocessing.image_preprocessing.adjusted_height->tensorflow.compat.v2.cast(height_factor * img_hd, tf.int32)
A:keras.layers.preprocessing.image_preprocessing.adjusted_size->tensorflow.compat.v2.stack([img_hd, adjusted_width])
A:keras.layers.preprocessing.image_preprocessing.width_factor->self._random_generator.random_uniform(shape=[], minval=1.0 + self.width_lower, maxval=1.0 + self.width_upper)
A:keras.layers.preprocessing.image_preprocessing.adjusted_width->tensorflow.compat.v2.cast(width_factor * img_wd, tf.int32)
keras.layers.CenterCrop(self,height,width,**kwargs)
keras.layers.CenterCrop.call(self,inputs)
keras.layers.CenterCrop.compute_output_shape(self,input_shape)
keras.layers.CenterCrop.get_config(self)
keras.layers.RandomContrast(self,factor,seed=None,**kwargs)
keras.layers.RandomContrast.augment_image(self,image,transformation=None)
keras.layers.RandomContrast.augment_label(self,label,transformation=None)
keras.layers.RandomContrast.compute_output_shape(self,input_shape)
keras.layers.RandomContrast.get_config(self)
keras.layers.RandomContrast.get_random_transformation(self,image=None,label=None,bounding_box=None)
keras.layers.RandomCrop(self,height,width,seed=None,**kwargs)
keras.layers.RandomCrop._random_crop(self,inputs)
keras.layers.RandomCrop._resize(self,inputs)
keras.layers.RandomCrop.call(self,inputs,training=True)
keras.layers.RandomCrop.compute_output_shape(self,input_shape)
keras.layers.RandomCrop.get_config(self)
keras.layers.RandomFlip(self,mode=HORIZONTAL_AND_VERTICAL,seed=None,**kwargs)
keras.layers.RandomFlip.augment_image(self,image,transformation=None)
keras.layers.RandomFlip.augment_label(self,label,transformation=None)
keras.layers.RandomFlip.compute_output_shape(self,input_shape)
keras.layers.RandomFlip.get_config(self)
keras.layers.RandomHeight(self,factor,interpolation='bilinear',seed=None,**kwargs)
keras.layers.RandomHeight.call(self,inputs,training=True)
keras.layers.RandomHeight.compute_output_shape(self,input_shape)
keras.layers.RandomHeight.get_config(self)
keras.layers.RandomRotation(self,factor,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.RandomRotation.call(self,inputs,training=True)
keras.layers.RandomRotation.compute_output_shape(self,input_shape)
keras.layers.RandomRotation.get_config(self)
keras.layers.RandomTranslation(self,height_factor,width_factor,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.RandomTranslation._batch_augment(self,inputs)
keras.layers.RandomTranslation.augment_image(self,image,transformation=None)
keras.layers.RandomTranslation.augment_label(self,label,transformation=None)
keras.layers.RandomTranslation.compute_output_shape(self,input_shape)
keras.layers.RandomTranslation.get_config(self)
keras.layers.RandomTranslation.get_random_transformation(self,image=None,label=None,bounding_box=None)
keras.layers.RandomWidth(self,factor,interpolation='bilinear',seed=None,**kwargs)
keras.layers.RandomWidth.call(self,inputs,training=True)
keras.layers.RandomWidth.compute_output_shape(self,input_shape)
keras.layers.RandomWidth.get_config(self)
keras.layers.RandomZoom(self,height_factor,width_factor=None,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.RandomZoom.call(self,inputs,training=True)
keras.layers.RandomZoom.compute_output_shape(self,input_shape)
keras.layers.RandomZoom.get_config(self)
keras.layers.Rescaling(self,scale,offset=0.0,**kwargs)
keras.layers.Rescaling.call(self,inputs)
keras.layers.Rescaling.compute_output_shape(self,input_shape)
keras.layers.Rescaling.get_config(self)
keras.layers.Resizing(self,height,width,interpolation='bilinear',crop_to_aspect_ratio=False,**kwargs)
keras.layers.Resizing.call(self,inputs)
keras.layers.Resizing.compute_output_shape(self,input_shape)
keras.layers.Resizing.get_config(self)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer(self,rate=1.0,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.__init__(self,rate=1.0,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer._augment(self,inputs)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer._batch_augment(self,inputs)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer._ensure_inputs_are_compute_dtype(self,inputs)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer._format_inputs(self,inputs)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer._format_output(self,output,is_dict)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer._map_fn(self)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.augment_bounding_box(self,bounding_box,transformation=None)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.augment_image(self,image,transformation=None)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.augment_label(self,label,transformation=None)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.auto_vectorize(self)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.auto_vectorize(self,auto_vectorize)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.call(self,inputs,training=True)
keras.layers.preprocessing.image_preprocessing.BaseImageAugmentationLayer.get_random_transformation(self,image=None,label=None,bounding_box=None)
keras.layers.preprocessing.image_preprocessing.CenterCrop(self,height,width,**kwargs)
keras.layers.preprocessing.image_preprocessing.CenterCrop.__init__(self,height,width,**kwargs)
keras.layers.preprocessing.image_preprocessing.CenterCrop.call(self,inputs)
keras.layers.preprocessing.image_preprocessing.CenterCrop.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.CenterCrop.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomBrightness(self,factor,value_range=(0,255),seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomBrightness.__init__(self,factor,value_range=(0,255),seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomBrightness._brightness_adjust(self,image,rgb_delta)
keras.layers.preprocessing.image_preprocessing.RandomBrightness._check_factor_range(self,input_number)
keras.layers.preprocessing.image_preprocessing.RandomBrightness._set_factor(self,factor)
keras.layers.preprocessing.image_preprocessing.RandomBrightness._set_value_range(self,value_range)
keras.layers.preprocessing.image_preprocessing.RandomBrightness.augment_image(self,image,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomBrightness.augment_label(self,label,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomBrightness.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomBrightness.get_random_transformation(self,image=None,label=None,bounding_box=None)
keras.layers.preprocessing.image_preprocessing.RandomContrast(self,factor,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomContrast.__init__(self,factor,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomContrast.augment_image(self,image,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomContrast.augment_label(self,label,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomContrast.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomContrast.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomContrast.get_random_transformation(self,image=None,label=None,bounding_box=None)
keras.layers.preprocessing.image_preprocessing.RandomCrop(self,height,width,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomCrop.__init__(self,height,width,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomCrop._random_crop(self,inputs)
keras.layers.preprocessing.image_preprocessing.RandomCrop._resize(self,inputs)
keras.layers.preprocessing.image_preprocessing.RandomCrop.call(self,inputs,training=True)
keras.layers.preprocessing.image_preprocessing.RandomCrop.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomCrop.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomFlip(self,mode=HORIZONTAL_AND_VERTICAL,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomFlip.__init__(self,mode=HORIZONTAL_AND_VERTICAL,seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomFlip.augment_image(self,image,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomFlip.augment_label(self,label,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomFlip.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomFlip.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomHeight(self,factor,interpolation='bilinear',seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomHeight.__init__(self,factor,interpolation='bilinear',seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomHeight.call(self,inputs,training=True)
keras.layers.preprocessing.image_preprocessing.RandomHeight.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomHeight.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomRotation(self,factor,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomRotation.__init__(self,factor,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomRotation.call(self,inputs,training=True)
keras.layers.preprocessing.image_preprocessing.RandomRotation.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomRotation.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomTranslation(self,height_factor,width_factor,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomTranslation.__init__(self,height_factor,width_factor,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomTranslation._batch_augment(self,inputs)
keras.layers.preprocessing.image_preprocessing.RandomTranslation.augment_image(self,image,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomTranslation.augment_label(self,label,transformation=None)
keras.layers.preprocessing.image_preprocessing.RandomTranslation.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomTranslation.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomTranslation.get_random_transformation(self,image=None,label=None,bounding_box=None)
keras.layers.preprocessing.image_preprocessing.RandomWidth(self,factor,interpolation='bilinear',seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomWidth.__init__(self,factor,interpolation='bilinear',seed=None,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomWidth.call(self,inputs,training=True)
keras.layers.preprocessing.image_preprocessing.RandomWidth.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomWidth.get_config(self)
keras.layers.preprocessing.image_preprocessing.RandomZoom(self,height_factor,width_factor=None,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomZoom.__init__(self,height_factor,width_factor=None,fill_mode='reflect',interpolation='bilinear',seed=None,fill_value=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.RandomZoom.call(self,inputs,training=True)
keras.layers.preprocessing.image_preprocessing.RandomZoom.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.RandomZoom.get_config(self)
keras.layers.preprocessing.image_preprocessing.Rescaling(self,scale,offset=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.Rescaling.__init__(self,scale,offset=0.0,**kwargs)
keras.layers.preprocessing.image_preprocessing.Rescaling.call(self,inputs)
keras.layers.preprocessing.image_preprocessing.Rescaling.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.Rescaling.get_config(self)
keras.layers.preprocessing.image_preprocessing.Resizing(self,height,width,interpolation='bilinear',crop_to_aspect_ratio=False,**kwargs)
keras.layers.preprocessing.image_preprocessing.Resizing.__init__(self,height,width,interpolation='bilinear',crop_to_aspect_ratio=False,**kwargs)
keras.layers.preprocessing.image_preprocessing.Resizing.call(self,inputs)
keras.layers.preprocessing.image_preprocessing.Resizing.compute_output_shape(self,input_shape)
keras.layers.preprocessing.image_preprocessing.Resizing.get_config(self)
keras.layers.preprocessing.image_preprocessing.check_fill_mode_and_interpolation(fill_mode,interpolation)
keras.layers.preprocessing.image_preprocessing.get_rotation_matrix(angles,image_height,image_width,name=None)
keras.layers.preprocessing.image_preprocessing.get_translation_matrix(translations,name=None)
keras.layers.preprocessing.image_preprocessing.get_zoom_matrix(zooms,image_height,image_width,name=None)
keras.layers.preprocessing.image_preprocessing.transform(images,transforms,fill_mode='reflect',fill_value=0.0,interpolation='bilinear',output_shape=None,name=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/preprocessing_stage.py----------------------------------------
A:keras.layers.preprocessing.preprocessing_stage.x->self.layers[i](x)
A:keras.layers.preprocessing.preprocessing_stage.current_layer_data->map_fn(data)
A:keras.layers.preprocessing.preprocessing_stage.data->self._flatten_to_reference_inputs(data)
A:keras.layers.preprocessing.preprocessing_stage.ds_input->_unzip_dataset(data)
A:keras.layers.preprocessing.preprocessing_stage.x_id->str(id(x))
A:keras.layers.preprocessing.preprocessing_stage.depth_keys->sorted(nodes_by_depth.keys(), reverse=True)
A:keras.layers.preprocessing.preprocessing_stage.(args, kwargs)->node.map_arguments(ds_dict)
A:keras.layers.preprocessing.preprocessing_stage.args->tensorflow.compat.v2.data.Dataset.zip(tf.__internal__.nest.list_to_tuple(*args))
A:keras.layers.preprocessing.preprocessing_stage.map_fn->build_map_fn(node, args, kwargs)
A:keras.layers.preprocessing.preprocessing_stage.outputs->_unzip_dataset(outputs)
A:keras.layers.preprocessing.preprocessing_stage.element_count->len(tf.nest.flatten(ds.element_spec))
keras.layers.preprocessing.preprocessing_stage.FunctionalPreprocessingStage(functional.Functional,base_preprocessing_layer.PreprocessingLayer)
keras.layers.preprocessing.preprocessing_stage.FunctionalPreprocessingStage.adapt(self,data,reset_state=True)
keras.layers.preprocessing.preprocessing_stage.FunctionalPreprocessingStage.fit(self,*args,**kwargs)
keras.layers.preprocessing.preprocessing_stage.PreprocessingStage(sequential.Sequential,base_preprocessing_layer.PreprocessingLayer)
keras.layers.preprocessing.preprocessing_stage.PreprocessingStage.adapt(self,data,reset_state=True)
keras.layers.preprocessing.preprocessing_stage._unzip_dataset(ds)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/preprocessing_utils.py----------------------------------------
A:keras.layers.preprocessing.preprocessing_utils.inputs->expand_dims(inputs, -1)
A:keras.layers.preprocessing.preprocessing_utils.x->x.tolist().tolist()
A:keras.layers.preprocessing.preprocessing_utils.result->tensorflow.compat.v2.math.bincount(inputs, weights=count_weights, minlength=depth, maxlength=depth, dtype=dtype, axis=-1, binary_output=binary_output)
A:keras.layers.preprocessing.preprocessing_utils.bincounts->dense_bincount(inputs, depth, binary_output, dtype, count_weights)
A:keras.layers.preprocessing.preprocessing_utils.value_weights->tensorflow.compat.v2.gather(idf_weights, bincounts.indices[:, -1])
keras.layers.preprocessing.preprocessing_utils.compute_shape_for_encode_categorical(shape,output_mode,depth)
keras.layers.preprocessing.preprocessing_utils.dense_bincount(inputs,depth,binary_output,dtype,count_weights=None)
keras.layers.preprocessing.preprocessing_utils.encode_categorical_inputs(inputs,output_mode,depth,dtype='float32',sparse=False,count_weights=None,idf_weights=None)
keras.layers.preprocessing.preprocessing_utils.ensure_tensor(inputs,dtype=None)
keras.layers.preprocessing.preprocessing_utils.expand_dims(inputs,axis)
keras.layers.preprocessing.preprocessing_utils.listify_tensors(x)
keras.layers.preprocessing.preprocessing_utils.sparse_bincount(inputs,depth,binary_output,dtype,count_weights=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/text_vectorization.py----------------------------------------
A:keras.layers.preprocessing.text_vectorization.self._ngrams->tuple(range(1, ngrams + 1))
A:keras.layers.preprocessing.text_vectorization.self._has_input_vocabulary->kwargs.pop('has_input_vocabulary', vocabulary is not None)
A:keras.layers.preprocessing.text_vectorization.self._lookup_layer->keras.layers.preprocessing.string_lookup.StringLookup(max_tokens=max_tokens, vocabulary=vocabulary, idf_weights=idf_weights, pad_to_max_tokens=pad_to_max_tokens, mask_token='', output_mode=output_mode if output_mode is not None else INT, sparse=sparse, has_input_vocabulary=self._has_input_vocabulary)
A:keras.layers.preprocessing.text_vectorization.output_shape->self.compute_output_shape(input_spec.shape.as_list())
A:keras.layers.preprocessing.text_vectorization.base_config->super(TextVectorization, self).get_config()
A:keras.layers.preprocessing.text_vectorization.inputs->self._preprocess(inputs)
A:keras.layers.preprocessing.text_vectorization.lookup_data->self._lookup_layer(inputs)
A:keras.layers.preprocessing.text_vectorization.shape->tensorflow.compat.v2.shape(lookup_data)
A:keras.layers.preprocessing.text_vectorization.padded_shape->tensorflow.compat.v2.concat((shape[:-1], [self._output_sequence_length]), 0)
A:keras.layers.preprocessing.text_vectorization.(padding, _)->tensorflow.compat.v2.required_space_to_batch_paddings(shape, padded_shape)
keras.layers.TextVectorization(self,max_tokens=None,standardize='lower_and_strip_punctuation',split='whitespace',ngrams=None,output_mode='int',output_sequence_length=None,pad_to_max_tokens=False,vocabulary=None,idf_weights=None,sparse=False,ragged=False,**kwargs)
keras.layers.TextVectorization._preprocess(self,inputs)
keras.layers.TextVectorization._trackable_saved_model_saver(self)
keras.layers.TextVectorization.adapt(self,data,batch_size=None,steps=None)
keras.layers.TextVectorization.call(self,inputs)
keras.layers.TextVectorization.compute_output_shape(self,input_shape)
keras.layers.TextVectorization.compute_output_signature(self,input_spec)
keras.layers.TextVectorization.finalize_state(self)
keras.layers.TextVectorization.get_config(self)
keras.layers.TextVectorization.get_vocabulary(self,include_special_tokens=True)
keras.layers.TextVectorization.reset_state(self)
keras.layers.TextVectorization.set_vocabulary(self,vocabulary,idf_weights=None)
keras.layers.TextVectorization.update_state(self,data)
keras.layers.TextVectorization.vocabulary_size(self)
keras.layers.preprocessing.text_vectorization.TextVectorization(self,max_tokens=None,standardize='lower_and_strip_punctuation',split='whitespace',ngrams=None,output_mode='int',output_sequence_length=None,pad_to_max_tokens=False,vocabulary=None,idf_weights=None,sparse=False,ragged=False,**kwargs)
keras.layers.preprocessing.text_vectorization.TextVectorization.__init__(self,max_tokens=None,standardize='lower_and_strip_punctuation',split='whitespace',ngrams=None,output_mode='int',output_sequence_length=None,pad_to_max_tokens=False,vocabulary=None,idf_weights=None,sparse=False,ragged=False,**kwargs)
keras.layers.preprocessing.text_vectorization.TextVectorization._preprocess(self,inputs)
keras.layers.preprocessing.text_vectorization.TextVectorization._trackable_saved_model_saver(self)
keras.layers.preprocessing.text_vectorization.TextVectorization.adapt(self,data,batch_size=None,steps=None)
keras.layers.preprocessing.text_vectorization.TextVectorization.call(self,inputs)
keras.layers.preprocessing.text_vectorization.TextVectorization.compute_output_shape(self,input_shape)
keras.layers.preprocessing.text_vectorization.TextVectorization.compute_output_signature(self,input_spec)
keras.layers.preprocessing.text_vectorization.TextVectorization.finalize_state(self)
keras.layers.preprocessing.text_vectorization.TextVectorization.get_config(self)
keras.layers.preprocessing.text_vectorization.TextVectorization.get_vocabulary(self,include_special_tokens=True)
keras.layers.preprocessing.text_vectorization.TextVectorization.reset_state(self)
keras.layers.preprocessing.text_vectorization.TextVectorization.set_vocabulary(self,vocabulary,idf_weights=None)
keras.layers.preprocessing.text_vectorization.TextVectorization.update_state(self,data)
keras.layers.preprocessing.text_vectorization.TextVectorization.vocabulary_size(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/index_lookup.py----------------------------------------
A:keras.layers.preprocessing.index_lookup.self._distribute_strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.layers.preprocessing.index_lookup.tokens->tensorflow.compat.v2.gather(tokens, sorted_indices)
A:keras.layers.preprocessing.index_lookup.self._layer.lookup_table->self._layer._lookup_table_from_tokens(tokens)
A:keras.layers.preprocessing.index_lookup.self._has_input_vocabulary->kwargs.pop('has_input_vocabulary', vocabulary is not None)
A:keras.layers.preprocessing.index_lookup.self._value_dtype->tensorflow.compat.v2.as_dtype(self.vocabulary_dtype)
A:keras.layers.preprocessing.index_lookup.self._key_dtype->tensorflow.compat.v2.as_dtype(self.vocabulary_dtype)
A:keras.layers.preprocessing.index_lookup.self._default_value->self._oov_start_index()
A:keras.layers.preprocessing.index_lookup.self._mask_key->tensorflow.compat.v2.convert_to_tensor(mask_key, self._key_dtype)
A:keras.layers.preprocessing.index_lookup.self._mask_value->tensorflow.compat.v2.convert_to_tensor(mask_value, self._value_dtype)
A:keras.layers.preprocessing.index_lookup.self.idf_weights->tensorflow.compat.v2.Variable([0] * self._token_start_index(), shape=(None,), dtype=self.compute_dtype, trainable=False)
A:keras.layers.preprocessing.index_lookup.self.idf_weights_const->self.idf_weights.value()
A:keras.layers.preprocessing.index_lookup.self.lookup_table->self._lookup_table_from_tokens(tokens)
A:keras.layers.preprocessing.index_lookup.self.token_counts->tensorflow.compat.v2.lookup.experimental.MutableHashTable(key_dtype=vocabulary_dtype, value_dtype=tf.int64, default_value=0)
A:keras.layers.preprocessing.index_lookup.self.token_document_counts->tensorflow.compat.v2.lookup.experimental.MutableHashTable(key_dtype=vocabulary_dtype, value_dtype=tf.int64, default_value=0)
A:keras.layers.preprocessing.index_lookup.self.num_documents->tensorflow.compat.v2.Variable(0, dtype=tf.int64, trainable=False)
A:keras.layers.preprocessing.index_lookup.output_shape->self.compute_output_shape(input_spec.shape.as_list())
A:keras.layers.preprocessing.index_lookup.(keys, values)->self.lookup_table.export()
A:keras.layers.preprocessing.index_lookup.lookup->collections.defaultdict(lambda : self.oov_token, zip(indices, vocab))
A:keras.layers.preprocessing.index_lookup.base_config->super().get_config()
A:keras.layers.preprocessing.index_lookup.vocabulary->numpy.array(vocabulary)
A:keras.layers.preprocessing.index_lookup.idf_weights->tensorflow.compat.v2.pad(idf_weights, [[0, self.max_tokens - tf.size(idf_weights)]], constant_values=0)
A:keras.layers.preprocessing.index_lookup.oov_start->self._oov_start_index()
A:keras.layers.preprocessing.index_lookup.token_start->self._token_start_index()
A:keras.layers.preprocessing.index_lookup.found_special_tokens->numpy.array_equal(special_tokens, vocabulary[:token_start])
A:keras.layers.preprocessing.index_lookup.repeated_tokens->self._find_repeated_tokens(tokens)
A:keras.layers.preprocessing.index_lookup.front_padding_value->numpy.average(idf_weights)
A:keras.layers.preprocessing.index_lookup.weights->tensorflow.compat.v2.convert_to_tensor(weights, dtype=self.compute_dtype)
A:keras.layers.preprocessing.index_lookup.data->tensorflow.compat.v2.expand_dims(data, 0)
A:keras.layers.preprocessing.index_lookup.(tokens, counts)->self.token_counts.export()
A:keras.layers.preprocessing.index_lookup.deduped_doc_data->tensorflow.compat.v2.map_fn(lambda x: tf.unique(x)[0], data)
A:keras.layers.preprocessing.index_lookup.(tokens, doc_counts)->self._num_tokens(deduped_doc_data)
A:keras.layers.preprocessing.index_lookup.token_document_counts->self.token_document_counts.lookup(tokens)
A:keras.layers.preprocessing.index_lookup.inputs->self._expand_dims(inputs, -1)
A:keras.layers.preprocessing.index_lookup.lookups->tensorflow.compat.v2.where(oov_locations, oov_indices, lookups)
A:keras.layers.preprocessing.index_lookup.mask_locations->tensorflow.compat.v2.equal(inputs, self._mask_key)
A:keras.layers.preprocessing.index_lookup.oov_indices->tensorflow.compat.v2.strings.to_hash_bucket_fast(inputs, num_buckets=self.num_oov_indices)
A:keras.layers.preprocessing.index_lookup.oov_inputs->tensorflow.compat.v2.gather_nd(inputs, oov_indices)
A:keras.layers.preprocessing.index_lookup.msg->tensorflow.compat.v2.strings.format('When `num_oov_indices=0` all inputs should be in vocabulary, found OOV values {}, consider setting `num_oov_indices=1`.', (oov_inputs,))
A:keras.layers.preprocessing.index_lookup.assertion->tensorflow.compat.v2.Assert(tf.equal(tf.size(oov_indices), 0), [msg])
A:keras.layers.preprocessing.index_lookup.oov_locations->tensorflow.compat.v2.equal(lookups, self._default_value)
A:keras.layers.preprocessing.index_lookup.initializer->tensorflow.compat.v2.lookup.TextFileInitializer(filename=filename, key_dtype=self._key_dtype, key_index=key_index, value_dtype=self._value_dtype, value_index=value_index, value_index_offset=self._token_start_index())
A:keras.layers.preprocessing.index_lookup.indices->tensorflow.compat.v2.range(token_start, token_end, dtype=indices_dtype)
A:keras.layers.preprocessing.index_lookup.new_vocab_size->self.vocabulary_size()
A:keras.layers.preprocessing.index_lookup.vocabulary_set->set(vocabulary)
A:keras.layers.preprocessing.index_lookup.flat_values->tensorflow.compat.v2.reshape(data, [-1])
A:keras.layers.preprocessing.index_lookup.(tokens, _, counts)->tensorflow.compat.v2.unique_with_counts(flat_values, out_idx=tf.int64)
keras.layers.preprocessing.index_lookup.IndexLookup(self,max_tokens,num_oov_indices,mask_token,oov_token,vocabulary_dtype,vocabulary=None,idf_weights=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.preprocessing.index_lookup.IndexLookup.__init__(self,max_tokens,num_oov_indices,mask_token,oov_token,vocabulary_dtype,vocabulary=None,idf_weights=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.preprocessing.index_lookup.IndexLookup._convert_to_ndarray(self,x)
keras.layers.preprocessing.index_lookup.IndexLookup._expand_dims(self,inputs,axis)
keras.layers.preprocessing.index_lookup.IndexLookup._find_repeated_tokens(self,vocabulary)
keras.layers.preprocessing.index_lookup.IndexLookup._inverse_document_frequency(self,token_document_counts,num_documents)
keras.layers.preprocessing.index_lookup.IndexLookup._lookup_dense(self,inputs)
keras.layers.preprocessing.index_lookup.IndexLookup._lookup_table_from_file(self,filename)
keras.layers.preprocessing.index_lookup.IndexLookup._lookup_table_from_tokens(self,tokens)
keras.layers.preprocessing.index_lookup.IndexLookup._maybe_freeze_vocab_size(self)
keras.layers.preprocessing.index_lookup.IndexLookup._num_tokens(self,data)
keras.layers.preprocessing.index_lookup.IndexLookup._oov_start_index(self)
keras.layers.preprocessing.index_lookup.IndexLookup._tensor_vocab_to_numpy(self,vocabulary)
keras.layers.preprocessing.index_lookup.IndexLookup._token_start_index(self)
keras.layers.preprocessing.index_lookup.IndexLookup._trackable_saved_model_saver(self)
keras.layers.preprocessing.index_lookup.IndexLookup._uninitialized_lookup_table(self)
keras.layers.preprocessing.index_lookup.IndexLookup.call(self,inputs)
keras.layers.preprocessing.index_lookup.IndexLookup.compute_output_shape(self,input_shape)
keras.layers.preprocessing.index_lookup.IndexLookup.compute_output_signature(self,input_spec)
keras.layers.preprocessing.index_lookup.IndexLookup.finalize_state(self)
keras.layers.preprocessing.index_lookup.IndexLookup.get_config(self)
keras.layers.preprocessing.index_lookup.IndexLookup.get_vocabulary(self,include_special_tokens=True)
keras.layers.preprocessing.index_lookup.IndexLookup.reset_state(self)
keras.layers.preprocessing.index_lookup.IndexLookup.set_vocabulary(self,vocabulary,idf_weights=None)
keras.layers.preprocessing.index_lookup.IndexLookup.update_state(self,data)
keras.layers.preprocessing.index_lookup.IndexLookup.vocab_size(self)
keras.layers.preprocessing.index_lookup.IndexLookup.vocabulary_size(self)
keras.layers.preprocessing.index_lookup.NullInitializer(self,key_dtype,value_dtype)
keras.layers.preprocessing.index_lookup.NullInitializer.__init__(self,key_dtype,value_dtype)
keras.layers.preprocessing.index_lookup.NullInitializer.initialize(self,table)
keras.layers.preprocessing.index_lookup.NullInitializer.key_dtype(self)
keras.layers.preprocessing.index_lookup.NullInitializer.value_dtype(self)
keras.layers.preprocessing.index_lookup.VocabWeightHandler(self,lookup_layer)
keras.layers.preprocessing.index_lookup.VocabWeightHandler.__init__(self,lookup_layer)
keras.layers.preprocessing.index_lookup.VocabWeightHandler.get_tensors(self)
keras.layers.preprocessing.index_lookup.VocabWeightHandler.num_tensors(self)
keras.layers.preprocessing.index_lookup.VocabWeightHandler.set_weights(self,weights)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/hashing.py----------------------------------------
A:keras.layers.preprocessing.hashing.inputs->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(inputs)
A:keras.layers.preprocessing.hashing.indices->self._hash_values_to_bins(inputs)
A:keras.layers.preprocessing.hashing.mask->tensorflow.compat.v2.equal(values, self.mask_value)
A:keras.layers.preprocessing.hashing.values->tensorflow.compat.v2.where(mask, tf.zeros_like(values), values)
A:keras.layers.preprocessing.hashing.output_shape->self.compute_output_shape(input_spec.shape)
A:keras.layers.preprocessing.hashing.config->super().get_config()
keras.layers.Hashing(self,num_bins,mask_value=None,salt=None,output_mode='int',sparse=False,**kwargs)
keras.layers.Hashing._hash_values_to_bins(self,values)
keras.layers.Hashing.call(self,inputs)
keras.layers.Hashing.compute_output_shape(self,input_shape)
keras.layers.Hashing.compute_output_signature(self,input_spec)
keras.layers.Hashing.get_config(self)
keras.layers.preprocessing.hashing.Hashing(self,num_bins,mask_value=None,salt=None,output_mode='int',sparse=False,**kwargs)
keras.layers.preprocessing.hashing.Hashing.__init__(self,num_bins,mask_value=None,salt=None,output_mode='int',sparse=False,**kwargs)
keras.layers.preprocessing.hashing.Hashing._hash_values_to_bins(self,values)
keras.layers.preprocessing.hashing.Hashing.call(self,inputs)
keras.layers.preprocessing.hashing.Hashing.compute_output_shape(self,input_shape)
keras.layers.preprocessing.hashing.Hashing.compute_output_signature(self,input_spec)
keras.layers.preprocessing.hashing.Hashing.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/hashed_crossing.py----------------------------------------
A:keras.layers.preprocessing.hashed_crossing.outputs->tensorflow.compat.v2.reshape(outputs, [])
A:keras.layers.preprocessing.hashed_crossing.output_shape->self.compute_output_shape(input_shapes)
A:keras.layers.preprocessing.hashed_crossing.config->super().get_config()
A:keras.layers.preprocessing.hashed_crossing.first_shape->inputs[0].shape.as_list()
A:keras.layers.preprocessing.hashed_crossing.rank->len(first_shape)
keras.layers.HashedCrossing(self,num_bins,output_mode='int',sparse=False,**kwargs)
keras.layers.HashedCrossing._check_at_least_two_inputs(self,inputs)
keras.layers.HashedCrossing._check_input_shape_and_type(self,inputs)
keras.layers.HashedCrossing.call(self,inputs)
keras.layers.HashedCrossing.compute_output_shape(self,input_shapes)
keras.layers.HashedCrossing.compute_output_signature(self,input_specs)
keras.layers.HashedCrossing.get_config(self)
keras.layers.preprocessing.hashed_crossing.HashedCrossing(self,num_bins,output_mode='int',sparse=False,**kwargs)
keras.layers.preprocessing.hashed_crossing.HashedCrossing.__init__(self,num_bins,output_mode='int',sparse=False,**kwargs)
keras.layers.preprocessing.hashed_crossing.HashedCrossing._check_at_least_two_inputs(self,inputs)
keras.layers.preprocessing.hashed_crossing.HashedCrossing._check_input_shape_and_type(self,inputs)
keras.layers.preprocessing.hashed_crossing.HashedCrossing.call(self,inputs)
keras.layers.preprocessing.hashed_crossing.HashedCrossing.compute_output_shape(self,input_shapes)
keras.layers.preprocessing.hashed_crossing.HashedCrossing.compute_output_signature(self,input_specs)
keras.layers.preprocessing.hashed_crossing.HashedCrossing.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/string_lookup.py----------------------------------------
A:keras.layers.preprocessing.string_lookup.base_config->super(StringLookup, self).get_config()
A:keras.layers.preprocessing.string_lookup.vocabulary->vocabulary.numpy().numpy()
keras.layers.StringLookup(self,max_tokens=None,num_oov_indices=1,mask_token=None,oov_token='[UNK]',vocabulary=None,idf_weights=None,encoding=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.StringLookup._tensor_vocab_to_numpy(self,vocabulary)
keras.layers.StringLookup.adapt(self,data,batch_size=None,steps=None)
keras.layers.StringLookup.get_config(self)
keras.layers.preprocessing.string_lookup.StringLookup(self,max_tokens=None,num_oov_indices=1,mask_token=None,oov_token='[UNK]',vocabulary=None,idf_weights=None,encoding=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.preprocessing.string_lookup.StringLookup.__init__(self,max_tokens=None,num_oov_indices=1,mask_token=None,oov_token='[UNK]',vocabulary=None,idf_weights=None,encoding=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.preprocessing.string_lookup.StringLookup._tensor_vocab_to_numpy(self,vocabulary)
keras.layers.preprocessing.string_lookup.StringLookup.adapt(self,data,batch_size=None,steps=None)
keras.layers.preprocessing.string_lookup.StringLookup.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/preprocessing_test_utils.py----------------------------------------
A:keras.layers.preprocessing.preprocessing_test_utils.data_1->numpy.array([data[1]])
A:keras.layers.preprocessing.preprocessing_test_utils.data_2->numpy.array(data[2:])
A:keras.layers.preprocessing.preprocessing_test_utils.data_0->numpy.array([data[0]])
A:keras.layers.preprocessing.preprocessing_test_utils.single_compute->combiner.compute(data)
A:keras.layers.preprocessing.preprocessing_test_utils.all_merge->combiner.merge([combiner.compute(data_0), combiner.compute(data_1), combiner.compute(data_2)])
A:keras.layers.preprocessing.preprocessing_test_utils.unordered_all_merge->combiner.merge([combiner.compute(data_1), combiner.compute(data_2), combiner.compute(data_0)])
A:keras.layers.preprocessing.preprocessing_test_utils.hierarchical_merge->combiner.merge([combiner.compute(data_1), combiner.merge([combiner.compute(data_2), combiner.compute(data_0)])])
A:keras.layers.preprocessing.preprocessing_test_utils.nested_compute->combiner.compute(data_0, combiner.compute(data_1, combiner.compute(data_2)))
A:keras.layers.preprocessing.preprocessing_test_utils.mixed_compute->combiner.merge([combiner.compute(data_0), combiner.compute(data_1, combiner.compute(data_2))])
A:keras.layers.preprocessing.preprocessing_test_utils.single_merge->combiner.merge([combiner.merge([combiner.compute(data_0)]), combiner.compute(data_1, combiner.compute(data_2))])
A:keras.layers.preprocessing.preprocessing_test_utils.acc->combiner.compute(data)
A:keras.layers.preprocessing.preprocessing_test_utils.extracted_data->combiner.extract(acc)
A:keras.layers.preprocessing.preprocessing_test_utils.restored_acc->combiner.restore(extracted_data)
A:keras.layers.preprocessing.preprocessing_test_utils.serialized_data->combiner.serialize(acc)
A:keras.layers.preprocessing.preprocessing_test_utils.deserialized_data->combiner.deserialize(serialized_data)
A:keras.layers.preprocessing.preprocessing_test_utils.acc2->combiner.compute(data)
keras.layers.preprocessing.preprocessing_test_utils.ArrayLike(self,values)
keras.layers.preprocessing.preprocessing_test_utils.ArrayLike.__array__(self)
keras.layers.preprocessing.preprocessing_test_utils.ArrayLike.__init__(self,values)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest(tf.test.TestCase)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.assertAllCloseOrEqual(self,a,b,msg=None)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.assert_extracted_output_equal(self,combiner,acc1,acc2,msg=None)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.validate_accumulator_computation(self,combiner,data,expected)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.validate_accumulator_extract(self,combiner,data,expected)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.validate_accumulator_extract_and_restore(self,combiner,data,expected)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.validate_accumulator_serialize_and_deserialize(self,combiner,data,expected)
keras.layers.preprocessing.preprocessing_test_utils.PreprocessingLayerTest.validate_accumulator_uniqueness(self,combiner,data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/discretization.py----------------------------------------
A:keras.layers.preprocessing.discretization.values->tensorflow.compat.v2.sort(values)
A:keras.layers.preprocessing.discretization.elements->tensorflow.compat.v2.cast(tf.size(values), tf.float32)
A:keras.layers.preprocessing.discretization.increment->tensorflow.compat.v2.cast(elements / num_buckets, tf.int32)
A:keras.layers.preprocessing.discretization.step->tensorflow.compat.v2.maximum(increment, 1)
A:keras.layers.preprocessing.discretization.weights->tensorflow.compat.v2.ones_like(boundaries)
A:keras.layers.preprocessing.discretization.cum_weights->numpy.interp(percents, cum_weight_percents, cum_weights)
A:keras.layers.preprocessing.discretization.new_bins->numpy.interp(percents, cum_weight_percents, summary[0])
A:keras.layers.preprocessing.discretization.summary->summarize(data, self.epsilon)
A:keras.layers.preprocessing.discretization.merged->tensorflow.compat.v2.gather(merged, tf.argsort(merged[0]), axis=1)
A:keras.layers.preprocessing.discretization.bin_boundaries->keras.layers.preprocessing.preprocessing_utils.listify_tensors(bin_boundaries)
A:keras.layers.preprocessing.discretization.self.summary->self.add_weight(name='summary', shape=(2, None), dtype=tf.float32, initializer=lambda shape, dtype: [[], []], trainable=False)
A:keras.layers.preprocessing.discretization.data->tensorflow.compat.v2.cast(data, tf.float32)
A:keras.layers.preprocessing.discretization.self.bin_boundaries->keras.layers.preprocessing.preprocessing_utils.listify_tensors(get_bin_boundaries(self.summary, self.num_bins))
A:keras.layers.preprocessing.discretization.config->super().get_config()
A:keras.layers.preprocessing.discretization.output_shape->self.compute_output_shape(input_spec.shape.as_list())
A:keras.layers.preprocessing.discretization.indices->bucketize(inputs)
keras.layers.Discretization(self,bin_boundaries=None,num_bins=None,epsilon=0.01,output_mode='int',sparse=False,**kwargs)
keras.layers.Discretization.adapt(self,data,batch_size=None,steps=None)
keras.layers.Discretization.build(self,input_shape)
keras.layers.Discretization.call(self,inputs)
keras.layers.Discretization.compute_output_shape(self,input_shape)
keras.layers.Discretization.compute_output_signature(self,input_spec)
keras.layers.Discretization.finalize_state(self)
keras.layers.Discretization.get_config(self)
keras.layers.Discretization.reset_state(self)
keras.layers.Discretization.update_state(self,data)
keras.layers.preprocessing.discretization.Discretization(self,bin_boundaries=None,num_bins=None,epsilon=0.01,output_mode='int',sparse=False,**kwargs)
keras.layers.preprocessing.discretization.Discretization.__init__(self,bin_boundaries=None,num_bins=None,epsilon=0.01,output_mode='int',sparse=False,**kwargs)
keras.layers.preprocessing.discretization.Discretization.adapt(self,data,batch_size=None,steps=None)
keras.layers.preprocessing.discretization.Discretization.build(self,input_shape)
keras.layers.preprocessing.discretization.Discretization.call(self,inputs)
keras.layers.preprocessing.discretization.Discretization.compute_output_shape(self,input_shape)
keras.layers.preprocessing.discretization.Discretization.compute_output_signature(self,input_spec)
keras.layers.preprocessing.discretization.Discretization.finalize_state(self)
keras.layers.preprocessing.discretization.Discretization.get_config(self)
keras.layers.preprocessing.discretization.Discretization.reset_state(self)
keras.layers.preprocessing.discretization.Discretization.update_state(self,data)
keras.layers.preprocessing.discretization._compress_summary_numpy(summary,epsilon)
keras.layers.preprocessing.discretization.compress(summary,epsilon)
keras.layers.preprocessing.discretization.get_bin_boundaries(summary,num_bins)
keras.layers.preprocessing.discretization.merge_summaries(prev_summary,next_summary,epsilon)
keras.layers.preprocessing.discretization.summarize(values,epsilon)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/normalization.py----------------------------------------
A:keras.layers.preprocessing.normalization.axis->tuple(axis)
A:keras.layers.preprocessing.normalization.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.preprocessing.normalization.ndim->len(input_shape)
A:keras.layers.preprocessing.normalization.self._keep_axis->sorted([d if d >= 0 else d + ndim for d in self.axis])
A:keras.layers.preprocessing.normalization.mean_and_var_shape->tuple((input_shape[d] for d in self._keep_axis))
A:keras.layers.preprocessing.normalization.self.adapt_mean->self.add_weight(name='mean', shape=mean_and_var_shape, dtype=self.compute_dtype, initializer='zeros', trainable=False)
A:keras.layers.preprocessing.normalization.self.adapt_variance->self.add_weight(name='variance', shape=mean_and_var_shape, dtype=self.compute_dtype, initializer='ones', trainable=False)
A:keras.layers.preprocessing.normalization.self.count->self.add_weight(name='count', shape=(), dtype=tf.int64, initializer='zeros', trainable=False)
A:keras.layers.preprocessing.normalization.mean->tensorflow.compat.v2.reshape(mean, self._broadcast_shape)
A:keras.layers.preprocessing.normalization.variance->tensorflow.compat.v2.reshape(variance, self._broadcast_shape)
A:keras.layers.preprocessing.normalization.self.mean->tensorflow.compat.v2.cast(self.mean, self.compute_dtype)
A:keras.layers.preprocessing.normalization.self.variance->tensorflow.compat.v2.cast(self.variance, self.compute_dtype)
A:keras.layers.preprocessing.normalization.data->tensorflow.compat.v2.cast(data, self.adapt_mean.dtype)
A:keras.layers.preprocessing.normalization.(batch_mean, batch_variance)->tensorflow.compat.v2.nn.moments(data, axes=self._reduce_axis)
A:keras.layers.preprocessing.normalization.batch_shape->tensorflow.compat.v2.shape(data, out_type=self.count.dtype)
A:keras.layers.preprocessing.normalization.batch_reduce_shape->tensorflow.compat.v2.gather(batch_shape, self._reduce_axis)
A:keras.layers.preprocessing.normalization.batch_count->tensorflow.compat.v2.reduce_prod(batch_reduce_shape)
A:keras.layers.preprocessing.normalization.inputs->tensorflow.compat.v2.cast(inputs, self.compute_dtype)
A:keras.layers.preprocessing.normalization.config->super().get_config()
keras.layers.Normalization(self,axis=-1,mean=None,variance=None,**kwargs)
keras.layers.Normalization._standardize_inputs(self,inputs)
keras.layers.Normalization.adapt(self,data,batch_size=None,steps=None)
keras.layers.Normalization.build(self,input_shape)
keras.layers.Normalization.call(self,inputs)
keras.layers.Normalization.compute_output_shape(self,input_shape)
keras.layers.Normalization.compute_output_signature(self,input_spec)
keras.layers.Normalization.finalize_state(self)
keras.layers.Normalization.get_config(self)
keras.layers.Normalization.reset_state(self)
keras.layers.Normalization.update_state(self,data)
keras.layers.preprocessing.normalization.Normalization(self,axis=-1,mean=None,variance=None,**kwargs)
keras.layers.preprocessing.normalization.Normalization.__init__(self,axis=-1,mean=None,variance=None,**kwargs)
keras.layers.preprocessing.normalization.Normalization._standardize_inputs(self,inputs)
keras.layers.preprocessing.normalization.Normalization.adapt(self,data,batch_size=None,steps=None)
keras.layers.preprocessing.normalization.Normalization.build(self,input_shape)
keras.layers.preprocessing.normalization.Normalization.call(self,inputs)
keras.layers.preprocessing.normalization.Normalization.compute_output_shape(self,input_shape)
keras.layers.preprocessing.normalization.Normalization.compute_output_signature(self,input_spec)
keras.layers.preprocessing.normalization.Normalization.finalize_state(self)
keras.layers.preprocessing.normalization.Normalization.get_config(self)
keras.layers.preprocessing.normalization.Normalization.reset_state(self)
keras.layers.preprocessing.normalization.Normalization.update_state(self,data)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/category_encoding.py----------------------------------------
A:keras.layers.preprocessing.category_encoding.kwargs['dtype']->keras.backend.floatx()
A:keras.layers.preprocessing.category_encoding.output_shape->self.compute_output_shape(input_spec.shape.as_list())
A:keras.layers.preprocessing.category_encoding.base_config->super(CategoryEncoding, self).get_config()
A:keras.layers.preprocessing.category_encoding.inputs->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(inputs)
A:keras.layers.preprocessing.category_encoding.count_weights->keras.layers.preprocessing.preprocessing_utils.ensure_tensor(count_weights, self.compute_dtype)
A:keras.layers.preprocessing.category_encoding.max_value->tensorflow.compat.v2.reduce_max(inputs)
A:keras.layers.preprocessing.category_encoding.min_value->tensorflow.compat.v2.reduce_min(inputs)
A:keras.layers.preprocessing.category_encoding.condition->tensorflow.compat.v2.logical_and(tf.greater(tf.cast(depth, max_value.dtype), max_value), tf.greater_equal(min_value, tf.cast(0, min_value.dtype)))
A:keras.layers.preprocessing.category_encoding.assertion->tensorflow.compat.v2.Assert(condition, ['Input values must be in the range 0 <= values < num_tokens with num_tokens={}'.format(depth)])
keras.layers.CategoryEncoding(self,num_tokens=None,output_mode='multi_hot',sparse=False,**kwargs)
keras.layers.CategoryEncoding.call(self,inputs,count_weights=None)
keras.layers.CategoryEncoding.compute_output_shape(self,input_shape)
keras.layers.CategoryEncoding.compute_output_signature(self,input_spec)
keras.layers.CategoryEncoding.get_config(self)
keras.layers.preprocessing.category_encoding.CategoryEncoding(self,num_tokens=None,output_mode='multi_hot',sparse=False,**kwargs)
keras.layers.preprocessing.category_encoding.CategoryEncoding.__init__(self,num_tokens=None,output_mode='multi_hot',sparse=False,**kwargs)
keras.layers.preprocessing.category_encoding.CategoryEncoding.call(self,inputs,count_weights=None)
keras.layers.preprocessing.category_encoding.CategoryEncoding.compute_output_shape(self,input_shape)
keras.layers.preprocessing.category_encoding.CategoryEncoding.compute_output_signature(self,input_spec)
keras.layers.preprocessing.category_encoding.CategoryEncoding.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/integer_lookup.py----------------------------------------
keras.layers.IntegerLookup(self,max_tokens=None,num_oov_indices=1,mask_token=None,oov_token=-1,vocabulary=None,vocabulary_dtype='int64',idf_weights=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.IntegerLookup.adapt(self,data,batch_size=None,steps=None)
keras.layers.preprocessing.integer_lookup.IntegerLookup(self,max_tokens=None,num_oov_indices=1,mask_token=None,oov_token=-1,vocabulary=None,vocabulary_dtype='int64',idf_weights=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.preprocessing.integer_lookup.IntegerLookup.__init__(self,max_tokens=None,num_oov_indices=1,mask_token=None,oov_token=-1,vocabulary=None,vocabulary_dtype='int64',idf_weights=None,invert=False,output_mode='int',sparse=False,pad_to_max_tokens=False,**kwargs)
keras.layers.preprocessing.integer_lookup.IntegerLookup.adapt(self,data,batch_size=None,steps=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/benchmarks/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/preprocessing/benchmarks/feature_column_benchmark.py----------------------------------------
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.self.t0->time.time()
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.self.tn->time.time()
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.lengths->(np.random.random(size=num_entries) * length).astype(int)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.total_length->numpy.sum(lengths)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.values->(np.random.random(size=total_length) * max_value).astype(dtype)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.num_oovs->int(pct_oov * total_length)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.oov_cadence->int(total_length / num_oovs)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.base->len(string.ascii_letters)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.n->math.ceil(math.log(vocab_size, base))
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.ds->tensorflow.compat.v2.data.Dataset.from_tensor_slices(data).repeat().prefetch(tf.data.AUTOTUNE).batch(batch_size).cache()
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.timer->StepTimingCallback()
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.avg_time->numpy.mean(avg_per_step_time)
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark.ds_iter->tensorflow.compat.v2.data.Dataset.from_tensor_slices(data).repeat().prefetch(tf.data.AUTOTUNE).batch(batch_size).cache().__iter__()
A:keras.layers.preprocessing.benchmarks.feature_column_benchmark._->fc_fn(next(ds_iter))
keras.layers.preprocessing.benchmarks.feature_column_benchmark.LayerBenchmark(tf.test.Benchmark)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.LayerBenchmark.report(self,name,keras_time,fc_time,iters)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.StepTimingCallback(self)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.StepTimingCallback.__init__(self)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.StepTimingCallback.on_predict_batch_begin(self,batch_index,_)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.StepTimingCallback.on_predict_end(self,_)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.create_data(length,num_entries,max_value,dtype)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.create_string_data(length,num_entries,vocabulary,pct_oov,oov_string='__OOV__')
keras.layers.preprocessing.benchmarks.feature_column_benchmark.create_vocabulary(vocab_size)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.run_fc(data,fc_fn,batch_size,num_runs,steps_per_repeat=100)
keras.layers.preprocessing.benchmarks.feature_column_benchmark.run_keras(data,model,batch_size,num_runs,steps_per_repeat=100)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/base_wrapper.py----------------------------------------
A:keras.layers.rnn.base_wrapper.base_config->super(Wrapper, self).get_config()
A:keras.layers.rnn.base_wrapper.config->copy.deepcopy(config)
A:keras.layers.rnn.base_wrapper.layer->deserialize_layer(config.pop('layer'), custom_objects=custom_objects)
keras.layers.rnn.Wrapper(self,layer,**kwargs)
keras.layers.rnn.Wrapper.activity_regularizer(self)
keras.layers.rnn.Wrapper.build(self,input_shape=None)
keras.layers.rnn.Wrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.Wrapper.get_config(self)
keras.layers.rnn.base_wrapper.Wrapper(self,layer,**kwargs)
keras.layers.rnn.base_wrapper.Wrapper.__init__(self,layer,**kwargs)
keras.layers.rnn.base_wrapper.Wrapper.activity_regularizer(self)
keras.layers.rnn.base_wrapper.Wrapper.build(self,input_shape=None)
keras.layers.rnn.base_wrapper.Wrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.base_wrapper.Wrapper.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/base_conv_rnn.py----------------------------------------
A:keras.layers.rnn.base_conv_rnn.norm_img_dims->tuple([conv_utils.conv_output_length(img_dims[idx], cell.kernel_size[idx], padding=cell.padding, stride=cell.strides[idx], dilation=cell.dilation_rate[idx]) for idx in range(len(img_dims))])
A:keras.layers.rnn.base_conv_rnn.self.input_spec[0]->InputSpec(shape=(batch_size, None) + input_shape[2:self.rank + 3])
A:keras.layers.rnn.base_conv_rnn.state_size->list(self.cell.state_size)
A:keras.layers.rnn.base_conv_rnn.img_dims->tuple((None for _ in range(self.rank)))
A:keras.layers.rnn.base_conv_rnn.initial_state->self.cell.input_conv(initial_state, tf.zeros(tuple(shape), initial_state.dtype), padding=self.cell.padding)
A:keras.layers.rnn.base_conv_rnn.shape->list(self.cell.kernel_shape)
A:keras.layers.rnn.base_conv_rnn.(inputs, initial_state, constants)->self._process_inputs(inputs, initial_state, constants)
A:keras.layers.rnn.base_conv_rnn.(last_output, outputs, states)->keras.backend.rnn(step, inputs, initial_state, constants=constants, go_backwards=self.go_backwards, mask=mask, input_length=timesteps, return_all_outputs=self.return_sequences)
A:keras.layers.rnn.base_conv_rnn.states->list(states)
A:keras.layers.rnn.base_conv_rnn.state_shape->state_shape[:1].concatenate(state_shape[2:])
A:keras.layers.rnn.base_conv_rnn.result->list(state_shape)
keras.layers.rnn.base_conv_rnn.ConvRNN(self,rank,cell,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.base_conv_rnn.ConvRNN.__init__(self,rank,cell,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.base_conv_rnn.ConvRNN.build(self,input_shape)
keras.layers.rnn.base_conv_rnn.ConvRNN.call(self,inputs,mask=None,training=None,initial_state=None,constants=None)
keras.layers.rnn.base_conv_rnn.ConvRNN.compute_output_shape(self,input_shape)
keras.layers.rnn.base_conv_rnn.ConvRNN.get_initial_state(self,inputs)
keras.layers.rnn.base_conv_rnn.ConvRNN.reset_states(self,states=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/stacked_rnn_cells.py----------------------------------------
A:keras.layers.rnn.stacked_rnn_cells.self.reverse_state_order->kwargs.pop('reverse_state_order', False)
A:keras.layers.rnn.stacked_rnn_cells.get_initial_state_fn->getattr(cell, 'get_initial_state', None)
A:keras.layers.rnn.stacked_rnn_cells.nested_states->tensorflow.compat.v2.nest.pack_sequence_as(state_size, tf.nest.flatten(states))
A:keras.layers.rnn.stacked_rnn_cells.(inputs, states)->cell_call_fn(inputs, states, **kwargs)
A:keras.layers.rnn.stacked_rnn_cells.shape->tensorflow.compat.v2.TensorShape(dim).as_list()
A:keras.layers.rnn.stacked_rnn_cells.input_shape->tuple([batch_size] + tf.TensorShape(output_dim).as_list())
A:keras.layers.rnn.stacked_rnn_cells.base_config->super(StackedRNNCells, self).get_config()
keras.layers.rnn.StackedRNNCells(self,cells,**kwargs)
keras.layers.rnn.StackedRNNCells.build(self,input_shape)
keras.layers.rnn.StackedRNNCells.call(self,inputs,states,constants=None,training=None,**kwargs)
keras.layers.rnn.StackedRNNCells.from_config(cls,config,custom_objects=None)
keras.layers.rnn.StackedRNNCells.get_config(self)
keras.layers.rnn.StackedRNNCells.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.StackedRNNCells.output_size(self)
keras.layers.rnn.StackedRNNCells.state_size(self)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells(self,cells,**kwargs)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.__init__(self,cells,**kwargs)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.build(self,input_shape)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.call(self,inputs,states,constants=None,training=None,**kwargs)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.from_config(cls,config,custom_objects=None)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.get_config(self)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.output_size(self)
keras.layers.rnn.stacked_rnn_cells.StackedRNNCells.state_size(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/conv_lstm2d.py----------------------------------------
keras.layers.rnn.ConvLSTM2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.conv_lstm2d.ConvLSTM2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.conv_lstm2d.ConvLSTM2D.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/cell_wrappers.py----------------------------------------
A:keras.layers.rnn.cell_wrappers.cell_call_spec->keras.utils.tf_inspect.getfullargspec(cell.call)
A:keras.layers.rnn.cell_wrappers.base_config->super(DeviceWrapper, self).get_config()
A:keras.layers.rnn.cell_wrappers.config->config.copy().copy()
A:keras.layers.rnn.cell_wrappers.cell->deserialize_layer(config.pop('cell'), custom_objects=custom_objects)
A:keras.layers.rnn.cell_wrappers.tensor_value->tensorflow.compat.v2.convert_to_tensor(v)
A:keras.layers.rnn.cell_wrappers.const_value->tensorflow.compat.v2.get_static_value(tensor_value)
A:keras.layers.rnn.cell_wrappers.(tensor_prob, const_prob)->tensor_and_const_value(prob)
A:keras.layers.rnn.cell_wrappers.shape->convert_to_batch_shape(s)
A:keras.layers.rnn.cell_wrappers.self._recurrent_input_noise->_enumerated_map_structure_up_to(input_size, lambda i, s: batch_noise(s, inner_seed=self._gen_seed('input', i)), input_size)
A:keras.layers.rnn.cell_wrappers.self._recurrent_state_noise->_enumerated_map_structure_up_to(cell.state_size, lambda i, s: batch_noise(s, inner_seed=self._gen_seed('state', i)), cell.state_size)
A:keras.layers.rnn.cell_wrappers.self._recurrent_output_noise->_enumerated_map_structure_up_to(cell.output_size, lambda i, s: batch_noise(s, inner_seed=self._gen_seed('output', i)), cell.output_size)
A:keras.layers.rnn.cell_wrappers.string->(str(self._seed) + salt).encode('utf-8')
A:keras.layers.rnn.cell_wrappers.binary_tensor->tensorflow.compat.v2.floor(random_tensor)
A:keras.layers.rnn.cell_wrappers.inputs->self._dropout(inputs, 'input', self._recurrent_input_noise, self._input_keep_prob)
A:keras.layers.rnn.cell_wrappers.(output, new_state)->cell_call_fn(inputs, state, **kwargs)
A:keras.layers.rnn.cell_wrappers.shallow_filtered_substructure->tensorflow.compat.v2.__internal__.nest.get_traverse_shallow_structure(self._dropout_state_filter, new_state)
A:keras.layers.rnn.cell_wrappers.new_state->self._dropout(new_state, 'state', self._recurrent_state_noise, self._state_keep_prob, shallow_filtered_substructure)
A:keras.layers.rnn.cell_wrappers.output->keras.utils.generic_utils.func_dump(function)
A:keras.layers.rnn.cell_wrappers.(function, function_type, function_module)->_serialize_function_to_config(self._residual_fn)
A:keras.layers.rnn.cell_wrappers.dropout_state_filter->_parse_config_to_function(config, custom_objects, 'dropout_fn', 'dropout_fn_type', 'dropout_fn_module')
A:keras.layers.rnn.cell_wrappers.(outputs, new_state)->cell_call_fn(inputs, state, **kwargs)
A:keras.layers.rnn.cell_wrappers.res_outputs->(self._residual_fn or default_residual_fn)(inputs, outputs)
A:keras.layers.rnn.cell_wrappers.residual_function->_parse_config_to_function(config, custom_objects, 'residual_fn', 'residual_fn_type', 'residual_fn_module')
A:keras.layers.rnn.cell_wrappers.globs->globals()
A:keras.layers.rnn.cell_wrappers.module->config.copy().copy().pop(module_attr_name, None)
A:keras.layers.rnn.cell_wrappers.function_type->config.copy().copy().pop(func_type_attr_name)
A:keras.layers.rnn.cell_wrappers.function->keras.utils.generic_utils.func_load(config[func_attr_name], globs=globs)
A:keras.layers.rnn.cell_wrappers.r->map_fn(ix[0], *inner_args, **inner_kwargs)
keras.layers.rnn.DeviceWrapper(self,cell,device,**kwargs)
keras.layers.rnn.DeviceWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.DeviceWrapper.get_config(self)
keras.layers.rnn.DeviceWrapper.zero_state(self,batch_size,dtype)
keras.layers.rnn.DropoutWrapper(self,cell,input_keep_prob=1.0,output_keep_prob=1.0,state_keep_prob=1.0,variational_recurrent=False,input_size=None,dtype=None,seed=None,dropout_state_filter_visitor=None,**kwargs)
keras.layers.rnn.DropoutWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.DropoutWrapper._dropout(self,values,salt_prefix,recurrent_noise,keep_prob,shallow_filtered_substructure=None)
keras.layers.rnn.DropoutWrapper._gen_seed(self,salt_prefix,index)
keras.layers.rnn.DropoutWrapper._variational_recurrent_dropout_value(self,unused_index,value,noise,keep_prob)
keras.layers.rnn.DropoutWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.DropoutWrapper.get_config(self)
keras.layers.rnn.ResidualWrapper(self,cell,residual_fn=None,**kwargs)
keras.layers.rnn.ResidualWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.ResidualWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.ResidualWrapper.get_config(self)
keras.layers.rnn.cell_wrappers.DeviceWrapper(self,cell,device,**kwargs)
keras.layers.rnn.cell_wrappers.DeviceWrapper.__init__(self,cell,device,**kwargs)
keras.layers.rnn.cell_wrappers.DeviceWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.cell_wrappers.DeviceWrapper.get_config(self)
keras.layers.rnn.cell_wrappers.DeviceWrapper.zero_state(self,batch_size,dtype)
keras.layers.rnn.cell_wrappers.DropoutWrapper(self,cell,input_keep_prob=1.0,output_keep_prob=1.0,state_keep_prob=1.0,variational_recurrent=False,input_size=None,dtype=None,seed=None,dropout_state_filter_visitor=None,**kwargs)
keras.layers.rnn.cell_wrappers.DropoutWrapper.__init__(self,cell,input_keep_prob=1.0,output_keep_prob=1.0,state_keep_prob=1.0,variational_recurrent=False,input_size=None,dtype=None,seed=None,dropout_state_filter_visitor=None,**kwargs)
keras.layers.rnn.cell_wrappers.DropoutWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.cell_wrappers.DropoutWrapper._dropout(self,values,salt_prefix,recurrent_noise,keep_prob,shallow_filtered_substructure=None)
keras.layers.rnn.cell_wrappers.DropoutWrapper._gen_seed(self,salt_prefix,index)
keras.layers.rnn.cell_wrappers.DropoutWrapper._variational_recurrent_dropout_value(self,unused_index,value,noise,keep_prob)
keras.layers.rnn.cell_wrappers.DropoutWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.cell_wrappers.DropoutWrapper.get_config(self)
keras.layers.rnn.cell_wrappers.ResidualWrapper(self,cell,residual_fn=None,**kwargs)
keras.layers.rnn.cell_wrappers.ResidualWrapper.__init__(self,cell,residual_fn=None,**kwargs)
keras.layers.rnn.cell_wrappers.ResidualWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.cell_wrappers.ResidualWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.cell_wrappers.ResidualWrapper.get_config(self)
keras.layers.rnn.cell_wrappers._RNNCellWrapper(self,cell,*args,**kwargs)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.__init__(self,cell,*args,**kwargs)
keras.layers.rnn.cell_wrappers._RNNCellWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.build(self,inputs_shape)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.call(self,inputs,state,**kwargs)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.get_config(self)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.output_size(self)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.state_size(self)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.wrapped_cell(self)
keras.layers.rnn.cell_wrappers._RNNCellWrapper.zero_state(self,batch_size,dtype)
keras.layers.rnn.cell_wrappers._default_dropout_state_filter_visitor(substate)
keras.layers.rnn.cell_wrappers._enumerated_map_structure_up_to(shallow_structure,map_fn,*args,**kwargs)
keras.layers.rnn.cell_wrappers._parse_config_to_function(config,custom_objects,func_attr_name,func_type_attr_name,module_attr_name)
keras.layers.rnn.cell_wrappers._serialize_function_to_config(function)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/time_distributed.py----------------------------------------
A:keras.layers.rnn.time_distributed.int_shape->list(int_shape)
A:keras.layers.rnn.time_distributed.shape->keras.backend.shape(tensor)
A:keras.layers.rnn.time_distributed.dims->dims.as_list().as_list()
A:keras.layers.rnn.time_distributed.input_shape->keras.utils.tf_utils.convert_shapes(input_shape, to_tuples=False)
A:keras.layers.rnn.time_distributed.input_dims->tensorflow.compat.v2.nest.flatten(tf.nest.map_structure(lambda x: x.ndims, input_shape))
A:keras.layers.rnn.time_distributed.self.input_spec->tensorflow.compat.v2.nest.map_structure(lambda x: InputSpec(shape=[None, None] + x.as_list()[2:]), input_shape)
A:keras.layers.rnn.time_distributed.child_input_shape->tensorflow.compat.v2.nest.map_structure(self._remove_timesteps, input_shape)
A:keras.layers.rnn.time_distributed.child_output_shape->keras.utils.tf_utils.convert_shapes(child_output_shape, to_tuples=False)
A:keras.layers.rnn.time_distributed.timesteps->keras.utils.tf_utils.convert_shapes(input_shape)
A:keras.layers.rnn.time_distributed.batch_size->keras.utils.tf_utils.convert_shapes(input_shape)
A:keras.layers.rnn.time_distributed.(inputs, row_lengths)->keras.backend.convert_inputs_if_ragged(inputs)
A:keras.layers.rnn.time_distributed.input_length->tensorflow.compat.v2.nest.map_structure(lambda x: backend.shape(x)[1], inputs)
A:keras.layers.rnn.time_distributed.output->self.layer(x, **kwargs)
A:keras.layers.rnn.time_distributed.(_, outputs, _)->keras.backend.rnn(step, inputs, initial_states=[], input_length=row_lengths[0] if is_ragged_input else input_length, mask=mask, unroll=False)
A:keras.layers.rnn.time_distributed.y->tensorflow.compat.v2.__internal__.nest.map_structure_up_to(y, tf.reshape, y, output_shape)
A:keras.layers.rnn.time_distributed.is_ragged_input->keras.utils.generic_utils.to_list(tf.nest.flatten(is_ragged_input))
A:keras.layers.rnn.time_distributed.input_values->tensorflow.compat.v2.nest.map_structure(lambda x: x.values, inputs)
A:keras.layers.rnn.time_distributed.input_row_lenghts->tensorflow.compat.v2.nest.map_structure(lambda x: x.nested_row_lengths()[0], inputs)
A:keras.layers.rnn.time_distributed.inner_input_shape->tensorflow.compat.v2.nest.map_structure(lambda tensor: self._get_shape_tuple((-1,), tensor, 2), inputs)
A:keras.layers.rnn.time_distributed.inputs->tensorflow.compat.v2.__internal__.nest.map_structure_up_to(inputs, tf.reshape, inputs, inner_input_shape)
A:keras.layers.rnn.time_distributed.inner_mask_shape->self._get_shape_tuple((-1,), mask, 2)
A:keras.layers.rnn.time_distributed.kwargs['mask']->keras.backend.reshape(mask, inner_mask_shape)
A:keras.layers.rnn.time_distributed.output_shape->tensorflow.compat.v2.nest.map_structure(lambda tensor, int_shape: self._get_shape_tuple((-1, input_length), tensor, 1, int_shape[2:]), y, output_shape)
A:keras.layers.rnn.time_distributed.inner_mask->keras.backend.reshape(inner_mask, inner_mask_shape)
A:keras.layers.rnn.time_distributed.inner_inputs->tensorflow.compat.v2.__internal__.nest.map_structure_up_to(inputs, tf.reshape, inputs, inner_input_shape)
A:keras.layers.rnn.time_distributed.output_mask->keras.backend.reshape(output_mask, output_mask_shape)
A:keras.layers.rnn.time_distributed.output_mask_int_shape->keras.backend.int_shape(mask)
A:keras.layers.rnn.time_distributed.output_mask_shape->self._get_shape_tuple((-1, input_length), output_mask, 1, output_mask_int_shape[1:])
keras.layers.rnn.TimeDistributed(self,layer,**kwargs)
keras.layers.rnn.TimeDistributed._get_shape_tuple(self,init_tuple,tensor,start_idx,int_shape=None)
keras.layers.rnn.TimeDistributed._remove_timesteps(self,dims)
keras.layers.rnn.TimeDistributed.build(self,input_shape)
keras.layers.rnn.TimeDistributed.call(self,inputs,training=None,mask=None)
keras.layers.rnn.TimeDistributed.compute_mask(self,inputs,mask=None)
keras.layers.rnn.TimeDistributed.compute_output_shape(self,input_shape)
keras.layers.rnn.time_distributed.TimeDistributed(self,layer,**kwargs)
keras.layers.rnn.time_distributed.TimeDistributed.__init__(self,layer,**kwargs)
keras.layers.rnn.time_distributed.TimeDistributed._get_shape_tuple(self,init_tuple,tensor,start_idx,int_shape=None)
keras.layers.rnn.time_distributed.TimeDistributed._remove_timesteps(self,dims)
keras.layers.rnn.time_distributed.TimeDistributed.build(self,input_shape)
keras.layers.rnn.time_distributed.TimeDistributed.call(self,inputs,training=None,mask=None)
keras.layers.rnn.time_distributed.TimeDistributed.compute_mask(self,inputs,mask=None)
keras.layers.rnn.time_distributed.TimeDistributed.compute_output_shape(self,input_shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/cudnn_lstm.py----------------------------------------
A:keras.layers.rnn.cudnn_lstm.cell_spec->collections.namedtuple('cell', 'state_size')
A:keras.layers.rnn.cudnn_lstm.self._cell->cell_spec(state_size=(self.units, self.units))
A:keras.layers.rnn.cudnn_lstm.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.cudnn_lstm.self.recurrent_initializer->keras.initializers.get(recurrent_initializer)
A:keras.layers.rnn.cudnn_lstm.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.cudnn_lstm.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.rnn.cudnn_lstm.self.recurrent_regularizer->keras.regularizers.get(recurrent_regularizer)
A:keras.layers.rnn.cudnn_lstm.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.rnn.cudnn_lstm.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.rnn.cudnn_lstm.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.rnn.cudnn_lstm.self.recurrent_constraint->keras.constraints.get(recurrent_constraint)
A:keras.layers.rnn.cudnn_lstm.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.rnn.cudnn_lstm.input_dim->int(input_shape[-1])
A:keras.layers.rnn.cudnn_lstm.self.kernel->self.add_weight(shape=(input_dim, self.units * 4), name='kernel', initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)
A:keras.layers.rnn.cudnn_lstm.self.recurrent_kernel->self.add_weight(shape=(self.units, self.units * 4), name='recurrent_kernel', initializer=self.recurrent_initializer, regularizer=self.recurrent_regularizer, constraint=self.recurrent_constraint)
A:keras.layers.rnn.cudnn_lstm.self.bias->self.add_weight(shape=(self.units * 8,), name='bias', initializer=bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint)
A:keras.layers.rnn.cudnn_lstm.inputs->tensorflow.compat.v2.transpose(inputs, perm=(1, 0, 2))
A:keras.layers.rnn.cudnn_lstm.input_h->tensorflow.compat.v2.expand_dims(input_h, axis=0)
A:keras.layers.rnn.cudnn_lstm.input_c->tensorflow.compat.v2.expand_dims(input_c, axis=0)
A:keras.layers.rnn.cudnn_lstm.params->keras.layers.rnn.gru_lstm_utils.canonical_to_params(weights=[self.kernel[:, :self.units], self.kernel[:, self.units:self.units * 2], self.kernel[:, self.units * 2:self.units * 3], self.kernel[:, self.units * 3:], self.recurrent_kernel[:, :self.units], self.recurrent_kernel[:, self.units:self.units * 2], self.recurrent_kernel[:, self.units * 2:self.units * 3], self.recurrent_kernel[:, self.units * 3:]], biases=[self.bias[:self.units], self.bias[self.units:self.units * 2], self.bias[self.units * 2:self.units * 3], self.bias[self.units * 3:self.units * 4], self.bias[self.units * 4:self.units * 5], self.bias[self.units * 5:self.units * 6], self.bias[self.units * 6:self.units * 7], self.bias[self.units * 7:]], shape=self._vector_shape)
A:keras.layers.rnn.cudnn_lstm.(outputs, h, c, _, _)->tensorflow.compat.v2.raw_ops.CudnnRNNV2(**args)
A:keras.layers.rnn.cudnn_lstm.output->tensorflow.compat.v2.transpose(outputs, perm=(1, 0, 2))
A:keras.layers.rnn.cudnn_lstm.base_config->super(CuDNNLSTM, self).get_config()
keras.layers.rnn.CuDNNLSTM(self,units,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,**kwargs)
keras.layers.rnn.CuDNNLSTM._process_batch(self,inputs,initial_state)
keras.layers.rnn.CuDNNLSTM.build(self,input_shape)
keras.layers.rnn.CuDNNLSTM.cell(self)
keras.layers.rnn.CuDNNLSTM.get_config(self)
keras.layers.rnn.cudnn_lstm.CuDNNLSTM(self,units,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,**kwargs)
keras.layers.rnn.cudnn_lstm.CuDNNLSTM.__init__(self,units,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,**kwargs)
keras.layers.rnn.cudnn_lstm.CuDNNLSTM._process_batch(self,inputs,initial_state)
keras.layers.rnn.cudnn_lstm.CuDNNLSTM.build(self,input_shape)
keras.layers.rnn.cudnn_lstm.CuDNNLSTM.cell(self)
keras.layers.rnn.cudnn_lstm.CuDNNLSTM.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/lstm.py----------------------------------------
A:keras.layers.rnn.lstm.self._enable_caching_device->kwargs.pop('enable_caching_device', False)
A:keras.layers.rnn.lstm.self.activation->keras.activations.get(activation)
A:keras.layers.rnn.lstm.self.recurrent_activation->keras.activations.get(recurrent_activation)
A:keras.layers.rnn.lstm.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.lstm.self.recurrent_initializer->keras.initializers.get(recurrent_initializer)
A:keras.layers.rnn.lstm.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.lstm.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.rnn.lstm.self.recurrent_regularizer->keras.regularizers.get(recurrent_regularizer)
A:keras.layers.rnn.lstm.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.rnn.lstm.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.rnn.lstm.self.recurrent_constraint->keras.constraints.get(recurrent_constraint)
A:keras.layers.rnn.lstm.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.rnn.lstm.self.dropout->min(1.0, max(0.0, dropout))
A:keras.layers.rnn.lstm.self.recurrent_dropout->min(1.0, max(0.0, recurrent_dropout))
A:keras.layers.rnn.lstm.implementation->kwargs.pop('implementation', 2)
A:keras.layers.rnn.lstm.default_caching_device->keras.layers.rnn.rnn_utils.caching_device(self)
A:keras.layers.rnn.lstm.self.kernel->self.add_weight(shape=(input_dim, self.units * 4), name='kernel', initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.lstm.self.recurrent_kernel->self.add_weight(shape=(self.units, self.units * 4), name='recurrent_kernel', initializer=self.recurrent_initializer, regularizer=self.recurrent_regularizer, constraint=self.recurrent_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.lstm.self.bias->self.add_weight(shape=(self.units * 4,), name='bias', initializer=bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.lstm.i->tensorflow.compat.v2.sigmoid(z0)
A:keras.layers.rnn.lstm.f->tensorflow.compat.v2.sigmoid(z1)
A:keras.layers.rnn.lstm.o->tensorflow.compat.v2.sigmoid(z3)
A:keras.layers.rnn.lstm.dp_mask->self.get_dropout_mask_for_cell(inputs, training, count=4)
A:keras.layers.rnn.lstm.rec_dp_mask->self.get_recurrent_dropout_mask_for_cell(h_tm1, training, count=4)
A:keras.layers.rnn.lstm.(k_i, k_f, k_c, k_o)->tensorflow.compat.v2.split(self.kernel, num_or_size_splits=4, axis=1)
A:keras.layers.rnn.lstm.x_i->keras.backend.bias_add(x_i, b_i)
A:keras.layers.rnn.lstm.x_f->keras.backend.bias_add(x_f, b_f)
A:keras.layers.rnn.lstm.x_c->keras.backend.bias_add(x_c, b_c)
A:keras.layers.rnn.lstm.x_o->keras.backend.bias_add(x_o, b_o)
A:keras.layers.rnn.lstm.(b_i, b_f, b_c, b_o)->tensorflow.compat.v2.split(self.bias, num_or_size_splits=4, axis=0)
A:keras.layers.rnn.lstm.(c, o)->self._compute_carry_and_output_fused(z, c_tm1)
A:keras.layers.rnn.lstm.z->keras.backend.bias_add(z, bias)
A:keras.layers.rnn.lstm.base_config->super(LSTM, self).get_config()
A:keras.layers.rnn.lstm.self.return_runtime->kwargs.pop('return_runtime', False)
A:keras.layers.rnn.lstm.cell->LSTMCell(units, activation=activation, recurrent_activation=recurrent_activation, use_bias=use_bias, kernel_initializer=kernel_initializer, recurrent_initializer=recurrent_initializer, unit_forget_bias=unit_forget_bias, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, kernel_constraint=kernel_constraint, recurrent_constraint=recurrent_constraint, bias_constraint=bias_constraint, dropout=dropout, recurrent_dropout=recurrent_dropout, implementation=implementation, dtype=kwargs.get('dtype'), trainable=kwargs.get('trainable', True), **cell_kwargs)
A:keras.layers.rnn.lstm.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.rnn.lstm.self._defun_wrapper->keras.layers.rnn.gru_lstm_utils.DefunWrapper(time_major, go_backwards, 'lstm')
A:keras.layers.rnn.lstm.(inputs, row_lengths)->keras.backend.convert_inputs_if_ragged(inputs)
A:keras.layers.rnn.lstm.(inputs, initial_state, _)->self._process_inputs(inputs, initial_state, None)
A:keras.layers.rnn.lstm.input_shape->keras.backend.int_shape(inputs)
A:keras.layers.rnn.lstm.(last_output, outputs, states)->keras.backend.rnn(step, inputs, initial_state, constants=None, go_backwards=self.go_backwards, mask=mask, unroll=self.unroll, input_length=row_lengths if row_lengths is not None else timesteps, time_major=self.time_major, zero_output_for_mask=self.zero_output_for_mask, return_all_outputs=self.return_sequences)
A:keras.layers.rnn.lstm.runtime->keras.layers.rnn.gru_lstm_utils.runtime(gru_lstm_utils.RUNTIME_UNKNOWN)
A:keras.layers.rnn.lstm.dropout_mask->self.get_dropout_mask_for_cell(inputs, training, count=4)
A:keras.layers.rnn.lstm.(last_output, outputs, new_h, new_c, runtime)->defun_standard_lstm(**params)
A:keras.layers.rnn.lstm.normal_lstm_kwargs->gpu_lstm_kwargs.copy()
A:keras.layers.rnn.lstm.device_type->keras.layers.rnn.gru_lstm_utils.get_context_device_type()
A:keras.layers.rnn.lstm.output->keras.backend.maybe_convert_to_ragged(is_ragged_input, outputs, row_lengths, go_backwards=self.go_backwards)
A:keras.layers.rnn.lstm.(z0, z1, z2, z3)->tensorflow.compat.v2.split(z, 4, axis=1)
A:keras.layers.rnn.lstm.(last_output, outputs, new_states)->keras.backend.rnn(step, inputs, [init_h, init_c], constants=None, unroll=False, time_major=time_major, mask=mask, go_backwards=go_backwards, input_length=sequence_lengths if sequence_lengths is not None else timesteps, zero_output_for_mask=zero_output_for_mask, return_all_outputs=return_sequences)
A:keras.layers.rnn.lstm.sequence_lengths->keras.layers.rnn.gru_lstm_utils.calculate_sequence_by_mask(mask, time_major)
A:keras.layers.rnn.lstm.inputs->tensorflow.compat.v2.reverse(inputs, axis=[0])
A:keras.layers.rnn.lstm.init_h->tensorflow.compat.v2.expand_dims(init_h, axis=seq_axis)
A:keras.layers.rnn.lstm.init_c->tensorflow.compat.v2.expand_dims(init_c, axis=seq_axis)
A:keras.layers.rnn.lstm.weights->tensorflow.compat.v2.split(kernel, 4, axis=1)
A:keras.layers.rnn.lstm.full_bias->tensorflow.compat.v2.split(full_bias, 8, axis=0)
A:keras.layers.rnn.lstm.params->keras.layers.rnn.gru_lstm_utils.canonical_to_params(weights=weights, biases=tf.split(full_bias, 8), shape=tf.constant([-1]), transpose_weights=True)
A:keras.layers.rnn.lstm.(outputs, h, c, _, _)->tensorflow.compat.v2.raw_ops.CudnnRNNV3(input=inputs, input_h=init_h, input_c=init_c, params=params, is_training=True, rnn_mode='lstm', sequence_lengths=sequence_lengths, time_major=time_major)
A:keras.layers.rnn.lstm.outputs->tensorflow.compat.v2.expand_dims(last_output, axis=0 if time_major else 1)
A:keras.layers.rnn.lstm.(outputs, h, c, _)->tensorflow.compat.v2.raw_ops.CudnnRNN(input=inputs, input_h=init_h, input_c=init_c, params=params, is_training=True, rnn_mode='lstm')
A:keras.layers.rnn.lstm.h->tensorflow.compat.v2.squeeze(h, axis=seq_axis)
A:keras.layers.rnn.lstm.c->tensorflow.compat.v2.squeeze(c, axis=seq_axis)
A:keras.layers.rnn.lstm.defun_standard_lstm->keras.layers.rnn.gru_lstm_utils.generate_defun_backend(api_name, gru_lstm_utils.CPU_DEVICE_NAME, standard_lstm, supportive_attribute)
A:keras.layers.rnn.lstm.defun_gpu_lstm->keras.layers.rnn.gru_lstm_utils.generate_defun_backend(api_name, gru_lstm_utils.GPU_DEVICE_NAME, gpu_lstm_with_fallback, supportive_attribute)
keras.layers.rnn.LSTMCellV2(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.LSTMCellV2._compute_carry_and_output(self,x,h_tm1,c_tm1)
keras.layers.rnn.LSTMCellV2._compute_carry_and_output_fused(self,z,c_tm1)
keras.layers.rnn.LSTMCellV2.build(self,input_shape)
keras.layers.rnn.LSTMCellV2.call(self,inputs,states,training=None)
keras.layers.rnn.LSTMCellV2.get_config(self)
keras.layers.rnn.LSTMCellV2.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.LSTMV2(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,time_major=False,unroll=False,**kwargs)
keras.layers.rnn.LSTMV2.activation(self)
keras.layers.rnn.LSTMV2.bias_constraint(self)
keras.layers.rnn.LSTMV2.bias_initializer(self)
keras.layers.rnn.LSTMV2.bias_regularizer(self)
keras.layers.rnn.LSTMV2.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.LSTMV2.dropout(self)
keras.layers.rnn.LSTMV2.from_config(cls,config)
keras.layers.rnn.LSTMV2.get_config(self)
keras.layers.rnn.LSTMV2.implementation(self)
keras.layers.rnn.LSTMV2.kernel_constraint(self)
keras.layers.rnn.LSTMV2.kernel_initializer(self)
keras.layers.rnn.LSTMV2.kernel_regularizer(self)
keras.layers.rnn.LSTMV2.recurrent_activation(self)
keras.layers.rnn.LSTMV2.recurrent_constraint(self)
keras.layers.rnn.LSTMV2.recurrent_dropout(self)
keras.layers.rnn.LSTMV2.recurrent_initializer(self)
keras.layers.rnn.LSTMV2.recurrent_regularizer(self)
keras.layers.rnn.LSTMV2.unit_forget_bias(self)
keras.layers.rnn.LSTMV2.units(self)
keras.layers.rnn.LSTMV2.use_bias(self)
keras.layers.rnn.lstm.LSTM(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,time_major=False,unroll=False,**kwargs)
keras.layers.rnn.lstm.LSTM.__init__(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,time_major=False,unroll=False,**kwargs)
keras.layers.rnn.lstm.LSTM.activation(self)
keras.layers.rnn.lstm.LSTM.bias_constraint(self)
keras.layers.rnn.lstm.LSTM.bias_initializer(self)
keras.layers.rnn.lstm.LSTM.bias_regularizer(self)
keras.layers.rnn.lstm.LSTM.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.lstm.LSTM.dropout(self)
keras.layers.rnn.lstm.LSTM.from_config(cls,config)
keras.layers.rnn.lstm.LSTM.get_config(self)
keras.layers.rnn.lstm.LSTM.implementation(self)
keras.layers.rnn.lstm.LSTM.kernel_constraint(self)
keras.layers.rnn.lstm.LSTM.kernel_initializer(self)
keras.layers.rnn.lstm.LSTM.kernel_regularizer(self)
keras.layers.rnn.lstm.LSTM.recurrent_activation(self)
keras.layers.rnn.lstm.LSTM.recurrent_constraint(self)
keras.layers.rnn.lstm.LSTM.recurrent_dropout(self)
keras.layers.rnn.lstm.LSTM.recurrent_initializer(self)
keras.layers.rnn.lstm.LSTM.recurrent_regularizer(self)
keras.layers.rnn.lstm.LSTM.unit_forget_bias(self)
keras.layers.rnn.lstm.LSTM.units(self)
keras.layers.rnn.lstm.LSTM.use_bias(self)
keras.layers.rnn.lstm.LSTMCell(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.lstm.LSTMCell.__init__(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.lstm.LSTMCell._compute_carry_and_output(self,x,h_tm1,c_tm1)
keras.layers.rnn.lstm.LSTMCell._compute_carry_and_output_fused(self,z,c_tm1)
keras.layers.rnn.lstm.LSTMCell.build(self,input_shape)
keras.layers.rnn.lstm.LSTMCell.call(self,inputs,states,training=None)
keras.layers.rnn.lstm.LSTMCell.get_config(self)
keras.layers.rnn.lstm.LSTMCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.lstm.gpu_lstm(inputs,init_h,init_c,kernel,recurrent_kernel,bias,mask,time_major,go_backwards,sequence_lengths,return_sequences)
keras.layers.rnn.lstm.lstm_with_backend_selection(inputs,init_h,init_c,kernel,recurrent_kernel,bias,mask,time_major,go_backwards,sequence_lengths,zero_output_for_mask,return_sequences)
keras.layers.rnn.lstm.standard_lstm(inputs,init_h,init_c,kernel,recurrent_kernel,bias,mask,time_major,go_backwards,sequence_lengths,zero_output_for_mask,return_sequences)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/abstract_rnn_cell.py----------------------------------------
keras.layers.rnn.AbstractRNNCell(base_layer.Layer)
keras.layers.rnn.AbstractRNNCell.call(self,inputs,states)
keras.layers.rnn.AbstractRNNCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.AbstractRNNCell.output_size(self)
keras.layers.rnn.AbstractRNNCell.state_size(self)
keras.layers.rnn.abstract_rnn_cell.AbstractRNNCell(base_layer.Layer)
keras.layers.rnn.abstract_rnn_cell.AbstractRNNCell.call(self,inputs,states)
keras.layers.rnn.abstract_rnn_cell.AbstractRNNCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.abstract_rnn_cell.AbstractRNNCell.output_size(self)
keras.layers.rnn.abstract_rnn_cell.AbstractRNNCell.state_size(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/conv_lstm3d.py----------------------------------------
keras.layers.rnn.ConvLSTM3D(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1),activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.conv_lstm3d.ConvLSTM3D(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1),activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.conv_lstm3d.ConvLSTM3D.__init__(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1),activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/dropout_rnn_cell_mixin.py----------------------------------------
A:keras.layers.rnn.dropout_rnn_cell_mixin.self._dropout_mask_cache->keras.backend.ContextValueCache(self._create_dropout_mask)
A:keras.layers.rnn.dropout_rnn_cell_mixin.self._recurrent_dropout_mask_cache->keras.backend.ContextValueCache(self._create_recurrent_dropout_mask)
A:keras.layers.rnn.dropout_rnn_cell_mixin.init_kwargs->dict(inputs=inputs, training=training, count=count)
A:keras.layers.rnn.dropout_rnn_cell_mixin.state->super(DropoutRNNCellMixin, self).__getstate__()
A:keras.layers.rnn.dropout_rnn_cell_mixin.state['_dropout_mask_cache']->keras.backend.ContextValueCache(self._create_dropout_mask)
A:keras.layers.rnn.dropout_rnn_cell_mixin.state['_recurrent_dropout_mask_cache']->keras.backend.ContextValueCache(self._create_recurrent_dropout_mask)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin(self,*args,**kwargs)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.__getstate__(self)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.__init__(self,*args,**kwargs)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.__setstate__(self,state)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin._create_dropout_mask(self,inputs,training,count=1)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin._create_non_trackable_mask_cache(self)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin._create_recurrent_dropout_mask(self,inputs,training,count=1)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.get_dropout_mask_for_cell(self,inputs,training,count=1)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.get_recurrent_dropout_mask_for_cell(self,inputs,training,count=1)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.reset_dropout_mask(self)
keras.layers.rnn.dropout_rnn_cell_mixin.DropoutRNNCellMixin.reset_recurrent_dropout_mask(self)
keras.layers.rnn.dropout_rnn_cell_mixin._generate_dropout_mask(generator,ones,rate,training=None,count=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/gru_v1.py----------------------------------------
A:keras.layers.rnn.gru_v1.implementation->kwargs.pop('implementation', 1)
A:keras.layers.rnn.gru_v1.cell->GRUCell(units, activation=activation, recurrent_activation=recurrent_activation, use_bias=use_bias, kernel_initializer=kernel_initializer, recurrent_initializer=recurrent_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, kernel_constraint=kernel_constraint, recurrent_constraint=recurrent_constraint, bias_constraint=bias_constraint, dropout=dropout, recurrent_dropout=recurrent_dropout, implementation=implementation, reset_after=reset_after, dtype=kwargs.get('dtype'), trainable=kwargs.get('trainable', True), **cell_kwargs)
A:keras.layers.rnn.gru_v1.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.rnn.gru_v1.base_config->super(GRU, self).get_config()
keras.layers.rnn.GRU(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,reset_after=False,**kwargs)
keras.layers.rnn.GRU.activation(self)
keras.layers.rnn.GRU.bias_constraint(self)
keras.layers.rnn.GRU.bias_initializer(self)
keras.layers.rnn.GRU.bias_regularizer(self)
keras.layers.rnn.GRU.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.GRU.dropout(self)
keras.layers.rnn.GRU.from_config(cls,config)
keras.layers.rnn.GRU.get_config(self)
keras.layers.rnn.GRU.implementation(self)
keras.layers.rnn.GRU.kernel_constraint(self)
keras.layers.rnn.GRU.kernel_initializer(self)
keras.layers.rnn.GRU.kernel_regularizer(self)
keras.layers.rnn.GRU.recurrent_activation(self)
keras.layers.rnn.GRU.recurrent_constraint(self)
keras.layers.rnn.GRU.recurrent_dropout(self)
keras.layers.rnn.GRU.recurrent_initializer(self)
keras.layers.rnn.GRU.recurrent_regularizer(self)
keras.layers.rnn.GRU.reset_after(self)
keras.layers.rnn.GRU.units(self)
keras.layers.rnn.GRU.use_bias(self)
keras.layers.rnn.GRUCell(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,reset_after=False,**kwargs)
keras.layers.rnn.gru_v1.GRU(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,reset_after=False,**kwargs)
keras.layers.rnn.gru_v1.GRU.__init__(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,reset_after=False,**kwargs)
keras.layers.rnn.gru_v1.GRU.activation(self)
keras.layers.rnn.gru_v1.GRU.bias_constraint(self)
keras.layers.rnn.gru_v1.GRU.bias_initializer(self)
keras.layers.rnn.gru_v1.GRU.bias_regularizer(self)
keras.layers.rnn.gru_v1.GRU.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.gru_v1.GRU.dropout(self)
keras.layers.rnn.gru_v1.GRU.from_config(cls,config)
keras.layers.rnn.gru_v1.GRU.get_config(self)
keras.layers.rnn.gru_v1.GRU.implementation(self)
keras.layers.rnn.gru_v1.GRU.kernel_constraint(self)
keras.layers.rnn.gru_v1.GRU.kernel_initializer(self)
keras.layers.rnn.gru_v1.GRU.kernel_regularizer(self)
keras.layers.rnn.gru_v1.GRU.recurrent_activation(self)
keras.layers.rnn.gru_v1.GRU.recurrent_constraint(self)
keras.layers.rnn.gru_v1.GRU.recurrent_dropout(self)
keras.layers.rnn.gru_v1.GRU.recurrent_initializer(self)
keras.layers.rnn.gru_v1.GRU.recurrent_regularizer(self)
keras.layers.rnn.gru_v1.GRU.reset_after(self)
keras.layers.rnn.gru_v1.GRU.units(self)
keras.layers.rnn.gru_v1.GRU.use_bias(self)
keras.layers.rnn.gru_v1.GRUCell(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,reset_after=False,**kwargs)
keras.layers.rnn.gru_v1.GRUCell.__init__(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,reset_after=False,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/base_cudnn_rnn.py----------------------------------------
A:keras.layers.rnn.base_cudnn_rnn.self._vector_shape->tensorflow.compat.v2.constant([-1])
A:keras.layers.rnn.base_cudnn_rnn.initial_state->self.get_initial_state(inputs)
A:keras.layers.rnn.base_cudnn_rnn.inputs->keras.backend.reverse(inputs, 1)
A:keras.layers.rnn.base_cudnn_rnn.(output, states)->self._process_batch(inputs, initial_state)
A:keras.layers.rnn.base_cudnn_rnn.base_config->super(RNN, self).get_config()
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN(self,return_sequences=False,return_state=False,go_backwards=False,stateful=False,time_major=False,**kwargs)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.__init__(self,return_sequences=False,return_state=False,go_backwards=False,stateful=False,time_major=False,**kwargs)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.from_config(cls,config)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.get_config(self)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.get_losses_for(self,inputs=None)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.losses(self)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.non_trainable_weights(self)
keras.layers.rnn.base_cudnn_rnn._CuDNNRNN.trainable_weights(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/legacy_cell_wrappers.py----------------------------------------
A:keras.layers.rnn.legacy_cell_wrappers.base_config->super(DeviceWrapper, self).get_config()
A:keras.layers.rnn.legacy_cell_wrappers.config->config.copy().copy()
A:keras.layers.rnn.legacy_cell_wrappers.cell->config.copy().copy().pop('cell')
A:keras.layers.rnn.legacy_cell_wrappers.tensor_value->tensorflow.compat.v2.convert_to_tensor(v)
A:keras.layers.rnn.legacy_cell_wrappers.const_value->tensorflow.compat.v2.get_static_value(tensor_value)
A:keras.layers.rnn.legacy_cell_wrappers.(tensor_prob, const_prob)->tensor_and_const_value(prob)
A:keras.layers.rnn.legacy_cell_wrappers.shape->convert_to_batch_shape(s)
A:keras.layers.rnn.legacy_cell_wrappers.self._recurrent_input_noise->_enumerated_map_structure_up_to(input_size, lambda i, s: batch_noise(s, inner_seed=self._gen_seed('input', i)), input_size)
A:keras.layers.rnn.legacy_cell_wrappers.self._recurrent_state_noise->_enumerated_map_structure_up_to(cell.state_size, lambda i, s: batch_noise(s, inner_seed=self._gen_seed('state', i)), cell.state_size)
A:keras.layers.rnn.legacy_cell_wrappers.self._recurrent_output_noise->_enumerated_map_structure_up_to(cell.output_size, lambda i, s: batch_noise(s, inner_seed=self._gen_seed('output', i)), cell.output_size)
A:keras.layers.rnn.legacy_cell_wrappers.string->(str(self._seed) + salt).encode('utf-8')
A:keras.layers.rnn.legacy_cell_wrappers.binary_tensor->tensorflow.compat.v2.floor(random_tensor)
A:keras.layers.rnn.legacy_cell_wrappers.inputs->self._dropout(inputs, 'input', self._recurrent_input_noise, self._input_keep_prob)
A:keras.layers.rnn.legacy_cell_wrappers.(output, new_state)->cell_call_fn(inputs, state, **kwargs)
A:keras.layers.rnn.legacy_cell_wrappers.shallow_filtered_substructure->tensorflow.compat.v2.__internal__.nest.get_traverse_shallow_structure(self._dropout_state_filter, new_state)
A:keras.layers.rnn.legacy_cell_wrappers.new_state->self._dropout(new_state, 'state', self._recurrent_state_noise, self._state_keep_prob, shallow_filtered_substructure)
A:keras.layers.rnn.legacy_cell_wrappers.output->self._dropout(output, 'output', self._recurrent_output_noise, self._output_keep_prob)
A:keras.layers.rnn.legacy_cell_wrappers.(function, function_type, function_module)->_serialize_function_to_config(self._residual_fn)
A:keras.layers.rnn.legacy_cell_wrappers.dropout_state_filter->_parse_config_to_function(config, custom_objects, 'dropout_fn', 'dropout_fn_type', 'dropout_fn_module')
A:keras.layers.rnn.legacy_cell_wrappers.(outputs, new_state)->cell_call_fn(inputs, state, **kwargs)
A:keras.layers.rnn.legacy_cell_wrappers.res_outputs->(self._residual_fn or default_residual_fn)(inputs, outputs)
A:keras.layers.rnn.legacy_cell_wrappers.residual_function->_parse_config_to_function(config, custom_objects, 'residual_fn', 'residual_fn_type', 'residual_fn_module')
keras.layers.rnn.legacy_DeviceWrapper(self,cell,device,**kwargs)
keras.layers.rnn.legacy_DeviceWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_DeviceWrapper.get_config(self)
keras.layers.rnn.legacy_DeviceWrapper.zero_state(self,batch_size,dtype)
keras.layers.rnn.legacy_DropoutWrapper(self,cell,input_keep_prob=1.0,output_keep_prob=1.0,state_keep_prob=1.0,variational_recurrent=False,input_size=None,dtype=None,seed=None,dropout_state_filter_visitor=None,**kwargs)
keras.layers.rnn.legacy_DropoutWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_DropoutWrapper._dropout(self,values,salt_prefix,recurrent_noise,keep_prob,shallow_filtered_substructure=None)
keras.layers.rnn.legacy_DropoutWrapper._gen_seed(self,salt_prefix,index)
keras.layers.rnn.legacy_DropoutWrapper._variational_recurrent_dropout_value(self,unused_index,value,noise,keep_prob)
keras.layers.rnn.legacy_DropoutWrapper.build(self,inputs_shape)
keras.layers.rnn.legacy_DropoutWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.legacy_DropoutWrapper.get_config(self)
keras.layers.rnn.legacy_DropoutWrapper.wrapped_cell(self)
keras.layers.rnn.legacy_ResidualWrapper(self,cell,residual_fn=None,**kwargs)
keras.layers.rnn.legacy_ResidualWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_ResidualWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.legacy_ResidualWrapper.get_config(self)
keras.layers.rnn.legacy_cell_wrappers.DeviceWrapper(self,cell,device,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.DeviceWrapper.__init__(self,cell,device,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.DeviceWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.DeviceWrapper.get_config(self)
keras.layers.rnn.legacy_cell_wrappers.DeviceWrapper.zero_state(self,batch_size,dtype)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper(self,cell,input_keep_prob=1.0,output_keep_prob=1.0,state_keep_prob=1.0,variational_recurrent=False,input_size=None,dtype=None,seed=None,dropout_state_filter_visitor=None,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper.__init__(self,cell,input_keep_prob=1.0,output_keep_prob=1.0,state_keep_prob=1.0,variational_recurrent=False,input_size=None,dtype=None,seed=None,dropout_state_filter_visitor=None,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper._dropout(self,values,salt_prefix,recurrent_noise,keep_prob,shallow_filtered_substructure=None)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper._gen_seed(self,salt_prefix,index)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper._variational_recurrent_dropout_value(self,unused_index,value,noise,keep_prob)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper.build(self,inputs_shape)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper.get_config(self)
keras.layers.rnn.legacy_cell_wrappers.DropoutWrapper.wrapped_cell(self)
keras.layers.rnn.legacy_cell_wrappers.ResidualWrapper(self,cell,residual_fn=None,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.ResidualWrapper.__init__(self,cell,residual_fn=None,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.ResidualWrapper._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_cell_wrappers.ResidualWrapper.from_config(cls,config,custom_objects=None)
keras.layers.rnn.legacy_cell_wrappers.ResidualWrapper.get_config(self)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1(self,cell,*args,**kwargs)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1.__init__(self,cell,*args,**kwargs)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1._call_wrapped_cell(self,inputs,state,cell_call_fn,**kwargs)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1.from_config(cls,config,custom_objects=None)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1.get_config(self)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1.output_size(self)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1.state_size(self)
keras.layers.rnn.legacy_cell_wrappers._RNNCellWrapperV1.zero_state(self,batch_size,dtype)
keras.layers.rnn.legacy_cell_wrappers._default_dropout_state_filter_visitor(substate)
keras.layers.rnn.legacy_cell_wrappers._hasattr(obj,attr_name)
keras.layers.rnn.legacy_cell_wrappers.assert_like_rnncell(cell_name,cell)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/base_conv_lstm.py----------------------------------------
A:keras.layers.rnn.base_conv_lstm.self.kernel_size->keras.utils.conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')
A:keras.layers.rnn.base_conv_lstm.self.strides->keras.utils.conv_utils.normalize_tuple(strides, self.rank, 'strides', allow_zero=True)
A:keras.layers.rnn.base_conv_lstm.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.rnn.base_conv_lstm.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.rnn.base_conv_lstm.self.dilation_rate->keras.utils.conv_utils.normalize_tuple(dilation_rate, self.rank, 'dilation_rate')
A:keras.layers.rnn.base_conv_lstm.self.activation->keras.activations.get(activation)
A:keras.layers.rnn.base_conv_lstm.self.recurrent_activation->keras.activations.get(recurrent_activation)
A:keras.layers.rnn.base_conv_lstm.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.base_conv_lstm.self.recurrent_initializer->keras.initializers.get(recurrent_initializer)
A:keras.layers.rnn.base_conv_lstm.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.base_conv_lstm.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.rnn.base_conv_lstm.self.recurrent_regularizer->keras.regularizers.get(recurrent_regularizer)
A:keras.layers.rnn.base_conv_lstm.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.rnn.base_conv_lstm.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.rnn.base_conv_lstm.self.recurrent_constraint->keras.constraints.get(recurrent_constraint)
A:keras.layers.rnn.base_conv_lstm.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.rnn.base_conv_lstm.self.dropout->min(1.0, max(0.0, dropout))
A:keras.layers.rnn.base_conv_lstm.self.recurrent_dropout->min(1.0, max(0.0, recurrent_dropout))
A:keras.layers.rnn.base_conv_lstm.self.kernel->self.add_weight(shape=self.kernel_shape, initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)
A:keras.layers.rnn.base_conv_lstm.self.recurrent_kernel->self.add_weight(shape=recurrent_kernel_shape, initializer=self.recurrent_initializer, name='recurrent_kernel', regularizer=self.recurrent_regularizer, constraint=self.recurrent_constraint)
A:keras.layers.rnn.base_conv_lstm.self.bias->self.add_weight(shape=(self.filters * 4,), name='bias', initializer=bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint)
A:keras.layers.rnn.base_conv_lstm.dp_mask->self.get_dropout_mask_for_cell(inputs, training, count=4)
A:keras.layers.rnn.base_conv_lstm.rec_dp_mask->self.get_recurrent_dropout_mask_for_cell(h_tm1, training, count=4)
A:keras.layers.rnn.base_conv_lstm.(kernel_i, kernel_f, kernel_c, kernel_o)->tensorflow.compat.v2.split(self.kernel, 4, axis=self.rank + 1)
A:keras.layers.rnn.base_conv_lstm.(recurrent_kernel_i, recurrent_kernel_f, recurrent_kernel_c, recurrent_kernel_o)->tensorflow.compat.v2.split(self.recurrent_kernel, 4, axis=self.rank + 1)
A:keras.layers.rnn.base_conv_lstm.(bias_i, bias_f, bias_c, bias_o)->tensorflow.compat.v2.split(self.bias, 4)
A:keras.layers.rnn.base_conv_lstm.x_i->self.input_conv(inputs_i, kernel_i, bias_i, padding=self.padding)
A:keras.layers.rnn.base_conv_lstm.x_f->self.input_conv(inputs_f, kernel_f, bias_f, padding=self.padding)
A:keras.layers.rnn.base_conv_lstm.x_c->self.input_conv(inputs_c, kernel_c, bias_c, padding=self.padding)
A:keras.layers.rnn.base_conv_lstm.x_o->self.input_conv(inputs_o, kernel_o, bias_o, padding=self.padding)
A:keras.layers.rnn.base_conv_lstm.h_i->self.recurrent_conv(h_tm1_i, recurrent_kernel_i)
A:keras.layers.rnn.base_conv_lstm.h_f->self.recurrent_conv(h_tm1_f, recurrent_kernel_f)
A:keras.layers.rnn.base_conv_lstm.h_c->self.recurrent_conv(h_tm1_c, recurrent_kernel_c)
A:keras.layers.rnn.base_conv_lstm.h_o->self.recurrent_conv(h_tm1_o, recurrent_kernel_o)
A:keras.layers.rnn.base_conv_lstm.i->self.recurrent_activation(x_i + h_i)
A:keras.layers.rnn.base_conv_lstm.f->self.recurrent_activation(x_f + h_f)
A:keras.layers.rnn.base_conv_lstm.o->self.recurrent_activation(x_o + h_o)
A:keras.layers.rnn.base_conv_lstm.conv_out->self._conv_func(x, w, strides=strides, padding='same', data_format=self.data_format)
A:keras.layers.rnn.base_conv_lstm.strides->keras.utils.conv_utils.normalize_tuple(1, self.rank, 'strides', allow_zero=True)
A:keras.layers.rnn.base_conv_lstm.base_config->super(ConvLSTM, self).get_config()
A:keras.layers.rnn.base_conv_lstm.cell->ConvLSTMCell(rank=rank, filters=filters, kernel_size=kernel_size, strides=strides, padding=padding, data_format=data_format, dilation_rate=dilation_rate, activation=activation, recurrent_activation=recurrent_activation, use_bias=use_bias, kernel_initializer=kernel_initializer, recurrent_initializer=recurrent_initializer, bias_initializer=bias_initializer, unit_forget_bias=unit_forget_bias, kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, kernel_constraint=kernel_constraint, recurrent_constraint=recurrent_constraint, bias_constraint=bias_constraint, dropout=dropout, recurrent_dropout=recurrent_dropout, dtype=kwargs.get('dtype'))
A:keras.layers.rnn.base_conv_lstm.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
keras.layers.rnn.base_conv_lstm.ConvLSTM(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.base_conv_lstm.ConvLSTM.__init__(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.base_conv_lstm.ConvLSTM.activation(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.bias_constraint(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.bias_initializer(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.bias_regularizer(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.base_conv_lstm.ConvLSTM.data_format(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.dilation_rate(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.dropout(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.filters(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.from_config(cls,config)
keras.layers.rnn.base_conv_lstm.ConvLSTM.get_config(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.kernel_constraint(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.kernel_initializer(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.kernel_regularizer(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.kernel_size(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.padding(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.recurrent_activation(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.recurrent_constraint(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.recurrent_dropout(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.recurrent_initializer(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.recurrent_regularizer(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.strides(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.unit_forget_bias(self)
keras.layers.rnn.base_conv_lstm.ConvLSTM.use_bias(self)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell.__init__(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell._conv_func(self)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell.build(self,input_shape)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell.call(self,inputs,states,training=None)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell.get_config(self)
keras.layers.rnn.base_conv_lstm.ConvLSTMCell.input_conv(self,x,w,b=None,padding='valid')
keras.layers.rnn.base_conv_lstm.ConvLSTMCell.recurrent_conv(self,x,w)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/conv_lstm1d.py----------------------------------------
keras.layers.rnn.ConvLSTM1D(self,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.conv_lstm1d.ConvLSTM1D(self,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.conv_lstm1d.ConvLSTM1D.__init__(self,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,dropout=0.0,recurrent_dropout=0.0,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/lstm_v1.py----------------------------------------
A:keras.layers.rnn.lstm_v1.implementation->kwargs.pop('implementation', 1)
A:keras.layers.rnn.lstm_v1.cell->LSTMCell(units, activation=activation, recurrent_activation=recurrent_activation, use_bias=use_bias, kernel_initializer=kernel_initializer, recurrent_initializer=recurrent_initializer, unit_forget_bias=unit_forget_bias, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, kernel_constraint=kernel_constraint, recurrent_constraint=recurrent_constraint, bias_constraint=bias_constraint, dropout=dropout, recurrent_dropout=recurrent_dropout, implementation=implementation, dtype=kwargs.get('dtype'), trainable=kwargs.get('trainable', True), **cell_kwargs)
A:keras.layers.rnn.lstm_v1.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.rnn.lstm_v1.base_config->super(LSTM, self).get_config()
keras.layers.rnn.LSTM(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.LSTM.activation(self)
keras.layers.rnn.LSTM.bias_constraint(self)
keras.layers.rnn.LSTM.bias_initializer(self)
keras.layers.rnn.LSTM.bias_regularizer(self)
keras.layers.rnn.LSTM.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.LSTM.dropout(self)
keras.layers.rnn.LSTM.from_config(cls,config)
keras.layers.rnn.LSTM.get_config(self)
keras.layers.rnn.LSTM.implementation(self)
keras.layers.rnn.LSTM.kernel_constraint(self)
keras.layers.rnn.LSTM.kernel_initializer(self)
keras.layers.rnn.LSTM.kernel_regularizer(self)
keras.layers.rnn.LSTM.recurrent_activation(self)
keras.layers.rnn.LSTM.recurrent_constraint(self)
keras.layers.rnn.LSTM.recurrent_dropout(self)
keras.layers.rnn.LSTM.recurrent_initializer(self)
keras.layers.rnn.LSTM.recurrent_regularizer(self)
keras.layers.rnn.LSTM.unit_forget_bias(self)
keras.layers.rnn.LSTM.units(self)
keras.layers.rnn.LSTM.use_bias(self)
keras.layers.rnn.LSTMCell(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.lstm_v1.LSTM(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.lstm_v1.LSTM.__init__(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.lstm_v1.LSTM.activation(self)
keras.layers.rnn.lstm_v1.LSTM.bias_constraint(self)
keras.layers.rnn.lstm_v1.LSTM.bias_initializer(self)
keras.layers.rnn.lstm_v1.LSTM.bias_regularizer(self)
keras.layers.rnn.lstm_v1.LSTM.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.lstm_v1.LSTM.dropout(self)
keras.layers.rnn.lstm_v1.LSTM.from_config(cls,config)
keras.layers.rnn.lstm_v1.LSTM.get_config(self)
keras.layers.rnn.lstm_v1.LSTM.implementation(self)
keras.layers.rnn.lstm_v1.LSTM.kernel_constraint(self)
keras.layers.rnn.lstm_v1.LSTM.kernel_initializer(self)
keras.layers.rnn.lstm_v1.LSTM.kernel_regularizer(self)
keras.layers.rnn.lstm_v1.LSTM.recurrent_activation(self)
keras.layers.rnn.lstm_v1.LSTM.recurrent_constraint(self)
keras.layers.rnn.lstm_v1.LSTM.recurrent_dropout(self)
keras.layers.rnn.lstm_v1.LSTM.recurrent_initializer(self)
keras.layers.rnn.lstm_v1.LSTM.recurrent_regularizer(self)
keras.layers.rnn.lstm_v1.LSTM.unit_forget_bias(self)
keras.layers.rnn.lstm_v1.LSTM.units(self)
keras.layers.rnn.lstm_v1.LSTM.use_bias(self)
keras.layers.rnn.lstm_v1.LSTMCell(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.lstm_v1.LSTMCell.__init__(self,units,activation='tanh',recurrent_activation='hard_sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',unit_forget_bias=True,kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/simple_rnn.py----------------------------------------
A:keras.layers.rnn.simple_rnn.self._enable_caching_device->kwargs.pop('enable_caching_device', False)
A:keras.layers.rnn.simple_rnn.self.activation->keras.activations.get(activation)
A:keras.layers.rnn.simple_rnn.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.simple_rnn.self.recurrent_initializer->keras.initializers.get(recurrent_initializer)
A:keras.layers.rnn.simple_rnn.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.simple_rnn.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.rnn.simple_rnn.self.recurrent_regularizer->keras.regularizers.get(recurrent_regularizer)
A:keras.layers.rnn.simple_rnn.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.rnn.simple_rnn.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.rnn.simple_rnn.self.recurrent_constraint->keras.constraints.get(recurrent_constraint)
A:keras.layers.rnn.simple_rnn.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.rnn.simple_rnn.self.dropout->min(1.0, max(0.0, dropout))
A:keras.layers.rnn.simple_rnn.self.recurrent_dropout->min(1.0, max(0.0, recurrent_dropout))
A:keras.layers.rnn.simple_rnn.default_caching_device->keras.layers.rnn.rnn_utils.caching_device(self)
A:keras.layers.rnn.simple_rnn.self.kernel->self.add_weight(shape=(input_shape[-1], self.units), name='kernel', initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.simple_rnn.self.recurrent_kernel->self.add_weight(shape=(self.units, self.units), name='recurrent_kernel', initializer=self.recurrent_initializer, regularizer=self.recurrent_regularizer, constraint=self.recurrent_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.simple_rnn.self.bias->self.add_weight(shape=(self.units,), name='bias', initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.simple_rnn.dp_mask->self.get_dropout_mask_for_cell(inputs, training)
A:keras.layers.rnn.simple_rnn.rec_dp_mask->self.get_recurrent_dropout_mask_for_cell(prev_output, training)
A:keras.layers.rnn.simple_rnn.h->keras.backend.bias_add(h, self.bias)
A:keras.layers.rnn.simple_rnn.output->self.activation(output)
A:keras.layers.rnn.simple_rnn.base_config->super(SimpleRNN, self).get_config()
A:keras.layers.rnn.simple_rnn.cell->SimpleRNNCell(units, activation=activation, use_bias=use_bias, kernel_initializer=kernel_initializer, recurrent_initializer=recurrent_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, kernel_constraint=kernel_constraint, recurrent_constraint=recurrent_constraint, bias_constraint=bias_constraint, dropout=dropout, recurrent_dropout=recurrent_dropout, dtype=kwargs.get('dtype'), trainable=kwargs.get('trainable', True), **cell_kwargs)
A:keras.layers.rnn.simple_rnn.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
keras.layers.rnn.SimpleRNN(self,units,activation='tanh',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.SimpleRNN.activation(self)
keras.layers.rnn.SimpleRNN.bias_constraint(self)
keras.layers.rnn.SimpleRNN.bias_initializer(self)
keras.layers.rnn.SimpleRNN.bias_regularizer(self)
keras.layers.rnn.SimpleRNN.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.SimpleRNN.dropout(self)
keras.layers.rnn.SimpleRNN.from_config(cls,config)
keras.layers.rnn.SimpleRNN.get_config(self)
keras.layers.rnn.SimpleRNN.kernel_constraint(self)
keras.layers.rnn.SimpleRNN.kernel_initializer(self)
keras.layers.rnn.SimpleRNN.kernel_regularizer(self)
keras.layers.rnn.SimpleRNN.recurrent_constraint(self)
keras.layers.rnn.SimpleRNN.recurrent_dropout(self)
keras.layers.rnn.SimpleRNN.recurrent_initializer(self)
keras.layers.rnn.SimpleRNN.recurrent_regularizer(self)
keras.layers.rnn.SimpleRNN.units(self)
keras.layers.rnn.SimpleRNN.use_bias(self)
keras.layers.rnn.SimpleRNNCell(self,units,activation='tanh',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.SimpleRNNCell.build(self,input_shape)
keras.layers.rnn.SimpleRNNCell.call(self,inputs,states,training=None)
keras.layers.rnn.SimpleRNNCell.get_config(self)
keras.layers.rnn.SimpleRNNCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.simple_rnn.SimpleRNN(self,units,activation='tanh',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.simple_rnn.SimpleRNN.__init__(self,units,activation='tanh',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,**kwargs)
keras.layers.rnn.simple_rnn.SimpleRNN.activation(self)
keras.layers.rnn.simple_rnn.SimpleRNN.bias_constraint(self)
keras.layers.rnn.simple_rnn.SimpleRNN.bias_initializer(self)
keras.layers.rnn.simple_rnn.SimpleRNN.bias_regularizer(self)
keras.layers.rnn.simple_rnn.SimpleRNN.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.simple_rnn.SimpleRNN.dropout(self)
keras.layers.rnn.simple_rnn.SimpleRNN.from_config(cls,config)
keras.layers.rnn.simple_rnn.SimpleRNN.get_config(self)
keras.layers.rnn.simple_rnn.SimpleRNN.kernel_constraint(self)
keras.layers.rnn.simple_rnn.SimpleRNN.kernel_initializer(self)
keras.layers.rnn.simple_rnn.SimpleRNN.kernel_regularizer(self)
keras.layers.rnn.simple_rnn.SimpleRNN.recurrent_constraint(self)
keras.layers.rnn.simple_rnn.SimpleRNN.recurrent_dropout(self)
keras.layers.rnn.simple_rnn.SimpleRNN.recurrent_initializer(self)
keras.layers.rnn.simple_rnn.SimpleRNN.recurrent_regularizer(self)
keras.layers.rnn.simple_rnn.SimpleRNN.units(self)
keras.layers.rnn.simple_rnn.SimpleRNN.use_bias(self)
keras.layers.rnn.simple_rnn.SimpleRNNCell(self,units,activation='tanh',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.simple_rnn.SimpleRNNCell.__init__(self,units,activation='tanh',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,**kwargs)
keras.layers.rnn.simple_rnn.SimpleRNNCell.build(self,input_shape)
keras.layers.rnn.simple_rnn.SimpleRNNCell.call(self,inputs,states,training=None)
keras.layers.rnn.simple_rnn.SimpleRNNCell.get_config(self)
keras.layers.rnn.simple_rnn.SimpleRNNCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/base_rnn.py----------------------------------------
A:keras.layers.rnn.base_rnn.cell->deserialize_layer(config.pop('cell'), custom_objects=custom_objects)
A:keras.layers.rnn.base_rnn.self.zero_output_for_mask->kwargs.pop('zero_output_for_mask', False)
A:keras.layers.rnn.base_rnn.state->tensorflow.compat.v2.nest.map_structure(lambda _: None, self.cell.state_size)
A:keras.layers.rnn.base_rnn.input_shape->keras.backend.int_shape(inputs)
A:keras.layers.rnn.base_rnn.output_dim->tensorflow.compat.v2.TensorShape(flat_output_size).as_list()
A:keras.layers.rnn.base_rnn.output_shape->_get_output_shape(state_size[0])
A:keras.layers.rnn.base_rnn.state_shape->tensorflow.compat.v2.nest.map_structure(_get_state_shape, state_size)
A:keras.layers.rnn.base_rnn.input_spec_shape->list(shape)
A:keras.layers.rnn.base_rnn.shape->tuple(shape.as_list())
A:keras.layers.rnn.base_rnn.state_spec_shape->tensorflow.compat.v2.TensorShape(shape).as_list()
A:keras.layers.rnn.base_rnn.self.input_spec[0]->tensorflow.compat.v2.nest.map_structure(get_input_spec, input_shape)
A:keras.layers.rnn.base_rnn.step_input_shape->tensorflow.compat.v2.nest.map_structure(get_step_input_shape, input_shape)
A:keras.layers.rnn.base_rnn.self.input_spec->keras.utils.generic_utils.to_list(tf.nest.map_structure(get_input_spec, input_shape))
A:keras.layers.rnn.base_rnn.state_size->list(self.cell.state_size)
A:keras.layers.rnn.base_rnn.self.state_spec->tensorflow.compat.v2.nest.map_structure(lambda s: InputSpec(shape=backend.int_shape(s)), initial_state)
A:keras.layers.rnn.base_rnn.validation_error->ValueError('An `initial_state` was passed that is not compatible with `cell.state_size`. Received `state_spec`={}; however `cell.state_size` is {}'.format(init_state_specs, cell_state_sizes))
A:keras.layers.rnn.base_rnn.flat_cell_state_sizes->tensorflow.compat.v2.nest.flatten(cell_state_sizes)
A:keras.layers.rnn.base_rnn.flat_state_specs->tensorflow.compat.v2.nest.flatten(init_state_specs)
A:keras.layers.rnn.base_rnn.get_initial_state_fn->getattr(self.cell, 'get_initial_state', None)
A:keras.layers.rnn.base_rnn.init_state->keras.layers.rnn.rnn_utils.generate_zero_filled_state(batch_size, self.cell.state_size, dtype)
A:keras.layers.rnn.base_rnn.(inputs, initial_state, constants)->self._process_inputs(inputs, initial_state, constants)
A:keras.layers.rnn.base_rnn.self._num_constants->len(constants)
A:keras.layers.rnn.base_rnn.flat_additional_inputs->tensorflow.compat.v2.nest.flatten(additional_inputs)
A:keras.layers.rnn.base_rnn.output->keras.backend.maybe_convert_to_ragged(is_ragged_input, outputs, row_lengths, go_backwards=self.go_backwards)
A:keras.layers.rnn.base_rnn.(inputs, row_lengths)->keras.backend.convert_inputs_if_ragged(inputs)
A:keras.layers.rnn.base_rnn.(output, new_states)->cell_call_fn(inputs, states, **kwargs)
A:keras.layers.rnn.base_rnn.(last_output, outputs, states)->keras.backend.rnn(step, inputs, initial_state, constants=constants, go_backwards=self.go_backwards, mask=mask, unroll=self.unroll, input_length=row_lengths if row_lengths is not None else timesteps, time_major=self.time_major, zero_output_for_mask=self.zero_output_for_mask, return_all_outputs=self.return_sequences)
A:keras.layers.rnn.base_rnn.states->list(states)
A:keras.layers.rnn.base_rnn.non_zero_count->tensorflow.compat.v2.add_n([tf.math.count_nonzero(s) for s in tf.nest.flatten(self.states)])
A:keras.layers.rnn.base_rnn.initial_state->self.get_initial_state(inputs)
A:keras.layers.rnn.base_rnn.flat_init_state_values->tensorflow.compat.v2.nest.flatten(rnn_utils.generate_zero_filled_state(batch_size, self.cell.state_size, self.variable_dtype or backend.floatx()))
A:keras.layers.rnn.base_rnn.flat_states_variables->tensorflow.compat.v2.nest.map_structure(backend.variable, flat_init_state_values)
A:keras.layers.rnn.base_rnn.self.states->tensorflow.compat.v2.nest.pack_sequence_as(self.cell.state_size, flat_states_variables)
A:keras.layers.rnn.base_rnn.flat_states->tensorflow.compat.v2.nest.flatten(self.states)
A:keras.layers.rnn.base_rnn.flat_input_states->tensorflow.compat.v2.nest.flatten(states)
A:keras.layers.rnn.base_rnn.config['cell']->keras.utils.generic_utils.serialize_keras_object(self.cell)
A:keras.layers.rnn.base_rnn.base_config->super(RNN, self).get_config()
A:keras.layers.rnn.base_rnn.num_constants->config.pop('num_constants', 0)
A:keras.layers.rnn.base_rnn.layer->cls(cell, **config)
keras.layers.rnn.RNN(self,cell,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,time_major=False,**kwargs)
keras.layers.rnn.RNN._maybe_reset_cell_dropout_mask(self,cell)
keras.layers.rnn.RNN._process_inputs(self,inputs,initial_state,constants)
keras.layers.rnn.RNN._trackable_saved_model_saver(self)
keras.layers.rnn.RNN._use_input_spec_as_call_signature(self)
keras.layers.rnn.RNN._validate_args_if_ragged(self,is_ragged_input,mask)
keras.layers.rnn.RNN._validate_state_spec(cell_state_sizes,init_state_specs)
keras.layers.rnn.RNN.build(self,input_shape)
keras.layers.rnn.RNN.call(self,inputs,mask=None,training=None,initial_state=None,constants=None)
keras.layers.rnn.RNN.compute_mask(self,inputs,mask)
keras.layers.rnn.RNN.compute_output_shape(self,input_shape)
keras.layers.rnn.RNN.from_config(cls,config,custom_objects=None)
keras.layers.rnn.RNN.get_config(self)
keras.layers.rnn.RNN.get_initial_state(self,inputs)
keras.layers.rnn.RNN.reset_states(self,states=None)
keras.layers.rnn.RNN.states(self)
keras.layers.rnn.RNN.states(self,states)
keras.layers.rnn.base_rnn.RNN(self,cell,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,time_major=False,**kwargs)
keras.layers.rnn.base_rnn.RNN.__init__(self,cell,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,time_major=False,**kwargs)
keras.layers.rnn.base_rnn.RNN._maybe_reset_cell_dropout_mask(self,cell)
keras.layers.rnn.base_rnn.RNN._process_inputs(self,inputs,initial_state,constants)
keras.layers.rnn.base_rnn.RNN._trackable_saved_model_saver(self)
keras.layers.rnn.base_rnn.RNN._use_input_spec_as_call_signature(self)
keras.layers.rnn.base_rnn.RNN._validate_args_if_ragged(self,is_ragged_input,mask)
keras.layers.rnn.base_rnn.RNN._validate_state_spec(cell_state_sizes,init_state_specs)
keras.layers.rnn.base_rnn.RNN.build(self,input_shape)
keras.layers.rnn.base_rnn.RNN.call(self,inputs,mask=None,training=None,initial_state=None,constants=None)
keras.layers.rnn.base_rnn.RNN.compute_mask(self,inputs,mask)
keras.layers.rnn.base_rnn.RNN.compute_output_shape(self,input_shape)
keras.layers.rnn.base_rnn.RNN.from_config(cls,config,custom_objects=None)
keras.layers.rnn.base_rnn.RNN.get_config(self)
keras.layers.rnn.base_rnn.RNN.get_initial_state(self,inputs)
keras.layers.rnn.base_rnn.RNN.reset_states(self,states=None)
keras.layers.rnn.base_rnn.RNN.states(self)
keras.layers.rnn.base_rnn.RNN.states(self,states)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/bidirectional.py----------------------------------------
A:keras.layers.rnn.bidirectional.self.forward_layer->self._recreate_layer_from_config(layer)
A:keras.layers.rnn.bidirectional.self.backward_layer->self._recreate_layer_from_config(layer, go_backwards=True)
A:keras.layers.rnn.bidirectional.self._backward_layer_config->keras.utils.generic_utils.serialize_keras_object(backward_layer)
A:keras.layers.rnn.bidirectional.nw->len(weights)
A:keras.layers.rnn.bidirectional.forward_value->getattr(self.forward_layer, a)
A:keras.layers.rnn.bidirectional.backward_value->getattr(self.backward_layer, a)
A:keras.layers.rnn.bidirectional.config->copy.deepcopy(config)
A:keras.layers.rnn.bidirectional.cell->getattr(layer, 'cell', None)
A:keras.layers.rnn.bidirectional.stacked_cells->getattr(cell, 'cells', [])
A:keras.layers.rnn.bidirectional.output_shape->tensorflow.compat.v2.TensorShape(output_shape)
A:keras.layers.rnn.bidirectional.state_shape->keras.utils.tf_utils.convert_shapes(output_shape[1:], to_tuples=False)
A:keras.layers.rnn.bidirectional.(inputs, initial_state, constants)->keras.layers.rnn.rnn_utils.standardize_args(inputs, initial_state, constants, self._num_constants)
A:keras.layers.rnn.bidirectional.num_states->len(initial_state)
A:keras.layers.rnn.bidirectional.state_specs->tensorflow.compat.v2.nest.map_structure(lambda state: InputSpec(shape=backend.int_shape(state)), initial_state)
A:keras.layers.rnn.bidirectional.self._num_constants->len(constants)
A:keras.layers.rnn.bidirectional.is_keras_tensor->keras.backend.is_keras_tensor(tf.nest.flatten(additional_inputs)[0])
A:keras.layers.rnn.bidirectional.output->keras.backend.concatenate([y, y_rev])
A:keras.layers.rnn.bidirectional.y->self.forward_layer(inputs, **kwargs)
A:keras.layers.rnn.bidirectional.y_rev->keras.backend.reverse(y_rev, time_dim)
A:keras.layers.rnn.bidirectional.base_config->super(Bidirectional, self).get_config()
A:keras.layers.rnn.bidirectional.num_constants->copy.deepcopy(config).pop('num_constants', 0)
A:keras.layers.rnn.bidirectional.config['layer']->deserialize_layer(config['layer'], custom_objects=custom_objects)
A:keras.layers.rnn.bidirectional.backward_layer_config->copy.deepcopy(config).pop('backward_layer', None)
A:keras.layers.rnn.bidirectional.backward_layer->deserialize_layer(backward_layer_config, custom_objects=custom_objects)
A:keras.layers.rnn.bidirectional.layer->cls(**config)
keras.layers.rnn.Bidirectional(self,layer,merge_mode='concat',weights=None,backward_layer=None,**kwargs)
keras.layers.rnn.Bidirectional._recreate_layer_from_config(self,layer,go_backwards=False)
keras.layers.rnn.Bidirectional._use_input_spec_as_call_signature(self)
keras.layers.rnn.Bidirectional._verify_layer_config(self)
keras.layers.rnn.Bidirectional.build(self,input_shape)
keras.layers.rnn.Bidirectional.call(self,inputs,training=None,mask=None,initial_state=None,constants=None)
keras.layers.rnn.Bidirectional.compute_mask(self,inputs,mask)
keras.layers.rnn.Bidirectional.compute_output_shape(self,input_shape)
keras.layers.rnn.Bidirectional.constraints(self)
keras.layers.rnn.Bidirectional.from_config(cls,config,custom_objects=None)
keras.layers.rnn.Bidirectional.get_config(self)
keras.layers.rnn.Bidirectional.reset_states(self)
keras.layers.rnn.bidirectional.Bidirectional(self,layer,merge_mode='concat',weights=None,backward_layer=None,**kwargs)
keras.layers.rnn.bidirectional.Bidirectional.__init__(self,layer,merge_mode='concat',weights=None,backward_layer=None,**kwargs)
keras.layers.rnn.bidirectional.Bidirectional._recreate_layer_from_config(self,layer,go_backwards=False)
keras.layers.rnn.bidirectional.Bidirectional._use_input_spec_as_call_signature(self)
keras.layers.rnn.bidirectional.Bidirectional._verify_layer_config(self)
keras.layers.rnn.bidirectional.Bidirectional.build(self,input_shape)
keras.layers.rnn.bidirectional.Bidirectional.call(self,inputs,training=None,mask=None,initial_state=None,constants=None)
keras.layers.rnn.bidirectional.Bidirectional.compute_mask(self,inputs,mask)
keras.layers.rnn.bidirectional.Bidirectional.compute_output_shape(self,input_shape)
keras.layers.rnn.bidirectional.Bidirectional.constraints(self)
keras.layers.rnn.bidirectional.Bidirectional.from_config(cls,config,custom_objects=None)
keras.layers.rnn.bidirectional.Bidirectional.get_config(self)
keras.layers.rnn.bidirectional.Bidirectional.reset_states(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/gru.py----------------------------------------
A:keras.layers.rnn.gru.self._enable_caching_device->kwargs.pop('enable_caching_device', False)
A:keras.layers.rnn.gru.self.activation->keras.activations.get(activation)
A:keras.layers.rnn.gru.self.recurrent_activation->keras.activations.get(recurrent_activation)
A:keras.layers.rnn.gru.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.gru.self.recurrent_initializer->keras.initializers.get(recurrent_initializer)
A:keras.layers.rnn.gru.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.gru.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.rnn.gru.self.recurrent_regularizer->keras.regularizers.get(recurrent_regularizer)
A:keras.layers.rnn.gru.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.rnn.gru.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.rnn.gru.self.recurrent_constraint->keras.constraints.get(recurrent_constraint)
A:keras.layers.rnn.gru.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.rnn.gru.self.dropout->min(1.0, max(0.0, dropout))
A:keras.layers.rnn.gru.self.recurrent_dropout->min(1.0, max(0.0, recurrent_dropout))
A:keras.layers.rnn.gru.implementation->kwargs.pop('implementation', 2)
A:keras.layers.rnn.gru.default_caching_device->keras.layers.rnn.rnn_utils.caching_device(self)
A:keras.layers.rnn.gru.self.kernel->self.add_weight(shape=(input_dim, self.units * 3), name='kernel', initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.gru.self.recurrent_kernel->self.add_weight(shape=(self.units, self.units * 3), name='recurrent_kernel', initializer=self.recurrent_initializer, regularizer=self.recurrent_regularizer, constraint=self.recurrent_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.gru.self.bias->self.add_weight(shape=bias_shape, name='bias', initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, caching_device=default_caching_device)
A:keras.layers.rnn.gru.dp_mask->self.get_dropout_mask_for_cell(inputs, training, count=3)
A:keras.layers.rnn.gru.rec_dp_mask->self.get_recurrent_dropout_mask_for_cell(h_tm1, training, count=3)
A:keras.layers.rnn.gru.(input_bias, recurrent_bias)->tensorflow.compat.v2.unstack(bias)
A:keras.layers.rnn.gru.x_z->keras.backend.bias_add(x_z, input_bias[:self.units])
A:keras.layers.rnn.gru.x_r->keras.backend.bias_add(x_r, input_bias[self.units:self.units * 2])
A:keras.layers.rnn.gru.x_h->keras.backend.bias_add(x_h, input_bias[self.units * 2:])
A:keras.layers.rnn.gru.recurrent_z->keras.backend.bias_add(recurrent_z, recurrent_bias[:self.units])
A:keras.layers.rnn.gru.recurrent_r->keras.backend.bias_add(recurrent_r, recurrent_bias[self.units:self.units * 2])
A:keras.layers.rnn.gru.z->tensorflow.compat.v2.sigmoid(x_z + recurrent_z)
A:keras.layers.rnn.gru.r->tensorflow.compat.v2.sigmoid(x_r + recurrent_r)
A:keras.layers.rnn.gru.recurrent_h->keras.backend.dot(r * h_tm1, self.recurrent_kernel[:, 2 * self.units:])
A:keras.layers.rnn.gru.hh->tensorflow.compat.v2.tanh(x_h + r * recurrent_h)
A:keras.layers.rnn.gru.matrix_x->keras.backend.bias_add(matrix_x, input_bias)
A:keras.layers.rnn.gru.(x_z, x_r, x_h)->tensorflow.compat.v2.split(matrix_x, 3, axis=1)
A:keras.layers.rnn.gru.matrix_inner->keras.backend.bias_add(matrix_inner, recurrent_bias)
A:keras.layers.rnn.gru.(recurrent_z, recurrent_r, recurrent_h)->tensorflow.compat.v2.split(matrix_inner, 3, axis=1)
A:keras.layers.rnn.gru.base_config->super(GRU, self).get_config()
A:keras.layers.rnn.gru.self._return_runtime->kwargs.pop('return_runtime', False)
A:keras.layers.rnn.gru.cell->GRUCell(units, activation=activation, recurrent_activation=recurrent_activation, use_bias=use_bias, kernel_initializer=kernel_initializer, recurrent_initializer=recurrent_initializer, bias_initializer=bias_initializer, kernel_regularizer=kernel_regularizer, recurrent_regularizer=recurrent_regularizer, bias_regularizer=bias_regularizer, kernel_constraint=kernel_constraint, recurrent_constraint=recurrent_constraint, bias_constraint=bias_constraint, dropout=dropout, recurrent_dropout=recurrent_dropout, implementation=implementation, reset_after=reset_after, dtype=kwargs.get('dtype'), trainable=kwargs.get('trainable', True), **cell_kwargs)
A:keras.layers.rnn.gru.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.rnn.gru.self._defun_wrapper->keras.layers.rnn.gru_lstm_utils.DefunWrapper(time_major, go_backwards, 'gru')
A:keras.layers.rnn.gru.(inputs, row_lengths)->keras.backend.convert_inputs_if_ragged(inputs)
A:keras.layers.rnn.gru.(inputs, initial_state, _)->self._process_inputs(inputs, initial_state, None)
A:keras.layers.rnn.gru.input_shape->keras.backend.int_shape(inputs)
A:keras.layers.rnn.gru.(last_output, outputs, states)->keras.backend.rnn(step, inputs, initial_state, constants=None, go_backwards=self.go_backwards, mask=mask, unroll=self.unroll, input_length=row_lengths if row_lengths is not None else timesteps, time_major=self.time_major, zero_output_for_mask=self.zero_output_for_mask, return_all_outputs=self.return_sequences)
A:keras.layers.rnn.gru.runtime->keras.layers.rnn.gru_lstm_utils.runtime(gru_lstm_utils.RUNTIME_UNKNOWN)
A:keras.layers.rnn.gru.(last_output, outputs, runtime, states)->self._defun_gru_call(inputs, initial_state, training, mask, row_lengths)
A:keras.layers.rnn.gru.output->keras.backend.maybe_convert_to_ragged(is_ragged_input, outputs, row_lengths, go_backwards=self.go_backwards)
A:keras.layers.rnn.gru.dropout_mask->self.get_dropout_mask_for_cell(inputs, training, count=3)
A:keras.layers.rnn.gru.(last_output, outputs, new_h, runtime)->defun_standard_gru(**params)
A:keras.layers.rnn.gru.normal_gru_kwargs->gpu_gru_kwargs.copy()
A:keras.layers.rnn.gru.device_type->keras.layers.rnn.gru_lstm_utils.get_context_device_type()
A:keras.layers.rnn.gru.(last_output, outputs, new_states)->keras.backend.rnn(step, inputs, [init_h], constants=None, unroll=False, time_major=time_major, mask=mask, go_backwards=go_backwards, input_length=sequence_lengths if sequence_lengths is not None else timesteps, zero_output_for_mask=zero_output_for_mask, return_all_outputs=return_sequences)
A:keras.layers.rnn.gru.sequence_lengths->keras.layers.rnn.gru_lstm_utils.calculate_sequence_by_mask(mask, time_major)
A:keras.layers.rnn.gru.inputs->tensorflow.compat.v2.reverse(inputs, axis=[0])
A:keras.layers.rnn.gru.init_h->tensorflow.compat.v2.expand_dims(init_h, axis=seq_axis)
A:keras.layers.rnn.gru.weights->tensorflow.compat.v2.split(kernel, 3, axis=1)
A:keras.layers.rnn.gru.bias->tensorflow.compat.v2.split(backend.flatten(bias), 6)
A:keras.layers.rnn.gru.params->keras.layers.rnn.gru_lstm_utils.canonical_to_params(weights=weights, biases=bias, shape=tf.constant([-1]), transpose_weights=True)
A:keras.layers.rnn.gru.(outputs, h, _, _, _)->tensorflow.compat.v2.raw_ops.CudnnRNNV3(input=inputs, input_h=init_h, input_c=0, params=params, is_training=True, rnn_mode='gru', sequence_lengths=sequence_lengths, time_major=time_major)
A:keras.layers.rnn.gru.outputs->tensorflow.compat.v2.expand_dims(last_output, axis=0 if time_major else 1)
A:keras.layers.rnn.gru.(outputs, h, _, _)->tensorflow.compat.v2.raw_ops.CudnnRNN(input=inputs, input_h=init_h, input_c=0, params=params, is_training=True, rnn_mode='gru')
A:keras.layers.rnn.gru.h->tensorflow.compat.v2.squeeze(h, axis=seq_axis)
A:keras.layers.rnn.gru.defun_standard_gru->keras.layers.rnn.gru_lstm_utils.generate_defun_backend(api_name, gru_lstm_utils.CPU_DEVICE_NAME, standard_gru, supportive_attribute)
A:keras.layers.rnn.gru.defun_gpu_gru->keras.layers.rnn.gru_lstm_utils.generate_defun_backend(api_name, gru_lstm_utils.GPU_DEVICE_NAME, gpu_gru_with_fallback, supportive_attribute)
keras.layers.rnn.GRUCellV2(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,reset_after=True,**kwargs)
keras.layers.rnn.GRUCellV2.build(self,input_shape)
keras.layers.rnn.GRUCellV2.call(self,inputs,states,training=None)
keras.layers.rnn.GRUCellV2.get_config(self)
keras.layers.rnn.GRUCellV2.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.GRUV2(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,time_major=False,reset_after=True,**kwargs)
keras.layers.rnn.GRUV2._defun_gru_call(self,inputs,initial_state,training,mask,sequence_lengths)
keras.layers.rnn.GRUV2.activation(self)
keras.layers.rnn.GRUV2.bias_constraint(self)
keras.layers.rnn.GRUV2.bias_initializer(self)
keras.layers.rnn.GRUV2.bias_regularizer(self)
keras.layers.rnn.GRUV2.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.GRUV2.dropout(self)
keras.layers.rnn.GRUV2.from_config(cls,config)
keras.layers.rnn.GRUV2.get_config(self)
keras.layers.rnn.GRUV2.implementation(self)
keras.layers.rnn.GRUV2.kernel_constraint(self)
keras.layers.rnn.GRUV2.kernel_initializer(self)
keras.layers.rnn.GRUV2.kernel_regularizer(self)
keras.layers.rnn.GRUV2.recurrent_activation(self)
keras.layers.rnn.GRUV2.recurrent_constraint(self)
keras.layers.rnn.GRUV2.recurrent_dropout(self)
keras.layers.rnn.GRUV2.recurrent_initializer(self)
keras.layers.rnn.GRUV2.recurrent_regularizer(self)
keras.layers.rnn.GRUV2.reset_after(self)
keras.layers.rnn.GRUV2.units(self)
keras.layers.rnn.GRUV2.use_bias(self)
keras.layers.rnn.gru.GRU(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,time_major=False,reset_after=True,**kwargs)
keras.layers.rnn.gru.GRU.__init__(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,return_sequences=False,return_state=False,go_backwards=False,stateful=False,unroll=False,time_major=False,reset_after=True,**kwargs)
keras.layers.rnn.gru.GRU._defun_gru_call(self,inputs,initial_state,training,mask,sequence_lengths)
keras.layers.rnn.gru.GRU.activation(self)
keras.layers.rnn.gru.GRU.bias_constraint(self)
keras.layers.rnn.gru.GRU.bias_initializer(self)
keras.layers.rnn.gru.GRU.bias_regularizer(self)
keras.layers.rnn.gru.GRU.call(self,inputs,mask=None,training=None,initial_state=None)
keras.layers.rnn.gru.GRU.dropout(self)
keras.layers.rnn.gru.GRU.from_config(cls,config)
keras.layers.rnn.gru.GRU.get_config(self)
keras.layers.rnn.gru.GRU.implementation(self)
keras.layers.rnn.gru.GRU.kernel_constraint(self)
keras.layers.rnn.gru.GRU.kernel_initializer(self)
keras.layers.rnn.gru.GRU.kernel_regularizer(self)
keras.layers.rnn.gru.GRU.recurrent_activation(self)
keras.layers.rnn.gru.GRU.recurrent_constraint(self)
keras.layers.rnn.gru.GRU.recurrent_dropout(self)
keras.layers.rnn.gru.GRU.recurrent_initializer(self)
keras.layers.rnn.gru.GRU.recurrent_regularizer(self)
keras.layers.rnn.gru.GRU.reset_after(self)
keras.layers.rnn.gru.GRU.units(self)
keras.layers.rnn.gru.GRU.use_bias(self)
keras.layers.rnn.gru.GRUCell(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,reset_after=True,**kwargs)
keras.layers.rnn.gru.GRUCell.__init__(self,units,activation='tanh',recurrent_activation='sigmoid',use_bias=True,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,dropout=0.0,recurrent_dropout=0.0,reset_after=True,**kwargs)
keras.layers.rnn.gru.GRUCell.build(self,input_shape)
keras.layers.rnn.gru.GRUCell.call(self,inputs,states,training=None)
keras.layers.rnn.gru.GRUCell.get_config(self)
keras.layers.rnn.gru.GRUCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.gru.gpu_gru(inputs,init_h,kernel,recurrent_kernel,bias,mask,time_major,go_backwards,sequence_lengths,return_sequences)
keras.layers.rnn.gru.gru_with_backend_selection(inputs,init_h,kernel,recurrent_kernel,bias,mask,time_major,go_backwards,sequence_lengths,zero_output_for_mask,return_sequences)
keras.layers.rnn.gru.standard_gru(inputs,init_h,kernel,recurrent_kernel,bias,mask,time_major,go_backwards,sequence_lengths,zero_output_for_mask,return_sequences)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/rnn_utils.py----------------------------------------
A:keras.layers.rnn.rnn_utils.inputs->tuple(inputs)
A:keras.layers.rnn.rnn_utils.initial_state->to_list_or_none(initial_state)
A:keras.layers.rnn.rnn_utils.constants->to_list_or_none(constants)
A:keras.layers.rnn.rnn_utils.flat_dims->tensorflow.compat.v2.TensorShape(unnested_state_size).as_list()
A:keras.layers.rnn.rnn_utils.default_enable_caching_device->tensorflow.compat.v2.compat.v1.executing_eagerly_outside_functions()
keras.layers.rnn.rnn_utils.caching_device(rnn_cell)
keras.layers.rnn.rnn_utils.config_for_enable_caching_device(rnn_cell)
keras.layers.rnn.rnn_utils.generate_zero_filled_state(batch_size_tensor,state_size,dtype)
keras.layers.rnn.rnn_utils.generate_zero_filled_state_for_cell(cell,inputs,batch_size,dtype)
keras.layers.rnn.rnn_utils.is_multiple_state(state_size)
keras.layers.rnn.rnn_utils.standardize_args(inputs,initial_state,constants,num_constants)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/gru_lstm_utils.py----------------------------------------
A:keras.layers.rnn.gru_lstm_utils.self.defun_layer->tensorflow.compat.v2.__internal__.function.defun_with_attributes(layer_func, attributes=supportive_attributes, autograph=False)
A:keras.layers.rnn.gru_lstm_utils.new_wrapper->type(self)(self.time_major, self.go_backwards, self.layer_name)
A:keras.layers.rnn.gru_lstm_utils.count_of_true->tensorflow.compat.v2.reduce_sum(tf.cast(mask, tf.int32), axis=1)
A:keras.layers.rnn.gru_lstm_utils.right_padded_mask->tensorflow.compat.v2.sequence_mask(count_of_true, maxlen=max_seq_length)
A:keras.layers.rnn.gru_lstm_utils.mask->tensorflow.compat.v2.transpose(mask)
A:keras.layers.rnn.gru_lstm_utils.current_device->get_device_name()
A:keras.layers.rnn.gru_lstm_utils.concrete_func->func.get_concrete_function(*args, **kwargs)
keras.layers.rnn.gru_lstm_utils.DefunWrapper(self,time_major,go_backwards,layer_name)
keras.layers.rnn.gru_lstm_utils.DefunWrapper.__deepcopy__(self,memo)
keras.layers.rnn.gru_lstm_utils.DefunWrapper.__init__(self,time_major,go_backwards,layer_name)
keras.layers.rnn.gru_lstm_utils.calculate_sequence_by_mask(mask,time_major)
keras.layers.rnn.gru_lstm_utils.canonical_to_params(weights,biases,shape,transpose_weights=False)
keras.layers.rnn.gru_lstm_utils.function_register(func,*args,**kwargs)
keras.layers.rnn.gru_lstm_utils.generate_defun_backend(unique_api_name,preferred_device,func,supportive_attributes)
keras.layers.rnn.gru_lstm_utils.get_context_device_type()
keras.layers.rnn.gru_lstm_utils.has_fully_masked_sequence(mask)
keras.layers.rnn.gru_lstm_utils.is_cudnn_supported_inputs(mask,time_major)
keras.layers.rnn.gru_lstm_utils.is_sequence_right_padded(mask)
keras.layers.rnn.gru_lstm_utils.read_variable_value(v)
keras.layers.rnn.gru_lstm_utils.runtime(runtime_name)
keras.layers.rnn.gru_lstm_utils.use_new_gru_lstm_impl()


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/cudnn_gru.py----------------------------------------
A:keras.layers.rnn.cudnn_gru.cell_spec->collections.namedtuple('cell', 'state_size')
A:keras.layers.rnn.cudnn_gru.self._cell->cell_spec(state_size=self.units)
A:keras.layers.rnn.cudnn_gru.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.cudnn_gru.self.recurrent_initializer->keras.initializers.get(recurrent_initializer)
A:keras.layers.rnn.cudnn_gru.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.cudnn_gru.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.rnn.cudnn_gru.self.recurrent_regularizer->keras.regularizers.get(recurrent_regularizer)
A:keras.layers.rnn.cudnn_gru.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.rnn.cudnn_gru.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.rnn.cudnn_gru.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.rnn.cudnn_gru.self.recurrent_constraint->keras.constraints.get(recurrent_constraint)
A:keras.layers.rnn.cudnn_gru.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.rnn.cudnn_gru.input_dim->int(input_shape[-1])
A:keras.layers.rnn.cudnn_gru.self.kernel->self.add_weight(shape=(input_dim, self.units * 3), name='kernel', initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)
A:keras.layers.rnn.cudnn_gru.self.recurrent_kernel->self.add_weight(shape=(self.units, self.units * 3), name='recurrent_kernel', initializer=self.recurrent_initializer, regularizer=self.recurrent_regularizer, constraint=self.recurrent_constraint)
A:keras.layers.rnn.cudnn_gru.self.bias->self.add_weight(shape=(self.units * 6,), name='bias', initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint)
A:keras.layers.rnn.cudnn_gru.inputs->tensorflow.compat.v2.transpose(inputs, perm=(1, 0, 2))
A:keras.layers.rnn.cudnn_gru.input_h->tensorflow.compat.v2.expand_dims(input_h, axis=0)
A:keras.layers.rnn.cudnn_gru.params->keras.layers.rnn.gru_lstm_utils.canonical_to_params(weights=[self.kernel[:, self.units:self.units * 2], self.kernel[:, :self.units], self.kernel[:, self.units * 2:], self.recurrent_kernel[:, self.units:self.units * 2], self.recurrent_kernel[:, :self.units], self.recurrent_kernel[:, self.units * 2:]], biases=[self.bias[self.units:self.units * 2], self.bias[:self.units], self.bias[self.units * 2:self.units * 3], self.bias[self.units * 4:self.units * 5], self.bias[self.units * 3:self.units * 4], self.bias[self.units * 5:]], shape=self._vector_shape)
A:keras.layers.rnn.cudnn_gru.(outputs, h, _, _, _)->tensorflow.compat.v2.raw_ops.CudnnRNNV2(**args)
A:keras.layers.rnn.cudnn_gru.output->tensorflow.compat.v2.transpose(outputs, perm=(1, 0, 2))
A:keras.layers.rnn.cudnn_gru.base_config->super(CuDNNGRU, self).get_config()
keras.layers.rnn.CuDNNGRU(self,units,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,**kwargs)
keras.layers.rnn.CuDNNGRU._process_batch(self,inputs,initial_state)
keras.layers.rnn.CuDNNGRU.build(self,input_shape)
keras.layers.rnn.CuDNNGRU.cell(self)
keras.layers.rnn.CuDNNGRU.get_config(self)
keras.layers.rnn.cudnn_gru.CuDNNGRU(self,units,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,**kwargs)
keras.layers.rnn.cudnn_gru.CuDNNGRU.__init__(self,units,kernel_initializer='glorot_uniform',recurrent_initializer='orthogonal',bias_initializer='zeros',kernel_regularizer=None,recurrent_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,recurrent_constraint=None,bias_constraint=None,return_sequences=False,return_state=False,go_backwards=False,stateful=False,**kwargs)
keras.layers.rnn.cudnn_gru.CuDNNGRU._process_batch(self,inputs,initial_state)
keras.layers.rnn.cudnn_gru.CuDNNGRU.build(self,input_shape)
keras.layers.rnn.cudnn_gru.CuDNNGRU.cell(self)
keras.layers.rnn.cudnn_gru.CuDNNGRU.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/rnn/legacy_cells.py----------------------------------------
A:keras.layers.rnn.legacy_cells.p_static->tensorflow.compat.v2.get_static_value(prefix)
A:keras.layers.rnn.legacy_cells.p->tensorflow.compat.v2.TensorShape(prefix)
A:keras.layers.rnn.legacy_cells.s_static->tensorflow.compat.v2.get_static_value(suffix)
A:keras.layers.rnn.legacy_cells.s->tensorflow.compat.v2.TensorShape(suffix)
A:keras.layers.rnn.legacy_cells.shape->tensorflow.compat.v2.concat((p, s), 0)
A:keras.layers.rnn.legacy_cells.c->tensorflow.compat.v2.clip_by_value(c, -self._cell_clip, self._cell_clip)
A:keras.layers.rnn.legacy_cells.size->tensorflow.compat.v2.zeros(c, dtype=dtype)
A:keras.layers.rnn.legacy_cells.c_static->_concat(batch_size, s, static=True)
A:keras.layers.rnn.legacy_cells.scope->tensorflow.compat.v2.compat.v1.variable_scope(tf.compat.v1.get_variable_scope(), custom_getter=self._rnn_get_variable)
A:keras.layers.rnn.legacy_cells.variable->getter(*args, **kwargs)
A:keras.layers.rnn.legacy_cells.inputs->tensorflow.compat.v2.convert_to_tensor(inputs, name='inputs')
A:keras.layers.rnn.legacy_cells.static_batch_size->tensorflow.compat.v2.get_static_value(batch_size, partial=True)
A:keras.layers.rnn.legacy_cells.is_eager->tensorflow.compat.v2.executing_eagerly()
A:keras.layers.rnn.legacy_cells.(last_state_size, last_batch_size, last_dtype, last_output)->getattr(self, '_last_zero_state')
A:keras.layers.rnn.legacy_cells.output->self._activation(gate_inputs)
A:keras.layers.rnn.legacy_cells.self.input_spec->keras.engine.input_spec.InputSpec(ndim=2)
A:keras.layers.rnn.legacy_cells.self._activation->keras.activations.get(activation)
A:keras.layers.rnn.legacy_cells.self._kernel->self.add_weight(_WEIGHTS_VARIABLE_NAME, shape=[input_depth + h_depth, 4 * self._num_units], initializer=self._initializer, partitioner=maybe_partitioner)
A:keras.layers.rnn.legacy_cells.self._bias->self.add_weight(_BIAS_VARIABLE_NAME, shape=[4 * self._num_units], initializer=initializer)
A:keras.layers.rnn.legacy_cells.gate_inputs->tensorflow.compat.v2.nn.bias_add(gate_inputs, self._bias)
A:keras.layers.rnn.legacy_cells.base_config->super(LSTMCell, self).get_config()
A:keras.layers.rnn.legacy_cells.self._kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.rnn.legacy_cells.self._bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.rnn.legacy_cells.self._gate_kernel->self.add_weight('gates/%s' % _WEIGHTS_VARIABLE_NAME, shape=[input_depth + self._num_units, 2 * self._num_units], initializer=self._kernel_initializer)
A:keras.layers.rnn.legacy_cells.self._gate_bias->self.add_weight('gates/%s' % _BIAS_VARIABLE_NAME, shape=[2 * self._num_units], initializer=self._bias_initializer if self._bias_initializer is not None else tf.compat.v1.constant_initializer(1.0, dtype=self.dtype))
A:keras.layers.rnn.legacy_cells.self._candidate_kernel->self.add_weight('candidate/%s' % _WEIGHTS_VARIABLE_NAME, shape=[input_depth + self._num_units, self._num_units], initializer=self._kernel_initializer)
A:keras.layers.rnn.legacy_cells.self._candidate_bias->self.add_weight('candidate/%s' % _BIAS_VARIABLE_NAME, shape=[self._num_units], initializer=self._bias_initializer if self._bias_initializer is not None else tf.compat.v1.zeros_initializer(dtype=self.dtype))
A:keras.layers.rnn.legacy_cells.value->tensorflow.compat.v2.sigmoid(gate_inputs)
A:keras.layers.rnn.legacy_cells.(r, u)->tensorflow.compat.v2.split(value=value, num_or_size_splits=2, axis=1)
A:keras.layers.rnn.legacy_cells.candidate->tensorflow.compat.v2.nn.bias_add(candidate, self._candidate_bias)
A:keras.layers.rnn.legacy_cells._LSTMStateTuple->collections.namedtuple('LSTMStateTuple', ('c', 'h'))
A:keras.layers.rnn.legacy_cells.one->tensorflow.compat.v2.constant(1, dtype=tf.int32)
A:keras.layers.rnn.legacy_cells.(c, h)->tensorflow.compat.v2.split(value=state, num_or_size_splits=2, axis=one)
A:keras.layers.rnn.legacy_cells.(i, j, f, o)->tensorflow.compat.v2.split(value=lstm_matrix, num_or_size_splits=4, axis=1)
A:keras.layers.rnn.legacy_cells.forget_bias_tensor->tensorflow.compat.v2.constant(self._forget_bias, dtype=f.dtype)
A:keras.layers.rnn.legacy_cells.new_c->add(multiply(c, sigmoid(add(f, forget_bias_tensor))), multiply(sigmoid(i), self._activation(j)))
A:keras.layers.rnn.legacy_cells.new_h->multiply(self._activation(new_c), sigmoid(o))
A:keras.layers.rnn.legacy_cells.new_state->tensorflow.compat.v2.concat([new_c, new_h], 1)
A:keras.layers.rnn.legacy_cells.self._initializer->keras.initializers.get(initializer)
A:keras.layers.rnn.legacy_cells.initializer->tensorflow.compat.v2.compat.v1.zeros_initializer(dtype=self.dtype)
A:keras.layers.rnn.legacy_cells.self._w_f_diag->self.add_weight('w_f_diag', shape=[self._num_units], initializer=self._initializer)
A:keras.layers.rnn.legacy_cells.self._w_i_diag->self.add_weight('w_i_diag', shape=[self._num_units], initializer=self._initializer)
A:keras.layers.rnn.legacy_cells.self._w_o_diag->self.add_weight('w_o_diag', shape=[self._num_units], initializer=self._initializer)
A:keras.layers.rnn.legacy_cells.self._proj_kernel->self.add_weight('projection/%s' % _WEIGHTS_VARIABLE_NAME, shape=[self._num_units, self._num_proj], initializer=self._initializer, partitioner=maybe_proj_partitioner)
A:keras.layers.rnn.legacy_cells.c_prev->tensorflow.compat.v2.slice(state, [0, 0], [-1, self._num_units])
A:keras.layers.rnn.legacy_cells.m_prev->tensorflow.compat.v2.slice(state, [0, self._num_units], [-1, num_proj])
A:keras.layers.rnn.legacy_cells.lstm_matrix->tensorflow.compat.v2.nn.bias_add(lstm_matrix, self._bias)
A:keras.layers.rnn.legacy_cells.m->tensorflow.compat.v2.clip_by_value(m, -self._proj_clip, self._proj_clip)
A:keras.layers.rnn.legacy_cells.cur_state->tensorflow.compat.v2.slice(state, [0, cur_state_pos], [-1, cell.state_size])
A:keras.layers.rnn.legacy_cells.(cur_inp, new_state)->cell(cur_inp, cur_state)
A:keras.layers.rnn.legacy_cells.dtype->tensorflow.compat.v2.as_dtype(dtype)
keras.layers.rnn.legacy_cells.BasicLSTMCell(self,num_units,forget_bias=1.0,state_is_tuple=True,activation=None,reuse=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.BasicLSTMCell.__init__(self,num_units,forget_bias=1.0,state_is_tuple=True,activation=None,reuse=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.BasicLSTMCell.build(self,inputs_shape)
keras.layers.rnn.legacy_cells.BasicLSTMCell.call(self,inputs,state)
keras.layers.rnn.legacy_cells.BasicLSTMCell.get_config(self)
keras.layers.rnn.legacy_cells.BasicLSTMCell.output_size(self)
keras.layers.rnn.legacy_cells.BasicLSTMCell.state_size(self)
keras.layers.rnn.legacy_cells.BasicRNNCell(self,num_units,activation=None,reuse=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.BasicRNNCell.__init__(self,num_units,activation=None,reuse=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.BasicRNNCell.build(self,inputs_shape)
keras.layers.rnn.legacy_cells.BasicRNNCell.call(self,inputs,state)
keras.layers.rnn.legacy_cells.BasicRNNCell.get_config(self)
keras.layers.rnn.legacy_cells.BasicRNNCell.output_size(self)
keras.layers.rnn.legacy_cells.BasicRNNCell.state_size(self)
keras.layers.rnn.legacy_cells.GRUCell(self,num_units,activation=None,reuse=None,kernel_initializer=None,bias_initializer=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.GRUCell.__init__(self,num_units,activation=None,reuse=None,kernel_initializer=None,bias_initializer=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.GRUCell.build(self,inputs_shape)
keras.layers.rnn.legacy_cells.GRUCell.call(self,inputs,state)
keras.layers.rnn.legacy_cells.GRUCell.get_config(self)
keras.layers.rnn.legacy_cells.GRUCell.output_size(self)
keras.layers.rnn.legacy_cells.GRUCell.state_size(self)
keras.layers.rnn.legacy_cells.LSTMCell(self,num_units,use_peepholes=False,cell_clip=None,initializer=None,num_proj=None,proj_clip=None,num_unit_shards=None,num_proj_shards=None,forget_bias=1.0,state_is_tuple=True,activation=None,reuse=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.LSTMCell.__init__(self,num_units,use_peepholes=False,cell_clip=None,initializer=None,num_proj=None,proj_clip=None,num_unit_shards=None,num_proj_shards=None,forget_bias=1.0,state_is_tuple=True,activation=None,reuse=None,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.LSTMCell.build(self,inputs_shape)
keras.layers.rnn.legacy_cells.LSTMCell.call(self,inputs,state)
keras.layers.rnn.legacy_cells.LSTMCell.get_config(self)
keras.layers.rnn.legacy_cells.LSTMCell.output_size(self)
keras.layers.rnn.legacy_cells.LSTMCell.state_size(self)
keras.layers.rnn.legacy_cells.LSTMStateTuple(_LSTMStateTuple)
keras.layers.rnn.legacy_cells.LSTMStateTuple.dtype(self)
keras.layers.rnn.legacy_cells.LayerRNNCell(self,inputs,state,scope=None,*args,**kwargs)
keras.layers.rnn.legacy_cells.LayerRNNCell.__call__(self,inputs,state,scope=None,*args,**kwargs)
keras.layers.rnn.legacy_cells.MultiRNNCell(self,cells,state_is_tuple=True)
keras.layers.rnn.legacy_cells.MultiRNNCell.__init__(self,cells,state_is_tuple=True)
keras.layers.rnn.legacy_cells.MultiRNNCell.call(self,inputs,state)
keras.layers.rnn.legacy_cells.MultiRNNCell.non_trainable_weights(self)
keras.layers.rnn.legacy_cells.MultiRNNCell.output_size(self)
keras.layers.rnn.legacy_cells.MultiRNNCell.state_size(self)
keras.layers.rnn.legacy_cells.MultiRNNCell.trainable_weights(self)
keras.layers.rnn.legacy_cells.MultiRNNCell.zero_state(self,batch_size,dtype)
keras.layers.rnn.legacy_cells.RNNCell(self,trainable=True,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.RNNCell.__init__(self,trainable=True,name=None,dtype=None,**kwargs)
keras.layers.rnn.legacy_cells.RNNCell._rnn_get_variable(self,getter,*args,**kwargs)
keras.layers.rnn.legacy_cells.RNNCell._use_input_spec_as_call_signature(self)
keras.layers.rnn.legacy_cells.RNNCell.build(self,_)
keras.layers.rnn.legacy_cells.RNNCell.get_config(self)
keras.layers.rnn.legacy_cells.RNNCell.get_initial_state(self,inputs=None,batch_size=None,dtype=None)
keras.layers.rnn.legacy_cells.RNNCell.output_size(self)
keras.layers.rnn.legacy_cells.RNNCell.state_size(self)
keras.layers.rnn.legacy_cells.RNNCell.zero_state(self,batch_size,dtype)
keras.layers.rnn.legacy_cells._check_rnn_cell_input_dtypes(inputs)
keras.layers.rnn.legacy_cells._check_supported_dtypes(dtype)
keras.layers.rnn.legacy_cells._concat(prefix,suffix,static=False)
keras.layers.rnn.legacy_cells._hasattr(obj,attr_name)
keras.layers.rnn.legacy_cells._zero_state_tensors(state_size,batch_size,dtype)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/locally_connected/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/locally_connected/locally_connected2d.py----------------------------------------
A:keras.layers.locally_connected.locally_connected2d.self.kernel_size->keras.utils.conv_utils.normalize_tuple(kernel_size, 2, 'kernel_size')
A:keras.layers.locally_connected.locally_connected2d.self.strides->keras.utils.conv_utils.normalize_tuple(strides, 2, 'strides', allow_zero=True)
A:keras.layers.locally_connected.locally_connected2d.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.locally_connected.locally_connected2d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.locally_connected.locally_connected2d.self.activation->keras.activations.get(activation)
A:keras.layers.locally_connected.locally_connected2d.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.locally_connected.locally_connected2d.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.locally_connected.locally_connected2d.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.locally_connected.locally_connected2d.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.locally_connected.locally_connected2d.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.locally_connected.locally_connected2d.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.locally_connected.locally_connected2d.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.locally_connected.locally_connected2d.self.input_spec->InputSpec(ndim=4, axes={-1: input_filter})
A:keras.layers.locally_connected.locally_connected2d.output_row->keras.utils.conv_utils.conv_output_length(input_row, self.kernel_size[0], self.padding, self.strides[0])
A:keras.layers.locally_connected.locally_connected2d.output_col->keras.utils.conv_utils.conv_output_length(input_col, self.kernel_size[1], self.padding, self.strides[1])
A:keras.layers.locally_connected.locally_connected2d.self.kernel->self.add_weight(shape=(len(self.kernel_idxs),), initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)
A:keras.layers.locally_connected.locally_connected2d.self.kernel_mask->keras.layers.locally_connected.locally_connected_utils.get_locallyconnected_mask(input_shape=(input_row, input_col), kernel_shape=self.kernel_size, strides=self.strides, padding=self.padding, data_format=self.data_format)
A:keras.layers.locally_connected.locally_connected2d.self.kernel_idxs->sorted(conv_utils.conv_kernel_idxs(input_shape=(input_row, input_col), kernel_shape=self.kernel_size, strides=self.strides, padding=self.padding, filters_in=input_filter, filters_out=self.filters, data_format=self.data_format))
A:keras.layers.locally_connected.locally_connected2d.self.bias->self.add_weight(shape=(output_row, output_col, self.filters), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)
A:keras.layers.locally_connected.locally_connected2d.rows->keras.utils.conv_utils.conv_output_length(rows, self.kernel_size[0], self.padding, self.strides[0])
A:keras.layers.locally_connected.locally_connected2d.cols->keras.utils.conv_utils.conv_output_length(cols, self.kernel_size[1], self.padding, self.strides[1])
A:keras.layers.locally_connected.locally_connected2d.output->self.activation(output)
A:keras.layers.locally_connected.locally_connected2d.base_config->super(LocallyConnected2D, self).get_config()
keras.layers.locally_connected.LocallyConnected2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,implementation=1,**kwargs)
keras.layers.locally_connected.LocallyConnected2D._use_input_spec_as_call_signature(self)
keras.layers.locally_connected.LocallyConnected2D.build(self,input_shape)
keras.layers.locally_connected.LocallyConnected2D.call(self,inputs)
keras.layers.locally_connected.LocallyConnected2D.compute_output_shape(self,input_shape)
keras.layers.locally_connected.LocallyConnected2D.get_config(self)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,implementation=1,**kwargs)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,implementation=1,**kwargs)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D._use_input_spec_as_call_signature(self)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D.build(self,input_shape)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D.call(self,inputs)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D.compute_output_shape(self,input_shape)
keras.layers.locally_connected.locally_connected2d.LocallyConnected2D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/locally_connected/locally_connected_utils.py----------------------------------------
A:keras.layers.locally_connected.locally_connected_utils.mask->numpy.expand_dims(mask, -1)
A:keras.layers.locally_connected.locally_connected_utils.ndims->int(mask.ndim / 2)
A:keras.layers.locally_connected.locally_connected_utils.inputs_flat->keras.backend.reshape(inputs, (backend.shape(inputs)[0], -1))
A:keras.layers.locally_connected.locally_connected_utils.kernel->make_2d(kernel, split_dim=backend.ndim(kernel) // 2)
A:keras.layers.locally_connected.locally_connected_utils.output_flat->tensorflow.compat.v2.sparse.sparse_dense_matmul(sp_a=tf.SparseTensor(kernel_idxs, kernel, kernel_shape), b=inputs_flat, adjoint_b=True)
A:keras.layers.locally_connected.locally_connected_utils.output->keras.backend.reshape(output_flat, [backend.shape(output_flat)[0]] + output_shape.as_list()[1:])
A:keras.layers.locally_connected.locally_connected_utils.output_flat_transpose->keras.backend.transpose(output_flat)
A:keras.layers.locally_connected.locally_connected_utils.output_reshaped->keras.backend.reshape(output_flat_transpose, [backend.shape(output_flat_transpose)[0]] + output_shape.as_list()[1:])
A:keras.layers.locally_connected.locally_connected_utils.shape->tensorflow.compat.v2.shape(tensor)
A:keras.layers.locally_connected.locally_connected_utils.in_size->tensorflow.compat.v2.reduce_prod(in_dims)
A:keras.layers.locally_connected.locally_connected_utils.out_size->tensorflow.compat.v2.reduce_prod(out_dims)
keras.layers.locally_connected.locally_connected_utils.get_locallyconnected_mask(input_shape,kernel_shape,strides,padding,data_format)
keras.layers.locally_connected.locally_connected_utils.local_conv_matmul(inputs,kernel,kernel_mask,output_shape)
keras.layers.locally_connected.locally_connected_utils.local_conv_sparse_matmul(inputs,kernel,kernel_idxs,kernel_shape,output_shape)
keras.layers.locally_connected.locally_connected_utils.make_2d(tensor,split_dim)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/locally_connected/locally_connected1d.py----------------------------------------
A:keras.layers.locally_connected.locally_connected1d.self.kernel_size->keras.utils.conv_utils.normalize_tuple(kernel_size, 1, 'kernel_size')
A:keras.layers.locally_connected.locally_connected1d.self.strides->keras.utils.conv_utils.normalize_tuple(strides, 1, 'strides', allow_zero=True)
A:keras.layers.locally_connected.locally_connected1d.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.locally_connected.locally_connected1d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.locally_connected.locally_connected1d.self.activation->keras.activations.get(activation)
A:keras.layers.locally_connected.locally_connected1d.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.locally_connected.locally_connected1d.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.locally_connected.locally_connected1d.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.locally_connected.locally_connected1d.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.locally_connected.locally_connected1d.self.activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.locally_connected.locally_connected1d.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.locally_connected.locally_connected1d.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.locally_connected.locally_connected1d.self.input_spec->InputSpec(ndim=3, axes={-1: input_dim})
A:keras.layers.locally_connected.locally_connected1d.self.output_length->keras.utils.conv_utils.conv_output_length(input_length, self.kernel_size[0], self.padding, self.strides[0])
A:keras.layers.locally_connected.locally_connected1d.self.kernel->self.add_weight(shape=(len(self.kernel_idxs),), initializer=self.kernel_initializer, name='kernel', regularizer=self.kernel_regularizer, constraint=self.kernel_constraint)
A:keras.layers.locally_connected.locally_connected1d.self.kernel_mask->keras.layers.locally_connected.locally_connected_utils.get_locallyconnected_mask(input_shape=(input_length,), kernel_shape=self.kernel_size, strides=self.strides, padding=self.padding, data_format=self.data_format)
A:keras.layers.locally_connected.locally_connected1d.self.kernel_idxs->sorted(conv_utils.conv_kernel_idxs(input_shape=(input_length,), kernel_shape=self.kernel_size, strides=self.strides, padding=self.padding, filters_in=input_dim, filters_out=self.filters, data_format=self.data_format))
A:keras.layers.locally_connected.locally_connected1d.self.bias->self.add_weight(shape=(self.output_length, self.filters), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)
A:keras.layers.locally_connected.locally_connected1d.length->keras.utils.conv_utils.conv_output_length(input_length, self.kernel_size[0], self.padding, self.strides[0])
A:keras.layers.locally_connected.locally_connected1d.output->self.activation(output)
A:keras.layers.locally_connected.locally_connected1d.base_config->super(LocallyConnected1D, self).get_config()
keras.layers.locally_connected.LocallyConnected1D(self,filters,kernel_size,strides=1,padding='valid',data_format=None,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,implementation=1,**kwargs)
keras.layers.locally_connected.LocallyConnected1D._use_input_spec_as_call_signature(self)
keras.layers.locally_connected.LocallyConnected1D.build(self,input_shape)
keras.layers.locally_connected.LocallyConnected1D.call(self,inputs)
keras.layers.locally_connected.LocallyConnected1D.compute_output_shape(self,input_shape)
keras.layers.locally_connected.LocallyConnected1D.get_config(self)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D(self,filters,kernel_size,strides=1,padding='valid',data_format=None,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,implementation=1,**kwargs)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D.__init__(self,filters,kernel_size,strides=1,padding='valid',data_format=None,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,implementation=1,**kwargs)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D._use_input_spec_as_call_signature(self)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D.build(self,input_shape)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D.call(self,inputs)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D.compute_output_shape(self,input_shape)
keras.layers.locally_connected.locally_connected1d.LocallyConnected1D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/activity_regularization.py----------------------------------------
A:keras.layers.regularization.activity_regularization.base_config->super(ActivityRegularization, self).get_config()
keras.layers.regularization.ActivityRegularization(self,l1=0.0,l2=0.0,**kwargs)
keras.layers.regularization.ActivityRegularization.compute_output_shape(self,input_shape)
keras.layers.regularization.ActivityRegularization.get_config(self)
keras.layers.regularization.activity_regularization.ActivityRegularization(self,l1=0.0,l2=0.0,**kwargs)
keras.layers.regularization.activity_regularization.ActivityRegularization.__init__(self,l1=0.0,l2=0.0,**kwargs)
keras.layers.regularization.activity_regularization.ActivityRegularization.compute_output_shape(self,input_shape)
keras.layers.regularization.activity_regularization.ActivityRegularization.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/dropout.py----------------------------------------
A:keras.layers.regularization.dropout.concrete_inputs_shape->tensorflow.compat.v2.shape(inputs)
A:keras.layers.regularization.dropout.training->keras.backend.learning_phase()
A:keras.layers.regularization.dropout.output->keras.utils.control_flow_util.smart_cond(training, dropped_inputs, lambda : tf.identity(inputs))
A:keras.layers.regularization.dropout.base_config->super(Dropout, self).get_config()
keras.layers.regularization.Dropout(self,rate,noise_shape=None,seed=None,**kwargs)
keras.layers.regularization.Dropout._get_noise_shape(self,inputs)
keras.layers.regularization.Dropout.build(self,input_shape)
keras.layers.regularization.Dropout.call(self,inputs,training=None)
keras.layers.regularization.Dropout.compute_output_shape(self,input_shape)
keras.layers.regularization.Dropout.get_config(self)
keras.layers.regularization.dropout.Dropout(self,rate,noise_shape=None,seed=None,**kwargs)
keras.layers.regularization.dropout.Dropout.__init__(self,rate,noise_shape=None,seed=None,**kwargs)
keras.layers.regularization.dropout.Dropout._get_noise_shape(self,inputs)
keras.layers.regularization.dropout.Dropout.build(self,input_shape)
keras.layers.regularization.dropout.Dropout.call(self,inputs,training=None)
keras.layers.regularization.dropout.Dropout.compute_output_shape(self,input_shape)
keras.layers.regularization.dropout.Dropout.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/gaussian_dropout.py----------------------------------------
A:keras.layers.regularization.gaussian_dropout.stddev->numpy.sqrt(self.rate / (1.0 - self.rate))
A:keras.layers.regularization.gaussian_dropout.base_config->super(GaussianDropout, self).get_config()
keras.layers.regularization.GaussianDropout(self,rate,seed=None,**kwargs)
keras.layers.regularization.GaussianDropout.call(self,inputs,training=None)
keras.layers.regularization.GaussianDropout.compute_output_shape(self,input_shape)
keras.layers.regularization.GaussianDropout.get_config(self)
keras.layers.regularization.gaussian_dropout.GaussianDropout(self,rate,seed=None,**kwargs)
keras.layers.regularization.gaussian_dropout.GaussianDropout.__init__(self,rate,seed=None,**kwargs)
keras.layers.regularization.gaussian_dropout.GaussianDropout.call(self,inputs,training=None)
keras.layers.regularization.gaussian_dropout.GaussianDropout.compute_output_shape(self,input_shape)
keras.layers.regularization.gaussian_dropout.GaussianDropout.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/spatial_dropout2d.py----------------------------------------
A:keras.layers.regularization.spatial_dropout2d.data_format->keras.backend.image_data_format()
A:keras.layers.regularization.spatial_dropout2d.self.input_spec->InputSpec(ndim=4)
A:keras.layers.regularization.spatial_dropout2d.input_shape->tensorflow.compat.v2.shape(inputs)
keras.layers.regularization.SpatialDropout2D(self,rate,data_format=None,**kwargs)
keras.layers.regularization.SpatialDropout2D._get_noise_shape(self,inputs)
keras.layers.regularization.spatial_dropout2d.SpatialDropout2D(self,rate,data_format=None,**kwargs)
keras.layers.regularization.spatial_dropout2d.SpatialDropout2D.__init__(self,rate,data_format=None,**kwargs)
keras.layers.regularization.spatial_dropout2d.SpatialDropout2D._get_noise_shape(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/spatial_dropout1d.py----------------------------------------
A:keras.layers.regularization.spatial_dropout1d.self.input_spec->InputSpec(ndim=3)
A:keras.layers.regularization.spatial_dropout1d.input_shape->tensorflow.compat.v2.shape(inputs)
keras.layers.regularization.SpatialDropout1D(self,rate,**kwargs)
keras.layers.regularization.SpatialDropout1D._get_noise_shape(self,inputs)
keras.layers.regularization.spatial_dropout1d.SpatialDropout1D(self,rate,**kwargs)
keras.layers.regularization.spatial_dropout1d.SpatialDropout1D.__init__(self,rate,**kwargs)
keras.layers.regularization.spatial_dropout1d.SpatialDropout1D._get_noise_shape(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/spatial_dropout3d.py----------------------------------------
A:keras.layers.regularization.spatial_dropout3d.data_format->keras.backend.image_data_format()
A:keras.layers.regularization.spatial_dropout3d.self.input_spec->InputSpec(ndim=5)
A:keras.layers.regularization.spatial_dropout3d.input_shape->tensorflow.compat.v2.shape(inputs)
keras.layers.regularization.SpatialDropout3D(self,rate,data_format=None,**kwargs)
keras.layers.regularization.SpatialDropout3D._get_noise_shape(self,inputs)
keras.layers.regularization.spatial_dropout3d.SpatialDropout3D(self,rate,data_format=None,**kwargs)
keras.layers.regularization.spatial_dropout3d.SpatialDropout3D.__init__(self,rate,data_format=None,**kwargs)
keras.layers.regularization.spatial_dropout3d.SpatialDropout3D._get_noise_shape(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/alpha_dropout.py----------------------------------------
A:keras.layers.regularization.alpha_dropout.noise_shape->self._get_noise_shape(inputs)
A:keras.layers.regularization.alpha_dropout.kept_idx->tensorflow.compat.v2.cast(kept_idx, inputs.dtype)
A:keras.layers.regularization.alpha_dropout.base_config->super(AlphaDropout, self).get_config()
keras.layers.regularization.AlphaDropout(self,rate,noise_shape=None,seed=None,**kwargs)
keras.layers.regularization.AlphaDropout._get_noise_shape(self,inputs)
keras.layers.regularization.AlphaDropout.call(self,inputs,training=None)
keras.layers.regularization.AlphaDropout.compute_output_shape(self,input_shape)
keras.layers.regularization.AlphaDropout.get_config(self)
keras.layers.regularization.alpha_dropout.AlphaDropout(self,rate,noise_shape=None,seed=None,**kwargs)
keras.layers.regularization.alpha_dropout.AlphaDropout.__init__(self,rate,noise_shape=None,seed=None,**kwargs)
keras.layers.regularization.alpha_dropout.AlphaDropout._get_noise_shape(self,inputs)
keras.layers.regularization.alpha_dropout.AlphaDropout.call(self,inputs,training=None)
keras.layers.regularization.alpha_dropout.AlphaDropout.compute_output_shape(self,input_shape)
keras.layers.regularization.alpha_dropout.AlphaDropout.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/regularization/gaussian_noise.py----------------------------------------
A:keras.layers.regularization.gaussian_noise.base_config->super(GaussianNoise, self).get_config()
keras.layers.regularization.GaussianNoise(self,stddev,seed=None,**kwargs)
keras.layers.regularization.GaussianNoise.call(self,inputs,training=None)
keras.layers.regularization.GaussianNoise.compute_output_shape(self,input_shape)
keras.layers.regularization.GaussianNoise.get_config(self)
keras.layers.regularization.gaussian_noise.GaussianNoise(self,stddev,seed=None,**kwargs)
keras.layers.regularization.gaussian_noise.GaussianNoise.__init__(self,stddev,seed=None,**kwargs)
keras.layers.regularization.gaussian_noise.GaussianNoise.call(self,inputs,training=None)
keras.layers.regularization.gaussian_noise.GaussianNoise.compute_output_shape(self,input_shape)
keras.layers.regularization.gaussian_noise.GaussianNoise.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/multiply.py----------------------------------------
keras.layers.merging.Multiply(_Merge)
keras.layers.merging.Multiply._merge_function(self,inputs)
keras.layers.merging.multiply(inputs,**kwargs)
keras.layers.merging.multiply.Multiply(_Merge)
keras.layers.merging.multiply.Multiply._merge_function(self,inputs)
keras.layers.merging.multiply.multiply(inputs,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/add.py----------------------------------------
keras.layers.merging.Add(_Merge)
keras.layers.merging.Add._merge_function(self,inputs)
keras.layers.merging.add(inputs,**kwargs)
keras.layers.merging.add.Add(_Merge)
keras.layers.merging.add.Add._merge_function(self,inputs)
keras.layers.merging.add.add(inputs,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/concatenate.py----------------------------------------
A:keras.layers.merging.concatenate.shape_set->set()
A:keras.layers.merging.concatenate.ranks->set((len(shape) for shape in shape_set))
A:keras.layers.merging.concatenate.unique_dims->set((shape[axis] for shape in shape_set if shape[axis] is not None))
A:keras.layers.merging.concatenate.output_shape->list(input_shapes[0])
A:keras.layers.merging.concatenate.concatenated->keras.backend.concatenate(masks, axis=self.axis)
A:keras.layers.merging.concatenate.base_config->super(Concatenate, self).get_config()
keras.layers.merging.Concatenate(self,axis=-1,**kwargs)
keras.layers.merging.Concatenate._merge_function(self,inputs)
keras.layers.merging.Concatenate.build(self,input_shape)
keras.layers.merging.Concatenate.compute_mask(self,inputs,mask=None)
keras.layers.merging.Concatenate.compute_output_shape(self,input_shape)
keras.layers.merging.Concatenate.get_config(self)
keras.layers.merging.concatenate(inputs,axis=-1,**kwargs)
keras.layers.merging.concatenate.Concatenate(self,axis=-1,**kwargs)
keras.layers.merging.concatenate.Concatenate.__init__(self,axis=-1,**kwargs)
keras.layers.merging.concatenate.Concatenate._merge_function(self,inputs)
keras.layers.merging.concatenate.Concatenate.build(self,input_shape)
keras.layers.merging.concatenate.Concatenate.compute_mask(self,inputs,mask=None)
keras.layers.merging.concatenate.Concatenate.compute_output_shape(self,input_shape)
keras.layers.merging.concatenate.Concatenate.get_config(self)
keras.layers.merging.concatenate.concatenate(inputs,axis=-1,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/average.py----------------------------------------
keras.layers.merging.Average(_Merge)
keras.layers.merging.Average._merge_function(self,inputs)
keras.layers.merging.average(inputs,**kwargs)
keras.layers.merging.average.Average(_Merge)
keras.layers.merging.average.Average._merge_function(self,inputs)
keras.layers.merging.average.average(inputs,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/dot.py----------------------------------------
A:keras.layers.merging.dot.x1->tensorflow.compat.v2.linalg.l2_normalize(x1, axis=axes[0])
A:keras.layers.merging.dot.x2->tensorflow.compat.v2.linalg.l2_normalize(x2, axis=axes[1])
A:keras.layers.merging.dot.output->keras.backend.batch_dot(x1, x2, axes)
A:keras.layers.merging.dot.shape1->list(input_shape[0])
A:keras.layers.merging.dot.shape2->list(input_shape[1])
A:keras.layers.merging.dot.base_config->super(Dot, self).get_config()
keras.layers.merging.Dot(self,axes,normalize=False,**kwargs)
keras.layers.merging.Dot._merge_function(self,inputs)
keras.layers.merging.Dot.build(self,input_shape)
keras.layers.merging.Dot.compute_mask(self,inputs,mask=None)
keras.layers.merging.Dot.compute_output_shape(self,input_shape)
keras.layers.merging.Dot.get_config(self)
keras.layers.merging.dot(inputs,axes,normalize=False,**kwargs)
keras.layers.merging.dot.Dot(self,axes,normalize=False,**kwargs)
keras.layers.merging.dot.Dot.__init__(self,axes,normalize=False,**kwargs)
keras.layers.merging.dot.Dot._merge_function(self,inputs)
keras.layers.merging.dot.Dot.build(self,input_shape)
keras.layers.merging.dot.Dot.compute_mask(self,inputs,mask=None)
keras.layers.merging.dot.Dot.compute_output_shape(self,input_shape)
keras.layers.merging.dot.Dot.get_config(self)
keras.layers.merging.dot.dot(inputs,axes,normalize=False,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/base_merge.py----------------------------------------
A:keras.layers.merging.base_merge.output_shape->self._compute_elemwise_op_output_shape(output_shape, shape)
A:keras.layers.merging.base_merge.input_ndims->list(map(backend.ndim, inputs))
A:keras.layers.merging.base_merge.max_ndim->max(input_ndims)
A:keras.layers.merging.base_merge.x_ndim->keras.backend.ndim(x)
A:keras.layers.merging.base_merge.x->tensorflow.compat.v2.expand_dims(x, axis=1)
A:keras.layers.merging.base_merge.x_shape->tensorflow.compat.v2.shape(x)
A:keras.layers.merging.base_merge.new_shape->keras.backend.concatenate([tf.expand_dims(batch_size, axis=-1), y_shape[:y_ndim - 1]])
A:keras.layers.merging.base_merge.x_transposed->tensorflow.compat.v2.reshape(x_transposed, new_shape)
A:keras.layers.merging.base_merge.y->tensorflow.compat.v2.transpose(y, perm=dims)
A:keras.layers.merging.base_merge.y_ndim->keras.backend.ndim(y)
A:keras.layers.merging.base_merge.y_shape->tensorflow.compat.v2.shape(y)
keras.layers.merging.base_merge._Merge(self,**kwargs)
keras.layers.merging.base_merge._Merge.__init__(self,**kwargs)
keras.layers.merging.base_merge._Merge._compute_elemwise_op_output_shape(self,shape1,shape2)
keras.layers.merging.base_merge._Merge._merge_function(self,inputs)
keras.layers.merging.base_merge._Merge.build(self,input_shape)
keras.layers.merging.base_merge._Merge.call(self,inputs)
keras.layers.merging.base_merge._Merge.compute_mask(self,inputs,mask=None)
keras.layers.merging.base_merge._Merge.compute_output_shape(self,input_shape)
keras.layers.merging.base_merge._Merge.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/subtract.py----------------------------------------
keras.layers.merging.Subtract(_Merge)
keras.layers.merging.Subtract._merge_function(self,inputs)
keras.layers.merging.Subtract.build(self,input_shape)
keras.layers.merging.subtract(inputs,**kwargs)
keras.layers.merging.subtract.Subtract(_Merge)
keras.layers.merging.subtract.Subtract._merge_function(self,inputs)
keras.layers.merging.subtract.Subtract.build(self,input_shape)
keras.layers.merging.subtract.subtract(inputs,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/minimum.py----------------------------------------
A:keras.layers.merging.minimum.output->tensorflow.compat.v2.minimum(output, inputs[i])
keras.layers.merging.Minimum(_Merge)
keras.layers.merging.Minimum._merge_function(self,inputs)
keras.layers.merging.minimum(inputs,**kwargs)
keras.layers.merging.minimum.Minimum(_Merge)
keras.layers.merging.minimum.Minimum._merge_function(self,inputs)
keras.layers.merging.minimum.minimum(inputs,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/merging/maximum.py----------------------------------------
A:keras.layers.merging.maximum.output->tensorflow.compat.v2.maximum(output, inputs[i])
keras.layers.merging.Maximum(_Merge)
keras.layers.merging.Maximum._merge_function(self,inputs)
keras.layers.merging.maximum(inputs,**kwargs)
keras.layers.merging.maximum.Maximum(_Merge)
keras.layers.merging.maximum.Maximum._merge_function(self,inputs)
keras.layers.merging.maximum.maximum(inputs,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/base_separable_conv.py----------------------------------------
A:keras.layers.convolutional.base_separable_conv.self.depthwise_initializer->keras.initializers.get(depthwise_initializer)
A:keras.layers.convolutional.base_separable_conv.self.pointwise_initializer->keras.initializers.get(pointwise_initializer)
A:keras.layers.convolutional.base_separable_conv.self.depthwise_regularizer->keras.regularizers.get(depthwise_regularizer)
A:keras.layers.convolutional.base_separable_conv.self.pointwise_regularizer->keras.regularizers.get(pointwise_regularizer)
A:keras.layers.convolutional.base_separable_conv.self.depthwise_constraint->keras.constraints.get(depthwise_constraint)
A:keras.layers.convolutional.base_separable_conv.self.pointwise_constraint->keras.constraints.get(pointwise_constraint)
A:keras.layers.convolutional.base_separable_conv.input_shape->tensorflow.compat.v2.TensorShape(input_shape)
A:keras.layers.convolutional.base_separable_conv.channel_axis->self._get_channel_axis()
A:keras.layers.convolutional.base_separable_conv.input_dim->int(input_shape[channel_axis])
A:keras.layers.convolutional.base_separable_conv.self.input_spec->InputSpec(ndim=self.rank + 2, axes={channel_axis: input_dim})
A:keras.layers.convolutional.base_separable_conv.self.depthwise_kernel->self.add_weight(name='depthwise_kernel', shape=depthwise_kernel_shape, initializer=self.depthwise_initializer, regularizer=self.depthwise_regularizer, constraint=self.depthwise_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.base_separable_conv.self.pointwise_kernel->self.add_weight(name='pointwise_kernel', shape=pointwise_kernel_shape, initializer=self.pointwise_initializer, regularizer=self.pointwise_regularizer, constraint=self.pointwise_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.base_separable_conv.self.bias->self.add_weight(name='bias', shape=(self.filters,), initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.base_separable_conv.base_config->super(SeparableConv, self).get_config()
keras.layers.convolutional.base_separable_conv.SeparableConv(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.layers.convolutional.base_separable_conv.SeparableConv.__init__(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,trainable=True,name=None,**kwargs)
keras.layers.convolutional.base_separable_conv.SeparableConv.build(self,input_shape)
keras.layers.convolutional.base_separable_conv.SeparableConv.call(self,inputs)
keras.layers.convolutional.base_separable_conv.SeparableConv.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/depthwise_conv1d.py----------------------------------------
A:keras.layers.convolutional.depthwise_conv1d.inputs->tensorflow.compat.v2.expand_dims(inputs, spatial_start_dim)
A:keras.layers.convolutional.depthwise_conv1d.depthwise_kernel->tensorflow.compat.v2.expand_dims(self.depthwise_kernel, axis=0)
A:keras.layers.convolutional.depthwise_conv1d.outputs->tensorflow.compat.v2.squeeze(outputs, [spatial_start_dim])
A:keras.layers.convolutional.depthwise_conv1d.rows->keras.utils.conv_utils.conv_output_length(rows, self.kernel_size[0], self.padding, self.strides[0], self.dilation_rate[0])
keras.layers.convolutional.DepthwiseConv1D(self,kernel_size,strides=1,padding='valid',depth_multiplier=1,data_format=None,dilation_rate=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.DepthwiseConv1D.call(self,inputs)
keras.layers.convolutional.DepthwiseConv1D.compute_output_shape(self,input_shape)
keras.layers.convolutional.depthwise_conv1d.DepthwiseConv1D(self,kernel_size,strides=1,padding='valid',depth_multiplier=1,data_format=None,dilation_rate=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.depthwise_conv1d.DepthwiseConv1D.__init__(self,kernel_size,strides=1,padding='valid',depth_multiplier=1,data_format=None,dilation_rate=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.depthwise_conv1d.DepthwiseConv1D.call(self,inputs)
keras.layers.convolutional.depthwise_conv1d.DepthwiseConv1D.compute_output_shape(self,input_shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/conv3d.py----------------------------------------
keras.layers.convolutional.Conv3D(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1),groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv3d.Conv3D(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1),groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv3d.Conv3D.__init__(self,filters,kernel_size,strides=(1,1,1),padding='valid',data_format=None,dilation_rate=(1,1,1),groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/depthwise_conv2d.py----------------------------------------
A:keras.layers.convolutional.depthwise_conv2d.outputs->keras.backend.bias_add(outputs, self.bias, data_format=self.data_format)
A:keras.layers.convolutional.depthwise_conv2d.rows->keras.utils.conv_utils.conv_output_length(rows, self.kernel_size[0], self.padding, self.strides[0], self.dilation_rate[0])
A:keras.layers.convolutional.depthwise_conv2d.cols->keras.utils.conv_utils.conv_output_length(cols, self.kernel_size[1], self.padding, self.strides[1], self.dilation_rate[1])
keras.layers.convolutional.DepthwiseConv2D(self,kernel_size,strides=(1,1),padding='valid',depth_multiplier=1,data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.DepthwiseConv2D.call(self,inputs)
keras.layers.convolutional.DepthwiseConv2D.compute_output_shape(self,input_shape)
keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D(self,kernel_size,strides=(1,1),padding='valid',depth_multiplier=1,data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D.__init__(self,kernel_size,strides=(1,1),padding='valid',depth_multiplier=1,data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D.call(self,inputs)
keras.layers.convolutional.depthwise_conv2d.DepthwiseConv2D.compute_output_shape(self,input_shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/base_depthwise_conv.py----------------------------------------
A:keras.layers.convolutional.base_depthwise_conv.self.depthwise_initializer->keras.initializers.get(depthwise_initializer)
A:keras.layers.convolutional.base_depthwise_conv.self.depthwise_regularizer->keras.regularizers.get(depthwise_regularizer)
A:keras.layers.convolutional.base_depthwise_conv.self.depthwise_constraint->keras.constraints.get(depthwise_constraint)
A:keras.layers.convolutional.base_depthwise_conv.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.convolutional.base_depthwise_conv.input_shape->tensorflow.compat.v2.TensorShape(input_shape)
A:keras.layers.convolutional.base_depthwise_conv.channel_axis->self._get_channel_axis()
A:keras.layers.convolutional.base_depthwise_conv.input_dim->int(input_shape[channel_axis])
A:keras.layers.convolutional.base_depthwise_conv.self.depthwise_kernel->self.add_weight(shape=depthwise_kernel_shape, initializer=self.depthwise_initializer, name='depthwise_kernel', regularizer=self.depthwise_regularizer, constraint=self.depthwise_constraint)
A:keras.layers.convolutional.base_depthwise_conv.self.bias->self.add_weight(shape=(input_dim * self.depth_multiplier,), initializer=self.bias_initializer, name='bias', regularizer=self.bias_regularizer, constraint=self.bias_constraint)
A:keras.layers.convolutional.base_depthwise_conv.self.input_spec->InputSpec(min_ndim=self.rank + 2, axes={channel_axis: input_dim})
A:keras.layers.convolutional.base_depthwise_conv.config->super(DepthwiseConv, self).get_config()
A:keras.layers.convolutional.base_depthwise_conv.config['depthwise_initializer']->keras.initializers.serialize(self.depthwise_initializer)
A:keras.layers.convolutional.base_depthwise_conv.config['depthwise_regularizer']->keras.regularizers.serialize(self.depthwise_regularizer)
A:keras.layers.convolutional.base_depthwise_conv.config['depthwise_constraint']->keras.constraints.serialize(self.depthwise_constraint)
keras.layers.convolutional.base_depthwise_conv.DepthwiseConv(self,rank,kernel_size,strides=1,padding='valid',depth_multiplier=1,data_format=None,dilation_rate=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.base_depthwise_conv.DepthwiseConv.__init__(self,rank,kernel_size,strides=1,padding='valid',depth_multiplier=1,data_format=None,dilation_rate=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.base_depthwise_conv.DepthwiseConv.build(self,input_shape)
keras.layers.convolutional.base_depthwise_conv.DepthwiseConv.call(self,inputs)
keras.layers.convolutional.base_depthwise_conv.DepthwiseConv.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/conv2d.py----------------------------------------
keras.layers.convolutional.Conv2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv2d.Conv2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv2d.Conv2D.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/conv2d_transpose.py----------------------------------------
A:keras.layers.convolutional.conv2d_transpose.self.output_padding->keras.utils.conv_utils.normalize_tuple(self.output_padding, 2, 'output_padding', allow_zero=True)
A:keras.layers.convolutional.conv2d_transpose.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.convolutional.conv2d_transpose.channel_axis->self._get_channel_axis()
A:keras.layers.convolutional.conv2d_transpose.input_dim->int(input_shape[channel_axis])
A:keras.layers.convolutional.conv2d_transpose.self.input_spec->InputSpec(ndim=4, axes={channel_axis: input_dim})
A:keras.layers.convolutional.conv2d_transpose.self.kernel->self.add_weight(name='kernel', shape=kernel_shape, initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.conv2d_transpose.self.bias->self.add_weight(name='bias', shape=(self.filters,), initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.conv2d_transpose.inputs_shape->tensorflow.compat.v2.shape(inputs)
A:keras.layers.convolutional.conv2d_transpose.dims->inputs.shape.as_list()
A:keras.layers.convolutional.conv2d_transpose.out_height->keras.utils.conv_utils.deconv_output_length(height, kernel_h, padding=self.padding, output_padding=out_pad_h, stride=stride_h, dilation=self.dilation_rate[0])
A:keras.layers.convolutional.conv2d_transpose.out_width->keras.utils.conv_utils.deconv_output_length(width, kernel_w, padding=self.padding, output_padding=out_pad_w, stride=stride_w, dilation=self.dilation_rate[1])
A:keras.layers.convolutional.conv2d_transpose.output_shape_tensor->tensorflow.compat.v2.stack(output_shape)
A:keras.layers.convolutional.conv2d_transpose.outputs->tensorflow.compat.v2.nn.bias_add(outputs, self.bias, data_format=conv_utils.convert_data_format(self.data_format, ndim=4))
A:keras.layers.convolutional.conv2d_transpose.out_shape->self.compute_output_shape(inputs.shape)
A:keras.layers.convolutional.conv2d_transpose.output_shape->list(input_shape)
A:keras.layers.convolutional.conv2d_transpose.output_shape[h_axis]->keras.utils.conv_utils.deconv_output_length(output_shape[h_axis], kernel_h, padding=self.padding, output_padding=out_pad_h, stride=stride_h, dilation=self.dilation_rate[0])
A:keras.layers.convolutional.conv2d_transpose.output_shape[w_axis]->keras.utils.conv_utils.deconv_output_length(output_shape[w_axis], kernel_w, padding=self.padding, output_padding=out_pad_w, stride=stride_w, dilation=self.dilation_rate[1])
A:keras.layers.convolutional.conv2d_transpose.config->super(Conv2DTranspose, self).get_config()
keras.layers.convolutional.Conv2DTranspose(self,filters,kernel_size,strides=(1,1),padding='valid',output_padding=None,data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.Conv2DTranspose.build(self,input_shape)
keras.layers.convolutional.Conv2DTranspose.call(self,inputs)
keras.layers.convolutional.Conv2DTranspose.compute_output_shape(self,input_shape)
keras.layers.convolutional.Conv2DTranspose.get_config(self)
keras.layers.convolutional.conv2d_transpose.Conv2DTranspose(self,filters,kernel_size,strides=(1,1),padding='valid',output_padding=None,data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv2d_transpose.Conv2DTranspose.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',output_padding=None,data_format=None,dilation_rate=(1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv2d_transpose.Conv2DTranspose.build(self,input_shape)
keras.layers.convolutional.conv2d_transpose.Conv2DTranspose.call(self,inputs)
keras.layers.convolutional.conv2d_transpose.Conv2DTranspose.compute_output_shape(self,input_shape)
keras.layers.convolutional.conv2d_transpose.Conv2DTranspose.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/separable_conv2d.py----------------------------------------
A:keras.layers.convolutional.separable_conv2d.outputs->tensorflow.compat.v2.nn.bias_add(outputs, self.bias, data_format=conv_utils.convert_data_format(self.data_format, ndim=4))
keras.layers.convolutional.SeparableConv2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.SeparableConv2D.call(self,inputs)
keras.layers.convolutional.separable_conv2d.SeparableConv2D(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.separable_conv2d.SeparableConv2D.__init__(self,filters,kernel_size,strides=(1,1),padding='valid',data_format=None,dilation_rate=(1,1),depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.separable_conv2d.SeparableConv2D.call(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/separable_conv1d.py----------------------------------------
A:keras.layers.convolutional.separable_conv1d.inputs->tensorflow.compat.v2.expand_dims(inputs, spatial_start_dim)
A:keras.layers.convolutional.separable_conv1d.depthwise_kernel->tensorflow.compat.v2.expand_dims(self.depthwise_kernel, 0)
A:keras.layers.convolutional.separable_conv1d.pointwise_kernel->tensorflow.compat.v2.expand_dims(self.pointwise_kernel, 0)
A:keras.layers.convolutional.separable_conv1d.outputs->tensorflow.compat.v2.squeeze(outputs, [spatial_start_dim])
keras.layers.convolutional.SeparableConv1D(self,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.SeparableConv1D.call(self,inputs)
keras.layers.convolutional.separable_conv1d.SeparableConv1D(self,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.separable_conv1d.SeparableConv1D.__init__(self,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,depth_multiplier=1,activation=None,use_bias=True,depthwise_initializer='glorot_uniform',pointwise_initializer='glorot_uniform',bias_initializer='zeros',depthwise_regularizer=None,pointwise_regularizer=None,bias_regularizer=None,activity_regularizer=None,depthwise_constraint=None,pointwise_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.separable_conv1d.SeparableConv1D.call(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/base_conv.py----------------------------------------
A:keras.layers.convolutional.base_conv.filters->int(filters)
A:keras.layers.convolutional.base_conv.self.kernel_size->keras.utils.conv_utils.normalize_tuple(kernel_size, rank, 'kernel_size')
A:keras.layers.convolutional.base_conv.self.strides->keras.utils.conv_utils.normalize_tuple(strides, rank, 'strides', allow_zero=True)
A:keras.layers.convolutional.base_conv.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.convolutional.base_conv.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.convolutional.base_conv.self.dilation_rate->keras.utils.conv_utils.normalize_tuple(dilation_rate, rank, 'dilation_rate')
A:keras.layers.convolutional.base_conv.self.activation->keras.activations.get(activation)
A:keras.layers.convolutional.base_conv.self.kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.convolutional.base_conv.self.bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.convolutional.base_conv.self.kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.convolutional.base_conv.self.bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.convolutional.base_conv.self.kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.convolutional.base_conv.self.bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.convolutional.base_conv.self.input_spec->InputSpec(min_ndim=self.rank + 2, axes={channel_axis: input_channel})
A:keras.layers.convolutional.base_conv.self._tf_data_format->keras.utils.conv_utils.convert_data_format(self.data_format, self.rank + 2)
A:keras.layers.convolutional.base_conv.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.convolutional.base_conv.input_channel->self._get_input_channel(input_shape)
A:keras.layers.convolutional.base_conv.self.kernel->self.add_weight(name='kernel', shape=kernel_shape, initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.base_conv.self.bias->self.add_weight(name='bias', shape=(self.filters,), initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.base_conv.channel_axis->self._get_channel_axis()
A:keras.layers.convolutional.base_conv.tf_padding->self.padding.upper()
A:keras.layers.convolutional.base_conv.inputs->tensorflow.compat.v2.pad(inputs, self._compute_causal_padding(inputs))
A:keras.layers.convolutional.base_conv.outputs->tensorflow.compat.v2.nn.bias_add(outputs, self.bias, data_format=self._tf_data_format)
A:keras.layers.convolutional.base_conv.bias->tensorflow.compat.v2.reshape(self.bias, (1, self.filters, 1))
A:keras.layers.convolutional.base_conv.out_shape->self.compute_output_shape(input_shape)
A:keras.layers.convolutional.base_conv.base_config->super(Conv, self).get_config()
A:keras.layers.convolutional.base_conv.op_padding->op_padding.upper().upper()
keras.layers.convolutional.base_conv.Conv(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,conv_op=None,**kwargs)
keras.layers.convolutional.base_conv.Conv.__init__(self,rank,filters,kernel_size,strides=1,padding='valid',data_format=None,dilation_rate=1,groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,trainable=True,name=None,conv_op=None,**kwargs)
keras.layers.convolutional.base_conv.Conv._compute_causal_padding(self,inputs)
keras.layers.convolutional.base_conv.Conv._get_channel_axis(self)
keras.layers.convolutional.base_conv.Conv._get_input_channel(self,input_shape)
keras.layers.convolutional.base_conv.Conv._get_padding_op(self)
keras.layers.convolutional.base_conv.Conv._jit_compiled_convolution_op(self,inputs,kernel)
keras.layers.convolutional.base_conv.Conv._recreate_conv_op(self,inputs)
keras.layers.convolutional.base_conv.Conv._spatial_output_shape(self,spatial_input_shape)
keras.layers.convolutional.base_conv.Conv._validate_init(self)
keras.layers.convolutional.base_conv.Conv.build(self,input_shape)
keras.layers.convolutional.base_conv.Conv.call(self,inputs)
keras.layers.convolutional.base_conv.Conv.compute_output_shape(self,input_shape)
keras.layers.convolutional.base_conv.Conv.convolution_op(self,inputs,kernel)
keras.layers.convolutional.base_conv.Conv.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/conv1d_transpose.py----------------------------------------
A:keras.layers.convolutional.conv1d_transpose.self.output_padding->keras.utils.conv_utils.normalize_tuple(self.output_padding, 1, 'output_padding', allow_zero=True)
A:keras.layers.convolutional.conv1d_transpose.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.convolutional.conv1d_transpose.channel_axis->self._get_channel_axis()
A:keras.layers.convolutional.conv1d_transpose.input_dim->int(input_shape[channel_axis])
A:keras.layers.convolutional.conv1d_transpose.self.input_spec->InputSpec(ndim=3, axes={channel_axis: input_dim})
A:keras.layers.convolutional.conv1d_transpose.self.kernel->self.add_weight(name='kernel', shape=kernel_shape, initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.conv1d_transpose.self.bias->self.add_weight(name='bias', shape=(self.filters,), initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.conv1d_transpose.inputs_shape->tensorflow.compat.v2.shape(inputs)
A:keras.layers.convolutional.conv1d_transpose.out_length->keras.utils.conv_utils.deconv_output_length(length, self.kernel_size[0], padding=self.padding, output_padding=output_padding, stride=self.strides[0], dilation=self.dilation_rate[0])
A:keras.layers.convolutional.conv1d_transpose.data_format->keras.utils.conv_utils.convert_data_format(self.data_format, ndim=3)
A:keras.layers.convolutional.conv1d_transpose.output_shape_tensor->tensorflow.compat.v2.stack(output_shape)
A:keras.layers.convolutional.conv1d_transpose.outputs->tensorflow.compat.v2.nn.bias_add(outputs, self.bias, data_format=data_format)
A:keras.layers.convolutional.conv1d_transpose.out_shape->self.compute_output_shape(inputs.shape)
A:keras.layers.convolutional.conv1d_transpose.output_shape->list(input_shape)
A:keras.layers.convolutional.conv1d_transpose.output_shape[t_axis]->keras.utils.conv_utils.deconv_output_length(output_shape[t_axis], self.kernel_size[0], padding=self.padding, output_padding=output_padding, stride=self.strides[0], dilation=self.dilation_rate[0])
A:keras.layers.convolutional.conv1d_transpose.config->super(Conv1DTranspose, self).get_config()
keras.layers.convolutional.Conv1DTranspose(self,filters,kernel_size,strides=1,padding='valid',output_padding=None,data_format=None,dilation_rate=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.Conv1DTranspose.build(self,input_shape)
keras.layers.convolutional.Conv1DTranspose.call(self,inputs)
keras.layers.convolutional.Conv1DTranspose.compute_output_shape(self,input_shape)
keras.layers.convolutional.Conv1DTranspose.get_config(self)
keras.layers.convolutional.conv1d_transpose.Conv1DTranspose(self,filters,kernel_size,strides=1,padding='valid',output_padding=None,data_format=None,dilation_rate=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv1d_transpose.Conv1DTranspose.__init__(self,filters,kernel_size,strides=1,padding='valid',output_padding=None,data_format=None,dilation_rate=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv1d_transpose.Conv1DTranspose.build(self,input_shape)
keras.layers.convolutional.conv1d_transpose.Conv1DTranspose.call(self,inputs)
keras.layers.convolutional.conv1d_transpose.Conv1DTranspose.compute_output_shape(self,input_shape)
keras.layers.convolutional.conv1d_transpose.Conv1DTranspose.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/conv3d_transpose.py----------------------------------------
A:keras.layers.convolutional.conv3d_transpose.self.output_padding->keras.utils.conv_utils.normalize_tuple(self.output_padding, 3, 'output_padding', allow_zero=True)
A:keras.layers.convolutional.conv3d_transpose.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.convolutional.conv3d_transpose.channel_axis->self._get_channel_axis()
A:keras.layers.convolutional.conv3d_transpose.input_dim->int(input_shape[channel_axis])
A:keras.layers.convolutional.conv3d_transpose.self.input_spec->InputSpec(ndim=5, axes={channel_axis: input_dim})
A:keras.layers.convolutional.conv3d_transpose.self.kernel->self.add_weight('kernel', shape=kernel_shape, initializer=self.kernel_initializer, regularizer=self.kernel_regularizer, constraint=self.kernel_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.conv3d_transpose.self.bias->self.add_weight('bias', shape=(self.filters,), initializer=self.bias_initializer, regularizer=self.bias_regularizer, constraint=self.bias_constraint, trainable=True, dtype=self.dtype)
A:keras.layers.convolutional.conv3d_transpose.inputs_shape->tensorflow.compat.v2.shape(inputs)
A:keras.layers.convolutional.conv3d_transpose.out_depth->keras.utils.conv_utils.deconv_output_length(depth, kernel_d, padding=self.padding, output_padding=out_pad_d, stride=stride_d)
A:keras.layers.convolutional.conv3d_transpose.out_height->keras.utils.conv_utils.deconv_output_length(height, kernel_h, padding=self.padding, output_padding=out_pad_h, stride=stride_h)
A:keras.layers.convolutional.conv3d_transpose.out_width->keras.utils.conv_utils.deconv_output_length(width, kernel_w, padding=self.padding, output_padding=out_pad_w, stride=stride_w)
A:keras.layers.convolutional.conv3d_transpose.output_shape_tensor->tensorflow.compat.v2.stack(output_shape)
A:keras.layers.convolutional.conv3d_transpose.outputs->tensorflow.compat.v2.nn.bias_add(outputs, self.bias, data_format=conv_utils.convert_data_format(self.data_format, ndim=4))
A:keras.layers.convolutional.conv3d_transpose.out_shape->self.compute_output_shape(inputs.shape)
A:keras.layers.convolutional.conv3d_transpose.output_shape->list(input_shape)
A:keras.layers.convolutional.conv3d_transpose.output_shape[d_axis]->keras.utils.conv_utils.deconv_output_length(output_shape[d_axis], kernel_d, padding=self.padding, output_padding=out_pad_d, stride=stride_d)
A:keras.layers.convolutional.conv3d_transpose.output_shape[h_axis]->keras.utils.conv_utils.deconv_output_length(output_shape[h_axis], kernel_h, padding=self.padding, output_padding=out_pad_h, stride=stride_h)
A:keras.layers.convolutional.conv3d_transpose.output_shape[w_axis]->keras.utils.conv_utils.deconv_output_length(output_shape[w_axis], kernel_w, padding=self.padding, output_padding=out_pad_w, stride=stride_w)
A:keras.layers.convolutional.conv3d_transpose.config->super(Conv3DTranspose, self).get_config()
keras.layers.convolutional.Conv3DTranspose(self,filters,kernel_size,strides=(1,1,1),padding='valid',output_padding=None,data_format=None,dilation_rate=(1,1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.Conv3DTranspose.build(self,input_shape)
keras.layers.convolutional.Conv3DTranspose.call(self,inputs)
keras.layers.convolutional.Conv3DTranspose.compute_output_shape(self,input_shape)
keras.layers.convolutional.Conv3DTranspose.get_config(self)
keras.layers.convolutional.conv3d_transpose.Conv3DTranspose(self,filters,kernel_size,strides=(1,1,1),padding='valid',output_padding=None,data_format=None,dilation_rate=(1,1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv3d_transpose.Conv3DTranspose.__init__(self,filters,kernel_size,strides=(1,1,1),padding='valid',output_padding=None,data_format=None,dilation_rate=(1,1,1),activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv3d_transpose.Conv3DTranspose.build(self,input_shape)
keras.layers.convolutional.conv3d_transpose.Conv3DTranspose.call(self,inputs)
keras.layers.convolutional.conv3d_transpose.Conv3DTranspose.compute_output_shape(self,input_shape)
keras.layers.convolutional.conv3d_transpose.Conv3DTranspose.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/convolutional/conv1d.py----------------------------------------
keras.layers.convolutional.Conv1D(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv1d.Conv1D(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.convolutional.conv1d.Conv1D.__init__(self,filters,kernel_size,strides=1,padding='valid',data_format='channels_last',dilation_rate=1,groups=1,activation=None,use_bias=True,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/normalization/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/normalization/unit_normalization.py----------------------------------------
A:keras.layers.normalization.unit_normalization.self.axis->keras.utils.tf_utils.validate_axis(self.axis, input_shape)
A:keras.layers.normalization.unit_normalization.inputs->tensorflow.compat.v2.cast(inputs, self.compute_dtype)
A:keras.layers.normalization.unit_normalization.config->super(UnitNormalization, self).get_config()
keras.layers.UnitNormalization(self,axis=-1,**kwargs)
keras.layers.UnitNormalization.build(self,input_shape)
keras.layers.UnitNormalization.call(self,inputs)
keras.layers.UnitNormalization.compute_output_shape(self,input_shape)
keras.layers.UnitNormalization.get_config(self)
keras.layers.normalization.unit_normalization.UnitNormalization(self,axis=-1,**kwargs)
keras.layers.normalization.unit_normalization.UnitNormalization.__init__(self,axis=-1,**kwargs)
keras.layers.normalization.unit_normalization.UnitNormalization.build(self,input_shape)
keras.layers.normalization.unit_normalization.UnitNormalization.call(self,inputs)
keras.layers.normalization.unit_normalization.UnitNormalization.compute_output_shape(self,input_shape)
keras.layers.normalization.unit_normalization.UnitNormalization.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/normalization/batch_normalization_v1.py----------------------------------------
keras.layers.BatchNormalization(batch_normalization.BatchNormalizationBase)
keras.layers.normalization.batch_normalization_v1.BatchNormalization(batch_normalization.BatchNormalizationBase)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/normalization/layer_normalization.py----------------------------------------
A:keras.layers.normalization.layer_normalization.self.axis->keras.utils.tf_utils.validate_axis(self.axis, input_shape)
A:keras.layers.normalization.layer_normalization.self.beta_initializer->keras.initializers.get(beta_initializer)
A:keras.layers.normalization.layer_normalization.self.gamma_initializer->keras.initializers.get(gamma_initializer)
A:keras.layers.normalization.layer_normalization.self.beta_regularizer->keras.regularizers.get(beta_regularizer)
A:keras.layers.normalization.layer_normalization.self.gamma_regularizer->keras.regularizers.get(gamma_regularizer)
A:keras.layers.normalization.layer_normalization.self.beta_constraint->keras.constraints.get(beta_constraint)
A:keras.layers.normalization.layer_normalization.self.gamma_constraint->keras.constraints.get(gamma_constraint)
A:keras.layers.normalization.layer_normalization.axis->sorted(self.axis)
A:keras.layers.normalization.layer_normalization.input_shape->tensorflow.compat.v2.TensorShape(input_shape)
A:keras.layers.normalization.layer_normalization.self.gamma->self.add_weight(name='gamma', shape=param_shape, initializer=self.gamma_initializer, regularizer=self.gamma_regularizer, constraint=self.gamma_constraint, trainable=True, experimental_autocast=False)
A:keras.layers.normalization.layer_normalization.self.beta->self.add_weight(name='beta', shape=param_shape, initializer=self.beta_initializer, regularizer=self.beta_regularizer, constraint=self.beta_constraint, trainable=True, experimental_autocast=False)
A:keras.layers.normalization.layer_normalization.self._fused->self._fused_can_be_used(rank)
A:keras.layers.normalization.layer_normalization.inputs->tensorflow.compat.v2.reshape(inputs, squeezed_shape)
A:keras.layers.normalization.layer_normalization.ndims->len(input_shape)
A:keras.layers.normalization.layer_normalization.(mean, variance)->tensorflow.compat.v2.nn.moments(inputs, self.axis, keepdims=True)
A:keras.layers.normalization.layer_normalization.outputs->tensorflow.compat.v2.reshape(outputs, tensor_shape)
A:keras.layers.normalization.layer_normalization.tensor_shape->tensorflow.compat.v2.shape(inputs)
A:keras.layers.normalization.layer_normalization.scale->tensorflow.compat.v2.ones([pre_dim], dtype=self.dtype)
A:keras.layers.normalization.layer_normalization.offset->tensorflow.compat.v2.zeros([pre_dim], dtype=self.dtype)
A:keras.layers.normalization.layer_normalization.(outputs, _, _)->tensorflow.compat.v2.compat.v1.nn.fused_batch_norm(inputs, scale=scale, offset=offset, epsilon=self.epsilon, data_format=data_format)
A:keras.layers.normalization.layer_normalization.base_config->super(LayerNormalization, self).get_config()
keras.layers.LayerNormalization(self,axis=-1,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.LayerNormalization._fused_can_be_used(self,ndims)
keras.layers.LayerNormalization.build(self,input_shape)
keras.layers.LayerNormalization.call(self,inputs)
keras.layers.LayerNormalization.compute_output_shape(self,input_shape)
keras.layers.LayerNormalization.get_config(self)
keras.layers.normalization.layer_normalization.LayerNormalization(self,axis=-1,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.normalization.layer_normalization.LayerNormalization.__init__(self,axis=-1,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.normalization.layer_normalization.LayerNormalization._fused_can_be_used(self,ndims)
keras.layers.normalization.layer_normalization.LayerNormalization.build(self,input_shape)
keras.layers.normalization.layer_normalization.LayerNormalization.call(self,inputs)
keras.layers.normalization.layer_normalization.LayerNormalization.compute_output_shape(self,input_shape)
keras.layers.normalization.layer_normalization.LayerNormalization.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/normalization/batch_normalization.py----------------------------------------
A:keras.layers.normalization.batch_normalization.self.beta_initializer->keras.initializers.get(beta_initializer)
A:keras.layers.normalization.batch_normalization.self.gamma_initializer->keras.initializers.get(gamma_initializer)
A:keras.layers.normalization.batch_normalization.self.moving_mean_initializer->keras.initializers.get(moving_mean_initializer)
A:keras.layers.normalization.batch_normalization.self.moving_variance_initializer->keras.initializers.get(moving_variance_initializer)
A:keras.layers.normalization.batch_normalization.self.beta_regularizer->keras.regularizers.get(beta_regularizer)
A:keras.layers.normalization.batch_normalization.self.gamma_regularizer->keras.regularizers.get(gamma_regularizer)
A:keras.layers.normalization.batch_normalization.self.beta_constraint->keras.constraints.get(beta_constraint)
A:keras.layers.normalization.batch_normalization.self.gamma_constraint->keras.constraints.get(gamma_constraint)
A:keras.layers.normalization.batch_normalization.strategy->tensorflow.compat.v2.distribute.get_strategy()
A:keras.layers.normalization.batch_normalization.self.axis->keras.utils.tf_utils.validate_axis(self.axis, input_shape)
A:keras.layers.normalization.batch_normalization.input_shape->tensorflow.compat.v2.TensorShape(input_shape)
A:keras.layers.normalization.batch_normalization.self.input_spec->InputSpec(ndim=rank, axes=axis_to_dim)
A:keras.layers.normalization.batch_normalization.self.gamma->self.add_weight(name='gamma', shape=param_shape, dtype=self._param_dtype, initializer=self.gamma_initializer, regularizer=self.gamma_regularizer, constraint=self.gamma_constraint, trainable=True, experimental_autocast=False)
A:keras.layers.normalization.batch_normalization.self._gamma_const->keras.backend.constant(1.0, dtype=self._param_dtype, shape=param_shape)
A:keras.layers.normalization.batch_normalization.self.beta->self.add_weight(name='beta', shape=param_shape, dtype=self._param_dtype, initializer=self.beta_initializer, regularizer=self.beta_regularizer, constraint=self.beta_constraint, trainable=True, experimental_autocast=False)
A:keras.layers.normalization.batch_normalization.self._beta_const->keras.backend.constant(0.0, dtype=self._param_dtype, shape=param_shape)
A:keras.layers.normalization.batch_normalization.self.moving_mean->self.add_weight(name='moving_mean', shape=param_shape, dtype=self._param_dtype, initializer=self.moving_mean_initializer, synchronization=tf.VariableSynchronization.ON_READ, trainable=False, aggregation=tf.VariableAggregation.MEAN, experimental_autocast=False)
A:keras.layers.normalization.batch_normalization.self.moving_variance->self.add_weight(name='moving_variance', shape=param_shape, dtype=self._param_dtype, initializer=self.moving_variance_initializer, synchronization=tf.VariableSynchronization.ON_READ, trainable=False, aggregation=tf.VariableAggregation.MEAN, experimental_autocast=False)
A:keras.layers.normalization.batch_normalization.self.moving_stddev->self.add_weight(name='moving_stddev', shape=param_shape, dtype=self._param_dtype, initializer=moving_stddev_initializer, synchronization=tf.VariableSynchronization.ON_READ, trainable=False, aggregation=tf.VariableAggregation.MEAN, experimental_autocast=False)
A:keras.layers.normalization.batch_normalization.var->self.add_weight(name=name, shape=shape, dtype=self._param_dtype, initializer=initializer, synchronization=tf.VariableSynchronization.ON_READ, trainable=False, aggregation=tf.VariableAggregation.MEAN, experimental_autocast=False)
A:keras.layers.normalization.batch_normalization.self.renorm_mean->_renorm_variable('renorm_mean', param_shape, self.moving_mean_initializer)
A:keras.layers.normalization.batch_normalization.self.renorm_stddev->_renorm_variable('renorm_stddev', param_shape, moving_stddev_initializer)
A:keras.layers.normalization.batch_normalization.decay->tensorflow.compat.v2.cast(decay, variable.dtype.base_dtype)
A:keras.layers.normalization.batch_normalization.update_delta->tensorflow.compat.v2.where(inputs_size > 0, update_delta, backend.zeros_like(update_delta))
A:keras.layers.normalization.batch_normalization.sample_size->tensorflow.compat.v2.cast(tf.size(inputs) / tf.size(variance), variance.dtype)
A:keras.layers.normalization.batch_normalization.(output, mean, variance)->keras.utils.control_flow_util.smart_cond(training, _fused_batch_norm_training, _fused_batch_norm_inference)
A:keras.layers.normalization.batch_normalization.variance->tensorflow.compat.v2.squeeze(variance, axes)
A:keras.layers.normalization.batch_normalization.training_value->keras.utils.control_flow_util.constant_value(training)
A:keras.layers.normalization.batch_normalization.momentum->tensorflow.compat.v2.convert_to_tensor(self.momentum)
A:keras.layers.normalization.batch_normalization.new_mean->tensorflow.compat.v2.reduce_mean(mean, axis=1, keepdims=True)
A:keras.layers.normalization.batch_normalization.new_variance->tensorflow.compat.v2.reduce_mean(variance, axis=1, keepdims=True)
A:keras.layers.normalization.batch_normalization.stddev->tensorflow.compat.v2.identity(stddev)
A:keras.layers.normalization.batch_normalization.renorm_stddev->tensorflow.compat.v2.maximum(self.renorm_stddev, tf.sqrt(self.epsilon))
A:keras.layers.normalization.batch_normalization.mean->tensorflow.compat.v2.squeeze(mean, axes)
A:keras.layers.normalization.batch_normalization.r->_broadcast(tf.stop_gradient(r, name='renorm_r'))
A:keras.layers.normalization.batch_normalization.d->_broadcast(tf.stop_gradient(d, name='renorm_d'))
A:keras.layers.normalization.batch_normalization.value->tensorflow.compat.v2.identity(value)
A:keras.layers.normalization.batch_normalization.new_var->self._assign_moving_average(var, value, self.renorm_momentum, inputs_size)
A:keras.layers.normalization.batch_normalization.update_new_mean->_update_renorm_variable(self.renorm_mean, mean, inputs_size)
A:keras.layers.normalization.batch_normalization.update_new_stddev->_update_renorm_variable(self.renorm_stddev, stddev, inputs_size)
A:keras.layers.normalization.batch_normalization.out_mean->tensorflow.compat.v2.identity(mean)
A:keras.layers.normalization.batch_normalization.out_variance->tensorflow.compat.v2.identity(variance)
A:keras.layers.normalization.batch_normalization.(mean, variance)->self._moments(tf.cast(inputs, self._param_dtype), reduction_axes, keep_dims=keep_dims)
A:keras.layers.normalization.batch_normalization.training->self._get_training_value(training)
A:keras.layers.normalization.batch_normalization.inputs->tensorflow.compat.v2.cast(inputs, tf.float32)
A:keras.layers.normalization.batch_normalization.original_shape->tensorflow.compat.v2.concat([tf.constant([-1]), original_shape[1:]], axis=0)
A:keras.layers.normalization.batch_normalization.expanded_shape->tensorflow.compat.v2.concat([tf.constant([self.virtual_batch_size, -1]), original_shape[1:]], axis=0)
A:keras.layers.normalization.batch_normalization.outputs->undo_virtual_batching(outputs)
A:keras.layers.normalization.batch_normalization.ndims->len(input_shape)
A:keras.layers.normalization.batch_normalization.(adj_scale, adj_bias)->self.adjustment(tf.shape(inputs))
A:keras.layers.normalization.batch_normalization.adj_scale->keras.utils.control_flow_util.smart_cond(training, lambda : adj_scale, lambda : tf.ones_like(adj_scale))
A:keras.layers.normalization.batch_normalization.adj_bias->keras.utils.control_flow_util.smart_cond(training, lambda : adj_bias, lambda : tf.zeros_like(adj_bias))
A:keras.layers.normalization.batch_normalization.(scale, offset)->_compose_transforms(r, d, scale, offset)
A:keras.layers.normalization.batch_normalization.(r, d, new_mean, new_variance)->self._renorm_correction_and_moments(new_mean, new_variance, training, input_batch_size)
A:keras.layers.normalization.batch_normalization.moving_stddev->_do_update(self.moving_stddev, tf.sqrt(new_variance + self.epsilon))
A:keras.layers.normalization.batch_normalization.offset->tensorflow.compat.v2.cast(offset, inputs.dtype)
A:keras.layers.normalization.batch_normalization.scale->tensorflow.compat.v2.cast(scale, inputs.dtype)
A:keras.layers.normalization.batch_normalization.base_config->super(BatchNormalizationBase, self).get_config()
A:keras.layers.normalization.batch_normalization.replica_ctx->tensorflow.compat.v2.distribute.get_replica_context()
A:keras.layers.normalization.batch_normalization.local_sum->tensorflow.compat.v2.reduce_sum(y, axis=axes, keepdims=True)
A:keras.layers.normalization.batch_normalization.local_squared_sum->tensorflow.compat.v2.reduce_sum(tf.square(y), axis=axes, keepdims=True)
A:keras.layers.normalization.batch_normalization.batch_size->tensorflow.compat.v2.cast(tf.shape(y)[axes[0]], tf.float32)
A:keras.layers.normalization.batch_normalization.y_sum->tensorflow.compat.v2.distribute.get_replica_context().all_reduce(tf.distribute.ReduceOp.SUM, local_sum)
A:keras.layers.normalization.batch_normalization.y_squared_sum->tensorflow.compat.v2.distribute.get_replica_context().all_reduce(tf.distribute.ReduceOp.SUM, local_squared_sum)
A:keras.layers.normalization.batch_normalization.global_batch_size->tensorflow.compat.v2.distribute.get_replica_context().all_reduce(tf.distribute.ReduceOp.SUM, batch_size)
A:keras.layers.normalization.batch_normalization.multiplier->tensorflow.compat.v2.cast(tf.reduce_prod(axes_vals), tf.float32)
keras.layers.BatchNormalizationV2(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.BatchNormalizationV2Base(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,renorm=False,renorm_clipping=None,renorm_momentum=0.99,fused=None,trainable=True,virtual_batch_size=None,adjustment=None,name=None,**kwargs)
keras.layers.BatchNormalizationV2Base._assign_moving_average(self,variable,value,momentum,inputs_size)
keras.layers.BatchNormalizationV2Base._assign_new_value(self,variable,value)
keras.layers.BatchNormalizationV2Base._calculate_mean_and_var(self,inputs,reduction_axes,keep_dims)
keras.layers.BatchNormalizationV2Base._fused_batch_norm(self,inputs,training)
keras.layers.BatchNormalizationV2Base._fused_can_be_used(self)
keras.layers.BatchNormalizationV2Base._get_training_value(self,training=None)
keras.layers.BatchNormalizationV2Base._moments(self,inputs,reduction_axes,keep_dims)
keras.layers.BatchNormalizationV2Base._param_dtype(self)
keras.layers.BatchNormalizationV2Base._raise_if_fused_cannot_be_used(self)
keras.layers.BatchNormalizationV2Base._renorm_correction_and_moments(self,mean,variance,training,inputs_size)
keras.layers.BatchNormalizationV2Base._support_zero_size_input(self)
keras.layers.BatchNormalizationV2Base.build(self,input_shape)
keras.layers.BatchNormalizationV2Base.call(self,inputs,training=None)
keras.layers.BatchNormalizationV2Base.compute_output_shape(self,input_shape)
keras.layers.BatchNormalizationV2Base.get_config(self)
keras.layers.BatchNormalizationV2Base.trainable(self)
keras.layers.BatchNormalizationV2Base.trainable(self,value)
keras.layers.SyncBatchNormalization(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.SyncBatchNormalization._calculate_mean_and_var(self,x,axes,keep_dims)
keras.layers.normalization.batch_normalization.BatchNormalization(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.normalization.batch_normalization.BatchNormalization.__init__(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.normalization.batch_normalization.BatchNormalizationBase(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,renorm=False,renorm_clipping=None,renorm_momentum=0.99,fused=None,trainable=True,virtual_batch_size=None,adjustment=None,name=None,**kwargs)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.__init__(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,renorm=False,renorm_clipping=None,renorm_momentum=0.99,fused=None,trainable=True,virtual_batch_size=None,adjustment=None,name=None,**kwargs)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._assign_moving_average(self,variable,value,momentum,inputs_size)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._assign_new_value(self,variable,value)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._calculate_mean_and_var(self,inputs,reduction_axes,keep_dims)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._fused_batch_norm(self,inputs,training)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._fused_can_be_used(self)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._get_training_value(self,training=None)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._moments(self,inputs,reduction_axes,keep_dims)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._param_dtype(self)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._raise_if_fused_cannot_be_used(self)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._renorm_correction_and_moments(self,mean,variance,training,inputs_size)
keras.layers.normalization.batch_normalization.BatchNormalizationBase._support_zero_size_input(self)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.build(self,input_shape)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.call(self,inputs,training=None)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.compute_output_shape(self,input_shape)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.get_config(self)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.trainable(self)
keras.layers.normalization.batch_normalization.BatchNormalizationBase.trainable(self,value)
keras.layers.normalization.batch_normalization.SyncBatchNormalization(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.normalization.batch_normalization.SyncBatchNormalization.__init__(self,axis=-1,momentum=0.99,epsilon=0.001,center=True,scale=True,beta_initializer='zeros',gamma_initializer='ones',moving_mean_initializer='zeros',moving_variance_initializer='ones',beta_regularizer=None,gamma_regularizer=None,beta_constraint=None,gamma_constraint=None,**kwargs)
keras.layers.normalization.batch_normalization.SyncBatchNormalization._calculate_mean_and_var(self,x,axes,keep_dims)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/attention/attention.py----------------------------------------
A:keras.layers.attention.attention.self.scale->self.add_weight(name='scale', shape=(), initializer='ones', dtype=self.dtype, trainable=True)
A:keras.layers.attention.attention.self.concat_score_weight->self.add_weight(name='concat_score_weight', shape=(), initializer='ones', dtype=self.dtype, trainable=True)
A:keras.layers.attention.attention.scores->tensorflow.compat.v2.matmul(query, key, transpose_b=True)
A:keras.layers.attention.attention.q_reshaped->tensorflow.compat.v2.expand_dims(query, axis=-2)
A:keras.layers.attention.attention.k_reshaped->tensorflow.compat.v2.expand_dims(key, axis=-3)
A:keras.layers.attention.attention.base_config->super(Attention, self).get_config()
keras.layers.attention.Attention(self,use_scale=False,score_mode='dot',**kwargs)
keras.layers.attention.Attention._calculate_scores(self,query,key)
keras.layers.attention.Attention.build(self,input_shape)
keras.layers.attention.Attention.get_config(self)
keras.layers.attention.attention.Attention(self,use_scale=False,score_mode='dot',**kwargs)
keras.layers.attention.attention.Attention.__init__(self,use_scale=False,score_mode='dot',**kwargs)
keras.layers.attention.attention.Attention._calculate_scores(self,query,key)
keras.layers.attention.attention.Attention.build(self,input_shape)
keras.layers.attention.attention.Attention.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/attention/multi_head_attention.py----------------------------------------
A:keras.layers.attention.multi_head_attention.batch_dims->tuple(np.delete(range(rank), attn_axes + (rank - 1,)))
A:keras.layers.attention.multi_head_attention.product_notation->''.join([target_notation[i] for i in batch_dims] + [target_notation[i] for i in attn_axes] + [source_notation[i] for i in attn_axes])
A:keras.layers.attention.multi_head_attention.attn_scores_rank->len(product_notation)
A:keras.layers.attention.multi_head_attention.self._kernel_initializer->keras.initializers.get(kernel_initializer)
A:keras.layers.attention.multi_head_attention.self._bias_initializer->keras.initializers.get(bias_initializer)
A:keras.layers.attention.multi_head_attention.self._kernel_regularizer->keras.regularizers.get(kernel_regularizer)
A:keras.layers.attention.multi_head_attention.self._bias_regularizer->keras.regularizers.get(bias_regularizer)
A:keras.layers.attention.multi_head_attention.self._activity_regularizer->keras.regularizers.get(activity_regularizer)
A:keras.layers.attention.multi_head_attention.self._kernel_constraint->keras.constraints.get(kernel_constraint)
A:keras.layers.attention.multi_head_attention.self._bias_constraint->keras.constraints.get(bias_constraint)
A:keras.layers.attention.multi_head_attention.base_config->super(MultiHeadAttention, self).get_config()
A:keras.layers.attention.multi_head_attention.query_shape->config.pop('query_shape')
A:keras.layers.attention.multi_head_attention.key_shape->config.pop('key_shape')
A:keras.layers.attention.multi_head_attention.value_shape->config.pop('value_shape')
A:keras.layers.attention.multi_head_attention.layer->cls(**config)
A:keras.layers.attention.multi_head_attention.self._query_shape->tensorflow.compat.v2.TensorShape(query)
A:keras.layers.attention.multi_head_attention.self._value_shape->tensorflow.compat.v2.TensorShape(value)
A:keras.layers.attention.multi_head_attention.self._key_shape->tensorflow.compat.v2.TensorShape(key)
A:keras.layers.attention.multi_head_attention.common_kwargs->dict(kernel_initializer=self._kernel_initializer, bias_initializer=self._bias_initializer, kernel_regularizer=self._kernel_regularizer, bias_regularizer=self._bias_regularizer, activity_regularizer=self._activity_regularizer, kernel_constraint=self._kernel_constraint, bias_constraint=self._bias_constraint)
A:keras.layers.attention.multi_head_attention.(einsum_equation, bias_axes, output_rank)->_build_proj_equation(free_dims, bound_dims=2, output_dims=len(output_shape))
A:keras.layers.attention.multi_head_attention.self._query_dense->keras.layers.einsum_dense.EinsumDense(einsum_equation, output_shape=_get_output_shape(output_rank - 1, [self._num_heads, self._key_dim]), bias_axes=bias_axes if self._use_bias else None, name='query', **common_kwargs)
A:keras.layers.attention.multi_head_attention.self._key_dense->keras.layers.einsum_dense.EinsumDense(einsum_equation, output_shape=_get_output_shape(output_rank - 1, [self._num_heads, self._key_dim]), bias_axes=bias_axes if self._use_bias else None, name='key', **common_kwargs)
A:keras.layers.attention.multi_head_attention.self._value_dense->keras.layers.einsum_dense.EinsumDense(einsum_equation, output_shape=_get_output_shape(output_rank - 1, [self._num_heads, self._value_dim]), bias_axes=bias_axes if self._use_bias else None, name='value', **common_kwargs)
A:keras.layers.attention.multi_head_attention.self._output_dense->self._make_output_dense(free_dims, common_kwargs, 'attention_output')
A:keras.layers.attention.multi_head_attention.self._attention_axes->tuple(self._attention_axes)
A:keras.layers.attention.multi_head_attention.(self._dot_product_equation, self._combine_equation, attn_scores_rank)->_build_attention_equation(rank, attn_axes=self._attention_axes)
A:keras.layers.attention.multi_head_attention.norm_axes->tuple(range(attn_scores_rank - len(self._attention_axes), attn_scores_rank))
A:keras.layers.attention.multi_head_attention.self._softmax->keras.layers.activation.Softmax(axis=norm_axes)
A:keras.layers.attention.multi_head_attention.self._dropout_layer->keras.layers.regularization.Dropout(rate=self._dropout)
A:keras.layers.attention.multi_head_attention.attention_mask->tensorflow.compat.v2.expand_dims(attention_mask, axis=mask_expansion_axis)
A:keras.layers.attention.multi_head_attention.query->self._query_dense(query)
A:keras.layers.attention.multi_head_attention.attention_scores->self._masked_softmax(attention_scores, attention_mask)
A:keras.layers.attention.multi_head_attention.attention_scores_dropout->self._dropout_layer(attention_scores, training=training)
A:keras.layers.attention.multi_head_attention.attention_output->self._output_dense(attention_output)
A:keras.layers.attention.multi_head_attention.key->self._key_dense(key)
A:keras.layers.attention.multi_head_attention.value->self._value_dense(value)
A:keras.layers.attention.multi_head_attention.(attention_output, attention_scores)->self._compute_attention(query, key, value, attention_mask, training)
keras.layers.attention.MultiHeadAttention(self,num_heads,key_dim,value_dim=None,dropout=0.0,use_bias=True,output_shape=None,attention_axes=None,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.attention.MultiHeadAttention._build_attention(self,rank)
keras.layers.attention.MultiHeadAttention._build_from_signature(self,query,value,key=None)
keras.layers.attention.MultiHeadAttention._compute_attention(self,query,key,value,attention_mask=None,training=None)
keras.layers.attention.MultiHeadAttention._make_output_dense(self,free_dims,common_kwargs,name=None)
keras.layers.attention.MultiHeadAttention._masked_softmax(self,attention_scores,attention_mask=None)
keras.layers.attention.MultiHeadAttention.call(self,query,value,key=None,attention_mask=None,return_attention_scores=False,training=None)
keras.layers.attention.MultiHeadAttention.from_config(cls,config)
keras.layers.attention.MultiHeadAttention.get_config(self)
keras.layers.attention.multi_head_attention.MultiHeadAttention(self,num_heads,key_dim,value_dim=None,dropout=0.0,use_bias=True,output_shape=None,attention_axes=None,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.attention.multi_head_attention.MultiHeadAttention.__init__(self,num_heads,key_dim,value_dim=None,dropout=0.0,use_bias=True,output_shape=None,attention_axes=None,kernel_initializer='glorot_uniform',bias_initializer='zeros',kernel_regularizer=None,bias_regularizer=None,activity_regularizer=None,kernel_constraint=None,bias_constraint=None,**kwargs)
keras.layers.attention.multi_head_attention.MultiHeadAttention._build_attention(self,rank)
keras.layers.attention.multi_head_attention.MultiHeadAttention._build_from_signature(self,query,value,key=None)
keras.layers.attention.multi_head_attention.MultiHeadAttention._compute_attention(self,query,key,value,attention_mask=None,training=None)
keras.layers.attention.multi_head_attention.MultiHeadAttention._make_output_dense(self,free_dims,common_kwargs,name=None)
keras.layers.attention.multi_head_attention.MultiHeadAttention._masked_softmax(self,attention_scores,attention_mask=None)
keras.layers.attention.multi_head_attention.MultiHeadAttention.call(self,query,value,key=None,attention_mask=None,return_attention_scores=False,training=None)
keras.layers.attention.multi_head_attention.MultiHeadAttention.from_config(cls,config)
keras.layers.attention.multi_head_attention.MultiHeadAttention.get_config(self)
keras.layers.attention.multi_head_attention._build_attention_equation(rank,attn_axes)
keras.layers.attention.multi_head_attention._build_proj_equation(free_dims,bound_dims,output_dims)
keras.layers.attention.multi_head_attention._get_output_shape(output_rank,known_last_dims)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/attention/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/attention/base_dense_attention.py----------------------------------------
A:keras.layers.attention.base_dense_attention.padding_mask->tensorflow.compat.v2.logical_not(scores_mask)
A:keras.layers.attention.base_dense_attention.training->keras.backend.learning_phase()
A:keras.layers.attention.base_dense_attention.weights->keras.utils.control_flow_util.smart_cond(training, dropped_weights, lambda : tf.identity(weights))
A:keras.layers.attention.base_dense_attention.scores->self._calculate_scores(query=q, key=k)
A:keras.layers.attention.base_dense_attention.v_mask->tensorflow.compat.v2.expand_dims(v_mask, axis=-2)
A:keras.layers.attention.base_dense_attention.scores_shape->tensorflow.compat.v2.shape(scores)
A:keras.layers.attention.base_dense_attention.causal_mask_shape->tensorflow.compat.v2.concat([tf.ones_like(scores_shape[:-2]), scores_shape[-2:]], axis=0)
A:keras.layers.attention.base_dense_attention.causal_mask->_lower_triangular_mask(causal_mask_shape)
A:keras.layers.attention.base_dense_attention.scores_mask->_merge_masks(v_mask, causal_mask)
A:keras.layers.attention.base_dense_attention.(result, attention_scores)->self._apply_scores(scores=scores, value=v, scores_mask=scores_mask, training=training)
A:keras.layers.attention.base_dense_attention.q_mask->tensorflow.compat.v2.expand_dims(q_mask, axis=-1)
A:keras.layers.attention.base_dense_attention.base_config->super(BaseDenseAttention, self).get_config()
A:keras.layers.attention.base_dense_attention.row_index->tensorflow.compat.v2.cumsum(tf.ones(shape=shape, dtype=tf.int32), axis=-2)
A:keras.layers.attention.base_dense_attention.col_index->tensorflow.compat.v2.cumsum(tf.ones(shape=shape, dtype=tf.int32), axis=-1)
keras.layers.attention.base_dense_attention.BaseDenseAttention(self,causal=False,dropout=0.0,**kwargs)
keras.layers.attention.base_dense_attention.BaseDenseAttention.__init__(self,causal=False,dropout=0.0,**kwargs)
keras.layers.attention.base_dense_attention.BaseDenseAttention._apply_scores(self,scores,value,scores_mask=None,training=None)
keras.layers.attention.base_dense_attention.BaseDenseAttention._calculate_scores(self,query,key)
keras.layers.attention.base_dense_attention.BaseDenseAttention._validate_call_args(self,inputs,mask)
keras.layers.attention.base_dense_attention.BaseDenseAttention.call(self,inputs,mask=None,training=None,return_attention_scores=False)
keras.layers.attention.base_dense_attention.BaseDenseAttention.compute_mask(self,inputs,mask=None)
keras.layers.attention.base_dense_attention.BaseDenseAttention.compute_output_shape(self,input_shape)
keras.layers.attention.base_dense_attention.BaseDenseAttention.get_config(self)
keras.layers.attention.base_dense_attention._lower_triangular_mask(shape)
keras.layers.attention.base_dense_attention._merge_masks(x,y)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/attention/additive_attention.py----------------------------------------
A:keras.layers.attention.additive_attention.v_shape->tensorflow.compat.v2.TensorShape(input_shape[1])
A:keras.layers.attention.additive_attention.dim->tensorflow.compat.v2.compat.dimension_value(dim)
A:keras.layers.attention.additive_attention.self.scale->self.add_weight(name='scale', shape=[dim], initializer='glorot_uniform', dtype=self.dtype, trainable=True)
A:keras.layers.attention.additive_attention.q_reshaped->tensorflow.compat.v2.expand_dims(query, axis=-2)
A:keras.layers.attention.additive_attention.k_reshaped->tensorflow.compat.v2.expand_dims(key, axis=-3)
A:keras.layers.attention.additive_attention.base_config->super(AdditiveAttention, self).get_config()
keras.layers.attention.AdditiveAttention(self,use_scale=True,**kwargs)
keras.layers.attention.AdditiveAttention._calculate_scores(self,query,key)
keras.layers.attention.AdditiveAttention.build(self,input_shape)
keras.layers.attention.AdditiveAttention.get_config(self)
keras.layers.attention.additive_attention.AdditiveAttention(self,use_scale=True,**kwargs)
keras.layers.attention.additive_attention.AdditiveAttention.__init__(self,use_scale=True,**kwargs)
keras.layers.attention.additive_attention.AdditiveAttention._calculate_scores(self,query,key)
keras.layers.attention.additive_attention.AdditiveAttention.build(self,input_shape)
keras.layers.attention.additive_attention.AdditiveAttention.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/up_sampling2d.py----------------------------------------
A:keras.layers.reshaping.up_sampling2d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.up_sampling2d.self.size->keras.utils.conv_utils.normalize_tuple(size, 2, 'size')
A:keras.layers.reshaping.up_sampling2d.self.input_spec->InputSpec(ndim=4)
A:keras.layers.reshaping.up_sampling2d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.up_sampling2d.base_config->super(UpSampling2D, self).get_config()
keras.layers.reshaping.UpSampling2D(self,size=(2,2),data_format=None,interpolation='nearest',**kwargs)
keras.layers.reshaping.UpSampling2D.call(self,inputs)
keras.layers.reshaping.UpSampling2D.compute_output_shape(self,input_shape)
keras.layers.reshaping.UpSampling2D.get_config(self)
keras.layers.reshaping.up_sampling2d.UpSampling2D(self,size=(2,2),data_format=None,interpolation='nearest',**kwargs)
keras.layers.reshaping.up_sampling2d.UpSampling2D.__init__(self,size=(2,2),data_format=None,interpolation='nearest',**kwargs)
keras.layers.reshaping.up_sampling2d.UpSampling2D.call(self,inputs)
keras.layers.reshaping.up_sampling2d.UpSampling2D.compute_output_shape(self,input_shape)
keras.layers.reshaping.up_sampling2d.UpSampling2D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/flatten.py----------------------------------------
A:keras.layers.reshaping.flatten.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.flatten.self.input_spec->InputSpec(min_ndim=1)
A:keras.layers.reshaping.flatten.inputs->tensorflow.compat.v2.transpose(inputs, perm=permutation)
A:keras.layers.reshaping.flatten.flattened_shape->tensorflow.compat.v2.constant([int(batch_dim), -1])
A:keras.layers.reshaping.flatten.batch_dim->tensorflow.compat.v2.compat.dimension_value(input_shape[0])
A:keras.layers.reshaping.flatten.last_dim->int(functools.reduce(operator.mul, non_batch_dims))
A:keras.layers.reshaping.flatten.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.flatten.output_shape->tensorflow.compat.v2.TensorShape([1])
A:keras.layers.reshaping.flatten.config->super(Flatten, self).get_config()
keras.layers.reshaping.Flatten(self,data_format=None,**kwargs)
keras.layers.reshaping.Flatten.call(self,inputs)
keras.layers.reshaping.Flatten.compute_output_shape(self,input_shape)
keras.layers.reshaping.Flatten.get_config(self)
keras.layers.reshaping.flatten.Flatten(self,data_format=None,**kwargs)
keras.layers.reshaping.flatten.Flatten.__init__(self,data_format=None,**kwargs)
keras.layers.reshaping.flatten.Flatten.call(self,inputs)
keras.layers.reshaping.flatten.Flatten.compute_output_shape(self,input_shape)
keras.layers.reshaping.flatten.Flatten.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/cropping2d.py----------------------------------------
A:keras.layers.reshaping.cropping2d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.cropping2d.height_cropping->keras.utils.conv_utils.normalize_tuple(cropping[0], 2, '1st entry of cropping', allow_zero=True)
A:keras.layers.reshaping.cropping2d.width_cropping->keras.utils.conv_utils.normalize_tuple(cropping[1], 2, '2nd entry of cropping', allow_zero=True)
A:keras.layers.reshaping.cropping2d.self.input_spec->InputSpec(ndim=4)
A:keras.layers.reshaping.cropping2d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.cropping2d.base_config->super(Cropping2D, self).get_config()
keras.layers.reshaping.Cropping2D(self,cropping=((0,0),(0,0)),data_format=None,**kwargs)
keras.layers.reshaping.Cropping2D.call(self,inputs)
keras.layers.reshaping.Cropping2D.compute_output_shape(self,input_shape)
keras.layers.reshaping.Cropping2D.get_config(self)
keras.layers.reshaping.cropping2d.Cropping2D(self,cropping=((0,0),(0,0)),data_format=None,**kwargs)
keras.layers.reshaping.cropping2d.Cropping2D.__init__(self,cropping=((0,0),(0,0)),data_format=None,**kwargs)
keras.layers.reshaping.cropping2d.Cropping2D.call(self,inputs)
keras.layers.reshaping.cropping2d.Cropping2D.compute_output_shape(self,input_shape)
keras.layers.reshaping.cropping2d.Cropping2D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/cropping3d.py----------------------------------------
A:keras.layers.reshaping.cropping3d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.cropping3d.dim1_cropping->keras.utils.conv_utils.normalize_tuple(cropping[0], 2, '1st entry of cropping', allow_zero=True)
A:keras.layers.reshaping.cropping3d.dim2_cropping->keras.utils.conv_utils.normalize_tuple(cropping[1], 2, '2nd entry of cropping', allow_zero=True)
A:keras.layers.reshaping.cropping3d.dim3_cropping->keras.utils.conv_utils.normalize_tuple(cropping[2], 2, '3rd entry of cropping', allow_zero=True)
A:keras.layers.reshaping.cropping3d.self.input_spec->InputSpec(ndim=5)
A:keras.layers.reshaping.cropping3d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.cropping3d.base_config->super(Cropping3D, self).get_config()
keras.layers.reshaping.Cropping3D(self,cropping=((1,1),(1,1),(1,1)),data_format=None,**kwargs)
keras.layers.reshaping.Cropping3D.call(self,inputs)
keras.layers.reshaping.Cropping3D.compute_output_shape(self,input_shape)
keras.layers.reshaping.Cropping3D.get_config(self)
keras.layers.reshaping.cropping3d.Cropping3D(self,cropping=((1,1),(1,1),(1,1)),data_format=None,**kwargs)
keras.layers.reshaping.cropping3d.Cropping3D.__init__(self,cropping=((1,1),(1,1),(1,1)),data_format=None,**kwargs)
keras.layers.reshaping.cropping3d.Cropping3D.call(self,inputs)
keras.layers.reshaping.cropping3d.Cropping3D.compute_output_shape(self,input_shape)
keras.layers.reshaping.cropping3d.Cropping3D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/cropping1d.py----------------------------------------
A:keras.layers.reshaping.cropping1d.self.cropping->keras.utils.conv_utils.normalize_tuple(cropping, 2, 'cropping', allow_zero=True)
A:keras.layers.reshaping.cropping1d.self.input_spec->InputSpec(ndim=3)
A:keras.layers.reshaping.cropping1d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.cropping1d.base_config->super(Cropping1D, self).get_config()
keras.layers.reshaping.Cropping1D(self,cropping=(1,1),**kwargs)
keras.layers.reshaping.Cropping1D.call(self,inputs)
keras.layers.reshaping.Cropping1D.compute_output_shape(self,input_shape)
keras.layers.reshaping.Cropping1D.get_config(self)
keras.layers.reshaping.cropping1d.Cropping1D(self,cropping=(1,1),**kwargs)
keras.layers.reshaping.cropping1d.Cropping1D.__init__(self,cropping=(1,1),**kwargs)
keras.layers.reshaping.cropping1d.Cropping1D.call(self,inputs)
keras.layers.reshaping.cropping1d.Cropping1D.compute_output_shape(self,input_shape)
keras.layers.reshaping.cropping1d.Cropping1D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/reshape.py----------------------------------------
A:keras.layers.reshaping.reshape.self.target_shape->tuple(target_shape)
A:keras.layers.reshaping.reshape.output_shape->list(output_shape)
A:keras.layers.reshaping.reshape.msg->'total size of new array must be unchanged, input_shape = {}, output_shape = {}'.format(input_shape, output_shape)
A:keras.layers.reshaping.reshape.original->numpy.prod(input_shape, dtype=int)
A:keras.layers.reshaping.reshape.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.reshape.result->tensorflow.compat.v2.reshape(inputs, (tf.shape(inputs)[0],) + self.target_shape)
A:keras.layers.reshaping.reshape.base_config->super(Reshape, self).get_config()
keras.layers.reshaping.Reshape(self,target_shape,**kwargs)
keras.layers.reshaping.Reshape._fix_unknown_dimension(self,input_shape,output_shape)
keras.layers.reshaping.Reshape.call(self,inputs)
keras.layers.reshaping.Reshape.compute_output_shape(self,input_shape)
keras.layers.reshaping.Reshape.get_config(self)
keras.layers.reshaping.reshape.Reshape(self,target_shape,**kwargs)
keras.layers.reshaping.reshape.Reshape.__init__(self,target_shape,**kwargs)
keras.layers.reshaping.reshape.Reshape._fix_unknown_dimension(self,input_shape,output_shape)
keras.layers.reshaping.reshape.Reshape.call(self,inputs)
keras.layers.reshaping.reshape.Reshape.compute_output_shape(self,input_shape)
keras.layers.reshaping.reshape.Reshape.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/up_sampling1d.py----------------------------------------
A:keras.layers.reshaping.up_sampling1d.self.size->int(size)
A:keras.layers.reshaping.up_sampling1d.self.input_spec->InputSpec(ndim=3)
A:keras.layers.reshaping.up_sampling1d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.up_sampling1d.output->keras.backend.repeat_elements(inputs, self.size, axis=1)
A:keras.layers.reshaping.up_sampling1d.base_config->super(UpSampling1D, self).get_config()
keras.layers.reshaping.UpSampling1D(self,size=2,**kwargs)
keras.layers.reshaping.UpSampling1D.call(self,inputs)
keras.layers.reshaping.UpSampling1D.compute_output_shape(self,input_shape)
keras.layers.reshaping.UpSampling1D.get_config(self)
keras.layers.reshaping.up_sampling1d.UpSampling1D(self,size=2,**kwargs)
keras.layers.reshaping.up_sampling1d.UpSampling1D.__init__(self,size=2,**kwargs)
keras.layers.reshaping.up_sampling1d.UpSampling1D.call(self,inputs)
keras.layers.reshaping.up_sampling1d.UpSampling1D.compute_output_shape(self,input_shape)
keras.layers.reshaping.up_sampling1d.UpSampling1D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/up_sampling3d.py----------------------------------------
A:keras.layers.reshaping.up_sampling3d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.up_sampling3d.self.size->keras.utils.conv_utils.normalize_tuple(size, 3, 'size')
A:keras.layers.reshaping.up_sampling3d.self.input_spec->InputSpec(ndim=5)
A:keras.layers.reshaping.up_sampling3d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.up_sampling3d.base_config->super(UpSampling3D, self).get_config()
keras.layers.reshaping.UpSampling3D(self,size=(2,2,2),data_format=None,**kwargs)
keras.layers.reshaping.UpSampling3D.call(self,inputs)
keras.layers.reshaping.UpSampling3D.compute_output_shape(self,input_shape)
keras.layers.reshaping.UpSampling3D.get_config(self)
keras.layers.reshaping.up_sampling3d.UpSampling3D(self,size=(2,2,2),data_format=None,**kwargs)
keras.layers.reshaping.up_sampling3d.UpSampling3D.__init__(self,size=(2,2,2),data_format=None,**kwargs)
keras.layers.reshaping.up_sampling3d.UpSampling3D.call(self,inputs)
keras.layers.reshaping.up_sampling3d.UpSampling3D.compute_output_shape(self,input_shape)
keras.layers.reshaping.up_sampling3d.UpSampling3D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/repeat_vector.py----------------------------------------
A:keras.layers.reshaping.repeat_vector.self.input_spec->InputSpec(ndim=2)
A:keras.layers.reshaping.repeat_vector.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.repeat_vector.base_config->super(RepeatVector, self).get_config()
keras.layers.reshaping.RepeatVector(self,n,**kwargs)
keras.layers.reshaping.RepeatVector.call(self,inputs)
keras.layers.reshaping.RepeatVector.compute_output_shape(self,input_shape)
keras.layers.reshaping.RepeatVector.get_config(self)
keras.layers.reshaping.repeat_vector.RepeatVector(self,n,**kwargs)
keras.layers.reshaping.repeat_vector.RepeatVector.__init__(self,n,**kwargs)
keras.layers.reshaping.repeat_vector.RepeatVector.call(self,inputs)
keras.layers.reshaping.repeat_vector.RepeatVector.compute_output_shape(self,input_shape)
keras.layers.reshaping.repeat_vector.RepeatVector.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/zero_padding2d.py----------------------------------------
A:keras.layers.reshaping.zero_padding2d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.zero_padding2d.height_padding->keras.utils.conv_utils.normalize_tuple(padding[0], 2, '1st entry of padding', allow_zero=True)
A:keras.layers.reshaping.zero_padding2d.width_padding->keras.utils.conv_utils.normalize_tuple(padding[1], 2, '2nd entry of padding', allow_zero=True)
A:keras.layers.reshaping.zero_padding2d.self.input_spec->InputSpec(ndim=4)
A:keras.layers.reshaping.zero_padding2d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.zero_padding2d.base_config->super(ZeroPadding2D, self).get_config()
keras.layers.reshaping.ZeroPadding2D(self,padding=(1,1),data_format=None,**kwargs)
keras.layers.reshaping.ZeroPadding2D.call(self,inputs)
keras.layers.reshaping.ZeroPadding2D.compute_output_shape(self,input_shape)
keras.layers.reshaping.ZeroPadding2D.get_config(self)
keras.layers.reshaping.zero_padding2d.ZeroPadding2D(self,padding=(1,1),data_format=None,**kwargs)
keras.layers.reshaping.zero_padding2d.ZeroPadding2D.__init__(self,padding=(1,1),data_format=None,**kwargs)
keras.layers.reshaping.zero_padding2d.ZeroPadding2D.call(self,inputs)
keras.layers.reshaping.zero_padding2d.ZeroPadding2D.compute_output_shape(self,input_shape)
keras.layers.reshaping.zero_padding2d.ZeroPadding2D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/permute.py----------------------------------------
A:keras.layers.reshaping.permute.self.dims->tuple(dims)
A:keras.layers.reshaping.permute.self.input_spec->InputSpec(ndim=len(self.dims) + 1)
A:keras.layers.reshaping.permute.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.permute.output_shape->copy.copy(input_shape)
A:keras.layers.reshaping.permute.base_config->super(Permute, self).get_config()
keras.layers.reshaping.Permute(self,dims,**kwargs)
keras.layers.reshaping.Permute.call(self,inputs)
keras.layers.reshaping.Permute.compute_output_shape(self,input_shape)
keras.layers.reshaping.Permute.get_config(self)
keras.layers.reshaping.permute.Permute(self,dims,**kwargs)
keras.layers.reshaping.permute.Permute.__init__(self,dims,**kwargs)
keras.layers.reshaping.permute.Permute.call(self,inputs)
keras.layers.reshaping.permute.Permute.compute_output_shape(self,input_shape)
keras.layers.reshaping.permute.Permute.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/zero_padding3d.py----------------------------------------
A:keras.layers.reshaping.zero_padding3d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.reshaping.zero_padding3d.dim1_padding->keras.utils.conv_utils.normalize_tuple(padding[0], 2, '1st entry of padding', allow_zero=True)
A:keras.layers.reshaping.zero_padding3d.dim2_padding->keras.utils.conv_utils.normalize_tuple(padding[1], 2, '2nd entry of padding', allow_zero=True)
A:keras.layers.reshaping.zero_padding3d.dim3_padding->keras.utils.conv_utils.normalize_tuple(padding[2], 2, '3rd entry of padding', allow_zero=True)
A:keras.layers.reshaping.zero_padding3d.self.input_spec->InputSpec(ndim=5)
A:keras.layers.reshaping.zero_padding3d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.reshaping.zero_padding3d.base_config->super(ZeroPadding3D, self).get_config()
keras.layers.reshaping.ZeroPadding3D(self,padding=(1,1,1),data_format=None,**kwargs)
keras.layers.reshaping.ZeroPadding3D.call(self,inputs)
keras.layers.reshaping.ZeroPadding3D.compute_output_shape(self,input_shape)
keras.layers.reshaping.ZeroPadding3D.get_config(self)
keras.layers.reshaping.zero_padding3d.ZeroPadding3D(self,padding=(1,1,1),data_format=None,**kwargs)
keras.layers.reshaping.zero_padding3d.ZeroPadding3D.__init__(self,padding=(1,1,1),data_format=None,**kwargs)
keras.layers.reshaping.zero_padding3d.ZeroPadding3D.call(self,inputs)
keras.layers.reshaping.zero_padding3d.ZeroPadding3D.compute_output_shape(self,input_shape)
keras.layers.reshaping.zero_padding3d.ZeroPadding3D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/reshaping/zero_padding1d.py----------------------------------------
A:keras.layers.reshaping.zero_padding1d.self.padding->keras.utils.conv_utils.normalize_tuple(padding, 2, 'padding', allow_zero=True)
A:keras.layers.reshaping.zero_padding1d.self.input_spec->InputSpec(ndim=3)
A:keras.layers.reshaping.zero_padding1d.base_config->super(ZeroPadding1D, self).get_config()
keras.layers.reshaping.ZeroPadding1D(self,padding=1,**kwargs)
keras.layers.reshaping.ZeroPadding1D.call(self,inputs)
keras.layers.reshaping.ZeroPadding1D.compute_output_shape(self,input_shape)
keras.layers.reshaping.ZeroPadding1D.get_config(self)
keras.layers.reshaping.zero_padding1d.ZeroPadding1D(self,padding=1,**kwargs)
keras.layers.reshaping.zero_padding1d.ZeroPadding1D.__init__(self,padding=1,**kwargs)
keras.layers.reshaping.zero_padding1d.ZeroPadding1D.call(self,inputs)
keras.layers.reshaping.zero_padding1d.ZeroPadding1D.compute_output_shape(self,input_shape)
keras.layers.reshaping.zero_padding1d.ZeroPadding1D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/global_max_pooling1d.py----------------------------------------
keras.layers.pooling.GlobalMaxPooling1D(GlobalPooling1D)
keras.layers.pooling.GlobalMaxPooling1D.call(self,inputs)
keras.layers.pooling.global_max_pooling1d.GlobalMaxPooling1D(GlobalPooling1D)
keras.layers.pooling.global_max_pooling1d.GlobalMaxPooling1D.call(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/max_pooling2d.py----------------------------------------
keras.layers.pooling.MaxPooling2D(self,pool_size=(2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.max_pooling2d.MaxPooling2D(self,pool_size=(2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.max_pooling2d.MaxPooling2D.__init__(self,pool_size=(2,2),strides=None,padding='valid',data_format=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/global_average_pooling1d.py----------------------------------------
A:keras.layers.pooling.global_average_pooling1d.mask->tensorflow.compat.v2.expand_dims(mask, 2 if self.data_format == 'channels_last' else 1)
keras.layers.pooling.GlobalAveragePooling1D(self,data_format='channels_last',**kwargs)
keras.layers.pooling.GlobalAveragePooling1D.call(self,inputs,mask=None)
keras.layers.pooling.GlobalAveragePooling1D.compute_mask(self,inputs,mask=None)
keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D(self,data_format='channels_last',**kwargs)
keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D.__init__(self,data_format='channels_last',**kwargs)
keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D.call(self,inputs,mask=None)
keras.layers.pooling.global_average_pooling1d.GlobalAveragePooling1D.compute_mask(self,inputs,mask=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/average_pooling1d.py----------------------------------------
keras.layers.pooling.AveragePooling1D(self,pool_size=2,strides=None,padding='valid',data_format='channels_last',**kwargs)
keras.layers.pooling.average_pooling1d.AveragePooling1D(self,pool_size=2,strides=None,padding='valid',data_format='channels_last',**kwargs)
keras.layers.pooling.average_pooling1d.AveragePooling1D.__init__(self,pool_size=2,strides=None,padding='valid',data_format='channels_last',**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/average_pooling3d.py----------------------------------------
keras.layers.pooling.AveragePooling3D(self,pool_size=(2,2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.average_pooling3d.AveragePooling3D(self,pool_size=(2,2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.average_pooling3d.AveragePooling3D.__init__(self,pool_size=(2,2,2),strides=None,padding='valid',data_format=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/global_max_pooling2d.py----------------------------------------
keras.layers.pooling.GlobalMaxPooling2D(GlobalPooling2D)
keras.layers.pooling.GlobalMaxPooling2D.call(self,inputs)
keras.layers.pooling.global_max_pooling2d.GlobalMaxPooling2D(GlobalPooling2D)
keras.layers.pooling.global_max_pooling2d.GlobalMaxPooling2D.call(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/base_global_pooling1d.py----------------------------------------
A:keras.layers.pooling.base_global_pooling1d.self.input_spec->InputSpec(ndim=3)
A:keras.layers.pooling.base_global_pooling1d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.pooling.base_global_pooling1d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.pooling.base_global_pooling1d.base_config->super(GlobalPooling1D, self).get_config()
keras.layers.pooling.base_global_pooling1d.GlobalPooling1D(self,data_format='channels_last',keepdims=False,**kwargs)
keras.layers.pooling.base_global_pooling1d.GlobalPooling1D.__init__(self,data_format='channels_last',keepdims=False,**kwargs)
keras.layers.pooling.base_global_pooling1d.GlobalPooling1D.call(self,inputs)
keras.layers.pooling.base_global_pooling1d.GlobalPooling1D.compute_output_shape(self,input_shape)
keras.layers.pooling.base_global_pooling1d.GlobalPooling1D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/base_pooling3d.py----------------------------------------
A:keras.layers.pooling.base_pooling3d.data_format->keras.backend.image_data_format()
A:keras.layers.pooling.base_pooling3d.self.pool_size->keras.utils.conv_utils.normalize_tuple(pool_size, 3, 'pool_size')
A:keras.layers.pooling.base_pooling3d.self.strides->keras.utils.conv_utils.normalize_tuple(strides, 3, 'strides', allow_zero=True)
A:keras.layers.pooling.base_pooling3d.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.pooling.base_pooling3d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.pooling.base_pooling3d.self.input_spec->InputSpec(ndim=5)
A:keras.layers.pooling.base_pooling3d.inputs->tensorflow.compat.v2.transpose(inputs, (0, 2, 3, 4, 1))
A:keras.layers.pooling.base_pooling3d.outputs->tensorflow.compat.v2.transpose(outputs, (0, 4, 1, 2, 3))
A:keras.layers.pooling.base_pooling3d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.pooling.base_pooling3d.len_dim1->keras.utils.conv_utils.conv_output_length(len_dim1, self.pool_size[0], self.padding, self.strides[0])
A:keras.layers.pooling.base_pooling3d.len_dim2->keras.utils.conv_utils.conv_output_length(len_dim2, self.pool_size[1], self.padding, self.strides[1])
A:keras.layers.pooling.base_pooling3d.len_dim3->keras.utils.conv_utils.conv_output_length(len_dim3, self.pool_size[2], self.padding, self.strides[2])
A:keras.layers.pooling.base_pooling3d.base_config->super(Pooling3D, self).get_config()
keras.layers.pooling.base_pooling3d.Pooling3D(self,pool_function,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.layers.pooling.base_pooling3d.Pooling3D.__init__(self,pool_function,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.layers.pooling.base_pooling3d.Pooling3D.call(self,inputs)
keras.layers.pooling.base_pooling3d.Pooling3D.compute_output_shape(self,input_shape)
keras.layers.pooling.base_pooling3d.Pooling3D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/average_pooling2d.py----------------------------------------
keras.layers.pooling.AveragePooling2D(self,pool_size=(2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.average_pooling2d.AveragePooling2D(self,pool_size=(2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.average_pooling2d.AveragePooling2D.__init__(self,pool_size=(2,2),strides=None,padding='valid',data_format=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/max_pooling3d.py----------------------------------------
keras.layers.pooling.MaxPooling3D(self,pool_size=(2,2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.max_pooling3d.MaxPooling3D(self,pool_size=(2,2,2),strides=None,padding='valid',data_format=None,**kwargs)
keras.layers.pooling.max_pooling3d.MaxPooling3D.__init__(self,pool_size=(2,2,2),strides=None,padding='valid',data_format=None,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/base_pooling1d.py----------------------------------------
A:keras.layers.pooling.base_pooling1d.data_format->keras.backend.image_data_format()
A:keras.layers.pooling.base_pooling1d.self.pool_size->keras.utils.conv_utils.normalize_tuple(pool_size, 1, 'pool_size')
A:keras.layers.pooling.base_pooling1d.self.strides->keras.utils.conv_utils.normalize_tuple(strides, 1, 'strides', allow_zero=True)
A:keras.layers.pooling.base_pooling1d.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.pooling.base_pooling1d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.pooling.base_pooling1d.self.input_spec->InputSpec(ndim=3)
A:keras.layers.pooling.base_pooling1d.inputs->tensorflow.compat.v2.expand_dims(inputs, pad_axis)
A:keras.layers.pooling.base_pooling1d.outputs->self.pool_function(inputs, self.pool_size + (1,), strides=self.strides + (1,), padding=self.padding, data_format=self.data_format)
A:keras.layers.pooling.base_pooling1d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.pooling.base_pooling1d.length->keras.utils.conv_utils.conv_output_length(steps, self.pool_size[0], self.padding, self.strides[0])
A:keras.layers.pooling.base_pooling1d.base_config->super(Pooling1D, self).get_config()
keras.layers.pooling.base_pooling1d.Pooling1D(self,pool_function,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.layers.pooling.base_pooling1d.Pooling1D.__init__(self,pool_function,pool_size,strides,padding='valid',data_format='channels_last',name=None,**kwargs)
keras.layers.pooling.base_pooling1d.Pooling1D.call(self,inputs)
keras.layers.pooling.base_pooling1d.Pooling1D.compute_output_shape(self,input_shape)
keras.layers.pooling.base_pooling1d.Pooling1D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/global_max_pooling3d.py----------------------------------------
keras.layers.pooling.GlobalMaxPooling3D(GlobalPooling3D)
keras.layers.pooling.GlobalMaxPooling3D.call(self,inputs)
keras.layers.pooling.global_max_pooling3d.GlobalMaxPooling3D(GlobalPooling3D)
keras.layers.pooling.global_max_pooling3d.GlobalMaxPooling3D.call(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/base_global_pooling2d.py----------------------------------------
A:keras.layers.pooling.base_global_pooling2d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.pooling.base_global_pooling2d.self.input_spec->InputSpec(ndim=4)
A:keras.layers.pooling.base_global_pooling2d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.pooling.base_global_pooling2d.base_config->super(GlobalPooling2D, self).get_config()
keras.layers.pooling.base_global_pooling2d.GlobalPooling2D(self,data_format=None,keepdims=False,**kwargs)
keras.layers.pooling.base_global_pooling2d.GlobalPooling2D.__init__(self,data_format=None,keepdims=False,**kwargs)
keras.layers.pooling.base_global_pooling2d.GlobalPooling2D.call(self,inputs)
keras.layers.pooling.base_global_pooling2d.GlobalPooling2D.compute_output_shape(self,input_shape)
keras.layers.pooling.base_global_pooling2d.GlobalPooling2D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/base_pooling2d.py----------------------------------------
A:keras.layers.pooling.base_pooling2d.data_format->keras.backend.image_data_format()
A:keras.layers.pooling.base_pooling2d.self.pool_size->keras.utils.conv_utils.normalize_tuple(pool_size, 2, 'pool_size')
A:keras.layers.pooling.base_pooling2d.self.strides->keras.utils.conv_utils.normalize_tuple(strides, 2, 'strides', allow_zero=True)
A:keras.layers.pooling.base_pooling2d.self.padding->keras.utils.conv_utils.normalize_padding(padding)
A:keras.layers.pooling.base_pooling2d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.pooling.base_pooling2d.self.input_spec->InputSpec(ndim=4)
A:keras.layers.pooling.base_pooling2d.outputs->self.pool_function(inputs, ksize=pool_shape, strides=strides, padding=self.padding.upper(), data_format=conv_utils.convert_data_format(self.data_format, 4))
A:keras.layers.pooling.base_pooling2d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.pooling.base_pooling2d.rows->keras.utils.conv_utils.conv_output_length(rows, self.pool_size[0], self.padding, self.strides[0])
A:keras.layers.pooling.base_pooling2d.cols->keras.utils.conv_utils.conv_output_length(cols, self.pool_size[1], self.padding, self.strides[1])
A:keras.layers.pooling.base_pooling2d.base_config->super(Pooling2D, self).get_config()
keras.layers.pooling.base_pooling2d.Pooling2D(self,pool_function,pool_size,strides,padding='valid',data_format=None,name=None,**kwargs)
keras.layers.pooling.base_pooling2d.Pooling2D.__init__(self,pool_function,pool_size,strides,padding='valid',data_format=None,name=None,**kwargs)
keras.layers.pooling.base_pooling2d.Pooling2D.call(self,inputs)
keras.layers.pooling.base_pooling2d.Pooling2D.compute_output_shape(self,input_shape)
keras.layers.pooling.base_pooling2d.Pooling2D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/global_average_pooling3d.py----------------------------------------
keras.layers.pooling.GlobalAveragePooling3D(GlobalPooling3D)
keras.layers.pooling.GlobalAveragePooling3D.call(self,inputs)
keras.layers.pooling.global_average_pooling3d.GlobalAveragePooling3D(GlobalPooling3D)
keras.layers.pooling.global_average_pooling3d.GlobalAveragePooling3D.call(self,inputs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/base_global_pooling3d.py----------------------------------------
A:keras.layers.pooling.base_global_pooling3d.self.data_format->keras.utils.conv_utils.normalize_data_format(data_format)
A:keras.layers.pooling.base_global_pooling3d.self.input_spec->InputSpec(ndim=5)
A:keras.layers.pooling.base_global_pooling3d.input_shape->tensorflow.compat.v2.TensorShape(input_shape).as_list()
A:keras.layers.pooling.base_global_pooling3d.base_config->super(GlobalPooling3D, self).get_config()
keras.layers.pooling.base_global_pooling3d.GlobalPooling3D(self,data_format=None,keepdims=False,**kwargs)
keras.layers.pooling.base_global_pooling3d.GlobalPooling3D.__init__(self,data_format=None,keepdims=False,**kwargs)
keras.layers.pooling.base_global_pooling3d.GlobalPooling3D.call(self,inputs)
keras.layers.pooling.base_global_pooling3d.GlobalPooling3D.compute_output_shape(self,input_shape)
keras.layers.pooling.base_global_pooling3d.GlobalPooling3D.get_config(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/max_pooling1d.py----------------------------------------
keras.layers.pooling.MaxPooling1D(self,pool_size=2,strides=None,padding='valid',data_format='channels_last',**kwargs)
keras.layers.pooling.max_pooling1d.MaxPooling1D(self,pool_size=2,strides=None,padding='valid',data_format='channels_last',**kwargs)
keras.layers.pooling.max_pooling1d.MaxPooling1D.__init__(self,pool_size=2,strides=None,padding='valid',data_format='channels_last',**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/keras2.9.0/lib/python3.6/site-packages/keras/layers/pooling/global_average_pooling2d.py----------------------------------------
keras.layers.pooling.GlobalAveragePooling2D(GlobalPooling2D)
keras.layers.pooling.GlobalAveragePooling2D.call(self,inputs)
keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D(GlobalPooling2D)
keras.layers.pooling.global_average_pooling2d.GlobalAveragePooling2D.call(self,inputs)

