
----------------------------------------/home/zhang/Packages/dask/dask0.4.0/compatibility.py----------------------------------------
dask.compatibility.skip(func)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/utils.py----------------------------------------
A:dask.utils.(handle, filename)->tempfile.mkstemp(extension)
A:dask.utils.f->open(filename, 'wt')
dask.utils.IndexCallable(self,fn)
dask.utils.IndexCallable.__getitem__(self,key)
dask.utils.IndexCallable.__init__(self,fn)
dask.utils.deepmap(func,*seqs)
dask.utils.filetext(text,extension='',open=open,mode='w')
dask.utils.filetexts(d,open=open)
dask.utils.ignoring(*exceptions)
dask.utils.raises(err,lamda)
dask.utils.repr_long_list(seq)
dask.utils.tmpfile(extension='')


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/core.py----------------------------------------
A:dask.core.val->func(*results)
A:dask.core.cycle->'->'.join(cycle)
A:dask.core.key->args.pop()
A:dask.core.v->list(v)
A:dask.core.arg->subs(arg, key, val)
A:dask.core.result->dict(((t, set()) for t in terms))
A:dask.core.completed->set()
A:dask.core.seen->set()
dask.core._deps(dsk,arg)
dask.core._get_task(d,task,maxdepth=1000)
dask.core._toposort(dsk,keys=None,returncycle=False)
dask.core.flatten(seq)
dask.core.get(d,key,get=None,concrete=True,**kwargs)
dask.core.get_dependencies(dsk,task,as_list=False)
dask.core.getcycle(d,keys)
dask.core.inc(x)
dask.core.isdag(d,keys)
dask.core.ishashable(x)
dask.core.istask(x)
dask.core.preorder_traversal(task)
dask.core.reverse_dict(d)
dask.core.subs(task,key,val)
dask.core.toposort(dsk)
dask.get(d,key,get=None,concrete=True,**kwargs)
dask.get_dependencies(dsk,task,as_list=False)
dask.getcycle(d,keys)
dask.istask(x)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/optimize.py----------------------------------------
A:dask.optimize.nxt->set()
A:dask.optimize.deadbeats->set()
A:dask.optimize.deps->tuple(get_dependencies(dsk2, key2, True))
A:dask.optimize.children->dict(map(reversed, parents.items()))
A:dask.optimize.(child, parent)->parents.popitem()
A:dask.optimize.parent->chain.pop()
A:dask.optimize.child->chain.pop()
A:dask.optimize.fused->set()
A:dask.optimize.val->subs(val, item, keysubs[item])
A:dask.optimize.keys->set([keys])
A:dask.optimize.replaceorder->toposort(dict(((k, dsk[k]) for k in keys if k in dsk)))
A:dask.optimize.fast_functions->set(fast_functions)
A:dask.optimize.dependencies->dict(((k, get_dependencies(dsk2, k)) for k in dsk2))
A:dask.optimize.dependents->reverse_dict(dependencies)
A:dask.optimize.result->set()
A:dask.optimize.aliases->set((k for (k, task) in dsk.items() if ishashable(task) and task in dsk))
A:dask.optimize.roots->set((k for (k, v) in dependents.items() if not v))
A:dask.optimize.dsk2->inline(dsk, aliases - roots, inline_constants=False)
A:dask.optimize.dsk3->inline(dsk, aliases - roots, inline_constants=False).copy()
A:dask.optimize.head_type->type(term1)
A:dask.optimize.pot1->preorder_traversal(term1)
A:dask.optimize.pot2->preorder_traversal(term2)
A:dask.optimize.v->core.subs.get(d, None)
A:dask.optimize.deps2->tuple(deps2)
A:dask.optimize.dep_dict1->dependency_dict(dsk1)
A:dask.optimize.possible_matches->_possible_matches(dep_dict1, deps, subs)
A:dask.optimize.dsk2_topo->toposort(dsk2)
A:dask.optimize.sd->_sync_keys(dsk1, dsk2, dsk2_topo)
A:dask.optimize.new_dsk->dsk1.copy()
A:dask.optimize.new_key->next(merge_sync.names)
A:dask.optimize.task->subs(task, a, b)
dask.optimize._possible_matches(dep_dict,deps,subs)
dask.optimize._sync_keys(dsk1,dsk2,dsk2_topo)
dask.optimize.cull(dsk,keys)
dask.optimize.dealias(dsk)
dask.optimize.dependency_dict(dsk)
dask.optimize.equivalent(term1,term2,subs=None)
dask.optimize.functions_of(task)
dask.optimize.fuse(dsk)
dask.optimize.inline(dsk,keys=None,inline_constants=True)
dask.optimize.inline_functions(dsk,fast_functions=None,inline_constants=False)
dask.optimize.merge_sync(dsk1,dsk2)
dask.optimize.sync_keys(dsk1,dsk2)
dask.optimize.unwrap_partial(func)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/rewrite.py----------------------------------------
A:dask.rewrite.self._stack->deque([END])
A:dask.rewrite.subterms->args(self.term)
A:dask.rewrite.self.term->self._stack.pop()
A:dask.rewrite.VAR->Token('?')
A:dask.rewrite.END->Token('end')
A:dask.rewrite.self.vars->tuple(sorted(set(self._varlist)))
A:dask.rewrite.term->rule.subs(sd)
A:dask.rewrite.self._net->Node()
A:dask.rewrite.ind->len(self.rules)
A:dask.rewrite.curr_node.edges[t]->Node()
A:dask.rewrite.S->Traverser(term)
A:dask.rewrite.subs->_process_match(rule, syms)
A:dask.rewrite.new_args->tuple((_bottom_up(net, t) for t in args(term)))
A:dask.rewrite.stack->deque()
A:dask.rewrite.n->N.edges.get(VAR, None)
A:dask.rewrite.(S, N, matches)->deque().pop()
dask.rewrite.Node(cls,edges=None,patterns=None)
dask.rewrite.Node.__new__(cls,edges=None,patterns=None)
dask.rewrite.Node.edges(self)
dask.rewrite.Node.patterns(self)
dask.rewrite.RewriteRule(self,lhs,rhs,vars=())
dask.rewrite.RewriteRule.__init__(self,lhs,rhs,vars=())
dask.rewrite.RewriteRule.__repr__(self)
dask.rewrite.RewriteRule.__str__(self)
dask.rewrite.RewriteRule._apply(self,sub_dict)
dask.rewrite.RuleSet(self,*rules)
dask.rewrite.RuleSet.__init__(self,*rules)
dask.rewrite.RuleSet._rewrite(self,term)
dask.rewrite.RuleSet.add(self,rule)
dask.rewrite.RuleSet.iter_matches(self,term)
dask.rewrite.RuleSet.rewrite(self,task,strategy='bottom_up')
dask.rewrite.Token(self,name)
dask.rewrite.Token.__init__(self,name)
dask.rewrite.Token.__repr__(self)
dask.rewrite.Traverser(self,term,stack=None)
dask.rewrite.Traverser.__init__(self,term,stack=None)
dask.rewrite.Traverser.__iter__(self)
dask.rewrite.Traverser.copy(self)
dask.rewrite.Traverser.current(self)
dask.rewrite.Traverser.next(self)
dask.rewrite.Traverser.skip(self)
dask.rewrite._bottom_up(net,term)
dask.rewrite._match(S,N)
dask.rewrite._process_match(rule,syms)
dask.rewrite._top_level(net,term)
dask.rewrite.args(task)
dask.rewrite.head(task)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/context.py----------------------------------------
A:dask.context._globals->defaultdict(lambda : None)
A:dask.context.self.old->defaultdict(lambda : None).copy()
dask.context.set_options(self,**kwargs)
dask.context.set_options.__enter__(self)
dask.context.set_options.__exit__(self,type,value,traceback)
dask.context.set_options.__init__(self,**kwargs)
dask.set_options(self,**kwargs)
dask.set_options.__enter__(self)
dask.set_options.__exit__(self,type,value,traceback)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/async.py----------------------------------------
A:dask.async.cache->dict()
A:dask.async.dependencies->dict(((k, get_dependencies(dsk, k)) for k in dsk))
A:dask.async.waiting->dict(((k, v) for (k, v) in waiting.items() if v))
A:dask.async.dependents->reverse_dict(dependencies)
A:dask.async.waiting_data->dict(((k, v.copy()) for (k, v) in dependents.items() if v))
A:dask.async.ready_set->set([k for (k, v) in waiting.items() if not v])
A:dask.async.ready->sorted(ready_set)
A:dask.async.result->_execute_task(task, data)
A:dask.async.(exc_type, exc_value, exc_traceback)->sys.exc_info()
A:dask.async.tb->''.join(traceback.format_tb(exc_traceback))
A:dask.async.result_flat->set([result])
A:dask.async.results->set(result_flat)
A:dask.async.state->start_state_from_dask(dsk, cache=cache)
A:dask.async.key->state['ready'].pop()
A:dask.async.data->dict(((dep, state['cache'][dep]) for dep in get_dependencies(dsk, key)))
A:dask.async.(key, res, tb)->Queue().get()
A:dask.async.g->state_to_networkx(dsk, state)
A:dask.async.(data, func)->color_nodes(dsk, state)
A:dask.async.queue->Queue()
dask.async._execute_task(arg,cache,dsk=None)
dask.async.apply_sync(func,args=(),kwds={})
dask.async.color_nodes(dsk,state)
dask.async.double(x)
dask.async.execute_task(key,task,data,queue,raise_on_exception=False)
dask.async.finish_task(dsk,key,result,state,results)
dask.async.get_async(apply_async,num_workers,dsk,result,cache=None,debug_counts=None,queue=None,raise_on_exception=False,**kwargs)
dask.async.get_sync(dsk,keys,**kwargs)
dask.async.inc(x)
dask.async.nested_get(ind,coll,lazy=False)
dask.async.release_data(key,state)
dask.async.start_state_from_dask(dsk,cache=None)
dask.async.state_to_networkx(dsk,state)
dask.async.visualize(dsk,state,filename='dask')


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/dot.py----------------------------------------
A:dask.dot.data_attributes->dict()
A:dask.dot.function_attributes->dict()
A:dask.dot.g->networkx.DiGraph()
A:dask.dot.func_node->make_hashable((v, 'function'))
A:dask.dot.arg2->make_hashable(dep)
A:dask.dot.p->networkx.to_pydot(dg)
A:dask.dot.dg->to_networkx(d, **kwargs)
dask.dot.dot_graph(d,filename='mydask',**kwargs)
dask.dot.lower(func)
dask.dot.make_hashable(x)
dask.dot.name(func)
dask.dot.to_networkx(d,data_attributes=None,function_attributes=None)
dask.dot.write_networkx_to_dot(dg,filename='mydask')


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/bag/core.py----------------------------------------
A:dask.bag.core.dsk2->dict((((name, i), (collect, grouper, npartitions, i, sorted(dsk1.keys()))) for i in range(npartitions)))
A:dask.bag.core.dsk3->fuse(dsk2)
A:dask.bag.core.dsk4->lazify(dsk3)
A:dask.bag.core.name->next(load_names)
A:dask.bag.core.func->curry(apply, func)
A:dask.bag.core.dsk->dict((((name, i), (list, (concat, (self.name, i)))) for i in range(self.npartitions)))
A:dask.bag.core.a->next(names)
A:dask.bag.core.b->Bag(merge(self.dask, dsk), name, 1)
A:dask.bag.core.topk->curry(heapq.nlargest, key=key)
A:dask.bag.core.(totals, counts)->list(zip(*x))
A:dask.bag.core.(squares, totals, counts)->list(zip(*x))
A:dask.bag.core.results->iter(results)
A:dask.bag.core.dsk1->dict((((name, i), (partition, grouper, (self.name, i), npartitions, paths[i % len(paths)])) for i in range(self.npartitions)))
A:dask.bag.core.pbags->list(take(npartitions, pbags))
A:dask.bag.core.result->defaultdict(list)
A:dask.bag.core.part->pb.get_partition(group)
A:dask.bag.core.groups->groupby(grouper, part)
A:dask.bag.core.filenames->sorted(glob(filenames))
A:dask.bag.core.extension->os.path.splitext(filenames[0])[1].strip('.')
A:dask.bag.core.myopen->opens.get(extension, open)
A:dask.bag.core.d->dict((((name, i), part) for (i, part) in enumerate(parts)))
A:dask.bag.core.seq->list(seq)
A:dask.bag.core.partition_size->int(len(seq) / 100)
A:dask.bag.core.parts->list(partition_all(partition_size, seq))
A:dask.bag.core.spec->inspect.getargspec(func)
dask.bag.Bag(self,dsk,name,npartitions,get=get)
dask.bag.Bag._keys(self)
dask.bag.Bag.all(self)
dask.bag.Bag.any(self)
dask.bag.Bag.compute(self,**kwargs)
dask.bag.Bag.concat(self)
dask.bag.Bag.count(self)
dask.bag.Bag.distinct(self)
dask.bag.Bag.filter(self,predicate)
dask.bag.Bag.fold(self,binop,combine=None,initial=None)
dask.bag.Bag.foldby(self,key,binop,initial=no_default,combine=None,combine_initial=no_default)
dask.bag.Bag.frequencies(self)
dask.bag.Bag.from_filenames(cls,*args,**kwargs)
dask.bag.Bag.from_sequence(cls,*args,**kwargs)
dask.bag.Bag.groupby(self,grouper,npartitions=None)
dask.bag.Bag.join(self,other,on_self,on_other=None)
dask.bag.Bag.map(self,func)
dask.bag.Bag.map_partitions(self,func)
dask.bag.Bag.max(self)
dask.bag.Bag.mean(self)
dask.bag.Bag.min(self)
dask.bag.Bag.pluck(self,key,default=no_default)
dask.bag.Bag.product(self,other)
dask.bag.Bag.reduction(self,perpartition,aggregate)
dask.bag.Bag.std(self,ddof=0)
dask.bag.Bag.sum(self)
dask.bag.Bag.take(self,k,compute=True)
dask.bag.Bag.topk(self,k,key=None)
dask.bag.Bag.var(self,ddof=0)
dask.bag.Item(self,dsk,key,get=get)
dask.bag.Item.compute(self,**kwargs)
dask.bag.core.Bag(self,dsk,name,npartitions,get=get)
dask.bag.core.Bag.__init__(self,dsk,name,npartitions,get=get)
dask.bag.core.Bag._keys(self)
dask.bag.core.Bag.all(self)
dask.bag.core.Bag.any(self)
dask.bag.core.Bag.compute(self,**kwargs)
dask.bag.core.Bag.concat(self)
dask.bag.core.Bag.count(self)
dask.bag.core.Bag.distinct(self)
dask.bag.core.Bag.filter(self,predicate)
dask.bag.core.Bag.fold(self,binop,combine=None,initial=None)
dask.bag.core.Bag.foldby(self,key,binop,initial=no_default,combine=None,combine_initial=no_default)
dask.bag.core.Bag.frequencies(self)
dask.bag.core.Bag.from_filenames(cls,*args,**kwargs)
dask.bag.core.Bag.from_sequence(cls,*args,**kwargs)
dask.bag.core.Bag.groupby(self,grouper,npartitions=None)
dask.bag.core.Bag.join(self,other,on_self,on_other=None)
dask.bag.core.Bag.map(self,func)
dask.bag.core.Bag.map_partitions(self,func)
dask.bag.core.Bag.max(self)
dask.bag.core.Bag.mean(self)
dask.bag.core.Bag.min(self)
dask.bag.core.Bag.pluck(self,key,default=no_default)
dask.bag.core.Bag.product(self,other)
dask.bag.core.Bag.reduction(self,perpartition,aggregate)
dask.bag.core.Bag.std(self,ddof=0)
dask.bag.core.Bag.sum(self)
dask.bag.core.Bag.take(self,k,compute=True)
dask.bag.core.Bag.topk(self,k,key=None)
dask.bag.core.Bag.var(self,ddof=0)
dask.bag.core.Item(self,dsk,key,get=get)
dask.bag.core.Item.__init__(self,dsk,key,get=get)
dask.bag.core.Item.compute(self,**kwargs)
dask.bag.core.collect(grouper,npartitions,group,pbags)
dask.bag.core.dictitems(d)
dask.bag.core.from_filenames(filenames)
dask.bag.core.from_sequence(seq,partition_size=None,npartitions=None)
dask.bag.core.get(dsk,keys,get=None,**kwargs)
dask.bag.core.lazify(dsk)
dask.bag.core.lazify_task(task,start=True)
dask.bag.core.list2(seq)
dask.bag.core.optimize(dsk,keys)
dask.bag.core.partition(grouper,sequence,npartitions,path)
dask.bag.core.takes_multiple_arguments(func)
dask.bag.from_filenames(filenames)
dask.bag.from_sequence(seq,partition_size=None,npartitions=None)
dask.bag.get(dsk,keys,get=None,**kwargs)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/bag/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/dataframe/shuffle.py----------------------------------------
A:dask.dataframe.shuffle.blockdivs->unique(blockdivs)
A:dask.dataframe.shuffle.name->next(names)
A:dask.dataframe.shuffle.dsk->dict((((name, i), (pframe.get_partition, pf, i)) for i in range(pf.npartitions)))
A:dask.dataframe.shuffle.f2->type(f)(merge(f.dask, dsk), name, f.column_info, f.blockdivs)
A:dask.dataframe.shuffle.head->type(f)(merge(f.dask, dsk), name, f.column_info, f.blockdivs).head()
A:dask.dataframe.shuffle.pf->pframe(like=head, blockdivs=blockdivs, **kwargs)
dask.dataframe.from_pframe(pf)
dask.dataframe.shuffle.from_pframe(pf)
dask.dataframe.shuffle.set_index(f,index,npartitions=None,**kwargs)
dask.dataframe.shuffle.set_partition(f,index,blockdivs,get=threaded.get,**kwargs)
dask.dataframe.shuffle.unique(blockdivs)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/dataframe/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/store/core.py----------------------------------------
A:dask.store.core.self.dsk->dict()
A:dask.store.core.cache->dict()
A:dask.store.core.self.data->set()
A:dask.store.core.self.compute_time->dict()
A:dask.store.core.self.access_times->defaultdict(list)
A:dask.store.core.start->time()
A:dask.store.core.result->func(*args)
A:dask.store.core.end->time()
dask.store.Store(self,cache=None)
dask.store.Store.__delitem__(self,key)
dask.store.Store.__getitem__(self,key)
dask.store.Store.__iter__(self)
dask.store.Store.__len__(self)
dask.store.Store.__setitem__(self,key,value)
dask.store.core.Store(self,cache=None)
dask.store.core.Store.__delitem__(self,key)
dask.store.core.Store.__getitem__(self,key)
dask.store.core.Store.__init__(self,cache=None)
dask.store.core.Store.__iter__(self)
dask.store.core.Store.__len__(self)
dask.store.core.Store.__setitem__(self,key,value)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/store/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/chunk.py----------------------------------------
A:dask.array.chunk.r->a_callable(x, *args, axis=axis, **kwargs)
A:dask.array.chunk.axes->range(x.ndim)
A:dask.array.chunk.r_slice->tuple()
A:dask.array.chunk.sum->keepdims_wrapper(np.sum)
A:dask.array.chunk.prod->keepdims_wrapper(np.prod)
A:dask.array.chunk.min->keepdims_wrapper(np.min)
A:dask.array.chunk.max->keepdims_wrapper(np.max)
A:dask.array.chunk.argmin->keepdims_wrapper(np.argmin)
A:dask.array.chunk.nanargmin->keepdims_wrapper(np.nanargmin)
A:dask.array.chunk.argmax->keepdims_wrapper(np.argmax)
A:dask.array.chunk.nanargmax->keepdims_wrapper(np.nanargmax)
A:dask.array.chunk.any->keepdims_wrapper(np.any)
A:dask.array.chunk.all->keepdims_wrapper(np.all)
A:dask.array.chunk.nansum->keepdims_wrapper(np.nansum)
A:dask.array.chunk.nanprod->keepdims_wrapper(np.nanprod)
A:dask.array.chunk.nanmin->keepdims_wrapper(np.nanmin)
A:dask.array.chunk.nanmax->keepdims_wrapper(np.nanmax)
A:dask.array.chunk.mean->keepdims_wrapper(np.mean)
A:dask.array.chunk.nanmean->keepdims_wrapper(np.nanmean)
A:dask.array.chunk.var->keepdims_wrapper(np.var)
A:dask.array.chunk.nanvar->keepdims_wrapper(np.nanvar)
A:dask.array.chunk.std->keepdims_wrapper(np.std)
A:dask.array.chunk.nanstd->keepdims_wrapper(np.nanstd)
A:dask.array.chunk.newshape->tuple(concat([(x.shape[i] / axes[i], axes[i]) for i in range(x.ndim)]))
A:dask.array.chunk.new_array->new_array.view(type=type(original_array)).view(type=type(original_array))
A:dask.array.chunk.array->numpy.array(array, copy=False, subok=subok)
A:dask.array.chunk.result->_maybe_view_as_subclass(array, broadcast)
dask.array.chunk.coarsen(reduction,x,axes)
dask.array.chunk.keepdims_wrapper(a_callable)
dask.array.chunk.trim(x,axes=None)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/linalg.py----------------------------------------
A:dask.array.linalg.dsk_qr_st1->top(np.linalg.qr, name_qr_st1, 'ij', data.name, 'ij', numblocks={data.name: numblocks})
A:dask.array.linalg.dsk_q_st1->dict((((name_q_st1, i, 0), (operator.getitem, (name_qr_st1, i, 0), 0)) for i in range(numblocks[0])))
A:dask.array.linalg.dsk_r_st1->dict((((name_r_st1, i, 0), (operator.getitem, (name_qr_st1, i, 0), 1)) for i in range(numblocks[0])))
A:dask.array.linalg.dsk_qr_st2->top(np.linalg.qr, name_qr_st2, 'ij', name_r_st1_stacked, 'ij', numblocks={name_r_st1_stacked: (1, 1)})
A:dask.array.linalg.dsk_q_st2->dict((((name_q_st2,) + (i, 0), (operator.getitem, (name_q_st2_aux, 0, 0), b)) for (i, b) in enumerate(block_slices)))
A:dask.array.linalg.dsk_q_st3->top(np.dot, name_q_st3, 'ij', name_q_st1, 'ij', name_q_st2, 'ij', numblocks={name_q_st1: numblocks, name_q_st2: numblocks})
A:dask.array.linalg.q->Array(dsk_q, name_q_st3, shape=data.shape, chunks=data.chunks)
A:dask.array.linalg.r->Array(dsk_r, name_r_st2, shape=(n, n), chunks=(n, n))
A:dask.array.linalg.dsk_svd_st2->top(np.linalg.svd, name_svd_st2, 'ij', name_r_st2, 'ij', numblocks={name_r_st2: (1, 1)})
A:dask.array.linalg.dsk_u_st4->top(dotmany, name_u_st4, 'ij', name_q_st3, 'ik', name_u_st2, 'kj', numblocks={name_q_st3: numblocks, name_u_st2: (1, 1)})
A:dask.array.linalg.u->Array(dsk_u, name_u_st4, shape=data.shape, chunks=data.chunks)
A:dask.array.linalg.s->Array(dsk_s, name_s_st2, shape=(n,), chunks=(n, n))
A:dask.array.linalg.v->Array(dsk_v, name_v_st2, shape=(n, n), chunks=(n, n))
dask.array.linalg._cumsum_blocks(it)
dask.array.linalg.qr(data,name=None)
dask.array.linalg.svd(data,name=None)
dask.array.linalg.tsqr(data,name=None,compute_svd=False)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/learn.py----------------------------------------
A:dask.array.learn.x->x.reblock(chunks=(x.chunks[0], sum(x.chunks[1]))).reblock(chunks=(x.chunks[0], sum(x.chunks[1])))
A:dask.array.learn.nblocks->len(x.chunks[0])
A:dask.array.learn.name->next(names)
A:dask.array.learn.func->partial(_predict, model)
dask.array.learn._partial_fit(model,x,y,kwargs=None)
dask.array.learn._predict(model,x)
dask.array.learn.fit(model,x,y,get=threaded.get,**kwargs)
dask.array.learn.predict(model,x)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/ghost.py----------------------------------------
A:dask.array.ghost.index->tuple([slice(None, None, None) if ind == bas else slice(0, axes.get(i, 0)) if ind < bas else slice(-axes.get(i, 0), None) for (i, (ind, bas)) in enumerate(zip(task[1:], base[1:]))])
A:dask.array.ghost.seq->list(map(concrete, seq))
A:dask.array.ghost.n->int(len(seq) / shape[0])
A:dask.array.ghost.dims->list(map(len, x.chunks))
A:dask.array.ghost.expand_key2->partial(expand_key, dims=dims)
A:dask.array.ghost.interior_keys->pipe(x._keys(), flatten, map(expand_key2), map(flatten), concat, list)
A:dask.array.ghost.interior_slices->dict(((k, fractional_slice(k, axes)) for k in interior_keys))
A:dask.array.ghost.name->next(ghost_names)
A:dask.array.ghost.ghost_blocks->dict((((name,) + k[1:], (rec_concatenate, (concrete, expand_key2(k)))) for k in interior_keys))
A:dask.array.ghost.chunks->list(x.chunks)
A:dask.array.ghost.c->wrap.full(tuple(map(sum, chunks)), value, chunks=tuple(chunks), dtype=x._dtype)
A:dask.array.ghost.kind->dict(((i, kind) for i in range(x.ndim)))
A:dask.array.ghost.depth->dict(((i, depth) for i in range(x.ndim)))
A:dask.array.ghost.x->constant(x, i, depth[i], kind[i])
A:dask.array.ghost.x2->boundaries(x, depth, boundary)
A:dask.array.ghost.x3->ghost_internal(x2, depth)
A:dask.array.ghost.trim->dict(((k, v * 2 if boundary.get(k, None) is not None else 0) for (k, v) in depth.items()))
A:dask.array.ghost.x4->chunk.trim(x3, trim)
dask.array.ghost.boundaries(x,depth=None,kind=None)
dask.array.ghost.concrete(seq)
dask.array.ghost.constant(x,axis,depth,value)
dask.array.ghost.expand_key(k,dims)
dask.array.ghost.fractional_slice(task,axes)
dask.array.ghost.ghost(x,depth,boundary)
dask.array.ghost.ghost_internal(x,axes)
dask.array.ghost.periodic(x,axis,depth)
dask.array.ghost.reflect(x,axis,depth)
dask.array.ghost.reshape(shape,seq)
dask.array.ghost.trim_internal(x,axes=None)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/slicing.py----------------------------------------
A:dask.array.slicing.ind->ind.tolist().tolist()
A:dask.array.slicing.index->tuple(map(sanitize_index_elements, index))
A:dask.array.slicing.blockdims->tuple(map(tuple, blockdims))
A:dask.array.slicing.(dsk_out, bd_out)->slice_with_newaxes(out_name, in_name, blockdims, index2)
A:dask.array.slicing.bd_out->tuple(map(tuple, bd_out))
A:dask.array.slicing.index2->posify_index(shape, index)
A:dask.array.slicing.(dsk, blockdims2)->slice_slices_and_integers(tmp, in_name, blockdims, index_without_list)
A:dask.array.slicing.dsk2->dict((((out_name,) + insert_many(k[1:], where_none, 0), v[:2] + (insert_many(v[2], where_none, None),)) for (k, v) in dsk.items() if k[0] == out_name))
A:dask.array.slicing.dsk3->merge(dsk, dsk2)
A:dask.array.slicing.blockdims3->insert_many(blockdims2, where_none, (1,))
A:dask.array.slicing.shape->tuple(map(sum, blockdims))
A:dask.array.slicing.index_without_list->tuple((slice(None, None, None) if isinstance(i, list) else i for i in index2))
A:dask.array.slicing.(blockdims2, dsk3)->take(out_name, in_name, blockdims, index2[where_list[0]], axis=axis)
A:dask.array.slicing.tmp->next(slice_names)
A:dask.array.slicing.(blockdims2, dsk2)->take(out_name, tmp, blockdims2, index2[axis], axis=axis2)
A:dask.array.slicing.block_slices->list(map(_slice_1d, shape, blockdims, index))
A:dask.array.slicing.in_names->list(product([in_name], *[i.keys() for i in block_slices]))
A:dask.array.slicing.out_names->list(product([out_name], *[range(len(d))[::-1] if i.step and i.step < 0 else range(len(d)) for (d, i) in zip(block_slices, index) if not isinstance(i, (int, long))]))
A:dask.array.slicing.all_slices->list(product(*[i.values() for i in block_slices]))
A:dask.array.slicing.dsk_out->dict(((out_name, (getitem, in_name, slices)) for (out_name, in_name, slices) in zip(out_names, in_names, all_slices)))
A:dask.array.slicing.lens->list(lengths)
A:dask.array.slicing.d->dict()
A:dask.array.slicing.d[i]->slice(start - tail_index[i], max(stop, -length - 1), step)
A:dask.array.slicing.tail_index->list(accumulate(add, lengths))
A:dask.array.slicing.pos_step->abs(step)
A:dask.array.slicing.d[k]->slice(None, None, None)
A:dask.array.slicing.d[0]->slice(0, 0, 1)
A:dask.array.slicing.seq->list(seq)
A:dask.array.slicing.result->list()
A:dask.array.slicing.L->list()
A:dask.array.slicing.colon->slice(None, None, None)
A:dask.array.slicing.n->len(blockdims)
A:dask.array.slicing.index_lists->partition_by_size(sizes, sorted(index))
A:dask.array.slicing.indims->list(dims)
A:dask.array.slicing.indims[axis]->list(range(len(where_index)))
A:dask.array.slicing.keys->list(product([outname], *dims))
A:dask.array.slicing.outdims->list(dims)
A:dask.array.slicing.slices->list(product(*slices))
A:dask.array.slicing.inkeys->list(product([inname], *outdims))
A:dask.array.slicing.blockdims2->list(blockdims)
A:dask.array.slicing.blockdims2[axis]->tuple(map(len, index_lists))
A:dask.array.slicing.rev_index->list(map(sorted(index).index, index))
A:dask.array.slicing.pairs->sorted(_slice_1d(dim_shape, lengths, index).items(), key=first)
dask.array.slicing._slice_1d(dim_shape,lengths,index)
dask.array.slicing.insert_many(seq,where,val)
dask.array.slicing.issorted(seq)
dask.array.slicing.new_blockdim(dim_shape,lengths,index)
dask.array.slicing.partition_by_size(sizes,seq)
dask.array.slicing.posify_index(shape,ind)
dask.array.slicing.replace_ellipsis(n,index)
dask.array.slicing.sanitize_index_elements(ind)
dask.array.slicing.slice_array(out_name,in_name,blockdims,index)
dask.array.slicing.slice_slices_and_integers(out_name,in_name,blockdims,index)
dask.array.slicing.slice_with_newaxes(out_name,in_name,blockdims,index)
dask.array.slicing.slice_wrap_lists(out_name,in_name,blockdims,index)
dask.array.slicing.take(outname,inname,blockdims,index,axis=0)
dask.array.slicing.take_sorted(outname,inname,blockdims,index,axis=0)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/reductions.py----------------------------------------
A:dask.array.reductions.axis->tuple(range(x.ndim))
A:dask.array.reductions.chunk2->partial(chunk, axis=axis, keepdims=True)
A:dask.array.reductions.aggregate2->partial(aggregate, axis=axis, keepdims=keepdims)
A:dask.array.reductions.inds->tuple(range(x.ndim))
A:dask.array.reductions.tmp->atop(chunk2, next(names), inds, x, inds)
A:dask.array.reductions.inds2->tuple((i for i in inds if i not in axis))
A:dask.array.reductions.result->numpy.empty(shape=n.shape, dtype=[('x', x.dtype), ('x2', x2.dtype), ('n', n.dtype)])
A:dask.array.reductions.dsk->numpy.empty(shape=n.shape, dtype=[('x', x.dtype), ('x2', x2.dtype), ('n', n.dtype)]).dask.copy()
A:dask.array.reductions.dsk[k2]->numpy.empty(shape=n.shape, dtype=[('x', x.dtype), ('x2', x2.dtype), ('n', n.dtype)]).dask.copy().pop(k)
A:dask.array.reductions.chunks->insert_many(result.chunks, axis, [1])
A:dask.array.reductions.n->A['n'].sum(**kwargs)
A:dask.array.reductions.total->sum(x, **kwargs)
A:dask.array.reductions.nanmean->wraps(chunk.nanmean)(nanmean)
A:dask.array.reductions.x->A['x'].sum(**kwargs)
A:dask.array.reductions.x2->A['x2'].sum(**kwargs)
A:dask.array.reductions.nanvar->wraps(chunk.nanvar)(nanvar)
A:dask.array.reductions.nanstd->wraps(chunk.nanstd)(nanstd)
A:dask.array.reductions.pairs->list(pairs)
A:dask.array.reductions.(mins, argmins)->zip(*pairs)
A:dask.array.reductions.mins->numpy.array(mins)
A:dask.array.reductions.argmins->numpy.array(argmins)
A:dask.array.reductions.args->argfunc(mins, axis=0)
A:dask.array.reductions.offsets->offsets.reshape((len(offsets),) + (1,) * (argmins.ndim - 1)).reshape((len(offsets),) + (1,) * (argmins.ndim - 1))
A:dask.array.reductions.a2->elemwise(argreduce, a)
dask.array.all(a,axis=None,keepdims=False)
dask.array.any(a,axis=None,keepdims=False)
dask.array.argmax(a,axis=None)
dask.array.argmin(a,axis=None)
dask.array.max(a,axis=None,keepdims=False)
dask.array.mean(a,axis=None,keepdims=False)
dask.array.mean_agg(pair,**kwargs)
dask.array.mean_chunk(x,sum=chunk.sum,numel=numel,**kwargs)
dask.array.min(a,axis=None,keepdims=False)
dask.array.nanargmax(a,axis=None)
dask.array.nanargmin(a,axis=None)
dask.array.nanmax(a,axis=None,keepdims=False)
dask.array.nanmean(a,axis=None,keepdims=False)
dask.array.nanmin(a,axis=None,keepdims=False)
dask.array.nanstd(a,axis=None,keepdims=False,ddof=0)
dask.array.nansum(a,axis=None,keepdims=False)
dask.array.nanvar(a,axis=None,keepdims=False,ddof=0)
dask.array.prod(a,axis=None,keepdims=False)
dask.array.reductions.all(a,axis=None,keepdims=False)
dask.array.reductions.any(a,axis=None,keepdims=False)
dask.array.reductions.arg_aggregate(func,argfunc,dims,pairs)
dask.array.reductions.arg_reduction(a,func,argfunc,axis=0,dtype=None)
dask.array.reductions.argmax(a,axis=None)
dask.array.reductions.argmin(a,axis=None)
dask.array.reductions.max(a,axis=None,keepdims=False)
dask.array.reductions.mean(a,axis=None,keepdims=False)
dask.array.reductions.mean_agg(pair,**kwargs)
dask.array.reductions.mean_chunk(x,sum=chunk.sum,numel=numel,**kwargs)
dask.array.reductions.min(a,axis=None,keepdims=False)
dask.array.reductions.nanargmax(a,axis=None)
dask.array.reductions.nanargmin(a,axis=None)
dask.array.reductions.nanmax(a,axis=None,keepdims=False)
dask.array.reductions.nanmean(a,axis=None,keepdims=False)
dask.array.reductions.nanmin(a,axis=None,keepdims=False)
dask.array.reductions.nannumel(x,**kwargs)
dask.array.reductions.nanstd(a,axis=None,keepdims=False,ddof=0)
dask.array.reductions.nansum(a,axis=None,keepdims=False)
dask.array.reductions.nanvar(a,axis=None,keepdims=False,ddof=0)
dask.array.reductions.numel(x,**kwargs)
dask.array.reductions.prod(a,axis=None,keepdims=False)
dask.array.reductions.reduction(x,chunk,aggregate,axis=None,keepdims=None,dtype=None)
dask.array.reductions.std(a,axis=None,keepdims=False,ddof=0)
dask.array.reductions.sum(a,axis=None,keepdims=False)
dask.array.reductions.var(a,axis=None,keepdims=False,ddof=0)
dask.array.reductions.var_agg(A,ddof=None,**kwargs)
dask.array.reductions.var_chunk(A,sum=chunk.sum,numel=numel,**kwargs)
dask.array.reductions.vnorm(a,ord=None,axis=None,keepdims=False)
dask.array.std(a,axis=None,keepdims=False,ddof=0)
dask.array.sum(a,axis=None,keepdims=False)
dask.array.var(a,axis=None,keepdims=False,ddof=0)
dask.array.var_agg(A,ddof=None,**kwargs)
dask.array.var_chunk(A,sum=chunk.sum,numel=numel,**kwargs)
dask.array.vnorm(a,ord=None,axis=None,keepdims=False)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/creation.py----------------------------------------
A:dask.array.creation.remainder->tuple()
A:dask.array.creation.num->int(abs(range_ // step))
A:dask.array.creation.chunks->normalize_chunks(chunks, (num,))
A:dask.array.creation.name->next(arange_names)
A:dask.array.creation.dtype->kwargs.get('dtype', None)
dask.array.arange(*args,**kwargs)
dask.array.creation._get_blocksizes(num,blocksize)
dask.array.creation.arange(*args,**kwargs)
dask.array.creation.linspace(start,stop,num=50,chunks=None,dtype=None)
dask.array.linspace(start,stop,num=50,chunks=None,dtype=None)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/wrap.py----------------------------------------
A:dask.array.wrap.kwargs['size']->kwargs.pop('shape')
A:dask.array.wrap.size->kwargs.pop('size')
A:dask.array.wrap.chunks->normalize_chunks(chunks, shape)
A:dask.array.wrap.name->kwargs.pop('name', None)
A:dask.array.wrap.dtype->kwargs.pop('dtype', None)
A:dask.array.wrap.kw->kwargs.copy()
A:dask.array.wrap.keys->product([name], *[range(len(bd)) for bd in chunks])
A:dask.array.wrap.sizes->product(*chunks)
A:dask.array.wrap.dsk->dict(zip(keys, vals))
A:dask.array.wrap.shape->kwargs.pop('shape')
A:dask.array.wrap.shapes->product(*chunks)
A:dask.array.wrap.func->curry(func, dtype=dtype, **kwargs)
A:dask.array.wrap.f->curry(wrap_func, func, **kwargs)
A:dask.array.wrap.w->wrap(wrap_func_shape_as_first_arg)
A:dask.array.wrap.ones->w(np.ones, dtype='f8')
A:dask.array.wrap.zeros->w(np.zeros, dtype='f8')
A:dask.array.wrap.empty->w(np.empty, dtype='f8')
A:dask.array.wrap.full->w(np.full)
dask.array.wrap.dims_from_size(size,blocksize)
dask.array.wrap.wrap(wrap_func,func,**kwargs)
dask.array.wrap.wrap_func_shape_as_first_arg(func,*args,**kwargs)
dask.array.wrap.wrap_func_size_as_kwarg(func,*args,**kwargs)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/random.py----------------------------------------
A:dask.array.random.wrap->wrap(wrap_func_size_as_kwarg)
A:dask.array.random.random->wrap(np.random.random)
A:dask.array.random.beta->wrap(np.random.beta)
A:dask.array.random.binomial->wrap(np.random.binomial)
A:dask.array.random.chisquare->wrap(np.random.chisquare)
A:dask.array.random.exponential->wrap(np.random.exponential)
A:dask.array.random.f->wrap(np.random.f)
A:dask.array.random.gamma->wrap(np.random.gamma)
A:dask.array.random.geometric->wrap(np.random.geometric)
A:dask.array.random.gumbel->wrap(np.random.gumbel)
A:dask.array.random.hypergeometric->wrap(np.random.hypergeometric)
A:dask.array.random.laplace->wrap(np.random.laplace)
A:dask.array.random.logistic->wrap(np.random.logistic)
A:dask.array.random.lognormal->wrap(np.random.lognormal)
A:dask.array.random.logseries->wrap(np.random.logseries)
A:dask.array.random.negative_binomial->wrap(np.random.negative_binomial)
A:dask.array.random.noncentral_chisquare->wrap(np.random.noncentral_chisquare)
A:dask.array.random.noncentral_f->wrap(np.random.noncentral_f)
A:dask.array.random.normal->wrap(np.random.normal)
A:dask.array.random.pareto->wrap(np.random.pareto)
A:dask.array.random.poisson->wrap(np.random.poisson)
A:dask.array.random.power->wrap(np.random.power)
A:dask.array.random.rayleigh->wrap(np.random.rayleigh)
A:dask.array.random.triangular->wrap(np.random.triangular)
A:dask.array.random.uniform->wrap(np.random.uniform)
A:dask.array.random.vonmises->wrap(np.random.vonmises)
A:dask.array.random.wald->wrap(np.random.wald)
A:dask.array.random.weibull->wrap(np.random.weibull)
A:dask.array.random.zipf->wrap(np.random.zipf)
A:dask.array.random.standard_cauchy->wrap(np.random.standard_cauchy)
A:dask.array.random.standard_exponential->wrap(np.random.standard_exponential)
A:dask.array.random.standard_gamma->wrap(np.random.standard_gamma)
A:dask.array.random.standard_normal->wrap(np.random.standard_normal)
A:dask.array.random.standard_t->wrap(np.random.standard_t)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/rechunk.py----------------------------------------
A:dask.array.rechunk.old_chunks->normalize_chunks(old_chunks, shape)
A:dask.array.rechunk.new_chunks->list(old_chunks)
A:dask.array.rechunk.cmo->cumdims_label(old_chunks, 'o')
A:dask.array.rechunk.cmn->cumdims_label(new_chunks, 'n')
A:dask.array.rechunk.zipped->zip(old_chunks, new_chunks)
A:dask.array.rechunk.old_to_new->tuple((_intersect_1d(_breakpoints(cm[0], cm[1])) for cm in zip(cmo, cmn)))
A:dask.array.rechunk.cross1->tuple(product(*old_to_new))
A:dask.array.rechunk.cross->tuple(chain((tuple(product(*cr)) for cr in cross1)))
A:dask.array.rechunk.newlist->list(old)
A:dask.array.rechunk.shape->tuple(map(sum, old_chunks))
A:dask.array.rechunk.chunks->normalize_chunks(chunks, x.shape)
A:dask.array.rechunk.crossed->intersect_chunks(x.chunks, chunks)
A:dask.array.rechunk.x2->merge(x.dask, x2)
A:dask.array.rechunk.temp_name->next(rechunk_names)
A:dask.array.rechunk.new_index->tuple(product(*(tuple(range(len(n))) for n in chunks)))
A:dask.array.rechunk.cr2->iter(cross1)
A:dask.array.rechunk.old_blocks->tuple((tuple((ind for (ind, _) in cr)) for cr in cross1))
A:dask.array.rechunk.subdims->tuple((len(set((ss[i] for ss in old_blocks))) for i in range(x.ndim)))
A:dask.array.rechunk.rec_cat_arg->numpy.empty(subdims).tolist()
A:dask.array.rechunk.inds_in_block->product(*(range(s) for s in subdims))
A:dask.array.rechunk.ind_slics->next(cr2)
A:dask.array.rechunk.old_inds->tuple((tuple((s[0] for s in ind_slics)) for i in range(x.ndim)))
A:dask.array.rechunk.slic->tuple((tuple((s[1] for s in ind_slics)) for i in range(x.ndim)))
A:dask.array.rechunk.ind_in_blk->next(inds_in_block)
A:dask.array.rechunk.temp->getitem(temp, ind_in_blk[i])
dask.array.rechunk(x,chunks)
dask.array.rechunk._breakpoints(cumold,cumnew)
dask.array.rechunk._intersect_1d(breaks)
dask.array.rechunk.blockdims_dict_to_tuple(old,new)
dask.array.rechunk.blockshape_dict_to_tuple(old_chunks,d)
dask.array.rechunk.cumdims_label(chunks,const)
dask.array.rechunk.intersect_chunks(old_chunks=None,new_chunks=None,shape=None)
dask.array.rechunk.rechunk(x,chunks)


----------------------------------------/home/zhang/Packages/dask/dask0.4.0/array/percentile.py----------------------------------------
A:dask.array.percentile.q->numpy.array(q)
A:dask.array.percentile.result->merge_percentiles(finalq, qs, [v.codes for v in vals], Ns, interpolation)
A:dask.array.percentile.a2->a.astype('i8')
A:dask.array.percentile.name->next(names)
A:dask.array.percentile.dsk->dict((((name, i), (_percentile, key, q, interpolation)) for (i, key) in enumerate(a._keys())))
A:dask.array.percentile.name2->next(names)
A:dask.array.percentile.finalq->numpy.array(finalq)
A:dask.array.percentile.qs->list(map(list, qs))
A:dask.array.percentile.vals->list(vals)
A:dask.array.percentile.Ns->list(Ns)
A:dask.array.percentile.L->list(zip(*[(q, val, N) for (q, val, N) in zip(qs, vals, Ns) if N]))
A:dask.array.percentile.count->numpy.empty(len(q))
A:dask.array.percentile.count[1:]->numpy.diff(q)
A:dask.array.percentile.combined_vals_counts->merge_sorted(*map(zip, vals, counts))
A:dask.array.percentile.(combined_vals, combined_counts)->zip(*combined_vals_counts)
A:dask.array.percentile.combined_vals->numpy.array(combined_vals)
A:dask.array.percentile.combined_counts->numpy.array(combined_counts)
A:dask.array.percentile.combined_q->numpy.cumsum(combined_counts)
A:dask.array.percentile.rv->numpy.interp(desired_q, combined_q, combined_vals)
A:dask.array.percentile.left->numpy.searchsorted(combined_q, desired_q, side='left')
A:dask.array.percentile.lower->numpy.minimum(left, right)
A:dask.array.percentile.upper->numpy.maximum(left, right)
A:dask.array.percentile.lower_residual->numpy.abs(combined_q[lower] - desired_q)
A:dask.array.percentile.upper_residual->numpy.abs(combined_q[upper] - desired_q)
dask.array.percentile(a,q,interpolation='linear')
dask.array.percentile._percentile(a,q,interpolation='linear')
dask.array.percentile.merge_percentiles(finalq,qs,vals,Ns,interpolation='lower')
dask.array.percentile.percentile(a,q,interpolation='linear')

