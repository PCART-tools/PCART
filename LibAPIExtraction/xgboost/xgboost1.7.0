
----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/dask.py----------------------------------------
A:xgboost.dask.dd->LazyLoader('dd', globals(), 'dask.dataframe')
A:xgboost.dask.da->LazyLoader('da', globals(), 'dask.array')
A:xgboost.dask.dask->LazyLoader('dask', globals(), 'dask')
A:xgboost.dask.distributed->LazyLoader('distributed', globals(), 'dask.distributed')
A:xgboost.dask.TrainReturnT->TypedDict('TrainReturnT', {'booster': Booster, 'history': Dict})
A:xgboost.dask.LOGGER->logging.getLogger('[xgboost.dask]')
A:xgboost.dask.rabit_tracker->RabitTracker(host_ip=host_ip, n_workers=n_workers, use_logger=False, sortby='task')
A:xgboost.dask.host_ip->dconfig.get('scheduler_address', None)
A:xgboost.dask.thread->Thread(target=rabit_tracker.join)
A:xgboost.dask.env->_try_start_tracker(n_workers, [addr_from_user, addr_from_dask])
A:xgboost.dask.worker->LazyLoader('distributed', globals(), 'dask.distributed').get_worker()
A:xgboost.dask.info->_xgb_get_client(self._client).scheduler_info()
A:xgboost.dask.client->_xgb_get_client(self._client)
A:xgboost.dask.self._init->_xgb_get_client(self._client).sync(self._map_local_data, client, data, label=label, weights=weight, base_margin=base_margin, qid=qid, feature_weights=feature_weights, label_lower_bound=label_lower_bound, label_upper_bound=label_upper_bound)
A:xgboost.dask.d->DMatrix(numpy.empty((0, 0)), feature_names=feature_names, feature_types=feature_types, enable_categorical=enable_categorical)
A:xgboost.dask.delayed_obj->DMatrix(numpy.empty((0, 0)), feature_names=feature_names, feature_types=feature_types, enable_categorical=enable_categorical).to_delayed()
A:xgboost.dask.X_parts->to_delayed(data)
A:xgboost.dask.y_parts->flatten_meta(label)
A:xgboost.dask.w_parts->flatten_meta(weights)
A:xgboost.dask.margin_parts->flatten_meta(base_margin)
A:xgboost.dask.qid_parts->flatten_meta(qid)
A:xgboost.dask.ll_parts->flatten_meta(label_lower_bound)
A:xgboost.dask.lu_parts->flatten_meta(label_upper_bound)
A:xgboost.dask._MapRetT->TypeVar('_MapRetT')
A:xgboost.dask.fut->_xgb_get_client(self._client).submit(func, *args, pure=False, workers=[addr], allow_other_workers=False)
A:xgboost.dask.feature_names->self.data().columns.format()
A:xgboost.dask.args->locals()
A:xgboost.dask.unzipped_dict->_get_worker_parts(list_of_parts)
A:xgboost.dask.it->DaskPartitionIter(**unzipped_dict, feature_types=feature_types, feature_names=feature_names, feature_weights=feature_weights)
A:xgboost.dask.dmatrix->DMatrix(**concated_dict, missing=missing, feature_names=feature_names, feature_types=feature_types, nthread=nthread, enable_categorical=enable_categorical, feature_weights=feature_weights)
A:xgboost.dask.T->TypeVar('T')
A:xgboost.dask.v->concat_or_none(value)
A:xgboost.dask.(host_ip, port)->LazyLoader('distributed', globals(), 'dask.distributed').comm.get_address_host_port(host_ip)
A:xgboost.dask.sched_addr->sched_addr.strip('/:').strip('/:')
A:xgboost.dask.worker_map->set(e[0].worker_map.keys())
A:xgboost.dask.X_worker_map->X_worker_map.union(worker_map).union(worker_map)
A:xgboost.dask.workers->_get_workers_from_data(dtrain, evals)
A:xgboost.dask.local_param->parameters.copy()
A:xgboost.dask.Xy->_dmatrix_from_list_of_parts(**train_ref, nthread=n_threads)
A:xgboost.dask.eval_Xy->_dmatrix_from_list_of_parts(**ref, nthread=n_threads)
A:xgboost.dask.booster->worker_train(params=local_param, dtrain=Xy, num_boost_round=num_boost_round, evals_result=local_history, evals=evals if len(evals) != 0 else None, obj=obj, feval=feval, custom_metric=custom_metric, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval, xgb_model=xgb_model, callbacks=callbacks)
A:xgboost.dask.index->getattr(data, 'index', None)
A:xgboost.dask.prediction->_maybe_dataframe(partition, prediction, columns, is_df)
A:xgboost.dask.columns->tuple(meta.keys())
A:xgboost.dask.predictions->LazyLoader('da', globals(), 'dask.array').concatenate(arrays, axis=0)
A:xgboost.dask.new_axis->list(range(len(output_shape) - 2))
A:xgboost.dask.rng->numpy.random.RandomState(1994)
A:xgboost.dask.test_sample->numpy.random.RandomState(1994).randn(1, features)
A:xgboost.dask.kwargs->kwargs.copy().copy()
A:xgboost.dask.m->DMatrix(data, missing=missing, base_margin=base_margin, feature_names=feature_names, feature_types=feature_types)
A:xgboost.dask.test_predt->worker_train(params=local_param, dtrain=Xy, num_boost_round=num_boost_round, evals_result=local_history, evals=evals if len(evals) != 0 else None, obj=obj, feval=feval, custom_metric=custom_metric, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval, xgb_model=xgb_model, callbacks=callbacks).predict(m, validate_features=False, **kwargs)
A:xgboost.dask.predt->worker_train(params=local_param, dtrain=Xy, num_boost_round=num_boost_round, evals_result=local_history, evals=evals if len(evals) != 0 else None, obj=obj, feval=feval, custom_metric=custom_metric, early_stopping_rounds=early_stopping_rounds, verbose_eval=verbose_eval, xgb_model=xgb_model, callbacks=callbacks).predict(m, output_margin=output_margin, pred_leaf=pred_leaf, pred_contribs=pred_contribs, approx_contribs=approx_contribs, pred_interactions=pred_interactions, validate_features=validate_features, iteration_range=iteration_range, strict_shape=strict_shape)
A:xgboost.dask.base_margin->part.get('base_margin', None)
A:xgboost.dask.workers_address->list(data.worker_map.keys())
A:xgboost.dask.s->_xgb_get_client(self._client).submit(lambda part: part['data'].shape[0], part, workers=[w])
A:xgboost.dask.parts_with_order->sorted(parts_with_order, key=lambda p: p[2])
A:xgboost.dask.f->_xgb_get_client(self._client).submit(dispatched_predict, _booster, part, workers=[w])
A:xgboost.dask.(train_dmatrix, evals)->_wrap_evaluation_matrices(create_dmatrix=_dispatch, **kwargs)
A:xgboost.dask.iteration_range->self._get_iteration_range(iteration_range)
A:xgboost.dask.predts->predts.to_dask_array().to_dask_array()
A:xgboost.dask.this->self.__dict__.copy()
A:xgboost.dask.asynchronous->getattr(self, '_asynchronous', False)
A:xgboost.dask.ret->self.__dict__.copy().client.sync(func, **kwargs, asynchronous=asynchronous)
A:xgboost.dask.params->super().get_xgb_params()
A:xgboost.dask.(model, metric, params, early_stopping_rounds, callbacks)->self._configure_fit(xgb_model, eval_metric, params, early_stopping_rounds, callbacks)
A:xgboost.dask.self.n_classes_->len(self.classes_)
A:xgboost.dask.vstack->update_wrapper(partial(da.vstack, allow_unknown_chunksizes=True), da.vstack)
A:xgboost.dask.preds->LazyLoader('da', globals(), 'dask.array').map_blocks(_argmax, pred_probs, drop_axis=1)
xgboost.dask.CommunicatorContext(self,**args:Any)
xgboost.dask.DaskDMatrix(self,client:'distributed.Client',data:_DataT,label:Optional[_DaskCollection]=None,*,weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,missing:float=None,silent:bool=False,feature_names:Optional[FeatureNames]=None,feature_types:FeatureTypes=None,group:Optional[_DaskCollection]=None,qid:Optional[_DaskCollection]=None,label_lower_bound:Optional[_DaskCollection]=None,label_upper_bound:Optional[_DaskCollection]=None,feature_weights:Optional[_DaskCollection]=None,enable_categorical:bool=False)
xgboost.dask.DaskDMatrix.__await__(self)->Generator
xgboost.dask.DaskDMatrix._create_fn_args(self,worker_addr:str)->Dict[str, Any]
xgboost.dask.DaskDMatrix.num_col(self)->int
xgboost.dask.DaskDeviceQuantileDMatrix(self,*args:Any,**kwargs:Any)
xgboost.dask.DaskPartitionIter(self,data:List[Any],label:Optional[List[Any]]=None,weight:Optional[List[Any]]=None,base_margin:Optional[List[Any]]=None,qid:Optional[List[Any]]=None,label_lower_bound:Optional[List[Any]]=None,label_upper_bound:Optional[List[Any]]=None,feature_names:Optional[FeatureNames]=None,feature_types:Optional[Union[Any,List[Any]]]=None,feature_weights:Optional[Any]=None)
xgboost.dask.DaskPartitionIter._get(self,attr:str)->Optional[Any]
xgboost.dask.DaskPartitionIter.data(self)->Any
xgboost.dask.DaskPartitionIter.next(self,input_data:Callable)->int
xgboost.dask.DaskPartitionIter.reset(self)->None
xgboost.dask.DaskQuantileDMatrix(self,client:'distributed.Client',data:_DataT,label:Optional[_DaskCollection]=None,*,weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,missing:float=None,silent:bool=False,feature_names:Optional[FeatureNames]=None,feature_types:Optional[Union[Any,List[Any]]]=None,max_bin:Optional[int]=None,ref:Optional[DMatrix]=None,group:Optional[_DaskCollection]=None,qid:Optional[_DaskCollection]=None,label_lower_bound:Optional[_DaskCollection]=None,label_upper_bound:Optional[_DaskCollection]=None,feature_weights:Optional[_DaskCollection]=None,enable_categorical:bool=False)
xgboost.dask.DaskQuantileDMatrix._create_fn_args(self,worker_addr:str)->Dict[str, Any]
xgboost.dask.DaskScikitLearnBase(XGBModel)
xgboost.dask.DaskScikitLearnBase.__await__(self)->Awaitable[Any]
xgboost.dask.DaskScikitLearnBase.__getstate__(self)->Dict
xgboost.dask.DaskScikitLearnBase._client_sync(self,func:Callable,**kwargs:Any)->Any
xgboost.dask.DaskScikitLearnBase.apply(self,X:_DataT,ntree_limit:Optional[int]=None,iteration_range:Optional[Tuple[int,int]]=None)->Any
xgboost.dask.DaskScikitLearnBase.client(self)->'distributed.Client'
xgboost.dask.DaskScikitLearnBase.client(self,clt:'distributed.Client')->None
xgboost.dask.DaskScikitLearnBase.predict(self,X:_DataT,output_margin:bool=False,ntree_limit:Optional[int]=None,validate_features:bool=True,base_margin:Optional[_DaskCollection]=None,iteration_range:Optional[Tuple[int,int]]=None)->Any
xgboost.dask.DaskXGBClassifier(DaskScikitLearnBase,XGBClassifierBase)
xgboost.dask.DaskXGBClassifier.fit(self,X:_DataT,y:_DaskCollection,*,sample_weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,eval_set:Optional[Sequence[Tuple[_DaskCollection,_DaskCollection]]]=None,eval_metric:Optional[Union[str,Sequence[str],Callable]]=None,early_stopping_rounds:Optional[int]=None,verbose:Union[int,bool]=True,xgb_model:Optional[Union[Booster,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[_DaskCollection]]=None,base_margin_eval_set:Optional[Sequence[_DaskCollection]]=None,feature_weights:Optional[_DaskCollection]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'DaskXGBClassifier'
xgboost.dask.DaskXGBClassifier.predict_proba(self,X:_DaskCollection,ntree_limit:Optional[int]=None,validate_features:bool=True,base_margin:Optional[_DaskCollection]=None,iteration_range:Optional[Tuple[int,int]]=None)->Any
xgboost.dask.DaskXGBRFClassifier(self,*,learning_rate:Optional[float]=1,subsample:Optional[float]=0.8,colsample_bynode:Optional[float]=0.8,reg_lambda:Optional[float]=1e-05,**kwargs:Any)
xgboost.dask.DaskXGBRFClassifier.fit(self,X:_DataT,y:_DaskCollection,*,sample_weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,eval_set:Optional[Sequence[Tuple[_DaskCollection,_DaskCollection]]]=None,eval_metric:Optional[Union[str,Sequence[str],Callable]]=None,early_stopping_rounds:Optional[int]=None,verbose:Union[int,bool]=True,xgb_model:Optional[Union[Booster,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[_DaskCollection]]=None,base_margin_eval_set:Optional[Sequence[_DaskCollection]]=None,feature_weights:Optional[_DaskCollection]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'DaskXGBRFClassifier'
xgboost.dask.DaskXGBRFClassifier.get_num_boosting_rounds(self)->int
xgboost.dask.DaskXGBRFClassifier.get_xgb_params(self)->Dict[str, Any]
xgboost.dask.DaskXGBRFRegressor(self,*,learning_rate:Optional[float]=1,subsample:Optional[float]=0.8,colsample_bynode:Optional[float]=0.8,reg_lambda:Optional[float]=1e-05,**kwargs:Any)
xgboost.dask.DaskXGBRFRegressor.fit(self,X:_DataT,y:_DaskCollection,*,sample_weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,eval_set:Optional[Sequence[Tuple[_DaskCollection,_DaskCollection]]]=None,eval_metric:Optional[Union[str,Sequence[str],Callable]]=None,early_stopping_rounds:Optional[int]=None,verbose:Union[int,bool]=True,xgb_model:Optional[Union[Booster,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[_DaskCollection]]=None,base_margin_eval_set:Optional[Sequence[_DaskCollection]]=None,feature_weights:Optional[_DaskCollection]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'DaskXGBRFRegressor'
xgboost.dask.DaskXGBRFRegressor.get_num_boosting_rounds(self)->int
xgboost.dask.DaskXGBRFRegressor.get_xgb_params(self)->Dict[str, Any]
xgboost.dask.DaskXGBRanker(self,*,objective:str='rank:pairwise',**kwargs:Any)
xgboost.dask.DaskXGBRanker.fit(self,X:_DataT,y:_DaskCollection,*,group:Optional[_DaskCollection]=None,qid:Optional[_DaskCollection]=None,sample_weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,eval_set:Optional[Sequence[Tuple[_DaskCollection,_DaskCollection]]]=None,eval_group:Optional[Sequence[_DaskCollection]]=None,eval_qid:Optional[Sequence[_DaskCollection]]=None,eval_metric:Optional[Union[str,Sequence[str],Callable]]=None,early_stopping_rounds:int=None,verbose:Union[int,bool]=False,xgb_model:Optional[Union[XGBModel,Booster]]=None,sample_weight_eval_set:Optional[Sequence[_DaskCollection]]=None,base_margin_eval_set:Optional[Sequence[_DaskCollection]]=None,feature_weights:Optional[_DaskCollection]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'DaskXGBRanker'
xgboost.dask.DaskXGBRegressor(DaskScikitLearnBase,XGBRegressorBase)
xgboost.dask.DaskXGBRegressor.fit(self,X:_DataT,y:_DaskCollection,*,sample_weight:Optional[_DaskCollection]=None,base_margin:Optional[_DaskCollection]=None,eval_set:Optional[Sequence[Tuple[_DaskCollection,_DaskCollection]]]=None,eval_metric:Optional[Union[str,Sequence[str],Callable]]=None,early_stopping_rounds:Optional[int]=None,verbose:Union[int,bool]=True,xgb_model:Optional[Union[Booster,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[_DaskCollection]]=None,base_margin_eval_set:Optional[Sequence[_DaskCollection]]=None,feature_weights:Optional[_DaskCollection]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'DaskXGBRegressor'
xgboost.dask._assert_dask_support()->None
xgboost.dask._can_output_df(is_df:bool,output_shape:Tuple)->bool
xgboost.dask._create_dmatrix(feature_names:Optional[FeatureNames],feature_types:Optional[Union[Any,List[Any]]],feature_weights:Optional[Any],missing:float,nthread:int,enable_categorical:bool,parts:Optional[_DataParts])->DMatrix
xgboost.dask._create_quantile_dmatrix(feature_names:Optional[FeatureNames],feature_types:Optional[Union[Any,List[Any]]],feature_weights:Optional[Any],missing:float,nthread:int,parts:Optional[_DataParts],max_bin:int,enable_categorical:bool,ref:Optional[DMatrix]=None)->QuantileDMatrix
xgboost.dask._dmatrix_from_list_of_parts(is_quantile:bool,**kwargs:Any)->DMatrix
xgboost.dask._get_dask_config()->Optional[Dict[str, Any]]
xgboost.dask._get_worker_parts(list_of_parts:_DataParts)->Dict[str, List[Any]]
xgboost.dask._get_workers_from_data(dtrain:DaskDMatrix,evals:Optional[Sequence[Tuple[DaskDMatrix,str]]])->List[str]
xgboost.dask._infer_predict_output(booster:Booster,features:int,is_df:bool,inplace:bool,**kwargs:Any)->Tuple[Tuple[int, ...], Dict[int, str]]
xgboost.dask._maybe_dataframe(data:Any,prediction:Any,columns:List[int],is_df:bool)->Any
xgboost.dask._set_worker_client(model:'DaskScikitLearnBase',client:'distributed.Client')->Generator
xgboost.dask._start_tracker(n_workers:int,addr_from_dask:Optional[str],addr_from_user:Optional[Tuple[str,int]])->Dict[str, Union[int, str]]
xgboost.dask._try_start_tracker(n_workers:int,addrs:List[Union[Optional[str],Optional[Tuple[str,int]]]])->Dict[str, Union[int, str]]
xgboost.dask._xgb_get_client(client:Optional['distributed.Client'])->'distributed.Client'
xgboost.dask.dconcat(value:Sequence[_T])->_T
xgboost.dask.inplace_predict(client:Optional['distributed.Client'],model:Union[TrainReturnT,Booster,'distributed.Future'],data:_DataT,iteration_range:Tuple[int,int]=(0,0),predict_type:str='value',missing:float=numpy.nan,validate_features:bool=True,base_margin:Optional[_DaskCollection]=None,strict_shape:bool=False)->Any
xgboost.dask.predict(client:Optional['distributed.Client'],model:Union[TrainReturnT,Booster,'distributed.Future'],data:Union[DaskDMatrix,_DataT],output_margin:bool=False,missing:float=numpy.nan,pred_leaf:bool=False,pred_contribs:bool=False,approx_contribs:bool=False,pred_interactions:bool=False,validate_features:bool=True,iteration_range:Tuple[int,int]=(0,0),strict_shape:bool=False)->Any
xgboost.dask.train(client:'distributed.Client',params:Dict[str,Any],dtrain:DaskDMatrix,num_boost_round:int=10,*,evals:Optional[Sequence[Tuple[DaskDMatrix,str]]]=None,obj:Optional[Objective]=None,feval:Optional[Metric]=None,early_stopping_rounds:Optional[int]=None,xgb_model:Optional[Booster]=None,verbose_eval:Union[int,bool]=True,callbacks:Optional[Sequence[TrainingCallback]]=None,custom_metric:Optional[Metric]=None)->Any


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/federated.py----------------------------------------
xgboost.federated.run_federated_server(port:int,world_size:int,server_key_path:str='',server_cert_path:str='',client_cert_path:str='')->None


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/collective.py----------------------------------------
A:xgboost.collective.LOGGER->logging.getLogger('[xgboost.collective]')
A:xgboost.collective.config->from_pystr_to_cstr(json.dumps(args))
A:xgboost.collective.ret->core._LIB.XGCommunicatorGetWorldSize()
A:xgboost.collective.is_dist->core._LIB.XGCommunicatorIsDistributed()
A:xgboost.collective.msg->str(msg)
A:xgboost.collective.name_str->ctypes.c_char_p()
A:xgboost.collective.rank->get_rank()
A:xgboost.collective.length->ctypes.c_ulong()
A:xgboost.collective.s->pickle.dumps(data, protocol=pickle.HIGHEST_PROTOCOL)
A:xgboost.collective.length.value->len(s)
A:xgboost.collective.dptr->(ctypes.c_char * length.value)()
A:xgboost.collective.data->pickle.loads(dptr.raw)
A:xgboost.collective.buf->buf.copy().copy()
xgboost.collective.CommunicatorContext(self,**args:Any)
xgboost.collective.CommunicatorContext.__enter__(self)->Dict[str, Any]
xgboost.collective.CommunicatorContext.__exit__(self,*args:List)->None
xgboost.collective.Op(IntEnum)
xgboost.collective.allreduce(data:np.ndarray,op:Op)->np.ndarray
xgboost.collective.broadcast(data:_T,root:int)->_T
xgboost.collective.communicator_print(msg:Any)->None
xgboost.collective.finalize()->None
xgboost.collective.get_processor_name()->str
xgboost.collective.get_rank()->int
xgboost.collective.get_world_size()->int
xgboost.collective.init(**args:Any)->None
xgboost.collective.is_distributed()->int


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/testing.py----------------------------------------
A:xgboost.testing.PytestSkip->TypedDict('PytestSkip', {'condition': bool, 'reason': str})
A:xgboost.testing.(conn, _)->server.accept()
A:xgboost.testing.msg->conn.recv(3).decode()
xgboost.testing.has_ipv6()->bool
xgboost.testing.skip_ipv6()->PytestSkip
xgboost.testing.timeout(sec:int,*args:Any,enable:bool=True,**kwargs:Any)->Any


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/_typing.py----------------------------------------
A:xgboost._typing.CTypeT->TypeVar('CTypeT', ctypes.c_void_p, ctypes.c_char_p, ctypes.c_int, ctypes.c_float, ctypes.c_uint, ctypes.c_size_t)
A:xgboost._typing._T->TypeVar('_T')
A:xgboost._typing._F->TypeVar('_F', bound=Callable[..., Any])


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/sklearn.py----------------------------------------
A:xgboost.sklearn.labels->dmatrix.get_label()
A:xgboost.sklearn.y_true->dmatrix.get_label()
A:xgboost.sklearn.cls.__doc__->''.join(full_doc)
A:xgboost.sklearn.train_dmatrix->create_dmatrix(data=X, label=y, group=group, qid=qid, weight=sample_weight, base_margin=base_margin, feature_weights=feature_weights, missing=missing, enable_categorical=enable_categorical, feature_types=feature_types, ref=None)
A:xgboost.sklearn.sample_weight_eval_set->validate_or_none(sample_weight_eval_set, 'sample_weight_eval_set')
A:xgboost.sklearn.base_margin_eval_set->validate_or_none(base_margin_eval_set, 'base_margin_eval_set')
A:xgboost.sklearn.eval_group->validate_or_none(eval_group, 'eval_group')
A:xgboost.sklearn.eval_qid->validate_or_none(eval_qid, 'eval_qid')
A:xgboost.sklearn.m->create_dmatrix(data=valid_X, label=valid_y, weight=sample_weight_eval_set[i], group=eval_group[i], qid=eval_qid[i], base_margin=base_margin_eval_set[i], missing=missing, enable_categorical=enable_categorical, feature_types=feature_types, ref=train_dmatrix)
A:xgboost.sklearn.nevals->len(evals)
A:xgboost.sklearn.evals->list(zip(evals, eval_names))
A:xgboost.sklearn.parameters->self.get_xgb_params()
A:xgboost.sklearn.params->self.get_xgb_params()
A:xgboost.sklearn.cp->copy.copy(self)
A:xgboost.sklearn.params['random_state']->params['random_state'].randint(np.iinfo(np.int32).max).randint(np.iinfo(np.int32).max)
A:xgboost.sklearn.ret->t(value)
A:xgboost.sklearn.config->json.loads(self.get_booster().save_config())
A:xgboost.sklearn.obj->stack.pop()
A:xgboost.sklearn.params[k]->parse_parameter(v)
A:xgboost.sklearn.meta['_le']->self._le.to_json()
A:xgboost.sklearn.meta['classes_']->self.classes_.tolist()
A:xgboost.sklearn.meta['_estimator_type']->self._get_type()
A:xgboost.sklearn.meta_str->self.get_booster().attr('scikit_learn')
A:xgboost.sklearn.self._Booster->train(params, train_dmatrix, self.get_num_boosting_rounds(), early_stopping_rounds=early_stopping_rounds, evals=evals, evals_result=evals_result, custom_metric=metric, verbose_eval=verbose, xgb_model=model, callbacks=callbacks)
A:xgboost.sklearn.meta->json.loads(meta_str)
A:xgboost.sklearn.self._le->XGBoostLabelEncoder()
A:xgboost.sklearn.self.classes_->numpy.unique(np.asarray(y))
A:xgboost.sklearn.metric->_metric_decorator(eval_metric)
A:xgboost.sklearn.tree_method->self.get_xgb_params().get('tree_method', None)
A:xgboost.sklearn.self.evals_result_->cast(Dict[str, Dict[str, List[float]]], evals_result)
A:xgboost.sklearn.(train_dmatrix, evals)->_wrap_evaluation_matrices(missing=self.missing, X=X, y=y, group=group, qid=qid, sample_weight=sample_weight, base_margin=base_margin, feature_weights=feature_weights, eval_set=eval_set, sample_weight_eval_set=sample_weight_eval_set, base_margin_eval_set=base_margin_eval_set, eval_group=eval_group, eval_qid=eval_qid, create_dmatrix=self._create_dmatrix, enable_categorical=self.enable_categorical, feature_types=self.feature_types)
A:xgboost.sklearn.(model, metric, params, early_stopping_rounds, callbacks)->self._configure_fit(xgb_model, eval_metric, params, early_stopping_rounds, callbacks)
A:xgboost.sklearn.predictor->self.get_params().get('predictor', None)
A:xgboost.sklearn.iteration_range->self._get_iteration_range(iteration_range)
A:xgboost.sklearn.predts->cupy.asnumpy(predts)
A:xgboost.sklearn.test->DMatrix(X, base_margin=base_margin, missing=self.missing, nthread=self.n_jobs, feature_types=self.feature_types, enable_categorical=self.enable_categorical)
A:xgboost.sklearn.test_dmatrix->DMatrix(X, missing=self.missing, feature_types=self.feature_types, nthread=self.n_jobs)
A:xgboost.sklearn.booster->self.get_booster()
A:xgboost.sklearn.score->self.get_booster().get_score(importance_type=self.importance_type if self.importance_type else dft())
A:xgboost.sklearn.all_features_arr->numpy.array(all_features, dtype=np.float32)
A:xgboost.sklearn.total->numpy.array(all_features, dtype=np.float32).sum()
A:xgboost.sklearn.b->self.get_booster()
A:xgboost.sklearn.coef->coef.reshape((n_classes, -1)).reshape((n_classes, -1))
A:xgboost.sklearn.n_classes->getattr(self, 'n_classes_', None)
A:xgboost.sklearn.PredtT->TypeVar('PredtT', bound=np.ndarray)
A:xgboost.sklearn.self.n_classes_->len(self.classes_)
A:xgboost.sklearn.expected_classes->numpy.arange(self.n_classes_)
A:xgboost.sklearn.fit.__doc__->XGBModel.fit.__doc__.replace('Fit gradient boosting model', 'Fit gradient boosting classifier', 1)
A:xgboost.sklearn.class_probs->super().predict(X=X, ntree_limit=ntree_limit, validate_features=validate_features, base_margin=base_margin, iteration_range=iteration_range)
A:xgboost.sklearn.column_indexes->numpy.repeat(0, class_probs.shape[0])
A:xgboost.sklearn.raw_predt->super().predict(X=X, ntree_limit=ntree_limit, validate_features=validate_features, base_margin=base_margin, iteration_range=iteration_range, output_margin=True)
A:xgboost.sklearn.class_prob->softmax(raw_predt, axis=1)
xgboost.XGBClassifier(self,*,objective:_SklObjective='binary:logistic',use_label_encoder:Optional[bool]=None,**kwargs:Any)
xgboost.XGBModel(self,max_depth:Optional[int]=None,max_leaves:Optional[int]=None,max_bin:Optional[int]=None,grow_policy:Optional[str]=None,learning_rate:Optional[float]=None,n_estimators:int=100,verbosity:Optional[int]=None,objective:_SklObjective=None,booster:Optional[str]=None,tree_method:Optional[str]=None,n_jobs:Optional[int]=None,gamma:Optional[float]=None,min_child_weight:Optional[float]=None,max_delta_step:Optional[float]=None,subsample:Optional[float]=None,sampling_method:Optional[str]=None,colsample_bytree:Optional[float]=None,colsample_bylevel:Optional[float]=None,colsample_bynode:Optional[float]=None,reg_alpha:Optional[float]=None,reg_lambda:Optional[float]=None,scale_pos_weight:Optional[float]=None,base_score:Optional[float]=None,random_state:Optional[Union[np.random.RandomState,int]]=None,missing:float=np.nan,num_parallel_tree:Optional[int]=None,monotone_constraints:Optional[Union[Dict[str,int],str]]=None,interaction_constraints:Optional[Union[str,Sequence[Sequence[str]]]]=None,importance_type:Optional[str]=None,gpu_id:Optional[int]=None,validate_parameters:Optional[bool]=None,predictor:Optional[str]=None,enable_categorical:bool=False,feature_types:FeatureTypes=None,max_cat_to_onehot:Optional[int]=None,max_cat_threshold:Optional[int]=None,eval_metric:Optional[Union[str,List[str],Callable]]=None,early_stopping_rounds:Optional[int]=None,callbacks:Optional[List[TrainingCallback]]=None,**kwargs:Any)
xgboost.XGBRFClassifier(self,*,learning_rate:float=1.0,subsample:float=0.8,colsample_bynode:float=0.8,reg_lambda:float=1e-05,**kwargs:Any)
xgboost.XGBRFRegressor(self,*,learning_rate:float=1.0,subsample:float=0.8,colsample_bynode:float=0.8,reg_lambda:float=1e-05,**kwargs:Any)
xgboost.XGBRanker(self,*,objective:str='rank:pairwise',**kwargs:Any)
xgboost.XGBRegressor(self,*,objective:_SklObjective='reg:squarederror',**kwargs:Any)
xgboost.sklearn.XGBClassifier(self,*,objective:_SklObjective='binary:logistic',use_label_encoder:Optional[bool]=None,**kwargs:Any)
xgboost.sklearn.XGBClassifier.fit(self,X:ArrayLike,y:ArrayLike,*,sample_weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,eval_set:Optional[Sequence[Tuple[ArrayLike,ArrayLike]]]=None,eval_metric:Optional[Union[str,Sequence[str],Metric]]=None,early_stopping_rounds:Optional[int]=None,verbose:Optional[Union[bool,int]]=True,xgb_model:Optional[Union[Booster,str,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[ArrayLike]]=None,base_margin_eval_set:Optional[Sequence[ArrayLike]]=None,feature_weights:Optional[ArrayLike]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'XGBClassifier'
xgboost.sklearn.XGBClassifier.predict(self,X:ArrayLike,output_margin:bool=False,ntree_limit:Optional[int]=None,validate_features:bool=True,base_margin:Optional[ArrayLike]=None,iteration_range:Optional[Tuple[int,int]]=None)->np.ndarray
xgboost.sklearn.XGBClassifier.predict_proba(self,X:ArrayLike,ntree_limit:Optional[int]=None,validate_features:bool=True,base_margin:Optional[ArrayLike]=None,iteration_range:Optional[Tuple[int,int]]=None)->np.ndarray
xgboost.sklearn.XGBModel(self,max_depth:Optional[int]=None,max_leaves:Optional[int]=None,max_bin:Optional[int]=None,grow_policy:Optional[str]=None,learning_rate:Optional[float]=None,n_estimators:int=100,verbosity:Optional[int]=None,objective:_SklObjective=None,booster:Optional[str]=None,tree_method:Optional[str]=None,n_jobs:Optional[int]=None,gamma:Optional[float]=None,min_child_weight:Optional[float]=None,max_delta_step:Optional[float]=None,subsample:Optional[float]=None,sampling_method:Optional[str]=None,colsample_bytree:Optional[float]=None,colsample_bylevel:Optional[float]=None,colsample_bynode:Optional[float]=None,reg_alpha:Optional[float]=None,reg_lambda:Optional[float]=None,scale_pos_weight:Optional[float]=None,base_score:Optional[float]=None,random_state:Optional[Union[np.random.RandomState,int]]=None,missing:float=np.nan,num_parallel_tree:Optional[int]=None,monotone_constraints:Optional[Union[Dict[str,int],str]]=None,interaction_constraints:Optional[Union[str,Sequence[Sequence[str]]]]=None,importance_type:Optional[str]=None,gpu_id:Optional[int]=None,validate_parameters:Optional[bool]=None,predictor:Optional[str]=None,enable_categorical:bool=False,feature_types:FeatureTypes=None,max_cat_to_onehot:Optional[int]=None,max_cat_threshold:Optional[int]=None,eval_metric:Optional[Union[str,List[str],Callable]]=None,early_stopping_rounds:Optional[int]=None,callbacks:Optional[List[TrainingCallback]]=None,**kwargs:Any)
xgboost.sklearn.XGBModel.__sklearn_is_fitted__(self)->bool
xgboost.sklearn.XGBModel._can_use_inplace_predict(self)->bool
xgboost.sklearn.XGBModel._configure_fit(self,booster:Optional[Union[Booster,'XGBModel',str]],eval_metric:Optional[Union[Callable,str,Sequence[str]]],params:Dict[str,Any],early_stopping_rounds:Optional[int],callbacks:Optional[Sequence[TrainingCallback]])->Tuple[Optional[Union[Booster, str, 'XGBModel']], Optional[Metric], Dict[str, Any], Optional[int], Optional[Sequence[TrainingCallback]]]
xgboost.sklearn.XGBModel._create_dmatrix(self,ref:Optional[DMatrix],**kwargs:Any)->DMatrix
xgboost.sklearn.XGBModel._early_stopping_attr(self,attr:str)->Union[float, int]
xgboost.sklearn.XGBModel._get_iteration_range(self,iteration_range:Optional[Tuple[int,int]])->Tuple[int, int]
xgboost.sklearn.XGBModel._get_type(self)->str
xgboost.sklearn.XGBModel._more_tags(self)->Dict[str, bool]
xgboost.sklearn.XGBModel._set_evaluation_result(self,evals_result:TrainingCallback.EvalsLog)->None
xgboost.sklearn.XGBModel.apply(self,X:ArrayLike,ntree_limit:int=0,iteration_range:Optional[Tuple[int,int]]=None)->np.ndarray
xgboost.sklearn.XGBModel.best_iteration(self)->int
xgboost.sklearn.XGBModel.best_ntree_limit(self)->int
xgboost.sklearn.XGBModel.best_score(self)->float
xgboost.sklearn.XGBModel.coef_(self)->np.ndarray
xgboost.sklearn.XGBModel.evals_result(self)->Dict[str, Dict[str, List[float]]]
xgboost.sklearn.XGBModel.feature_importances_(self)->np.ndarray
xgboost.sklearn.XGBModel.feature_names_in_(self)->np.ndarray
xgboost.sklearn.XGBModel.fit(self,X:ArrayLike,y:ArrayLike,*,sample_weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,eval_set:Optional[Sequence[Tuple[ArrayLike,ArrayLike]]]=None,eval_metric:Optional[Union[str,Sequence[str],Metric]]=None,early_stopping_rounds:Optional[int]=None,verbose:Optional[Union[bool,int]]=True,xgb_model:Optional[Union[Booster,str,'XGBModel']]=None,sample_weight_eval_set:Optional[Sequence[ArrayLike]]=None,base_margin_eval_set:Optional[Sequence[ArrayLike]]=None,feature_weights:Optional[ArrayLike]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'XGBModel'
xgboost.sklearn.XGBModel.get_booster(self)->Booster
xgboost.sklearn.XGBModel.get_num_boosting_rounds(self)->int
xgboost.sklearn.XGBModel.get_params(self,deep:bool=True)->Dict[str, Any]
xgboost.sklearn.XGBModel.get_xgb_params(self)->Dict[str, Any]
xgboost.sklearn.XGBModel.intercept_(self)->np.ndarray
xgboost.sklearn.XGBModel.load_model(self,fname:Union[str,bytearray,os.PathLike])->None
xgboost.sklearn.XGBModel.n_features_in_(self)->int
xgboost.sklearn.XGBModel.predict(self,X:ArrayLike,output_margin:bool=False,ntree_limit:Optional[int]=None,validate_features:bool=True,base_margin:Optional[ArrayLike]=None,iteration_range:Optional[Tuple[int,int]]=None)->np.ndarray
xgboost.sklearn.XGBModel.save_model(self,fname:Union[str,os.PathLike])->None
xgboost.sklearn.XGBModel.set_params(self,**params:Any)->'XGBModel'
xgboost.sklearn.XGBRFClassifier(self,*,learning_rate:float=1.0,subsample:float=0.8,colsample_bynode:float=0.8,reg_lambda:float=1e-05,**kwargs:Any)
xgboost.sklearn.XGBRFClassifier.fit(self,X:ArrayLike,y:ArrayLike,*,sample_weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,eval_set:Optional[Sequence[Tuple[ArrayLike,ArrayLike]]]=None,eval_metric:Optional[Union[str,Sequence[str],Metric]]=None,early_stopping_rounds:Optional[int]=None,verbose:Optional[Union[bool,int]]=True,xgb_model:Optional[Union[Booster,str,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[ArrayLike]]=None,base_margin_eval_set:Optional[Sequence[ArrayLike]]=None,feature_weights:Optional[ArrayLike]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'XGBRFClassifier'
xgboost.sklearn.XGBRFClassifier.get_num_boosting_rounds(self)->int
xgboost.sklearn.XGBRFClassifier.get_xgb_params(self)->Dict[str, Any]
xgboost.sklearn.XGBRFRegressor(self,*,learning_rate:float=1.0,subsample:float=0.8,colsample_bynode:float=0.8,reg_lambda:float=1e-05,**kwargs:Any)
xgboost.sklearn.XGBRFRegressor.fit(self,X:ArrayLike,y:ArrayLike,*,sample_weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,eval_set:Optional[Sequence[Tuple[ArrayLike,ArrayLike]]]=None,eval_metric:Optional[Union[str,Sequence[str],Metric]]=None,early_stopping_rounds:Optional[int]=None,verbose:Optional[Union[bool,int]]=True,xgb_model:Optional[Union[Booster,str,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[ArrayLike]]=None,base_margin_eval_set:Optional[Sequence[ArrayLike]]=None,feature_weights:Optional[ArrayLike]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'XGBRFRegressor'
xgboost.sklearn.XGBRFRegressor.get_num_boosting_rounds(self)->int
xgboost.sklearn.XGBRFRegressor.get_xgb_params(self)->Dict[str, Any]
xgboost.sklearn.XGBRanker(self,*,objective:str='rank:pairwise',**kwargs:Any)
xgboost.sklearn.XGBRanker.fit(self,X:ArrayLike,y:ArrayLike,*,group:Optional[ArrayLike]=None,qid:Optional[ArrayLike]=None,sample_weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,eval_set:Optional[Sequence[Tuple[ArrayLike,ArrayLike]]]=None,eval_group:Optional[Sequence[ArrayLike]]=None,eval_qid:Optional[Sequence[ArrayLike]]=None,eval_metric:Optional[Union[str,Sequence[str],Metric]]=None,early_stopping_rounds:Optional[int]=None,verbose:Optional[Union[bool,int]]=False,xgb_model:Optional[Union[Booster,str,XGBModel]]=None,sample_weight_eval_set:Optional[Sequence[ArrayLike]]=None,base_margin_eval_set:Optional[Sequence[ArrayLike]]=None,feature_weights:Optional[ArrayLike]=None,callbacks:Optional[Sequence[TrainingCallback]]=None)->'XGBRanker'
xgboost.sklearn.XGBRankerMixIn
xgboost.sklearn.XGBRegressor(self,*,objective:_SklObjective='reg:squarederror',**kwargs:Any)
xgboost.sklearn._check_rf_callback(early_stopping_rounds:Optional[int],callbacks:Optional[Sequence[TrainingCallback]])->None
xgboost.sklearn._cls_predict_proba(n_classes:int,prediction:PredtT,vstack:Callable)->PredtT
xgboost.sklearn._metric_decorator(func:Callable)->Metric
xgboost.sklearn._objective_decorator(func:Callable[[np.ndarray,np.ndarray],Tuple[np.ndarray,np.ndarray]])->Callable[[np.ndarray, DMatrix], Tuple[np.ndarray, np.ndarray]]
xgboost.sklearn._wrap_evaluation_matrices(missing:float,X:Any,y:Any,group:Optional[Any],qid:Optional[Any],sample_weight:Optional[Any],base_margin:Optional[Any],feature_weights:Optional[Any],eval_set:Optional[Sequence[Tuple[Any,Any]]],sample_weight_eval_set:Optional[Sequence[Any]],base_margin_eval_set:Optional[Sequence[Any]],eval_group:Optional[Sequence[Any]],eval_qid:Optional[Sequence[Any]],create_dmatrix:Callable,enable_categorical:bool,feature_types:Optional[FeatureTypes])->Tuple[Any, List[Tuple[Any, str]]]
xgboost.sklearn.xgboost_model_doc(header:str,items:List[str],extra_parameters:Optional[str]=None,end_note:Optional[str]=None)->Callable[[Type], Type]


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/tracker.py----------------------------------------
A:xgboost.tracker.chunk->self.sock.recv(min(nbytes - nread, 1024))
A:xgboost.tracker.slen->self.recvint()
A:xgboost.tracker.worker->ExSocket(sock)
A:xgboost.tracker.self.host->get_some_ip(s_addr[0])
A:xgboost.tracker.magic->ExSocket(sock).recvint()
A:xgboost.tracker.self.rank->ExSocket(sock).recvint()
A:xgboost.tracker.self.world_size->ExSocket(sock).recvint()
A:xgboost.tracker.self.task_id->ExSocket(sock).recvstr()
A:xgboost.tracker.self.cmd->ExSocket(sock).recvstr()
A:xgboost.tracker.msg->self.sock.recvstr()
A:xgboost.tracker.nnset->set(tree_map[rank])
A:xgboost.tracker.ngood->self.sock.recvint()
A:xgboost.tracker.goodset->set([])
A:xgboost.tracker.nerr->self.sock.recvint()
A:xgboost.tracker.self.port->self.sock.recvint()
A:xgboost.tracker.sock->socket.socket(get_family(host_ip), socket.SOCK_STREAM)
A:xgboost.tracker.tree_map[r]->self._get_neighbor(r, n_workers)
A:xgboost.tracker.nset->set(tree_map[rank])
A:xgboost.tracker.vlst->self.find_share_ring(tree_map, parent_map, v)
A:xgboost.tracker.rlst->self.find_share_ring(tree_map, parent_map, 0)
A:xgboost.tracker.n_workers->len(tree_map)
A:xgboost.tracker.(tree_map, parent_map)->self._get_tree(n_workers)
A:xgboost.tracker.ring_map->self.get_ring(tree_map, parent_map)
A:xgboost.tracker.(fd, s_addr)->self.sock.accept()
A:xgboost.tracker.s->socket.socket(socket.AF_INET, socket.SOCK_DGRAM)
A:xgboost.tracker.(tree_map, parent_map, ring_map)->self.get_link_map(n_workers)
A:xgboost.tracker.todo_nodes->list(range(n_workers))
A:xgboost.tracker.rank->list(range(n_workers)).pop(0)
A:xgboost.tracker.pending->self._sort_pending(pending)
A:xgboost.tracker.self.thread->Thread(target=run, args=(), daemon=True)
A:xgboost.tracker.host_ip->socket.gethostbyname(socket.gethostname())
A:xgboost.tracker.rabit->RabitTracker(host_ip=get_host_ip(args.host_ip), n_workers=args.num_workers, use_logger=True)
A:xgboost.tracker.parser->argparse.ArgumentParser(description='Rabit Tracker start.')
A:xgboost.tracker.args->argparse.ArgumentParser(description='Rabit Tracker start.').parse_args()
xgboost.RabitTracker(self,host_ip:str,n_workers:int,port:int=0,use_logger:bool=False,sortby:str='host')
xgboost.tracker.ExSocket(self,sock:socket.socket)
xgboost.tracker.ExSocket.recvall(self,nbytes:int)->bytes
xgboost.tracker.ExSocket.recvint(self)->int
xgboost.tracker.ExSocket.recvstr(self)->str
xgboost.tracker.ExSocket.sendint(self,value:int)->None
xgboost.tracker.ExSocket.sendstr(self,value:str)->None
xgboost.tracker.RabitTracker(self,host_ip:str,n_workers:int,port:int=0,use_logger:bool=False,sortby:str='host')
xgboost.tracker.RabitTracker.__del__(self)->None
xgboost.tracker.RabitTracker._get_neighbor(rank:int,n_workers:int)->List[int]
xgboost.tracker.RabitTracker._get_tree(self,n_workers:int)->Tuple[_TreeMap, Dict[int, int]]
xgboost.tracker.RabitTracker._sort_pending(self,pending:List[WorkerEntry])->List[WorkerEntry]
xgboost.tracker.RabitTracker.accept_workers(self,n_workers:int)->None
xgboost.tracker.RabitTracker.alive(self)->bool
xgboost.tracker.RabitTracker.find_share_ring(self,tree_map:_TreeMap,parent_map:Dict[int,int],rank:int)->List[int]
xgboost.tracker.RabitTracker.get_link_map(self,n_workers:int)->Tuple[_TreeMap, Dict[int, int], _RingMap]
xgboost.tracker.RabitTracker.get_ring(self,tree_map:_TreeMap,parent_map:Dict[int,int])->_RingMap
xgboost.tracker.RabitTracker.join(self)->None
xgboost.tracker.RabitTracker.start(self,n_workers:int)->None
xgboost.tracker.RabitTracker.worker_envs(self)->Dict[str, Union[str, int]]
xgboost.tracker.WorkerEntry(self,sock:socket.socket,s_addr:Tuple[str,int])
xgboost.tracker.WorkerEntry._get_remote(self,wait_conn:Dict[int,'WorkerEntry'],nnset:Set[int])->List[int]
xgboost.tracker.WorkerEntry.assign_rank(self,rank:int,wait_conn:Dict[int,'WorkerEntry'],tree_map:_TreeMap,parent_map:Dict[int,int],ring_map:_RingMap)->List[int]
xgboost.tracker.WorkerEntry.decide_rank(self,job_map:Dict[str,int])->int
xgboost.tracker.WorkerEntry.print(self,use_logger:bool)->None
xgboost.tracker.get_family(addr:str)->int
xgboost.tracker.get_host_ip(host_ip:Optional[str]=None)->str
xgboost.tracker.get_some_ip(host:str)->str
xgboost.tracker.main()->None
xgboost.tracker.start_rabit_tracker(args:argparse.Namespace)->None


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/data.py----------------------------------------
A:xgboost.data.interface_str->_array_interface(data)
A:xgboost.data.handle->ctypes.c_void_p()
A:xgboost.data.config->bytes(json.dumps({'missing': missing, 'nthread': nthread}), 'utf-8')
A:xgboost.data.data->_transform_dlpack(data)
A:xgboost.data.(data, dtype)->_ensure_np_dtype(data, dtype)
A:xgboost.data.(data, _)->_ensure_np_dtype(data, data.dtype)
A:xgboost.data.feature_names->_transform_dlpack(data).columns.format()
A:xgboost.data.transformed->_pandas_cat_null(data)
A:xgboost.data.transformed[cat_columns]->transformed[cat_columns].apply(lambda x: x.cat.codes).astype(np.float32).replace(-1.0, np.NaN).apply(lambda x: x.cat.codes).astype(np.float32).replace(-1.0, np.NaN)
A:xgboost.data.transformed[nul_columns]->transformed[nul_columns].astype(np.float32).astype(np.float32)
A:xgboost.data.(feature_names, feature_types)->_pandas_feature_info(data, meta, feature_names, feature_types, enable_categorical)
A:xgboost.data.arr->arr.astype(dtype).astype(dtype)
A:xgboost.data.(data, feature_names, feature_types)->_transform_dt_df(data, feature_names, feature_types, None, None)
A:xgboost.data.data_types_names->tuple((lt.name for lt in data.ltypes))
A:xgboost.data.feature_types->numpy.vectorize(_dt_type_mapper2.get)(data_types_names).tolist()
A:xgboost.data.ptrs->(ctypes.c_void_p * data.ncols)()
A:xgboost.data.col->_transform_dlpack(data).internal.column(icol)
A:xgboost.data.ptrs[icol]->frame_column_data_r(data, icol)
A:xgboost.data.feature_type_strings->(ctypes.c_char_p * data.ncols)()
A:xgboost.data.feature_type_strings[icol]->ctypes.c_char_p(data.stypes[icol].name.encode('utf-8'))
A:xgboost.data.batch->next(data_iter)
A:xgboost.data.ptr_schema->int(ffi.cast('uintptr_t', c_schemas[-1]))
A:xgboost.data.ptr_array->int(ffi.cast('uintptr_t', c_arrays[-1]))
A:xgboost.data.batches->_transform_dlpack(data).to_batches()
A:xgboost.data.rb_iter->iter(batches)
A:xgboost.data.it->record_batch_data_iter(rb_iter)
A:xgboost.data.next_callback->ctypes.CFUNCTYPE(ctypes.c_int, ctypes.c_void_p)(it)
A:xgboost.data.interfaces_str->_cudf_array_interfaces(data, cat_codes)
A:xgboost.data.(data, cat_codes, feature_names, feature_types)->_transform_cudf_df(data, feature_names, feature_types, enable_categorical)
A:xgboost.data.array->numpy.asarray(data)
A:xgboost.data.converted->_convert_unknown_data(data)
A:xgboost.data.data_np->numpy.array(data)
A:xgboost.data.interface->bytes(json.dumps([data.__cuda_array_interface__], indent=2), 'utf-8')
A:xgboost.data.(data, _, _)->_transform_pandas_df(data, False, meta=name, meta_type=dtype)
A:xgboost.data.(arr, feature_names, feature_types)->_transform_pandas_df(data, enable_categorical, feature_names, feature_types)
A:xgboost.data.err->TypeError('Value type is not supported for data iterator:' + str(type(data)))
xgboost.data.SingleBatchInternalIter(self,**kwargs:Any)
xgboost.data.SingleBatchInternalIter.next(self,input_data:Callable)->int
xgboost.data.SingleBatchInternalIter.reset(self)->None
xgboost.data._array_interface(data:np.ndarray)->bytes
xgboost.data._check_complex(data:DataType)->None
xgboost.data._check_data_shape(data:DataType)->None
xgboost.data._convert_unknown_data(data:DataType)->DataType
xgboost.data._cudf_array_interfaces(data:DataType,cat_codes:list)->bytes
xgboost.data._ensure_np_dtype(data:DataType,dtype:Optional[NumpyDType])->Tuple[np.ndarray, Optional[NumpyDType]]
xgboost.data._from_arrow(data:DataType,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool)->DispatchedDataBackendReturnType
xgboost.data._from_cudf_df(data:DataType,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool)->DispatchedDataBackendReturnType
xgboost.data._from_cupy_array(data:DataType,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_dlpack(data:DataType,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_dt_df(data:DataType,missing:Optional[FloatCompatible],nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool)->DispatchedDataBackendReturnType
xgboost.data._from_list(data:Sequence,missing:FloatCompatible,n_threads:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_numpy_array(data:DataType,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_pandas_df(data:DataFrame,enable_categorical:bool,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_pandas_series(data:DataType,missing:FloatCompatible,nthread:int,enable_categorical:bool,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_scipy_csc(data:DataType,missing:Optional[FloatCompatible],feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_scipy_csr(data:DataType,missing:FloatCompatible,nthread:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_tuple(data:Sequence,missing:FloatCompatible,n_threads:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._from_uri(data:DataType,missing:Optional[FloatCompatible],feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes])->DispatchedDataBackendReturnType
xgboost.data._has_array_protocol(data:DataType)->bool
xgboost.data._invalid_dataframe_dtype(data:DataType)->None
xgboost.data._is_arrow(data:DataType)->bool
xgboost.data._is_cudf_df(data:DataType)->bool
xgboost.data._is_cudf_ser(data:DataType)->bool
xgboost.data._is_cupy_array(data:DataType)->bool
xgboost.data._is_cupy_csc(data:DataType)->bool
xgboost.data._is_cupy_csr(data:DataType)->bool
xgboost.data._is_dlpack(data:DataType)->bool
xgboost.data._is_dt_df(data:DataType)->bool
xgboost.data._is_iter(data:DataType)->bool
xgboost.data._is_list(data:DataType)->bool
xgboost.data._is_modin_df(data:DataType)->bool
xgboost.data._is_modin_series(data:DataType)->bool
xgboost.data._is_numpy_array(data:DataType)->bool
xgboost.data._is_pandas_df(data:DataType)->bool
xgboost.data._is_pandas_series(data:DataType)->bool
xgboost.data._is_scipy_coo(data:DataType)->bool
xgboost.data._is_scipy_csc(data:DataType)->bool
xgboost.data._is_scipy_csr(data:DataType)->bool
xgboost.data._is_tuple(data:DataType)->bool
xgboost.data._is_uri(data:DataType)->bool
xgboost.data._maybe_np_slice(data:DataType,dtype:Optional[NumpyDType])->np.ndarray
xgboost.data._meta_from_cudf_df(data:DataType,field:str,handle:ctypes.c_void_p)->None
xgboost.data._meta_from_cudf_series(data:DataType,field:str,handle:ctypes.c_void_p)->None
xgboost.data._meta_from_cupy_array(data:DataType,field:str,handle:ctypes.c_void_p)->None
xgboost.data._meta_from_dt(data:DataType,field:str,dtype:Optional[NumpyDType],handle:ctypes.c_void_p)->None
xgboost.data._meta_from_list(data:Sequence,field:str,dtype:Optional[NumpyDType],handle:ctypes.c_void_p)->None
xgboost.data._meta_from_numpy(data:np.ndarray,field:str,dtype:Optional[NumpyDType],handle:ctypes.c_void_p)->None
xgboost.data._meta_from_pandas_series(data:DataType,name:str,dtype:Optional[NumpyDType],handle:ctypes.c_void_p)->None
xgboost.data._meta_from_tuple(data:Sequence,field:str,dtype:Optional[NumpyDType],handle:ctypes.c_void_p)->None
xgboost.data._pandas_cat_null(data:DataFrame)->DataFrame
xgboost.data._pandas_feature_info(data:DataFrame,meta:Optional[str],feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool)->Tuple[Optional[FeatureNames], Optional[FeatureTypes]]
xgboost.data._proxy_transform(data:DataType,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool)->Tuple[Union[bool, ctypes.c_void_p, np.ndarray], Optional[list], Optional[FeatureNames], Optional[FeatureTypes]]
xgboost.data._to_data_type(dtype:str,name:str)->int
xgboost.data._transform_cudf_df(data:DataType,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool)->Tuple[ctypes.c_void_p, list, Optional[FeatureNames], Optional[FeatureTypes]]
xgboost.data._transform_cupy_array(data:DataType)->CupyT
xgboost.data._transform_dlpack(data:DataType)->bool
xgboost.data._transform_dt_df(data:DataType,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],meta:Optional[str]=None,meta_type:Optional[NumpyDType]=None)->Tuple[np.ndarray, Optional[FeatureNames], Optional[FeatureTypes]]
xgboost.data._transform_pandas_df(data:DataFrame,enable_categorical:bool,feature_names:Optional[FeatureNames]=None,feature_types:Optional[FeatureTypes]=None,meta:Optional[str]=None,meta_type:Optional[NumpyDType]=None)->Tuple[np.ndarray, Optional[FeatureNames], Optional[FeatureTypes]]
xgboost.data._validate_meta_shape(data:DataType,name:str)->None
xgboost.data._warn_unused_missing(data:DataType,missing:Optional[FloatCompatible])->None
xgboost.data.dispatch_data_backend(data:DataType,missing:FloatCompatible,threads:int,feature_names:Optional[FeatureNames],feature_types:Optional[FeatureTypes],enable_categorical:bool=False)->DispatchedDataBackendReturnType
xgboost.data.dispatch_meta_backend(matrix:DMatrix,data:DataType,name:str,dtype:Optional[NumpyDType]=None)->None
xgboost.data.dispatch_proxy_set_data(proxy:_ProxyDMatrix,data:DataType,cat_codes:Optional[list],allow_host:bool)->None
xgboost.data.is_nullable_dtype(dtype:PandasDType)->bool
xgboost.data.record_batch_data_iter(data_iter:Iterator)->Callable


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/core.py----------------------------------------
A:xgboost.core.IterRange->TypeVar('IterRange', Optional[Tuple[int, int]], Tuple[int, int])
A:xgboost.core.(num_parallel_tree, _)->_get_booster_layer_trees(booster)
A:xgboost.core.num_parallel_tree->int(config['learner']['gradient_booster']['gbtree_train_param']['num_parallel_tree'])
A:xgboost.core.c_callback->ctypes.CFUNCTYPE(None, ctypes.c_char_p)
A:xgboost.core.major->ctypes.c_int()
A:xgboost.core.minor->ctypes.c_int()
A:xgboost.core.patch->ctypes.c_int()
A:xgboost.core.VERSION_FILE->os.path.join(os.path.dirname(__file__), 'VERSION')
A:xgboost.core.lib_paths->find_lib_path()
A:xgboost.core.pathBackup->os.environ['PATH'].split(os.pathsep)
A:xgboost.core.os.environ['PATH']->os.pathsep.join(pathBackup)
A:xgboost.core.lib->ctypes.cdll.LoadLibrary(lib_path)
A:xgboost.core.libname->os.path.basename(lib_paths[0])
A:xgboost.core.lib.callback->_get_log_callback_func()
A:xgboost.core.(major, minor, patch)->ver.split('-')[0].split('.')
A:xgboost.core.libver->_lib_version(lib)
A:xgboost.core.pyver->parse(_py_version())
A:xgboost.core.pyver_str->'.'.join((str(v) for v in pyver))
A:xgboost.core.libver_str->'.'.join((str(v) for v in libver))
A:xgboost.core._LIB->_load_lib()
A:xgboost.core.enable_categorical->_has_categorical(self, data)
A:xgboost.core.j_info->ctypes.c_char_p()
A:xgboost.core.res->from_cstr_to_pystr(sarr, length)
A:xgboost.core.interface_str->_cuda_array_interface(data)
A:xgboost.core.unownd->UnownedMemory(addr, length * ctypes.sizeof(CUPY_TO_CTYPES_MAPPING[dtype]), owner=None)
A:xgboost.core.memptr->MemoryPointer(unownd, 0)
A:xgboost.core.mem->cupy.ndarray((length,), dtype=dtype, memptr=memptr)
A:xgboost.core.arr->line.split('[')
A:xgboost.core.rptr->(ctypes.c_char * length).from_buffer(res)
A:xgboost.core.arr_shape->ctypes2numpy(shape, dims.value, np.uint64)
A:xgboost.core.length->c_bst_ulong()
A:xgboost.core.arr_predict->arr_predict.reshape(arr_shape).reshape(arr_shape)
A:xgboost.core.self._handle->_ProxyDMatrix()
A:xgboost.core.self._reset_callback->ctypes.CFUNCTYPE(None, ctypes.c_void_p)(self._reset_wrapper)
A:xgboost.core.self._next_callback->ctypes.CFUNCTYPE(ctypes.c_int, ctypes.c_void_p)(self._next_wrapper)
A:xgboost.core.self._exception->e.with_traceback(tb)
A:xgboost.core.(new, cat_codes, feature_names, feature_types)->_proxy_transform(data, feature_names, feature_types, self._enable_categorical)
A:xgboost.core.sig->signature(func)
A:xgboost.core.msg->ctypes.c_char_p()
A:xgboost.core._deprecate_positional_args->require_keyword_args(False)
A:xgboost.core.(handle, feature_names, feature_types)->dispatch_data_backend(data, missing=self.missing, threads=self.nthread, feature_names=feature_names, feature_types=feature_types, enable_categorical=enable_categorical)
A:xgboost.core.args_cstr->from_pystr_to_cstr(json.dumps(args))
A:xgboost.core.handle->ctypes.c_void_p()
A:xgboost.core.(reset_callback, next_callback)->SingleBatchInternalIter(data=data, **meta).get_callbacks(True, enable_categorical)
A:xgboost.core.ret->self.get_dump(fmap, with_stats, dump_format)
A:xgboost.core.fname->os.fspath(os.path.expanduser(fname))
A:xgboost.core.group_ptr->self.get_uint_info('group_ptr')
A:xgboost.core.indptr->numpy.empty(self.num_row() + 1, dtype=np.uint64)
A:xgboost.core.indices->numpy.empty(self.num_nonmissing(), dtype=np.uint32)
A:xgboost.core.data->_transform_cupy_array(data)
A:xgboost.core.c_indptr->numpy.empty(self.num_row() + 1, dtype=np.uint64).ctypes.data_as(ctypes.POINTER(c_bst_ulong))
A:xgboost.core.c_indices->numpy.empty(self.num_nonmissing(), dtype=np.uint32).ctypes.data_as(ctypes.POINTER(ctypes.c_uint32))
A:xgboost.core.c_data->_transform_cupy_array(data).ctypes.data_as(ctypes.POINTER(ctypes.c_float))
A:xgboost.core.config->make_jcargs(format=raw_format)
A:xgboost.core.res.handle->ctypes.c_void_p()
A:xgboost.core.rindex->_maybe_np_slice(rindex, dtype=np.int32)
A:xgboost.core.sarr->ctypes.POINTER(ctypes.c_char_p)()
A:xgboost.core.feature_names->list(feature_names)
A:xgboost.core.c_feature_names->(ctypes.c_char_p * len(feature_names_bytes))(*feature_names_bytes)
A:xgboost.core.feature_types->list(feature_types)
A:xgboost.core.c_feature_types->(ctypes.c_char_p * len(feature_types_bytes))(*feature_types_bytes)
A:xgboost.core.self.handle->ctypes.c_void_p()
A:xgboost.core.interfaces_str->_cudf_array_interfaces(data, cat_codes)
A:xgboost.core.it->SingleBatchInternalIter(data=data, **meta)
A:xgboost.core.num_groups->int(config['learner']['learner_model_param']['num_class'])
A:xgboost.core.params->params.items().items()
A:xgboost.core.params_list->list(params.items())
A:xgboost.core.dmats->c_array(ctypes.c_void_p, [d[0].handle for d in evals])
A:xgboost.core.state->model_file.__getstate__()
A:xgboost.core.ptr->(ctypes.c_char * len(buf)).from_buffer(buf)
A:xgboost.core.params_processed->self._configure_constraints(params_processed)
A:xgboost.core.constrained_features->set(value.keys())
A:xgboost.core.value->params.items().items().get('interaction_constraints')
A:xgboost.core.params['monotone_constraints']->self._transform_monotone_constrains(value)
A:xgboost.core.params['interaction_constraints']->self._transform_interaction_constraints(value)
A:xgboost.core.this->self.__dict__.copy()
A:xgboost.core.cptr->ctypes.POINTER(ctypes.c_char)()
A:xgboost.core.buf->ctypes2buffer(cptr, length.value)
A:xgboost.core.val->slice(val, val + 1)
A:xgboost.core.c_start->ctypes.c_int(start)
A:xgboost.core.c_stop->ctypes.c_int(stop)
A:xgboost.core.c_step->ctypes.c_int(step)
A:xgboost.core.sliced_handle->ctypes.c_void_p()
A:xgboost.core.status->_load_lib().XGBoosterSlice(self.handle, c_start, c_stop, c_step, ctypes.byref(sliced_handle))
A:xgboost.core.sliced->Booster()
A:xgboost.core.json_string->ctypes.c_char_p()
A:xgboost.core.result->ctypes.c_char_p().value.decode()
A:xgboost.core.success->ctypes.c_int()
A:xgboost.core.attr_names->from_cstr_to_pystr(sarr, length)
A:xgboost.core.c_value->c_str(str(value))
A:xgboost.core.feature_info->from_cstr_to_pystr(sarr, length)
A:xgboost.core.c_feature_info->(ctypes.c_char_p * len(feature_info_bytes))(*feature_info_bytes)
A:xgboost.core.pred->self.predict(dtrain, output_margin=True, training=True)
A:xgboost.core.(grad, hess)->fobj(pred, dtrain)
A:xgboost.core.evnames->c_array(ctypes.c_char_p, [c_str(d[1]) for d in evals])
A:xgboost.core.feval_ret->feval(self.predict(dmat, training=False, output_margin=output_margin), dmat)
A:xgboost.core.iteration_range->_convert_ntree_limit(self, ntree_limit, iteration_range)
A:xgboost.core.preds->ctypes.POINTER(ctypes.c_float)()
A:xgboost.core.shape->ctypes.POINTER(c_bst_ulong)()
A:xgboost.core.dims->c_bst_ulong()
A:xgboost.core.p_handle->ctypes.c_void_p()
A:xgboost.core.(data, fns, _)->_transform_pandas_df(data, enable_categorical)
A:xgboost.core.(data, _)->_ensure_np_dtype(data, data.dtype)
A:xgboost.core.(data, cat_codes, fns, _)->_transform_cudf_df(data, None, None, enable_categorical)
A:xgboost.core.self.best_iteration->int(self.attr('best_iteration'))
A:xgboost.core.self.best_score->float(self.attr('best_score'))
A:xgboost.core.self.best_ntree_limit->int(self.attr('best_ntree_limit'))
A:xgboost.core.rounds->ctypes.c_int()
A:xgboost.core.features->ctypes.POINTER(ctypes.c_char_p)()
A:xgboost.core.fout->os.fspath(os.path.expanduser(fout))
A:xgboost.core.fout_obj->open(fout, 'w', encoding='utf-8')
A:xgboost.core.fmap->os.fspath(os.path.expanduser(fmap))
A:xgboost.core.scores->ctypes.POINTER(ctypes.c_float)()
A:xgboost.core.n_out_features->c_bst_ulong()
A:xgboost.core.out_dim->c_bst_ulong()
A:xgboost.core.features_arr->from_cstr_to_pystr(features, n_out_features)
A:xgboost.core.scores_arr->_prediction_output(shape, out_dim, scores, False)
A:xgboost.core.results[feat]->float(score)
A:xgboost.core.trees->self.get_dump(fmap, with_stats=True)
A:xgboost.core.parse->fid[0].split(':')
A:xgboost.core.stats->re.split('=|,', fid[1])
A:xgboost.core.fid->arr[1].split(']')
A:xgboost.core.cats_split->cats.split(',')
A:xgboost.core.str_i->str(i)
A:xgboost.core.df->DataFrame({'Tree': tree_ids, 'Node': node_ids, 'ID': ids, 'Feature': fids, 'Split': splits, 'Yes': y_directs, 'No': n_directs, 'Missing': missings, 'Gain': gains, 'Cover': covers, 'Category': categories})
A:xgboost.core.xgdump->self.get_dump(fmap=fmap)
A:xgboost.core.regexp->re.compile('\\[{0}<([\\d.Ee+-]+)\\]'.format(feature))
A:xgboost.core.m->re.findall(regexp, val)
A:xgboost.core.n_unique->len(np.unique(values))
A:xgboost.core.bins->max(min(n_unique, bins) if bins is not None else n_unique, 1)
A:xgboost.core.nph->numpy.histogram(values, bins=bins)
A:xgboost.core.nph_stacked->numpy.column_stack((nph[1][1:], nph[0]))
A:xgboost.core.index->fn.index(feature)
xgboost.Booster(self,params:Optional[BoosterParam]=None,cache:Optional[Sequence[DMatrix]]=None,model_file:Optional[Union['Booster',bytearray,os.PathLike,str]]=None)
xgboost.DMatrix(self,data:DataType,label:Optional[ArrayLike]=None,*,weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,missing:Optional[float]=None,silent:bool=False,feature_names:Optional[FeatureNames]=None,feature_types:Optional[FeatureTypes]=None,nthread:Optional[int]=None,group:Optional[ArrayLike]=None,qid:Optional[ArrayLike]=None,label_lower_bound:Optional[ArrayLike]=None,label_upper_bound:Optional[ArrayLike]=None,feature_weights:Optional[ArrayLike]=None,enable_categorical:bool=False)
xgboost.DataIter(self,cache_prefix:Optional[str]=None)
xgboost.DeviceQuantileDMatrix(self,*args:Any,**kwargs:Any)
xgboost.QuantileDMatrix(self,data:DataType,label:Optional[ArrayLike]=None,*,weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,missing:Optional[float]=None,silent:bool=False,feature_names:Optional[FeatureNames]=None,feature_types:Optional[FeatureTypes]=None,nthread:Optional[int]=None,max_bin:Optional[int]=None,ref:Optional[DMatrix]=None,group:Optional[ArrayLike]=None,qid:Optional[ArrayLike]=None,label_lower_bound:Optional[ArrayLike]=None,label_upper_bound:Optional[ArrayLike]=None,feature_weights:Optional[ArrayLike]=None,enable_categorical:bool=False)
xgboost._py_version()->str
xgboost.build_info()->dict
xgboost.core.Booster(self,params:Optional[BoosterParam]=None,cache:Optional[Sequence[DMatrix]]=None,model_file:Optional[Union['Booster',bytearray,os.PathLike,str]]=None)
xgboost.core.Booster.__copy__(self)->'Booster'
xgboost.core.Booster.__deepcopy__(self,_:Any)->'Booster'
xgboost.core.Booster.__del__(self)->None
xgboost.core.Booster.__getitem__(self,val:Union[int,tuple,slice])->'Booster'
xgboost.core.Booster.__getstate__(self)->Dict
xgboost.core.Booster.__setstate__(self,state:Dict)->None
xgboost.core.Booster._configure_constraints(self,params:BoosterParam)->BoosterParam
xgboost.core.Booster._get_feature_info(self,field:str)->Optional[FeatureInfo]
xgboost.core.Booster._set_feature_info(self,features:Optional[FeatureInfo],field:str)->None
xgboost.core.Booster._transform_interaction_constraints(self,value:Union[Sequence[Sequence[str]],str])->Union[str, List[List[int]]]
xgboost.core.Booster._transform_monotone_constrains(self,value:Union[Dict[str,int],str,Tuple[int,...]])->Union[Tuple[int, ...], str]
xgboost.core.Booster._validate_dmatrix_features(self,data:DMatrix)->None
xgboost.core.Booster._validate_features(self,feature_names:Optional[FeatureNames])->None
xgboost.core.Booster.attr(self,key:str)->Optional[str]
xgboost.core.Booster.attributes(self)->Dict[str, Optional[str]]
xgboost.core.Booster.boost(self,dtrain:DMatrix,grad:np.ndarray,hess:np.ndarray)->None
xgboost.core.Booster.copy(self)->'Booster'
xgboost.core.Booster.dump_model(self,fout:Union[str,os.PathLike],fmap:Union[str,os.PathLike]='',with_stats:bool=False,dump_format:str='text')->None
xgboost.core.Booster.eval(self,data:DMatrix,name:str='eval',iteration:int=0)->str
xgboost.core.Booster.eval_set(self,evals:Sequence[Tuple[DMatrix,str]],iteration:int=0,feval:Optional[Metric]=None,output_margin:bool=True)->str
xgboost.core.Booster.feature_names(self)->Optional[FeatureNames]
xgboost.core.Booster.feature_names(self,features:Optional[FeatureNames])->None
xgboost.core.Booster.feature_types(self)->Optional[FeatureTypes]
xgboost.core.Booster.feature_types(self,features:Optional[FeatureTypes])->None
xgboost.core.Booster.get_dump(self,fmap:Union[str,os.PathLike]='',with_stats:bool=False,dump_format:str='text')->List[str]
xgboost.core.Booster.get_fscore(self,fmap:Union[str,os.PathLike]='')->Dict[str, Union[float, List[float]]]
xgboost.core.Booster.get_score(self,fmap:Union[str,os.PathLike]='',importance_type:str='weight')->Dict[str, Union[float, List[float]]]
xgboost.core.Booster.get_split_value_histogram(self,feature:str,fmap:Union[os.PathLike,str]='',bins:Optional[int]=None,as_pandas:bool=True)->Union[np.ndarray, DataFrame]
xgboost.core.Booster.inplace_predict(self,data:DataType,iteration_range:Tuple[int,int]=(0,0),predict_type:str='value',missing:float=np.nan,validate_features:bool=True,base_margin:Any=None,strict_shape:bool=False)->NumpyOrCupy
xgboost.core.Booster.load_config(self,config:str)->None
xgboost.core.Booster.load_model(self,fname:Union[str,bytearray,os.PathLike])->None
xgboost.core.Booster.num_boosted_rounds(self)->int
xgboost.core.Booster.num_features(self)->int
xgboost.core.Booster.predict(self,data:DMatrix,output_margin:bool=False,ntree_limit:int=0,pred_leaf:bool=False,pred_contribs:bool=False,approx_contribs:bool=False,pred_interactions:bool=False,validate_features:bool=True,training:bool=False,iteration_range:Tuple[int,int]=(0,0),strict_shape:bool=False)->np.ndarray
xgboost.core.Booster.save_config(self)->str
xgboost.core.Booster.save_model(self,fname:Union[str,os.PathLike])->None
xgboost.core.Booster.save_raw(self,raw_format:str='deprecated')->bytearray
xgboost.core.Booster.set_attr(self,**kwargs:Optional[str])->None
xgboost.core.Booster.set_param(self,params:Union[Dict,Iterable[Tuple[str,Any]],str],value:Optional[str]=None)->None
xgboost.core.Booster.trees_to_dataframe(self,fmap:Union[str,os.PathLike]='')->DataFrame
xgboost.core.Booster.update(self,dtrain:DMatrix,iteration:int,fobj:Optional[Objective]=None)->None
xgboost.core.DMatrix(self,data:DataType,label:Optional[ArrayLike]=None,*,weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,missing:Optional[float]=None,silent:bool=False,feature_names:Optional[FeatureNames]=None,feature_types:Optional[FeatureTypes]=None,nthread:Optional[int]=None,group:Optional[ArrayLike]=None,qid:Optional[ArrayLike]=None,label_lower_bound:Optional[ArrayLike]=None,label_upper_bound:Optional[ArrayLike]=None,feature_weights:Optional[ArrayLike]=None,enable_categorical:bool=False)
xgboost.core.DMatrix.__del__(self)->None
xgboost.core.DMatrix._init_from_iter(self,iterator:DataIter,enable_categorical:bool)->None
xgboost.core.DMatrix.feature_names(self)->Optional[FeatureNames]
xgboost.core.DMatrix.feature_names(self,feature_names:Optional[FeatureNames])->None
xgboost.core.DMatrix.feature_types(self)->Optional[FeatureTypes]
xgboost.core.DMatrix.feature_types(self,feature_types:Optional[Union[List[str],str]])->None
xgboost.core.DMatrix.get_base_margin(self)->np.ndarray
xgboost.core.DMatrix.get_data(self)->scipy.sparse.csr_matrix
xgboost.core.DMatrix.get_float_info(self,field:str)->np.ndarray
xgboost.core.DMatrix.get_group(self)->np.ndarray
xgboost.core.DMatrix.get_label(self)->np.ndarray
xgboost.core.DMatrix.get_uint_info(self,field:str)->np.ndarray
xgboost.core.DMatrix.get_weight(self)->np.ndarray
xgboost.core.DMatrix.num_col(self)->int
xgboost.core.DMatrix.num_nonmissing(self)->int
xgboost.core.DMatrix.num_row(self)->int
xgboost.core.DMatrix.save_binary(self,fname:Union[str,os.PathLike],silent:bool=True)->None
xgboost.core.DMatrix.set_base_margin(self,margin:ArrayLike)->None
xgboost.core.DMatrix.set_float_info(self,field:str,data:ArrayLike)->None
xgboost.core.DMatrix.set_float_info_npy2d(self,field:str,data:ArrayLike)->None
xgboost.core.DMatrix.set_group(self,group:ArrayLike)->None
xgboost.core.DMatrix.set_info(self,*,label:Optional[ArrayLike]=None,weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,group:Optional[ArrayLike]=None,qid:Optional[ArrayLike]=None,label_lower_bound:Optional[ArrayLike]=None,label_upper_bound:Optional[ArrayLike]=None,feature_names:Optional[FeatureNames]=None,feature_types:Optional[FeatureTypes]=None,feature_weights:Optional[ArrayLike]=None)->None
xgboost.core.DMatrix.set_label(self,label:ArrayLike)->None
xgboost.core.DMatrix.set_uint_info(self,field:str,data:ArrayLike)->None
xgboost.core.DMatrix.set_weight(self,weight:ArrayLike)->None
xgboost.core.DMatrix.slice(self,rindex:Union[List[int],np.ndarray],allow_groups:bool=False)->'DMatrix'
xgboost.core.DataIter(self,cache_prefix:Optional[str]=None)
xgboost.core.DataIter.__del__(self)->None
xgboost.core.DataIter._handle_exception(self,fn:Callable,dft_ret:_T)->_T
xgboost.core.DataIter._next_wrapper(self,this:None)->int
xgboost.core.DataIter._reset_wrapper(self,this:None)->None
xgboost.core.DataIter.get_callbacks(self,allow_host:bool,enable_categorical:bool)->Tuple[Callable, Callable]
xgboost.core.DataIter.next(self,input_data:Callable)->int
xgboost.core.DataIter.proxy(self)->'_ProxyDMatrix'
xgboost.core.DataIter.reraise(self)->None
xgboost.core.DataIter.reset(self)->None
xgboost.core.DeviceQuantileDMatrix(self,*args:Any,**kwargs:Any)
xgboost.core.QuantileDMatrix(self,data:DataType,label:Optional[ArrayLike]=None,*,weight:Optional[ArrayLike]=None,base_margin:Optional[ArrayLike]=None,missing:Optional[float]=None,silent:bool=False,feature_names:Optional[FeatureNames]=None,feature_types:Optional[FeatureTypes]=None,nthread:Optional[int]=None,max_bin:Optional[int]=None,ref:Optional[DMatrix]=None,group:Optional[ArrayLike]=None,qid:Optional[ArrayLike]=None,label_lower_bound:Optional[ArrayLike]=None,label_upper_bound:Optional[ArrayLike]=None,feature_weights:Optional[ArrayLike]=None,enable_categorical:bool=False)
xgboost.core.QuantileDMatrix._init(self,data:DataType,ref:Optional[DMatrix],enable_categorical:bool,**meta:Any)->None
xgboost.core.XGBoostError(ValueError)
xgboost.core._ProxyDMatrix(self)
xgboost.core._ProxyDMatrix._set_data_from_array(self,data:np.ndarray)->None
xgboost.core._ProxyDMatrix._set_data_from_csr(self,csr:scipy.sparse.csr_matrix)->None
xgboost.core._ProxyDMatrix._set_data_from_cuda_columnar(self,data:DataType,cat_codes:list)->None
xgboost.core._ProxyDMatrix._set_data_from_cuda_interface(self,data:DataType)->None
xgboost.core._check_call(ret:int)->None
xgboost.core._configure_metrics(params:BoosterParam)->BoosterParam
xgboost.core._convert_ntree_limit(booster:'Booster',ntree_limit:Optional[int],iteration_range:IterRange)->IterRange
xgboost.core._cuda_array_interface(data:DataType)->bytes
xgboost.core._expect(expectations:Sequence[Type],got:Type)->str
xgboost.core._get_booster_layer_trees(model:'Booster')->Tuple[int, int]
xgboost.core._get_log_callback_func()->Callable
xgboost.core._has_categorical(booster:'Booster',data:DataType)->bool
xgboost.core._lib_version(lib:ctypes.CDLL)->Tuple[int, int, int]
xgboost.core._load_lib()->ctypes.CDLL
xgboost.core._log_callback(msg:bytes)->None
xgboost.core._numpy2ctypes_type(dtype:Type[np.number])->Type[CNumeric]
xgboost.core._prediction_output(shape:CNumericPtr,dims:c_bst_ulong,predts:CFloatPtr,is_cuda:bool)->NumpyOrCupy
xgboost.core._py_version()->str
xgboost.core.build_info()->dict
xgboost.core.c_array(ctype:Type[CTypeT],values:ArrayLike)->Union[ctypes.Array, ctypes._Pointer]
xgboost.core.c_str(string:str)->ctypes.c_char_p
xgboost.core.ctypes2buffer(cptr:CStrPtr,length:int)->bytearray
xgboost.core.ctypes2cupy(cptr:CNumericPtr,length:int,dtype:Type[np.number])->CupyT
xgboost.core.ctypes2numpy(cptr:CNumericPtr,length:int,dtype:Type[np.number])->np.ndarray
xgboost.core.from_cstr_to_pystr(data:CStrPptr,length:c_bst_ulong)->List[str]
xgboost.core.from_pystr_to_cstr(data:Union[str,List[str]])->Union[bytes, ctypes.Array]
xgboost.core.make_jcargs(**kwargs:Any)->bytes
xgboost.core.require_keyword_args(error:bool)->Callable[[Callable[..., _T]], Callable[..., _T]]


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/libpath.py----------------------------------------
A:xgboost.libpath.curr_path->os.path.dirname(os.path.abspath(os.path.expanduser(__file__)))
xgboost.libpath.XGBoostLibraryNotFound(Exception)
xgboost.libpath.find_lib_path()->List[str]


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/config.py----------------------------------------
A:xgboost.config.config->json.loads(py_str(value))
A:xgboost.config.config_str->ctypes.c_char_p()
A:xgboost.config.old_config->get_config().copy()
xgboost.config.config_context(**new_config:Any)->Iterator[None]
xgboost.config.config_doc(*,header:Optional[str]=None,extra_note:Optional[str]=None,parameters:Optional[str]=None,returns:Optional[str]=None,see_also:Optional[str]=None)->Callable[[_F], _F]
xgboost.config.get_config()->Dict[str, Any]
xgboost.config.set_config(**new_config:Any)->None
xgboost.config_context(**new_config:Any)->Iterator[None]
xgboost.get_config()->Dict[str, Any]
xgboost.set_config(**new_config:Any)->None


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/plotting.py----------------------------------------
A:xgboost.plotting.importance->booster.get_booster().get_score(importance_type=importance_type, fmap=fmap)
A:xgboost.plotting.tuples->sorted(tuples, key=lambda _x: _x[1])
A:xgboost.plotting.(labels, values)->zip(*tuples)
A:xgboost.plotting.(_, ax)->matplotlib.pyplot.subplots(1, 1)
A:xgboost.plotting.ylocs->numpy.arange(len(values))
A:xgboost.plotting.booster->booster.get_booster().get_booster()
A:xgboost.plotting.g->to_graphviz(booster, fmap=fmap, num_trees=num_trees, rankdir=rankdir, **kwargs)
A:xgboost.plotting.s->BytesIO()
A:xgboost.plotting.img->matplotlib.image.imread(s)
xgboost.plot_importance(booster:Booster,ax:Optional[Axes]=None,height:float=0.2,xlim:Optional[tuple]=None,ylim:Optional[tuple]=None,title:str='Featureimportance',xlabel:str='Fscore',ylabel:str='Features',fmap:PathLike='',importance_type:str='weight',max_num_features:Optional[int]=None,grid:bool=True,show_values:bool=True,**kwargs:Any)->Axes
xgboost.plot_tree(booster:Booster,fmap:PathLike='',num_trees:int=0,rankdir:Optional[str]=None,ax:Optional[Axes]=None,**kwargs:Any)->Axes
xgboost.plotting.plot_importance(booster:Booster,ax:Optional[Axes]=None,height:float=0.2,xlim:Optional[tuple]=None,ylim:Optional[tuple]=None,title:str='Featureimportance',xlabel:str='Fscore',ylabel:str='Features',fmap:PathLike='',importance_type:str='weight',max_num_features:Optional[int]=None,grid:bool=True,show_values:bool=True,**kwargs:Any)->Axes
xgboost.plotting.plot_tree(booster:Booster,fmap:PathLike='',num_trees:int=0,rankdir:Optional[str]=None,ax:Optional[Axes]=None,**kwargs:Any)->Axes
xgboost.plotting.to_graphviz(booster:Booster,fmap:PathLike='',num_trees:int=0,rankdir:Optional[str]=None,yes_color:Optional[str]=None,no_color:Optional[str]=None,condition_node_params:Optional[dict]=None,leaf_node_params:Optional[dict]=None,**kwargs:Any)->GraphvizSource
xgboost.to_graphviz(booster:Booster,fmap:PathLike='',num_trees:int=0,rankdir:Optional[str]=None,yes_color:Optional[str]=None,no_color:Optional[str]=None,condition_node_params:Optional[dict]=None,leaf_node_params:Optional[dict]=None,**kwargs:Any)->GraphvizSource


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/callback.py----------------------------------------
A:xgboost.callback.it->it.decode().decode()
A:xgboost.callback.(k, v)->it.decode().decode().split(':')
A:xgboost.callback.as_arr->numpy.array(s)
A:xgboost.callback.msg->msg.decode().decode()
A:xgboost.callback._ART->TypeVar('_ART')
A:xgboost.callback.world->collective.get_world_size()
A:xgboost.callback.arr->numpy.array([score])
A:xgboost.callback.self.callbacks->set(callbacks)
A:xgboost.callback.model->c.after_training(model=model)
A:xgboost.callback.(num_parallel_tree, _)->_get_booster_layer_trees(model)
A:xgboost.callback.model.best_score->float(cast(str, model.attr('best_score')))
A:xgboost.callback.model.best_iteration->int(cast(str, model.attr('best_iteration')))
A:xgboost.callback.model.best_ntree_limit->int(cast(str, model.attr('best_ntree_limit')))
A:xgboost.callback.std->float(cast(Tuple[str, float, float], d)[2])
A:xgboost.callback.splited_names->name.split('-')
A:xgboost.callback.metric_name->'-'.join(splited_names[1:])
A:xgboost.callback.x->_allreduce_metric(x)
A:xgboost.callback.self.history[data_name]->collections.OrderedDict()
A:xgboost.callback.data_history[metric_name]->cast(_ScoreList, [])
A:xgboost.callback.scores->_aggcv(scores)
A:xgboost.callback.ret->any((c.after_iteration(model, epoch, self.history) for c in self.callbacks))
A:xgboost.callback.self.starting_round->c.after_training(model=model).num_boosted_rounds()
A:xgboost.callback.self.stopping_history[name][metric]->cast(_ScoreList, [score])
A:xgboost.callback.self._path->os.fspath(directory)
A:xgboost.callback.path->os.path.join(self._path, self._name + '_' + str(epoch) + ('.pkl' if self._as_pickle else '.json'))
xgboost.callback.CallbackContainer(self,callbacks:Sequence[TrainingCallback],metric:Callable=None,output_margin:bool=True,is_cv:bool=False)
xgboost.callback.CallbackContainer._update_history(self,score:Union[List[Tuple[str,float]],List[Tuple[str,float,float]]],epoch:int)->None
xgboost.callback.CallbackContainer.after_iteration(self,model:_Model,epoch:int,dtrain:DMatrix,evals:Optional[List[Tuple[DMatrix,str]]])->bool
xgboost.callback.CallbackContainer.after_training(self,model:_Model)->_Model
xgboost.callback.CallbackContainer.before_iteration(self,model:_Model,epoch:int,dtrain:DMatrix,evals:Optional[List[Tuple[DMatrix,str]]])->bool
xgboost.callback.CallbackContainer.before_training(self,model:_Model)->_Model
xgboost.callback.EarlyStopping(self,rounds:int,metric_name:Optional[str]=None,data_name:Optional[str]=None,maximize:Optional[bool]=None,save_best:Optional[bool]=False,min_delta:float=0.0)
xgboost.callback.EarlyStopping._update_rounds(self,score:_Score,name:str,metric:str,model:_Model,epoch:int)->bool
xgboost.callback.EarlyStopping.after_iteration(self,model:_Model,epoch:int,evals_log:TrainingCallback.EvalsLog)->bool
xgboost.callback.EarlyStopping.after_training(self,model:_Model)->_Model
xgboost.callback.EarlyStopping.before_training(self,model:_Model)->_Model
xgboost.callback.EvaluationMonitor(self,rank:int=0,period:int=1,show_stdv:bool=False)
xgboost.callback.EvaluationMonitor._fmt_metric(self,data:str,metric:str,score:float,std:Optional[float])->str
xgboost.callback.EvaluationMonitor.after_iteration(self,model:_Model,epoch:int,evals_log:TrainingCallback.EvalsLog)->bool
xgboost.callback.EvaluationMonitor.after_training(self,model:_Model)->_Model
xgboost.callback.LearningRateScheduler(self,learning_rates:Union[Callable[[int],float],Sequence[float]])
xgboost.callback.LearningRateScheduler.after_iteration(self,model:_Model,epoch:int,evals_log:TrainingCallback.EvalsLog)->bool
xgboost.callback.TrainingCallback(self)
xgboost.callback.TrainingCallback.after_iteration(self,model:_Model,epoch:int,evals_log:EvalsLog)->bool
xgboost.callback.TrainingCallback.after_training(self,model:_Model)->_Model
xgboost.callback.TrainingCallback.before_iteration(self,model:_Model,epoch:int,evals_log:EvalsLog)->bool
xgboost.callback.TrainingCallback.before_training(self,model:_Model)->_Model
xgboost.callback.TrainingCheckPoint(self,directory:Union[str,os.PathLike],name:str='model',as_pickle:bool=False,iterations:int=100)
xgboost.callback.TrainingCheckPoint.after_iteration(self,model:_Model,epoch:int,evals_log:TrainingCallback.EvalsLog)->bool
xgboost.callback._aggcv(rlist:List[str])->List[Tuple[str, float, float]]
xgboost.callback._allreduce_metric(score:_ART)->_ART


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/training.py----------------------------------------
A:xgboost.training.metric_fn->_configure_custom_metric(feval, custom_metric)
A:xgboost.training.bst->CallbackContainer(callbacks, metric=metric_fn, output_margin=callable(obj) or metric_fn is feval).after_training(bst)
A:xgboost.training.cb_container->CallbackContainer(callbacks, metric=metric_fn, output_margin=callable(obj) or metric_fn is feval)
A:xgboost.training.self.bst->Booster(param, [dtrain, dtest])
A:xgboost.training.group_boundaries->dall.get_uint_info('group_ptr')
A:xgboost.training.group_sizes->numpy.diff(group_boundaries)
A:xgboost.training.idx->numpy.arange(dall.num_row())
A:xgboost.training.out_group_idset->numpy.array_split(idx, nfold)
A:xgboost.training.dtrain->dall.slice(in_idset[k])
A:xgboost.training.dtest->dall.slice(out_idset[k])
A:xgboost.training.(dtrain, dtest, tparam)->fpreproc(dtrain, dtest, param.copy())
A:xgboost.training.evals->list(evals)
A:xgboost.training.out_idset->numpy.array_split(idx, nfold)
A:xgboost.training.splits->list(sfk.split(X=dall.get_label(), y=dall.get_label()))
A:xgboost.training.nfold->len(out_idset)
A:xgboost.training.sfk->XGBStratifiedKFold(n_splits=nfold, shuffle=True, random_state=seed)
A:xgboost.training.params->dict(((k, v) for (k, v) in params.items()))
A:xgboost.training.cvfolds->mknfold(dtrain, nfold, params, seed, metrics, fpreproc, stratified, folds, shuffle)
A:xgboost.training.callbacks_container->CallbackContainer(callbacks, metric=metric_fn, is_cv=True, output_margin=callable(obj) or metric_fn is feval)
A:xgboost.training.booster->_PackedBooster(cvfolds)
A:xgboost.training.should_break->CallbackContainer(callbacks, metric=metric_fn, is_cv=True, output_margin=callable(obj) or metric_fn is feval).after_iteration(booster, i, dtrain, None)
A:xgboost.training.results->pandas.DataFrame.from_dict(results)
xgboost.cv(params:BoosterParam,dtrain:DMatrix,num_boost_round:int=10,nfold:int=3,stratified:bool=False,folds:XGBStratifiedKFold=None,metrics:Sequence[str]=(),obj:Optional[Objective]=None,feval:Optional[Metric]=None,maximize:bool=None,early_stopping_rounds:int=None,fpreproc:FPreProcCallable=None,as_pandas:bool=True,verbose_eval:Optional[Union[int,bool]]=None,show_stdv:bool=True,seed:int=0,callbacks:Sequence[TrainingCallback]=None,shuffle:bool=True,custom_metric:Optional[Metric]=None)->Union[Dict[str, float], DataFrame]
xgboost.train(params:Dict[str,Any],dtrain:DMatrix,num_boost_round:int=10,*,evals:Optional[Sequence[Tuple[DMatrix,str]]]=None,obj:Optional[Objective]=None,feval:Optional[Metric]=None,maximize:Optional[bool]=None,early_stopping_rounds:Optional[int]=None,evals_result:TrainingCallback.EvalsLog=None,verbose_eval:Optional[Union[bool,int]]=True,xgb_model:Optional[Union[str,os.PathLike,Booster,bytearray]]=None,callbacks:Optional[Sequence[TrainingCallback]]=None,custom_metric:Optional[Metric]=None)->Booster
xgboost.training.CVPack(self,dtrain:DMatrix,dtest:DMatrix,param:Optional[Union[Dict,List]])
xgboost.training.CVPack.__getattr__(self,name:str)->Callable
xgboost.training.CVPack.eval(self,iteration:int,feval:Optional[Metric],output_margin:bool)->str
xgboost.training.CVPack.update(self,iteration:int,fobj:Optional[Objective])->None
xgboost.training._PackedBooster(self,cvfolds:_CVFolds)
xgboost.training._PackedBooster.attr(self,key:str)->Optional[str]
xgboost.training._PackedBooster.best_iteration(self)->int
xgboost.training._PackedBooster.best_score(self)->float
xgboost.training._PackedBooster.eval(self,iteration:int,feval:Optional[Metric],output_margin:bool)->List[str]
xgboost.training._PackedBooster.num_boosted_rounds(self)->int
xgboost.training._PackedBooster.set_attr(self,**kwargs:Optional[str])->Any
xgboost.training._PackedBooster.set_param(self,params:Union[Dict,Iterable[Tuple[str,Any]],str],value:Optional[str]=None)->None
xgboost.training._PackedBooster.update(self,iteration:int,obj:Optional[Objective])->None
xgboost.training._assert_new_callback(callbacks:Optional[Sequence[TrainingCallback]])->None
xgboost.training._configure_custom_metric(feval:Optional[Metric],custom_metric:Optional[Metric])->Optional[Metric]
xgboost.training.cv(params:BoosterParam,dtrain:DMatrix,num_boost_round:int=10,nfold:int=3,stratified:bool=False,folds:XGBStratifiedKFold=None,metrics:Sequence[str]=(),obj:Optional[Objective]=None,feval:Optional[Metric]=None,maximize:bool=None,early_stopping_rounds:int=None,fpreproc:FPreProcCallable=None,as_pandas:bool=True,verbose_eval:Optional[Union[int,bool]]=None,show_stdv:bool=True,seed:int=0,callbacks:Sequence[TrainingCallback]=None,shuffle:bool=True,custom_metric:Optional[Metric]=None)->Union[Dict[str, float], DataFrame]
xgboost.training.groups_to_rows(groups:List[np.ndarray],boundaries:np.ndarray)->np.ndarray
xgboost.training.mkgroupfold(dall:DMatrix,nfold:int,param:BoosterParam,evals:Sequence[str]=(),fpreproc:FPreProcCallable=None,shuffle:bool=True)->List[CVPack]
xgboost.training.mknfold(dall:DMatrix,nfold:int,param:BoosterParam,seed:int,evals:Sequence[str]=(),fpreproc:FPreProcCallable=None,stratified:bool=False,folds:XGBStratifiedKFold=None,shuffle:bool=True)->List[CVPack]
xgboost.training.train(params:Dict[str,Any],dtrain:DMatrix,num_boost_round:int=10,*,evals:Optional[Sequence[Tuple[DMatrix,str]]]=None,obj:Optional[Objective]=None,feval:Optional[Metric]=None,maximize:Optional[bool]=None,early_stopping_rounds:Optional[int]=None,evals_result:TrainingCallback.EvalsLog=None,verbose_eval:Optional[Union[bool,int]]=True,xgb_model:Optional[Union[str,os.PathLike,Booster,bytearray]]=None,callbacks:Optional[Sequence[TrainingCallback]]=None,custom_metric:Optional[Metric]=None)->Booster


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/compat.py----------------------------------------
A:xgboost.compat.meta[k]->v.tolist()
A:xgboost.compat.self.classes_->numpy.array(v)
A:xgboost.compat.value_arr->cast(Sequence[np.ndarray], value)
A:xgboost.compat.d->cupy.cuda.runtime.getDevice()
A:xgboost.compat.arr->cast(cupy.ndarray, v)
A:xgboost.compat.module->importlib.import_module(self.__name__)
A:xgboost.compat.self.module->self._load()
xgboost.compat.LazyLoader(self,local_name:str,parent_module_globals:Dict,name:str,warning:Optional[str]=None)
xgboost.compat.LazyLoader.__dir__(self)->List[str]
xgboost.compat.LazyLoader.__getattr__(self,item:str)->Any
xgboost.compat.LazyLoader._load(self)->types.ModuleType
xgboost.compat.XGBoostLabelEncoder(LabelEncoder)
xgboost.compat.XGBoostLabelEncoder.from_json(self,doc:Dict)->None
xgboost.compat.XGBoostLabelEncoder.to_json(self)->Dict
xgboost.compat.concat(value:Sequence[_T])->_T
xgboost.compat.lazy_isinstance(instance:Any,module:str,name:str)->bool
xgboost.compat.py_str(x:bytes)->str


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/__init__.py----------------------------------------
A:xgboost.__init__.__version__->_py_version()


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/estimator.py----------------------------------------
xgboost.spark.SparkXGBClassifier(self,**kwargs)
xgboost.spark.SparkXGBRanker(self,**kwargs)
xgboost.spark.SparkXGBRegressor(self,**kwargs)
xgboost.spark.estimator.SparkXGBClassifier(self,**kwargs)
xgboost.spark.estimator.SparkXGBClassifier._pyspark_model_cls(cls)
xgboost.spark.estimator.SparkXGBClassifier._validate_params(self)
xgboost.spark.estimator.SparkXGBClassifier._xgb_cls(cls)
xgboost.spark.estimator.SparkXGBRanker(self,**kwargs)
xgboost.spark.estimator.SparkXGBRanker._pyspark_model_cls(cls)
xgboost.spark.estimator.SparkXGBRanker._validate_params(self)
xgboost.spark.estimator.SparkXGBRanker._xgb_cls(cls)
xgboost.spark.estimator.SparkXGBRegressor(self,**kwargs)
xgboost.spark.estimator.SparkXGBRegressor._pyspark_model_cls(cls)
xgboost.spark.estimator.SparkXGBRegressor._validate_params(self)
xgboost.spark.estimator.SparkXGBRegressor._xgb_cls(cls)


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/utils.py----------------------------------------
A:xgboost.spark.utils.sig->inspect.signature(func)
A:xgboost.spark.utils.self.args['DMLC_TASK_ID']->str(context.partitionId())
A:xgboost.spark.utils.host->_get_host_ip(context)
A:xgboost.spark.utils.rabit_context->RabitTracker(host_ip=host, n_workers=n_workers)
A:xgboost.spark.utils.thread->Thread(target=rabit_context.join)
A:xgboost.spark.utils.env->_start_tracker(context, n_workers)
A:xgboost.spark.utils.logger->logging.getLogger(name)
A:xgboost.spark.utils.handler->logging.StreamHandler(sys.stderr)
A:xgboost.spark.utils.resources->task_context.resources()
xgboost.spark.utils.CommunicatorContext(self,context,**args)
xgboost.spark.utils.CommunicatorContext.__enter__(self)
xgboost.spark.utils.CommunicatorContext.__exit__(self,*args)
xgboost.spark.utils._get_args_from_message_list(messages)
xgboost.spark.utils._get_default_params_from_func(func,unsupported_set)
xgboost.spark.utils._get_gpu_id(task_context)->int
xgboost.spark.utils._get_host_ip(context)
xgboost.spark.utils._get_max_num_concurrent_tasks(spark_context)
xgboost.spark.utils._get_rabit_args(context,n_workers)
xgboost.spark.utils._get_spark_session()
xgboost.spark.utils._is_local(spark_context)->bool
xgboost.spark.utils._start_tracker(context,n_workers)
xgboost.spark.utils.get_class_name(cls)
xgboost.spark.utils.get_logger(name,level='INFO')


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/data.py----------------------------------------
A:xgboost.spark.data.array->_read_csr_matrix_from_unwrapped_spark_vec(part)
A:xgboost.spark.data.Alias->namedtuple('Alias', ('data', 'label', 'weight', 'margin', 'valid', 'qid'))
A:xgboost.spark.data.alias->Alias('values', 'label', 'weight', 'baseMargin', 'validationIndicator', 'qid')
A:xgboost.spark.data.vec_size->len(vec_values)
A:xgboost.spark.data.csr_indices->numpy.arange(vec_size, dtype=np.int32)
A:xgboost.spark.data.csr_indptr_arr->numpy.array(csr_indptr_list)
A:xgboost.spark.data.csr_indices_arr->numpy.concatenate(csr_indices_list)
A:xgboost.spark.data.csr_values_arr->numpy.concatenate(csr_values_list)
A:xgboost.spark.data.it->PartIter(data, gpu_id, **meta)
A:xgboost.spark.data.m->QuantileDMatrix(it, **params, ref=ref)
A:xgboost.spark.data.data->concat_or_none(values[alias.data])
A:xgboost.spark.data.label->concat_or_none(values.get(alias.label, None))
A:xgboost.spark.data.weight->concat_or_none(values.get(alias.weight, None))
A:xgboost.spark.data.margin->concat_or_none(values.get(alias.margin, None))
A:xgboost.spark.data.qid->concat_or_none(values.get(alias.qid, None))
A:xgboost.spark.data.(meta, params)->split_params()
A:xgboost.spark.data.dtrain->make(train_data, kwargs)
xgboost.spark.data.PartIter(self,data:Dict[str,List],device_id:Optional[int],**kwargs:Any)
xgboost.spark.data.PartIter._fetch(self,data:Optional[Sequence[pd.DataFrame]])->Optional[pd.DataFrame]
xgboost.spark.data.PartIter.next(self,input_data:Callable)->int
xgboost.spark.data.PartIter.reset(self)->None
xgboost.spark.data._read_csr_matrix_from_unwrapped_spark_vec(part:pd.DataFrame)->csr_matrix
xgboost.spark.data.cache_partitions(iterator:Iterator[pd.DataFrame],append:Callable[[pd.DataFrame,str,bool],None])->None
xgboost.spark.data.concat_or_none(seq:Optional[Sequence[np.ndarray]])->Optional[np.ndarray]
xgboost.spark.data.create_dmatrix_from_partitions(iterator:Iterator[pd.DataFrame],feature_cols:Optional[Sequence[str]],gpu_id:Optional[int],use_qdm:bool,kwargs:Dict[str,Any],enable_sparse_data_optim:bool,has_validation_col:bool)->Tuple[DMatrix, Optional[DMatrix]]
xgboost.spark.data.make_qdm(data:Dict[str,List[np.ndarray]],gpu_id:Optional[int],meta:Dict[str,Any],ref:Optional[DMatrix],params:Dict[str,Any])->DMatrix
xgboost.spark.data.stack_series(series:pd.Series)->np.ndarray


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/core.py----------------------------------------
A:xgboost.spark.core.num_workers->self.getOrDefault(self.num_workers)
A:xgboost.spark.core.use_gpu->self.getOrDefault(self.use_gpu)
A:xgboost.spark.core.force_repartition->Param(Params._dummy(), 'force_repartition', 'A boolean variable. Set force_repartition=true if you ' + 'want to force the input dataset to be repartitioned before XGBoost training.' + 'Note: The auto repartitioning judgement is not fully accurate, so it is recommended' + 'to have force_repartition be True.')
A:xgboost.spark.core.repartition_random_shuffle->Param(Params._dummy(), 'repartition_random_shuffle', 'A boolean variable. Set repartition_random_shuffle=true if you want to random shuffle dataset when repartitioning is required. By default is True.')
A:xgboost.spark.core.feature_names->Param(Params._dummy(), 'feature_names', 'A list of str to specify feature names.')
A:xgboost.spark.core.xgb_model_default->cls._xgb_cls()()
A:xgboost.spark.core.params_dict->pyspark_estimator_class._get_xgb_params_default()
A:xgboost.spark.core.filtered_params_dict->self._get_predict_params_default()
A:xgboost.spark.core.xgb_params[param.name]->self.getOrDefault(param)
A:xgboost.spark.core.arbitrary_params_dict->self.getOrDefault(self.getParam('arbitrary_params_dict'))
A:xgboost.spark.core.fit_params->self._gen_fit_params_dict()
A:xgboost.spark.core.fit_params_keys->self._get_fit_params_default().keys()
A:xgboost.spark.core.fit_params[param.name]->self.getOrDefault(param)
A:xgboost.spark.core.predict_params->self._gen_predict_params_dict()
A:xgboost.spark.core.predict_params_keys->self._get_predict_params_default().keys()
A:xgboost.spark.core.predict_params[param.name]->self.getOrDefault(param)
A:xgboost.spark.core.init_model->self.getOrDefault(self.xgb_model)
A:xgboost.spark.core.tree_method->self.getParam('tree_method')
A:xgboost.spark.core.gpu_per_task->_get_spark_session().sparkContext.getConf().get('spark.task.resource.gpu.amount')
A:xgboost.spark.core.is_local->_is_local(_get_spark_session().sparkContext)
A:xgboost.spark.core.features_col->_validate_and_convert_feature_col_as_float_col_list(dataset, feature_col_names)
A:xgboost.spark.core.features_array_col->_validate_and_convert_feature_col_as_array_col(dataset, self.getOrDefault(self.featuresCol))
A:xgboost.spark.core.unwrap_udt->_get_unwrap_udt_fn()
A:xgboost.spark.core.features_unwrapped_vec_col->unwrap_udt(feature_col)
A:xgboost.spark.core._existing_extra_params->self.getOrDefault(self.arbitrary_params_dict)
A:xgboost.spark.core.xgb_sklearn_params->self._gen_xgb_params_dict(gen_xgb_sklearn_estimator_param=True)
A:xgboost.spark.core.sklearn_model->self._xgb_cls()(**xgb_sklearn_params)
A:xgboost.spark.core.num_partitions->dataset.withColumn(probabilityColName, array_to_vector(col(pred_struct_col).probability)).rdd.getNumPartitions()
A:xgboost.spark.core.query_plan->dataset.withColumn(probabilityColName, array_to_vector(col(pred_struct_col).probability))._sc._jvm.PythonSQLUtils.explainString(dataset._jdf.queryExecution(), 'extended')
A:xgboost.spark.core.start->dataset.withColumn(probabilityColName, array_to_vector(col(pred_struct_col).probability))._sc._jvm.PythonSQLUtils.explainString(dataset._jdf.queryExecution(), 'extended').index('== Optimized Logical Plan ==')
A:xgboost.spark.core.params->self._gen_xgb_params_dict()
A:xgboost.spark.core.verbose_eval->self._gen_fit_params_dict().pop('verbose', None)
A:xgboost.spark.core.num_classes->int(dataset.select(countDistinct(alias.label)).collect()[0][0])
A:xgboost.spark.core.params['objective']->self.getOrDefault(self.objective)
A:xgboost.spark.core.params['num_boost_round']->self.getOrDefault(self.n_estimators)
A:xgboost.spark.core.xgb_train_default_args->_get_default_params_from_func(xgboost.train, _unsupported_train_params)
A:xgboost.spark.core.label_col->col(self.getOrDefault(self.labelCol)).alias(alias.label)
A:xgboost.spark.core.enable_sparse_data_optim->self.getOrDefault(self.enable_sparse_data_optim)
A:xgboost.spark.core.features_col_name->self.getOrDefault(self.featuresCol)
A:xgboost.spark.core.features_cols_names->self.getOrDefault(self.features_cols)
A:xgboost.spark.core.features_cols->_validate_and_convert_feature_col_as_float_col_list(dataset, features_cols_names)
A:xgboost.spark.core.dataset->dataset.withColumn(probabilityColName, array_to_vector(col(pred_struct_col).probability)).withColumn(probabilityColName, array_to_vector(col(pred_struct_col).probability))
A:xgboost.spark.core.max_concurrent_tasks->_get_max_num_concurrent_tasks(sc)
A:xgboost.spark.core.train_params->self._get_distributed_train_params(dataset)
A:xgboost.spark.core.(booster_params, train_call_kwargs_params)->self._get_xgb_train_call_args(train_params)
A:xgboost.spark.core.cpu_per_task->int(_get_spark_session().sparkContext.getConf().get('spark.task.cpus', '1'))
A:xgboost.spark.core.context->pyspark.BarrierTaskContext.get()
A:xgboost.spark.core._rabit_args->_get_args_from_message_list(messages)
A:xgboost.spark.core.messages->pyspark.BarrierTaskContext.get().allGather(message=json.dumps(_rabit_args))
A:xgboost.spark.core.(dtrain, dvalid)->create_dmatrix_from_partitions(pandas_df_iter, features_cols_names, gpu_id, use_qdm, dmatrix_kwargs, enable_sparse_data_optim=enable_sparse_data_optim, has_validation_col=has_validation_col)
A:xgboost.spark.core.booster->worker_train(params=booster_params, dtrain=dtrain, evals=dval, evals_result=evals_result, **train_call_kwargs_params)
A:xgboost.spark.core.(config, booster)->_run_job()
A:xgboost.spark.core.result_xgb_model->self._convert_to_sklearn_model(bytearray(booster, 'utf-8'), config)
A:xgboost.spark.core.feature_col_names->self.getOrDefault(self.features_cols)
A:xgboost.spark.core.base_margin_col->col(self.getOrDefault(self.base_margin_col)).alias(alias.margin)
A:xgboost.spark.core.(features_col, feature_col_names)->self._get_feature_col(dataset)
A:xgboost.spark.core.X->stack_series(data[alias.data])
A:xgboost.spark.core.base_margin->stack_series(data[alias.margin])
A:xgboost.spark.core.preds->numpy.argmax(class_probs, axis=1)
A:xgboost.spark.core.pred_col->predict_udf(struct(*features_col))
A:xgboost.spark.core.predictionColName->self.getOrDefault(self.predictionCol)
A:xgboost.spark.core.classone_probs->expit(margins)
A:xgboost.spark.core.raw_preds->numpy.vstack((-margins, margins)).transpose()
A:xgboost.spark.core.class_probs->softmax(raw_preds, axis=1)
A:xgboost.spark.core.margins->model.predict(X, base_margin=base_margin, output_margin=True, validate_features=False, **predict_params)
A:xgboost.spark.core.(raw_preds, class_probs)->transform_margin(margins)
A:xgboost.spark.core.pred_struct->predict_udf(struct(*features_col))
A:xgboost.spark.core.rawPredictionColName->self.getOrDefault(self.rawPredictionCol)
A:xgboost.spark.core.probabilityColName->self.getOrDefault(self.probabilityCol)
A:xgboost.spark.core.param_obj->Param(Params._dummy(), name=name, doc=doc)
A:xgboost.spark.core.fit_params_dict->pyspark_estimator_class._get_fit_params_default()
A:xgboost.spark.core.predict_params_dict->pyspark_estimator_class._get_predict_params_default()
xgboost.spark.core.SparkXGBClassifierModel(_SparkXGBModel,HasProbabilityCol,HasRawPredictionCol)
xgboost.spark.core.SparkXGBClassifierModel._transform(self,dataset)
xgboost.spark.core.SparkXGBClassifierModel._xgb_cls(cls)
xgboost.spark.core.SparkXGBRankerModel(_SparkXGBModel)
xgboost.spark.core.SparkXGBRankerModel._xgb_cls(cls)
xgboost.spark.core.SparkXGBRegressorModel(_SparkXGBModel)
xgboost.spark.core.SparkXGBRegressorModel._xgb_cls(cls)
xgboost.spark.core._SparkXGBEstimator(self)
xgboost.spark.core._SparkXGBEstimator._convert_to_sklearn_model(self,booster:bytearray,config:str)
xgboost.spark.core._SparkXGBEstimator._create_pyspark_model(self,xgb_model)
xgboost.spark.core._SparkXGBEstimator._fit(self,dataset)
xgboost.spark.core._SparkXGBEstimator._get_distributed_train_params(self,dataset)
xgboost.spark.core._SparkXGBEstimator._get_xgb_train_call_args(cls,train_params)
xgboost.spark.core._SparkXGBEstimator._pyspark_model_cls(cls)
xgboost.spark.core._SparkXGBEstimator._query_plan_contains_valid_repartition(self,dataset)
xgboost.spark.core._SparkXGBEstimator._repartition_needed(self,dataset)
xgboost.spark.core._SparkXGBEstimator.read(cls)
xgboost.spark.core._SparkXGBEstimator.setParams(self,**kwargs)
xgboost.spark.core._SparkXGBEstimator.write(self)
xgboost.spark.core._SparkXGBModel(self,xgb_sklearn_model=None)
xgboost.spark.core._SparkXGBModel._get_feature_col(self,dataset)->(list, Optional[list])
xgboost.spark.core._SparkXGBModel._transform(self,dataset)
xgboost.spark.core._SparkXGBModel._xgb_cls(cls)
xgboost.spark.core._SparkXGBModel.get_booster(self)
xgboost.spark.core._SparkXGBModel.get_feature_importances(self,importance_type='weight')
xgboost.spark.core._SparkXGBModel.read(cls)
xgboost.spark.core._SparkXGBModel.write(self)
xgboost.spark.core._SparkXGBParams(HasFeaturesCol,HasLabelCol,HasWeightCol,HasPredictionCol,HasValidationIndicatorCol,HasArbitraryParamsDict,HasBaseMarginCol,HasFeaturesCols,HasEnableSparseDataOptim,HasQueryIdCol)
xgboost.spark.core._SparkXGBParams._gen_fit_params_dict(self)
xgboost.spark.core._SparkXGBParams._gen_predict_params_dict(self)
xgboost.spark.core._SparkXGBParams._gen_xgb_params_dict(self,gen_xgb_sklearn_estimator_param=False)
xgboost.spark.core._SparkXGBParams._get_fit_params_default(cls)
xgboost.spark.core._SparkXGBParams._get_predict_params_default(cls)
xgboost.spark.core._SparkXGBParams._get_xgb_params_default(cls)
xgboost.spark.core._SparkXGBParams._set_fit_params_default(self)
xgboost.spark.core._SparkXGBParams._set_predict_params_default(self)
xgboost.spark.core._SparkXGBParams._set_xgb_params_default(self)
xgboost.spark.core._SparkXGBParams._validate_params(self)
xgboost.spark.core._SparkXGBParams._xgb_cls(cls)
xgboost.spark.core._get_unwrap_udt_fn()
xgboost.spark.core._get_unwrapped_vec_cols(feature_col)
xgboost.spark.core._set_pyspark_xgb_cls_param_attrs(pyspark_estimator_class,pyspark_model_class)
xgboost.spark.core._validate_and_convert_feature_col_as_array_col(dataset,features_col_name)
xgboost.spark.core._validate_and_convert_feature_col_as_float_col_list(dataset,features_col_names:list)->list


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/params.py----------------------------------------
A:xgboost.spark.params.arbitrary_params_dict->Param(Params._dummy(), 'arbitrary_params_dict', 'arbitrary_params_dict This parameter holds all of the additional parameters which are not exposed as the the XGBoost Spark estimator params but can be recognized by underlying XGBoost library. It is stored as a dictionary.')
A:xgboost.spark.params.base_margin_col->Param(Params._dummy(), 'base_margin_col', 'This stores the name for the column of the base margin')
A:xgboost.spark.params.features_cols->Param(Params._dummy(), 'features_cols', 'feature column names.', typeConverter=TypeConverters.toListString)
A:xgboost.spark.params.enable_sparse_data_optim->Param(Params._dummy(), 'enable_sparse_data_optim', 'This stores the boolean config of enabling sparse data optimization, if enabled, Xgboost DMatrix object will be constructed from sparse matrix instead of dense matrix. This config is disabled by default. If most of examples in your training dataset contains sparse features, we suggest to enable this config.', typeConverter=TypeConverters.toBoolean)
A:xgboost.spark.params.qid_col->Param(Params._dummy(), 'qid_col', 'query id column name', typeConverter=TypeConverters.toString)
xgboost.spark.params.HasArbitraryParamsDict(Params)
xgboost.spark.params.HasBaseMarginCol(Params)
xgboost.spark.params.HasEnableSparseDataOptim(self)
xgboost.spark.params.HasFeaturesCols(self)
xgboost.spark.params.HasQueryIdCol(Params)


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/model.py----------------------------------------
A:xgboost.spark.model.root_dir->pyspark.SparkFiles.getRootDirectory()
A:xgboost.spark.model.xgb_tmp_dir->os.path.join(root_dir, 'xgboost-tmp')
A:xgboost.spark.model.xgb_model->deserialize_xgb_model(ser_xgb_model, create_xgb_model)
A:xgboost.spark.model.tmp_file_name->os.path.join(_get_or_create_tmp_dir(), f'{uuid.uuid4()}.json')
A:xgboost.spark.model.ser_model_string->f.read()
A:xgboost.spark.model.booster->deserialize_xgb_model(ser_xgb_model, create_xgb_model).get_booster().save_raw('json').decode('utf-8')
A:xgboost.spark.model.callbacks->pyspark.cloudpickle.loads(base64.decodebytes(serialized_callbacks.encode('ascii')))
A:xgboost.spark.model.serialized_callbacks->base64.encodebytes(cloudpickle.dumps(callbacks)).decode('ascii')
A:xgboost.spark.model.init_booster->deserialize_booster(ser_init_booster)
A:xgboost.spark.model.ser_init_booster->serialize_booster(init_booster)
A:xgboost.spark.model.save_path->os.path.join(path, _INIT_BOOSTER_SAVE_PATH)
A:xgboost.spark.model.metadata->pyspark.ml.util.DefaultParamsReader.loadMetadata(path, sc, expectedClassName=get_class_name(pyspark_xgb_cls))
A:xgboost.spark.model.pyspark_xgb->pyspark_xgb_cls()
A:xgboost.spark.model.load_path->os.path.join(path, metadata['init_booster'])
A:xgboost.spark.model.self.logger->get_logger(self.__class__.__name__, level='WARN')
A:xgboost.spark.model.(_, pyspark_xgb)->_SparkXGBSharedReadWrite.loadMetadataAndInstance(self.cls, path, self.sc, self.logger)
A:xgboost.spark.model.model_save_path->os.path.join(path, 'model')
A:xgboost.spark.model.(_, py_model)->_SparkXGBSharedReadWrite.loadMetadataAndInstance(self.cls, path, self.sc, self.logger)
A:xgboost.spark.model.xgb_sklearn_params->py_model._gen_xgb_params_dict(gen_xgb_sklearn_estimator_param=True)
A:xgboost.spark.model.model_load_path->os.path.join(path, 'model')
xgboost.spark.model.SparkXGBModelReader(self,cls)
xgboost.spark.model.SparkXGBModelReader.load(self,path)
xgboost.spark.model.SparkXGBModelWriter(self,instance)
xgboost.spark.model.SparkXGBModelWriter.saveImpl(self,path)
xgboost.spark.model.SparkXGBReader(self,cls)
xgboost.spark.model.SparkXGBReader.load(self,path)
xgboost.spark.model.SparkXGBWriter(self,instance)
xgboost.spark.model.SparkXGBWriter.saveImpl(self,path)
xgboost.spark.model._SparkXGBSharedReadWrite
xgboost.spark.model._SparkXGBSharedReadWrite.loadMetadataAndInstance(pyspark_xgb_cls,path,sc,logger)
xgboost.spark.model._SparkXGBSharedReadWrite.saveMetadata(instance,path,sc,logger,extraMetadata=None)
xgboost.spark.model._get_or_create_tmp_dir()
xgboost.spark.model._get_spark_session()
xgboost.spark.model.deserialize_booster(ser_model_string)
xgboost.spark.model.deserialize_xgb_model(model_string,xgb_model_creator)
xgboost.spark.model.serialize_booster(booster)


----------------------------------------/home/zhang/Packages/xgboost/xgboost1.7.0/spark/__init__.py----------------------------------------

