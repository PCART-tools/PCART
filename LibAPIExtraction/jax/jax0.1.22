
----------------------------------------/home/zhang/Packages/jax/jax0.1.22/flatten_util.py----------------------------------------
A:jax.flatten_util.(leaves, treedef)->tree_flatten(pytree)
A:jax.flatten_util.(flat, unravel_list)->vjp(ravel_list, *leaves)
A:jax.flatten_util.pytree_args->unravel_inputs(flat_in)
jax.flatten_util.ravel_fun(unravel_inputs,flat_in,**kwargs)
jax.flatten_util.ravel_list(*lst)
jax.flatten_util.ravel_pytree(pytree)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/util.py----------------------------------------
A:jax.util.n->len(args[0])
A:jax.util.args->list(map(list, args))
A:jax.util.wrapped->functools.partial(fun, *args, **kwargs)
A:jax.util.node->childless_nodes.pop()
A:jax.util.sides->list(map(predicate, xs))
A:jax.util._NO_MEMO_ENTRY->object()
A:jax.util.cache->OrderedDict()
A:jax.util.ans->OrderedDict().get(key, _NO_MEMO_ENTRY)
A:jax.util.anscache[key]->fun(*args, **kwargs)
A:jax.util.valself[key]->func(key)
A:jax.util.module_fns->set()
A:jax.util.attr->getattr(module, key)
jax.util.WrapHashably(self,val)
jax.util.WrapHashably.__eq__(self,other)
jax.util.WrapHashably.__hash__(self)
jax.util.concatenate(xs)
jax.util.curry(f)
jax.util.get_module_functions(module)
jax.util.memoize(fun,max_size=4096)
jax.util.memoize_unary(func)
jax.util.partial(fun,*args,**kwargs)
jax.util.partialmethod(functools.partial)
jax.util.partialmethod.__get__(self,instance,owner)
jax.util.prod(xs)
jax.util.safe_map(f,*args)
jax.util.safe_zip(*args)
jax.util.split_merge(predicate,xs)
jax.util.toposort(end_node)
jax.util.unzip2(xys)
jax.util.unzip3(xyzs)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/abstract_arrays.py----------------------------------------
A:jax.abstract_arrays.fname->getattr(fun, '__name__', fun)
A:jax.abstract_arrays._bool_nonzero->concretization_function_error(bool)
A:jax.abstract_arrays._float->concretization_function_error(float)
A:jax.abstract_arrays._int->concretization_function_error(int)
A:jax.abstract_arrays._long->concretization_function_error(long)
A:jax.abstract_arrays._complex->concretization_function_error(complex)
A:jax.abstract_arrays._hex->concretization_function_error(hex)
A:jax.abstract_arrays._oct->concretization_function_error(oct)
A:jax.abstract_arrays.self.dtype->numpy.dtype(xla_bridge.canonicalize_dtype(onp.result_type(val)))
A:jax.abstract_arrays.ndim->property(lambda self: len(self.shape))
A:jax.abstract_arrays.size->property(lambda self: prod(self.shape))
A:jax.abstract_arrays.shapestr->','.join(map(str, self.shape))
A:jax.abstract_arrays.self.shape->numpy.shape(val)
A:jax.abstract_arrays.dtype->lib.xla_bridge.canonicalize_dtype(onp.result_type(x))
jax.abstract_arrays.ConcreteArray(self,val)
jax.abstract_arrays.ConcreteArray.__eq__(self,other)
jax.abstract_arrays.ConcreteArray.__hash__(self)
jax.abstract_arrays.ConcreteArray.at_least_vspace(self)
jax.abstract_arrays.ConcreteArray.join(self,other)
jax.abstract_arrays.ConcreteArray.str_short(self)
jax.abstract_arrays.ShapedArray(self,shape,dtype)
jax.abstract_arrays.ShapedArray.__eq__(self,other)
jax.abstract_arrays.ShapedArray.__hash__(self)
jax.abstract_arrays.ShapedArray.__len__(self)
jax.abstract_arrays.ShapedArray._len(self,ignored_tracer)
jax.abstract_arrays.ShapedArray.at_least_vspace(self)
jax.abstract_arrays.ShapedArray.join(self,other)
jax.abstract_arrays.ShapedArray.str_short(self)
jax.abstract_arrays.UnshapedArray(self,dtype)
jax.abstract_arrays.UnshapedArray.__eq__(self,other)
jax.abstract_arrays.UnshapedArray.__hash__(self)
jax.abstract_arrays.UnshapedArray.__repr__(self)
jax.abstract_arrays.UnshapedArray.at_least_vspace(self)
jax.abstract_arrays.UnshapedArray.join(self,other)
jax.abstract_arrays.UnshapedArray.str_short(self)
jax.abstract_arrays.concretization_err_msg(fun)
jax.abstract_arrays.concretization_function_error(fun)
jax.abstract_arrays.make_shaped_array(x)
jax.abstract_arrays.zeros_like_array(x)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/lax_reference.py----------------------------------------
A:jax.lax_reference.quotient->numpy.floor_divide(lhs, rhs)
A:jax.lax_reference.select->numpy.logical_and(onp.sign(lhs) != onp.sign(rhs), onp.remainder(lhs, rhs) != 0)
A:jax.lax_reference.pads->padtype_to_pads(op.shape, dims, strides, padding)
A:jax.lax_reference.(lhs_perm, rhs_perm, out_perm)->_conv_general_permutations(dimension_numbers)
A:jax.lax_reference.padding->padtype_to_pads(onp.take(lhs.shape, lhs_perm)[2:], onp.take(rhs.shape, rhs_perm)[2:], window_strides, padding)
A:jax.lax_reference.trans_lhs->transpose(lhs, lhs_perm)
A:jax.lax_reference.trans_rhs->transpose(rhs, rhs_perm)
A:jax.lax_reference.out->numpy.zeros(operand.shape[:2] + tuple(outspace), operand.dtype)
A:jax.lax_reference.new_id->itertools.count()
A:jax.lax_reference.shared_id->next(new_id)
A:jax.lax_reference.out_axis_ids->filter(not_none, batch_ids + lhs_out_axis_ids + rhs_out_axis_ids)
A:jax.lax_reference.inshape->tuple((1 if i not in broadcast_dimensions else d for (i, d) in enumerate(shape)))
A:jax.lax_reference.dimensions->frozenset(dimensions)
A:jax.lax_reference.(lo, hi, interior)->zip(*padding_config)
A:jax.lax_reference.outshape->numpy.add(onp.add(onp.add(lo, hi), operand.shape), onp.multiply(interior, onp.subtract(operand.shape, 1)))
A:jax.lax_reference.lhs_slices->tuple((_slice(None, None, step) for step in factors))
A:jax.lax_reference.rhs_slices->tuple((_slice(l if l < 0 else 0, -h if h < 0 else None) for (l, h) in zip(lo, hi)))
A:jax.lax_reference.strides->numpy.ones(len(start_indices)).astype(int)
A:jax.lax_reference.slices->tuple((_slice(abs(lo) if lo < 0 else 0, hi % dim if hi < 0 else None) for ((lo, hi), dim) in zip(pads, onp.shape(arr))))
A:jax.lax_reference.idx->tuple((_slice(start, start + size) for (start, size) in zip(start_indices, slice_sizes)))
A:jax.lax_reference.updated_operand->numpy.copy(operand)
A:jax.lax_reference.reducer->_make_reducer(computation, init_value)
A:jax.lax_reference.view->numpy.lib.stride_tricks.as_strided(lhs, view_shape, view_strides)
A:jax.lax_reference.idxs->list(onp.ix_(*[onp.arange(d) for d in keys.shape]))
A:jax.lax_reference.idxs[dimension]->numpy.argsort(keys, axis=dimension)
A:jax.lax_reference.(view, view_axes, rhs_axes, out_axes)->_conv_view(lhs, rhs.shape, window_strides, pads, 0.0)
A:jax.lax_reference.out_shape->numpy.ceil(onp.true_divide(in_shape, window_strides)).astype(int)
A:jax.lax_reference.lhs->_pad(lhs, [(0, 0)] * 2 + list(pads), pad_value)
A:jax.lax_reference.dim->len(filter_shape)
A:jax.lax_reference.out_strides->numpy.multiply(window_strides, lhs.strides[2:])
A:jax.lax_reference.view_axes->list(range(view.ndim))
A:jax.lax_reference.outspace->numpy.add(operand.shape[2:], onp.multiply(onp.subtract(factors, 1), onp.subtract(operand.shape[2:], 1)))
A:jax.lax_reference.monoid_record->_monoids.get(getattr(py_binop, '__name__'))
A:jax.lax_reference.MonoidRecord->collections.namedtuple('MonoidRecord', ['reducer', 'identity'])
A:jax.lax_reference.result->numpy.full(onp.delete(onp.shape(operand), axis), init_val, dtype=onp.asarray(operand).dtype)
A:jax.lax_reference.out_idx->tuple(onp.delete(idx, axis))
A:jax.lax_reference.result[out_idx]->py_binop(result[out_idx], operand[idx])
jax.lax_reference._conv(lhs,rhs,window_strides,pads)
jax.lax_reference._conv_general_permutations(dimension_numbers)
jax.lax_reference._conv_view(lhs,rhs_shape,window_strides,pads,pad_value)
jax.lax_reference._dilate(operand,factors)
jax.lax_reference._get_max_identity(dt)
jax.lax_reference._get_min_identity(dt)
jax.lax_reference._identity_getter(op)
jax.lax_reference._make_reducer(py_binop,init_val)
jax.lax_reference._pad(arr,pads,pad_value)
jax.lax_reference._reducer_from_pyfunc(py_binop,init_val)
jax.lax_reference.bitcast_convert_type(operand,dtype)
jax.lax_reference.broadcast(operand,sizes)
jax.lax_reference.broadcast_in_dim(operand,shape,broadcast_dimensions)
jax.lax_reference.clamp(min,operand,max)
jax.lax_reference.complex(x,y)
jax.lax_reference.concatenate(operands,dimension)
jax.lax_reference.conj(x)
jax.lax_reference.conv(lhs,rhs,window_strides,padding)
jax.lax_reference.conv_general_dilated(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers)
jax.lax_reference.conv_with_general_padding(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation)
jax.lax_reference.convert_element_type(operand,dtype)
jax.lax_reference.div(lhs,rhs)
jax.lax_reference.dot_general(lhs,rhs,dimension_numbers)
jax.lax_reference.dynamic_slice(operand,start_indices,slice_sizes)
jax.lax_reference.dynamic_update_slice(operand,update,start_indices)
jax.lax_reference.pad(operand,padding_value,padding_config)
jax.lax_reference.padtype_to_pads(in_shape,filter_shape,window_strides,padding)
jax.lax_reference.reduce(operand,init_value,computation,dimensions)
jax.lax_reference.reduce_window(operand,init_value,computation,window_dimensions,window_strides,padding)
jax.lax_reference.rem(lhs,rhs)
jax.lax_reference.reshape(operand,new_sizes,dimensions=None)
jax.lax_reference.rev(operand,dimensions)
jax.lax_reference.slice(operand,start_indices,limit_indices,strides=None)
jax.lax_reference.sort_key_val(keys,values,dimension=-1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/lax.py----------------------------------------
A:jax.lax.ndim->_max((len(shape) for shape in shapes))
A:jax.lax.shapes->numpy.array([operand.shape for operand in operands])
A:jax.lax.min_shape->numpy.min(shapes, axis=0)
A:jax.lax.max_shape->numpy.max(shapes, axis=0)
A:jax.lax.result_shape->numpy.floor_divide(onp.add(onp.subtract(limit_indices, start_indices), strides) - 1, strides)
A:jax.lax.new_dtype->lib.xla_bridge.canonicalize_dtype(new_dtype)
A:jax.lax.old_dtype->_dtype(operand)
A:jax.lax.operand->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').ShiftLeft(operand, c.Constant(pair_uint_dtype(bits), canonicalize_types=False))
A:jax.lax.dimension_numbers->_conv_general_proto(dimension_numbers)
A:jax.lax.padding->_conv_general_vjp_rhs_padding(onp.take(lhs_shape, lhs_sdims), onp.take(rhs_shape, rhs_sdims), window_strides, onp.take(g.shape, out_sdims), padding, lhs_dilation, rhs_dilation)
A:jax.lax.start_indices->concatenate([reshape(i, [1]) for i in start_indices], 0)
A:jax.lax.(jaxpr, consts)->_reduction_jaxpr(mul, init_value)
A:jax.lax.indices->concatenate([reshape(i, [i.shape[0], 1]) for i in idxs], 1)
A:jax.lax.slice_sizes->list(operand.shape)
A:jax.lax.offset_dims->tuple(onp.add(1, dimension_numbers.offset_dims))
A:jax.lax.dnums->ScatterDimensionNumbers(update_window_dims=update_window_dims, inserted_window_dims=inserted_window_dims, scatter_dims_to_operand_dims=scatter_dims_to_operand_dims)
A:jax.lax.permutation->tuple(permutation)
A:jax.lax.monoid_reducer->_get_monoid_window_reducer(computation, init_value)
A:jax.lax.pval->_abstractify(init_value)
A:jax.lax.(jaxpr, _, consts)->interpreters.partial_eval.trace_unwrapped_to_jaxpr(computation, (pval, pval))
A:jax.lax.aval->core.get_aval(on_true)
A:jax.lax.init_value->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Constant(onp.array(0, dtype))
A:jax.lax.(select_jaxpr, select_consts)->_reduction_jaxpr(select)
A:jax.lax.(scatter_jaxpr, scatter_consts)->_reduction_jaxpr(scatter)
A:jax.lax.result->numpy.asarray(_reduce(operator.and_, eyes), self.dtype)
A:jax.lax.(init_val_flat, in_tree)->pytree_to_jaxtupletree(init_val)
A:jax.lax.(flat_body_fun, out_tree)->pytree_fun_to_jaxtupletree_fun(lu.wrap_init(body_fun), (in_tree,))
A:jax.lax.(flat_cond_fun, _)->pytree_fun_to_jaxtupletree_fun(lu.wrap_init(cond_fun), (in_tree,))
A:jax.lax.pval_flat->_abstractify(init_val_flat)
A:jax.lax.(cond_jaxpr, _, cond_consts)->interpreters.partial_eval.trace_to_jaxpr(flat_cond_fun, (pval_flat,))
A:jax.lax.(body_jaxpr, pval_out, body_consts)->interpreters.partial_eval.trace_to_jaxpr(flat_body_fun, (pval_flat,))
A:jax.lax.(tracer_vars, tracer_consts)->unzip2(tracer)
A:jax.lax.(nontracer_vars, nontracer_consts)->unzip2(nontracer)
A:jax.lax.cond_split->split_tracers_and_nontracers(cond_jaxpr, cond_consts)
A:jax.lax.body_split->split_tracers_and_nontracers(body_jaxpr, body_consts)
A:jax.lax.out_flat->Primitive('while').bind(init_val_flat, core.pack(cond_tracer_consts), core.pack(body_tracer_consts), cond_consts=_OpaqueParam(cond_nontracer_consts), body_consts=_OpaqueParam(body_nontracer_consts), aval_out=aval_out, cond_jaxpr=cond_jaxpr, body_jaxpr=body_jaxpr)
A:jax.lax.(op_flat, in_tree)->pytree_to_flatjaxtuple(operand)
A:jax.lax.(fun_flat, out_tree)->pytree_fun_to_flatjaxtuple_fun(lu.wrap_init(fun), (in_tree,))
A:jax.lax.(jaxpr, pvout, consts)->interpreters.partial_eval.trace_to_jaxpr(fun_flat, (_abstractify(op_flat),))
A:jax.lax.true_data->trace_jaxpr(true_fun, true_operand)
A:jax.lax.false_data->trace_jaxpr(false_fun, false_operand)
A:jax.lax.joined_pval->interpreters.partial_eval.join_pvals(true_pval, false_pval)
A:jax.lax.revis->_revise_cond_jaxpr(joined_pval, false_pval, false_jaxpr, false_consts)
A:jax.lax.out->sort_key_val(keys, new_values, new_dimension)
A:jax.lax.outvar->interpreters.partial_eval.Var(0, 'loop_carry_out')
A:jax.lax.new_jaxpr->jaxpr.copy()
A:jax.lax.newvar->interpreters.partial_eval.gensym('_cond')
A:jax.lax.(new_constvars, new_constvals)->unzip2([(newvar(), c) for (new, old, c) in zip(new_pv, old_pv, old_const) if old is None and new is not None])
A:jax.lax.newvars->iter(new_constvars)
A:jax.lax.(a, a_tree)->pytree_to_flatjaxtuple(a)
A:jax.lax.(bs, b_tree)->pytree_to_flatjaxtuple(bs)
A:jax.lax.(f, out_tree)->pytree_fun_to_flatjaxtuple_fun(lu.wrap_init(f), (a_tree, b_tree))
A:jax.lax.a_pval(a_aval, _)->_abstractify(a)
A:jax.lax.(bs_aval, _)->_abstractify(bs)
A:jax.lax.b_aval->core.AbstractTuple([ShapedArray(b.shape[1:], b.dtype) for b in bs_aval])
A:jax.lax.b_pval->interpreters.partial_eval.PartialVal((b_aval, core.unit))
A:jax.lax.(jaxpr, pval_out, consts)->interpreters.partial_eval.trace_to_jaxpr(f, (a_pval, b_pval))
A:jax.lax.a_out->core.eval_jaxpr(jaxpr, consts, (), a, core.pack(b))
A:jax.lax.(_, out)->fori_loop(0, length, body_fun, (a, state))
A:jax.lax.primal_out->core.Primitive('scan').bind(a, bs, consts_primals, aval_out=aval_out, jaxpr=jaxpr)
A:jax.lax.tangent_out->scatter_add(masked_g_operand, scatter_indices, masked_g_updates, dimension_numbers=dnums)
A:jax.lax.scan_p->core.Primitive('scan')
A:jax.lax.xla.translations[scan_p]->partial(xla.lower_fun, _scan_impl)
A:jax.lax.shape->numpy.asarray(list(map(int, operand.shape)), start_indices.dtype)
A:jax.lax.dtype->lib.xla_bridge.canonicalize_dtype(dtype)
A:jax.lax.val->numpy.asarray(fill_value, dtype)
A:jax.lax.dimension->kwargs.pop('dimension')
A:jax.lax.axes->tuple(onp.delete(range(len(shape)), broadcast_dimensions))
A:jax.lax.pads->padtype_to_pads(lhs_shape[2:], rhs_shape[2:], strides, pads)
A:jax.lax.size->_reduce(set.union, map(batching.dimsize, batch_dims, batched_args)).pop()
A:jax.lax.limit_indices->list(operand.shape)
A:jax.lax.axis->int(axis)
A:jax.lax.start_indices[axis]->reshape(rem(start_index, axis_size), [1])
A:jax.lax.limit_indices[axis]->int(limit_index)
A:jax.lax.strides[axis]->int(stride)
A:jax.lax.axis_size->_const(start_index, operand.shape[axis])
A:jax.lax.slice_sizes[axis]->int(slice_size)
A:jax.lax.update->reshape(update, operand.shape[:ax] + (1,) + operand.shape[ax + 1:])
A:jax.lax.(_, result)->while_loop(while_cond_fun, while_body_fun, (lower, init_val))
A:jax.lax.batch->tuple(range(lhs.ndim - 2))
A:jax.lax.ShapedArray.broadcast->core.aval_method(broadcast)
A:jax.lax.ShapedArray.transpose->core.aval_method(transpose)
A:jax.lax.ShapedArray.reshape->core.aval_method(reshape)
A:jax.lax.ShapedArray._iter->staticmethod(_iter)
A:jax.lax.prim->Primitive(name)
A:jax.lax.least_specialized->_max(map(type, args), key=operator.attrgetter('array_abstraction_level'))
A:jax.lax.xla_opname->''.join((term.capitalize() for term in name.split('_')))
A:jax.lax.typename->str(onp.dtype(aval_dtype).name)
A:jax.lax.dtype_rule->partial(binop_dtype_rule, result_dtype, accepted_dtypes, name)
A:jax.lax.standard_unop->partial(unop, identity)
A:jax.lax.typenames->', '.join((str(onp.dtype(t).name) for t in types))
A:jax.lax.shape_rule->partial(_broadcasting_shape_rule, name)
A:jax.lax.standard_binop->partial(binop, _input_dtype)
A:jax.lax.x_shape->numpy.shape(x)
A:jax.lax.(broadcast_dimensions,)->numpy.where(onp.equal(x_shape, shape))
A:jax.lax.(squeezed_dimensions,)->numpy.where(onp.not_equal(x_shape, shape))
A:jax.lax.inshape->numpy.delete(x_shape, squeezed_dimensions)
A:jax.lax.neg_p->standard_unop(_num, 'neg')
A:jax.lax.sign_p->standard_unop(_num, 'sign')
A:jax.lax.floor_p->standard_unop(_float, 'floor')
A:jax.lax.ceil_p->standard_unop(_float, 'ceil')
A:jax.lax.round_p->standard_unop(_float, 'round')
A:jax.lax.is_finite_p->unop(_fixed_dtype(onp.bool_), _float, 'is_finite')
A:jax.lax.exp_p->standard_unop(_float | _complex, 'exp')
A:jax.lax.log_p->standard_unop(_float | _complex, 'log')
A:jax.lax.expm1_p->standard_unop(_float | _complex, 'expm1')
A:jax.lax.log1p_p->standard_unop(_float | _complex, 'log1p')
A:jax.lax.tanh_p->standard_unop(_float | _complex, 'tanh')
A:jax.lax.sin_p->standard_unop(_float | _complex, 'sin')
A:jax.lax.cos_p->standard_unop(_float | _complex, 'cos')
A:jax.lax.atan2_p->standard_binop([_float, _float], 'atan2')
A:jax.lax.lgamma_p->standard_unop(_float, 'lgamma')
A:jax.lax.digamma_p->standard_unop(_float, 'digamma')
A:jax.lax.erf_p->standard_unop(_float, 'erf')
A:jax.lax.erfc_p->standard_unop(_float, 'erfc')
A:jax.lax.erf_inv_p->standard_unop(_float, 'erf_inv')
A:jax.lax.real_p->unop(_complex_basetype, _complex, 'real')
A:jax.lax.imag_p->unop(_complex_basetype, _complex, 'imag')
A:jax.lax.complex_p->binop(_complex_dtype, [_complex_elem_types, _complex_elem_types], 'complex')
A:jax.lax.conj_p->unop(_complex_dtype, _float | _complex, 'conj')
A:jax.lax.ad.primitive_jvps[conj_p]->partial(ad.linear_jvp, conj_p)
A:jax.lax.abs_p->unop(_complex_basetype, _num, 'abs')
A:jax.lax.pow_p->standard_binop([_float | _complex, _float | _complex], 'pow')
A:jax.lax.jac->mul(y, pow(x, select(eq(y, _zeros(y)), _ones(y), sub(y, _ones(y)))))
A:jax.lax.not_p->standard_unop(_int | _bool, 'not')
A:jax.lax.and_p->standard_binop([_any, _any], 'and')
A:jax.lax.or_p->standard_binop([_any, _any], 'or')
A:jax.lax.xor_p->standard_binop([_any, _any], 'xor')
A:jax.lax.add_p->standard_binop([_num, _num], 'add')
A:jax.lax.sub_p->standard_binop([_num, _num], 'sub')
A:jax.lax.mul_p->standard_binop([_num, _num], 'mul')
A:jax.lax.zero->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Constant(onp.array(0, dtype))
A:jax.lax.out_shape->numpy.ceil(onp.true_divide(in_shape, window_strides)).astype(int)
A:jax.lax.safe_mul_p->standard_binop([_num, _num], 'safe_mul', translation_rule=_safe_mul_translation_rule)
A:jax.lax.div_p->standard_binop([_num, _num], 'div')
A:jax.lax.rem_p->standard_binop([_num, _num], 'rem')
A:jax.lax.which->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').BroadcastInDim(which, out_shape, bcast_dims(which_shape))
A:jax.lax.x->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').ParameterWithShape(xla_bridge.Shape.array_shape(pair_uint_dtype, ()))
A:jax.lax.y->tie_in(*batched_args)
A:jax.lax.comparator->cmp(c)
A:jax.lax.rx->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Real(x)
A:jax.lax.ry->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Real(y)
A:jax.lax.max_p->standard_binop([_any, _any], 'max', translation_rule=partial(_minmax_translation_rule, minmax=lambda c: c.Max, cmp=lambda c: c.Gt))
A:jax.lax.min_p->standard_binop([_any, _any], 'min', translation_rule=partial(_minmax_translation_rule, minmax=lambda c: c.Min, cmp=lambda c: c.Lt))
A:jax.lax.shift_left_p->standard_binop([_int, _int], 'shift_left')
A:jax.lax.shift_right_arithmetic_p->standard_binop([_int, _int], 'shift_right_arithmetic')
A:jax.lax.shift_right_logical_p->standard_binop([_int, _int], 'shift_right_logical')
A:jax.lax.eq_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'eq')
A:jax.lax.ne_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'ne')
A:jax.lax.ge_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'ge')
A:jax.lax.gt_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'gt')
A:jax.lax.le_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'le')
A:jax.lax.lt_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'lt')
A:jax.lax.new_etype->lib.xla_bridge.dtype_to_etype(new_dtype)
A:jax.lax.convert_element_type_p->standard_primitive(_convert_element_type_shape_rule, _convert_element_type_dtype_rule, 'convert_element_type', _convert_element_type_translation_rule)
A:jax.lax.bitcast_convert_type_p->standard_primitive(_bitcast_convert_type_shape_rule, _bitcast_convert_type_dtype_rule, 'bitcast_convert_type', _bitcast_convert_type_translation_rule)
A:jax.lax.lhs_trans->numpy.take(lhs_shape, lhs_perm)
A:jax.lax.rhs_trans->numpy.take(rhs_shape, rhs_perm)
A:jax.lax.out_trans->conv_shape_tuple(lhs_trans, rhs_trans, window_strides, padding)
A:jax.lax.(lhs_sdims, rhs_sdims, out_sdims)->map(_conv_sdims, dimension_numbers)
A:jax.lax.t_rhs_spec->_conv_transpose(rhs_spec)
A:jax.lax.trans_dimension_numbers->ConvDimensionNumbers(lhs_trans, out_trans, rhs_trans)
A:jax.lax.revd_weights->rev(rhs, rhs_sdims)
A:jax.lax.(lhs_trans, rhs_trans, out_trans)->map(_conv_transpose, dimension_numbers)
A:jax.lax.lhs->broadcast(lhs, (rhs.shape[rbd],))
A:jax.lax.rhs->broadcast(rhs, (lhs.shape[lbd],))
A:jax.lax.outputs->concatenate(outputs, 0)
A:jax.lax.conv_general_dilated_p->standard_primitive(_conv_general_dilated_shape_rule, _conv_general_dilated_dtype_rule, 'conv_general_dilated', _conv_general_dilated_translation_rule)
A:jax.lax._dot_dtype_rule->partial(binop_dtype_rule, _input_dtype, [_num, _num], 'dot')
A:jax.lax.dot_p->standard_primitive(_dot_shape_rule, _dot_dtype_rule, 'dot')
A:jax.lax.lhs_batch_shape->numpy.take(lhs.shape, lhs_batch)
A:jax.lax.rhs_batch_shape->numpy.take(rhs.shape, rhs_batch)
A:jax.lax.lhs_contracting_shape->numpy.take(lhs.shape, lhs_contracting)
A:jax.lax.rhs_contracting_shape->numpy.take(rhs.shape, rhs_contracting)
A:jax.lax.batch_shape->tuple(onp.take(lhs.shape, lhs_batch))
A:jax.lax.lhs_tensored_shape->tuple(onp.delete(lhs.shape, lhs_contract_or_batch))
A:jax.lax.rhs_tensored_shape->tuple(onp.delete(rhs.shape, rhs_contract_or_batch))
A:jax.lax.x_kept->remaining(range(x_ndim), x_contract, x_batch)
A:jax.lax.y_kept->remaining(range(y.ndim), y_contract, y_batch)
A:jax.lax.(ans_batch, ans_y, _)->ranges_like(x_batch, y_kept, x_kept)
A:jax.lax.(ans_batch, _, ans_y)->ranges_like(x_batch, x_kept, y_kept)
A:jax.lax.x_contract_sorted_by_y->list(onp.take(x_contract, onp.argsort(y_contract)))
A:jax.lax.out_axes->numpy.argsort(list(x_batch) + x_kept + x_contract_sorted_by_y)
A:jax.lax.lhs_contract->tuple(onp.add(1, lhs_contract))
A:jax.lax.rhs_contract->tuple(onp.add(1, rhs_contract))
A:jax.lax.batched_out->dot_general(lhs, rhs, new_dimension_numbers)
A:jax.lax.dot_general_p->standard_primitive(_dot_general_shape_rule, _dot_general_dtype_rule, 'dot_general')
A:jax.lax.broadcast_p->standard_primitive(_broadcast_shape_rule, _input_dtype, 'broadcast')
A:jax.lax.new_shape->list(shape)
A:jax.lax.broadcast_in_dim_p->standard_primitive(_broadcast_in_dim_shape_rule, _input_dtype, 'broadcast_in_dim')
A:jax.lax._clamp_dtype_rule->partial(binop_dtype_rule, _input_dtype, [_any, _any, _any], 'clamp')
A:jax.lax.clamp_p->standard_primitive(_clamp_shape_rule, _clamp_dtype_rule, 'clamp')
A:jax.lax.op->next((op for op in operands if not isinstance(op, UnshapedArray)))
A:jax.lax.concat_size->sum((o.shape[dimension] for o in operands))
A:jax.lax.operand_shapes->kwargs.pop('operand_shapes')
A:jax.lax.limit_points->numpy.cumsum([shape[dimension] for shape in operand_shapes])
A:jax.lax.starts->numpy.zeros((len(operands), t.ndim), dtype=int)
A:jax.lax.limits->numpy.tile(t.shape, (len(operands), 1))
A:jax.lax.concatenate_p->standard_primitive(_concatenate_shape_rule, _concatenate_dtype_rule, 'concatenate', _concatenate_translation_rule)
A:jax.lax.(lo, hi, interior)->zip(*padding_config)
A:jax.lax.unpad_config->zip(onp.negative(lo), onp.negative(hi), onp.zeros_like(interior))
A:jax.lax.unpadded->pad(t, onp.array(0.0, t.dtype), unpad_config)
A:jax.lax.padding_config->list(padding_config)
A:jax.lax.pad_p->standard_primitive(_pad_shape_rule, _input_dtype, 'pad')
A:jax.lax.reshape_p->standard_primitive(_reshape_shape_rule, _reshape_dtype_rule, 'reshape', _reshape_translation_rule)
A:jax.lax.rev_p->standard_primitive(_rev_shape_rule, _input_dtype, 'rev')
A:jax.lax.perm->list(range(x.ndim))
A:jax.lax.transpose_p->standard_primitive(_transpose_shape_rule, _input_dtype, 'transpose')
A:jax.lax.zeros->broadcast(_const(t, 0), operand_shape)
A:jax.lax.pred->core.eval_jaxpr(cond_jaxpr, cond_consts.val + cond_tracer_consts, (), loop_carry)
A:jax.lax.on_false->interpreters.batching.bdim_at_front(on_false, of_bdim, size, force_broadcast=True)
A:jax.lax.on_true->interpreters.batching.bdim_at_front(on_true, ot_bdim, size, force_broadcast=True)
A:jax.lax.select_p->standard_primitive(_select_shape_rule, _select_dtype_rule, 'select')
A:jax.lax.strides->numpy.ones(operand.ndim, onp.int32)
A:jax.lax.real_limits->numpy.add(onp.add(start_indices, 1), onp.multiply(onp.subtract(t.shape, 1), strides))
A:jax.lax.new_start_indices->list(start_indices)
A:jax.lax.new_limit_indices->list(limit_indices)
A:jax.lax.new_strides->list(strides)
A:jax.lax.slice_p->standard_primitive(_slice_shape_rule, _input_dtype, 'slice', _slice_translation_rule)
A:jax.lax.dims->tuple(range(len(operand_shape)))
A:jax.lax.dynamic_slice_p->standard_primitive(_dynamic_slice_shape_rule, _input_dtype, 'dynamic_slice', _dynamic_slice_translation_rule)
A:jax.lax.val_out->sort_key_val(keys, values, dimension)
A:jax.lax.g_operand->interpreters.ad.instantiate_zeros(operand, g_operand)
A:jax.lax.g_update->interpreters.ad.instantiate_zeros(update, g_update)
A:jax.lax.dynamic_update_slice_p->standard_primitive(_dynamic_update_slice_shape_rule, _dynamic_update_slice_dtype_rule, 'dynamic_update_slice', _dynamic_update_slice_translation_rule)
A:jax.lax.proto->lib.xla_bridge.xla_data_pb2.ConvolutionDimensionNumbers()
A:jax.lax.msg->'slice_sizes must have rank equal to the gather operand; operand.shape={}, slice_sizes={}'.format(operand_shape, slice_sizes)
A:jax.lax.expanded_start_indices_shape->list(start_indices.shape)
A:jax.lax.result_rank->len(dimension_numbers.offset_dims)
A:jax.lax.indices_shape->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').GetShape(scatter_indices)
A:jax.lax.scatter_dnums->ScatterDimensionNumbers(update_window_dims=dimension_numbers.offset_dims, inserted_window_dims=dimension_numbers.collapsed_slice_dims, scatter_dims_to_operand_dims=dimension_numbers.start_index_map)
A:jax.lax.collapsed_slice_dims->tuple(onp.add(1, dimension_numbers.collapsed_slice_dims))
A:jax.lax.start_index_map->tuple(onp.add(1, dimension_numbers.start_index_map))
A:jax.lax.count_shape->list(scatter_indices.shape)
A:jax.lax.counts->_reduce_sum(location_indicators, axes)
A:jax.lax.gather_p->standard_primitive(_gather_shape_rule, _gather_dtype_rule, 'gather', _gather_translation_rule)
A:jax.lax.update_computation->_reduction_computation(c, update_jaxpr, update_consts, init_value)
A:jax.lax.g_updates->interpreters.ad.instantiate_zeros(updates, g_updates)
A:jax.lax.gather_dnums->GatherDimensionNumbers(offset_dims=dnums.update_window_dims, collapsed_slice_dims=dnums.inserted_window_dims, start_index_map=dnums.scatter_dims_to_operand_dims)
A:jax.lax.update_t->gather(t, scatter_indices, dimension_numbers=gather_dnums, slice_sizes=slice_sizes)
A:jax.lax.updates->reshape(updates, (1,) + updates_shape)
A:jax.lax.inserted_window_dims->tuple(onp.add(1, dimension_numbers.inserted_window_dims))
A:jax.lax.scatter_dims_to_operand_dims->tuple(onp.add(1, dimension_numbers.scatter_dims_to_operand_dims))
A:jax.lax.scatter_indices->concatenate([counts, scatter_indices], len(count_shape) - 1)
A:jax.lax.update_window_dims->tuple(onp.add(1, dimension_numbers.update_window_dims))
A:jax.lax.scatter_add_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-add', _scatter_translation_rule)
A:jax.lax.batching.primitive_batchers[scatter_add_p]->partial(_scatter_batching_rule, scatter_add)
A:jax.lax.updates_dtype->_dtype(updates)
A:jax.lax.new_operand->pad(new_operand, _zero(operand), ((0, 1, 0),) + tuple(((0, 0, 0) for _ in operand_shape)))
A:jax.lax.ids_shape->numpy.array(updates_shape)
A:jax.lax.num_ids->numpy.prod(ids_shape)
A:jax.lax.update_ids->add(reshape(iota(updates_dtype, num_ids), ids_shape), _ones(updates))
A:jax.lax.reshaped_update_ids->reshape(update_ids, (1,) + updates_shape)
A:jax.lax.updates_and_ids->concatenate((updates, reshaped_update_ids), 0)
A:jax.lax.new_dnums->ScatterDimensionNumbers(update_window_dims=(0,) + tuple((d + 1 for d in dnums.update_window_dims)), inserted_window_dims=tuple((d + 1 for d in dnums.inserted_window_dims)), scatter_dims_to_operand_dims=tuple((d + 1 for d in dnums.scatter_dims_to_operand_dims)))
A:jax.lax.scattered_ids->index_in_dim(outputs, 1, keepdims=False)
A:jax.lax.gathered_update_ids->gather(scattered_ids, scatter_indices, dimension_numbers=gather_dnums, slice_sizes=slice_sizes)
A:jax.lax.masked_g_operand->select(eq(scattered_ids, _zeros(scattered_ids)), g_operand, _zeros(g_operand))
A:jax.lax.masked_g_updates->select(eq(update_ids, gathered_update_ids), g_updates, _zeros(g_updates))
A:jax.lax.scatter_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter', _scatter_translation_rule)
A:jax.lax.batching.primitive_batchers[scatter_p]->partial(_scatter_batching_rule, scatter)
A:jax.lax.xla_computation->_select_and_gather_add_pair_reducer(dtype, select_prim)
A:jax.lax.reduce_p->standard_primitive(_reduce_shape_rule, _input_dtype, 'reduce', _reduce_translation_rule)
A:jax.lax.scalar->lib.xla_bridge.Shape.array_shape(dtype, ())
A:jax.lax.broadcast_dimensions->numpy.delete(onp.arange(keys.ndim), keys_bdim)
A:jax.lax.reduce_sum_p->standard_primitive(_reduce_sum_shape_rule, _input_dtype, 'reduce_sum', _reduce_sum_translation_rule)
A:jax.lax.location_indicators->convert_element_type(_eq_meet(operand, reshape(ans, shape)), g.dtype)
A:jax.lax._reduce_max_translation_rule->partial(_reduce_chooser_translation_rule, max_p, _get_max_identity)
A:jax.lax.reduce_max_p->standard_primitive(_reduce_chooser_shape_rule, _input_dtype, 'reduce_max', _reduce_max_translation_rule)
A:jax.lax._reduce_min_translation_rule->partial(_reduce_chooser_translation_rule, min_p, _get_min_identity)
A:jax.lax.reduce_min_p->standard_primitive(_reduce_chooser_shape_rule, _input_dtype, 'reduce_min', _reduce_min_translation_rule)
A:jax.lax._reduce_or_translation_rule->partial(_reduce_logical_translation_rule, or_p, _get_max_identity)
A:jax.lax.reduce_or_p->standard_primitive(_reduce_logical_shape_rule, _fixed_dtype(onp.bool_), 'reduce_or', _reduce_or_translation_rule)
A:jax.lax._reduce_and_translation_rule->partial(_reduce_logical_translation_rule, and_p, _get_min_identity)
A:jax.lax.reduce_and_p->standard_primitive(_reduce_logical_shape_rule, _fixed_dtype(onp.bool_), 'reduce_and', _reduce_and_translation_rule)
A:jax.lax.reduce_window_p->standard_primitive(_reduce_window_shape_rule, _input_dtype, 'reduce_window', _reduce_window_translation_rule)
A:jax.lax.in_pads->padtype_to_pads(input_shape, window_dimensions, window_strides, padding)
A:jax.lax.pad_cotangent->pad(cotangent, _zero(cotangent), padding_config)
A:jax.lax.oprand->_reduce_window_sum(operand, window_dimensions, window_strides, padding)
A:jax.lax.reduce_window_sum_p->standard_primitive(_reduce_window_sum_shape_rule, _input_dtype, 'reduce_window_sum', _reduce_window_sum_translation_rule)
A:jax.lax.operand_padded->numpy.add(operand_shape, onp.add(*zip(*pads)))
A:jax.lax._reduce_window_max_translation_rule->partial(_reduce_window_chooser_translation_rule, max_p, _get_max_identity)
A:jax.lax.reduce_window_max_p->standard_primitive(_common_reduce_window_shape_rule, _input_dtype, 'reduce_window_max', _reduce_window_max_translation_rule)
A:jax.lax._reduce_window_min_translation_rule->partial(_reduce_window_chooser_translation_rule, min_p, _get_min_identity)
A:jax.lax.reduce_window_min_p->standard_primitive(_common_reduce_window_shape_rule, _input_dtype, 'reduce_window_min', _reduce_window_min_translation_rule)
A:jax.lax.select->interpreters.xla.primitive_computation(select_prim, scalar, scalar)
A:jax.lax.scatter->interpreters.xla.primitive_computation(add_p, scalar, scalar)
A:jax.lax.select_and_scatter_p->standard_primitive(_select_and_scatter_shape_rule, _input_dtype, 'select_and_scatter', _select_and_scatter_translation)
A:jax.lax.source->interpreters.batching.move_dim_to_front(source, s_bdims)
A:jax.lax.select_and_scatter_add_p->standard_primitive(_select_and_scatter_add_shape_rule, _input_dtype, 'select_and_scatter_add', _select_and_scatter_add_translation)
A:jax.lax.uint_etype->lib.xla_bridge.dtype_to_etype(_UINT_DTYPES[bits])
A:jax.lax.etype->lib.xla_bridge.dtype_to_etype(diag_const.dtype)
A:jax.lax.c->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer')
A:jax.lax.bits_const->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Constant(pair_uint_dtype(bits), canonicalize_types=False)
A:jax.lax.st->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').ConvertElementType(c.ShiftRightLogical(t, bits_const), uint_etype)
A:jax.lax.sx->fst(x)
A:jax.lax.sy->fst(y)
A:jax.lax.pair_uint_etype->lib.xla_bridge.dtype_to_etype_exact(pair_uint_dtype)
A:jax.lax.tangents->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').ConvertElementType(tangents, pair_uint_etype)
A:jax.lax.init->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').ShiftLeft(init, c.Constant(pair_uint_dtype(bits), canonicalize_types=False))
A:jax.lax.select_and_gather_add_p->standard_primitive(_select_and_gather_add_shape_rule, _input_dtype, 'select_and_gather_add', _select_and_gather_add_translation)
A:jax.lax.(_, g_out)->sort_key_val(operand, g, dimension)
A:jax.lax.sort_p->standard_primitive(sort_shape, _input_dtype, 'sort')
A:jax.lax.keys_tangents_out->_sort_jvp_rule(keys_tangents, keys, dimension)
A:jax.lax.values_tangents_out->_sort_jvp_rule(values_tangents, keys, dimension)
A:jax.lax.iota->tuple(range(len(lhs_shape)))
A:jax.lax.(_, perm)->sort_key_val(keys, iota)
A:jax.lax.keys_trans->interpreters.batching.moveaxis(keys.shape[keys_bdim], values_bdim, keys_bdim, keys)
A:jax.lax.new_keys->broadcast_in_dim(keys, values.shape, broadcast_dimensions)
A:jax.lax.new_values->broadcast_in_dim(values, keys.shape, broadcast_dimensions)
A:jax.lax.sort_key_val_p->Primitive('sort_key_val')
A:jax.lax.xla.translations[sort_key_val_p]->partial(standard_translate, 'sort_key_val')
A:jax.lax.loop_carry->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Tuple(init_val, cond_tracer_consts, body_tracer_consts)
A:jax.lax.loop_carry_var->interpreters.partial_eval.Var(0, 'loop_carry')
A:jax.lax.cond_var->interpreters.partial_eval.Var(0, 'cond_consts')
A:jax.lax.body_var->interpreters.partial_eval.Var(0, 'body_consts')
A:jax.lax.num_cond_consts->len(cond_consts.val)
A:jax.lax.cond_jaxpr_converted->cond_jaxpr.copy()
A:jax.lax.num_body_consts->len(body_consts.val)
A:jax.lax.body_jaxpr_converted->body_jaxpr.copy()
A:jax.lax.cond_computation->interpreters.xla.jaxpr_computation(cond_jaxpr_converted, cond_consts.val, (), shape)
A:jax.lax.body_computation->interpreters.xla.jaxpr_computation(body_jaxpr_converted, body_consts.val, (), shape)
A:jax.lax.full_ans->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').While(cond_computation, body_computation, loop_carry)
A:jax.lax.sizes->_reduce(set.union, map(batching.dimsize, batch_dims, batched_args))
A:jax.lax.init_val->interpreters.batching.bdim_at_front(init_val, init_val_bd, size, force_broadcast=True)
A:jax.lax.cond_tracer_consts->tuple((x for x in cond_tracer_consts))
A:jax.lax.f->interpreters.batching.batch_transform(lifted, size, (init_val_bd, cond_tracer_consts_bd, body_tracer_consts_bd), init_val_bd)
A:jax.lax.preds->interpreters.batching.batch_transform(lifted, size, (init_val_bd, cond_tracer_consts_bd, body_tracer_consts_bd), init_val_bd).call_wrapped((batched_loop_carry, cond_tracer_consts))
A:jax.lax.body_tracer_consts->tuple((x for x in body_tracer_consts))
A:jax.lax.new_loop_carry->core.eval_jaxpr(body_jaxpr, body_consts.val + body_tracer_consts, (), loop_carry)
A:jax.lax.while_p->Primitive('while')
A:jax.lax.arg_var->interpreters.partial_eval.Var(0, 'arg')
A:jax.lax.consts_var->interpreters.partial_eval.Var(0, 'consts')
A:jax.lax.jaxpr_converted->jaxpr.copy()
A:jax.lax.true_arg->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Tuple(true_op, true_consts)
A:jax.lax.true_comp->make_computation(true_jaxpr, true_arg)
A:jax.lax.false_arg->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Tuple(false_op, false_consts)
A:jax.lax.false_comp->make_computation(false_jaxpr, false_arg)
A:jax.lax.cond_p->Primitive('cond')
A:jax.lax.tie_in_p->Primitive('tie_in')
A:jax.lax.shaped_identity_p->Primitive('shape_id')
A:jax.lax.self.dtype->_dtype(fill_value)
A:jax.lax.self.ndim->len(shape)
A:jax.lax.self.size->prod(shape)
A:jax.lax.self._npy_value->numpy.broadcast_to(result, self.shape)
A:jax.lax.stop_gradient_p->Primitive('stop_gradient')
A:jax.lax.psum_p->PmapPrimitive('psum')
A:jax.lax.pswapaxes_p->PmapPrimitive('pswapaxes')
A:jax.lax.psplit_p->PmapPrimitive('psplit')
A:jax.lax.pcollect_p->PmapPrimitive('pcollect')
A:jax.lax.dtypes->list(map(onp.dtype, dtypes))
A:jax.lax.lhs_padded->numpy.add(lhs_shape[2:], onp.add(*zip(*pads)))
A:jax.lax.out_space->numpy.maximum(0, out_space)
A:jax.lax.(lhs_perm, rhs_perm, out_perm)->map(getperm, dimension_numbers, charpairs)
A:jax.lax.obj_arr->numpy.array(obj)
A:jax.lax._zeros->partial(full_like, fill_value=0)
A:jax.lax._zero->partial(full_like, shape=(), fill_value=0)
A:jax.lax._ones->partial(full_like, fill_value=1)
A:jax.lax._one->partial(full_like, shape=(), fill_value=1)
A:jax.lax._twos->partial(full_like, fill_value=2)
A:jax.lax._two->partial(full_like, shape=(), fill_value=2)
A:jax.lax.x_len->len(x)
A:jax.lax.blacklist->set(itertools.chain(*removed_lists))
A:jax.lax.(lhs_spec, rhs_spec, out_spec)->conv_general_permutations(dimension_numbers)
A:jax.lax.spatial->sorted(spatial, key=lambda i: rhs_spec.index(spec[i]))
A:jax.lax.lhs_dilated_shape->_dilate_shape(in_shape, lhs_dilation)
A:jax.lax.out_dilated_shape->_dilate_shape(out_shape, window_strides)
A:jax.lax.rhs_dilated_shape->_dilate_shape(window_dimensions, rhs_dilation)
A:jax.lax.higher_dtype->numpy.promote_types(a_dtype, b_dtype)
A:jax.lax.a->convert_element_type(a, b_dtype)
A:jax.lax.b->convert_element_type(b, a_dtype)
A:jax.lax.lst->list(lst)
jax.lax.ConvDimensionNumbers(collections.namedtuple('ConvDimensionNumbers',['lhs_spec','rhs_spec','out_spec']))
jax.lax.GatherDimensionNumbers(collections.namedtuple('GatherDimensionNumbers',['offset_dims','collapsed_slice_dims','start_index_map']))
jax.lax.PmapPrimitive(name)
jax.lax.ScatterDimensionNumbers(collections.namedtuple('ScatterDimensionNumbers',['update_window_dims','inserted_window_dims','scatter_dims_to_operand_dims']))
jax.lax._EyeConstant(self,shape,axes,dtype)
jax.lax._EyeConstant._value(self)
jax.lax._EyeConstant.constant_handler(c,diag_const,canonicalize_types=True)
jax.lax._FilledConstant(self,fill_value,shape)
jax.lax._FilledConstant._value(self)
jax.lax._FilledConstant.constant_handler(c,filled_const,canonicalize_types=True)
jax.lax._IotaConstant(self,dtype,shape,axis)
jax.lax._IotaConstant._value(self)
jax.lax._IotaConstant.constant_handler(c,iota_constant,canonicalize_types=True)
jax.lax._OpaqueParam(self,val)
jax.lax._abstractify(x)
jax.lax._add_transpose(t,x,y)
jax.lax._balanced_eq(x,z,y)
jax.lax._bitcast_convert_type_dtype_rule(operand,new_dtype)
jax.lax._bitcast_convert_type_shape_rule(operand,new_dtype)
jax.lax._bitcast_convert_type_translation_rule(c,operand,new_dtype)
jax.lax._brcast(x,*others)
jax.lax._brcast_to(x,shape)
jax.lax._broadcast_batch_rule(batched_args,batch_dims,sizes)
jax.lax._broadcast_in_dim_batch_rule(batched_args,batch_dims,shape,broadcast_dimensions)
jax.lax._broadcast_in_dim_shape_rule(operand,shape,broadcast_dimensions)
jax.lax._broadcast_in_dim_transpose_rule(t,shape,broadcast_dimensions)
jax.lax._broadcast_shape_rule(operand,sizes)
jax.lax._broadcasting_select(c,which,x,y)
jax.lax._broadcasting_shape_rule(name,*avals)
jax.lax._check_conv_shapes(name,lhs_shape,rhs_shape,window_strides)
jax.lax._check_same_dtypes(name,ignore_fp_precision,*dtypes)
jax.lax._check_shapelike(fun_name,arg_name,obj)
jax.lax._clamp_shape_rule(min,operand,max)
jax.lax._common_reduce_window_shape_rule(operand,window_dimensions,window_strides,padding)
jax.lax._concatenate_batch_rule(batched_args,batch_dims,dimension,operand_shapes)
jax.lax._concatenate_dtype_rule(*operands,**kwargs)
jax.lax._concatenate_shape_rule(*operands,**kwargs)
jax.lax._concatenate_translation_rule(c,*operands,**kwargs)
jax.lax._concatenate_transpose_rule(t,*operands,**kwargs)
jax.lax._cond_abstract_eval(pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax._cond_translation_rule(c,pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax._conj_transpose_rule(t,x,input_dtype)
jax.lax._const(example,val)
jax.lax._conv_general_dilated_batch_rule(batched_args,batch_dims,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,**unused_kwargs)
jax.lax._conv_general_dilated_dtype_rule(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,**unused_kwargs)
jax.lax._conv_general_dilated_shape_rule(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,**unused_kwargs)
jax.lax._conv_general_dilated_translation_rule(c,lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,**unused_kwargs)
jax.lax._conv_general_dilated_transpose_lhs(g,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,lhs_shape,rhs_shape)
jax.lax._conv_general_dilated_transpose_rhs(g,lhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,lhs_shape,rhs_shape)
jax.lax._conv_general_proto(dimension_numbers)
jax.lax._conv_general_vjp_lhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax.lax._conv_general_vjp_rhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax.lax._convert_element_type_dtype_rule(operand,new_dtype,old_dtype)
jax.lax._convert_element_type_shape_rule(operand,new_dtype,old_dtype)
jax.lax._convert_element_type_translation_rule(c,operand,new_dtype,old_dtype)
jax.lax._dilate_shape(shape,dilation)
jax.lax._div_transpose_rule(cotangent,x,y)
jax.lax._dot_batch_rule(batched_args,batch_dims)
jax.lax._dot_general_batch_rule(batched_args,batch_dims,dimension_numbers)
jax.lax._dot_general_dtype_rule(lhs,rhs,dimension_numbers)
jax.lax._dot_general_shape_rule(lhs,rhs,dimension_numbers)
jax.lax._dot_general_transpose_lhs(g,y,dimension_numbers,swap_ans=False)
jax.lax._dot_general_transpose_rhs(g,x,dimension_numbers)
jax.lax._dot_papply_rule(name,vals,dims)
jax.lax._dot_shape_rule(lhs,rhs)
jax.lax._dot_transpose_lhs(t,rhs)
jax.lax._dot_transpose_rhs(t,lhs)
jax.lax._dynamic_slice_batching_rule(batched_args,batch_dims,slice_sizes,operand_shape)
jax.lax._dynamic_slice_indices(operand,start_indices)
jax.lax._dynamic_slice_jvp_rule(g,operand,start_indices,slice_sizes,operand_shape)
jax.lax._dynamic_slice_shape_rule(operand,start_indices,slice_sizes,operand_shape)
jax.lax._dynamic_slice_translation_rule(c,operand,start_indices,slice_sizes,operand_shape)
jax.lax._dynamic_slice_transpose_rule(t,operand,start_indices,slice_sizes,operand_shape)
jax.lax._dynamic_update_slice_dtype_rule(operand,update,start_indices,update_shape)
jax.lax._dynamic_update_slice_jvp(primals,tangents,update_shape)
jax.lax._dynamic_update_slice_shape_rule(operand,update,start_indices,update_shape)
jax.lax._dynamic_update_slice_translation_rule(c,operand,update,start_indices,update_shape)
jax.lax._dynamic_update_slice_transpose_rule(t,operand,update,start_indices,update_shape)
jax.lax._eq_meet(a,b)
jax.lax._gather_batching_rule(batched_args,batch_dims,dimension_numbers,slice_sizes,operand_shape)
jax.lax._gather_dimensions_proto(indices_shape,dimension_numbers)
jax.lax._gather_dtype_rule(operand,start_indices,**kwargs)
jax.lax._gather_jvp_rule(g,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax._gather_serial_pmap_rule(val,axis)
jax.lax._gather_shape_rule(operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax._gather_translation_rule(c,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax._gather_transpose_rule(t,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax._get_max_identity(dtype)
jax.lax._get_min_identity(dtype)
jax.lax._get_monoid_reducer(monoid_op,x)
jax.lax._get_monoid_window_reducer(monoid_op,x)
jax.lax._iter(tracer)
jax.lax._jaxtupletree_select(pred,on_true,on_false)
jax.lax._minmax_translation_rule(c,x,y,minmax=None,cmp=None)
jax.lax._ndim(x)
jax.lax._outer(x,y)
jax.lax._pack_eqn(invars,outvar)
jax.lax._pad_batch_rule(batched_args,batch_dims,padding_config)
jax.lax._pad_shape_rule(operand,padding_value,padding_config)
jax.lax._pad_transpose(t,operand,padding_value,padding_config)
jax.lax._pcollect_serial_pmap_rule(x,axis_in)
jax.lax._pow_jvp_lhs(g,x,y)
jax.lax._pow_jvp_rhs(g,x,y)
jax.lax._psplit_serial_pmap_rule(x,axis_in,axis)
jax.lax._psum_parallel_translation_rule(c,val,device_groups)
jax.lax._psum_serial_pmap_rule(val,axis)
jax.lax._psum_transpose_rule(t,axis_name)
jax.lax._pswapaxes_serial_pmap_rule(x,axis_in,axis)
jax.lax._reduce_and(operand,axes)
jax.lax._reduce_batch_rule(batched_args,batch_dims,computation,jaxpr,consts,dimensions)
jax.lax._reduce_chooser_jvp_rule(g,ans,operand,axes)
jax.lax._reduce_chooser_shape_rule(operand,axes)
jax.lax._reduce_chooser_translation_rule(prim,identity,c,operand,axes)
jax.lax._reduce_logical_shape_rule(operand,axes)
jax.lax._reduce_logical_translation_rule(prim,identity,c,operand,axes)
jax.lax._reduce_max(operand,axes)
jax.lax._reduce_min(operand,axes)
jax.lax._reduce_or(operand,axes)
jax.lax._reduce_shape_rule(operand,init_value,computation,jaxpr,consts,dimensions)
jax.lax._reduce_sum(operand,axes)
jax.lax._reduce_sum_shape_rule(operand,axes,input_shape)
jax.lax._reduce_sum_translation_rule(c,operand,axes,input_shape)
jax.lax._reduce_sum_transpose_rule(cotangent,input_shape,axes)
jax.lax._reduce_translation_rule(c,operand,init_value,computation,jaxpr,consts,dimensions)
jax.lax._reduce_window_chooser_jvp_rule(prim,g,operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_chooser_translation_rule(prim,identity,c,operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_max(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_max_batch_rule(batched_args,bdims,window_dimensions,window_strides,padding,**kwargs)
jax.lax._reduce_window_min(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_prod(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_shape_rule(operand,init_value,jaxpr,consts,window_dimensions,window_strides,padding)
jax.lax._reduce_window_sum(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_sum_batch_rule(batched_args,bdims,window_dimensions,window_strides,padding,**kwargs)
jax.lax._reduce_window_sum_shape_rule(operand,window_dimensions,window_strides,padding,input_shape)
jax.lax._reduce_window_sum_translation_rule(c,operand,window_dimensions,window_strides,padding,input_shape)
jax.lax._reduce_window_sum_transpose_rule(cotangent,window_dimensions,window_strides,padding,input_shape)
jax.lax._reduce_window_translation_rule(c,operand,init_value,jaxpr,consts,window_dimensions,window_strides,padding)
jax.lax._reduction_computation(c,jaxpr,consts,init_value)
jax.lax._reduction_jaxpr(computation,init_value)
jax.lax._reshape_batch_rule(batched_args,batch_dims,new_sizes,dimensions,**unused)
jax.lax._reshape_dtype_rule(operand,new_sizes,dimensions,**unused_kwargs)
jax.lax._reshape_papply_rule(name,vals,axes,new_sizes,dimensions,old_sizes)
jax.lax._reshape_shape_rule(operand,new_sizes,dimensions,**unused_kwargs)
jax.lax._reshape_translation_rule(c,operand,new_sizes,dimensions,old_sizes)
jax.lax._reshape_transpose_rule(t,new_sizes,dimensions,old_sizes)
jax.lax._rev_batch_rule(batched_args,batch_dims,dimensions)
jax.lax._rev_shape_rule(operand,dimensions)
jax.lax._revise_cond_jaxpr(new_pval,old_pval,jaxpr,consts)
jax.lax._safe_mul(x,y)
jax.lax._safe_mul_translation_rule(c,x,y)
jax.lax._scan_abstract_eval(a,bs,consts,aval_out,jaxpr)
jax.lax._scan_impl(a,bs,consts,aval_out,jaxpr)
jax.lax._scan_jvp(primals,tangents,aval_out,jaxpr)
jax.lax._scatter_add_jvp(primals,tangents,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax._scatter_add_transpose_rule(t,operand,scatter_indices,updates,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax._scatter_batching_rule(scatter_op,batched_args,batch_dims,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax._scatter_dimensions_proto(indices_shape,dimension_numbers)
jax.lax._scatter_dtype_rule(operand,scatter_indices,updates,**kwargs)
jax.lax._scatter_jvp(primals,tangents,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax._scatter_shape_rule(operand,scatter_indices,updates,**kwargs)
jax.lax._scatter_translation_rule(c,operand,scatter_indices,updates,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax._select_and_gather_add(tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_gather_add_pair_reducer(dtype,select_prim)
jax.lax._select_and_gather_add_shape_rule(tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_gather_add_translation(c,tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_gather_add_transpose(t,tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_scatter(operand,select,window_dimensions,window_strides,padding,source,init_value,scatter)
jax.lax._select_and_scatter_add(source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_scatter_add_batch_rule(batched_args,batch_dims,**kwargs)
jax.lax._select_and_scatter_add_shape_rule(source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_scatter_add_translation(c,source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_scatter_add_transpose(t,source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax._select_and_scatter_shape_rule(operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax.lax._select_and_scatter_translation(c,operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax.lax._select_batch_rule(batched_args,batch_dims,**unused_kwargs)
jax.lax._select_dtype_rule(pred,on_true,on_false)
jax.lax._select_shape_rule(pred,on_true,on_false)
jax.lax._select_transpose_rule(t,pred,on_true,on_false)
jax.lax._slice_batching_rule(batched_args,batch_dims,start_indices,limit_indices,strides,**unused_kwargs)
jax.lax._slice_shape_rule(operand,start_indices,limit_indices,strides,operand_shape)
jax.lax._slice_translation_rule(c,operand,start_indices,limit_indices,strides,operand_shape)
jax.lax._slice_transpose_rule(t,start_indices,limit_indices,strides,operand_shape)
jax.lax._sort_jvp_rule(g,operand,dimension)
jax.lax._sort_key_val_abstract_eval(keys,values,dimension)
jax.lax._sort_key_val_batch_rule(batched_args,batch_dims,dimension)
jax.lax._sort_key_val_impl(keys,values,dimension)
jax.lax._sort_key_val_jvp(primals,tangents,dimension)
jax.lax._sort_key_val_transpose_rule(t,keys,values,dimension)
jax.lax._stop_gradient_batch_rule(batched_args,batch_dims)
jax.lax._stop_gradient_jvp_rule(primals,tangents)
jax.lax._sub_transpose(t,x,y)
jax.lax._tie_in_batch_rule(batched_args,batch_dims)
jax.lax._tie_in_transpose_rule(t)
jax.lax._transpose_batch_rule(batched_args,batch_dims,permutation)
jax.lax._transpose_papply_rule(name,vals,dims,permutation)
jax.lax._transpose_shape_rule(operand,permutation)
jax.lax._unbound_name_error(primitive_name,*args,**kwargs)
jax.lax._unpack_eqn(invar,outvars)
jax.lax._while_loop_abstract_eval(init_val,cond_tracer_consts,body_tracer_consts,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax._while_loop_batching_rule(batched_args,batch_dims,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax._while_loop_translation_rule(c,init_val,cond_tracer_consts,body_tracer_consts,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax.abs(x)
jax.lax.acos(x)
jax.lax.acosh(x)
jax.lax.add(x,y)
jax.lax.asin(x)
jax.lax.asinh(x)
jax.lax.atan(x)
jax.lax.atan2(x,y)
jax.lax.atanh(x)
jax.lax.batch_matmul(lhs,rhs)
jax.lax.binop(result_dtype,accepted_dtypes,name,translation_rule=None)
jax.lax.binop_dtype_rule(result_dtype,accepted_dtypes,name,*avals,**kwargs)
jax.lax.bitcast_convert_type(operand,new_dtype)
jax.lax.bitwise_and(x,y)
jax.lax.bitwise_not(x)
jax.lax.bitwise_or(x,y)
jax.lax.bitwise_xor(x,y)
jax.lax.broadcast(operand,sizes)
jax.lax.broadcast_in_dim(operand,shape,broadcast_dimensions)
jax.lax.broadcast_shapes(*shapes)
jax.lax.broadcasted_eye(dtype,shape,axes)
jax.lax.broadcasted_iota(dtype,shape,dimension)
jax.lax.ceil(x)
jax.lax.clamp(min,x,max)
jax.lax.collapse(operand,start_dimension,stop_dimension)
jax.lax.complex(x,y)
jax.lax.concatenate(operands,dimension)
jax.lax.cond(pred,true_operand,true_fun,false_operand,false_fun)
jax.lax.conj(x)
jax.lax.conv(lhs,rhs,window_strides,padding)
jax.lax.conv_dimension_numbers(lhs_shape,rhs_shape,dimension_numbers)
jax.lax.conv_general_dilated(lhs,rhs,window_strides,padding,lhs_dilation=None,rhs_dilation=None,dimension_numbers=None)
jax.lax.conv_general_permutations(dimension_numbers)
jax.lax.conv_general_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax.lax.conv_shape_tuple(lhs_shape,rhs_shape,strides,pads)
jax.lax.conv_with_general_padding(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation)
jax.lax.convert_element_type(operand,new_dtype)
jax.lax.cos(x)
jax.lax.cosh(x)
jax.lax.digamma(x)
jax.lax.div(x,y)
jax.lax.dot(lhs,rhs)
jax.lax.dot_general(lhs,rhs,dimension_numbers)
jax.lax.dynamic_index_in_dim(operand,index,axis=0,keepdims=True)
jax.lax.dynamic_slice(operand,start_indices,slice_sizes)
jax.lax.dynamic_slice_in_dim(operand,start_index,slice_size,axis=0)
jax.lax.dynamic_update_index_in_dim(operand,update,index,axis)
jax.lax.dynamic_update_slice(operand,update,start_indices)
jax.lax.dynamic_update_slice_in_dim(operand,update,start_index,axis)
jax.lax.eq(x,y)
jax.lax.erf(x)
jax.lax.erf_inv(x)
jax.lax.erfc(x)
jax.lax.exp(x)
jax.lax.expm1(x)
jax.lax.eye(dtype,size)
jax.lax.floor(x)
jax.lax.fori_loop(lower,upper,body_fun,init_val)
jax.lax.full(shape,fill_value,dtype=None)
jax.lax.full_like(x,fill_value,dtype=None,shape=None)
jax.lax.gather(operand,start_indices,dimension_numbers,slice_sizes)
jax.lax.ge(x,y)
jax.lax.gt(x,y)
jax.lax.identity(x)
jax.lax.imag(x)
jax.lax.index_in_dim(operand,index,axis=0,keepdims=True)
jax.lax.index_take(src,idxs,axes)
jax.lax.iota(dtype,size)
jax.lax.is_finite(x)
jax.lax.le(x,y)
jax.lax.lgamma(x)
jax.lax.log(x)
jax.lax.log1p(x)
jax.lax.lt(x,y)
jax.lax.max(x,y)
jax.lax.maybe_tracer_tuple_to_abstract_tuple(tup)
jax.lax.min(x,y)
jax.lax.mul(x,y)
jax.lax.ne(x,y)
jax.lax.neg(x)
jax.lax.pad(operand,padding_value,padding_config)
jax.lax.padtype_to_pads(in_shape,window_shape,window_strides,padding)
jax.lax.pcollect(x,axis_name)
jax.lax.pow(x,y)
jax.lax.psplit(x,axis_name,axis)
jax.lax.psum(x,axis_name)
jax.lax.pswapaxes(x,axis_name,axis)
jax.lax.ranges_like(*xs)
jax.lax.real(x)
jax.lax.reciprocal(x)
jax.lax.reduce(operand,init_value,computation,dimensions)
jax.lax.reduce_window(operand,init_value,computation,window_dimensions,window_strides,padding)
jax.lax.reduce_window_shape_tuple(operand_shape,window_dimensions,window_strides,padding)
jax.lax.rem(x,y)
jax.lax.remaining(original,*removed_lists)
jax.lax.reshape(operand,new_sizes,dimensions=None)
jax.lax.rev(operand,dimensions)
jax.lax.round(x)
jax.lax.rsqrt(x)
jax.lax.scan(f,a,bs)
jax.lax.scatter(operand,scatter_indices,updates,dimension_numbers)
jax.lax.scatter_add(operand,scatter_indices,updates,dimension_numbers)
jax.lax.select(pred,on_true,on_false)
jax.lax.shaped_identity(x)
jax.lax.shift_left(x,y)
jax.lax.shift_right_arithmetic(x,y)
jax.lax.shift_right_logical(x,y)
jax.lax.sign(x)
jax.lax.sin(x)
jax.lax.sinh(x)
jax.lax.slice(operand,start_indices,limit_indices,strides=None)
jax.lax.slice_in_dim(operand,start_index,limit_index,stride=1,axis=0)
jax.lax.sort(operand,dimension=-1)
jax.lax.sort_key_val(keys,values,dimension=-1)
jax.lax.sqrt(x)
jax.lax.square(x)
jax.lax.standard_abstract_eval(shape_rule,dtype_rule,*args,**kwargs)
jax.lax.standard_primitive(shape_rule,dtype_rule,name,translation_rule=None)
jax.lax.standard_translate(name,c,*args,**kwargs)
jax.lax.stop_gradient(x)
jax.lax.sub(x,y)
jax.lax.subvals(lst,replace)
jax.lax.tan(x)
jax.lax.tanh(x)
jax.lax.tie_in(x,y)
jax.lax.transpose(operand,permutation)
jax.lax.unop(result_dtype,accepted_dtypes,name)
jax.lax.unop_dtype_rule(result_dtype,accepted_dtypes,name,aval,**kwargs)
jax.lax.while_loop(cond_fun,body_fun,init_val)
jax.lax.zeros_like_array(x)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/test_util.py----------------------------------------
A:jax.test_util.atol->max(atol, 0.5)
A:jax.test_util.rtol->max(rtol, 0.1)
A:jax.test_util.close->partial(numpy_close, atol=atol, rtol=rtol)
A:jax.test_util.add->partial(tree_multimap, onp.add)
A:jax.test_util.sub->partial(tree_multimap, onp.subtract)
A:jax.test_util.conj->partial(tree_map, onp.conj)
A:jax.test_util.shape->numpy.shape(x)
A:jax.test_util.dtype->_dtype(x)
A:jax.test_util.delta->scalar_mul(tangents, eps)
A:jax.test_util.f_pos->f(*add(primals, delta))
A:jax.test_util.f_neg->f(*sub(primals, delta))
A:jax.test_util.rng->numpy.random.RandomState(0)
A:jax.test_util.tangent->tree_map(_rand_like, args)
A:jax.test_util.(v_out, t_out)->f_jvp(args, tangent)
A:jax.test_util.v_out_expected->f(*args)
A:jax.test_util.t_out_expected->numerical_jvp(f, args, tangent, eps=eps)
A:jax.test_util._rand_like->partial(rand_like, onp.random.RandomState(0))
A:jax.test_util.(v_out, vjpfun)->f_vjp(*args)
A:jax.test_util.tangent_out->numerical_jvp(f, args, tangent, eps=eps)
A:jax.test_util.cotangent->tree_map(_rand_like, v_out)
A:jax.test_util.cotangent_out->conj(vjpfun(conj(cotangent)))
A:jax.test_util.ip->inner_prod(tangent, cotangent_out)
A:jax.test_util.ip_expected->inner_prod(tangent_out, cotangent)
A:jax.test_util.(out_primal_py, vjp_py)->api.vjp(f, *args)
A:jax.test_util.test_name->getattr(test_method, '__name__', '[unknown test]')
A:jax.test_util.flag_value->getattr(FLAGS, flag_name)
A:jax.test_util.NUMPY_SCALAR_SHAPE->_NumpyScalar()
A:jax.test_util.shapestr->','.join((str(dim) for dim in shape))
A:jax.test_util.vals->numpy.where(zeros, 0, vals)
A:jax.test_util.x_ravel->numpy.asarray(x).ravel()
A:jax.test_util.base_rand->rand_default()
A:jax.test_util.dims->_dims_of_shape(shape)
A:jax.test_util.xs->list(xs)
A:jax.test_util.k->min(len(xs), FLAGS.num_generated_cases)
A:jax.test_util.msg->'Arguments x and y not equal to tolerance atol={}, rtol={}:\nx:\n{}\ny:\n{}\n'.format(atol, rtol, x, y)
A:jax.test_util.x_dtype->c128_to_c64(onp.asarray(x).dtype)
A:jax.test_util.y_dtype->c128_to_c64(onp.asarray(y).dtype)
A:jax.test_util.x->numpy.asarray(x)
A:jax.test_util.y->numpy.asarray(y)
A:jax.test_util.args->args_maker()
A:jax.test_util.python_ans->fun(*args)
A:jax.test_util.cfun->api.jit(wrapped_fun)
A:jax.test_util.monitored_ans->cfun(*args)
A:jax.test_util.compiled_ans->cfun(*args)
A:jax.test_util.numpy_ans->numpy_reference_op(*args)
A:jax.test_util.lax_ans->lax_op(*args)
jax.test_util.JaxTestCase(parameterized.TestCase)
jax.test_util.JaxTestCase._CheckAgainstNumpy(self,numpy_reference_op,lax_op,args_maker,check_dtypes=False,tol=1e-05)
jax.test_util.JaxTestCase._CompileAndCheck(self,fun,args_maker,check_dtypes,rtol=None,atol=None)
jax.test_util.JaxTestCase.assertAllClose(self,x,y,check_dtypes,atol=None,rtol=None)
jax.test_util.JaxTestCase.assertArraysAllClose(self,x,y,check_dtypes,atol=None,rtol=None)
jax.test_util.JaxTestCase.assertDtypesMatch(self,x,y)
jax.test_util._NumpyScalar(object)
jax.test_util._NumpyScalar.__len__(self)
jax.test_util._cast_to_shape(value,shape,dtype)
jax.test_util._dims_of_shape(shape)
jax.test_util._rand_dtype(rand,shape,dtype,scale=1.0,post=lambdax:x)
jax.test_util.cases_from_gens(*gens)
jax.test_util.cases_from_list(xs)
jax.test_util.check_close(xs,ys,atol=ATOL,rtol=RTOL)
jax.test_util.check_eq(xs,ys)
jax.test_util.check_grads(f,args,order,atol=None,rtol=None,eps=None)
jax.test_util.check_jvp(f,f_jvp,args,atol=ATOL,rtol=RTOL,eps=EPS)
jax.test_util.check_raises(thunk,err_type,msg)
jax.test_util.check_raises_regexp(thunk,err_type,pattern)
jax.test_util.check_vjp(f,f_vjp,args,atol=ATOL,rtol=RTOL,eps=EPS)
jax.test_util.dtype_str(dtype)
jax.test_util.format_shape_dtype_string(shape,dtype)
jax.test_util.format_test_name_suffix(opname,shapes,dtypes)
jax.test_util.inner_prod(xs,ys)
jax.test_util.numerical_jvp(f,primals,tangents,eps=EPS)
jax.test_util.numpy_close(a,b,atol=ATOL,rtol=RTOL,equal_nan=False)
jax.test_util.numpy_eq(x,y)
jax.test_util.rand_bool()
jax.test_util.rand_default()
jax.test_util.rand_int(low,high=None)
jax.test_util.rand_like(rng,x)
jax.test_util.rand_nonzero()
jax.test_util.rand_not_small()
jax.test_util.rand_positive()
jax.test_util.rand_small()
jax.test_util.rand_small_positive()
jax.test_util.rand_some_equal()
jax.test_util.rand_some_inf()
jax.test_util.rand_some_zero()
jax.test_util.rand_uniform(low=0.0,high=1.0)
jax.test_util.scalar_mul(xs,a)
jax.test_util.skip_on_devices(*disabled_devices)
jax.test_util.skip_on_flag(flag_name,skip_value)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/core.py----------------------------------------
A:jax.core.JaxprEqn->namedtuple('JaxprEqn', ['invars', 'outvars', 'primitive', 'bound_subjaxprs', 'destructure', 'params'])
A:jax.core.top_trace->find_top_trace(args)
A:jax.core.tracers->map(top_trace.full_raise, args)
A:jax.core.out_tracer->find_top_trace(args).process_primitive(self, tracers, kwargs)
A:jax.core.in_vals->map(read, eqn.invars)
A:jax.core.subfuns->map(lu.wrap_init, subfuns)
A:jax.core.ans->full_lower(top_trace.process_call(primitive, f, tracers, kwargs))
A:jax.core.attr->getattr(self.aval, name)
A:jax.core.t->ref(sublevel)
A:jax.core.aval_property->namedtuple('aval_property', ['fget'])
A:jax.core.aval_method->namedtuple('aval_method', ['fun'])
A:jax.core.trace_stack->TraceStack()
A:jax.core.level->TraceStack().next_level(bottom)
A:jax.core.master->MasterTrace(level, trace_type)
A:jax.core.sublevel->cur_sublevel()
A:jax.core.bot->Bot()
A:jax.core.xs->list(xs)
A:jax.core.unit->JaxTuple(())
A:jax.core.identity_p->Primitive('id')
A:jax.core.pack_p->Primitive('pack')
A:jax.core.x->full_lower(todos.pop()(x))
A:jax.core.trace->type(t)(t.master, sublevel)
A:jax.core.(ans, cur_todo)->full_lower(top_trace.process_call(primitive, f, tracers, kwargs)).trace.post_process_call(primitive, ans)
A:jax.core.(f, env_trace_todo)->process_env_traces(f, primitive, level)
A:jax.core.call_p->Primitive('call')
A:jax.core.call->partial(call_bind, call_p)
A:jax.core.env->set()
A:jax.core.read->partial(read_env, env)
A:jax.core.write->partial(write_env, env)
A:jax.core.const_env->set()
A:jax.core.read_const->partial(read_env, const_env)
A:jax.core.write_const->partial(write_env, const_env)
A:jax.core.pp_subexpr->pp('')
jax.core.AbstractTuple(AbstractValue,tuple)
jax.core.AbstractTuple.__bool__(self,ignored_tracer)
jax.core.AbstractTuple.__repr__(self)
jax.core.AbstractTuple._iter(tracer)
jax.core.AbstractTuple._len(self,ignored_tracer)
jax.core.AbstractTuple.at_least_vspace(self)
jax.core.AbstractTuple.join(self,other)
jax.core.AbstractValue(object)
jax.core.AbstractValue.__repr__(self)
jax.core.AbstractValue.at_least_vspace(self)
jax.core.Bot(AbstractValue)
jax.core.JaxTuple(cls,xs)
jax.core.JaxTuple.__repr__(self)
jax.core.Jaxpr(self,constvars,freevars,invars,outvar,eqns)
jax.core.Jaxpr.__repr__(self)
jax.core.Jaxpr.__str__(self)
jax.core.Jaxpr.copy(self)
jax.core.MasterTrace(self,level,trace_type)
jax.core.MasterTrace.__eq__(self,other)
jax.core.MasterTrace.__hash__(self)
jax.core.MasterTrace.__repr__(self)
jax.core.Primitive(self,name)
jax.core.Primitive.__repr__(self)
jax.core.Primitive.abstract_eval(self,*args,**kwargs)
jax.core.Primitive.bind(self,*args,**kwargs)
jax.core.Primitive.def_abstract_eval(self,abstract_eval)
jax.core.Primitive.def_custom_bind(self,bind)
jax.core.Primitive.def_impl(self,impl)
jax.core.Primitive.impl(self,*args,**kwargs)
jax.core.Sublevel(int)
jax.core.Trace(self,master,sublevel)
jax.core.Trace.__repr__(self)
jax.core.Trace.full_raise(self,val)
jax.core.Trace.lift(self,tracer)
jax.core.Trace.pure(self,val)
jax.core.Trace.sublift(self,tracer)
jax.core.TraceStack(self)
jax.core.TraceStack.__repr__(self)
jax.core.TraceStack.next_level(self,bottom)
jax.core.TraceStack.pop(self,bottom)
jax.core.TraceStack.push(self,val,bottom)
jax.core.Tracer(self,trace)
jax.core.Tracer.__abs__(self)
jax.core.Tracer.__add__(self,other)
jax.core.Tracer.__and__(self,other)
jax.core.Tracer.__array__(self)
jax.core.Tracer.__bool__(self)
jax.core.Tracer.__complex__(self)
jax.core.Tracer.__div__(self,other)
jax.core.Tracer.__divmod__(self,other)
jax.core.Tracer.__eq__(self,other)
jax.core.Tracer.__float__(self)
jax.core.Tracer.__floordiv__(self,other)
jax.core.Tracer.__ge__(self,other)
jax.core.Tracer.__getattr__(self,name)
jax.core.Tracer.__getitem__(self,idx)
jax.core.Tracer.__gt__(self,other)
jax.core.Tracer.__hex__(self)
jax.core.Tracer.__int__(self)
jax.core.Tracer.__invert__(self)
jax.core.Tracer.__iter__(self)
jax.core.Tracer.__le__(self,other)
jax.core.Tracer.__len__(self)
jax.core.Tracer.__long__(self)
jax.core.Tracer.__lshift__(self,other)
jax.core.Tracer.__lt__(self,other)
jax.core.Tracer.__matmul__(self,other)
jax.core.Tracer.__mod__(self,other)
jax.core.Tracer.__mul__(self,other)
jax.core.Tracer.__ne__(self,other)
jax.core.Tracer.__neg__(self)
jax.core.Tracer.__nonzero__(self)
jax.core.Tracer.__oct__(self)
jax.core.Tracer.__or__(self,other)
jax.core.Tracer.__pow__(self,other)
jax.core.Tracer.__radd__(self,other)
jax.core.Tracer.__rand__(self,other)
jax.core.Tracer.__rdiv__(self,other)
jax.core.Tracer.__rdivmod__(self,other)
jax.core.Tracer.__repr__(self)
jax.core.Tracer.__rfloordiv__(self,other)
jax.core.Tracer.__rmatmul__(self,other)
jax.core.Tracer.__rmod__(self,other)
jax.core.Tracer.__rmul__(self,other)
jax.core.Tracer.__ror__(self,other)
jax.core.Tracer.__rpow__(self,other)
jax.core.Tracer.__rshift__(self,other)
jax.core.Tracer.__rsub__(self,other)
jax.core.Tracer.__rtruediv__(self,other)
jax.core.Tracer.__rxor__(self,other)
jax.core.Tracer.__setitem__(self,idx,val)
jax.core.Tracer.__sub__(self,other)
jax.core.Tracer.__truediv__(self,other)
jax.core.Tracer.__xor__(self,other)
jax.core.Tracer.aval(self)
jax.core.apply_todos(todos,x)
jax.core.call_bind(primitive,f,*args,**kwargs)
jax.core.call_impl(f,*args,**kwargs)
jax.core.check_jaxpr(jaxpr)
jax.core.concrete_aval(x)
jax.core.concrete_jaxtuple(xs)
jax.core.cur_sublevel()
jax.core.eval_jaxpr(jaxpr,consts,freevar_vals,*args)
jax.core.find_top_trace(xs)
jax.core.full_lower(val)
jax.core.get_aval(x)
jax.core.lattice_join(x,y)
jax.core.new_master(trace_type,bottom=False)
jax.core.new_sublevel()
jax.core.pack(args)
jax.core.pack_p_bind(*args)
jax.core.pp_jaxpr(jaxpr)
jax.core.process_env_traces(primitive,level,*args)
jax.core.tuple_to_jaxtuple(x)
jax.core.valid_jaxtype(x)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/ad_util.py----------------------------------------
A:jax.ad_util.add_jaxvals_p->Primitive('add_any')
A:jax.ad_util.zeros_like_p->Primitive('zeros_like')
A:jax.ad_util.zero->Zero()
jax.ad_util.Zero(object)
jax.ad_util.Zero.__repr__(self)
jax.ad_util.add_abstract(xs,ys)
jax.ad_util.add_impl(xs,ys)
jax.ad_util.add_jaxtuples(xs,ys)
jax.ad_util.add_jaxvals(x,y)
jax.ad_util.zeros_like_impl(example)
jax.ad_util.zeros_like_impl_jaxtuple(xs)
jax.ad_util.zeros_like_jaxval(val)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/config.py----------------------------------------
A:jax.config.self.FLAGS->NameSpace(self.read)
A:jax.config.config->Config()
jax.config.Config(self)
jax.config.Config.DEFINE_bool(self,name,default,*args,**kwargs)
jax.config.Config.DEFINE_enum(self,name,default,*args,**kwargs)
jax.config.Config.DEFINE_integer(self,name,default,*args,**kwargs)
jax.config.Config.DEFINE_string(self,name,default,*args,**kwargs)
jax.config.Config.add_option(self,name,default,opt_type,meta_args,meta_kwargs)
jax.config.Config.check_exists(self,name)
jax.config.Config.complete_absl_config(self,absl_flags)
jax.config.Config.config_with_absl(self)
jax.config.Config.parse_flags_with_absl(self)
jax.config.Config.read(self,name)
jax.config.Config.update(self,name,val)
jax.config.NameSpace(self,getter)
jax.config.NameSpace.__getattr__(self,name)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/api.py----------------------------------------
A:jax.api.f->lu.wrap_init(fun)
A:jax.api.(f, dyn_args)->_argnums_partial(f, dyn_argnums, args)
A:jax.api.(jaxtupletree_args, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.(jaxtree_fun, out_tree)->pytree_fun_to_jaxtupletree_fun(wrapped, in_trees)
A:jax.api.jaxtupletree_out->interpreters.pxla.xla_pcall(f, *jaxtupletree_args, axis_name=axis_name, axis_size=axis_size)
A:jax.api.f_jitted.__name__->namestr(f_jitted.__name__, axis_name)
A:jax.api.aval->core.get_aval(x)
A:jax.api.wrapped->lu.wrap_init(fun)
A:jax.api.(jax_args, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.pvals->map(pv_like, jax_args)
A:jax.api.(jaxpr, _, consts)->interpreters.partial_eval.trace_to_jaxpr(jaxtree_fun, pvals, **kwargs)
A:jax.api.value_and_grad_f->value_and_grad(fun, argnums, has_aux=has_aux)
A:jax.api.(_, g)->value_and_grad_f(*args, **kwargs)
A:jax.api.((_, aux), g)->value_and_grad_f(*args, **kwargs)
A:jax.api.(f_partial, dyn_args)->_argnums_partial(f, argnums, args)
A:jax.api.(ans, vjp_py)->vjp(f_partial, *dyn_args)
A:jax.api.(ans, vjp_py, aux)->vjp(f_partial, *dyn_args, has_aux=True)
A:jax.api.g->vjp_py(onp.ones((), onp.result_type(ans)))
A:jax.api.pushfwd->partial(jvp, fun, primals)
A:jax.api.(y, jac)->vmap(pushfwd, out_axes=(None, -1))(_std_basis(dyn_args))
A:jax.api.(y, pullback)->vjp(f_partial, *dyn_args)
A:jax.api.jac->tree_map(partial(_unravel_array_into_pytree, y, 0), jac)
A:jax.api.(leaves, _)->tree_flatten(pytree)
A:jax.api.ndim->sum(map(onp.size, leaves))
A:jax.api.(leaves, treedef)->tree_flatten(pytree)
A:jax.api.dtypes->map(_dtype, leaves)
A:jax.api.parts->_split(arr, onp.cumsum(map(onp.size, leaves[:-1])), axis)
A:jax.api.(in_flat, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.out_flat->interpreters.parallel.papply(jaxtree_fun, axis_name, args_flat, axis_size, in_axes_, out_axes)
A:jax.api.axis_sizes->set((onp.shape(leaf)[0] for leaf in leaves))
A:jax.api.axis_size->set((onp.shape(leaf)[0] for leaf in leaves)).pop()
A:jax.api.(f, out_tree)->pytree_fun_to_jaxtupletree_fun(f, in_trees)
A:jax.api.axis_name->interpreters.parallel.newvar()
A:jax.api.(args_flat, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.(primal_jtuple, tree_def)->pytree_to_jaxtupletree(primal)
A:jax.api.(tangent_jtuple, tree_def_2)->pytree_to_jaxtupletree(tangent)
A:jax.api.fun->lu.wrap_init(traceable)
A:jax.api.(ps_flat, ts_flat, in_trees)->unzip3(map(trim_arg, primals, tangents))
A:jax.api.(out_primal, out_tangent)->interpreters.ad.jvp(jaxtree_fun).call_wrapped(ps_flat, ts_flat)
A:jax.api.(primals_flat, in_trees)->unzip2(map(pytree_to_jaxtupletree, primals))
A:jax.api.(out_primal, out_pval, jaxpr, consts)->interpreters.ad.linearize(jaxtree_fun, *primals_flat)
A:jax.api.out_tree->out_tree()
A:jax.api.out_primal_py->build_tree(out_tree, out_primal)
A:jax.api.lifted_jvp->partial(lift_linearized, jaxpr, consts, (in_trees, out_tree), out_pval)
A:jax.api.primals->pack(args)
A:jax.api.tangents->pack(args)
A:jax.api.(_, ans)->eval_jaxpr(jaxpr, consts, (), primals, tangents)
A:jax.api.has_aux->kwargs.pop('has_aux', False)
A:jax.api.(out_primal, out_vjp)->interpreters.ad.vjp(jaxtree_fun, primals_flat)
A:jax.api.(out_primal, out_vjp, aux)->interpreters.ad.vjp(jaxtree_fun, primals_flat, has_aux=True)
A:jax.api.ct_out_tree->PyTreeDef(node_types[tuple], None, in_trees)
A:jax.api.vjp_py->partial(apply_jaxtree_fun, out_vjp_packed, (ct_in_trees, ct_out_tree))
A:jax.api.(pvals, in_trees)->unzip2(map(tree_to_pval_tuples, py_pvals))
A:jax.api.(jaxpr, out_pval, consts)->interpreters.partial_eval.trace_to_jaxpr(jaxtree_fun, pvals, **kwargs)
A:jax.api.ans->eval_jaxpr(jaxpr, consts, (), *args)
A:jax.api.(jaxpr, _, _)->interpreters.partial_eval.trace_to_jaxpr(jaxtree_fun, pvals, **kwargs)
A:jax.api.jaxpr_maker.__name__->'make_jaxpr({})'.format(jaxpr_maker.__name__)
A:jax.api.tree_to_pval_tuples->partial(process_pytree, pe.pack_pvals)
A:jax.api.device_put->jit(lambda x: x)
A:jax.api.device_get->partial(tree_map, device_get_array)
A:jax.api.dyn_argnums->tuple(dyn_argnums)
A:jax.api.fixed_args->tuple([None if i in dyn_argnums else WrapHashably(arg) for (i, arg) in enumerate(args)])
A:jax.api.dyn_args->tuple((args[i] for i in dyn_argnums))
A:jax.api.name->getattr(fun, '__name__', '<unnamed user primitive>')
A:jax.api.fun_p->core.Primitive(name)
A:jax.api.xla.translations[fun_p]->partial(xla.lower_fun, fun)
A:jax.api.ad.primitive_jvps[fun_p]->partial(jvp, fun)
A:jax.api.arity->len(leaves)
A:jax.api.dims->map(onp.size, leaves)
A:jax.api.basis_array->numpy.stack([onp.concatenate([onp.ones(dims[j]) if i == j else onp.zeros(dims[j]) for j in range(arity)]) for i in range(arity)])
A:jax.api.new_fun->custom_transforms(fun)
A:jax.api.(y, jacs)->vmap(pushfwd, out_axes=(None, 0))(_elementwise_std_basis(tangents))
A:jax.api.(flat_tangents, _)->tree_flatten(tangents)
A:jax.api.out_tangent->sum([t * jac for (t, jac) in zip(flat_tangents, jacs)])
jax._TempAxisName(object)
jax._TempAxisName.__repr__(self)
jax._argnums_partial(f,dyn_argnums,args)
jax._argnums_partial_(dyn_argnums,fixed_args,*dyn_args)
jax._check_args(args)
jax._check_scalar(x)
jax._dtype(x)
jax._elementwise_std_basis(pytree)
jax._split(x,indices,axis)
jax._std_basis(pytree)
jax._unravel_array_into_pytree(pytree,axis,arr)
jax.api._TempAxisName(object)
jax.api._TempAxisName.__repr__(self)
jax.api._argnums_partial(f,dyn_argnums,args)
jax.api._argnums_partial_(dyn_argnums,fixed_args,*dyn_args)
jax.api._check_args(args)
jax.api._check_scalar(x)
jax.api._dtype(x)
jax.api._elementwise_std_basis(pytree)
jax.api._split(x,indices,axis)
jax.api._std_basis(pytree)
jax.api._unravel_array_into_pytree(pytree,axis,arr)
jax.api.custom_transforms(fun)
jax.api.disable_jit()
jax.api.grad(fun,argnums=0,has_aux=False)
jax.api.hessian(fun,argnums=0)
jax.api.jacfwd(fun,argnums=0)
jax.api.jacrev(fun,argnums=0)
jax.api.jarrett(fun)
jax.api.jit(fun,static_argnums=())
jax.api.jvp(fun,primals,tangents)
jax.api.lift_jaxpr(jaxpr,consts,io_tree,pvals,py_args)
jax.api.lift_linearized(jaxpr,consts,io_tree,out_pval,*py_args)
jax.api.linearize(fun,*primals)
jax.api.make_jaxpr(fun)
jax.api.papply(fun,axis_size,in_axes=0,out_axes=0)
jax.api.pmap(fun,axis_name=None)
jax.api.serial_pmap(fun,axis_name=None,in_axes=0,out_axes=0)
jax.api.trace_to_jaxpr(traceable,py_pvals,**kwargs)
jax.api.value_and_grad(fun,argnums=0,has_aux=False)
jax.api.vjp(fun,*primals,**kwargs)
jax.api.vmap(fun,in_axes=0,out_axes=0)
jax.api.xla_computation(fun,static_argnums=())
jax.custom_transforms(fun)
jax.disable_jit()
jax.grad(fun,argnums=0,has_aux=False)
jax.hessian(fun,argnums=0)
jax.jacfwd(fun,argnums=0)
jax.jacrev(fun,argnums=0)
jax.jarrett(fun)
jax.jit(fun,static_argnums=())
jax.jvp(fun,primals,tangents)
jax.lift_jaxpr(jaxpr,consts,io_tree,pvals,py_args)
jax.lift_linearized(jaxpr,consts,io_tree,out_pval,*py_args)
jax.linearize(fun,*primals)
jax.make_jaxpr(fun)
jax.papply(fun,axis_size,in_axes=0,out_axes=0)
jax.pmap(fun,axis_name=None)
jax.serial_pmap(fun,axis_name=None,in_axes=0,out_axes=0)
jax.trace_to_jaxpr(traceable,py_pvals,**kwargs)
jax.value_and_grad(fun,argnums=0,has_aux=False)
jax.vjp(fun,*primals,**kwargs)
jax.vmap(fun,in_axes=0,out_axes=0)
jax.xla_computation(fun,static_argnums=())


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/linear_util.py----------------------------------------
A:jax.linear_util.store->Store()
A:jax.linear_util.(ans, aux)->f(*init_args + rest)
A:jax.linear_util.gen->gen(*gen_args + tuple(args))
A:jax.linear_util.args->next(gen)
A:jax.linear_util.ans->call(f, *args)
A:jax.linear_util.(gen, out_store)->stack.pop()
A:jax.linear_util.transformation_stack->map(transform_to_str, enumerate(self.transforms))
A:jax.linear_util.out_store->Store()
A:jax.linear_util.cache->OrderedDict()
jax.linear_util.Store(object)
jax.linear_util.Store.__nonzero__(self)
jax.linear_util.Store.store(self,val)
jax.linear_util.Store.val(self)
jax.linear_util.StoreException(Exception)
jax.linear_util.WrappedFun(self,f,transforms,kwargs)
jax.linear_util.WrappedFun.__eq__(self,other)
jax.linear_util.WrappedFun.__hash__(self)
jax.linear_util.WrappedFun.__repr__(self)
jax.linear_util.WrappedFun.call_wrapped(self,*args)
jax.linear_util.WrappedFun.hashable_payload(self)
jax.linear_util.WrappedFun.populate_stores(self,other)
jax.linear_util.WrappedFun.wrap(self,*transformation)
jax.linear_util.fun_name(f)
jax.linear_util.memoize(call,max_size=4096)
jax.linear_util.staged(f,*init_args)
jax.linear_util.thunk(f)
jax.linear_util.transformation(gen,fun,*transformation_args)
jax.linear_util.transformation_with_aux(gen,fun,*transformation_args)
jax.linear_util.wrap_init(f,kwargs={})


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/version.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/random.py----------------------------------------
A:jax.random.k1->convert(lax.shift_right_logical(seed, 32))
A:jax.random.k2->convert(lax.bitwise_and(seed, 4294967295))
A:jax.random.nbits->numpy.array(onp.iinfo(dtype).bits, dtype)
A:jax.random.d->lax.convert_element_type(d, x.dtype)
A:jax.random.rotate_left->_make_rotate_left(lax._dtype(count))
A:jax.random.v[1]->rotate_left(v[1], rot)
A:jax.random.x->apply_round(x, r)
A:jax.random.out->np.concatenate(x)
A:jax.random.counts->lax.tie_in(key, lax.iota(onp.uint32, max_count))
A:jax.random.key2->lax.tie_in(key, PRNGKey(data))
A:jax.random.bits->_random_bits(key, nbits, shape)
A:jax.random.dtype->jax.lib.xla_bridge.canonicalize_dtype(dtype)
A:jax.random.minval->lax.convert_element_type(minval, dtype)
A:jax.random.maxval->lax.max(lax.add(minval, onp.array(1, dtype)), maxval)
A:jax.random.finfo->numpy.finfo(dtype)
A:jax.random.float_bits->lax.bitwise_or(lax.shift_right_logical(bits, onp.array(nbits - nmant, lax._dtype(bits))), onp.array(1.0, dtype).view(onp.uint32 if nbits == 32 else onp.uint64))
A:jax.random.(k1, k2)->split(key)
A:jax.random.span->lax.convert_element_type(maxval - minval, unsigned_dtype)
A:jax.random.multiplier->lax.rem(lax.mul(multiplier, multiplier), span)
A:jax.random.random_offset->lax.rem(random_offset, span)
A:jax.random.num_rounds->int(onp.ceil(exponent * onp.log(x.size) / onp.log(uint32max)))
A:jax.random.(key, subkey)->split(key)
A:jax.random.sort_keys->_random_bits(subkey, 32, x.shape)
A:jax.random.(_, x)->lax.sort_key_val(sort_keys, x, axis)
A:jax.random.lo->numpy.nextafter(onp.array(-1.0, dtype), 0.0, dtype=dtype)
A:jax.random.hi->numpy.array(1.0, dtype)
A:jax.random.u->uniform(key, shape, dtype, lo, hi)
A:jax.random.mean->np.broadcast_to(mean, shape)
jax.random.PRNGKey(seed)
jax.random._bit_stats(bits)
jax.random._is_prng_key(key)
jax.random._make_rotate_left(dtype)
jax.random._random_bits(key,bit_width,shape)
jax.random.bernoulli(key,mean=onp.float32(0.5),shape=())
jax.random.fold_in(key,data)
jax.random.normal(key,shape,dtype=onp.float32)
jax.random.randint(key,shape,minval,maxval,dtype=onp.int32)
jax.random.shuffle(key,x,axis=0)
jax.random.split(key,num=2)
jax.random.threefry_2x32(keypair,count)
jax.random.uniform(key,shape,dtype=onp.float32,minval=0.0,maxval=1.0)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/tree_util.py----------------------------------------
A:jax.tree_util.node_type->node_types.get(type(tree))
A:jax.tree_util.(children, node_spec)->node_types.get(type(tree)).to_iterable(tree)
A:jax.tree_util.other_node_type->node_types.get(type(other_tree))
A:jax.tree_util.(other_children, other_node_data)->node_types.get(type(tree)).to_iterable(other_tree)
A:jax.tree_util.(children, node_data)->node_types.get(type(tree)).to_iterable(tree)
A:jax.tree_util.all_children->zip(*all_children)
A:jax.tree_util.(flat, treedef)->tree_flatten(pytree_to_transpose)
A:jax.tree_util.(rest_flat, treedefs)->unzip2(map(tree_flatten, rest))
A:jax.tree_util.td->next((td for td in treedefs if td != treedef))
A:jax.tree_util.out_flat->zip(*map(f, flat, *rest_flat))
A:jax.tree_util.(flat, _)->tree_flatten(tree)
A:jax.tree_util.(proc_children, child_specs)->unzip2([walk_pytree(f_node, f_leaf, child) for child in children])
A:jax.tree_util.tree_def->PyTreeDef(node_type, node_spec, child_specs)
A:jax.tree_util.children->map(partial(_nested_treedef, inner), outer.children)
A:jax.tree_util.tree_flatten->partial(walk_pytree, concatenate, lambda x: [x])
A:jax.tree_util.expected_treedef->_nested_treedef(inner_treedef, outer_treedef)
A:jax.tree_util.inner_size->_num_leaves(inner_treedef)
A:jax.tree_util.outer_size->_num_leaves(outer_treedef)
A:jax.tree_util.flat->iter(flat)
A:jax.tree_util.transposed_lol->zip(*lol)
A:jax.tree_util.subtrees->map(partial(tree_unflatten, outer_treedef), transposed_lol)
A:jax.tree_util.(_, spec)->process_pytree(lambda _: None, tree)
A:jax.tree_util.data_repr->'[{}]'.format(self.node_data)
A:jax.tree_util.leaf->PyLeaf()
A:jax.tree_util.keys->tuple(sorted(xs.keys()))
A:jax.tree_util.node_types[py_type]->NodeType(str(py_type), to_iterable, from_iterable)
jax.tree_util.NodeType(self,name,to_iterable,from_iterable)
jax.tree_util.PyLeaf(object)
jax.tree_util.PyLeaf.__repr__(self)
jax.tree_util.PyTreeDef(self,node_type,node_data,children)
jax.tree_util.PyTreeDef.__eq__(self,other)
jax.tree_util.PyTreeDef.__hash__(self)
jax.tree_util.PyTreeDef.__ne__(self,other)
jax.tree_util.PyTreeDef.__repr__(self)
jax.tree_util._nested_treedef(inner,outer)
jax.tree_util._num_leaves(treedef)
jax.tree_util._tree_unflatten(xs,treedef)
jax.tree_util.build_tree(treedef,xs)
jax.tree_util.dict_to_iterable(xs)
jax.tree_util.prefix_multimap(f,treedef,tree,*rest)
jax.tree_util.process_pytree(process_node,tree)
jax.tree_util.register_pytree_node(py_type,to_iterable,from_iterable)
jax.tree_util.tree_all(tree)
jax.tree_util.tree_map(f,tree)
jax.tree_util.tree_mimomap(f,tree,*rest)
jax.tree_util.tree_multimap(f,tree,*rest)
jax.tree_util.tree_reduce(f,tree)
jax.tree_util.tree_structure(tree)
jax.tree_util.tree_transpose(outer_treedef,inner_treedef,pytree_to_transpose)
jax.tree_util.tree_unflatten(treedef,xs)
jax.tree_util.walk_pytree(f_node,f_leaf,tree)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/lax_linalg.py----------------------------------------
A:jax.lax_linalg.x->jax.interpreters.batching.bdim_at_front(x, bx, size, force_broadcast=True)
A:jax.lax_linalg.(q, r)->Primitive('qr').bind(x, full_matrices=False)
A:jax.lax_linalg.(s, u, v)->Primitive('svd').bind(x, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax.lax_linalg.L->jax.numpy.lax_numpy.tril(cholesky_p.bind(x))
A:jax.lax_linalg.tmp->triangular_solve(a, g_a, left_side, lower, transpose_a, conjugate_a)
A:jax.lax_linalg.L_dot->jax.lax.batch_matmul(L, phi(triangular_solve(L, tmp, left_side=True, transpose_a=False, lower=True)))
A:jax.lax_linalg.cholesky_p->standard_unop(_float | _complex, 'cholesky')
A:jax.lax_linalg.shape->c.GetShape(operand)
A:jax.lax_linalg.(v, w)->Primitive('eigh').bind(symmetrize(a), lower=lower)
A:jax.lax_linalg.v->ShapedArray(batch_dims + (n, n), operand.dtype)
A:jax.lax_linalg.w->w.astype(a.dtype).astype(a.dtype)
A:jax.lax_linalg.out->jaxlib.lapack.jax_gesdd(c, operand, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax.lax_linalg.eye_n->jax.numpy.lax_numpy.eye(a.shape[-1], dtype=a.dtype)
A:jax.lax_linalg.vdag_adot_v->dot(dot(_H(v), a_dot), v)
A:jax.lax_linalg.dv->dot(v, np.multiply(Fmat, vdag_adot_v))
A:jax.lax_linalg.dw->jax.numpy.lax_numpy.diagonal(vdag_adot_v)
A:jax.lax_linalg.eigh_p->Primitive('eigh')
A:jax.lax_linalg.triangular_solve_dtype_rule->partial(binop_dtype_rule, _input_dtype, (_float | _complex, _float | _complex), 'triangular_solve')
A:jax.lax_linalg.g_a->jax.lax.neg(g_a)
A:jax.lax_linalg.cotangent_b->triangular_solve(a, cotangent, left_side, lower, not transpose_a, conjugate_a)
A:jax.lax_linalg.size->next((t.shape[i] for (t, i) in zip(batched_args, batch_dims) if i is not None))
A:jax.lax_linalg.y->jax.interpreters.batching.bdim_at_front(y, by, size, force_broadcast=True)
A:jax.lax_linalg.triangular_solve_p->standard_primitive(triangular_solve_shape_rule, triangular_solve_dtype_rule, 'triangular_solve')
A:jax.lax_linalg.(lu, pivot)->jax.interpreters.xla.apply_primitive(lu_p, operand)
A:jax.lax_linalg.pivot->c.Sub(c.GetTupleElement(out, 1), c.ConstantS32Scalar(1))
A:jax.lax_linalg.(lu, pivots)->Primitive('lu').bind(a)
A:jax.lax_linalg.a_shape->jax.numpy.lax_numpy.shape(a)
A:jax.lax_linalg.dtype->jax.lax._dtype(a)
A:jax.lax_linalg.k->min(m, n)
A:jax.lax_linalg.permutation->jax.numpy.lax_numpy.arange(k)
A:jax.lax_linalg.ndims->len(a_shape)
A:jax.lax_linalg.zero->jax.numpy.lax_numpy._constant_like(lu, 0)
A:jax.lax_linalg.l->jax.lax.pad(np.tril(lu[..., :, :k], -1), zero, l_padding)
A:jax.lax_linalg.u_eye->jax.lax.pad(np.eye(n - k, n - k, dtype=dtype), zero, ((k, 0, 0), (k, 0, 0)))
A:jax.lax_linalg.la->triangular_solve(l, x, left_side=True, transpose_a=False, lower=True)
A:jax.lax_linalg.lau->triangular_solve(u, la, left_side=False, transpose_a=False, lower=False)
A:jax.lax_linalg.l_dot->jax.numpy.lax_numpy.matmul(l, np.tril(lau, -1))
A:jax.lax_linalg.u_dot->jax.numpy.lax_numpy.matmul(np.triu(lau), u)
A:jax.lax_linalg.lu_p->Primitive('lu')
A:jax.lax_linalg.lu->c.GetTupleElement(out, 0)
A:jax.lax_linalg.(n,)->jax.numpy.lax_numpy.shape(swaps)
A:jax.lax_linalg.(_, permutation)->jax.lax.fori_loop(onp.array(0, onp.int32), onp.array(n, onp.int32), body_fn, (swaps, permutation))
A:jax.lax_linalg.q->ShapedArray(batch_dims + (m, k), operand.dtype)
A:jax.lax_linalg.r->ShapedArray(batch_dims + (k, n), operand.dtype)
A:jax.lax_linalg.dx_rinv->triangular_solve(r, dx)
A:jax.lax_linalg.qt_dx_rinv->jax.numpy.lax_numpy.matmul(_T(q), dx_rinv)
A:jax.lax_linalg.qt_dx_rinv_lower->jax.numpy.lax_numpy.tril(qt_dx_rinv, -1)
A:jax.lax_linalg.dr->jax.numpy.lax_numpy.matmul(qt_dx_rinv - domega, r)
A:jax.lax_linalg.qr_p->Primitive('qr')
A:jax.lax_linalg.(s, u, vt)->jax.interpreters.xla.apply_primitive(svd_p, operand, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax.lax_linalg.s->ShapedArray(batch_dims + (min(m, n),), operand.dtype)
A:jax.lax_linalg.u->ShapedArray(batch_dims + (m, m if full_matrices else min(m, n)), operand.dtype)
A:jax.lax_linalg.vt->ShapedArray(batch_dims + (n if full_matrices else min(m, n), n), operand.dtype)
A:jax.lax_linalg.svd_p->Primitive('svd')
jax.lax_linalg._H(x)
jax.lax_linalg._T(x)
jax.lax_linalg.cholesky(x,symmetrize_input=True)
jax.lax_linalg.cholesky_batching_rule(batched_args,batch_dims)
jax.lax_linalg.cholesky_cpu_translation_rule(c,operand)
jax.lax_linalg.cholesky_jvp_rule(primals,tangents)
jax.lax_linalg.eigh(x,lower=True,symmetrize_input=True)
jax.lax_linalg.eigh_abstract_eval(operand,lower)
jax.lax_linalg.eigh_cpu_translation_rule(c,operand,lower)
jax.lax_linalg.eigh_impl(operand,lower)
jax.lax_linalg.eigh_jvp_rule(primals,tangents,lower)
jax.lax_linalg.eigh_translation_rule(c,operand,lower)
jax.lax_linalg.lu(x)
jax.lax_linalg.lu_abstract_eval(operand)
jax.lax_linalg.lu_cpu_translation_rule(c,operand)
jax.lax_linalg.lu_impl(operand)
jax.lax_linalg.lu_jvp_rule(primals,tangents)
jax.lax_linalg.lu_pivots_to_permutation(swaps,k)
jax.lax_linalg.lu_translation_rule(c,operand)
jax.lax_linalg.qr(x,full_matrices=True)
jax.lax_linalg.qr_abstract_eval(operand,full_matrices)
jax.lax_linalg.qr_impl(operand,full_matrices)
jax.lax_linalg.qr_jvp_rule(primals,tangents,full_matrices)
jax.lax_linalg.qr_translation_rule(c,operand,full_matrices)
jax.lax_linalg.svd(x,full_matrices=True,compute_uv=True)
jax.lax_linalg.svd_abstract_eval(operand,full_matrices,compute_uv)
jax.lax_linalg.svd_cpu_translation_rule(c,operand,full_matrices,compute_uv)
jax.lax_linalg.svd_impl(operand,full_matrices,compute_uv)
jax.lax_linalg.svd_translation_rule(c,operand,full_matrices,compute_uv)
jax.lax_linalg.symmetrize(x)
jax.lax_linalg.triangular_solve(a,b,left_side=False,lower=False,transpose_a=False,conjugate_a=False)
jax.lax_linalg.triangular_solve_batching_rule(batched_args,batch_dims,left_side,lower,transpose_a,conjugate_a)
jax.lax_linalg.triangular_solve_cpu_translation_rule(c,a,b,left_side,lower,transpose_a,conjugate_a)
jax.lax_linalg.triangular_solve_jvp_rule_a(g_a,ans,a,b,left_side,lower,transpose_a,conjugate_a)
jax.lax_linalg.triangular_solve_shape_rule(a,b,left_side=False,**unused_kwargs)
jax.lax_linalg.triangular_solve_transpose_rule(cotangent,a,b,left_side,lower,transpose_a,conjugate_a)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/api_util.py----------------------------------------
A:jax.api_util.fun.__name__->namestr.format(fun=get_name(wrapped))
A:jax.api_util.fun.__module__->get_module(wrapped)
A:jax.api_util.fun.__doc__->docstr.format(fun=get_name(wrapped), doc=get_doc(wrapped), **kwargs)
A:jax.api_util.py_args->map(tree_unflatten, in_trees, args)
A:jax.api_util.(args, in_trees)->unzip2(map(pytree_to_jaxtupletree, py_args))
A:jax.api_util.ans->fun(*args)
A:jax.api_util.pytree_to_jaxtupletree->partial(process_pytree, pack)
A:jax.api_util.(flat_ans, out_tree)->tree_flatten(pytree)
jax.api_util.apply_jaxtree_fun(fun,io_tree,*py_args)
jax.api_util.get_doc(fun)
jax.api_util.get_module(fun)
jax.api_util.get_name(fun)
jax.api_util.pytree_fun_to_flatjaxtuple_fun(in_trees,*args)
jax.api_util.pytree_fun_to_jaxtupletree_fun(in_trees,*args)
jax.api_util.pytree_to_flatjaxtuple(pytree)
jax.api_util.wraps(wrapped,fun,namestr='{fun}',docstr='{doc}',**kwargs)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/pprint_util.py----------------------------------------
A:jax.pprint_util.indented_block->rhs.indent(indent + len(s))
A:jax.pprint_util.kv_pairs->vcat([pp('{}='.format(k)) >> pp(v) for (k, v) in kv_pairs])
jax.pprint_util.PrettyPrint(self,lines)
jax.pprint_util.PrettyPrint.__add__(self,rhs)
jax.pprint_util.PrettyPrint.__rshift__(self,rhs)
jax.pprint_util.PrettyPrint.__str__(self)
jax.pprint_util.PrettyPrint.indent(self,indent)
jax.pprint_util.hcat(ps)
jax.pprint_util.pp(s)
jax.pprint_util.pp_kv_pairs(kv_pairs)
jax.pprint_util.print_list(xs)
jax.pprint_util.vcat(ps)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/linalg.py----------------------------------------
A:jax.scipy.linalg.a->numpy.linalg._promote_arg_dtypes(np.asarray(a))
A:jax.scipy.linalg.l->lax_linalg.cholesky(a if lower else np.conj(_T(a)), symmetrize_input=False)
A:jax.scipy.linalg.(c, b)->numpy.linalg._promote_arg_dtypes(np.asarray(c), np.asarray(b))
A:jax.scipy.linalg.c_shape->numpy.lax_numpy.shape(c)
A:jax.scipy.linalg.b_shape->numpy.lax_numpy.shape(b)
A:jax.scipy.linalg.c_ndims->len(c_shape)
A:jax.scipy.linalg.b_ndims->len(b_shape)
A:jax.scipy.linalg.b->lax_linalg.triangular_solve(c, b, left_side=True, lower=lower, transpose_a=lower, conjugate_a=lower)
A:jax.scipy.linalg.(v, w)->lax_linalg.eigh(a, lower=lower)
A:jax.scipy.linalg.(lu, pivots)->lax_linalg.lu(a)
A:jax.scipy.linalg.dtype->lax._dtype(a)
A:jax.scipy.linalg.(m, n)->numpy.lax_numpy.shape(a)
A:jax.scipy.linalg.permutation->lax_linalg.lu_pivots_to_permutation(pivots, m)
A:jax.scipy.linalg.p->numpy.lax_numpy.real(np.array(permutation == np.arange(m)[:, None], dtype=dtype))
A:jax.scipy.linalg.k->min(m, n)
A:jax.scipy.linalg.(q, r)->lax_linalg.qr(a, full_matrices)
A:jax.scipy.linalg.(a, b)->numpy.linalg._promote_arg_dtypes(np.asarray(a), np.asarray(b))
A:jax.scipy.linalg.out->lax_linalg.triangular_solve(a, b, left_side=True, lower=lower, transpose_a=transpose_a, conjugate_a=conjugate_a)
jax.scipy.linalg.cho_factor(a,lower=False,overwrite_a=False,check_finite=True)
jax.scipy.linalg.cho_solve(c_and_lower,b,overwrite_b=False,check_finite=True)
jax.scipy.linalg.cholesky(a,lower=False,overwrite_a=False,check_finite=True)
jax.scipy.linalg.det(a,overwrite_a=False,check_finite=True)
jax.scipy.linalg.eigh(a,b=None,lower=True,eigvals_only=False,overwrite_a=False,overwrite_b=False,turbo=True,eigvals=None,type=1,check_finite=True)
jax.scipy.linalg.inv(a,overwrite_a=False,check_finite=True)
jax.scipy.linalg.lu(a,permute_l=False,overwrite_a=False,check_finite=True)
jax.scipy.linalg.lu_factor(a,overwrite_a=False,check_finite=True)
jax.scipy.linalg.qr(a,overwrite_a=False,lwork=None,mode='full',pivoting=False,check_finite=True)
jax.scipy.linalg.solve(a,b,sym_pos=False,lower=False,overwrite_a=False,overwrite_b=False,debug=False,check_finite=True)
jax.scipy.linalg.solve_triangular(a,b,trans=0,lower=False,unit_diagonal=False,overwrite_b=False,debug=None,check_finite=True)
jax.scipy.linalg.svd(a,full_matrices=True,compute_uv=True,overwrite_a=False,check_finite=True,lapack_driver='gesdd')
jax.scipy.linalg.tril(m,k=0)
jax.scipy.linalg.triu(m,k=0)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/special.py----------------------------------------
A:jax.scipy.special.gammaln->_wraps(osp_special.gammaln)(lambda x: lax.lgamma(x))
A:jax.scipy.special.digamma->_wraps(osp_special.digamma)(lambda x: lax.digamma(x))
A:jax.scipy.special.erf->_wraps(osp_special.erf)(lambda x: lax.erf(x))
A:jax.scipy.special.erfc->_wraps(osp_special.erfc)(lambda x: lax.erfc(x))
A:jax.scipy.special.erfinv->_wraps(osp_special.erfinv)(lambda x: lax.erf_inv(x))
A:jax.scipy.special.x->numpy.lax_numpy.asarray(x)
A:jax.scipy.special.one->lax._const(x, 1)
A:jax.scipy.special.dims->_reduction_dims(a, axis)
A:jax.scipy.special.shape->numpy.lax_numpy.shape(p)
A:jax.scipy.special.amax->lax.reduce(a, _constant_like(a, -onp.inf), lax.max, dims)
A:jax.scipy.special.amax_singletons->dimadd(amax)
A:jax.scipy.special.out->lax.add(lax.log(lax.reduce(lax.exp(lax.sub(a, amax_singletons)), _constant_like(a, 0), lax.add, dims)), amax)
A:jax.scipy.special._LOGNDTR_FLOAT64_LOWER->numpy.array(-20, onp.float64)
A:jax.scipy.special._LOGNDTR_FLOAT32_LOWER->numpy.array(-10, onp.float32)
A:jax.scipy.special._LOGNDTR_FLOAT64_UPPER->numpy.array(8, onp.float64)
A:jax.scipy.special._LOGNDTR_FLOAT32_UPPER->numpy.array(5, onp.float32)
A:jax.scipy.special.dtype->lax._dtype(x)
A:jax.scipy.special.z->lax.sqrt(dtype(-2.0) * lax.log(sanitized_mcp))
A:jax.scipy.special.y->lax.select(lax.lt(z, half_sqrt_2), dtype(1.0) + lax.erf(w), lax.select(lax.gt(w, dtype(0.0)), dtype(2.0) - lax.erfc(z), lax.erfc(z)))
A:jax.scipy.special.p0->list(reversed([-59.96335010141079, 98.00107541859997, -56.67628574690703, 13.931260938727968, -1.2391658386738125]))
A:jax.scipy.special.q0->list(reversed([1.0, 1.9544885833814176, 4.676279128988815, 86.36024213908905, -225.46268785411937, 200.26021238006066, -82.03722561683334, 15.90562251262117, -1.1833162112133]))
A:jax.scipy.special.p1->list(reversed([4.0554489230596245, 31.525109459989388, 57.16281922464213, 44.08050738932008, 14.684956192885803, 2.1866330685079025, -0.1402560791713545, -0.03504246268278482, -0.0008574567851546854]))
A:jax.scipy.special.q1->list(reversed([1.0, 15.779988325646675, 45.39076351288792, 41.3172038254672, 15.04253856929075, 2.504649462083094, -0.14218292285478779, -0.03808064076915783, -0.0009332594808954574]))
A:jax.scipy.special.p2->list(reversed([3.2377489177694603, 6.915228890689842, 3.9388102529247444, 1.3330346081580755, 0.20148538954917908, 0.012371663481782003, 0.00030158155350823543, 2.6580697468673755e-06, 6.239745391849833e-09]))
A:jax.scipy.special.q2->list(reversed([1.0, 6.02427039364742, 3.6798356385616087, 1.3770209948908132, 0.21623699359449663, 0.013420400608854318, 0.00032801446468212774, 2.8924786474538068e-06, 6.790194080099813e-09]))
A:jax.scipy.special.coeffs->numpy.array(coeffs, dtype)
A:jax.scipy.special.maybe_complement_p->numpy.lax_numpy.where(p > dtype(-onp.expm1(-2.0)), dtype(1.0) - p, p)
A:jax.scipy.special.sanitized_mcp->numpy.lax_numpy.where(maybe_complement_p <= dtype(0.0), np.full(shape, dtype(0.5)), maybe_complement_p)
A:jax.scipy.special.ww->lax.square(w)
A:jax.scipy.special.infinity->numpy.lax_numpy.full(shape, dtype(onp.inf))
A:jax.scipy.special.x_nan_replaced->numpy.lax_numpy.where(p <= dtype(0.0), -infinity, np.where(p >= dtype(1.0), infinity, x))
A:jax.scipy.special.x_2->lax.square(x)
A:jax.scipy.special.even_sum->numpy.lax_numpy.zeros_like(x)
A:jax.scipy.special.odd_sum->numpy.lax_numpy.zeros_like(x)
jax.scipy.special._double_factorial(n)
jax.scipy.special._log_ndtr_asymptotic_series(x,series_order)
jax.scipy.special._log_ndtr_lower(x,series_order)
jax.scipy.special._ndtr(x)
jax.scipy.special._ndtri(p)
jax.scipy.special.expit(x)
jax.scipy.special.log_ndtr(x,series_order=3)
jax.scipy.special.logit(x)
jax.scipy.special.logsumexp(a,axis=None,b=None,keepdims=False,return_sign=False)
jax.scipy.special.ndtr(x)
jax.scipy.special.ndtri(p)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/misc.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/expon.py----------------------------------------
A:jax.scipy.stats.expon.(x, loc, scale)->_promote_args_like(osp_stats.expon.logpdf, x, loc, scale)
A:jax.scipy.stats.expon.log_scale->lax.log(scale)
A:jax.scipy.stats.expon.linear_term->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.expon.log_probs->lax.neg(lax.add(linear_term, log_scale))
jax.scipy.stats.expon.logpdf(x,loc=0,scale=1)
jax.scipy.stats.expon.pdf(x,loc=0,scale=1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/laplace.py----------------------------------------
A:jax.scipy.stats.laplace.(x, loc, scale)->_promote_args_like(osp_stats.laplace.logpdf, x, loc, scale)
A:jax.scipy.stats.laplace.two->_constant_like(x, 2)
A:jax.scipy.stats.laplace.linear_term->lax.div(lax.abs(lax.sub(x, loc)), scale)
jax.scipy.stats.laplace.logpdf(x,loc=0,scale=1)
jax.scipy.stats.laplace.pdf(x,loc=0,scale=1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/multivariate_normal.py----------------------------------------
A:jax.scipy.stats.multivariate_normal.x->x.astype(cov.dtype).astype(cov.dtype)
A:jax.scipy.stats.multivariate_normal.mean->mean.astype(cov.dtype).astype(cov.dtype)
A:jax.scipy.stats.multivariate_normal.two->_constant_like(x, 2)
A:jax.scipy.stats.multivariate_normal.dim->_constant_like(x, mean.shape[0])
A:jax.scipy.stats.multivariate_normal.det_sig->det(cov).astype(cov.dtype)
A:jax.scipy.stats.multivariate_normal.log_normalizer->lax.log(lax.mul(lax.pow(_constant_like(x, 2 * onp.pi), dim), det_sig))
A:jax.scipy.stats.multivariate_normal.x_2d->x.astype(cov.dtype).astype(cov.dtype).reshape((-1, mean.shape[0]))
A:jax.scipy.stats.multivariate_normal.quadratic->dot(dot(subtract(x, mean), inv(cov)), subtract(x, mean).T).astype(cov.dtype)
jax.scipy.stats.multivariate_normal.logpdf(x,mean,cov)
jax.scipy.stats.multivariate_normal.pdf(x,mean,cov)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/gamma.py----------------------------------------
A:jax.scipy.stats.gamma.(x, a, loc, scale)->_promote_args_like(osp_stats.gamma.logpdf, x, a, loc, scale)
A:jax.scipy.stats.gamma.one->_constant_like(x, 1)
A:jax.scipy.stats.gamma.y->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.gamma.log_linear_term->lax.sub(lax.mul(lax.sub(a, one), lax.log(y)), y)
A:jax.scipy.stats.gamma.shape_terms->lax.add(gammaln(a), lax.log(scale))
A:jax.scipy.stats.gamma.log_probs->lax.sub(log_linear_term, shape_terms)
jax.scipy.stats.gamma.logpdf(x,a,loc=0,scale=1)
jax.scipy.stats.gamma.pdf(x,a,loc=0,scale=1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/uniform.py----------------------------------------
A:jax.scipy.stats.uniform.(x, loc, scale)->_promote_args_like(osp_stats.uniform.logpdf, x, loc, scale)
A:jax.scipy.stats.uniform.log_probs->lax.neg(lax.log(scale))
jax.scipy.stats.uniform.logpdf(x,loc=0,scale=1)
jax.scipy.stats.uniform.pdf(x,loc=0,scale=1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/beta.py----------------------------------------
A:jax.scipy.stats.beta.(x, a, b, loc, scale)->_promote_args_like(osp_stats.beta.logpdf, x, a, b, loc, scale)
A:jax.scipy.stats.beta.one->_constant_like(x, 1)
A:jax.scipy.stats.beta.shape_term_tmp->lax.add(gammaln(a), gammaln(b))
A:jax.scipy.stats.beta.shape_term->lax.sub(gammaln(lax.add(a, b)), shape_term_tmp)
A:jax.scipy.stats.beta.y->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.beta.log_linear_term->lax.add(lax.mul(lax.sub(a, one), lax.log(y)), lax.mul(lax.sub(b, one), lax.log(lax.sub(one, y))))
A:jax.scipy.stats.beta.log_probs->lax.sub(lax.add(shape_term, log_linear_term), lax.log(scale))
jax.scipy.stats.beta.logpdf(x,a,b,loc=0,scale=1)
jax.scipy.stats.beta.pdf(x,a,b,loc=0,scale=1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/scipy/stats/norm.py----------------------------------------
A:jax.scipy.stats.norm.(x, loc, scale)->_promote_args_like(osp_stats.norm.logcdf, x, loc, scale)
A:jax.scipy.stats.norm.two->_constant_like(x, 2)
A:jax.scipy.stats.norm.scale_sqrd->lax.pow(scale, two)
A:jax.scipy.stats.norm.log_normalizer->lax.log(lax.mul(_constant_like(x, 2 * onp.pi), scale_sqrd))
A:jax.scipy.stats.norm.quadratic->lax.div(lax.pow(lax.sub(x, loc), two), scale_sqrd)
jax.scipy.stats.norm.cdf(x,loc=0,scale=1)
jax.scipy.stats.norm.logcdf(x,loc=0,scale=1)
jax.scipy.stats.norm.logpdf(x,loc=0,scale=1)
jax.scipy.stats.norm.pdf(x,loc=0,scale=1)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/lib/xla_bridge.py----------------------------------------
A:jax.lib.xla_bridge.version->tuple((int(x) for x in jaxlib.__version__.split('.')))
A:jax.lib.xla_bridge.valself[key]->func(key)
A:jax.lib.xla_bridge.backend->_backends.get(FLAGS.jax_xla_backend)
A:jax.lib.xla_bridge._->get_xla_client()
A:jax.lib.xla_bridge.client->get_xla_client()
A:jax.lib.xla_bridge.dtype->numpy.dtype(dtype)
A:jax.lib.xla_bridge.pyval->normalize_to_xla_dtypes(pyval)
A:jax.lib.xla_bridge.value->normalize_to_xla_dtypes(value)
A:jax.lib.xla_bridge.example_value->numpy.asarray(example_value)
A:jax.lib.xla_bridge.py_type->type(py_val)
A:jax.lib.xla_bridge.(zero_stride_axes,)->numpy.where(onp.equal(0, val.strides))
A:jax.lib.xla_bridge.(other_axes,)->numpy.where(onp.not_equal(0, val.strides))
A:jax.lib.xla_bridge.xla_val->c.Broadcast(c.NumpyArrayConstant(collapsed_val, canonicalize_types), onp.take(val.shape, zero_stride_axes))
A:jax.lib.xla_bridge.permutation->numpy.argsort(tuple(zero_stride_axes) + tuple(other_axes))
jax.lib.xla_bridge._JaxComputationBuilderBase(object)
jax.lib.xla_bridge._JaxComputationBuilderBase.AllToAll(self,operand,split_dimension,concat_dimension,replica_groups)
jax.lib.xla_bridge._JaxComputationBuilderBase.Build(self,*args,**kwargs)
jax.lib.xla_bridge._JaxComputationBuilderBase.Constant(self,py_val,canonicalize_types=True)
jax.lib.xla_bridge._JaxComputationBuilderBase.ConstantLike(self,example_value,value,canonicalize_types=True)
jax.lib.xla_bridge._JaxComputationBuilderBase.NumpyArrayConstant(self,value,canonicalize_types=True)
jax.lib.xla_bridge._JaxComputationBuilderBase.Parameter(self,value,name=None,parameter_num=None)
jax.lib.xla_bridge._check_jaxlib_version()
jax.lib.xla_bridge._get_backend()
jax.lib.xla_bridge._get_xla_client(backend_name,platform_name)
jax.lib.xla_bridge._ndarray_constant_handler(c,val,canonicalize_types=True)
jax.lib.xla_bridge._scalar_constant_handler(c,val,canonicalize_types=True)
jax.lib.xla_bridge.canonicalize_dtype(dtype)
jax.lib.xla_bridge.canonicalize_shape(shape)
jax.lib.xla_bridge.device_count()
jax.lib.xla_bridge.device_put(pyval,device_num=0)
jax.lib.xla_bridge.dtype_to_etype(dtype)
jax.lib.xla_bridge.dtype_to_etype_exact(dtype)
jax.lib.xla_bridge.get_compile_options(num_replicas=None)
jax.lib.xla_bridge.get_jax_computation_builder_class()
jax.lib.xla_bridge.get_xla_client()
jax.lib.xla_bridge.infeed_put(replica_id,pyval)
jax.lib.xla_bridge.make_computation_builder(name)
jax.lib.xla_bridge.memoize(func)
jax.lib.xla_bridge.memoize_thunk(func)
jax.lib.xla_bridge.normalize_to_xla_dtypes(val)
jax.lib.xla_bridge.register_backend(name,factory)
jax.lib.xla_bridge.register_constant_handler(type_,handler_fun)
jax.lib.xla_bridge.shape_of(value)
jax.lib.xla_bridge.supported_numpy_dtypes()


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/lib/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/experimental/lapax.py----------------------------------------
A:jax.experimental.lapax.out->jax.lax.rev(out, *onp.where([row_rev, col_rev]))
A:jax.experimental.lapax.out[i, i]->_cholesky(a[i, i])
A:jax.experimental.lapax.out[i:, i]->solve(out[i, i], a[i:, i])
A:jax.experimental.lapax.out[i, :]->solve(a[i, i], b[i, :])
A:jax.experimental.lapax.out[:, i]->solve(a[i, i], b[:, i])
A:jax.experimental.lapax.out[:, i:]->solve(a[i, i], b[:, i])
A:jax.experimental.lapax.dims->tuple(range(ndarray.ndim))
A:jax.experimental.lapax.self.shape->tuple(onp.floor_divide(ndarray.shape, block_size) + (onp.mod(ndarray.shape, block_size) > 0))
A:jax.experimental.lapax.self.ndarray->_matrix_put(self.ndarray, idx, val.ndarray, self.bs)
A:jax.experimental.lapax.__add__->_make_infix_op(lax.add)
A:jax.experimental.lapax.__sub__->_make_infix_op(lax.sub)
A:jax.experimental.lapax.__mul__->_make_infix_op(lax.batch_matmul)
A:jax.experimental.lapax.__div__->_make_infix_op(lax.div)
A:jax.experimental.lapax.__truediv__->_make_infix_op(lax.div)
A:jax.experimental.lapax.T->property(_make_infix_op(_matrix_transpose))
A:jax.experimental.lapax.idx_elt->slice(idx_elt, idx_elt + 1, 1)
A:jax.experimental.lapax.indices->tuple(onp.arange(block_dim)[idx_elt])
A:jax.experimental.lapax.end->min(k * (start - step), shape[axis])
A:jax.experimental.lapax.(sli, row_rev)->_canonical_idx(ndarray.shape, idx_i, -2, block_size)
A:jax.experimental.lapax.(slj, col_rev)->_canonical_idx(ndarray.shape, idx_j, -1, block_size)
A:jax.experimental.lapax.val->jax.lax.rev(val, *onp.where([row_rev, col_rev]))
jax.experimental.lapax.LapaxMatrix(self,ndarray,block_size=1)
jax.experimental.lapax.LapaxMatrix.__getitem__(self,idx)
jax.experimental.lapax.LapaxMatrix.__setitem__(self,idx,val)
jax.experimental.lapax.LapaxMatrix.bview(self,block_size)
jax.experimental.lapax._canonical_idx(shape,idx_elt,axis,block_size=1)
jax.experimental.lapax._cholesky(a)
jax.experimental.lapax._make_infix_op(fun)
jax.experimental.lapax._matrix_put(ndarray,idx,val,block_size=1)
jax.experimental.lapax._matrix_take(ndarray,idx,block_size=1)
jax.experimental.lapax._matrix_transpose(ndarray)
jax.experimental.lapax._solve_triangular_left(a,b,left_side,lower,trans_a)
jax.experimental.lapax._solve_triangular_right(a,b,left_side,lower,trans_a)
jax.experimental.lapax.cholesky(a,block_size=1)
jax.experimental.lapax.full_like(x,val)
jax.experimental.lapax.solve_triangular(a,b,left_side,lower,trans_a,block_size=1)
jax.experimental.lapax.sqrt(x)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/experimental/stax.py----------------------------------------
A:jax.experimental.stax.unnormalized->jax.numpy.exp(x - x.max(axis, keepdims=True))
A:jax.experimental.stax.size->numpy.prod(onp.delete(shape, [in_dim, out_dim]))
A:jax.experimental.stax.zeros->functools.partial(np.zeros, dtype='float32')
A:jax.experimental.stax.ones->functools.partial(np.ones, dtype='float32')
A:jax.experimental.stax.filter_shape_iter->iter(filter_shape)
A:jax.experimental.stax.output_shape->jax.lax.conv_general_shape_tuple(input_shape, kernel_shape, strides, padding, dimension_numbers)
A:jax.experimental.stax.bias_shape->tuple(itertools.dropwhile(lambda x: x == 1, bias_shape))
A:jax.experimental.stax.Conv->functools.partial(GeneralConv, ('NHWC', 'HWIO', 'NHWC'))
A:jax.experimental.stax.shape->tuple((d for (i, d) in enumerate(input_shape) if i not in axis))
A:jax.experimental.stax.ed->tuple((None if i in axis else slice(None) for i in range(np.ndim(x))))
A:jax.experimental.stax.Tanh->_elemwise_no_params(np.tanh)
A:jax.experimental.stax.Relu->_elemwise_no_params(relu)
A:jax.experimental.stax.Exp->_elemwise_no_params(np.exp)
A:jax.experimental.stax.LogSoftmax->_elemwise_no_params(logsoftmax, axis=-1)
A:jax.experimental.stax.Softmax->_elemwise_no_params(softmax, axis=-1)
A:jax.experimental.stax.Softplus->_elemwise_no_params(softplus)
A:jax.experimental.stax.out_shape->jax.lax.reduce_window_shape_tuple(input_shape, dims, strides, padding)
A:jax.experimental.stax.out->jax.lax.reduce_window(inputs, init_val, reducer, dims, strides, padding)
A:jax.experimental.stax.MaxPool->_pooling_layer(lax.max, -np.inf)
A:jax.experimental.stax.SumPool->_pooling_layer(lax.add, 0.0)
A:jax.experimental.stax.one->jax.numpy.ones(inputs.shape[1:-1], dtype=inputs.dtype)
A:jax.experimental.stax.window_sizes->jax.lax.reduce_window(one, 0.0, lax.add, dims, strides, padding)
A:jax.experimental.stax.AvgPool->_pooling_layer(lax.add, 0.0, _normalize_by_window_size)
A:jax.experimental.stax.Flatten->Flatten()
A:jax.experimental.stax.Identity->Identity()
A:jax.experimental.stax.FanInSum->FanInSum()
A:jax.experimental.stax.concat_size->sum((shape[ax] for shape in input_shape))
A:jax.experimental.stax.rng->kwargs.pop('rng', None)
A:jax.experimental.stax.keep->jax.random.bernoulli(rng, rate, inputs.shape)
A:jax.experimental.stax.nlayers->len(layers)
A:jax.experimental.stax.(init_funs, apply_funs)->zip(*layers)
A:jax.experimental.stax.(input_shape, param)->init_fun(input_shape)
A:jax.experimental.stax.inputs->fun(param, inputs, rng=rng, **kwargs)
jax.experimental.stax.BatchNorm(axis=(0,1,2),epsilon=1e-05,center=True,scale=True,beta_init=zeros,gamma_init=ones)
jax.experimental.stax.Dense(out_dim,W_init=glorot(),b_init=randn())
jax.experimental.stax.Dropout(rate,mode='train')
jax.experimental.stax.FanInConcat(axis=-1)
jax.experimental.stax.FanInSum()
jax.experimental.stax.FanOut(num)
jax.experimental.stax.Flatten()
jax.experimental.stax.GeneralConv(dimension_numbers,out_chan,filter_shape,strides=None,padding='VALID',W_init=None,b_init=randn(1e-06))
jax.experimental.stax.Identity()
jax.experimental.stax._elemwise_no_params(fun,**fun_kwargs)
jax.experimental.stax._normalize_by_window_size(dims,strides,padding)
jax.experimental.stax._pooling_layer(reducer,init_val,rescaler=None)
jax.experimental.stax.fastvar(x,axis,keepdims)
jax.experimental.stax.glorot(out_dim=0,in_dim=1,scale=onp.sqrt(2),rng=npr)
jax.experimental.stax.logsoftmax(x,axis=-1)
jax.experimental.stax.parallel(*layers)
jax.experimental.stax.randn(stddev=0.01,rng=npr)
jax.experimental.stax.relu(x)
jax.experimental.stax.serial(*layers)
jax.experimental.stax.shape_dependent(make_layer)
jax.experimental.stax.softmax(x,axis=-1)
jax.experimental.stax.softplus(x)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/experimental/optimizers.py----------------------------------------
A:jax.experimental.optimizers.(init_fun, update_fun)->opt_maker(*args, **kwargs)
A:jax.experimental.optimizers.step_size->make_schedule(step_size)
A:jax.experimental.optimizers.v0->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.avg_sq_grad->jax.numpy.ones_like(x0)
A:jax.experimental.optimizers.m0->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.boundaries->jax.numpy.array(boundaries)
A:jax.experimental.optimizers.values->jax.numpy.array(values)
jax.experimental.optimizers.adam(step_size,b1=0.9,b2=0.999,eps=1e-08)
jax.experimental.optimizers.constant(step_size)
jax.experimental.optimizers.exponential_decay(step_size,decay_steps,decay_rate)
jax.experimental.optimizers.inverse_time_decay(step_size,decay_steps,decay_rate,staircase=False)
jax.experimental.optimizers.iterate(state_trees)
jax.experimental.optimizers.make_schedule(scalar_or_schedule_fun)
jax.experimental.optimizers.momentum(step_size,mass)
jax.experimental.optimizers.optimizer(opt_maker)
jax.experimental.optimizers.piecewise_constant(boundaries,values)
jax.experimental.optimizers.rmsprop(step_size,gamma=0.9,eps=1e-08)
jax.experimental.optimizers.sgd(step_size)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/experimental/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/numpy/linalg.py----------------------------------------
A:jax.numpy.linalg.dtype->lax._dtype(a)
A:jax.numpy.linalg.a->_promote_arg_dtypes(np.asarray(a))
A:jax.numpy.linalg.a_shape->np.shape(a)
A:jax.numpy.linalg.(lu, pivot)->lax_linalg.lu(a)
A:jax.numpy.linalg.diag->np.diagonal(lu, axis1=-2, axis2=-1)
A:jax.numpy.linalg.is_zero->np.any(diag == np.array(0, dtype=dtype), axis=-1)
A:jax.numpy.linalg.parity->np.count_nonzero(pivot != np.arange(a_shape[-1]), axis=-1)
A:jax.numpy.linalg.sign->np.where(is_zero, np.array(0, dtype=dtype), sign * np.array(-2 * (parity % 2) + 1, dtype=dtype))
A:jax.numpy.linalg.logdet->np.where(is_zero, np.array(-np.inf, dtype=dtype), np.sum(np.log(np.abs(diag)), axis=-1))
A:jax.numpy.linalg.(sign, logdet)->slogdet(a)
A:jax.numpy.linalg.msg->"UPLO must be one of None, 'L', or 'U', got {}".format(UPLO)
A:jax.numpy.linalg.(v, w)->lax_linalg.eigh(a, lower=lower, symmetrize_input=symmetrize_input)
A:jax.numpy.linalg.(q, r)->lax_linalg.qr(a, full_matrices)
A:jax.numpy.linalg.x->lax_linalg.triangular_solve(lu, x, left_side=True, lower=False)
A:jax.numpy.linalg.x_shape->np.shape(x)
A:jax.numpy.linalg.ndim->len(x_shape)
A:jax.numpy.linalg.axis->tuple((np._canonicalize_axis(x, ndim) for x in axis))
A:jax.numpy.linalg.num_axes->len(axis)
A:jax.numpy.linalg.y->np.reshape(y, result_shape)
A:jax.numpy.linalg.result_shape->list(x_shape)
A:jax.numpy.linalg.(a, b)->_promote_arg_dtypes(np.asarray(a), np.asarray(b))
A:jax.numpy.linalg.b_shape->np.shape(b)
A:jax.numpy.linalg.a_ndims->len(a_shape)
A:jax.numpy.linalg.b_ndims->len(b_shape)
A:jax.numpy.linalg.(lu, pivots)->lax_linalg.lu(a)
A:jax.numpy.linalg.permutation->lax_linalg.lu_pivots_to_permutation(pivots, m)
A:jax.numpy.linalg.globals()[func.__name__]->_not_implemented(func)
jax.numpy.linalg._promote_arg_dtypes(*args)
jax.numpy.linalg.cholesky(a)
jax.numpy.linalg.det(a)
jax.numpy.linalg.eigh(a,UPLO=None,symmetrize_input=True)
jax.numpy.linalg.inv(a)
jax.numpy.linalg.norm(x,ord=None,axis=None,keepdims=False)
jax.numpy.linalg.qr(a,mode='reduced')
jax.numpy.linalg.slogdet(a)
jax.numpy.linalg.solve(a,b)
jax.numpy.linalg.svd(a,full_matrices=True,compute_uv=True)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/numpy/lax_numpy.py----------------------------------------
A:jax.numpy.lax_numpy.nd->len(lax.broadcast_shapes(*shapes))
A:jax.numpy.lax_numpy.to_dtype->_result_dtype(op, *args)
A:jax.numpy.lax_numpy.(pos, arg)->next(((i, arg) for (i, arg) in enumerate(args) if not_array(arg)))
A:jax.numpy.lax_numpy._numpy_signature_re->lax.convert_element_type(re, dtype).compile('^([\\w., ]+=)?\\s*[\\w\\.]+\\(.*\\)$')
A:jax.numpy.lax_numpy.sections->fun.__doc__.split('\n\n')
A:jax.numpy.lax_numpy.summary->sections[i].strip()
A:jax.numpy.lax_numpy.body->'\n\n'.join(signatures + sections[i + 1:])
A:jax.numpy.lax_numpy.docstr->'{summary}\n\nLAX-backend implementation of :func:`{fun}`. Original docstring below.\n\n{body}'.format(summary=summary, fun=fun.__name__, body=body)
A:jax.numpy.lax_numpy.absoluteabs->_one_to_one_unop(onp.absolute, lax.abs)
A:jax.numpy.lax_numpy.fabs->_one_to_one_unop(onp.fabs, lax.abs, True)
A:jax.numpy.lax_numpy.bitwise_not->_one_to_one_unop(onp.bitwise_not, lax.bitwise_not)
A:jax.numpy.lax_numpy.negative->_one_to_one_unop(onp.negative, lax.neg)
A:jax.numpy.lax_numpy.positive->_one_to_one_unop(onp.positive, lambda x: x)
A:jax.numpy.lax_numpy.sign->_one_to_one_unop(onp.sign, lax.sign)
A:jax.numpy.lax_numpy.floor->_one_to_one_unop(onp.floor, lax.floor, True)
A:jax.numpy.lax_numpy.ceil->_one_to_one_unop(onp.ceil, lax.ceil, True)
A:jax.numpy.lax_numpy.exp->_one_to_one_unop(onp.exp, lax.exp, True)
A:jax.numpy.lax_numpy.log->_one_to_one_unop(onp.log, lax.log, True)
A:jax.numpy.lax_numpy.expm1->_one_to_one_unop(onp.expm1, lax.expm1, True)
A:jax.numpy.lax_numpy.log1p->_one_to_one_unop(onp.log1p, lax.log1p, True)
A:jax.numpy.lax_numpy.sin->_one_to_one_unop(onp.sin, lax.sin, True)
A:jax.numpy.lax_numpy.cos->_one_to_one_unop(onp.cos, lax.cos, True)
A:jax.numpy.lax_numpy.tan->_one_to_one_unop(onp.tan, lax.tan, True)
A:jax.numpy.lax_numpy.arcsin->_one_to_one_unop(onp.arcsin, lax.asin, True)
A:jax.numpy.lax_numpy.arccos->_one_to_one_unop(onp.arccos, lax.acos, True)
A:jax.numpy.lax_numpy.arctan->_one_to_one_unop(onp.arctan, lax.atan, True)
A:jax.numpy.lax_numpy.sinh->_one_to_one_unop(onp.sinh, lax.sinh, True)
A:jax.numpy.lax_numpy.cosh->_one_to_one_unop(onp.cosh, lax.cosh, True)
A:jax.numpy.lax_numpy.tanh->_one_to_one_unop(onp.tanh, lax.tanh, True)
A:jax.numpy.lax_numpy.arcsinh->_one_to_one_unop(onp.arcsinh, lax.asinh, True)
A:jax.numpy.lax_numpy.arccosh->_one_to_one_unop(onp.arccosh, lax.acosh, True)
A:jax.numpy.lax_numpy.arctanh->_one_to_one_unop(onp.arctanh, lax.atanh, True)
A:jax.numpy.lax_numpy.add->_one_to_one_binop(onp.add, lax.add)
A:jax.numpy.lax_numpy.bitwise_and->_one_to_one_binop(onp.bitwise_and, lax.bitwise_and)
A:jax.numpy.lax_numpy.bitwise_or->_one_to_one_binop(onp.bitwise_or, lax.bitwise_or)
A:jax.numpy.lax_numpy.bitwise_xor->_one_to_one_binop(onp.bitwise_xor, lax.bitwise_xor)
A:jax.numpy.lax_numpy.right_shift->_one_to_one_binop(onp.right_shift, lax.shift_right_arithmetic)
A:jax.numpy.lax_numpy.left_shift->_one_to_one_binop(onp.left_shift, lax.shift_left)
A:jax.numpy.lax_numpy.equal->_one_to_one_binop(onp.equal, lax.eq)
A:jax.numpy.lax_numpy.multiply->_one_to_one_binop(onp.multiply, lax.mul)
A:jax.numpy.lax_numpy.not_equal->_one_to_one_binop(onp.not_equal, lax.ne)
A:jax.numpy.lax_numpy.subtract->_one_to_one_binop(onp.subtract, lax.sub)
A:jax.numpy.lax_numpy.arctan2->_one_to_one_binop(onp.arctan2, lax.atan2, True)
A:jax.numpy.lax_numpy.minimum->_one_to_one_binop(onp.minimum, lax.min)
A:jax.numpy.lax_numpy.maximum->_one_to_one_binop(onp.maximum, lax.max)
A:jax.numpy.lax_numpy.float_power->_one_to_one_binop(onp.float_power, lax.pow, True)
A:jax.numpy.lax_numpy.(x, y)->_promote_to_result_dtype(onp.hypot, x, y)
A:jax.numpy.lax_numpy.rx->lax.real(x)
A:jax.numpy.lax_numpy.ry->lax.real(y)
A:jax.numpy.lax_numpy.greater_equal->_comparison_op(onp.greater_equal, lax.ge)
A:jax.numpy.lax_numpy.greater->_comparison_op(onp.greater, lax.gt)
A:jax.numpy.lax_numpy.less_equal->_comparison_op(onp.less_equal, lax.le)
A:jax.numpy.lax_numpy.less->_comparison_op(onp.less, lax.lt)
A:jax.numpy.lax_numpy.logical_and->_logical_op(onp.logical_and, lax.bitwise_and)
A:jax.numpy.lax_numpy.logical_not->_logical_op(onp.logical_not, lax.bitwise_not)
A:jax.numpy.lax_numpy.logical_or->_logical_op(onp.logical_or, lax.bitwise_or)
A:jax.numpy.lax_numpy.logical_xor->_logical_op(onp.logical_xor, lax.bitwise_xor)
A:jax.numpy.lax_numpy.result_dtype->_dtype(np_fun(onp.ones((), dtype=dtype or _dtype(a))))
A:jax.numpy.lax_numpy.(x1, x2)->broadcast_arrays(x1, x2)
A:jax.numpy.lax_numpy.dtype->_dtype(x)
A:jax.numpy.lax_numpy.quotient->lax.div(x1, x2)
A:jax.numpy.lax_numpy.select->logical_and(lax.sign(x1) != lax.sign(x2), lax.rem(x1, x2) != 0)
A:jax.numpy.lax_numpy.x1r->lax.real(x1)
A:jax.numpy.lax_numpy.x1i->lax.imag(x1)
A:jax.numpy.lax_numpy.x2r->lax.real(x2)
A:jax.numpy.lax_numpy.x2i->lax.imag(x2)
A:jax.numpy.lax_numpy.which->lax.ge(lax.abs(x2r), lax.abs(x2i))
A:jax.numpy.lax_numpy.rat1->where(which, lax._const(x2i, 1), lax.div(x2r, x2i))
A:jax.numpy.lax_numpy.rat2->where(which, lax.div(x2i, x2r), lax._const(x2i, 1))
A:jax.numpy.lax_numpy.out->moveaxis(out, list(range(naxes)), list(range(start, start + naxes)))
A:jax.numpy.lax_numpy.mod->lax.select(ind, mod + x1, mod)
A:jax.numpy.lax_numpy.div->lax.select(ind, div - _constant_like(div, 1), div)
A:jax.numpy.lax_numpy.ind->lax.bitwise_and(mod != 0, lax.sign(x2) != lax.sign(mod))
A:jax.numpy.lax_numpy.x1->lax.mul(x1, x1)
A:jax.numpy.lax_numpy.x2->lax.shift_right_logical(x2, _constant_like(x2, 1))
A:jax.numpy.lax_numpy.acc->where(lax.bitwise_and(x2, _constant_like(x2, 1)), lax.mul(acc, x1), acc)
A:jax.numpy.lax_numpy.amax->lax.max(x1, x2)
A:jax.numpy.lax_numpy.(x,)->_promote_to_result_dtype(onp.sinc, x)
A:jax.numpy.lax_numpy.fmod->_wraps(onp.fmod)(lambda x, y: lax.rem(x, y))
A:jax.numpy.lax_numpy.zero->lax._const(x, 0)
A:jax.numpy.lax_numpy.pi_x->lax.mul(lax._const(x, pi), x)
A:jax.numpy.lax_numpy.perm->tuple([names.index(name) for name in result_names])
A:jax.numpy.lax_numpy.rank->len(m.shape)
A:jax.numpy.lax_numpy.i->_canonicalize_axis(i, a_ndim)
A:jax.numpy.lax_numpy.re->lax.convert_element_type(re, dtype)
A:jax.numpy.lax_numpy.im->lax.convert_element_type(im, dtype)
A:jax.numpy.lax_numpy.dummy_val->numpy.broadcast_to(0, ary.shape)
A:jax.numpy.lax_numpy.axis->_canonicalize_axis(axis, ndim(a))
A:jax.numpy.lax_numpy.shape->_shape(a)
A:jax.numpy.lax_numpy.source->numpy.mod(source, ndim(a)).reshape(-1)
A:jax.numpy.lax_numpy.destination->numpy.mod(destination, ndim(a)).reshape(-1)
A:jax.numpy.lax_numpy.(a, b)->_promote_dtypes(a, b)
A:jax.numpy.lax_numpy.rtol->lax.convert_element_type(rtol, dtype)
A:jax.numpy.lax_numpy.atol->lax.convert_element_type(atol, dtype)
A:jax.numpy.lax_numpy.numpy_version->tuple(map(int, onp.version.version.split('.')))
A:jax.numpy.lax_numpy.condition->lax.ne(condition, zeros_like(condition))
A:jax.numpy.lax_numpy.(condition, x, y)->broadcast_arrays(condition, x, y)
A:jax.numpy.lax_numpy.(empty, _)->_promote_dtypes(x, y)
A:jax.numpy.lax_numpy.result_shape->tuple((1 if elt is None else next(unexpanded_shape_itr) for elt in canonical_idx if isinstance(elt, (type(None), slice))))
A:jax.numpy.lax_numpy.(diff,)->numpy.where(onp.not_equal(shape[nlead:], _shape(arr)))
A:jax.numpy.lax_numpy.kept_dims->tuple(onp.delete(onp.arange(len(shape)), new_dims))
A:jax.numpy.lax_numpy.broadcast_dims->numpy.concatenate((onp.arange(0, axis + 1), onp.arange(axis + 2, num_dims + 1)))
A:jax.numpy.lax_numpy.squeezed_array->squeeze(arr, diff)
A:jax.numpy.lax_numpy.subarrays->numpy.split(dummy_val, indices_or_sections, axis)
A:jax.numpy.lax_numpy.split_indices->numpy.cumsum([0] + [onp.shape(sub)[axis] for sub in subarrays])
A:jax.numpy.lax_numpy.vsplit->_split_on_axis(onp.vsplit, axis=0)
A:jax.numpy.lax_numpy.hsplit->_split_on_axis(onp.hsplit, axis=1)
A:jax.numpy.lax_numpy.dsplit->_split_on_axis(onp.dsplit, axis=2)
A:jax.numpy.lax_numpy.a_min->lax.convert_element_type(a_min, _dtype(a))
A:jax.numpy.lax_numpy.a->ravel(a)
A:jax.numpy.lax_numpy.a_max->lax.convert_element_type(a_max, _dtype(a))
A:jax.numpy.lax_numpy.factor->_constant_like(x, 10 ** decimals)
A:jax.numpy.lax_numpy.isposinf->_wraps(onp.isposinf)(partial(_isposneginf, inf))
A:jax.numpy.lax_numpy.isneginf->_wraps(onp.isneginf)(partial(_isposneginf, -inf))
A:jax.numpy.lax_numpy.info->finfo(xla_bridge.canonicalize_dtype(_dtype(x)))
A:jax.numpy.lax_numpy.x->asarray(x)
A:jax.numpy.lax_numpy.dims->_reduction_dims(a, axis)
A:jax.numpy.lax_numpy.result->_rewriting_take(result, elt, axis=axis)
A:jax.numpy.lax_numpy.shape_with_singletons->lax.subvals(shape(a), zip(dims, (1,) * len(dims)))
A:jax.numpy.lax_numpy.a_dtype->lib.xla_bridge.canonicalize_dtype(_dtype(a))
A:jax.numpy.lax_numpy._cast_to_bool->partial(lax.convert_element_type, new_dtype=onp.bool_)
A:jax.numpy.lax_numpy.sum->_make_reduction(onp.sum, lax.add, 0)
A:jax.numpy.lax_numpy.productprod->_make_reduction(onp.prod, lax.mul, 1)
A:jax.numpy.lax_numpy.amaxmax->_make_reduction(onp.max, lax.max, -onp.inf)
A:jax.numpy.lax_numpy.aminmin->_make_reduction(onp.min, lax.min, onp.inf)
A:jax.numpy.lax_numpy.allalltrue->_make_reduction(onp.all, lax.bitwise_and, True, _cast_to_bool)
A:jax.numpy.lax_numpy.anysometrue->_make_reduction(onp.any, lax.bitwise_or, False, _cast_to_bool)
A:jax.numpy.lax_numpy.normalizer->numpy.prod(onp.take(shape(a), axis))
A:jax.numpy.lax_numpy.td->true_divide(sum(a, axis, dtype=dtype, keepdims=keepdims), lax.convert_element_type(normalizer, dtype))
A:jax.numpy.lax_numpy.centered->lax.abs(centered)
A:jax.numpy.lax_numpy.y->zeros_like(x)
A:jax.numpy.lax_numpy.nanmin->_make_nan_reduction(onp.nanmin, min, inf, nan_if_all_nan=True)
A:jax.numpy.lax_numpy.nanmax->_make_nan_reduction(onp.nanmax, max, -inf, nan_if_all_nan=True)
A:jax.numpy.lax_numpy.nansum->_make_nan_reduction(onp.nansum, sum, 0, nan_if_all_nan=False)
A:jax.numpy.lax_numpy.nanprod->_make_nan_reduction(onp.nanprod, prod, 1, nan_if_all_nan=False)
A:jax.numpy.lax_numpy.a_shape->shape(a)
A:jax.numpy.lax_numpy.num_dims->len(a_shape)
A:jax.numpy.lax_numpy.cumsum->_make_cumulative_reduction(onp.cumsum, lax._reduce_window_sum, 0, squash_nan=False)
A:jax.numpy.lax_numpy.cumprod->_make_cumulative_reduction(onp.cumprod, lax._reduce_window_prod, 1, squash_nan=False)
A:jax.numpy.lax_numpy.nancumsum->_make_cumulative_reduction(onp.nancumsum, lax._reduce_window_sum, 0, squash_nan=True)
A:jax.numpy.lax_numpy.nancumprod->_make_cumulative_reduction(onp.nancumprod, lax._reduce_window_prod, 1, squash_nan=True)
A:jax.numpy.lax_numpy.array->lax.pad(array, constant_values[i, 1], widths)
A:jax.numpy.lax_numpy.pad_width->numpy.broadcast_to(onp.asarray(pad_width), (array.ndim, 2))
A:jax.numpy.lax_numpy.constant_values->broadcast_to(asarray(constant_values), (array.ndim, 2))
A:jax.numpy.lax_numpy.shape0->shape(arrays[0])
A:jax.numpy.lax_numpy.new_shape->list(shape0)
A:jax.numpy.lax_numpy.arr->arr.reshape(shape(arr) + (1,)).reshape(shape(arr) + (1,))
A:jax.numpy.lax_numpy.k_dtype->_dtype(k)
A:jax.numpy.lax_numpy.cols->lax.broadcasted_iota(k_dtype, (N, M), 1)
A:jax.numpy.lax_numpy.broadcast_shape->list(a_shape)
A:jax.numpy.lax_numpy.mask->tri(*shape(m)[-2:], k=k - 1, dtype=bool)
A:jax.numpy.lax_numpy.default_int->lib.xla_bridge.canonicalize_dtype(onp.int_)
A:jax.numpy.lax_numpy.a_ndims->len(a_shape)
A:jax.numpy.lax_numpy.d->gcd(x1, x2)
A:jax.numpy.lax_numpy.diag_size->_max(0, _min(a_shape[axis1] + _min(offset, 0), a_shape[axis2] - _max(offset, 0)))
A:jax.numpy.lax_numpy.v_shape->shape(v)
A:jax.numpy.lax_numpy.v->lax.pad(v, zero(v), ((_max(0, k), _max(0, -k), 0),))
A:jax.numpy.lax_numpy.p->numpy.asarray(p)
A:jax.numpy.lax_numpy.batch_shape->lax.broadcast_shapes(shape(a)[:-2], shape(b)[:-2])
A:jax.numpy.lax_numpy.b->array(b)
A:jax.numpy.lax_numpy.batch_dims->tuple(range(nbatch))
A:jax.numpy.lax_numpy.a_reshape->lax.reshape(a, (_prod(a.shape[:-axes]), _prod(a.shape[-axes:])))
A:jax.numpy.lax_numpy.b_reshape->lax.reshape(b, (_prod(b.shape[:axes]), _prod(b.shape[axes:])))
A:jax.numpy.lax_numpy.out_reshape->lax.dot(a_reshape, b_reshape)
A:jax.numpy.lax_numpy.num_axes->len(ax1)
A:jax.numpy.lax_numpy.a_transposed->moveaxis(a, ax1, tuple(range(a.ndim - num_axes, a.ndim)))
A:jax.numpy.lax_numpy.b_transposed->moveaxis(b, ax2, tuple(range(num_axes)))
A:jax.numpy.lax_numpy.(operands, contractions)->opt_einsum.contract_path(*operands, einsum_call=True, use_blas=True)
A:jax.numpy.lax_numpy.contractions->tuple((data[:3] for data in contractions))
A:jax.numpy.lax_numpy.operands->list(_promote_dtypes(*operands))
A:jax.numpy.lax_numpy.operand->lax.transpose(operand, perm)
A:jax.numpy.lax_numpy.names->names.replace(name, '', count - 1).replace(name, '', count - 1)
A:jax.numpy.lax_numpy.eye->lax.broadcasted_eye(operand.dtype, operand.shape, axes)
A:jax.numpy.lax_numpy.(input_str, result_names)->einstr.split('->')
A:jax.numpy.lax_numpy.input_names->input_str.split(',')
A:jax.numpy.lax_numpy.counts->collections.Counter(names)
A:jax.numpy.lax_numpy.(operand, names)->sum_repeats(operand, names, counts, result_names)
A:jax.numpy.lax_numpy.(lhs, rhs)->map(operands.pop, operand_indices)
A:jax.numpy.lax_numpy.(lhs_counts, rhs_counts)->map(collections.Counter, input_names)
A:jax.numpy.lax_numpy.(lhs, lhs_names)->sum_repeats(lhs, lhs_names, lhs_counts, result_names + rhs_names)
A:jax.numpy.lax_numpy.(rhs, rhs_names)->sum_repeats(rhs, rhs_names, rhs_counts, result_names + lhs_names)
A:jax.numpy.lax_numpy.(lhs_batch, rhs_batch)->unzip2(((lhs_names.find(n), rhs_names.find(n)) for n in batch_names))
A:jax.numpy.lax_numpy.lhs->lhs.reshape(lhs.shape[:nbatch] + (-1,) + lhs.shape[-1:]).reshape(lhs.shape[:nbatch] + (-1,) + lhs.shape[-1:])
A:jax.numpy.lax_numpy.lhs_names->_movechars(lhs_names, lhs_batch, batch_dims)
A:jax.numpy.lax_numpy.rhs->rhs.reshape(rhs.shape[:nbatch] + (-1,) + rhs.shape[-1:]).reshape(rhs.shape[:nbatch] + (-1,) + rhs.shape[-1:])
A:jax.numpy.lax_numpy.rhs_names->_movechars(rhs_names, rhs_batch, batch_dims)
A:jax.numpy.lax_numpy.batch_names->''.join((lhs_names[i] for i in range(len(lhs_names)) if i in batch_dims))
A:jax.numpy.lax_numpy.(lhs_cont, rhs_cont)->unzip2(((lhs_names.index(n), rhs_names.index(n)) for n in contracted_names))
A:jax.numpy.lax_numpy.nbatch->len(batch_names)
A:jax.numpy.lax_numpy.ncont->len(lhs_cont)
A:jax.numpy.lax_numpy.lhs_cdims->tuple(range(lhs.ndim - ncont, lhs.ndim))
A:jax.numpy.lax_numpy.rhs_cdims->tuple(range(rhs.ndim - ncont, rhs.ndim))
A:jax.numpy.lax_numpy.b_ndims->len(b_shape)
A:jax.numpy.lax_numpy.axisa->_canonicalize_axis(axisa, a_ndims)
A:jax.numpy.lax_numpy.axisb->_canonicalize_axis(axisb, b_ndims)
A:jax.numpy.lax_numpy.b_shape->shape(b)
A:jax.numpy.lax_numpy.c->array([a1 * b2 - a2 * b1, a2 * b0 - a0 * b2, a0 * b1 - a1 * b0])
A:jax.numpy.lax_numpy.c_ndims->len(shape(c))
A:jax.numpy.lax_numpy.axisc->_canonicalize_axis(axisc, c_ndims)
A:jax.numpy.lax_numpy.a_broadcast_dims->list(range(a_ndims - d, a_ndims + d, 2))
A:jax.numpy.lax_numpy.a_broadcast_shape->numpy.ones(a_ndims + d, dtype=onp.int64)
A:jax.numpy.lax_numpy.b_broadcast_dims->list(range(b_ndims - d + 1, b_ndims + d + 1, 2))
A:jax.numpy.lax_numpy.b_broadcast_shape->numpy.ones(b_ndims + d, dtype=onp.int64)
A:jax.numpy.lax_numpy.out_shape->numpy.array(b_shape, dtype=onp.int64)
A:jax.numpy.lax_numpy.a_broadcast->lax.broadcast_in_dim(a, a_broadcast_shape, list(range(a_ndims - d)) + a_broadcast_dims)
A:jax.numpy.lax_numpy.b_broadcast->lax.broadcast_in_dim(b, b_broadcast_shape, list(range(b_ndims - d)) + b_broadcast_dims)
A:jax.numpy.lax_numpy.x_shape->shape(x)
A:jax.numpy.lax_numpy.iota->lax.broadcasted_iota(onp.int64, shape(a), axis)
A:jax.numpy.lax_numpy.idxs->numpy.arange(a.shape[axis]).reshape(shape)
A:jax.numpy.lax_numpy.mask_idxs->where(lax._eq_meet(a, op(a, axis, keepdims=True)), idxs, maxval)
A:jax.numpy.lax_numpy.(_, perm)->lax.sort_key_val(a, iota, dimension=axis)
A:jax.numpy.lax_numpy.a_ndim->len(a_shape)
A:jax.numpy.lax_numpy.slices[i]->slice(-offset, None)
A:jax.numpy.lax_numpy.indices->mod(indices, _constant_like(indices, a.shape[axis]))
A:jax.numpy.lax_numpy.index_dims->len(shape(indices))
A:jax.numpy.lax_numpy.slice_sizes->list(shape(a))
A:jax.numpy.lax_numpy.dnums->lax.GatherDimensionNumbers(offset_dims=tuple(list(range(axis)) + list(range(axis + index_dims, len(a.shape) + index_dims - 1))), collapsed_slice_dims=(axis,), start_index_map=(axis,))
A:jax.numpy.lax_numpy.all_indices->tuple(map(ravel, all_indices))
A:jax.numpy.lax_numpy.out_flat->lax.index_take(arr, all_indices, tuple(range(ndim(arr))))
A:jax.numpy.lax_numpy.abstract_idx->core.get_aval(idx)
A:jax.numpy.lax_numpy.idx->broadcast_arrays(*idx)
A:jax.numpy.lax_numpy.(start, limit, stride, needs_rev)->_static_idx(idx, arr.shape[axis])
A:jax.numpy.lax_numpy.reshaped_arr->arr.reshape(shape(arr) + (1,)).reshape(shape(arr) + (1,)).reshape((-1,) + arr.shape[idx.ndim:])
A:jax.numpy.lax_numpy.(int_idx,)->numpy.where(idx.ravel())
A:jax.numpy.lax_numpy.canonical_idx->_canonicalize_tuple_index(arr, tuple(idx))
A:jax.numpy.lax_numpy.unexpanded_shape_itr->iter(result.shape)
A:jax.numpy.lax_numpy.flat_idx->tuple((mod(ravel(x), _constant_like(x, arr_sliced.shape[i])) for (i, x) in zip(axes, idx_advanced)))
A:jax.numpy.lax_numpy.arr_sliced->_rewriting_take(arr, tuple(idx_noadvanced))
A:jax.numpy.lax_numpy.(idx_advanced, axes)->zip(*advanced_pairs)
A:jax.numpy.lax_numpy.idx_advanced->broadcast_arrays(*idx_advanced)
A:jax.numpy.lax_numpy.shape_suffix->tuple(onp.delete(_shape(arr_sliced), axes))
A:jax.numpy.lax_numpy.axes_are_contiguous->numpy.all(onp.diff(axes) == 1)
A:jax.numpy.lax_numpy.len_without_none->_sum((1 for e in idx if e is not None and e is not Ellipsis))
A:jax.numpy.lax_numpy.ellipsis_index->next(ellipses, None)
A:jax.numpy.lax_numpy.end->_min(start - step, size)
A:jax.numpy.lax_numpy.(gcd, _)->lax.while_loop(cond_fn, body_fn, (x1, x2))
A:jax.numpy.lax_numpy.globals()[func.__name__]->_not_implemented(func)
jax.numpy._ArrayMeta(type(onp.ndarray))
jax.numpy._ArrayMeta.__instancecheck__(self,instance)
jax.numpy._argminmax(op,a,axis)
jax.numpy._canonicalize_axis(axis,num_dims)
jax.numpy._canonicalize_tuple_index(arr,idx)
jax.numpy._check_arraylike(fun_name,*args)
jax.numpy._comparison_op(numpy_fn,lax_fn)
jax.numpy._constant_like(x,const)
jax.numpy._dot_general(lhs,rhs,lhs_cont,rhs_cont,nbatch)
jax.numpy._dtype_info(dtype)
jax.numpy._einsum(operands,contractions)
jax.numpy._float_divmod(x1,x2)
jax.numpy._is_advanced_int_indexer(idx)
jax.numpy._is_advanced_int_indexer_without_slices(idx)
jax.numpy._is_int_arraylike(x)
jax.numpy._is_slice_none(idx)
jax.numpy._isposneginf(infinity,x)
jax.numpy._logical_op(np_op,bitwise_op)
jax.numpy._make_cumulative_reduction(onp_reduction,window_reduce,init_val,squash_nan=False)
jax.numpy._make_nan_reduction(onp_reduction,np_reduction,init_val,nan_if_all_nan)
jax.numpy._make_reduction(np_fun,op,init_val,preproc=None)
jax.numpy._movechars(s,src,dst)
jax.numpy._not_implemented(fun)
jax.numpy._one_to_one_binop(numpy_fn,lax_fn,promote_like=False)
jax.numpy._one_to_one_unop(numpy_fn,lax_fn,promote_like=False)
jax.numpy._promote_args(fun_name,*args)
jax.numpy._promote_args_like(op,*args)
jax.numpy._promote_dtypes(*args)
jax.numpy._promote_shapes(*args)
jax.numpy._promote_to_result_dtype(op,*args)
jax.numpy._reduction_dims(a,axis)
jax.numpy._reduction_init_val(a,init_val)
jax.numpy._result_dtype(op,*args)
jax.numpy._rewriting_take(arr,idx,axis=0)
jax.numpy._split_on_axis(onp_fun,axis)
jax.numpy._static_idx(idx,size)
jax.numpy._swap_args(f)
jax.numpy._wraps(fun)
jax.numpy.allclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.angle(x)
jax.numpy.append(arr,values,axis=None)
jax.numpy.arange(*args,**kwargs)
jax.numpy.argmax(a,axis=None)
jax.numpy.argmin(a,axis=None)
jax.numpy.argsort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.array(object,dtype=None,copy=True,order='K',ndmin=0)
jax.numpy.atleast_1d(*arys)
jax.numpy.atleast_2d(*arys)
jax.numpy.atleast_3d(*arys)
jax.numpy.broadcast_arrays(*args)
jax.numpy.broadcast_to(arr,shape)
jax.numpy.clip(a,a_min=None,a_max=None)
jax.numpy.column_stack(tup)
jax.numpy.concatenate(arrays,axis=0)
jax.numpy.conjugate(x)
jax.numpy.count_nonzero(a,axis=None)
jax.numpy.cross(a,b,axisa=-1,axisb=-1,axisc=-1,axis=None)
jax.numpy.deg2rad(x)
jax.numpy.diag(v,k=0)
jax.numpy.diagonal(a,offset=0,axis1=0,axis2=1)
jax.numpy.divide(x1,x2)
jax.numpy.divmod(x1,x2)
jax.numpy.dot(a,b)
jax.numpy.dstack(tup)
jax.numpy.einsum(*operands)
jax.numpy.exp2(x)
jax.numpy.expand_dims(a,axis)
jax.numpy.eye(N,M=None,k=None,dtype=onp.dtype('float64'))
jax.numpy.flip(m,axis)
jax.numpy.fliplr(m)
jax.numpy.flipud(m)
jax.numpy.floor_divide(x1,x2)
jax.numpy.full(shape,fill_value,dtype=None)
jax.numpy.full_like(a,fill_value,dtype=None)
jax.numpy.gcd(x1,x2)
jax.numpy.heaviside(x,y)
jax.numpy.hstack(tup)
jax.numpy.hypot(x,y)
jax.numpy.identity(n,dtype=None)
jax.numpy.imag(x)
jax.numpy.inner(a,b)
jax.numpy.isclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.iscomplex(x)
jax.numpy.isfinite(x)
jax.numpy.isinf(x)
jax.numpy.isnan(x)
jax.numpy.isreal(x)
jax.numpy.kron(a,b)
jax.numpy.lax_numpy._ArrayMeta(type(onp.ndarray))
jax.numpy.lax_numpy._ArrayMeta.__instancecheck__(self,instance)
jax.numpy.lax_numpy._argminmax(op,a,axis)
jax.numpy.lax_numpy._canonicalize_axis(axis,num_dims)
jax.numpy.lax_numpy._canonicalize_tuple_index(arr,idx)
jax.numpy.lax_numpy._check_arraylike(fun_name,*args)
jax.numpy.lax_numpy._comparison_op(numpy_fn,lax_fn)
jax.numpy.lax_numpy._constant_like(x,const)
jax.numpy.lax_numpy._dot_general(lhs,rhs,lhs_cont,rhs_cont,nbatch)
jax.numpy.lax_numpy._dtype_info(dtype)
jax.numpy.lax_numpy._einsum(operands,contractions)
jax.numpy.lax_numpy._float_divmod(x1,x2)
jax.numpy.lax_numpy._is_advanced_int_indexer(idx)
jax.numpy.lax_numpy._is_advanced_int_indexer_without_slices(idx)
jax.numpy.lax_numpy._is_int_arraylike(x)
jax.numpy.lax_numpy._is_slice_none(idx)
jax.numpy.lax_numpy._isposneginf(infinity,x)
jax.numpy.lax_numpy._logical_op(np_op,bitwise_op)
jax.numpy.lax_numpy._make_cumulative_reduction(onp_reduction,window_reduce,init_val,squash_nan=False)
jax.numpy.lax_numpy._make_nan_reduction(onp_reduction,np_reduction,init_val,nan_if_all_nan)
jax.numpy.lax_numpy._make_reduction(np_fun,op,init_val,preproc=None)
jax.numpy.lax_numpy._movechars(s,src,dst)
jax.numpy.lax_numpy._not_implemented(fun)
jax.numpy.lax_numpy._one_to_one_binop(numpy_fn,lax_fn,promote_like=False)
jax.numpy.lax_numpy._one_to_one_unop(numpy_fn,lax_fn,promote_like=False)
jax.numpy.lax_numpy._promote_args(fun_name,*args)
jax.numpy.lax_numpy._promote_args_like(op,*args)
jax.numpy.lax_numpy._promote_dtypes(*args)
jax.numpy.lax_numpy._promote_shapes(*args)
jax.numpy.lax_numpy._promote_to_result_dtype(op,*args)
jax.numpy.lax_numpy._reduction_dims(a,axis)
jax.numpy.lax_numpy._reduction_init_val(a,init_val)
jax.numpy.lax_numpy._result_dtype(op,*args)
jax.numpy.lax_numpy._rewriting_take(arr,idx,axis=0)
jax.numpy.lax_numpy._split_on_axis(onp_fun,axis)
jax.numpy.lax_numpy._static_idx(idx,size)
jax.numpy.lax_numpy._swap_args(f)
jax.numpy.lax_numpy._wraps(fun)
jax.numpy.lax_numpy.allclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.lax_numpy.angle(x)
jax.numpy.lax_numpy.append(arr,values,axis=None)
jax.numpy.lax_numpy.arange(*args,**kwargs)
jax.numpy.lax_numpy.argmax(a,axis=None)
jax.numpy.lax_numpy.argmin(a,axis=None)
jax.numpy.lax_numpy.argsort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.lax_numpy.array(object,dtype=None,copy=True,order='K',ndmin=0)
jax.numpy.lax_numpy.atleast_1d(*arys)
jax.numpy.lax_numpy.atleast_2d(*arys)
jax.numpy.lax_numpy.atleast_3d(*arys)
jax.numpy.lax_numpy.broadcast_arrays(*args)
jax.numpy.lax_numpy.broadcast_to(arr,shape)
jax.numpy.lax_numpy.clip(a,a_min=None,a_max=None)
jax.numpy.lax_numpy.column_stack(tup)
jax.numpy.lax_numpy.concatenate(arrays,axis=0)
jax.numpy.lax_numpy.conjugate(x)
jax.numpy.lax_numpy.count_nonzero(a,axis=None)
jax.numpy.lax_numpy.cross(a,b,axisa=-1,axisb=-1,axisc=-1,axis=None)
jax.numpy.lax_numpy.deg2rad(x)
jax.numpy.lax_numpy.diag(v,k=0)
jax.numpy.lax_numpy.diagonal(a,offset=0,axis1=0,axis2=1)
jax.numpy.lax_numpy.divide(x1,x2)
jax.numpy.lax_numpy.divmod(x1,x2)
jax.numpy.lax_numpy.dot(a,b)
jax.numpy.lax_numpy.dstack(tup)
jax.numpy.lax_numpy.einsum(*operands)
jax.numpy.lax_numpy.exp2(x)
jax.numpy.lax_numpy.expand_dims(a,axis)
jax.numpy.lax_numpy.eye(N,M=None,k=None,dtype=onp.dtype('float64'))
jax.numpy.lax_numpy.flip(m,axis)
jax.numpy.lax_numpy.fliplr(m)
jax.numpy.lax_numpy.flipud(m)
jax.numpy.lax_numpy.floor_divide(x1,x2)
jax.numpy.lax_numpy.full(shape,fill_value,dtype=None)
jax.numpy.lax_numpy.full_like(a,fill_value,dtype=None)
jax.numpy.lax_numpy.gcd(x1,x2)
jax.numpy.lax_numpy.heaviside(x,y)
jax.numpy.lax_numpy.hstack(tup)
jax.numpy.lax_numpy.hypot(x,y)
jax.numpy.lax_numpy.identity(n,dtype=None)
jax.numpy.lax_numpy.imag(x)
jax.numpy.lax_numpy.inner(a,b)
jax.numpy.lax_numpy.isclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.lax_numpy.iscomplex(x)
jax.numpy.lax_numpy.isfinite(x)
jax.numpy.lax_numpy.isinf(x)
jax.numpy.lax_numpy.isnan(x)
jax.numpy.lax_numpy.isreal(x)
jax.numpy.lax_numpy.kron(a,b)
jax.numpy.lax_numpy.lcm(x1,x2)
jax.numpy.lax_numpy.log10(x)
jax.numpy.lax_numpy.log2(x)
jax.numpy.lax_numpy.logaddexp(x1,x2)
jax.numpy.lax_numpy.logaddexp2(x1,x2)
jax.numpy.lax_numpy.matmul(a,b)
jax.numpy.lax_numpy.mean(a,axis=None,dtype=None,out=None,keepdims=False)
jax.numpy.lax_numpy.moveaxis(a,source,destination)
jax.numpy.lax_numpy.nan_to_num(x,copy=True)
jax.numpy.lax_numpy.ndarray(six.with_metaclass(_ArrayMeta,onp.ndarray))
jax.numpy.lax_numpy.ones(shape,dtype=onp.dtype('float64'))
jax.numpy.lax_numpy.ones_like(x,dtype=None)
jax.numpy.lax_numpy.outer(a,b,out=None)
jax.numpy.lax_numpy.pad(array,pad_width,mode,constant_values=0)
jax.numpy.lax_numpy.polyval(p,x)
jax.numpy.lax_numpy.power(x1,x2)
jax.numpy.lax_numpy.ptp(a,axis=None,out=None,keepdims=False)
jax.numpy.lax_numpy.rad2deg(x)
jax.numpy.lax_numpy.ravel(a,order='C')
jax.numpy.lax_numpy.real(x)
jax.numpy.lax_numpy.reciprocal(x)
jax.numpy.lax_numpy.remainder(x1,x2)
jax.numpy.lax_numpy.repeat(a,repeats,axis=None)
jax.numpy.lax_numpy.reshape(a,newshape,order='C')
jax.numpy.lax_numpy.roll(a,shift,axis=None)
jax.numpy.lax_numpy.rot90(m,k=1,axes=(0,1))
jax.numpy.lax_numpy.round(a,decimals=0)
jax.numpy.lax_numpy.sinc(x)
jax.numpy.lax_numpy.sort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.lax_numpy.split(ary,indices_or_sections,axis=0)
jax.numpy.lax_numpy.sqrt(x)
jax.numpy.lax_numpy.square(x)
jax.numpy.lax_numpy.squeeze(a,axis=None)
jax.numpy.lax_numpy.stack(arrays,axis=0)
jax.numpy.lax_numpy.std(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.lax_numpy.swapaxes(a,axis1,axis2)
jax.numpy.lax_numpy.take(a,indices,axis=None,out=None,mode=None)
jax.numpy.lax_numpy.take_along_axis(arr,indices,axis)
jax.numpy.lax_numpy.tensordot(a,b,axes=2)
jax.numpy.lax_numpy.trace(a,offset=0,axis1=0,axis2=1,dtype=None,out=None)
jax.numpy.lax_numpy.transpose(x,axis=None)
jax.numpy.lax_numpy.tri(N,M=None,k=0,dtype=None)
jax.numpy.lax_numpy.tril(m,k=0)
jax.numpy.lax_numpy.triu(m,k=0)
jax.numpy.lax_numpy.true_divide(x1,x2)
jax.numpy.lax_numpy.vander(x,N=None,increasing=False)
jax.numpy.lax_numpy.var(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.lax_numpy.vdot(a,b)
jax.numpy.lax_numpy.vstack(tup)
jax.numpy.lax_numpy.where(condition,x=None,y=None)
jax.numpy.lax_numpy.zeros(shape,dtype=onp.dtype('float64'))
jax.numpy.lax_numpy.zeros_like(x,dtype=None)
jax.numpy.lcm(x1,x2)
jax.numpy.log10(x)
jax.numpy.log2(x)
jax.numpy.logaddexp(x1,x2)
jax.numpy.logaddexp2(x1,x2)
jax.numpy.matmul(a,b)
jax.numpy.mean(a,axis=None,dtype=None,out=None,keepdims=False)
jax.numpy.moveaxis(a,source,destination)
jax.numpy.nan_to_num(x,copy=True)
jax.numpy.ndarray(six.with_metaclass(_ArrayMeta,onp.ndarray))
jax.numpy.ones(shape,dtype=onp.dtype('float64'))
jax.numpy.ones_like(x,dtype=None)
jax.numpy.outer(a,b,out=None)
jax.numpy.pad(array,pad_width,mode,constant_values=0)
jax.numpy.polyval(p,x)
jax.numpy.power(x1,x2)
jax.numpy.ptp(a,axis=None,out=None,keepdims=False)
jax.numpy.rad2deg(x)
jax.numpy.ravel(a,order='C')
jax.numpy.real(x)
jax.numpy.reciprocal(x)
jax.numpy.remainder(x1,x2)
jax.numpy.repeat(a,repeats,axis=None)
jax.numpy.reshape(a,newshape,order='C')
jax.numpy.roll(a,shift,axis=None)
jax.numpy.rot90(m,k=1,axes=(0,1))
jax.numpy.round(a,decimals=0)
jax.numpy.sinc(x)
jax.numpy.sort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.split(ary,indices_or_sections,axis=0)
jax.numpy.sqrt(x)
jax.numpy.square(x)
jax.numpy.squeeze(a,axis=None)
jax.numpy.stack(arrays,axis=0)
jax.numpy.std(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.swapaxes(a,axis1,axis2)
jax.numpy.take(a,indices,axis=None,out=None,mode=None)
jax.numpy.take_along_axis(arr,indices,axis)
jax.numpy.tensordot(a,b,axes=2)
jax.numpy.trace(a,offset=0,axis1=0,axis2=1,dtype=None,out=None)
jax.numpy.transpose(x,axis=None)
jax.numpy.tri(N,M=None,k=0,dtype=None)
jax.numpy.tril(m,k=0)
jax.numpy.triu(m,k=0)
jax.numpy.true_divide(x1,x2)
jax.numpy.vander(x,N=None,increasing=False)
jax.numpy.var(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.vdot(a,b)
jax.numpy.vstack(tup)
jax.numpy.where(condition,x=None,y=None)
jax.numpy.zeros(shape,dtype=onp.dtype('float64'))
jax.numpy.zeros_like(x,dtype=None)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/numpy/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/numpy/fft.py----------------------------------------
A:jax.numpy.fft.globals()[func.__name__]->_not_implemented(func)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/ops/scatter.py----------------------------------------
A:jax.ops.scatter.x->numpy.lax_numpy.asarray(x)
A:jax.ops.scatter.y->lax.rev(y, reversed_y_dims)
A:jax.ops.scatter.x_shape->numpy.lax_numpy.shape(x)
A:jax.ops.scatter.y_shape->numpy.lax_numpy.shape(y)
A:jax.ops.scatter.idx->numpy.lax_numpy._canonicalize_tuple_index(x, idx)
A:jax.ops.scatter.scatter_indices->numpy.lax_numpy.concatenate((scatter_indices, i), len(scatter_indices_shape))
A:jax.ops.scatter.abstract_i->core.get_aval(i)
A:jax.ops.scatter.i->lax.broadcast_in_dim(i, shape=scatter_indices_shape + (1,), broadcast_dimensions=(len(scatter_indices_shape) - 1,))
A:jax.ops.scatter.(start, limit, stride, needs_rev)->numpy.lax_numpy._static_idx(i, x.shape[x_axis])
A:jax.ops.scatter.dnums->lax.ScatterDimensionNumbers(update_window_dims=tuple(update_window_dims), inserted_window_dims=tuple(inserted_window_dims), scatter_dims_to_operand_dims=tuple(scatter_dims_to_operand_dims))
A:jax.ops.scatter.index->_Indexable()
jax.ops.index_add(x,idx,y)
jax.ops.index_update(x,idx,y)
jax.ops.scatter._Indexable(object)
jax.ops.scatter._Indexable.__getitem__(self,index)
jax.ops.scatter._scatter_update(x,idx,y,scatter_op)
jax.ops.scatter.index_add(x,idx,y)
jax.ops.scatter.index_update(x,idx,y)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/ops/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/pxla.py----------------------------------------
A:jax.interpreters.pxla.nrep->len(replica_results)
A:jax.interpreters.pxla.assignments->assign_shards_to_replicas(nrep, axis_size)
A:jax.interpreters.pxla.(_, ids)->numpy.unique(assignments, return_index=True)
A:jax.interpreters.pxla.get_shard->memoize_unary(lambda i: arg.device_buffers[i].to_py())
A:jax.interpreters.pxla.(groupsize, ragged)->divmod(nrep, size)
A:jax.interpreters.pxla.indices->numpy.tile(onp.arange(size)[:, None], (1, groupsize))
A:jax.interpreters.pxla.(trailing_size, ragged)->divmod(nrep, prod(mesh_spec))
A:jax.interpreters.pxla.groups->map(onp.ravel, groups)
A:jax.interpreters.pxla.elts->map(_xla_unshard, shape.tuple_shapes(), xla_destructure(c, x))
A:jax.interpreters.pxla.dims->list(shape.dimensions())
A:jax.interpreters.pxla.start_indices->_xla_shard_start_indices(c, dims[0], len(dims))
A:jax.interpreters.pxla.idx->lib.xla_bridge.make_computation_builder('replicated_computation').Rem(c.ReplicaId(), c.Constant(onp.array(axis_size, onp.uint32)))
A:jax.interpreters.pxla.zero->numpy.zeros(ndim - 1, onp.uint32)
A:jax.interpreters.pxla.group_size->len(device_groups[0])
A:jax.interpreters.pxla.broadcasted->lib.xla_bridge.make_computation_builder('replicated_computation').Broadcast(x, (group_size,))
A:jax.interpreters.pxla.AxisEnv->namedtuple('AxisEnv', ['nreps', 'names', 'sizes'])
A:jax.interpreters.pxla.mesh_axis->axis_read(axis_env, name)
A:jax.interpreters.pxla.axis_env->AxisEnv(num_replicas, [axis_name], [axis_size])
A:jax.interpreters.pxla.arg_shapes->list(map(xla_shape, abstract_args))
A:jax.interpreters.pxla.built_c->replicated_comp(jaxpr, axis_env, consts, (), *arg_shapes)
A:jax.interpreters.pxla.result_shape->xla_shape_to_result_shape(built_c.GetReturnValueShape())
A:jax.interpreters.pxla.compiled->replicated_comp(jaxpr, axis_env, consts, (), *arg_shapes).Compile(arg_shapes, xb.get_compile_options(num_replicas))
A:jax.interpreters.pxla.c->lib.xla_bridge.make_computation_builder('replicated_computation')
A:jax.interpreters.pxla.all_freevars->itertools.chain(jaxpr.constvars, jaxpr.freevars)
A:jax.interpreters.pxla.in_nodes->map(read, eqn.invars)
A:jax.interpreters.pxla.ans->translation_rule(eqn.primitive)(c, *in_nodes, **eqn.params)
A:jax.interpreters.pxla.new_env->axis_env_extend(name, size)
A:jax.interpreters.pxla.in_shards->map(partial(xla_shard, c, new_env.sizes), in_nodes)
A:jax.interpreters.pxla.in_shapes->map(c.GetShape, in_nodes)
A:jax.interpreters.pxla.subc->replicated_comp(subjaxpr, new_env, (), map(c.GetShape, map(read, const_bindings + freevar_bindings)), *in_shapes)
A:jax.interpreters.pxla.sharded_result->xla.xla_call_translation_rule(c, subfun, *in_shards)
A:jax.interpreters.pxla.self._npy_value->unshard_output(self.shape[0], npy_shards)
A:jax.interpreters.pxla.axis_name->params.pop('axis_name')
A:jax.interpreters.pxla.axis_size->params.pop('axis_size')
A:jax.interpreters.pxla.(flat_args, in_trees)->unzip2(map(xla.tree_flatten, args))
A:jax.interpreters.pxla.flat_args->concatenate(flat_args)
A:jax.interpreters.pxla.(fun, out_tree)->xla.flatten_fun(fun, in_trees)
A:jax.interpreters.pxla.abstract_args->map(partial(abstractify, axis_size), flat_args)
A:jax.interpreters.pxla.compiled_fun->parallel_callable(fun, axis_name, axis_size, *abstract_args)
A:jax.interpreters.pxla.flat_ans->compiled_fun(out_tree(), *flat_args)
A:jax.interpreters.pxla.(jaxpr, (pval, consts, env))->trace_to_subjaxpr(fun, master).call_wrapped(pvals)
A:jax.interpreters.pxla.out->compile_replicated(jaxpr, axis_name, axis_size, consts, *avals)
A:jax.interpreters.pxla.handle_arg->partial(shard_arg, compiled._device_ordinals)
A:jax.interpreters.pxla.handle_result->xla.result_handler(result_shape)
A:jax.interpreters.pxla.out_bufs->replicated_comp(jaxpr, axis_env, consts, (), *arg_shapes).Compile(arg_shapes, xb.get_compile_options(num_replicas)).ExecutePerReplica(input_bufs)
A:jax.interpreters.pxla.xla_pcall_p->core.Primitive('xla_pcall')
A:jax.interpreters.pxla.xla_pcall->partial(core.call_bind, xla_pcall_p)
A:jax.interpreters.pxla.ad.primitive_transposes[xla_pcall_p]->partial(ad.map_transpose, xla_pcall_p)
jax.interpreters.pxla.ShardedDeviceArray(self,axis_size,replica_results)
jax.interpreters.pxla.ShardedDeviceArray._value(self)
jax.interpreters.pxla._max(itr)
jax.interpreters.pxla._shard_aval(axis_size,aval)
jax.interpreters.pxla._xla_shard_start_indices(c,axis_size,ndim)
jax.interpreters.pxla.abstractify(axis_size,x)
jax.interpreters.pxla.assign_shards_to_replicas(nrep,size)
jax.interpreters.pxla.axis_groups(axis_env,name)
jax.interpreters.pxla.axis_read(axis_env,axis_name)
jax.interpreters.pxla.compile_replicated(jaxpr,axis_name,axis_size,consts,*abstract_args)
jax.interpreters.pxla.execute_replicated(compiled,pval,axis_size,nrep,handle_in,handle_out,out_tree,*args)
jax.interpreters.pxla.jaxpr_replicas(jaxpr)
jax.interpreters.pxla.parallel_callable(fun,axis_name,axis_size,*avals)
jax.interpreters.pxla.replica_groups(nrep,mesh_spec,mesh_axis)
jax.interpreters.pxla.replicated_comp(jaxpr,ax_env,const_vals,freevar_shapes,*arg_shapes)
jax.interpreters.pxla.shard_arg(device_ordinals,arg)
jax.interpreters.pxla.unshard_output(axis_size,replica_results)
jax.interpreters.pxla.xla_pcall_impl(fun,*args,**params)
jax.interpreters.pxla.xla_shard(c,sizes,x)
jax.interpreters.pxla.xla_unshard(c,device_groups,x)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/batching.py----------------------------------------
A:jax.interpreters.batching.sizes->reduce(set.union, map(dimsize, in_dims, in_vals))
A:jax.interpreters.batching.sz->(dimsize(bdx, xs) | dimsize(bdy, ys)).pop()
A:jax.interpreters.batching.trace->BatchTrace(master, core.cur_sublevel())
A:jax.interpreters.batching.in_tracers->map(partial(BatchTracer, trace), vals, in_dims)
A:jax.interpreters.batching.out_tracer->BatchTrace(master, core.cur_sublevel()).full_raise(ans)
A:jax.interpreters.batching.batched_aval->get_aval(self.val)
A:jax.interpreters.batching.t->type(aval)
A:jax.interpreters.batching.(vals_in, dims_in)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.batched_primitive->get_primitive_batcher(primitive)
A:jax.interpreters.batching.(val_out, dim_out)->batched_primitive(vals_in, dims_in, **params)
A:jax.interpreters.batching.(vals, dims)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.(f, dim_out)->batch_subtrace(f, self.master, dims)
A:jax.interpreters.batching.val_out->call_primitive.bind(f, *vals, **params)
A:jax.interpreters.batching.vals->pack([t.val for t in tracers])
A:jax.interpreters.batching.batch_dim->tuple((t.batch_dim for t in tracers))
A:jax.interpreters.batching.unbatched_shape->tuple(onp.delete(aval.shape, bdim))
A:jax.interpreters.batching.batched_shape->tuple(onp.insert(aval.shape, bdim, size))
A:jax.interpreters.batching.primitive_batchers[prim]->partial(reducer_batcher, prim)
A:jax.interpreters.batching.args->map(partial(handle_scalar_broadcasting, ndim), args, batch_dims)
A:jax.interpreters.batching.ndim->max(map(onp.ndim, args))
A:jax.interpreters.batching.axes->tuple(onp.where(onp.less(axes, bdim), axes, onp.add(axes, 1)))
A:jax.interpreters.batching.bdim_out->list(onp.delete(onp.arange(operand.ndim), axes)).index(bdim)
A:jax.interpreters.batching.params->dict(params, input_shape=operand.shape)
A:jax.interpreters.batching.move_bdim->partial(bdim_at_front, broadcast_size=sz, force_broadcast=True)
A:jax.interpreters.batching.(xs, ys)->map(move_bdim, batched_args, batch_dims)
A:jax.interpreters.batching.aval->get_aval(x)
A:jax.interpreters.batching.x->broadcast(x, sz, force_broadcast=force_broadcast)
jax.interpreters.batching.BatchTrace(Trace)
jax.interpreters.batching.BatchTrace.lift(self,val)
jax.interpreters.batching.BatchTrace.pack(self,tracers)
jax.interpreters.batching.BatchTrace.post_process_call(self,_,out_tracer)
jax.interpreters.batching.BatchTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.batching.BatchTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.batching.BatchTrace.pure(self,val)
jax.interpreters.batching.BatchTrace.sublift(self,val)
jax.interpreters.batching.BatchTracer(self,trace,val,batch_dim)
jax.interpreters.batching.BatchTracer.aval(self)
jax.interpreters.batching.BatchTracer.full_lower(self)
jax.interpreters.batching.BatchTracer.unpack(self)
jax.interpreters.batching.add_batch_dim_to_aval(bdim,size,aval)
jax.interpreters.batching.add_batched(batched_args,batch_dims)
jax.interpreters.batching.batch(fun,in_vals,in_dims,out_dim_dst)
jax.interpreters.batching.batch_subtrace(master,dims,*vals)
jax.interpreters.batching.batch_transform(size,in_dims,out_dim_dst,vals)
jax.interpreters.batching.bdim_at_front(x,bdim,broadcast_size=1,force_broadcast=False)
jax.interpreters.batching.broadcast(x,sz,force_broadcast=False)
jax.interpreters.batching.broadcast_batcher(prim,batched_args,batch_dims,**params)
jax.interpreters.batching.defbroadcasting(prim)
jax.interpreters.batching.defreducer(prim)
jax.interpreters.batching.defvectorized(prim)
jax.interpreters.batching.dimsize(dim,x)
jax.interpreters.batching.get_aval(x)
jax.interpreters.batching.get_primitive_batcher(p)
jax.interpreters.batching.handle_scalar_broadcasting(nd,x,bdim)
jax.interpreters.batching.move_dim_to_front(x,dim)
jax.interpreters.batching.moveaxis(sz,dst,src,x,force_broadcast=True)
jax.interpreters.batching.raise_to_shaped(aval)
jax.interpreters.batching.reducer_batcher(prim,batched_args,batch_dims,axes,**params)
jax.interpreters.batching.remove_batch_dim_from_aval(bdim,aval)
jax.interpreters.batching.shaped_aval(x)
jax.interpreters.batching.shaped_jaxtuple(xs)
jax.interpreters.batching.vectorized_batcher(prim,batched_args,batch_dims,**params)
jax.interpreters.batching.zeros_like_batched(batched_args,batch_dims)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/partial_eval.py----------------------------------------
A:jax.interpreters.partial_eval.tracers->map(self.instantiate_const, tracers)
A:jax.interpreters.partial_eval.out_aval->primitive.abstract_eval(*avals, **params)
A:jax.interpreters.partial_eval.eqn->JaxprEqn([self], [None] * n, core.identity_p, (), True, {})
A:jax.interpreters.partial_eval.pval->pack_pvals([t.pval for t in tracers])
A:jax.interpreters.partial_eval.(in_pvs, in_consts)->unzip2([t.pval for t in tracers])
A:jax.interpreters.partial_eval.(fun, aux)->partial_eval(f, self, reduced_pvs)
A:jax.interpreters.partial_eval.(out_pv_const, consts)->call_primitive.bind(fun, *in_consts, **params)
A:jax.interpreters.partial_eval.(out_pv, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.const_tracers->map(trace.new_instantiated_const, consts)
A:jax.interpreters.partial_eval.env_tracers->map(trace.full_raise, env)
A:jax.interpreters.partial_eval.reduced_pvs->map(remove_axis_from_pv, in_pvs)
A:jax.interpreters.partial_eval.(out_const, consts)->call_primitive.bind(fun, *in_consts, **params)
A:jax.interpreters.partial_eval.(out_pv_reduced, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.out_pv->add_axis_to_pv(params['axis_size'], out_pv_reduced)
A:jax.interpreters.partial_eval.jaxpr_converted->Jaxpr(const_vars, env_vars, invars, var(out_tracer), eqns).copy()
A:jax.interpreters.partial_eval.jaxpr_converted.invars->list(it.chain(jaxpr.constvars, jaxpr.invars))
A:jax.interpreters.partial_eval.invars->map(var, in_tracers)
A:jax.interpreters.partial_eval.(jaxpr, consts, env)->tracers_to_jaxpr(in_tracers, out_tracer)
A:jax.interpreters.partial_eval.out->pack((out_const, pack(consts)))
A:jax.interpreters.partial_eval.trace->JaxprTrace(master, core.cur_sublevel())
A:jax.interpreters.partial_eval.map_primitives->set()
A:jax.interpreters.partial_eval.f->trace_to_subjaxpr(f, trace.master)
A:jax.interpreters.partial_eval.(_, pvout, _)->trace_to_jaxpr(lu.wrap_init(fun, params), pvs_in)
A:jax.interpreters.partial_eval.n->len(pv)
A:jax.interpreters.partial_eval.key->object()
A:jax.interpreters.partial_eval.d->Destructuring(i, eqn, key)
A:jax.interpreters.partial_eval.Destructuring->namedtuple('Destructuring', ['i', 'eqn', 'key'])
A:jax.interpreters.partial_eval.abstract_unit->core.AbstractTuple()
A:jax.interpreters.partial_eval.aval->core.lattice_join(pv1, pv2)
A:jax.interpreters.partial_eval.(join_pvs, join_consts)->unzip2(map(join_pvals, pvals1, pvals2))
A:jax.interpreters.partial_eval.(pvs, consts)->unzip2(pvals)
A:jax.interpreters.partial_eval.pv_out->JaxprTracerTuple(pvs)
A:jax.interpreters.partial_eval.fun->trace_to_subjaxpr(fun, master)
A:jax.interpreters.partial_eval.(jaxpr, (out_pval, consts, env))->trace_to_subjaxpr(fun, master).call_wrapped(pvals, **kwargs)
A:jax.interpreters.partial_eval.in_tracers->map(trace.new_arg, pvals)
A:jax.interpreters.partial_eval.out_tracer->JaxprTrace(master, core.cur_sublevel()).full_raise(out_tracer)
A:jax.interpreters.partial_eval.FreeVar->namedtuple('FreeVar', ['val'])
A:jax.interpreters.partial_eval.ConstVar->namedtuple('ConstVar', ['val'])
A:jax.interpreters.partial_eval.LambdaBinding->namedtuple('LambdaBinding', [])
A:jax.interpreters.partial_eval.newvar->gensym('')
A:jax.interpreters.partial_eval.t_to_var->defaultdict(newvar)
A:jax.interpreters.partial_eval.sorted_tracers->toposort(out_tracer)
A:jax.interpreters.partial_eval.(env_vars, env_vals)->unzip2(env.items())
A:jax.interpreters.partial_eval.(const_vars, const_vals)->unzip2(consts.items())
A:jax.interpreters.partial_eval.jaxpr->Jaxpr(const_vars, env_vars, invars, var(out_tracer), eqns)
A:jax.interpreters.partial_eval.counter->itertools.count()
A:jax.interpreters.partial_eval.in_vals->map(read, eqn.invars)
A:jax.interpreters.partial_eval.ans->merge_pvals(jaxpr_ans, pval)
A:jax.interpreters.partial_eval.pvals->map(abstractify, args)
A:jax.interpreters.partial_eval.(jaxpr, (pval, consts, env))->trace_to_subjaxpr(fun, master).call_wrapped(pvals)
A:jax.interpreters.partial_eval.jaxpr_ans->eval_jaxpr_raw(jaxpr, consts, env, *args)
A:jax.interpreters.partial_eval.compiled_call_p->Primitive('compiled_call')
A:jax.interpreters.partial_eval.compiled_call->partial(core.call_bind, compiled_call_p)
jax.interpreters.partial_eval.JaxprTrace(Trace)
jax.interpreters.partial_eval.JaxprTrace.instantiate_const(self,tracer)
jax.interpreters.partial_eval.JaxprTrace.lift(self,val)
jax.interpreters.partial_eval.JaxprTrace.new_arg(self,pval)
jax.interpreters.partial_eval.JaxprTrace.new_const(self,val)
jax.interpreters.partial_eval.JaxprTrace.new_instantiated_const(self,val)
jax.interpreters.partial_eval.JaxprTrace.pack(self,tracers)
jax.interpreters.partial_eval.JaxprTrace.post_process_call(self,call_primitive,out_tracer)
jax.interpreters.partial_eval.JaxprTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_map(self,call_primitive,f,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.pure(self,val)
jax.interpreters.partial_eval.JaxprTrace.sublift(self,val)
jax.interpreters.partial_eval.JaxprTracer(self,trace,pval,recipe)
jax.interpreters.partial_eval.JaxprTracer.__repr__(self)
jax.interpreters.partial_eval.JaxprTracer.aval(self)
jax.interpreters.partial_eval.JaxprTracer.full_lower(self)
jax.interpreters.partial_eval.JaxprTracer.ispure(self)
jax.interpreters.partial_eval.JaxprTracer.parents(self)
jax.interpreters.partial_eval.JaxprTracer.unpack(self)
jax.interpreters.partial_eval.JaxprTracerTuple(tuple)
jax.interpreters.partial_eval.PartialVal(cls,xs)
jax.interpreters.partial_eval.Var(self,count,suffix)
jax.interpreters.partial_eval.Var.__repr__(self)
jax.interpreters.partial_eval.abstract_eval_fun(fun,*avals,**params)
jax.interpreters.partial_eval.abstractify(x)
jax.interpreters.partial_eval.add_axis_to_aval(size,aval)
jax.interpreters.partial_eval.add_axis_to_pv(size,pv)
jax.interpreters.partial_eval.as_abstract_val(pv)
jax.interpreters.partial_eval.compiled_call_impl(fun,*args,**kwargs)
jax.interpreters.partial_eval.eqn_parents(eqn)
jax.interpreters.partial_eval.eqn_tracer_to_var(var,outvars,eqn)
jax.interpreters.partial_eval.eval_jaxpr_raw(jaxpr,consts,freevar_vals,*args)
jax.interpreters.partial_eval.gensym(suffix)
jax.interpreters.partial_eval.identity(x)
jax.interpreters.partial_eval.join_pvals(pval1,pval2)
jax.interpreters.partial_eval.merge_pvals(val,pval)
jax.interpreters.partial_eval.pack_pvals(pvals)
jax.interpreters.partial_eval.partial_eval(f,trace,pvs)
jax.interpreters.partial_eval.partial_eval_wrapper(avals,*consts,**kwargs)
jax.interpreters.partial_eval.partial_val_aval(pv,const)
jax.interpreters.partial_eval.remove_axis_from_aval(aval)
jax.interpreters.partial_eval.remove_axis_from_pv(pv)
jax.interpreters.partial_eval.trace_to_jaxpr(fun,pvals,**kwargs)
jax.interpreters.partial_eval.trace_to_subjaxpr(master,pvals)
jax.interpreters.partial_eval.trace_unwrapped_to_jaxpr(fun,pvals,**kwargs)
jax.interpreters.partial_eval.tracers_to_jaxpr(in_tracers,out_tracer)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/parallel.py----------------------------------------
A:jax.interpreters.parallel.sizes->reduce(set.union, map(batching.dimsize, in_axes, in_vals))
A:jax.interpreters.parallel.(fun, out_axis)->serial_pmap_transform(fun, name, in_axes)
A:jax.interpreters.parallel.out_val->papply_transform(fun).call_wrapped(name, in_vals, axis_size, in_axes, out_axis)
A:jax.interpreters.parallel.trace->PapplyTrace(master, core.cur_sublevel())
A:jax.interpreters.parallel.in_tracers->map(partial(PapplyTracer, trace, name, axis_size), args, in_axes)
A:jax.interpreters.parallel.out_tracer->ensure_axis(out_axis, out_tracer.axis, out_tracer)
A:jax.interpreters.parallel.batched_aval->batching.get_aval(self.val)
A:jax.interpreters.parallel.t->type(self.axis)
A:jax.interpreters.parallel.(names_in, vals_in, axes_in)->unzip3(((t.name, t.val, t.axis) for t in tracers))
A:jax.interpreters.parallel.name->tuple((t.name for t in tracers))
A:jax.interpreters.parallel.(val_out, axis_out)->rule(name, vals, axes, **params)
A:jax.interpreters.parallel.val_out->call_primitive.bind(f, *vals, **params)
A:jax.interpreters.parallel.rule->batching.get_primitive_batcher(primitive)
A:jax.interpreters.parallel.(names, vals, axes)->unzip3(((t.name, t.val, t.axis) for t in tracers))
A:jax.interpreters.parallel.(f, axis_out)->serial_pmap_subtrace(f, self.master, name, axes)
A:jax.interpreters.parallel.vals->core.pack([t.val for t in tracers])
A:jax.interpreters.parallel.axis->tuple((t.axis for t in tracers))
A:jax.interpreters.parallel.newvar->pe.gensym('_axis')
A:jax.interpreters.parallel.aval->batching.get_aval(x)
A:jax.interpreters.parallel.perm->list(range(x.ndim))
A:jax.interpreters.parallel.size->tuple((t.axis_size for t in tracers))
A:jax.interpreters.parallel.result->prim.bind(operand, axes=other_axes, input_shape=input_shape)
A:jax.interpreters.parallel.x->psplit(x, axis_name, xdim)
A:jax.interpreters.parallel.papply_primitive_rules[prim]->partial(broadcasting_papply, prim)
jax.interpreters.parallel.PapplyTrace(Trace)
jax.interpreters.parallel.PapplyTrace.lift(self,val)
jax.interpreters.parallel.PapplyTrace.pack(self,tracers)
jax.interpreters.parallel.PapplyTrace.post_process_call(self,_,out_tracer)
jax.interpreters.parallel.PapplyTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.parallel.PapplyTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.parallel.PapplyTrace.pure(self,val)
jax.interpreters.parallel.PapplyTrace.sublift(self,val)
jax.interpreters.parallel.PapplyTracer(self,trace,name,axis_size,val,axis)
jax.interpreters.parallel.PapplyTracer.aval(self)
jax.interpreters.parallel.PapplyTracer.full_lower(self)
jax.interpreters.parallel.PapplyTracer.unpack(self)
jax.interpreters.parallel.SerialPmapTrace(Trace)
jax.interpreters.parallel.SerialPmapTrace.lift(self,val)
jax.interpreters.parallel.SerialPmapTrace.pack(self,tracers)
jax.interpreters.parallel.SerialPmapTrace.post_process_call(self,_,out_tracer)
jax.interpreters.parallel.SerialPmapTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.parallel.SerialPmapTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.parallel.SerialPmapTrace.pure(self,val)
jax.interpreters.parallel.SerialPmapTrace.sublift(self,val)
jax.interpreters.parallel.SerialPmapTracer(self,trace,name,val,axis)
jax.interpreters.parallel.SerialPmapTracer.aval(self)
jax.interpreters.parallel.SerialPmapTracer.full_lower(self)
jax.interpreters.parallel.SerialPmapTracer.unpack(self)
jax.interpreters.parallel.broadcasting_papply(prim,name,vals,axes,**params)
jax.interpreters.parallel.defbroadcasting(prim)
jax.interpreters.parallel.defreducer(prim,collective_prim)
jax.interpreters.parallel.defvectorized(prim)
jax.interpreters.parallel.ensure_axis(dst,src,x)
jax.interpreters.parallel.identity(x)
jax.interpreters.parallel.papply(fun,name,in_vals,axis_size,in_axes,out_axis)
jax.interpreters.parallel.papply_transform(name,args,axis_size,in_axes,out_axis)
jax.interpreters.parallel.reducer_papply(prim,cprim,name,vals,papply_axes,input_shape,axes)
jax.interpreters.parallel.serial_pmap(fun,name,in_vals,in_axes,out_axis_target)
jax.interpreters.parallel.serial_pmap_subtrace(master,name,axes,*vals)
jax.interpreters.parallel.serial_pmap_transform(name,axes,*vals)
jax.interpreters.parallel.vectorized_papply(prim,name,vals,axes,**params)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/ad.py----------------------------------------
A:jax.interpreters.ad.(fun, aux)->jvp_subtrace_aux(fun)
A:jax.interpreters.ad.out_tangent->instantiate_zeros(out_primal, out_tangent)
A:jax.interpreters.ad.trace->JVPTrace(master, core.cur_sublevel())
A:jax.interpreters.ad.out_tracer->JVPTrace(master, core.cur_sublevel()).full_raise(ans)
A:jax.interpreters.ad.(out_tracer, aux_tracer)->map(trace.full_raise, (ans, aux))
A:jax.interpreters.ad.has_aux->kwargs.pop('has_aux', False)
A:jax.interpreters.ad.jvpfun->pack_output(jvpfun)
A:jax.interpreters.ad.(jvpfun, aux)->jvp(traceable, has_aux=True)
A:jax.interpreters.ad.(jaxpr, out_pval, consts)->pe.trace_to_jaxpr(jvpfun, in_pvals)
A:jax.interpreters.ad.(pval_primal, pval_tangent)->unpair_pval(out_pval)
A:jax.interpreters.ad.(out_primal, pval, jaxpr, consts)->linearize(traceable, *primals)
A:jax.interpreters.ad.(out_primal, pval, jaxpr, consts, aux)->linearize(traceable, *primals, has_aux=True)
A:jax.interpreters.ad.ct->ignore_consts(ct, pval)
A:jax.interpreters.ad.dummy_primal_and_ct->pack((core.unit, ct))
A:jax.interpreters.ad.(_, arg_cts)->backward_pass(jaxpr, consts, (), dummy_args, dummy_primal_and_ct)
A:jax.interpreters.ad.cts_in->map(read_cotangent, eqn.outvars)
A:jax.interpreters.ad.invals->map(primal_env.get, eqn.invars)
A:jax.interpreters.ad.(subjaxprs, sub_consts, sub_freevar_vals)->unzip3([(subjaxpr, map(primal_env.get, const_vars), map(primal_env.get, bound_vars)) for (subjaxpr, const_vars, bound_vars) in eqn.bound_subjaxprs])
A:jax.interpreters.ad.(cts_out, ct_free_vars_out)->get_primitive_transpose(eqn.primitive)(eqn.params, subjaxprs, sub_consts, sub_freevar_vals, invals, ct_in)
A:jax.interpreters.ad.cts_out->get_primitive_transpose(eqn.primitive)(ct_in, *invals, **eqn.params)
A:jax.interpreters.ad.freevar_cts->tree_map(lambda x: x.sum(0), freevar_cts)
A:jax.interpreters.ad.(primal_out, tangent_out)->build_tree(out_tree_def(), result)
A:jax.interpreters.ad.(nonzero_tangents, in_tree_def)->tree_to_jaxtuples(tangents)
A:jax.interpreters.ad.(f, out_tree_def)->traceable(jvp_subtrace(f, self.master), in_tree_def)
A:jax.interpreters.ad.result->call_primitive.bind(f, pack(primals), nonzero_tangents, **params)
A:jax.interpreters.ad.(out_jtuple, tree_def)->tree_to_jaxtuples((cotangents_out, freevar_cts))
A:jax.interpreters.ad.xt->TangentTuple((zero,) * len(yt))
A:jax.interpreters.ad.yt->TangentTuple((zero,) * len(xt))
A:jax.interpreters.ad.primals->pack((t.primal for t in tracers))
A:jax.interpreters.ad.tangents->map(instantiate_zeros, primals, tangents)
A:jax.interpreters.ad.primitive_jvps[primitive]->partial(zero_jvp, primitive)
A:jax.interpreters.ad.primitive_transposes[primitive]->partial(linear_transpose, transpose_rule)
A:jax.interpreters.ad.val_out->primitive.bind(*primals, **params)
A:jax.interpreters.ad.primitive_transposes[prim]->partial(bilinear_transpose, lhs_rule, rhs_rule)
A:jax.interpreters.ad.defbilinear->partial(defbilinear_broadcasting, lambda g, x: g)
A:jax.interpreters.ad.new_tangents->build_tree(in_tree_def, new_tangents)
A:jax.interpreters.ad.(args, ct, freevar_vals)->build_tree(in_tree_def, (args, ct, freevar_vals))
A:jax.interpreters.ad.((args, ct, freevar_vals), in_tree_def)->tree_to_jaxtuples((args, ct, freevar_vals))
A:jax.interpreters.ad.fun->wrap_init(backward_pass)
A:jax.interpreters.ad.(fun, out_tree_def)->transposed_mapped(fun, jaxpr, in_tree_def, tuple(freevar_vals))
A:jax.interpreters.ad.all_args->pack((pack(args), pack(consts), ct))
A:jax.interpreters.ad.ans->primitive.bind(fun, all_args, **params)
A:jax.interpreters.ad.(args, ct)->build_tree(in_tree_def, (args, ct))
A:jax.interpreters.ad.((args, ct), in_tree_def)->tree_to_jaxtuples((args, ct))
A:jax.interpreters.ad.(cts_out, freevar_cts)->build_tree(out_tree_def(), ans)
A:jax.interpreters.ad.primitive_transposes[core.call_p]->partial(call_transpose, call_p)
A:jax.interpreters.ad.primitive_transposes[pe.compiled_call_p]->partial(call_transpose, pe.compiled_call_p)
A:jax.interpreters.ad.tree_to_jaxtuples->partial(process_pytree, pack)
jax.interpreters.ad.JVPTrace(Trace)
jax.interpreters.ad.JVPTrace.join(self,xt,yt)
jax.interpreters.ad.JVPTrace.lift(self,val)
jax.interpreters.ad.JVPTrace.pack(self,tracers)
jax.interpreters.ad.JVPTrace.post_process_call(self,_,out_tracer)
jax.interpreters.ad.JVPTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.ad.JVPTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.ad.JVPTrace.pure(self,val)
jax.interpreters.ad.JVPTrace.sublift(self,val)
jax.interpreters.ad.JVPTracer(self,trace,primal,tangent)
jax.interpreters.ad.JVPTracer.aval(self)
jax.interpreters.ad.JVPTracer.full_lower(self)
jax.interpreters.ad.JVPTracer.unpack(self)
jax.interpreters.ad.TangentTuple(tuple)
jax.interpreters.ad.add_tangents(x,y)
jax.interpreters.ad.backward_pass(jaxpr,consts,freevar_vals,args,cotangent_in)
jax.interpreters.ad.bilinear_transpose(lhs_rule,rhs_rule,cotangent,x,y,**kwargs)
jax.interpreters.ad.call_transpose(primitive,params,jaxpr,consts,freevar_vals,args,ct)
jax.interpreters.ad.defbilinear_broadcasting(bcast,prim,lhs_rule,rhs_rule)
jax.interpreters.ad.defjvp(primitive,*jvprules)
jax.interpreters.ad.defjvp2(primitive,*jvprules)
jax.interpreters.ad.defjvp_zero(primitive)
jax.interpreters.ad.deflinear(primitive,transpose_rule)
jax.interpreters.ad.get_primitive_transpose(p)
jax.interpreters.ad.identity(x)
jax.interpreters.ad.ignore_consts(ct,pval)
jax.interpreters.ad.instantiate_zeros(example,tangent)
jax.interpreters.ad.jvp(fun,has_aux=False)
jax.interpreters.ad.jvp_subtrace(master,primals,tangents)
jax.interpreters.ad.jvp_subtrace_aux(master,primals,tangents)
jax.interpreters.ad.jvpfun(primals,tangents)
jax.interpreters.ad.linear_jvp(primitive,primals,tangents,**params)
jax.interpreters.ad.linear_transpose(transpose_rule,cotangent,*args,**kwargs)
jax.interpreters.ad.linearize(traceable,*primals,**kwargs)
jax.interpreters.ad.map_transpose(primitive,params,jaxpr,consts,freevar_vals,args,ct)
jax.interpreters.ad.pack_output(*args)
jax.interpreters.ad.standard_jvp(jvprules,primitive,primals,tangents,**params)
jax.interpreters.ad.standard_jvp2(jvprules,primitive,primals,tangents,**params)
jax.interpreters.ad.traceable(in_tree_def,new_primals,new_tangents)
jax.interpreters.ad.transposed_fun(jaxpr,in_tree_def,args)
jax.interpreters.ad.transposed_mapped(jaxpr,in_tree_def,freevar_vals,args)
jax.interpreters.ad.unpair_pval(pval)
jax.interpreters.ad.vjp(traceable,primals,has_aux=False)
jax.interpreters.ad.zero_jvp(primitive,primals,tangents,**params)


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/__init__.py----------------------------------------


----------------------------------------/home/zhang/Packages/jax/jax0.1.22/interpreters/xla.py----------------------------------------
A:jax.interpreters.xla.abstract_args->map(abstractify, args)
A:jax.interpreters.xla.compiled_fun->xla_callable(fun, *map(abstractify, flat_args))
A:jax.interpreters.xla.shapes->map(xla_shape, abstract_args)
A:jax.interpreters.xla.built_c->jaxpr_computation(jaxpr, consts, (), *xla_shapes)
A:jax.interpreters.xla.result_shape->xla_shape_to_result_shape(built_c.GetReturnValueShape())
A:jax.interpreters.xla.handle_result->result_handler(result_shape)
A:jax.interpreters.xla.compiled->lib.xla_bridge.make_computation_builder('constant_instantiating_computation').Build(xla_const).Compile((), xb.get_compile_options())
A:jax.interpreters.xla.c->lib.xla_bridge.make_computation_builder('constant_instantiating_computation')
A:jax.interpreters.xla.xla_args->map(c.ParameterWithShape, shapes)
A:jax.interpreters.xla.xla_result->translation_rule(prim)(c, *xla_args, **kwargs)
A:jax.interpreters.xla.x->canonicalize_pyval_dtype(x)
A:jax.interpreters.xla.py_val->device_buffer.to_py()
A:jax.interpreters.xla.handlers->list(map(result_handler, result_shape))
A:jax.interpreters.xla.bufs->device_buffer.destructure()
A:jax.interpreters.xla.arg_shapes->list(map(xla_shape, abstract_args))
A:jax.interpreters.xla.consts_env->dict(zip(jaxpr.constvars, const_vals))
A:jax.interpreters.xla.all_freevars->itertools.chain(jaxpr.constvars, jaxpr.freevars)
A:jax.interpreters.xla.in_nodes->map(read, eqn.invars)
A:jax.interpreters.xla.in_shapes->map(c.GetShape, in_nodes)
A:jax.interpreters.xla.ans->translation_rule(eqn.primitive)(c, *subfuns + in_nodes, **eqn.params)
A:jax.interpreters.xla.num_elements->len(c.GetShape(ans).tuple_shapes())
A:jax.interpreters.xla.backend_specific_rule->backend_specific_translations[xb._platform_name].get(p)
A:jax.interpreters.xla.xla_shapes->map(c.GetShape, xla_args)
A:jax.interpreters.xla.avals->map(aval_from_xla_shape, xla_shapes)
A:jax.interpreters.xla.(jaxpr, pvout, consts)->pe.trace_unwrapped_to_jaxpr(fun, pvals, **params)
A:jax.interpreters.xla.backend_specific_translations->defaultdict(dict)
A:jax.interpreters.xla.forward_to_value->partial(forward_method, '_value')
A:jax.interpreters.xla.self._npy_value->self.device_buffer.to_py()
A:jax.interpreters.xla.__array__->partialmethod(forward_to_value, onp.asarray)
A:jax.interpreters.xla.__str__->partialmethod(forward_to_value, str)
A:jax.interpreters.xla.__repr__->partialmethod(forward_to_value, repr)
A:jax.interpreters.xla.__bool____nonzero__->partialmethod(forward_to_value, bool)
A:jax.interpreters.xla.__float__->partialmethod(forward_to_value, float)
A:jax.interpreters.xla.__int__->partialmethod(forward_to_value, int)
A:jax.interpreters.xla.__long__->partialmethod(forward_to_value, long)
A:jax.interpreters.xla.__complex__->partialmethod(forward_to_value, complex)
A:jax.interpreters.xla.__hex__->partialmethod(forward_to_value, hex)
A:jax.interpreters.xla.__oct__->partialmethod(forward_to_value, oct)
A:jax.interpreters.xla.__reduce__->partialmethod(forward_to_value, op.methodcaller('__reduce__'))
A:jax.interpreters.xla.xla_const->const.constant_handler(c, const)
A:jax.interpreters.xla.jtuple_trees->tuple(map(partial(build_tree, iter(flat_args)), in_trees))
A:jax.interpreters.xla.aval->core.get_aval(maybe_tree)
A:jax.interpreters.xla.(ans_flat, out_tree)->tree_flatten(ans)
A:jax.interpreters.xla.(flat_children, child_specs)->unzip2(map(tree_flatten, maybe_tree))
A:jax.interpreters.xla.JTupleTreeDef->namedtuple('JTupleTreeDef', ['child_specs'])
A:jax.interpreters.xla.leaf->Leaf()
A:jax.interpreters.xla.(flat_args, in_trees)->unzip2(map(tree_flatten, args))
A:jax.interpreters.xla.flat_args->concatenate(flat_args)
A:jax.interpreters.xla.(fun, out_tree)->flatten_fun(fun, in_trees)
A:jax.interpreters.xla.flat_ans->compiled_fun(*flat_args)
A:jax.interpreters.xla.(jaxpr, (pval, consts, env))->pe.trace_to_subjaxpr(fun, master).call_wrapped(pvals)
A:jax.interpreters.xla.(compiled, result_shape)->compile_jaxpr(jaxpr, consts, *abstract_args)
A:jax.interpreters.xla.out_buf->lib.xla_bridge.make_computation_builder('constant_instantiating_computation').Build(xla_const).Compile((), xb.get_compile_options()).Execute(input_bufs, not core.skip_checks)
A:jax.interpreters.xla.xla_call_p->core.Primitive('xla_call')
A:jax.interpreters.xla.xla_call->partial(core.call_bind, xla_call_p)
A:jax.interpreters.xla.ad.primitive_transposes[xla_call_p]->partial(ad.call_transpose, xla_call_p)
jax.interpreters.xla.DeviceArray(self,device_buffer,shape,dtype,ndim,size)
jax.interpreters.xla.DeviceArray.__eq__(self,other)
jax.interpreters.xla.DeviceArray.__format__(self,format_spec)
jax.interpreters.xla.DeviceArray.__hash__(self)
jax.interpreters.xla.DeviceArray.__iter__(self)
jax.interpreters.xla.DeviceArray.__len__(self)
jax.interpreters.xla.DeviceArray.__reversed__(self)
jax.interpreters.xla.DeviceArray._value(self)
jax.interpreters.xla.DeviceArray.copy(self)
jax.interpreters.xla.DeviceConstant(DeviceArray)
jax.interpreters.xla.DeviceConstant.constant_handler(c,constant_instance,canonicalize_types=True)
jax.interpreters.xla.DeviceValue(self,device_buffer)
jax.interpreters.xla.Leaf(object)
jax.interpreters.xla.Leaf.__repr__(self)
jax.interpreters.xla.ResultArray(tuple)
jax.interpreters.xla.ResultTuple(tuple)
jax.interpreters.xla._device_array_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.xla.abstractify(x)
jax.interpreters.xla.abstractify_tuple(tup)
jax.interpreters.xla.apply_primitive(prim,*args,**kwargs)
jax.interpreters.xla.aval_from_xla_shape(shape)
jax.interpreters.xla.build_jaxpr(jaxpr,const_vals,*abstract_args)
jax.interpreters.xla.build_tree(xs,tree_spec)
jax.interpreters.xla.canonicalize_ndarray_dtype(x)
jax.interpreters.xla.canonicalize_pyval_dtype(x)
jax.interpreters.xla.canonicalize_tuple_dtype(tup)
jax.interpreters.xla.compile_jaxpr(jaxpr,const_vals,*abstract_args)
jax.interpreters.xla.device_put(x,device_num=0)
jax.interpreters.xla.execute_compiled(compiled,pval,handle_result,*args)
jax.interpreters.xla.execute_compiled_primitive(compiled,result_handler,*args)
jax.interpreters.xla.flatten_fun(in_trees,*flat_args)
jax.interpreters.xla.forward_method(attrname,self,fun,*args)
jax.interpreters.xla.identity(x)
jax.interpreters.xla.instantiate_device_constant(const,cutoff=1000000.0,device_num=0)
jax.interpreters.xla.jaxpr_computation(jaxpr,const_vals,freevar_shapes,*arg_shapes)
jax.interpreters.xla.lower_fun(fun,c,*xla_args,**params)
jax.interpreters.xla.primitive_computation(prim,*shapes,**kwargs)
jax.interpreters.xla.result_handler(result_shape)
jax.interpreters.xla.translation_rule(p)
jax.interpreters.xla.tree_flatten(maybe_tree)
jax.interpreters.xla.tuple_constant(c,val,canonicalize_types=True)
jax.interpreters.xla.xla_call_impl(fun,*args)
jax.interpreters.xla.xla_call_translation_rule(c,subc_a1,*a2)
jax.interpreters.xla.xla_callable(fun,*abstract_args)
jax.interpreters.xla.xla_destructure(c,ans)
jax.interpreters.xla.xla_primitive_callable(prim,*abstract_args,**kwargs)
jax.interpreters.xla.xla_shape(x)
jax.interpreters.xla.xla_shape_to_result_shape(xla_shape)
jax.interpreters.xla.zeros_like_translation_rule(c,x)

