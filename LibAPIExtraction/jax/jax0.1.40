
----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/api_util.py----------------------------------------
A:jax.api_util.fun.__name__->namestr.format(fun=get_name(wrapped))
A:jax.api_util.fun.__module__->get_module(wrapped)
A:jax.api_util.fun.__doc__->docstr.format(fun=get_name(wrapped), doc=get_doc(wrapped), **kwargs)
A:jax.api_util.py_args->map(tree_unflatten, in_trees, args)
A:jax.api_util.py_kwargs->build_tree(kwargs_tree, kwargs)
A:jax.api_util.(args, in_trees)->unzip2(map(pytree_to_jaxtupletree, py_args))
A:jax.api_util.ans->fun(*args)
A:jax.api_util.pytree_to_jaxtupletree->partial(process_pytree, pack)
A:jax.api_util.(py_args, py_kwargs)->tree_unflatten(in_tree, args_flat)
A:jax.api_util.(flat, out_tree)->tree_flatten(pytree)
A:jax.api_util.(flat_ans, out_tree)->tree_flatten(ans)
jax.api_util.abstract_tuple_tree_leaves(aval)
jax.api_util.apply_jaxtree_fun(fun,io_tree,*py_args)
jax.api_util.flatten_fun(in_tree,*args_flat)
jax.api_util.flatten_fun_leafout(in_tree,*args_flat)
jax.api_util.get_doc(fun)
jax.api_util.get_module(fun)
jax.api_util.get_name(fun)
jax.api_util.pytree_fun_to_flatjaxtuple_fun(in_trees,*args)
jax.api_util.pytree_fun_to_jaxtupletree_fun(args_trees,*args)
jax.api_util.pytree_fun_to_jaxtupletree_fun2(kwargs_tree,args_trees,kwargs,*args)
jax.api_util.pytree_to_flatjaxtuple(pytree)
jax.api_util.wraps(wrapped,fun,namestr='{fun}',docstr='{doc}',**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/flatten_util.py----------------------------------------
A:jax.flatten_util.(leaves, treedef)->tree_flatten(pytree)
A:jax.flatten_util.(flat, unravel_list)->vjp(ravel_list, *leaves)
A:jax.flatten_util.pytree_args->unravel_inputs(flat_in)
jax.flatten_util.ravel_fun(unravel_inputs,flat_in,**kwargs)
jax.flatten_util.ravel_list(*lst)
jax.flatten_util.ravel_pytree(pytree)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/core.py----------------------------------------
A:jax.core.arg_aval->get_aval(arg)
A:jax.core.out->eval_jaxpr(typed_jaxpr.jaxpr, typed_jaxpr.literals, (), *args)
A:jax.core.out_aval->get_aval(out)
A:jax.core.JaxprEqn->namedtuple('JaxprEqn', ['invars', 'outvars', 'primitive', 'bound_subjaxprs', 'restructure', 'destructure', 'params'])
A:jax.core.self.hash->hash((val.item(), val.dtype))
A:jax.core.literalable_types->set()
A:jax.core.top_trace->find_top_trace(args)
A:jax.core.tracers->map(top_trace.full_raise, args)
A:jax.core.out_tracer->find_top_trace(args).process_primitive(self, tracers, kwargs)
A:jax.core.in_vals->map(read, eqn.invars)
A:jax.core.subfuns->map(lu.wrap_init, subfuns)
A:jax.core.ans->full_lower(top_trace.process_call(primitive, f, tracers, params))
A:jax.core.attr->getattr(self.aval, name)
A:jax.core.t->ref(sublevel)
A:jax.core.aval_property->namedtuple('aval_property', ['fget'])
A:jax.core.aval_method->namedtuple('aval_method', ['fun'])
A:jax.core.trace_stack->TraceStack()
A:jax.core.level->TraceStack().next_level(bottom)
A:jax.core.master->MasterTrace(level, trace_type)
A:jax.core.sublevel->cur_sublevel()
A:jax.core.bot->Bot()
A:jax.core.self.xsxs->tuple(xs)
A:jax.core.xs->tuple(xs)
A:jax.core.unit->JaxTuple(())
A:jax.core.identity_p->Primitive('id')
A:jax.core.pack_p->Primitive('pack')
A:jax.core.x->full_lower(todos.pop()(x))
A:jax.core.trace->type(t)(t.master, sublevel)
A:jax.core.(ans, cur_todo)->full_lower(top_trace.process_call(primitive, f, tracers, params)).trace.post_process_call(primitive, ans, dict(params_tuple))
A:jax.core.params_tuple->tuple(params.items())
A:jax.core.(f, env_trace_todo)->process_env_traces(f, primitive, level, params_tuple)
A:jax.core.call_p->Primitive('call')
A:jax.core.call->partial(call_bind, call_p)
A:jax.core.env->set()
A:jax.core.read->partial(read_env, env)
A:jax.core.write->partial(write_env, env)
A:jax.core.pp_subexpr->pp('')
jax.core.AbstractTuple(cls,xs=())
jax.core.AbstractTuple.__new__(cls,xs=())
jax.core.AbstractTuple.__repr__(self)
jax.core.AbstractTuple._bool(self,ignored_tracer)
jax.core.AbstractTuple._eq(self,self_traced,other)
jax.core.AbstractTuple._iter(tracer)
jax.core.AbstractTuple._len(self,ignored_tracer)
jax.core.AbstractTuple.at_least_vspace(self)
jax.core.AbstractTuple.join(self,other)
jax.core.AbstractValue(object)
jax.core.AbstractValue.__repr__(self)
jax.core.AbstractValue.at_least_vspace(self)
jax.core.Bot(AbstractValue)
jax.core.JaxTuple(self,xs)
jax.core.JaxTuple.__eq__(self,other)
jax.core.JaxTuple.__init__(self,xs)
jax.core.JaxTuple.__iter__(self)
jax.core.JaxTuple.__len__(self)
jax.core.JaxTuple.__repr__(self)
jax.core.Jaxpr(self,constvars,freevars,invars,outvar,eqns)
jax.core.Jaxpr.__init__(self,constvars,freevars,invars,outvar,eqns)
jax.core.Jaxpr.__repr__(self)
jax.core.Jaxpr.__str__(self)
jax.core.Jaxpr.copy(self)
jax.core.Literal(self,val)
jax.core.Literal.__eq__(self,other)
jax.core.Literal.__hash__(self)
jax.core.Literal.__init__(self,val)
jax.core.Literal.__repr__(self)
jax.core.MasterTrace(self,level,trace_type)
jax.core.MasterTrace.__eq__(self,other)
jax.core.MasterTrace.__hash__(self)
jax.core.MasterTrace.__init__(self,level,trace_type)
jax.core.MasterTrace.__repr__(self)
jax.core.Primitive(self,name)
jax.core.Primitive.__init__(self,name)
jax.core.Primitive.__repr__(self)
jax.core.Primitive.abstract_eval(self,*args,**kwargs)
jax.core.Primitive.bind(self,*args,**kwargs)
jax.core.Primitive.def_abstract_eval(self,abstract_eval)
jax.core.Primitive.def_custom_bind(self,bind)
jax.core.Primitive.def_impl(self,impl)
jax.core.Primitive.impl(self,*args,**kwargs)
jax.core.Sublevel(int)
jax.core.Trace(self,master,sublevel)
jax.core.Trace.__init__(self,master,sublevel)
jax.core.Trace.__repr__(self)
jax.core.Trace.full_raise(self,val)
jax.core.Trace.lift(self,tracer)
jax.core.Trace.pure(self,val)
jax.core.Trace.sublift(self,tracer)
jax.core.TraceStack(self)
jax.core.TraceStack.__init__(self)
jax.core.TraceStack.__repr__(self)
jax.core.TraceStack.next_level(self,bottom)
jax.core.TraceStack.pop(self,bottom)
jax.core.TraceStack.push(self,val,bottom)
jax.core.Tracer(self,trace)
jax.core.Tracer.__abs__(self)
jax.core.Tracer.__add__(self,other)
jax.core.Tracer.__and__(self,other)
jax.core.Tracer.__array__(self)
jax.core.Tracer.__bool__(self)
jax.core.Tracer.__complex__(self)
jax.core.Tracer.__div__(self,other)
jax.core.Tracer.__divmod__(self,other)
jax.core.Tracer.__eq__(self,other)
jax.core.Tracer.__float__(self)
jax.core.Tracer.__floordiv__(self,other)
jax.core.Tracer.__ge__(self,other)
jax.core.Tracer.__getattr__(self,name)
jax.core.Tracer.__getitem__(self,idx)
jax.core.Tracer.__gt__(self,other)
jax.core.Tracer.__hex__(self)
jax.core.Tracer.__init__(self,trace)
jax.core.Tracer.__int__(self)
jax.core.Tracer.__invert__(self)
jax.core.Tracer.__iter__(self)
jax.core.Tracer.__le__(self,other)
jax.core.Tracer.__len__(self)
jax.core.Tracer.__long__(self)
jax.core.Tracer.__lshift__(self,other)
jax.core.Tracer.__lt__(self,other)
jax.core.Tracer.__matmul__(self,other)
jax.core.Tracer.__mod__(self,other)
jax.core.Tracer.__mul__(self,other)
jax.core.Tracer.__ne__(self,other)
jax.core.Tracer.__neg__(self)
jax.core.Tracer.__nonzero__(self)
jax.core.Tracer.__oct__(self)
jax.core.Tracer.__or__(self,other)
jax.core.Tracer.__pow__(self,other)
jax.core.Tracer.__radd__(self,other)
jax.core.Tracer.__rand__(self,other)
jax.core.Tracer.__rdiv__(self,other)
jax.core.Tracer.__rdivmod__(self,other)
jax.core.Tracer.__repr__(self)
jax.core.Tracer.__rfloordiv__(self,other)
jax.core.Tracer.__rmatmul__(self,other)
jax.core.Tracer.__rmod__(self,other)
jax.core.Tracer.__rmul__(self,other)
jax.core.Tracer.__ror__(self,other)
jax.core.Tracer.__rpow__(self,other)
jax.core.Tracer.__rshift__(self,other)
jax.core.Tracer.__rsub__(self,other)
jax.core.Tracer.__rtruediv__(self,other)
jax.core.Tracer.__rxor__(self,other)
jax.core.Tracer.__setitem__(self,idx,val)
jax.core.Tracer.__sub__(self,other)
jax.core.Tracer.__truediv__(self,other)
jax.core.Tracer.__xor__(self,other)
jax.core.Tracer.aval(self)
jax.core.TypedJaxpr(self,jaxpr,literals,in_avals,out_aval)
jax.core.TypedJaxpr.__init__(self,jaxpr,literals,in_avals,out_aval)
jax.core.TypedJaxpr.__iter__(self)
jax.core.TypedJaxpr.__repr__(self)
jax.core.TypedJaxpr.__str__(self)
jax.core._TupleMeta(type(tuple))
jax.core._TupleMeta.__instancecheck__(self,instance)
jax.core.apply_todos(todos,x)
jax.core.call_bind(primitive,f,*args,**params)
jax.core.call_impl(f,*args,**params)
jax.core.check_jaxpr(jaxpr)
jax.core.concrete_aval(x)
jax.core.concrete_jaxtuple(xs)
jax.core.cur_sublevel()
jax.core.eval_jaxpr(jaxpr,consts,freevar_vals,*args)
jax.core.find_top_trace(xs)
jax.core.full_lower(val)
jax.core.get_aval(x)
jax.core.jaxpr_as_fun(typed_jaxpr,*args)
jax.core.lattice_join(x,y)
jax.core.new_master(trace_type,bottom=False)
jax.core.new_sublevel()
jax.core.pack(args)
jax.core.pack_p_bind(*args)
jax.core.pat_fmap(f,v,*xs)
jax.core.pp_jaxpr(jaxpr)
jax.core.process_env_traces(primitive,level,params_tuple,*args)
jax.core.tuple_to_jaxtuple(x)
jax.core.valid_jaxtype(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/pprint_util.py----------------------------------------
A:jax.pprint_util.indented_block->rhs.indent(indent + len(s))
A:jax.pprint_util.kv_pairs->vcat([pp('{}='.format(k)) >> pp(v) for (k, v) in kv_pairs])
jax.pprint_util.PrettyPrint(self,lines)
jax.pprint_util.PrettyPrint.__add__(self,rhs)
jax.pprint_util.PrettyPrint.__init__(self,lines)
jax.pprint_util.PrettyPrint.__rshift__(self,rhs)
jax.pprint_util.PrettyPrint.__str__(self)
jax.pprint_util.PrettyPrint.indent(self,indent)
jax.pprint_util.hcat(ps)
jax.pprint_util.pp(s)
jax.pprint_util.pp_kv_pairs(kv_pairs)
jax.pprint_util.print_list(xs)
jax.pprint_util.vcat(ps)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/api.py----------------------------------------
A:jax.api.f->lu.wrap_init(fun)
A:jax.api.(f, dyn_args)->_argnums_partial(f, dyn_argnums, args)
A:jax.api.(args_flat, in_tree)->tree_flatten((args, kwargs))
A:jax.api.(flat_fun, out_tree)->flatten_fun_leafout(f, in_tree)
A:jax.api.out->interpreters.partial_eval.abstract_eval_fun(f.call_wrapped, *abstract_args)
A:jax.api.f_jitted.__name__->jitted_name.format(f_jitted.__name__, static_argnums)
A:jax.api.aval->interpreters.xla.abstractify(x)
A:jax.api.wrapped->lu.wrap_init(fun, kwargs)
A:jax.api.(jax_args, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.(jaxtree_fun, out_tree)->pytree_fun_to_jaxtupletree_fun(wrapped, in_trees)
A:jax.api.pvals->map(pv_like, jax_args)
A:jax.api.(jaxpr, _, consts)->interpreters.partial_eval.trace_to_jaxpr(jaxtree_fun, pvals)
A:jax.api.axis_env_->make_axis_env(xla.jaxpr_replicas(jaxpr))
A:jax.api.(jax_kwargs, kwargs_tree)->pytree_to_jaxtupletree(kwargs)
A:jax.api.value_and_grad_f->value_and_grad(fun, argnums, has_aux=has_aux, holomorphic=holomorphic)
A:jax.api.(_, g)->value_and_grad_f(*args, **kwargs)
A:jax.api.((_, aux), g)->value_and_grad_f(*args, **kwargs)
A:jax.api.(f_partial, dyn_args)->_argnums_partial(f, argnums, args)
A:jax.api.(ans, vjp_py)->vjp(f_partial, *dyn_args)
A:jax.api.(ans, vjp_py, aux)->vjp(f_partial, *dyn_args, has_aux=True)
A:jax.api.dtype->numpy.result_type(*leaves)
A:jax.api.g->vjp_py(onp.ones((), dtype=dtype))
A:jax.api.pushfwd->partial(jvp, fun, primals)
A:jax.api.(y, jac)->vmap(pushfwd, out_axes=(None, -1))(_std_basis(dyn_args))
A:jax.api.(y, pullback)->vjp(f_partial, *dyn_args)
A:jax.api.jac->tree_map(partial(_unravel_array_into_pytree, y, 0), jac)
A:jax.api.(leaves, _)->tree_flatten(pytree)
A:jax.api.ndim->sum(map(onp.size, leaves))
A:jax.api.flat_basis->numpy.eye(ndim, dtype=dtype)
A:jax.api.(leaves, treedef)->tree_flatten(pytree)
A:jax.api.parts->_split(arr, onp.cumsum(map(onp.size, leaves[:-1])), axis)
A:jax.api.(in_flat, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.out_flat->interpreters.parallel.papply(jaxtree_fun, axis_name, args_flat, axis_size)
A:jax.api.axis_size->_pmap_axis_size(args)
A:jax.api.f_pmapped.__name__->namestr(f_pmapped.__name__, axis_name)
A:jax.api.(chunk_size, leftover)->divmod(axis_size, pxla.unmapped_device_count())
A:jax.api.reshaped_args->map(partial(_reshape_split, num_chunks), in_flat)
A:jax.api.soft_mapped_fun->interpreters.pxla.split_axis(jaxtree_fun, axis_name, chunk_size)
A:jax.api.reshaped_out->interpreters.pxla.xla_pmap(soft_mapped_fun, *reshaped_args, axis_name=axis_name, axis_size=num_chunks)
A:jax.api.t->type(aval)
A:jax.api.axis_name->_TempAxisName()
A:jax.api.(args_flat, in_trees)->unzip2(map(pytree_to_jaxtupletree, args))
A:jax.api.args_flat->map(partial(_reshape_split, num_chunks), args_flat)
A:jax.api.(f, out_tree)->pytree_fun_to_jaxtupletree_fun2(lu.wrap_init(fun), kwargs_tree, in_trees)
A:jax.api.(f, out_axis)->interpreters.parallel.papply_transform(f, axis_name, axis_size)
A:jax.api.(primal_jtuple, tree_def)->pytree_to_jaxtupletree(primal)
A:jax.api.(tangent_jtuple, tree_def_2)->pytree_to_jaxtupletree(tangent)
A:jax.api.fun->lu.wrap_init(traceable, kwargs)
A:jax.api.(ps_flat, ts_flat, in_trees)->unzip3(map(trim_arg, primals, tangents))
A:jax.api.(out_primal, out_tangent)->interpreters.ad.jvp(jaxtree_fun).call_wrapped(ps_flat, ts_flat)
A:jax.api.(primals_flat, in_trees)->unzip2(map(pytree_to_jaxtupletree, primals))
A:jax.api.(out_primal, out_pval, jaxpr, consts)->interpreters.ad.linearize(jaxtree_fun, *primals_flat)
A:jax.api.out_tree->out_tree()
A:jax.api.out_primal_py->build_tree(out_tree, out_primal)
A:jax.api.primal_avals->list(map(core.get_aval, primals_flat))
A:jax.api.lifted_jvp->partial(lift_linearized, jaxpr, primal_avals, consts, (in_trees, out_tree), out_pval)
A:jax.api.tangent_avals->list(map(core.get_aval, tangents))
A:jax.api.primals->pack(tangents)
A:jax.api.tangents->pack(tangents)
A:jax.api.(_, ans)->eval_jaxpr(jaxpr, consts, (), primals, tangents)
A:jax.api.has_aux->kwargs.pop('has_aux', False)
A:jax.api.(out_primal, out_vjp)->interpreters.ad.vjp(jaxtree_fun, primals_flat)
A:jax.api.(out_primal, out_vjp, aux)->interpreters.ad.vjp(jaxtree_fun, primals_flat, has_aux=True)
A:jax.api.(out_tree, aux_tree)->treedef_children(out_tree)
A:jax.api.ct_out_tree->treedef_tuple(in_trees)
A:jax.api.vjp_py->partial(apply_jaxtree_fun, out_vjp_packed, (ct_in_trees, ct_out_tree))
A:jax.api.(pvals, in_trees)->unzip2(map(tree_to_pval_tuples, py_pvals))
A:jax.api.(jaxpr, out_pval, consts)->interpreters.partial_eval.trace_to_jaxpr(jaxtree_fun, pvals)
A:jax.api.ans->fun(*primals)
A:jax.api.(jaxpr, _, _)->interpreters.partial_eval.trace_to_jaxpr(jaxtree_fun, pvals)
A:jax.api.jaxpr_maker.__name__->'make_jaxpr({})'.format(jaxpr_maker.__name__)
A:jax.api.tree_to_pval_tuples->partial(process_pytree, pe.pack_pvals)
A:jax.api.dyn_argnums->tuple(dyn_argnums)
A:jax.api.fixed_args->tuple([None if i in dyn_argnums else _wrap_hashably(arg) for (i, arg) in enumerate(args)])
A:jax.api.dyn_args->tuple((args[i] for i in dyn_argnums))
A:jax.api.pvals_in->map(pv_like, (jax_kwargs,) + jax_args)
A:jax.api.name->getattr(fun, '__name__', '<unnamed custom_transforms primitive>')
A:jax.api.fun_p->core.Primitive(name)
A:jax.api.args->map(build_tree, params['in_trees'], jax_args)
A:jax.api.args_dot->tuple(map(build_tree, in_trees, jax_args_dot))
A:jax.api.(pytree_out, pytree_out_dot)->custom_jvp(args, args_dot)
A:jax.api.(out, out_tree)->pytree_to_jaxtupletree(pytree_out)
A:jax.api.(out_dot, out_tree2)->pytree_to_jaxtupletree(pytree_out_dot)
A:jax.api.(pytree_out, vjp_pytree)->custom_vjp(*args)
A:jax.api.args_cts->tuple(vjp_pytree(ct))
A:jax.api.(vjp, _)->pytree_fun_to_jaxtupletree_fun(lu.wrap_init(vjp_pytree_), (out_tree,))
A:jax.api.(ans, _)->fun(*args, **kwargs)
A:jax.api.primal_fun->custom_transforms(primal_fun)
A:jax.api.new_fun->custom_transforms(fun)
A:jax.api.(y, jacs)->vmap(pushfwd, out_axes=(None, 0))(_elementwise_std_basis(tangents))
A:jax.api.(flat_tangents, _)->tree_flatten(tangents)
A:jax.api.out_tangent->sum([t * jac for (t, jac) in zip(flat_tangents, jacs)])
A:jax.api.arity->len(leaves)
A:jax.api.dims->map(onp.size, leaves)
A:jax.api.basis_array->numpy.stack([onp.concatenate([onp.ones(dims[j], dtype) if i == j else onp.zeros(dims[j], dtype) for j in range(arity)]) for i in range(arity)])
A:jax.api.id_name->next(id_names)
A:jax.api.graphviz_maker.__name__->'make_graphviz({})'.format(graphviz_maker.__name__)
A:jax.api.abstract_args->map(abstractify, (jax_kwargs,) + tuple(jax_args))
jax.CustomTransformsFunction(self,fun,prim)
jax.CustomTransformsFunction.__repr__(self)
jax._TempAxisName(object)
jax._TempAxisName.__repr__(self)
jax._argnums_partial(f,dyn_argnums,args)
jax._argnums_partial_(dyn_argnums,fixed_args,*dyn_args,**kwargs)
jax._axis_size(x)
jax._check_args(args)
jax._check_callable(fun)
jax._check_custom_transforms_type(name,fun)
jax._check_inexact_input_vjp(x)
jax._check_real_input_jacfwd(x)
jax._check_real_output_jacrev(x)
jax._check_scalar(x)
jax._device_get(x)
jax._dtype(x)
jax._elementwise_std_basis(pytree)
jax._jit(fun,static_argnums,device_assignment,device_values=True)
jax._make_graphviz(fun)
jax._papply(fun)
jax._parallelize(fun)
jax._pmap_axis_size(args)
jax._reshape_merge(ans)
jax._reshape_split(num_chunks,arg)
jax._split(x,indices,axis)
jax._std_basis(pytree)
jax._unravel_array_into_pytree(pytree,axis,arr)
jax._valid_jaxtype(arg)
jax._wrap_hashably(arg)
jax.api.CustomTransformsFunction(self,fun,prim)
jax.api.CustomTransformsFunction.__init__(self,fun,prim)
jax.api.CustomTransformsFunction.__repr__(self)
jax.api._TempAxisName(object)
jax.api._TempAxisName.__repr__(self)
jax.api._argnums_partial(f,dyn_argnums,args)
jax.api._argnums_partial_(dyn_argnums,fixed_args,*dyn_args,**kwargs)
jax.api._axis_size(x)
jax.api._check_args(args)
jax.api._check_callable(fun)
jax.api._check_custom_transforms_type(name,fun)
jax.api._check_inexact_input_vjp(x)
jax.api._check_real_input_jacfwd(x)
jax.api._check_real_output_jacrev(x)
jax.api._check_scalar(x)
jax.api._device_get(x)
jax.api._dtype(x)
jax.api._elementwise_std_basis(pytree)
jax.api._jit(fun,static_argnums,device_assignment,device_values=True)
jax.api._make_graphviz(fun)
jax.api._papply(fun)
jax.api._parallelize(fun)
jax.api._pmap_axis_size(args)
jax.api._reshape_merge(ans)
jax.api._reshape_split(num_chunks,arg)
jax.api._split(x,indices,axis)
jax.api._std_basis(pytree)
jax.api._unravel_array_into_pytree(pytree,axis,arr)
jax.api._valid_jaxtype(arg)
jax.api._wrap_hashably(arg)
jax.api.custom_gradient(fun)
jax.api.custom_transforms(fun)
jax.api.defjvp(fun,*jvprules)
jax.api.defjvp_all(fun,custom_jvp)
jax.api.defvjp(fun,*vjprules)
jax.api.defvjp_all(fun,custom_vjp)
jax.api.device_get(x)
jax.api.device_put(x,device_num=0)
jax.api.disable_jit()
jax.api.eval_shape(fun,*args,**kwargs)
jax.api.grad(fun,argnums=0,has_aux=False,holomorphic=False)
jax.api.hessian(fun,argnums=0,holomorphic=False)
jax.api.jacfwd(fun,argnums=0,holomorphic=False)
jax.api.jacrev(fun,argnums=0,holomorphic=False)
jax.api.jarrett(fun)
jax.api.jit(fun,static_argnums=(),device_assignment=None)
jax.api.jvp(fun,primals,tangents)
jax.api.lift_jaxpr(jaxpr,consts,io_tree,pvals,py_args)
jax.api.lift_linearized(jaxpr,primal_avals,consts,io_tree,out_pval,*py_args)
jax.api.linearize(fun,*primals)
jax.api.make_jaxpr(fun)
jax.api.pmap(fun,axis_name=None)
jax.api.soft_pmap(fun,axis_name=None)
jax.api.trace_to_jaxpr(traceable,py_pvals,**kwargs)
jax.api.value_and_grad(fun,argnums=0,has_aux=False,holomorphic=False)
jax.api.vjp(fun,*primals,**kwargs)
jax.api.vmap(fun,in_axes=0,out_axes=0)
jax.api.xla_computation(fun,static_argnums=(),axis_env=None)
jax.custom_gradient(fun)
jax.custom_transforms(fun)
jax.defjvp(fun,*jvprules)
jax.defjvp_all(fun,custom_jvp)
jax.defvjp(fun,*vjprules)
jax.defvjp_all(fun,custom_vjp)
jax.device_get(x)
jax.device_put(x,device_num=0)
jax.disable_jit()
jax.eval_shape(fun,*args,**kwargs)
jax.grad(fun,argnums=0,has_aux=False,holomorphic=False)
jax.hessian(fun,argnums=0,holomorphic=False)
jax.jacfwd(fun,argnums=0,holomorphic=False)
jax.jacrev(fun,argnums=0,holomorphic=False)
jax.jarrett(fun)
jax.jit(fun,static_argnums=(),device_assignment=None)
jax.jvp(fun,primals,tangents)
jax.lift_jaxpr(jaxpr,consts,io_tree,pvals,py_args)
jax.lift_linearized(jaxpr,primal_avals,consts,io_tree,out_pval,*py_args)
jax.linearize(fun,*primals)
jax.make_jaxpr(fun)
jax.pmap(fun,axis_name=None)
jax.soft_pmap(fun,axis_name=None)
jax.trace_to_jaxpr(traceable,py_pvals,**kwargs)
jax.value_and_grad(fun,argnums=0,has_aux=False,holomorphic=False)
jax.vjp(fun,*primals,**kwargs)
jax.vmap(fun,in_axes=0,out_axes=0)
jax.xla_computation(fun,static_argnums=(),axis_env=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax_reference.py----------------------------------------
A:jax.lax_reference.quotient->numpy.floor_divide(lhs, rhs)
A:jax.lax_reference.select->numpy.logical_and(onp.sign(lhs) != onp.sign(rhs), onp.remainder(lhs, rhs) != 0)
A:jax.lax_reference.pads->padtype_to_pads(op.shape, dims, strides, padding)
A:jax.lax_reference.(lhs_perm, rhs_perm, out_perm)->_conv_general_permutations(dimension_numbers)
A:jax.lax_reference.padding->padtype_to_pads(onp.take(lhs.shape, lhs_perm)[2:], onp.take(rhs.shape, rhs_perm)[2:], window_strides, padding)
A:jax.lax_reference.trans_lhs->transpose(lhs, lhs_perm)
A:jax.lax_reference.trans_rhs->transpose(rhs, rhs_perm)
A:jax.lax_reference.out->numpy.zeros(operand.shape[:2] + tuple(outspace), operand.dtype)
A:jax.lax_reference.new_id->itertools.count()
A:jax.lax_reference.shared_id->next(new_id)
A:jax.lax_reference.out_axis_ids->filter(not_none, batch_ids + lhs_out_axis_ids + rhs_out_axis_ids)
A:jax.lax_reference.inshape->tuple((1 if i not in broadcast_dimensions else d for (i, d) in enumerate(shape)))
A:jax.lax_reference.dimensions->frozenset(dimensions)
A:jax.lax_reference.(lo, hi, interior)->zip(*padding_config)
A:jax.lax_reference.outshape->numpy.add(onp.add(onp.add(lo, hi), operand.shape), onp.multiply(interior, onp.subtract(operand.shape, 1)))
A:jax.lax_reference.lhs_slices->tuple((_slice(None, None, step) for step in factors))
A:jax.lax_reference.rhs_slices->tuple((_slice(l if l < 0 else 0, -h if h < 0 else None) for (l, h) in zip(lo, hi)))
A:jax.lax_reference.strides->numpy.ones(len(start_indices)).astype(int)
A:jax.lax_reference.slices->tuple((_slice(abs(lo) if lo < 0 else 0, hi % dim if hi < 0 else None) for ((lo, hi), dim) in zip(pads, onp.shape(arr))))
A:jax.lax_reference.idx->tuple((_slice(start, start + size) for (start, size) in zip(start_indices, slice_sizes)))
A:jax.lax_reference.updated_operand->numpy.copy(operand)
A:jax.lax_reference.reducer->_make_reducer(computation, init_value)
A:jax.lax_reference.view->numpy.lib.stride_tricks.as_strided(lhs, view_shape, view_strides)
A:jax.lax_reference.idxs->list(onp.ix_(*[onp.arange(d) for d in keys.shape]))
A:jax.lax_reference.idxs[dimension]->numpy.argsort(keys, axis=dimension)
A:jax.lax_reference.(view, view_axes, rhs_axes, out_axes)->_conv_view(lhs, rhs.shape, window_strides, pads, 0.0)
A:jax.lax_reference.out_shape->numpy.ceil(onp.true_divide(in_shape, window_strides)).astype(int)
A:jax.lax_reference.lhs->_pad(lhs, [(0, 0)] * 2 + list(pads), pad_value)
A:jax.lax_reference.dim->len(filter_shape)
A:jax.lax_reference.out_strides->numpy.multiply(window_strides, lhs.strides[2:])
A:jax.lax_reference.view_axes->list(range(view.ndim))
A:jax.lax_reference.outspace->numpy.add(operand.shape[2:], onp.multiply(onp.subtract(factors, 1), onp.subtract(operand.shape[2:], 1)))
A:jax.lax_reference.monoid_record->_monoids.get(getattr(py_binop, '__name__'))
A:jax.lax_reference.MonoidRecord->collections.namedtuple('MonoidRecord', ['reducer', 'identity'])
A:jax.lax_reference.result->numpy.full(onp.delete(onp.shape(operand), axis), init_val, dtype=onp.asarray(operand).dtype)
A:jax.lax_reference.out_idx->tuple(onp.delete(idx, axis))
A:jax.lax_reference.result[out_idx]->py_binop(result[out_idx], operand[idx])
jax.lax_reference._conv(lhs,rhs,window_strides,pads)
jax.lax_reference._conv_general_permutations(dimension_numbers)
jax.lax_reference._conv_view(lhs,rhs_shape,window_strides,pads,pad_value)
jax.lax_reference._dilate(operand,factors)
jax.lax_reference._get_max_identity(dt)
jax.lax_reference._get_min_identity(dt)
jax.lax_reference._identity_getter(op)
jax.lax_reference._make_reducer(py_binop,init_val)
jax.lax_reference._pad(arr,pads,pad_value)
jax.lax_reference._reducer_from_pyfunc(py_binop,init_val)
jax.lax_reference.bitcast_convert_type(operand,dtype)
jax.lax_reference.broadcast(operand,sizes)
jax.lax_reference.broadcast_in_dim(operand,shape,broadcast_dimensions)
jax.lax_reference.clamp(min,operand,max)
jax.lax_reference.complex(x,y)
jax.lax_reference.concatenate(operands,dimension)
jax.lax_reference.conj(x)
jax.lax_reference.conv(lhs,rhs,window_strides,padding)
jax.lax_reference.conv_general_dilated(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers)
jax.lax_reference.conv_with_general_padding(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation)
jax.lax_reference.convert_element_type(operand,dtype)
jax.lax_reference.div(lhs,rhs)
jax.lax_reference.dot_general(lhs,rhs,dimension_numbers)
jax.lax_reference.dynamic_slice(operand,start_indices,slice_sizes)
jax.lax_reference.dynamic_update_slice(operand,update,start_indices)
jax.lax_reference.pad(operand,padding_value,padding_config)
jax.lax_reference.padtype_to_pads(in_shape,filter_shape,window_strides,padding)
jax.lax_reference.reduce(operand,init_value,computation,dimensions)
jax.lax_reference.reduce_window(operand,init_value,computation,window_dimensions,window_strides,padding)
jax.lax_reference.rem(lhs,rhs)
jax.lax_reference.reshape(operand,new_sizes,dimensions=None)
jax.lax_reference.rev(operand,dimensions)
jax.lax_reference.slice(operand,start_indices,limit_indices,strides=None)
jax.lax_reference.sort_key_val(keys,values,dimension=-1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/version.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax_linalg.py----------------------------------------
A:jax.lax_linalg.x->jax.interpreters.batching.bdim_at_front(x, bd)
A:jax.lax_linalg.(w, vl, vr)->Primitive('eig').bind(x)
A:jax.lax_linalg.(v, w)->Primitive('eigh').bind(symmetrize(a), lower=lower)
A:jax.lax_linalg.(lu, pivots)->Primitive('lu').bind(a)
A:jax.lax_linalg.(q, r)->Primitive('qr').bind(x, full_matrices=False)
A:jax.lax_linalg.(s, u, v)->Primitive('svd').bind(x, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax.lax_linalg.t->f(c, *args, **kwargs)
A:jax.lax_linalg.L->jax.numpy.lax_numpy.tril(cholesky_p.bind(x))
A:jax.lax_linalg.l->jax.lax.pad(np.tril(lu[..., :, :k], -1), zero, l_padding)
A:jax.lax_linalg.tmp->triangular_solve(a, g_a, left_side, lower, transpose_a, conjugate_a, unit_diagonal)
A:jax.lax_linalg.L_dot->jax.lax.batch_matmul(L, phi(triangular_solve(L, tmp, left_side=True, transpose_a=False, lower=True)))
A:jax.lax_linalg.cholesky_p->standard_unop(_float | _complex, 'cholesky')
A:jax.lax_linalg.shape->c.GetShape(operand)
A:jax.lax_linalg.dtype->jax.lax.dtype(a)
A:jax.lax_linalg.nan->c.Constant(onp.array(onp.nan, dtype=dtype))
A:jax.lax_linalg._cpu_potrf->_unpack_tuple(lapack.jax_potrf, 2)
A:jax.lax_linalg.(result, info)->_cpu_potrf(c, operand, lower=True)
A:jax.lax_linalg.vlvr->ShapedArray(batch_dims + (n, n), operand.dtype)
A:jax.lax_linalg.w->w.astype(a.dtype).astype(a.dtype)
A:jax.lax_linalg._cpu_geev->_unpack_tuple(lapack.jax_geev, 4)
A:jax.lax_linalg.(w, vl, vr, info)->_cpu_geev(c, operand)
A:jax.lax_linalg.ok->c.Eq(info, c.ConstantS32Scalar(0))
A:jax.lax_linalg.vl->_broadcasting_select(c, c.Reshape(ok, None, batch_dims + (1, 1)), vl, _nan_like(c, vl))
A:jax.lax_linalg.vr->_broadcasting_select(c, c.Reshape(ok, None, batch_dims + (1, 1)), vr, _nan_like(c, vr))
A:jax.lax_linalg.eig_p->Primitive('eig')
A:jax.lax_linalg.v->_broadcasting_select(c, c.Reshape(ok, None, batch_dims + (1, 1)), v, _nan_like(c, v))
A:jax.lax_linalg.(v, w, info)->syevd_impl(c, operand, lower=lower)
A:jax.lax_linalg.eye_n->jax.numpy.lax_numpy.eye(a.shape[-1], dtype=a.dtype)
A:jax.lax_linalg.vdag_adot_v->dot(dot(_H(v), a_dot), v)
A:jax.lax_linalg.dv->dot(v, np.multiply(Fmat, vdag_adot_v))
A:jax.lax_linalg.dw->jax.numpy.lax_numpy.diagonal(vdag_adot_v)
A:jax.lax_linalg.eigh_p->Primitive('eigh')
A:jax.lax_linalg._cpu_syevd->_unpack_tuple(lapack.jax_syevd, 3)
A:jax.lax_linalg.xla.backend_specific_translations['cpu'][eigh_p]->partial(_eigh_cpu_gpu_translation_rule, _cpu_syevd)
A:jax.lax_linalg.xla.backend_specific_translations['gpu'][eigh_p]->partial(_eigh_cpu_gpu_translation_rule, cusolver.syevd)
A:jax.lax_linalg.triangular_solve_dtype_rule->partial(binop_dtype_rule, _input_dtype, (_float | _complex, _float | _complex), 'triangular_solve')
A:jax.lax_linalg.g_a->jax.lax.neg(g_a)
A:jax.lax_linalg.cotangent_b->triangular_solve(a, cotangent, left_side, lower, not transpose_a, conjugate_a, unit_diagonal)
A:jax.lax_linalg.size->next((t.shape[i] for (t, i) in zip(batched_args, batch_dims) if i is not None))
A:jax.lax_linalg.y->jax.interpreters.batching.bdim_at_front(y, by, size, force_broadcast=True)
A:jax.lax_linalg.triangular_solve_p->standard_primitive(triangular_solve_shape_rule, triangular_solve_dtype_rule, 'triangular_solve')
A:jax.lax_linalg.a->jax.numpy.lax_numpy.where(error, lax.full_like(a, np.nan), a)
A:jax.lax_linalg.m_idx->jax.numpy.lax_numpy.arange(m)
A:jax.lax_linalg.n_idx->jax.numpy.lax_numpy.arange(n)
A:jax.lax_linalg.magnitude->jax.numpy.lax_numpy.abs(a[:, k])
A:jax.lax_linalg.i->jax.numpy.lax_numpy.argmax(np.where(m_idx >= k, magnitude, -np.inf))
A:jax.lax_linalg.pivot->c.Sub(pivot, c.ConstantS32Scalar(1))
A:jax.lax_linalg.perm->jax.numpy.lax_numpy.arange(m, dtype=np.int32)
A:jax.lax_linalg.error->jax.numpy.lax_numpy.array(False, np.bool_)
A:jax.lax_linalg.r->ShapedArray(batch_dims + (k, n), operand.dtype)
A:jax.lax_linalg.b->min(r - k, block_size)
A:jax.lax_linalg.(block_pivot, perm, lu_block, block_error)->_lu_unblocked(a[k:, k:k + b])
A:jax.lax_linalg.batch_size->numpy.prod(batch_dims, dtype=onp.int64)
A:jax.lax_linalg.(pivot, lu)->_lu_blocked(x)
A:jax.lax_linalg.lu->_broadcasting_select(c, c.Reshape(ok, None, batch_dims + (1, 1)), lu, _nan_like(c, lu))
A:jax.lax_linalg.(lu, pivot)->jax.interpreters.xla.apply_primitive(lu_p, operand)
A:jax.lax_linalg.a_shape->jax.numpy.lax_numpy.shape(a)
A:jax.lax_linalg.k->min(m, n)
A:jax.lax_linalg.permutation->jax.lax.broadcasted_iota(np.int32, batch_dims + (m,), len(batch_dims))
A:jax.lax_linalg.ndims->len(a_shape)
A:jax.lax_linalg.zero->jax.numpy.lax_numpy._constant_like(lu, 0)
A:jax.lax_linalg.u_eye->jax.lax.pad(np.eye(n - k, n - k, dtype=dtype), zero, ((k, 0, 0), (k, 0, 0)))
A:jax.lax_linalg.la->triangular_solve(l, x, left_side=True, transpose_a=False, lower=True, unit_diagonal=True)
A:jax.lax_linalg.lau->triangular_solve(u, la, left_side=False, transpose_a=False, lower=False)
A:jax.lax_linalg.l_dot->jax.numpy.lax_numpy.matmul(l, np.tril(lau, -1))
A:jax.lax_linalg.u_dot->jax.numpy.lax_numpy.matmul(np.triu(lau), u)
A:jax.lax_linalg.(lu, pivot, info)->getrf_impl(c, operand)
A:jax.lax_linalg.lu_p->Primitive('lu')
A:jax.lax_linalg.xla.translations[lu_p]->jax.interpreters.xla.lower_fun(_lu_python, instantiate=True)
A:jax.lax_linalg._cpu_getrf->_unpack_tuple(lapack.jax_getrf, 3)
A:jax.lax_linalg.xla.backend_specific_translations['cpu'][lu_p]->partial(_lu_cpu_gpu_translation_rule, _cpu_getrf)
A:jax.lax_linalg.xla.backend_specific_translations['gpu'][lu_p]->partial(_lu_cpu_gpu_translation_rule, cusolver.getrf)
A:jax.lax_linalg.iotas->jax.numpy.lax_numpy.ix_(*(lax.iota(np.int32, b) for b in batch_dims))
A:jax.lax_linalg.q->ShapedArray(batch_dims + (m, k), operand.dtype)
A:jax.lax_linalg.dx_rinv->triangular_solve(r, dx)
A:jax.lax_linalg.qt_dx_rinv->jax.numpy.lax_numpy.matmul(_T(q), dx_rinv)
A:jax.lax_linalg.qt_dx_rinv_lower->jax.numpy.lax_numpy.tril(qt_dx_rinv, -1)
A:jax.lax_linalg.dr->jax.numpy.lax_numpy.matmul(qt_dx_rinv - domega, r)
A:jax.lax_linalg.qr_p->Primitive('qr')
A:jax.lax_linalg.(s, u, vt)->jax.interpreters.xla.apply_primitive(svd_p, operand, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax.lax_linalg.s->_broadcasting_select(c, c.Reshape(ok, None, (1,)), s, _nan_like(c, s))
A:jax.lax_linalg.u->_broadcasting_select(c, c.Reshape(ok, None, (1, 1)), u, _nan_like(c, u))
A:jax.lax_linalg.vt->_broadcasting_select(c, c.Reshape(ok, None, (1, 1)), vt, _nan_like(c, vt))
A:jax.lax_linalg.(s, U, Vt)->Primitive('svd').bind(A, full_matrices=False, compute_uv=True)
A:jax.lax_linalg.dS->jax.numpy.lax_numpy.dot(np.dot(Ut, dA), V)
A:jax.lax_linalg.ds->jax.numpy.lax_numpy.real(np.diag(dS))
A:jax.lax_linalg.dU->jax.numpy.lax_numpy.dot(U, F * (dSS + dSS.T))
A:jax.lax_linalg.dV->jax.numpy.lax_numpy.dot(V, F * (SdS + SdS.T))
A:jax.lax_linalg.(s, u, vt, info)->gesvd_impl(c, operand, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax.lax_linalg.svd_p->Primitive('svd')
A:jax.lax_linalg._cpu_gesdd->_unpack_tuple(lapack.jax_gesdd, 4)
A:jax.lax_linalg.xla.backend_specific_translations['cpu'][svd_p]->partial(_svd_cpu_gpu_translation_rule, _cpu_gesdd)
A:jax.lax_linalg.xla.backend_specific_translations['gpu'][svd_p]->partial(_svd_cpu_gpu_translation_rule, cusolver.gesvd)
jax.lax_linalg._H(x)
jax.lax_linalg._T(x)
jax.lax_linalg._eigh_cpu_gpu_translation_rule(syevd_impl,c,operand,lower)
jax.lax_linalg._lu_abstract_eval(operand)
jax.lax_linalg._lu_batching_rule(batched_args,batch_dims)
jax.lax_linalg._lu_blocked(a,block_size=32)
jax.lax_linalg._lu_cpu_gpu_translation_rule(getrf_impl,c,operand)
jax.lax_linalg._lu_impl(operand)
jax.lax_linalg._lu_jvp_rule(primals,tangents)
jax.lax_linalg._lu_python(x)
jax.lax_linalg._lu_unblocked(a)
jax.lax_linalg._nan_like(c,operand)
jax.lax_linalg._svd_cpu_gpu_translation_rule(gesvd_impl,c,operand,full_matrices,compute_uv)
jax.lax_linalg._unpack_tuple(f,n)
jax.lax_linalg.cholesky(x,symmetrize_input=True)
jax.lax_linalg.cholesky_batching_rule(batched_args,batch_dims)
jax.lax_linalg.cholesky_cpu_translation_rule(c,operand)
jax.lax_linalg.cholesky_jvp_rule(primals,tangents)
jax.lax_linalg.eig(x)
jax.lax_linalg.eig_abstract_eval(operand)
jax.lax_linalg.eig_batching_rule(batched_args,batch_dims)
jax.lax_linalg.eig_cpu_translation_rule(c,operand)
jax.lax_linalg.eig_impl(operand)
jax.lax_linalg.eig_translation_rule(c,operand)
jax.lax_linalg.eigh(x,lower=True,symmetrize_input=True)
jax.lax_linalg.eigh_abstract_eval(operand,lower)
jax.lax_linalg.eigh_batching_rule(batched_args,batch_dims,lower)
jax.lax_linalg.eigh_impl(operand,lower)
jax.lax_linalg.eigh_jvp_rule(primals,tangents,lower)
jax.lax_linalg.eigh_translation_rule(c,operand,lower)
jax.lax_linalg.lu(x)
jax.lax_linalg.lu_pivots_to_permutation(swaps,m)
jax.lax_linalg.qr(x,full_matrices=True)
jax.lax_linalg.qr_abstract_eval(operand,full_matrices)
jax.lax_linalg.qr_batching_rule(batched_args,batch_dims,full_matrices)
jax.lax_linalg.qr_impl(operand,full_matrices)
jax.lax_linalg.qr_jvp_rule(primals,tangents,full_matrices)
jax.lax_linalg.qr_translation_rule(c,operand,full_matrices)
jax.lax_linalg.svd(x,full_matrices=True,compute_uv=True)
jax.lax_linalg.svd_abstract_eval(operand,full_matrices,compute_uv)
jax.lax_linalg.svd_batching_rule(batched_args,batch_dims,full_matrices,compute_uv)
jax.lax_linalg.svd_impl(operand,full_matrices,compute_uv)
jax.lax_linalg.svd_jvp_rule(primals,tangents,full_matrices,compute_uv)
jax.lax_linalg.svd_translation_rule(c,operand,full_matrices,compute_uv)
jax.lax_linalg.symmetrize(x)
jax.lax_linalg.triangular_solve(a,b,left_side=False,lower=False,transpose_a=False,conjugate_a=False,unit_diagonal=False)
jax.lax_linalg.triangular_solve_batching_rule(batched_args,batch_dims,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax.lax_linalg.triangular_solve_cpu_translation_rule(c,a,b,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax.lax_linalg.triangular_solve_jvp_rule_a(g_a,ans,a,b,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax.lax_linalg.triangular_solve_shape_rule(a,b,left_side=False,**unused_kwargs)
jax.lax_linalg.triangular_solve_transpose_rule(cotangent,a,b,left_side,lower,transpose_a,conjugate_a,unit_diagonal)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/config.py----------------------------------------
A:jax.config.self.FLAGS->NameSpace(self.read)
A:jax.config.config->Config()
jax.config.Config(self)
jax.config.Config.DEFINE_bool(self,name,default,*args,**kwargs)
jax.config.Config.DEFINE_enum(self,name,default,*args,**kwargs)
jax.config.Config.DEFINE_integer(self,name,default,*args,**kwargs)
jax.config.Config.DEFINE_string(self,name,default,*args,**kwargs)
jax.config.Config.__init__(self)
jax.config.Config.add_option(self,name,default,opt_type,meta_args,meta_kwargs)
jax.config.Config.check_exists(self,name)
jax.config.Config.complete_absl_config(self,absl_flags)
jax.config.Config.config_with_absl(self)
jax.config.Config.parse_flags_with_absl(self)
jax.config.Config.read(self,name)
jax.config.Config.update(self,name,val)
jax.config.NameSpace(self,getter)
jax.config.NameSpace.__getattr__(self,name)
jax.config.NameSpace.__init__(self,getter)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/tree_util.py----------------------------------------
A:jax.tree_util.(leaves, treedef)->lib.pytree.flatten(tree)
A:jax.tree_util.(flat, treedef)->tree_flatten(pytree_to_transpose)
A:jax.tree_util.expected_treedef->_nested_treedef(inner_treedef, outer_treedef)
A:jax.tree_util.flat->iter(flat)
A:jax.tree_util.transposed_lol->zip(*lol)
A:jax.tree_util.subtrees->map(partial(tree_unflatten, outer_treedef), transposed_lol)
A:jax.tree_util.(_, treedef)->lib.pytree.flatten(tree)
A:jax.tree_util.node_type->_get_node_type(tree)
A:jax.tree_util.(children, node_spec)->_get_node_type(tree).to_iterable(tree)
A:jax.tree_util.(children, aux_data)->_get_node_type(tree).to_iterable(tree)
A:jax.tree_util.other_node_type->_get_node_type(other_tree)
A:jax.tree_util.(other_children, other_aux_data)->_get_node_type(tree).to_iterable(other_tree)
A:jax.tree_util.(proc_children, child_specs)->unzip2([_walk_pytree(f_node, f_leaf, child) for child in children])
A:jax.tree_util.tree_def->_PyTreeDef(node_type, node_spec, child_specs)
A:jax.tree_util.children->map(partial(_nested_treedef, inner), outer.children)
A:jax.tree_util.(children, _)->_get_node_type(tree).to_iterable(tree)
A:jax.tree_util.(itr, treedef)->_walk_pytree(it.chain.from_iterable, lambda x: (x,), tree)
A:jax.tree_util.inner_size->_num_leaves(inner_treedef)
A:jax.tree_util.outer_size->_num_leaves(outer_treedef)
A:jax.tree_util.(_, spec)->process_pytree(lambda _: None, tree)
A:jax.tree_util.data_repr->'[{}]'.format(self.node_data)
A:jax.tree_util.leaf->_PyLeaf()
A:jax.tree_util.keys->tuple(sorted(xs.keys()))
A:jax.tree_util.node_types[py_type]->NodeType(str(py_type), to_iterable, from_iterable)
A:jax.tree_util.t->type(maybe_tree)
A:jax.tree_util.NamedtupleNode->NodeType('namedtuple', lambda xs: (tuple(xs), type(xs)), lambda t, xs: t(*xs))
jax.tree_util.Partial(functools.partial)
jax.tree_util.tree_all(tree)
jax.tree_util.tree_reduce(f,tree)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/ad_util.py----------------------------------------
A:jax.ad_util.add_jaxvals_p->Primitive('add_any')
A:jax.ad_util.zeros_like_p->Primitive('zeros_like')
A:jax.ad_util.zero->Zero()
jax.ad_util.Zero(object)
jax.ad_util.Zero.__repr__(self)
jax.ad_util.add_abstract(xs,ys)
jax.ad_util.add_impl(xs,ys)
jax.ad_util.add_jaxtuples(xs,ys)
jax.ad_util.add_jaxvals(x,y)
jax.ad_util.zeros_like_abstract_tuple(tup)
jax.ad_util.zeros_like_aval(aval)
jax.ad_util.zeros_like_impl(example)
jax.ad_util.zeros_like_impl_jaxtuple(xs)
jax.ad_util.zeros_like_jaxval(val)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/linear_util.py----------------------------------------
A:jax.linear_util.store->Store()
A:jax.linear_util.(ans, aux)->f(*init_args + rest)
A:jax.linear_util.gen->gen(*gen_args + tuple(args), **kwargs)
A:jax.linear_util.(args, kwargs)->next(gen)
A:jax.linear_util.ans->gen(*gen_args + tuple(args), **kwargs).send(ans)
A:jax.linear_util.(gen, out_store)->stack.pop()
A:jax.linear_util.transformation_stack->map(transform_to_str, enumerate(self.transforms))
A:jax.linear_util.out_store->Store()
A:jax.linear_util.(ans, f_prev)->memoized_fun_body(f, args)
jax.linear_util.Store(object)
jax.linear_util.Store.__nonzero__(self)
jax.linear_util.Store.store(self,val)
jax.linear_util.Store.val(self)
jax.linear_util.StoreException(Exception)
jax.linear_util.WrappedFun(self,f,transforms,params)
jax.linear_util.WrappedFun.__eq__(self,other)
jax.linear_util.WrappedFun.__hash__(self)
jax.linear_util.WrappedFun.__init__(self,f,transforms,params)
jax.linear_util.WrappedFun.__repr__(self)
jax.linear_util.WrappedFun.call_wrapped(self,*args,**kwargs)
jax.linear_util.WrappedFun.hashable_payload(self)
jax.linear_util.WrappedFun.populate_stores(self,other)
jax.linear_util.WrappedFun.wrap(self,*transformation)
jax.linear_util.fun_name(f)
jax.linear_util.memoize(call,max_size=4096)
jax.linear_util.staged(f,*init_args)
jax.linear_util.thunk(f)
jax.linear_util.transformation(gen,fun,*transformation_args)
jax.linear_util.transformation_with_aux(gen,fun,*transformation_args)
jax.linear_util.wrap_init(f,params={})


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/test_util.py----------------------------------------
A:jax.test_util.atol->max(atol, 0.5)
A:jax.test_util.rtol->max(rtol, 0.1)
A:jax.test_util.close->partial(numpy_close, atol=atol, rtol=rtol)
A:jax.test_util.add->partial(tree_multimap, onp.add)
A:jax.test_util.sub->partial(tree_multimap, onp.subtract)
A:jax.test_util.conj->partial(tree_map, onp.conj)
A:jax.test_util.shape->numpy.shape(x)
A:jax.test_util.dtype->_dtype(x)
A:jax.test_util.delta->scalar_mul(tangents, eps)
A:jax.test_util.f_pos->f(*add(primals, delta))
A:jax.test_util.f_neg->f(*sub(primals, delta))
A:jax.test_util.rng->numpy.random.RandomState(42)
A:jax.test_util.tangent->tree_map(_rand_like, args)
A:jax.test_util.(v_out, t_out)->f_jvp(args, tangent)
A:jax.test_util.v_out_expected->f(*args)
A:jax.test_util.t_out_expected->numerical_jvp(f, args, tangent, eps=eps)
A:jax.test_util._rand_like->partial(rand_like, onp.random.RandomState(0))
A:jax.test_util.(v_out, vjpfun)->f_vjp(*args)
A:jax.test_util.tangent_out->numerical_jvp(f, args, tangent, eps=eps)
A:jax.test_util.cotangent->tree_map(_rand_like, v_out)
A:jax.test_util.cotangent_out->conj(vjpfun(conj(cotangent)))
A:jax.test_util.ip->inner_prod(tangent, cotangent_out)
A:jax.test_util.ip_expected->inner_prod(tangent_out, cotangent)
A:jax.test_util.args->args_maker()
A:jax.test_util._check_jvp->partial(check_jvp, atol=atol, rtol=rtol, eps=eps)
A:jax.test_util._check_vjp->partial(check_vjp, atol=atol, rtol=rtol, eps=eps)
A:jax.test_util.(out_primal_py, vjp_py)->api.vjp(f, *args)
A:jax.test_util.test_name->getattr(test_method, '__name__', '[unknown test]')
A:jax.test_util.flag_value->getattr(FLAGS, flag_name)
A:jax.test_util.NUMPY_SCALAR_SHAPE->_NumpyScalar()
A:jax.test_util.PYTHON_SCALAR_SHAPE->_PythonScalar()
A:jax.test_util.shapestr->','.join((str(dim) for dim in shape))
A:jax.test_util.vals->numpy.where(zeros, 0, vals)
A:jax.test_util.x_ravel->numpy.asarray(x).ravel()
A:jax.test_util.base_rand->rand_default()
A:jax.test_util.dims->_dims_of_shape(shape)
A:jax.test_util.xs->list(xs)
A:jax.test_util.k->min(len(xs), FLAGS.num_generated_cases)
A:jax.test_util.indices->numpy.random.RandomState(42).choice(onp.arange(len(xs)), k, replace=False)
A:jax.test_util.msg->'Arguments x and y not equal to tolerance atol={}, rtol={}:\nx:\n{}\ny:\n{}\n'.format(atol, rtol, x, y)
A:jax.test_util.x_dtype->c128_to_c64(onp.asarray(x).dtype)
A:jax.test_util.y_dtype->c128_to_c64(onp.asarray(y).dtype)
A:jax.test_util.x->numpy.asarray(x)
A:jax.test_util.y->numpy.asarray(y)
A:jax.test_util.python_ans->fun(*args)
A:jax.test_util.cfun->api.jit(wrapped_fun)
A:jax.test_util.monitored_ans->cfun(*args)
A:jax.test_util.compiled_ans->cfun(*args)
A:jax.test_util.numpy_ans->numpy_reference_op(*args)
A:jax.test_util.lax_ans->lax_op(*args)
jax.test_util.JaxTestCase(parameterized.TestCase)
jax.test_util.JaxTestCase._CheckAgainstNumpy(self,numpy_reference_op,lax_op,args_maker,check_dtypes=False,tol=1e-05)
jax.test_util.JaxTestCase._CompileAndCheck(self,fun,args_maker,check_dtypes,rtol=None,atol=None)
jax.test_util.JaxTestCase.assertAllClose(self,x,y,check_dtypes,atol=None,rtol=None)
jax.test_util.JaxTestCase.assertArraysAllClose(self,x,y,check_dtypes,atol=None,rtol=None)
jax.test_util.JaxTestCase.assertDtypesMatch(self,x,y)
jax.test_util.ScalarShape(object)
jax.test_util.ScalarShape.__len__(self)
jax.test_util._NumpyScalar(ScalarShape)
jax.test_util._PythonScalar(ScalarShape)
jax.test_util._cast_to_shape(value,shape,dtype)
jax.test_util._dims_of_shape(shape)
jax.test_util._rand_dtype(rand,shape,dtype,scale=1.0,post=lambdax:x)
jax.test_util.cases_from_gens(*gens)
jax.test_util.cases_from_list(xs)
jax.test_util.check_close(xs,ys,atol=ATOL,rtol=RTOL)
jax.test_util.check_eq(xs,ys)
jax.test_util.check_grads(f,args,order,modes=['fwd','rev'],atol=None,rtol=None,eps=None)
jax.test_util.check_jvp(f,f_jvp,args,atol=ATOL,rtol=RTOL,eps=EPS)
jax.test_util.check_raises(thunk,err_type,msg)
jax.test_util.check_raises_regexp(thunk,err_type,pattern)
jax.test_util.check_vjp(f,f_vjp,args,atol=ATOL,rtol=RTOL,eps=EPS)
jax.test_util.dtype_str(dtype)
jax.test_util.format_shape_dtype_string(shape,dtype)
jax.test_util.format_test_name_suffix(opname,shapes,dtypes)
jax.test_util.inner_prod(xs,ys)
jax.test_util.is_sequence(x)
jax.test_util.numerical_jvp(f,primals,tangents,eps=EPS)
jax.test_util.numpy_close(a,b,atol=ATOL,rtol=RTOL,equal_nan=False)
jax.test_util.numpy_eq(x,y)
jax.test_util.rand_bool()
jax.test_util.rand_default()
jax.test_util.rand_int(low,high=None)
jax.test_util.rand_like(rng,x)
jax.test_util.rand_nonzero()
jax.test_util.rand_not_small()
jax.test_util.rand_positive()
jax.test_util.rand_small()
jax.test_util.rand_small_positive()
jax.test_util.rand_some_equal()
jax.test_util.rand_some_inf()
jax.test_util.rand_some_inf_and_nan()
jax.test_util.rand_some_zero()
jax.test_util.rand_uniform(low=0.0,high=1.0)
jax.test_util.scalar_mul(xs,a)
jax.test_util.skip_on_devices(*disabled_devices)
jax.test_util.skip_on_flag(flag_name,skip_value)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/random.py----------------------------------------
A:jax.random.k1->convert(lax.shift_right_logical(seed, 32))
A:jax.random.k2->convert(lax.bitwise_and(seed, 4294967295))
A:jax.random.nbits->numpy.array(onp.iinfo(dtype).bits, dtype)
A:jax.random.d->lax.sub(alpha, one_over_three)
A:jax.random.rotate_left->_make_rotate_left(lax.dtype(count))
A:jax.random.v[1]->rotate_left(v[1], rot)
A:jax.random.x->normal(subkey, (), dtype=dtype)
A:jax.random.rotations->numpy.uint32([13, 15, 26, 6, 17, 29, 16, 24])
A:jax.random.out->np.concatenate(x)
A:jax.random.counts->lax.tie_in(key, lax.iota(onp.uint32, max_count))
A:jax.random.key2->lax.tie_in(key, PRNGKey(data))
A:jax.random.bits->_random_bits(key, nbits, shape)
A:jax.random.shape->tuple(map(int, shape))
A:jax.random.dtype->jax.lib.xla_bridge.canonicalize_dtype(dtype)
A:jax.random.minval->lax.convert_element_type(minval, dtype)
A:jax.random.maxval->lax.max(lax.add(minval, onp.array(1, dtype)), maxval)
A:jax.random.finfo->numpy.finfo(dtype)
A:jax.random.float_bits->lax.bitwise_or(lax.shift_right_logical(bits, onp.array(nbits - nmant, lax.dtype(bits))), onp.array(1.0, dtype).view(onp.uint32 if nbits == 32 else onp.uint64))
A:jax.random.(k1, k2)->split(key)
A:jax.random.span->lax.convert_element_type(maxval - minval, unsigned_dtype)
A:jax.random.multiplier->lax.rem(lax.mul(multiplier, multiplier), span)
A:jax.random.random_offset->lax.rem(random_offset, span)
A:jax.random.num_rounds->int(onp.ceil(exponent * onp.log(x.size) / onp.log(uint32max)))
A:jax.random.(key, subkey)->split(key)
A:jax.random.sort_keys->_random_bits(subkey, 32, x.shape)
A:jax.random.(_, x)->lax.sort_key_val(sort_keys, x, axis)
A:jax.random.lo->numpy.nextafter(onp.array(-1.0, dtype), 0.0, dtype=dtype)
A:jax.random.hi->numpy.array(1.0, dtype)
A:jax.random.u->uniform(key, shape, dtype, minval=-1.0 + np.finfo(dtype).epsneg, maxval=1.0)
A:jax.random.p->np.broadcast_to(p, shape)
A:jax.random.a->np.broadcast_to(a, shape)
A:jax.random.b->np.broadcast_to(b, shape)
A:jax.random.(key_a, key_b)->split(key)
A:jax.random.gamma_a->gamma(key_a, a, shape, dtype)
A:jax.random.gamma_b->gamma(key_b, b, shape, dtype)
A:jax.random.pi->_constant_like(u, onp.pi)
A:jax.random.alpha->lax.select(lax.ge(alpha, one), alpha, lax.add(alpha, one))
A:jax.random.gamma_samples->gamma(key, alpha, shape + alpha.shape[-1:], dtype)
A:jax.random.zero->_constant_like(alpha, 0)
A:jax.random.one->_constant_like(alpha, 1)
A:jax.random.minus_one->_constant_like(alpha, -1)
A:jax.random.one_over_two->_constant_like(alpha, 0.5)
A:jax.random.one_over_three->_constant_like(alpha, 1.0 / 3.0)
A:jax.random.squeeze_const->_constant_like(alpha, 0.0331)
A:jax.random.boost->lax.select(lax.ge(alpha, one), one, lax.pow(uniform(subkey, (), dtype=dtype), lax.div(one, alpha)))
A:jax.random.c->lax.div(one_over_three, lax.pow(d, one_over_two))
A:jax.random.cond->lax.bitwise_and(lax.ge(U, lax.sub(one, lax.mul(squeeze_const, lax.mul(X, X)))), lax.ge(lax.log(U), lax.add(lax.mul(X, one_over_two), lax.mul(d, lax.add(lax.sub(one, V), lax.log(V))))))
A:jax.random.v->np.log(alpha)
A:jax.random.(key, x_key, U_key)->split(key, 3)
A:jax.random.(_, x, v)->lax.while_loop(lambda kxv: lax.le(kxv[2], zero), _next_kxv, (x_key, zero, minus_one))
A:jax.random.X->lax.mul(x, x)
A:jax.random.V->lax.mul(lax.mul(v, v), v)
A:jax.random.U->uniform(U_key, (), dtype=dtype)
A:jax.random.(_, _, V, _)->lax.while_loop(_cond_fn, _body_fn, (key, zero, one, _constant_like(alpha, 2)))
A:jax.random.z->lax.mul(lax.mul(d, V), boost)
A:jax.random.sqrt_8a->np.sqrt(8 * alpha)
A:jax.random.log_z_div_a->np.log(z / alpha)
A:jax.random.sign->np.where(z < alpha, 1.0, -1.0)
A:jax.random.z_div_a->np.divide(z, alpha)
A:jax.random.grad->np.exp(p / np.maximum(q, 0.01))
A:jax.random.(_, _, grad, flag)->lax.while_loop(lambda zagf: ~zagf[3], _case4, (z, alpha, grad, flag))
A:jax.random.samples->vmap(_gamma_one)(keys, alphas)
A:jax.random.alphas->np.reshape(a, -1)
A:jax.random.grads->vmap(_gamma_grad_one)(samples, alphas)
A:jax.random.keys->split(key, onp.size(alphas))
A:jax.random.e->exponential(key, shape, dtype)
A:jax.random.df->lax.convert_element_type(df, dtype)
A:jax.random.(key_n, key_g)->split(key)
A:jax.random.n->normal(key_n, shape, dtype)
A:jax.random.two->_constant_like(n, 2)
A:jax.random.half_df->lax.div(df, two)
A:jax.random.g->gamma(key_n, half_df, shape, dtype)
jax.random.PRNGKey(seed)
jax.random._bernoulli(key,p,shape)
jax.random._beta(key,a,b,shape,dtype)
jax.random._bit_stats(bits)
jax.random._cauchy(key,shape,dtype)
jax.random._check_shape(name,shape)
jax.random._dirichlet(key,alpha,shape,dtype)
jax.random._exponential(key,shape,dtype)
jax.random._fold_in(key,data)
jax.random._gamma(key,a,shape,dtype)
jax.random._gamma_grad(sample,a)
jax.random._gamma_grad_one(z,alpha)
jax.random._gamma_impl(key,a)
jax.random._gamma_one(key,alpha)
jax.random._gumbel(key,shape,dtype)
jax.random._is_prng_key(key)
jax.random._laplace(key,shape,dtype)
jax.random._make_rotate_left(dtype)
jax.random._normal(key,shape,dtype)
jax.random._pareto(key,b,shape,dtype)
jax.random._randint(key,shape,minval,maxval,dtype)
jax.random._random_bits(key,bit_width,shape)
jax.random._shuffle(key,x,axis)
jax.random._split(key,num)
jax.random._t(key,df,shape,dtype)
jax.random._uniform(key,shape,dtype,minval,maxval)
jax.random.bernoulli(key,p=onp.float32(0.5),shape=())
jax.random.beta(key,a,b,shape=(),dtype=onp.float64)
jax.random.cauchy(key,shape=(),dtype=onp.float64)
jax.random.dirichlet(key,alpha,shape=(),dtype=onp.float64)
jax.random.exponential(key,shape=(),dtype=onp.float64)
jax.random.fold_in(key,data)
jax.random.gamma(key,a,shape=(),dtype=onp.float64)
jax.random.gumbel(key,shape=(),dtype=onp.float64)
jax.random.laplace(key,shape=(),dtype=onp.float64)
jax.random.normal(key,shape=(),dtype=onp.float64)
jax.random.pareto(key,b,shape=(),dtype=onp.float64)
jax.random.randint(key,shape,minval,maxval,dtype=onp.int64)
jax.random.shuffle(key,x,axis=0)
jax.random.split(key,num=2)
jax.random.t(key,df,shape=(),dtype=onp.float64)
jax.random.threefry_2x32(keypair,count)
jax.random.uniform(key,shape=(),dtype=onp.float64,minval=0.0,maxval=1.0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/util.py----------------------------------------
A:jax.util.n->len(args[0])
A:jax.util.args->list(map(list, args))
A:jax.util.wrapped->functools.partial(fun, *args, **kwargs)
A:jax.util.node->childless_nodes.pop()
A:jax.util.sides->list(map(predicate, xs))
A:jax.util.valself[key]->func(key)
A:jax.util.module_fns->set()
A:jax.util.attr->getattr(module, key)
jax.util.Hashable(self,val)
jax.util.Hashable.__eq__(self,other)
jax.util.Hashable.__hash__(self)
jax.util.Hashable.__init__(self,val)
jax.util.WrapHashably(self,val)
jax.util.WrapHashably.__eq__(self,other)
jax.util.WrapHashably.__hash__(self)
jax.util.WrapHashably.__init__(self,val)
jax.util.concatenate(xs)
jax.util.curry(f)
jax.util.get_module_functions(module)
jax.util.memoize(fun,max_size=4096)
jax.util.memoize_unary(func)
jax.util.partial(fun,*args,**kwargs)
jax.util.partialmethod(functools.partial)
jax.util.partialmethod.__get__(self,instance,owner)
jax.util.prod(xs)
jax.util.safe_map(f,*args)
jax.util.safe_zip(*args)
jax.util.split_merge(predicate,xs)
jax.util.toposort(end_node)
jax.util.unzip2(xys)
jax.util.unzip3(xyzs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/abstract_arrays.py----------------------------------------
A:jax.abstract_arrays.fname->getattr(fun, '__name__', fun)
A:jax.abstract_arrays.self.dtype->numpy.dtype(xla_bridge.canonicalize_dtype(onp.result_type(val)))
A:jax.abstract_arrays._bool_nonzero->concretization_function_error(bool)
A:jax.abstract_arrays._float->concretization_function_error(float)
A:jax.abstract_arrays._int->concretization_function_error(int)
A:jax.abstract_arrays._long->concretization_function_error(long)
A:jax.abstract_arrays._complex->concretization_function_error(complex)
A:jax.abstract_arrays._hex->concretization_function_error(hex)
A:jax.abstract_arrays._oct->concretization_function_error(oct)
A:jax.abstract_arrays.ndim->property(lambda self: len(self.shape))
A:jax.abstract_arrays.size->property(lambda self: prod(self.shape))
A:jax.abstract_arrays.shapestr->','.join(map(str, self.shape))
A:jax.abstract_arrays.self.shape->numpy.shape(val)
A:jax.abstract_arrays.dtype->lib.xla_bridge.canonicalize_dtype(onp.result_type(x))
jax.abstract_arrays.ConcreteArray(self,val)
jax.abstract_arrays.ConcreteArray.__eq__(self,other)
jax.abstract_arrays.ConcreteArray.__hash__(self)
jax.abstract_arrays.ConcreteArray.__init__(self,val)
jax.abstract_arrays.ConcreteArray.at_least_vspace(self)
jax.abstract_arrays.ConcreteArray.join(self,other)
jax.abstract_arrays.ConcreteArray.str_short(self)
jax.abstract_arrays.ShapedArray(self,shape,dtype)
jax.abstract_arrays.ShapedArray.__eq__(self,other)
jax.abstract_arrays.ShapedArray.__hash__(self)
jax.abstract_arrays.ShapedArray.__init__(self,shape,dtype)
jax.abstract_arrays.ShapedArray.__len__(self)
jax.abstract_arrays.ShapedArray._len(self,ignored_tracer)
jax.abstract_arrays.ShapedArray.at_least_vspace(self)
jax.abstract_arrays.ShapedArray.join(self,other)
jax.abstract_arrays.ShapedArray.str_short(self)
jax.abstract_arrays.UnshapedArray(self,dtype)
jax.abstract_arrays.UnshapedArray.__eq__(self,other)
jax.abstract_arrays.UnshapedArray.__hash__(self)
jax.abstract_arrays.UnshapedArray.__init__(self,dtype)
jax.abstract_arrays.UnshapedArray.__ne__(self,other)
jax.abstract_arrays.UnshapedArray.__repr__(self)
jax.abstract_arrays.UnshapedArray.at_least_vspace(self)
jax.abstract_arrays.UnshapedArray.join(self,other)
jax.abstract_arrays.UnshapedArray.str_short(self)
jax.abstract_arrays.concretization_err_msg(fun)
jax.abstract_arrays.concretization_function_error(fun)
jax.abstract_arrays.make_shaped_array(x)
jax.abstract_arrays.raise_to_shaped(aval)
jax.abstract_arrays.zeros_like_array(x)
jax.abstract_arrays.zeros_like_shaped_array(aval)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/experimental/optimizers.py----------------------------------------
A:jax.experimental.optimizers.OptimizerState->namedtuple('OptimizerState', ['packed_state', 'tree_def', 'subtree_defs'])
A:jax.experimental.optimizers.(init, update, get_params)->opt_maker(*args, **kwargs)
A:jax.experimental.optimizers.(x0_flat, tree)->tree_flatten(x0_tree)
A:jax.experimental.optimizers.(states_flat, subtrees)->unzip2(map(tree_flatten, initial_states))
A:jax.experimental.optimizers.packed_state->pack(map(pack, states_flat))
A:jax.experimental.optimizers.(grad_flat, tree2)->tree_flatten(grad_tree)
A:jax.experimental.optimizers.states->map(tree_unflatten, subtrees, packed_state)
A:jax.experimental.optimizers.new_states->map(partial(update, i), grad_flat, states)
A:jax.experimental.optimizers.(new_states_flat, subtrees2)->unzip2(map(tree_flatten, new_states))
A:jax.experimental.optimizers.new_packed_state->pack(map(pack, new_states_flat))
A:jax.experimental.optimizers.params->map(get_params, states)
A:jax.experimental.optimizers.step_size->make_schedule(step_size)
A:jax.experimental.optimizers.v0->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.g_sq->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.m->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.g_sq_inv_sqrt->jax.numpy.where(g_sq > 0, 1.0 / np.sqrt(g_sq), 0.0)
A:jax.experimental.optimizers.avg_sq_grad->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.mom->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.m0->jax.numpy.zeros_like(x0)
A:jax.experimental.optimizers.lst->list(seq)
A:jax.experimental.optimizers.idx->splice([None] * ndim, axis, [slice(None)])
A:jax.experimental.optimizers.accum_inv_sqrt->jax.numpy.where(accum > 0, 1.0 / np.sqrt(accum), 0)
A:jax.experimental.optimizers.boundaries->jax.numpy.array(boundaries)
A:jax.experimental.optimizers.values->jax.numpy.array(values)
A:jax.experimental.optimizers.(leaves, _)->tree_flatten(tree)
A:jax.experimental.optimizers.norm->l2_norm(grad_tree)
A:jax.experimental.optimizers.subtrees->map(tree_unflatten, subtree_defs, packed_state)
A:jax.experimental.optimizers.(sentinels, tree_def)->tree_flatten(marked_pytree)
A:jax.experimental.optimizers.(states_flat, subtree_defs)->unzip2(map(tree_flatten, subtrees))
jax.experimental.optimizers.JoinPoint(self,subtree)
jax.experimental.optimizers.JoinPoint.__init__(self,subtree)
jax.experimental.optimizers.JoinPoint.__iter__(self)
jax.experimental.optimizers.adagrad(step_size,momentum=0.9)
jax.experimental.optimizers.adam(step_size,b1=0.9,b2=0.999,eps=1e-08)
jax.experimental.optimizers.clip_grads(grad_tree,max_norm)
jax.experimental.optimizers.constant(step_size)
jax.experimental.optimizers.exponential_decay(step_size,decay_steps,decay_rate)
jax.experimental.optimizers.inverse_time_decay(step_size,decay_steps,decay_rate,staircase=False)
jax.experimental.optimizers.l2_norm(tree)
jax.experimental.optimizers.make_schedule(scalar_or_schedule)
jax.experimental.optimizers.momentum(step_size,mass)
jax.experimental.optimizers.optimizer(opt_maker)
jax.experimental.optimizers.pack_optimizer_state(marked_pytree)
jax.experimental.optimizers.piecewise_constant(boundaries,values)
jax.experimental.optimizers.rmsprop(step_size,gamma=0.9,eps=1e-08)
jax.experimental.optimizers.rmsprop_momentum(step_size,gamma=0.9,eps=1e-08,momentum=0.9)
jax.experimental.optimizers.sgd(step_size)
jax.experimental.optimizers.sm3(step_size,momentum=0.9)
jax.experimental.optimizers.unpack_optimizer_state(opt_state)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/experimental/stax.py----------------------------------------
A:jax.experimental.stax.unnormalized->jax.numpy.exp(x - x.max(axis, keepdims=True))
A:jax.experimental.stax.std->jax.lax.convert_element_type(std, np.float32)
A:jax.experimental.stax.size->numpy.prod(onp.delete(shape, [in_axis, out_axis]))
A:jax.experimental.stax.(k1, k2)->jax.random.split(rng)
A:jax.experimental.stax.filter_shape_iter->iter(filter_shape)
A:jax.experimental.stax.output_shape->jax.lax.conv_transpose_shape_tuple(input_shape, kernel_shape, strides, padding, dimension_numbers)
A:jax.experimental.stax.bias_shape->tuple(itertools.dropwhile(lambda x: x == 1, bias_shape))
A:jax.experimental.stax.Conv->functools.partial(GeneralConv, ('NHWC', 'HWIO', 'NHWC'))
A:jax.experimental.stax.Conv1DTranspose->functools.partial(GeneralConvTranspose, ('NHC', 'HIO', 'NHC'))
A:jax.experimental.stax.ConvTranspose->functools.partial(GeneralConvTranspose, ('NHWC', 'HWIO', 'NHWC'))
A:jax.experimental.stax.shape->tuple((d for (i, d) in enumerate(input_shape) if i not in axis))
A:jax.experimental.stax.ed->tuple((None if i in axis else slice(None) for i in range(np.ndim(x))))
A:jax.experimental.stax.Tanh->elementwise(np.tanh)
A:jax.experimental.stax.Relu->elementwise(relu)
A:jax.experimental.stax.Exp->elementwise(np.exp)
A:jax.experimental.stax.LogSoftmax->elementwise(logsoftmax, axis=-1)
A:jax.experimental.stax.Softmax->elementwise(softmax, axis=-1)
A:jax.experimental.stax.Softplus->elementwise(softplus)
A:jax.experimental.stax.Sigmoid->elementwise(sigmoid)
A:jax.experimental.stax.Elu->elementwise(elu)
A:jax.experimental.stax.LeakyRelu->elementwise(leaky_relu)
A:jax.experimental.stax.out_shape->jax.lax.reduce_window_shape_tuple(input_shape, dims, strides, padding)
A:jax.experimental.stax.out->jax.lax.reduce_window(inputs, init_val, reducer, dims, strides, padding)
A:jax.experimental.stax.MaxPool->_pooling_layer(lax.max, -np.inf)
A:jax.experimental.stax.SumPool->_pooling_layer(lax.add, 0.0)
A:jax.experimental.stax.one->jax.numpy.ones(inputs.shape[1:-1], dtype=inputs.dtype)
A:jax.experimental.stax.window_sizes->jax.lax.reduce_window(one, 0.0, lax.add, dims, strides, padding)
A:jax.experimental.stax.AvgPool->_pooling_layer(lax.add, 0.0, _normalize_by_window_size)
A:jax.experimental.stax.Flatten->Flatten()
A:jax.experimental.stax.Identity->Identity()
A:jax.experimental.stax.FanInSum->FanInSum()
A:jax.experimental.stax.concat_size->sum((shape[ax] for shape in input_shape))
A:jax.experimental.stax.rng->kwargs.pop('rng', None)
A:jax.experimental.stax.keep->jax.random.bernoulli(rng, rate, inputs.shape)
A:jax.experimental.stax.nlayers->len(layers)
A:jax.experimental.stax.(init_funs, apply_funs)->zip(*layers)
A:jax.experimental.stax.(rng, layer_rng)->jax.random.split(rng)
A:jax.experimental.stax.(input_shape, param)->init_fun(layer_rng, input_shape)
A:jax.experimental.stax.inputs->fun(param, inputs, rng=rng, **kwargs)
A:jax.experimental.stax.rngs->jax.random.split(rng, nlayers)
jax.experimental.stax.BatchNorm(axis=(0,1,2),epsilon=1e-05,center=True,scale=True,beta_init=zeros,gamma_init=ones)
jax.experimental.stax.Dense(out_dim,W_init=glorot(),b_init=randn())
jax.experimental.stax.Dropout(rate,mode='train')
jax.experimental.stax.FanInConcat(axis=-1)
jax.experimental.stax.FanInSum()
jax.experimental.stax.FanOut(num)
jax.experimental.stax.Flatten()
jax.experimental.stax.GeneralConv(dimension_numbers,out_chan,filter_shape,strides=None,padding='VALID',W_init=None,b_init=randn(1e-06))
jax.experimental.stax.GeneralConvTranspose(dimension_numbers,out_chan,filter_shape,strides=None,padding='VALID',W_init=None,b_init=randn(1e-06))
jax.experimental.stax.Identity()
jax.experimental.stax._normalize_by_window_size(dims,strides,padding)
jax.experimental.stax._pooling_layer(reducer,init_val,rescaler=None)
jax.experimental.stax.elementwise(fun,**fun_kwargs)
jax.experimental.stax.elu(x)
jax.experimental.stax.fastvar(x,axis,keepdims)
jax.experimental.stax.glorot(out_axis=0,in_axis=1,scale=onp.sqrt(2))
jax.experimental.stax.leaky_relu(x)
jax.experimental.stax.logsoftmax(x,axis=-1)
jax.experimental.stax.parallel(*layers)
jax.experimental.stax.randn(stddev=0.01)
jax.experimental.stax.relu(x)
jax.experimental.stax.serial(*layers)
jax.experimental.stax.shape_dependent(make_layer)
jax.experimental.stax.sigmoid(x)
jax.experimental.stax.softmax(x,axis=-1)
jax.experimental.stax.softplus(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/experimental/lapax.py----------------------------------------
A:jax.experimental.lapax.out->jax.lax.rev(out, *onp.where([row_rev, col_rev]))
A:jax.experimental.lapax.out[i, i]->_cholesky(a[i, i])
A:jax.experimental.lapax.out[i:, i]->solve(out[i, i], a[i:, i])
A:jax.experimental.lapax.out[i, :]->solve(a[i, i], b[i, :])
A:jax.experimental.lapax.out[:, i]->solve(a[i, i], b[:, i])
A:jax.experimental.lapax.out[:, i:]->solve(a[i, i], b[:, i])
A:jax.experimental.lapax.dims->tuple(range(ndarray.ndim))
A:jax.experimental.lapax.self.shape->tuple(onp.floor_divide(ndarray.shape, block_size) + (onp.mod(ndarray.shape, block_size) > 0))
A:jax.experimental.lapax.self.ndarray->_matrix_put(self.ndarray, idx, val.ndarray, self.bs)
A:jax.experimental.lapax.__add__->_make_infix_op(lax.add)
A:jax.experimental.lapax.__sub__->_make_infix_op(lax.sub)
A:jax.experimental.lapax.__mul__->_make_infix_op(lax.batch_matmul)
A:jax.experimental.lapax.__div__->_make_infix_op(lax.div)
A:jax.experimental.lapax.__truediv__->_make_infix_op(lax.div)
A:jax.experimental.lapax.T->property(_make_infix_op(_matrix_transpose))
A:jax.experimental.lapax.idx_elt->slice(idx_elt, idx_elt + 1, 1)
A:jax.experimental.lapax.indices->tuple(onp.arange(block_dim)[idx_elt])
A:jax.experimental.lapax.end->min(k * (start - step), shape[axis])
A:jax.experimental.lapax.(sli, row_rev)->_canonical_idx(ndarray.shape, idx_i, -2, block_size)
A:jax.experimental.lapax.(slj, col_rev)->_canonical_idx(ndarray.shape, idx_j, -1, block_size)
A:jax.experimental.lapax.val->jax.lax.rev(val, *onp.where([row_rev, col_rev]))
jax.experimental.lapax.LapaxMatrix(self,ndarray,block_size=1)
jax.experimental.lapax.LapaxMatrix.__getitem__(self,idx)
jax.experimental.lapax.LapaxMatrix.__init__(self,ndarray,block_size=1)
jax.experimental.lapax.LapaxMatrix.__setitem__(self,idx,val)
jax.experimental.lapax.LapaxMatrix.bview(self,block_size)
jax.experimental.lapax._canonical_idx(shape,idx_elt,axis,block_size=1)
jax.experimental.lapax._cholesky(a)
jax.experimental.lapax._make_infix_op(fun)
jax.experimental.lapax._matrix_put(ndarray,idx,val,block_size=1)
jax.experimental.lapax._matrix_take(ndarray,idx,block_size=1)
jax.experimental.lapax._matrix_transpose(ndarray)
jax.experimental.lapax._solve_triangular_left(a,b,left_side,lower,trans_a)
jax.experimental.lapax._solve_triangular_right(a,b,left_side,lower,trans_a)
jax.experimental.lapax.cholesky(a,block_size=1)
jax.experimental.lapax.full_like(x,val)
jax.experimental.lapax.solve_triangular(a,b,left_side,lower,trans_a,block_size=1)
jax.experimental.lapax.sqrt(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/experimental/ode.py----------------------------------------
A:jax.experimental.ode.c_sol->jax.numpy.array([35 / 384, 0, 500 / 1113, 125 / 192, -2187 / 6784, 11 / 84, 0])
A:jax.experimental.ode.c_error->jax.numpy.array([35 / 384 - 1951 / 21600, 0, 500 / 1113 - 22642 / 50085, 125 / 192 - 451 / 720, -2187 / 6784 - -12231 / 42400, 11 / 84 - 649 / 6300, -1.0 / 60.0])
A:jax.experimental.ode.dps_c_mid->jax.numpy.array([6025192743 / 30085553152 / 2, 0, 51252292925 / 65400821598 / 2, -2691868925 / 45128329728 / 2, 187940372067 / 1594534317056 / 2, -1776094331 / 19743644256 / 2, 11237099 / 235043384 / 2])
A:jax.experimental.ode.v->jax.numpy.stack([dy0, dy1, y0, y1, y_mid])
A:jax.experimental.ode.a->jax.numpy.dot(np.hstack([-2 * dt, 2 * dt, np.array([-8.0, -8.0, 16.0])]), v)
A:jax.experimental.ode.b->jax.numpy.dot(np.hstack([5 * dt, -3 * dt, np.array([18.0, 14.0, -32.0])]), v)
A:jax.experimental.ode.c->jax.numpy.dot(np.hstack([-4 * dt, dt, np.array([-11.0, -5.0, 16.0])]), v)
A:jax.experimental.ode.d0->L2_norm(y0 / scale)
A:jax.experimental.ode.d1->L2_norm(f0 / scale)
A:jax.experimental.ode.f1->fun(y1, t0 + h0)
A:jax.experimental.ode.h1->jax.numpy.maximum(1e-06, h0 * 0.001)
A:jax.experimental.ode.k->jax.numpy.append(k, np.array([ft]), axis=0)
A:jax.experimental.ode.ft->func(yi, ti)
A:jax.experimental.ode.mean_error_ratio->jax.numpy.max(mean_error_ratio)
A:jax.experimental.ode.error_ratio->jax.numpy.sqrt(mean_error_ratio)
A:jax.experimental.ode.factor->jax.numpy.maximum(1.0 / ifactor, np.minimum(error_ratio ** (1.0 / order) / safety, 1.0 / dfactor))
A:jax.experimental.ode.t->jax.numpy.array(t)
A:jax.experimental.ode.f0->func(y0, t[0])
A:jax.experimental.ode.dt->optimal_step_size(dt, error_ratios)
A:jax.experimental.ode.interp_coeff->interp_fit_dopri(cur_y, next_y, k, dt)
A:jax.experimental.ode.(next_y, next_f, next_y_error, k)->runge_kutta_step(func, cur_y, cur_f, cur_t, dt)
A:jax.experimental.ode.error_ratios->error_ratio(next_y_error, atol, rtol, cur_y, next_y)
A:jax.experimental.ode.output_y->jax.numpy.polyval(interp_coeff, relative_output_time)
A:jax.experimental.ode.x->jax.numpy.linspace(*xlimits, num=numticks)
A:jax.experimental.ode.y->jax.numpy.linspace(*ylimits, num=numticks)
A:jax.experimental.ode.(X, Y)->jax.numpy.meshgrid(x, y)
A:jax.experimental.ode.zs->vmap(func)(Y.ravel(), X.ravel())
A:jax.experimental.ode.Z->vmap(func)(Y.ravel(), X.ravel()).reshape(X.shape)
A:jax.experimental.ode.y0->jax.numpy.array([1.0])
A:jax.experimental.ode.ys->odeint(f, y0, np.array([t0, t1]), fargs, atol=1e-08, rtol=1e-08)
A:jax.experimental.ode.rys->odeint(f, ys[-1], np.array([t1, t0]), atol=1e-08, rtol=1e-08)
A:jax.experimental.ode.(T, D)->jax.numpy.shape(yt)
A:jax.experimental.ode.(flat_args, unravel)->ravel_pytree(func_args)
A:jax.experimental.ode.(y, adjoint, _, _)->unpack(augmented_state)
A:jax.experimental.ode.(dy_dt, vjp_all)->vjp(flat_func, y, t, flat_args)
A:jax.experimental.ode.(vjp_a, vjp_t, vjp_args)->vjp_all(-adjoint)
A:jax.experimental.ode.vjp_args->jax.numpy.zeros(np.size(flat_args))
A:jax.experimental.ode.vjp_cur_t->jax.numpy.dot(func(yt[i, :], t[i], *func_args), g[i, :])
A:jax.experimental.ode.aug_y0->jax.numpy.hstack((yt[i, :], vjp_y, vjp_t0, vjp_args))
A:jax.experimental.ode.aug_ans->odeint(augmented_dynamics, aug_y0, np.stack([t[i], t[i - 1]]), (flat_args,))
A:jax.experimental.ode.(_, vjp_y, vjp_t0, vjp_args)->unpack(aug_ans[1])
A:jax.experimental.ode.(flat_x, unravel)->ravel_pytree(x)
A:jax.experimental.ode.D->len(flat_x)
A:jax.experimental.ode.g->jax.numpy.ones_like(ys)
A:jax.experimental.ode.d->numpy.zeros_like(flat_x)
A:jax.experimental.ode.numerical_grad->nd(onearg_odeint, (y0, np.array([t0, t1]), fargs))
A:jax.experimental.ode.ode_vjp->grad_odeint(ys, f, y0, np.array([t0, t1]), fargs)
A:jax.experimental.ode.(exact_grad, _)->ravel_pytree(ode_vjp(g))
A:jax.experimental.ode.ts->jax.numpy.linspace(t0, t1, 100)
A:jax.experimental.ode.(ys, (t_evals, y_evals, f_evals))->odeint(f, y0, ts, fargs, atol=0.001, rtol=0.001, return_evals=True)
A:jax.experimental.ode.fig->matplotlib.pyplot.figure(figsize=(8, 6), facecolor='white')
A:jax.experimental.ode.ax->matplotlib.pyplot.figure(figsize=(8, 6), facecolor='white').add_subplot(111, frameon=False)
jax.experimental.ode.L2_norm(x)
jax.experimental.ode.error_ratio(error_estimate,rtol,atol,y0,y1)
jax.experimental.ode.fit_4th_order_polynomial(y0,y1,y_mid,dy0,dy1,dt)
jax.experimental.ode.grad_odeint(yt,func,y0,t,func_args)
jax.experimental.ode.initial_step_size(fun,t0,y0,order,rtol,atol,f0)
jax.experimental.ode.interp_fit_dopri(y0,y1,k,dt)
jax.experimental.ode.nd(f,x,eps=0.0001)
jax.experimental.ode.odeint(ofunc,y0,t,args=(),rtol=1e-07,atol=1e-09,return_evals=False)
jax.experimental.ode.optimal_step_size(last_step,mean_error_ratio,safety=0.9,ifactor=10.0,dfactor=0.2,order=5)
jax.experimental.ode.plot_gradient_field(ax,func,xlimits,ylimits,numticks=30)
jax.experimental.ode.runge_kutta_step(func,y0,f0,t0,dt)
jax.experimental.ode.test_fwd_back()
jax.experimental.ode.test_odeint_vjp()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/special.py----------------------------------------
A:jax.scipy.special.(x,)->_promote_args_like(osp_special.entr, x)
A:jax.scipy.special.x->numpy.lax_numpy.asarray(x)
A:jax.scipy.special.one->lax._const(x, 1)
A:jax.scipy.special.dims->_reduction_dims(a, axis)
A:jax.scipy.special.shape->numpy.lax_numpy.shape(p)
A:jax.scipy.special.amax->lax.reduce(a, _constant_like(a, -onp.inf), lax.max, dims)
A:jax.scipy.special.amax_singletons->dimadd(amax)
A:jax.scipy.special.out->lax.add(lax.log(lax.reduce(lax.exp(lax.sub(a, amax_singletons)), _constant_like(a, 0), lax.add, dims)), amax)
A:jax.scipy.special.(x, y)->_promote_args_like(osp_special.xlog1py, x, y)
A:jax.scipy.special.(a,)->_promote_args_like(lambda a: osp_special.multigammaln(a, 1), a)
A:jax.scipy.special.d->lax.convert_element_type(d, lax.dtype(a))
A:jax.scipy.special.constant->lax.mul(lax.mul(lax.mul(_constant_like(a, 0.25), d), lax.sub(d, _constant_like(a, 1))), lax.log(_constant_like(a, onp.pi)))
A:jax.scipy.special.res->numpy.lax_numpy.sum(gammaln(np.expand_dims(a, axis=-1) - lax.div(np.arange(d), _constant_like(a, 2))), axis=-1)
A:jax.scipy.special._LOGNDTR_FLOAT64_LOWER->numpy.array(-20, onp.float64)
A:jax.scipy.special._LOGNDTR_FLOAT32_LOWER->numpy.array(-10, onp.float32)
A:jax.scipy.special._LOGNDTR_FLOAT64_UPPER->numpy.array(8, onp.float64)
A:jax.scipy.special._LOGNDTR_FLOAT32_UPPER->numpy.array(5, onp.float32)
A:jax.scipy.special.dtype->lax.dtype(x)
A:jax.scipy.special.z->lax.sqrt(dtype(-2.0) * lax.log(sanitized_mcp))
A:jax.scipy.special.y->lax.select(lax.lt(z, half_sqrt_2), dtype(1.0) + lax.erf(w), lax.select(lax.gt(w, dtype(0.0)), dtype(2.0) - lax.erfc(z), lax.erfc(z)))
A:jax.scipy.special.p0->list(reversed([-59.96335010141079, 98.00107541859997, -56.67628574690703, 13.931260938727968, -1.2391658386738125]))
A:jax.scipy.special.q0->list(reversed([1.0, 1.9544885833814176, 4.676279128988815, 86.36024213908905, -225.46268785411937, 200.26021238006066, -82.03722561683334, 15.90562251262117, -1.1833162112133]))
A:jax.scipy.special.p1->list(reversed([4.0554489230596245, 31.525109459989388, 57.16281922464213, 44.08050738932008, 14.684956192885803, 2.1866330685079025, -0.1402560791713545, -0.03504246268278482, -0.0008574567851546854]))
A:jax.scipy.special.q1->list(reversed([1.0, 15.779988325646675, 45.39076351288792, 41.3172038254672, 15.04253856929075, 2.504649462083094, -0.14218292285478779, -0.03808064076915783, -0.0009332594808954574]))
A:jax.scipy.special.p2->list(reversed([3.2377489177694603, 6.915228890689842, 3.9388102529247444, 1.3330346081580755, 0.20148538954917908, 0.012371663481782003, 0.00030158155350823543, 2.6580697468673755e-06, 6.239745391849833e-09]))
A:jax.scipy.special.q2->list(reversed([1.0, 6.02427039364742, 3.6798356385616087, 1.3770209948908132, 0.21623699359449663, 0.013420400608854318, 0.00032801446468212774, 2.8924786474538068e-06, 6.790194080099813e-09]))
A:jax.scipy.special.coeffs->numpy.array(coeffs, dtype)
A:jax.scipy.special.maybe_complement_p->numpy.lax_numpy.where(p > dtype(-onp.expm1(-2.0)), dtype(1.0) - p, p)
A:jax.scipy.special.sanitized_mcp->numpy.lax_numpy.where(maybe_complement_p <= dtype(0.0), np.full(shape, dtype(0.5)), maybe_complement_p)
A:jax.scipy.special.ww->lax.square(w)
A:jax.scipy.special.infinity->numpy.lax_numpy.full(shape, dtype(onp.inf))
A:jax.scipy.special.x_nan_replaced->numpy.lax_numpy.where(p <= dtype(0.0), -infinity, np.where(p >= dtype(1.0), infinity, x))
A:jax.scipy.special.x_2->lax.square(x)
A:jax.scipy.special.even_sum->numpy.lax_numpy.zeros_like(x)
A:jax.scipy.special.odd_sum->numpy.lax_numpy.zeros_like(x)
A:jax.scipy.special._norm_logpdf_constant->numpy.log(onp.sqrt(2 * onp.pi))
A:jax.scipy.special.neg_half->_constant_like(x, -0.5)
A:jax.scipy.special.log_normalizer->_constant_like(x, _norm_logpdf_constant)
jax.scipy.special._double_factorial(n)
jax.scipy.special._log_ndtr_asymptotic_series(x,series_order)
jax.scipy.special._log_ndtr_lower(x,series_order)
jax.scipy.special._ndtr(x)
jax.scipy.special._ndtri(p)
jax.scipy.special._norm_logpdf(x)
jax.scipy.special.digamma(x)
jax.scipy.special.entr(x)
jax.scipy.special.erf(x)
jax.scipy.special.erfc(x)
jax.scipy.special.erfinv(x)
jax.scipy.special.expit(x)
jax.scipy.special.gammaln(x)
jax.scipy.special.log_ndtr(x,series_order=3)
jax.scipy.special.logit(x)
jax.scipy.special.logsumexp(a,axis=None,b=None,keepdims=False,return_sign=False)
jax.scipy.special.multigammaln(a,d)
jax.scipy.special.ndtr(x)
jax.scipy.special.ndtri(p)
jax.scipy.special.xlog1py(x,y)
jax.scipy.special.xlogy(x,y)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/linalg.py----------------------------------------
A:jax.scipy.linalg.a->numpy.linalg._promote_arg_dtypes(np.asarray(a))
A:jax.scipy.linalg.l->lax_linalg.cholesky(a if lower else np.conj(_T(a)), symmetrize_input=False)
A:jax.scipy.linalg.(c, b)->numpy.linalg._promote_arg_dtypes(np.asarray(c), np.asarray(b))
A:jax.scipy.linalg.c_shape->numpy.lax_numpy.shape(c)
A:jax.scipy.linalg.b_shape->numpy.lax_numpy.shape(b)
A:jax.scipy.linalg.c_ndims->len(c_shape)
A:jax.scipy.linalg.b_ndims->len(b_shape)
A:jax.scipy.linalg.b->lax_linalg.triangular_solve(c, b, left_side=True, lower=lower, transpose_a=lower, conjugate_a=lower)
A:jax.scipy.linalg.(v, w)->lax_linalg.eigh(a, lower=lower)
A:jax.scipy.linalg.(lu, pivots)->lax_linalg.lu(a)
A:jax.scipy.linalg.dtype->lax.dtype(a)
A:jax.scipy.linalg.(m, n)->numpy.lax_numpy.shape(a)
A:jax.scipy.linalg.permutation->lax_linalg.lu_pivots_to_permutation(pivots, m)
A:jax.scipy.linalg.p->numpy.lax_numpy.real(np.array(permutation == np.arange(m)[:, None], dtype=dtype))
A:jax.scipy.linalg.k->min(m, n)
A:jax.scipy.linalg.(q, r)->lax_linalg.qr(a, full_matrices)
A:jax.scipy.linalg.(a, b)->numpy.linalg._promote_arg_dtypes(np.asarray(a), np.asarray(b))
A:jax.scipy.linalg.out->lax_linalg.triangular_solve(a, b, left_side=True, lower=lower, transpose_a=transpose_a, conjugate_a=conjugate_a, unit_diagonal=unit_diagonal)
jax.scipy.linalg.cho_factor(a,lower=False,overwrite_a=False,check_finite=True)
jax.scipy.linalg.cho_solve(c_and_lower,b,overwrite_b=False,check_finite=True)
jax.scipy.linalg.cholesky(a,lower=False,overwrite_a=False,check_finite=True)
jax.scipy.linalg.det(a,overwrite_a=False,check_finite=True)
jax.scipy.linalg.eigh(a,b=None,lower=True,eigvals_only=False,overwrite_a=False,overwrite_b=False,turbo=True,eigvals=None,type=1,check_finite=True)
jax.scipy.linalg.inv(a,overwrite_a=False,check_finite=True)
jax.scipy.linalg.lu(a,permute_l=False,overwrite_a=False,check_finite=True)
jax.scipy.linalg.lu_factor(a,overwrite_a=False,check_finite=True)
jax.scipy.linalg.qr(a,overwrite_a=False,lwork=None,mode='full',pivoting=False,check_finite=True)
jax.scipy.linalg.solve(a,b,sym_pos=False,lower=False,overwrite_a=False,overwrite_b=False,debug=False,check_finite=True)
jax.scipy.linalg.solve_triangular(a,b,trans=0,lower=False,unit_diagonal=False,overwrite_b=False,debug=None,check_finite=True)
jax.scipy.linalg.svd(a,full_matrices=True,compute_uv=True,overwrite_a=False,check_finite=True,lapack_driver='gesdd')
jax.scipy.linalg.tril(m,k=0)
jax.scipy.linalg.triu(m,k=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/beta.py----------------------------------------
A:jax.scipy.stats.beta.(x, a, b, loc, scale)->_promote_args_like(osp_stats.beta.logpdf, x, a, b, loc, scale)
A:jax.scipy.stats.beta.one->_constant_like(x, 1)
A:jax.scipy.stats.beta.shape_term_tmp->lax.add(gammaln(a), gammaln(b))
A:jax.scipy.stats.beta.shape_term->lax.sub(gammaln(lax.add(a, b)), shape_term_tmp)
A:jax.scipy.stats.beta.y->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.beta.log_linear_term->lax.add(lax.mul(lax.sub(a, one), lax.log(y)), lax.mul(lax.sub(b, one), lax.log(lax.sub(one, y))))
A:jax.scipy.stats.beta.log_probs->lax.sub(lax.add(shape_term, log_linear_term), lax.log(scale))
jax.scipy.stats.beta.logpdf(x,a,b,loc=0,scale=1)
jax.scipy.stats.beta.pdf(x,a,b,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/multivariate_normal.py----------------------------------------
A:jax.scipy.stats.multivariate_normal.x->x.astype(cov.dtype).astype(cov.dtype)
A:jax.scipy.stats.multivariate_normal.mean->mean.astype(cov.dtype).astype(cov.dtype)
A:jax.scipy.stats.multivariate_normal.two->_constant_like(x, 2)
A:jax.scipy.stats.multivariate_normal.dim->_constant_like(x, mean.shape[0])
A:jax.scipy.stats.multivariate_normal.det_sig->det(cov).astype(cov.dtype)
A:jax.scipy.stats.multivariate_normal.log_normalizer->lax.log(lax.mul(lax.pow(_constant_like(x, 2 * onp.pi), dim), det_sig))
A:jax.scipy.stats.multivariate_normal.x_2d->x.astype(cov.dtype).astype(cov.dtype).reshape((-1, mean.shape[0]))
A:jax.scipy.stats.multivariate_normal.quadratic->dot(dot(subtract(x, mean), inv(cov)), subtract(x, mean).T).astype(cov.dtype)
jax.scipy.stats.multivariate_normal.logpdf(x,mean,cov)
jax.scipy.stats.multivariate_normal.pdf(x,mean,cov)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/cauchy.py----------------------------------------
A:jax.scipy.stats.cauchy.(x, loc, scale)->_promote_args_like(osp_stats.cauchy.logpdf, x, loc, scale)
A:jax.scipy.stats.cauchy.one->_constant_like(x, 1)
A:jax.scipy.stats.cauchy.pi->_constant_like(x, onp.pi)
A:jax.scipy.stats.cauchy.scaled_x->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.cauchy.normalize_term->lax.log(lax.mul(pi, scale))
jax.scipy.stats.cauchy.logpdf(x,loc=0,scale=1)
jax.scipy.stats.cauchy.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/bernoulli.py----------------------------------------
A:jax.scipy.stats.bernoulli.(k, p, loc)->numpy.lax_numpy._promote_args_like(osp_stats.bernoulli.logpmf, k, p, loc)
A:jax.scipy.stats.bernoulli.zero->numpy.lax_numpy._constant_like(k, 0)
A:jax.scipy.stats.bernoulli.one->numpy.lax_numpy._constant_like(k, 1)
A:jax.scipy.stats.bernoulli.x->lax.sub(k, loc)
jax.scipy.stats.bernoulli.logpmf(k,p,loc=0)
jax.scipy.stats.bernoulli.pmf(k,p,loc=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/expon.py----------------------------------------
A:jax.scipy.stats.expon.(x, loc, scale)->_promote_args_like(osp_stats.expon.logpdf, x, loc, scale)
A:jax.scipy.stats.expon.log_scale->lax.log(scale)
A:jax.scipy.stats.expon.linear_term->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.expon.log_probs->lax.neg(lax.add(linear_term, log_scale))
jax.scipy.stats.expon.logpdf(x,loc=0,scale=1)
jax.scipy.stats.expon.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/t.py----------------------------------------
A:jax.scipy.stats.t.(x, df, loc, scale)->_promote_args_like(osp_stats.t.logpdf, x, df, loc, scale)
A:jax.scipy.stats.t.two->_constant_like(x, 2)
A:jax.scipy.stats.t.scaled_x->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.t.df_over_two->lax.div(df, two)
A:jax.scipy.stats.t.df_plus_one_over_two->lax.add(df_over_two, _constant_like(x, 0.5))
A:jax.scipy.stats.t.normalize_term_const->lax.mul(lax.mul(scale, scale), _constant_like(x, onp.pi))
A:jax.scipy.stats.t.normalize_term_tmp->lax.div(lax.log(lax.mul(normalize_term_const, df)), two)
A:jax.scipy.stats.t.normalize_term->lax.sub(lax.add(lax.lgamma(df_over_two), normalize_term_tmp), lax.lgamma(df_plus_one_over_two))
A:jax.scipy.stats.t.quadratic->lax.div(lax.mul(scaled_x, scaled_x), df)
jax.scipy.stats.t.logpdf(x,df,loc=0,scale=1)
jax.scipy.stats.t.pdf(x,df,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/laplace.py----------------------------------------
A:jax.scipy.stats.laplace.(x, loc, scale)->_promote_args_like(osp_stats.laplace.cdf, x, loc, scale)
A:jax.scipy.stats.laplace.two->_constant_like(x, 2)
A:jax.scipy.stats.laplace.linear_term->lax.div(lax.abs(lax.sub(x, loc)), scale)
A:jax.scipy.stats.laplace.half->_constant_like(x, 0.5)
A:jax.scipy.stats.laplace.one->_constant_like(x, 1)
A:jax.scipy.stats.laplace.zero->_constant_like(x, 0)
A:jax.scipy.stats.laplace.diff->lax.div(lax.sub(x, loc), scale)
jax.scipy.stats.laplace.cdf(x,loc=0,scale=1)
jax.scipy.stats.laplace.logpdf(x,loc=0,scale=1)
jax.scipy.stats.laplace.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/pareto.py----------------------------------------
A:jax.scipy.stats.pareto.(x, b, loc, scale)->_promote_args_like(osp_stats.pareto.logpdf, x, b, loc, scale)
A:jax.scipy.stats.pareto.one->_constant_like(x, 1)
A:jax.scipy.stats.pareto.scaled_x->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.pareto.normalize_term->lax.log(lax.div(scale, b))
A:jax.scipy.stats.pareto.log_probs->lax.neg(lax.add(normalize_term, lax.mul(lax.add(b, one), lax.log(scaled_x))))
jax.scipy.stats.pareto.logpdf(x,b,loc=0,scale=1)
jax.scipy.stats.pareto.pdf(x,b,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/norm.py----------------------------------------
A:jax.scipy.stats.norm.(x, loc, scale)->_promote_args_like(osp_stats.norm.logcdf, x, loc, scale)
A:jax.scipy.stats.norm.two->_constant_like(x, 2)
A:jax.scipy.stats.norm.scale_sqrd->lax.pow(scale, two)
A:jax.scipy.stats.norm.log_normalizer->lax.log(lax.mul(_constant_like(x, 2 * onp.pi), scale_sqrd))
A:jax.scipy.stats.norm.quadratic->lax.div(lax.pow(lax.sub(x, loc), two), scale_sqrd)
jax.scipy.stats.norm.cdf(x,loc=0,scale=1)
jax.scipy.stats.norm.logcdf(x,loc=0,scale=1)
jax.scipy.stats.norm.logpdf(x,loc=0,scale=1)
jax.scipy.stats.norm.pdf(x,loc=0,scale=1)
jax.scipy.stats.norm.ppf(q,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/dirichlet.py----------------------------------------
A:jax.scipy.stats.dirichlet.x_sum->numpy.lax_numpy.sum(x, axis=-1)
A:jax.scipy.stats.dirichlet.to_dtype->lax.dtype(osp_stats.dirichlet.logpdf(*args))
A:jax.scipy.stats.dirichlet.one->numpy.lax_numpy._constant_like(x, 1)
A:jax.scipy.stats.dirichlet.log_probs->lax.sub(np.sum(xlogy(lax.sub(alpha, one), x), axis=-1), normalize_term)
jax.scipy.stats.dirichlet._is_simplex(x)
jax.scipy.stats.dirichlet.logpdf(x,alpha)
jax.scipy.stats.dirichlet.pdf(x,alpha)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/gamma.py----------------------------------------
A:jax.scipy.stats.gamma.(x, a, loc, scale)->_promote_args_like(osp_stats.gamma.logpdf, x, a, loc, scale)
A:jax.scipy.stats.gamma.one->_constant_like(x, 1)
A:jax.scipy.stats.gamma.y->lax.div(lax.sub(x, loc), scale)
A:jax.scipy.stats.gamma.log_linear_term->lax.sub(lax.mul(lax.sub(a, one), lax.log(y)), y)
A:jax.scipy.stats.gamma.shape_terms->lax.add(gammaln(a), lax.log(scale))
A:jax.scipy.stats.gamma.log_probs->lax.sub(log_linear_term, shape_terms)
jax.scipy.stats.gamma.logpdf(x,a,loc=0,scale=1)
jax.scipy.stats.gamma.pdf(x,a,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/scipy/stats/uniform.py----------------------------------------
A:jax.scipy.stats.uniform.(x, loc, scale)->_promote_args_like(osp_stats.uniform.logpdf, x, loc, scale)
A:jax.scipy.stats.uniform.log_probs->lax.neg(lax.log(scale))
jax.scipy.stats.uniform.logpdf(x,loc=0,scale=1)
jax.scipy.stats.uniform.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lib/__init__.py----------------------------------------
A:jax.lib.__init__.version->tuple((int(x) for x in jaxlib_version.__version__.split('.')))
jax.lib.__init__._check_jaxlib_jaxlib_version()
jax.lib.__init__._check_jaxlib_version()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lib/xla_bridge.py----------------------------------------
A:jax.lib.xla_bridge.device_assignment->xla_client.DeviceAssignment.create(device_assignment)
A:jax.lib.xla_bridge.backend->_backends.get(FLAGS.jax_xla_backend)
A:jax.lib.xla_bridge.tf_context->xrt.get_tf_context(FLAGS.jax_backend_target, worker)
A:jax.lib.xla_bridge.dtype->numpy.dtype(dtype)
A:jax.lib.xla_bridge.value->normalize_to_xla_dtypes(value)
A:jax.lib.xla_bridge.example_value->numpy.asarray(example_value)
A:jax.lib.xla_bridge.py_type->type(py_val)
A:jax.lib.xla_bridge.(zero_stride_axes,)->numpy.where(onp.equal(0, val.strides))
A:jax.lib.xla_bridge.(other_axes,)->numpy.where(onp.not_equal(0, val.strides))
A:jax.lib.xla_bridge.xla_val->c.Broadcast(c.NumpyArrayConstant(collapsed_val, canonicalize_types), onp.take(val.shape, zero_stride_axes))
A:jax.lib.xla_bridge.permutation->numpy.argsort(tuple(zero_stride_axes) + tuple(other_axes))
jax.lib.xla_bridge._JaxComputationBuilder(xla_client.ComputationBuilder)
jax.lib.xla_bridge._JaxComputationBuilder.AllToAll(self,operand,split_axis,concat_axis,replica_groups)
jax.lib.xla_bridge._JaxComputationBuilder.Build(self,*args,**kwargs)
jax.lib.xla_bridge._JaxComputationBuilder.Constant(self,py_val,canonicalize_types=True)
jax.lib.xla_bridge._JaxComputationBuilder.ConstantLike(self,example_value,value,canonicalize_types=True)
jax.lib.xla_bridge._JaxComputationBuilder.CrossReplicaSum(self,operand,replica_groups)
jax.lib.xla_bridge._JaxComputationBuilder.NumpyArrayConstant(self,value,canonicalize_types=True)
jax.lib.xla_bridge._JaxComputationBuilder.Parameter(self,value,name=None,parameter_num=None)
jax.lib.xla_bridge._get_local_backend()
jax.lib.xla_bridge._get_xrt_backend()
jax.lib.xla_bridge._ndarray_constant_handler(c,val,canonicalize_types=True)
jax.lib.xla_bridge._scalar_constant_handler(c,val,canonicalize_types=True)
jax.lib.xla_bridge.canonicalize_dtype(dtype)
jax.lib.xla_bridge.device_count()
jax.lib.xla_bridge.dtype_to_etype(dtype)
jax.lib.xla_bridge.get_backend()
jax.lib.xla_bridge.get_compile_options(num_replicas=None,device_assignment=None)
jax.lib.xla_bridge.make_computation_builder(name)
jax.lib.xla_bridge.memoize_thunk(func)
jax.lib.xla_bridge.normalize_to_xla_dtypes(val)
jax.lib.xla_bridge.register_backend(name,factory)
jax.lib.xla_bridge.register_constant_handler(type_,handler_fun)
jax.lib.xla_bridge.shape_of(value)
jax.lib.xla_bridge.supported_numpy_dtypes()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/numpy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/numpy/fft.py----------------------------------------
A:jax.numpy.fft.dtype->np.result_type(arg, onp.complex64)
A:jax.numpy.fft.axes->range(a.ndim - len(s), a.ndim)
A:jax.numpy.fft.a->_promote_to_complex(a)
A:jax.numpy.fft.globals()[func.__name__]->_not_implemented(func)
jax.numpy.fft._promote_to_complex(arg)
jax.numpy.fft.fftn(a,s=None,axes=None,norm=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/numpy/linalg.py----------------------------------------
A:jax.numpy.linalg.dtype->lax.dtype(a)
A:jax.numpy.linalg.a->_promote_arg_dtypes(np.asarray(a))
A:jax.numpy.linalg.a_shape->np.shape(a)
A:jax.numpy.linalg.(lu, pivot)->lax_linalg.lu(a)
A:jax.numpy.linalg.diag->np.diagonal(lu, axis1=-2, axis2=-1)
A:jax.numpy.linalg.is_zero->np.any(diag == np.array(0, dtype=dtype), axis=-1)
A:jax.numpy.linalg.parity->np.count_nonzero(pivot != np.arange(a_shape[-1]), axis=-1)
A:jax.numpy.linalg.sign->np.where(is_zero, np.array(0, dtype=dtype), sign * np.array(-2 * (parity % 2) + 1, dtype=dtype))
A:jax.numpy.linalg.logdet->np.where(is_zero, np.array(-np.inf, dtype=dtype), np.sum(np.log(np.abs(diag)), axis=-1))
A:jax.numpy.linalg.(sign, logdet)->slogdet(a)
A:jax.numpy.linalg.(w, vl, vr)->lax_linalg.eig(a)
A:jax.numpy.linalg.msg->"UPLO must be one of None, 'L', or 'U', got {}".format(UPLO)
A:jax.numpy.linalg.(v, w)->lax_linalg.eigh(a, lower=lower, symmetrize_input=symmetrize_input)
A:jax.numpy.linalg.x->lax_linalg.triangular_solve(lu, x, left_side=True, lower=False)
A:jax.numpy.linalg.x_shape->np.shape(x)
A:jax.numpy.linalg.ndim->len(x_shape)
A:jax.numpy.linalg.axis->tuple((np._canonicalize_axis(x, ndim) for x in axis))
A:jax.numpy.linalg.num_axes->len(axis)
A:jax.numpy.linalg.y->np.reshape(y, result_shape)
A:jax.numpy.linalg.result_shape->list(x_shape)
A:jax.numpy.linalg.(q, r)->lax_linalg.qr(a, full_matrices)
A:jax.numpy.linalg.(a, b)->_promote_arg_dtypes(np.asarray(a), np.asarray(b))
A:jax.numpy.linalg.b_shape->np.shape(b)
A:jax.numpy.linalg.a_ndims->len(a_shape)
A:jax.numpy.linalg.b_ndims->len(b_shape)
A:jax.numpy.linalg.(lu, pivots)->lax_linalg.lu(a)
A:jax.numpy.linalg.batch_dims->lax.broadcast_shapes(lu.shape[:-2], x.shape[:-2])
A:jax.numpy.linalg.lu->np.broadcast_to(lu, batch_dims + lu.shape[-2:])
A:jax.numpy.linalg.permutation->np.broadcast_to(permutation, batch_dims + (m,))
A:jax.numpy.linalg.iotas->np.ix_(*(lax.iota(np.int32, b) for b in batch_dims + (1,)))
A:jax.numpy.linalg.globals()[func.__name__]->_not_implemented(func)
jax.numpy.linalg._promote_arg_dtypes(*args)
jax.numpy.linalg.cholesky(a)
jax.numpy.linalg.det(a)
jax.numpy.linalg.eig(a)
jax.numpy.linalg.eigh(a,UPLO=None,symmetrize_input=True)
jax.numpy.linalg.inv(a)
jax.numpy.linalg.norm(x,ord=None,axis=None,keepdims=False)
jax.numpy.linalg.qr(a,mode='reduced')
jax.numpy.linalg.slogdet(a)
jax.numpy.linalg.solve(a,b)
jax.numpy.linalg.svd(a,full_matrices=True,compute_uv=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/numpy/lax_numpy.py----------------------------------------
A:jax.numpy.lax_numpy.nd->ndim(array)
A:jax.numpy.lax_numpy.from_dtypes->map(_dtype, args)
A:jax.numpy.lax_numpy.to_dtype->_result_dtype(op, *args)
A:jax.numpy.lax_numpy.(pos, arg)->next(((i, arg) for (i, arg) in enumerate(args) if not_array(arg)))
A:jax.numpy.lax_numpy._numpy_signature_re->lax.real(x).compile('^([\\w., ]+=)?\\s*[\\w\\.]+\\(.*\\)$')
A:jax.numpy.lax_numpy.sections->fun.__doc__.split('\n\n')
A:jax.numpy.lax_numpy.summary->sections[i].strip()
A:jax.numpy.lax_numpy.body->'\n\n'.join(signatures + sections[i + 1:])
A:jax.numpy.lax_numpy.docstr->'{summary}\n\nLAX-backend implementation of :func:`{fun}`. Original docstring below.\n\n{body}'.format(summary=summary, fun=fun.__name__, body=body)
A:jax.numpy.lax_numpy.axis->_canonicalize_axis(axis, ndim(a))
A:jax.numpy.lax_numpy.absoluteabs->_one_to_one_unop(onp.absolute, lax.abs)
A:jax.numpy.lax_numpy.fabs->_one_to_one_unop(onp.fabs, lax.abs, True)
A:jax.numpy.lax_numpy.bitwise_not->_one_to_one_unop(onp.bitwise_not, lax.bitwise_not)
A:jax.numpy.lax_numpy.negative->_one_to_one_unop(onp.negative, lax.neg)
A:jax.numpy.lax_numpy.positive->_one_to_one_unop(onp.positive, lambda x: x)
A:jax.numpy.lax_numpy.sign->_one_to_one_unop(onp.sign, lax.sign)
A:jax.numpy.lax_numpy.floor->_one_to_one_unop(onp.floor, lax.floor, True)
A:jax.numpy.lax_numpy.ceil->_one_to_one_unop(onp.ceil, lax.ceil, True)
A:jax.numpy.lax_numpy.exp->_one_to_one_unop(onp.exp, lax.exp, True)
A:jax.numpy.lax_numpy.log->_one_to_one_unop(onp.log, lax.log, True)
A:jax.numpy.lax_numpy.expm1->_one_to_one_unop(onp.expm1, lax.expm1, True)
A:jax.numpy.lax_numpy.log1p->_one_to_one_unop(onp.log1p, lax.log1p, True)
A:jax.numpy.lax_numpy.sin->_one_to_one_unop(onp.sin, lax.sin, True)
A:jax.numpy.lax_numpy.cos->_one_to_one_unop(onp.cos, lax.cos, True)
A:jax.numpy.lax_numpy.tan->_one_to_one_unop(onp.tan, lax.tan, True)
A:jax.numpy.lax_numpy.arcsin->_one_to_one_unop(onp.arcsin, lax.asin, True)
A:jax.numpy.lax_numpy.arccos->_one_to_one_unop(onp.arccos, lax.acos, True)
A:jax.numpy.lax_numpy.arctan->_one_to_one_unop(onp.arctan, lax.atan, True)
A:jax.numpy.lax_numpy.sinh->_one_to_one_unop(onp.sinh, lax.sinh, True)
A:jax.numpy.lax_numpy.cosh->_one_to_one_unop(onp.cosh, lax.cosh, True)
A:jax.numpy.lax_numpy.tanh->_one_to_one_unop(onp.tanh, lax.tanh, True)
A:jax.numpy.lax_numpy.arcsinh->_one_to_one_unop(onp.arcsinh, lax.asinh, True)
A:jax.numpy.lax_numpy.arccosh->_one_to_one_unop(onp.arccosh, lax.acosh, True)
A:jax.numpy.lax_numpy.arctanh->_one_to_one_unop(onp.arctanh, lax.atanh, True)
A:jax.numpy.lax_numpy.sqrt->_one_to_one_unop(onp.sqrt, lax.sqrt, True)
A:jax.numpy.lax_numpy.add->_one_to_one_binop(onp.add, lax.add)
A:jax.numpy.lax_numpy.bitwise_and->_one_to_one_binop(onp.bitwise_and, lax.bitwise_and)
A:jax.numpy.lax_numpy.bitwise_or->_one_to_one_binop(onp.bitwise_or, lax.bitwise_or)
A:jax.numpy.lax_numpy.bitwise_xor->_one_to_one_binop(onp.bitwise_xor, lax.bitwise_xor)
A:jax.numpy.lax_numpy.right_shift->_one_to_one_binop(onp.right_shift, lax.shift_right_arithmetic)
A:jax.numpy.lax_numpy.left_shift->_one_to_one_binop(onp.left_shift, lax.shift_left)
A:jax.numpy.lax_numpy.equal->_one_to_one_binop(onp.equal, lax.eq)
A:jax.numpy.lax_numpy.multiply->_one_to_one_binop(onp.multiply, lax.mul)
A:jax.numpy.lax_numpy.not_equal->_one_to_one_binop(onp.not_equal, lax.ne)
A:jax.numpy.lax_numpy.subtract->_one_to_one_binop(onp.subtract, lax.sub)
A:jax.numpy.lax_numpy.arctan2->_one_to_one_binop(onp.arctan2, lax.atan2, True)
A:jax.numpy.lax_numpy.minimum->_one_to_one_binop(onp.minimum, lax.min)
A:jax.numpy.lax_numpy.maximum->_one_to_one_binop(onp.maximum, lax.max)
A:jax.numpy.lax_numpy.float_power->_one_to_one_binop(onp.float_power, lax.pow, True)
A:jax.numpy.lax_numpy.(x, y)->_promote_to_result_dtype(onp.hypot, x, y)
A:jax.numpy.lax_numpy.rx->lax.real(x)
A:jax.numpy.lax_numpy.ry->lax.real(y)
A:jax.numpy.lax_numpy.greater_equal->_comparison_op(onp.greater_equal, lax.ge)
A:jax.numpy.lax_numpy.greater->_comparison_op(onp.greater, lax.gt)
A:jax.numpy.lax_numpy.less_equal->_comparison_op(onp.less_equal, lax.le)
A:jax.numpy.lax_numpy.less->_comparison_op(onp.less, lax.lt)
A:jax.numpy.lax_numpy.logical_and->_logical_op(onp.logical_and, lax.bitwise_and)
A:jax.numpy.lax_numpy.logical_not->_logical_op(onp.logical_not, lax.bitwise_not)
A:jax.numpy.lax_numpy.logical_or->_logical_op(onp.logical_or, lax.bitwise_or)
A:jax.numpy.lax_numpy.logical_xor->_logical_op(onp.logical_xor, lax.bitwise_xor)
A:jax.numpy.lax_numpy.result_dtype->_dtype(np_fun(onp.ones((), dtype=dtype or _dtype(a))))
A:jax.numpy.lax_numpy.(x1, x2)->broadcast_arrays(x1, x2)
A:jax.numpy.lax_numpy.dtype->_dtype(x)
A:jax.numpy.lax_numpy.quotient->lax.div(x1, x2)
A:jax.numpy.lax_numpy.select->logical_and(lax.sign(x1) != lax.sign(x2), lax.rem(x1, x2) != 0)
A:jax.numpy.lax_numpy.x1r->lax.real(x1)
A:jax.numpy.lax_numpy.x1i->lax.imag(x1)
A:jax.numpy.lax_numpy.x2r->lax.real(x2)
A:jax.numpy.lax_numpy.x2i->lax.imag(x2)
A:jax.numpy.lax_numpy.which->lax.ge(lax.abs(x2r), lax.abs(x2i))
A:jax.numpy.lax_numpy.rat1->where(which, lax._const(x2i, 1), lax.div(x2r, x2i))
A:jax.numpy.lax_numpy.rat2->where(which, lax.div(x2i, x2r), lax._const(x2i, 1))
A:jax.numpy.lax_numpy.out->lax.reshape(out, (1,) * (ndmin - ndim(out)) + shape(out))
A:jax.numpy.lax_numpy.mod->lax.select(ind, mod + x1, mod)
A:jax.numpy.lax_numpy.div->lax.select(ind, div - _constant_like(div, 1), div)
A:jax.numpy.lax_numpy.ind->lax.bitwise_and(mod != 0, lax.sign(x2) != lax.sign(mod))
A:jax.numpy.lax_numpy.x1->lax.mul(x1, x1)
A:jax.numpy.lax_numpy.x2->lax.shift_right_logical(x2, _constant_like(x2, 1))
A:jax.numpy.lax_numpy.acc->where(lax.bitwise_and(x2, _constant_like(x2, 1)), lax.mul(acc, x1), acc)
A:jax.numpy.lax_numpy.amax->lax.max(x1, x2)
A:jax.numpy.lax_numpy.(x,)->_promote_to_result_dtype(onp.sinc, x)
A:jax.numpy.lax_numpy.fmod->_wraps(onp.fmod)(lambda x, y: lax.rem(x, y))
A:jax.numpy.lax_numpy.zero->lax._const(x, 0)
A:jax.numpy.lax_numpy.pi_x->lax.mul(lax._const(x, pi), x)
A:jax.numpy.lax_numpy.perm->tuple([names.index(name) for name in result_names])
A:jax.numpy.lax_numpy.rank->ndim(arr)
A:jax.numpy.lax_numpy.i->array(i)
A:jax.numpy.lax_numpy.re->lax.real(x)
A:jax.numpy.lax_numpy.im->lax.imag(x)
A:jax.numpy.lax_numpy.slice1[axis]->slice(1, None)
A:jax.numpy.lax_numpy.slice2[axis]->slice(None, -1)
A:jax.numpy.lax_numpy.slice1->tuple(slice1)
A:jax.numpy.lax_numpy.slice2->tuple(slice2)
A:jax.numpy.lax_numpy.a->lax.sort(a, dimension=axis)
A:jax.numpy.lax_numpy.dummy_val->numpy.broadcast_to(0, ary.shape)
A:jax.numpy.lax_numpy.order->kwargs.pop('order', 'C')
A:jax.numpy.lax_numpy.invalid_kwargs->"'{}'".format("'".join(kwargs))
A:jax.numpy.lax_numpy.shape->_shape(a)
A:jax.numpy.lax_numpy.source->numpy.mod(source, ndim(a)).reshape(-1)
A:jax.numpy.lax_numpy.destination->numpy.mod(destination, ndim(a)).reshape(-1)
A:jax.numpy.lax_numpy.(a, b)->_promote_dtypes(a, b)
A:jax.numpy.lax_numpy.rtol->lax.convert_element_type(rtol, dtype)
A:jax.numpy.lax_numpy.atol->lax.convert_element_type(atol, dtype)
A:jax.numpy.lax_numpy.numpy_version->tuple(map(int, onp.version.version.split('.')))
A:jax.numpy.lax_numpy.condition->lax.ne(condition, zeros_like(condition))
A:jax.numpy.lax_numpy.(condition, x, y)->broadcast_arrays(condition, x, y)
A:jax.numpy.lax_numpy.(empty, _)->_promote_dtypes(x, y)
A:jax.numpy.lax_numpy.output->where(cond, choice, output)
A:jax.numpy.lax_numpy.result_shape->lax.broadcast_shapes(*shapes)
A:jax.numpy.lax_numpy.(diff,)->numpy.where(onp.not_equal(shape[nlead:], _shape(arr)))
A:jax.numpy.lax_numpy.kept_dims->tuple(onp.delete(onp.arange(len(shape)), new_dims))
A:jax.numpy.lax_numpy.broadcast_dims->numpy.concatenate((onp.arange(0, axis + 1), onp.arange(axis + 2, num_dims + 1)))
A:jax.numpy.lax_numpy.squeezed_array->squeeze(arr, diff)
A:jax.numpy.lax_numpy.subarrays->numpy.split(dummy_val, indices_or_sections, axis)
A:jax.numpy.lax_numpy.split_indices->numpy.cumsum([0] + [onp.shape(sub)[axis] for sub in subarrays])
A:jax.numpy.lax_numpy.vsplit->_split_on_axis(onp.vsplit, axis=0)
A:jax.numpy.lax_numpy.hsplit->_split_on_axis(onp.hsplit, axis=1)
A:jax.numpy.lax_numpy.dsplit->_split_on_axis(onp.dsplit, axis=2)
A:jax.numpy.lax_numpy.a_min->lax.convert_element_type(a_min, _dtype(a))
A:jax.numpy.lax_numpy.a_max->lax.convert_element_type(a_max, _dtype(a))
A:jax.numpy.lax_numpy.factor->_constant_like(x, 10 ** decimals)
A:jax.numpy.lax_numpy.isposinf->_wraps(onp.isposinf)(partial(_isposneginf, inf))
A:jax.numpy.lax_numpy.isneginf->_wraps(onp.isneginf)(partial(_isposneginf, -inf))
A:jax.numpy.lax_numpy.info->finfo(xla_bridge.canonicalize_dtype(dtype))
A:jax.numpy.lax_numpy.x->remainder(x, a_shape[i] or 1)
A:jax.numpy.lax_numpy.dims->_reduction_dims(a, axis)
A:jax.numpy.lax_numpy.result->lax.dot_general(lhs, rhs, dimension_numbers)
A:jax.numpy.lax_numpy.shape_with_singletons->lax.subvals(shape(a), zip(dims, (1,) * len(dims)))
A:jax.numpy.lax_numpy.a_dtype->lib.xla_bridge.canonicalize_dtype(_dtype(a))
A:jax.numpy.lax_numpy._cast_to_bool->partial(lax.convert_element_type, new_dtype=onp.bool_)
A:jax.numpy.lax_numpy.sum->_make_reduction(onp.sum, lax.add, 0)
A:jax.numpy.lax_numpy.productprod->_make_reduction(onp.prod, lax.mul, 1)
A:jax.numpy.lax_numpy.amaxmax->_make_reduction(onp.max, lax.max, -onp.inf)
A:jax.numpy.lax_numpy.aminmin->_make_reduction(onp.min, lax.min, onp.inf)
A:jax.numpy.lax_numpy.allalltrue->_make_reduction(onp.all, lax.bitwise_and, True, _cast_to_bool)
A:jax.numpy.lax_numpy.anysometrue->_make_reduction(onp.any, lax.bitwise_or, False, _cast_to_bool)
A:jax.numpy.lax_numpy.normalizer->numpy.prod(onp.take(shape(a), axis))
A:jax.numpy.lax_numpy.avg->mean(a, axis=axis)
A:jax.numpy.lax_numpy.weights_sum->broadcast_to(weights_sum, avg.shape)
A:jax.numpy.lax_numpy.weights->moveaxis(weights, -1, axis)
A:jax.numpy.lax_numpy.out_dtype->lib.xla_bridge.canonicalize_dtype(result_type(a.dtype, weights.dtype))
A:jax.numpy.lax_numpy.a_shape->shape(a)
A:jax.numpy.lax_numpy.a_ndim->len(a_shape)
A:jax.numpy.lax_numpy.weights_shape->shape(weights)
A:jax.numpy.lax_numpy.centered->lax.abs(centered)
A:jax.numpy.lax_numpy.y->lax.rev(y, indexer.reversed_y_dims)
A:jax.numpy.lax_numpy.nanmin->_make_nan_reduction(onp.nanmin, min, inf, nan_if_all_nan=True)
A:jax.numpy.lax_numpy.nanmax->_make_nan_reduction(onp.nanmax, max, -inf, nan_if_all_nan=True)
A:jax.numpy.lax_numpy.nansum->_make_nan_reduction(onp.nansum, sum, 0, nan_if_all_nan=False)
A:jax.numpy.lax_numpy.nanprod->_make_nan_reduction(onp.nanprod, prod, 1, nan_if_all_nan=False)
A:jax.numpy.lax_numpy.num_dims->len(a_shape)
A:jax.numpy.lax_numpy.cumsum->_make_cumulative_reduction(onp.cumsum, lax._reduce_window_sum, 0, squash_nan=False)
A:jax.numpy.lax_numpy.cumprod->_make_cumulative_reduction(onp.cumprod, lax._reduce_window_prod, 1, squash_nan=False)
A:jax.numpy.lax_numpy.nancumsum->_make_cumulative_reduction(onp.nancumsum, lax._reduce_window_sum, 0, squash_nan=True)
A:jax.numpy.lax_numpy.nancumprod->_make_cumulative_reduction(onp.nancumprod, lax._reduce_window_prod, 1, squash_nan=True)
A:jax.numpy.lax_numpy.array->lax.concatenate(parts, dimension=i)
A:jax.numpy.lax_numpy.pad_width->numpy.broadcast_to(onp.asarray(pad_width), (nd, 2))
A:jax.numpy.lax_numpy.constant_values->lax.convert_element_type(constant_values, array.dtype)
A:jax.numpy.lax_numpy.rarray->lax.rev(array, dimensions=(i,))
A:jax.numpy.lax_numpy.parts->reversed(build_padding(pad_width[i, 0], forward=not wrap_mode))
A:jax.numpy.lax_numpy.shape0->shape(arrays[0])
A:jax.numpy.lax_numpy.new_shape->list(shape0)
A:jax.numpy.lax_numpy.arrays->_promote_dtypes(*arrays)
A:jax.numpy.lax_numpy.arr->asarray(arr)
A:jax.numpy.lax_numpy.view->memoryview(object)
A:jax.numpy.lax_numpy.k_dtype->_dtype(k)
A:jax.numpy.lax_numpy.cols->lax.broadcasted_iota(k_dtype, (N, M), 1)
A:jax.numpy.lax_numpy.n->len(args)
A:jax.numpy.lax_numpy.broadcast_shape->list(a_shape)
A:jax.numpy.lax_numpy.mask->tri(*m_shape[-2:], k=k - 1, dtype=bool)
A:jax.numpy.lax_numpy.m_shape->shape(m)
A:jax.numpy.lax_numpy.default_int->lib.xla_bridge.canonicalize_dtype(onp.int_)
A:jax.numpy.lax_numpy.a_ndims->len(shape(a))
A:jax.numpy.lax_numpy.d->diag(c)
A:jax.numpy.lax_numpy.diag_size->_max(0, _min(a_shape[axis1] + _min(offset, 0), a_shape[axis2] - _max(offset, 0)))
A:jax.numpy.lax_numpy.v_shape->shape(v)
A:jax.numpy.lax_numpy.v->lax.pad(v, zero(v), ((_max(0, k), _max(0, -k), 0),))
A:jax.numpy.lax_numpy.p->numpy.asarray(p)
A:jax.numpy.lax_numpy.batch_shape->lax.broadcast_shapes(shape(a)[:-2], shape(b)[:-2])
A:jax.numpy.lax_numpy.b->reshape(b, (1,) * (ndim(a) - ndim(b)) + shape(b))
A:jax.numpy.lax_numpy.batch_dims->tuple(range(nbatch))
A:jax.numpy.lax_numpy.a_reshape->lax.reshape(a, (_prod(a.shape[:-axes]), _prod(a.shape[-axes:])))
A:jax.numpy.lax_numpy.b_reshape->lax.reshape(b, (_prod(b.shape[:axes]), _prod(b.shape[axes:])))
A:jax.numpy.lax_numpy.out_reshape->lax.dot(a_reshape, b_reshape)
A:jax.numpy.lax_numpy.num_axes->len(ax1)
A:jax.numpy.lax_numpy.a_transposed->moveaxis(a, ax1, tuple(range(a.ndim - num_axes, a.ndim)))
A:jax.numpy.lax_numpy.b_transposed->moveaxis(b, ax2, tuple(range(num_axes)))
A:jax.numpy.lax_numpy.optimize->kwargs.pop('optimize', 'greedy')
A:jax.numpy.lax_numpy.(operands, contractions)->opt_einsum.contract_path(*operands, einsum_call=True, use_blas=True, optimize=optimize)
A:jax.numpy.lax_numpy.contractions->tuple((data[:3] for data in contractions))
A:jax.numpy.lax_numpy.operands->list(_promote_dtypes(*operands))
A:jax.numpy.lax_numpy.operand->lax.transpose(operand, perm)
A:jax.numpy.lax_numpy.names->names.replace(name, '', count - 1).replace(name, '', count - 1)
A:jax.numpy.lax_numpy.eye->lax.broadcasted_eye(operand.dtype, operand.shape, axes)
A:jax.numpy.lax_numpy.(input_str, result_names)->einstr.split('->')
A:jax.numpy.lax_numpy.input_names->input_str.split(',')
A:jax.numpy.lax_numpy.counts->collections.Counter(names)
A:jax.numpy.lax_numpy.(operand, names)->sum_repeats(operand, names, counts, result_names)
A:jax.numpy.lax_numpy.(lhs, rhs)->map(operands.pop, operand_indices)
A:jax.numpy.lax_numpy.(lhs_counts, rhs_counts)->map(collections.Counter, input_names)
A:jax.numpy.lax_numpy.(lhs, lhs_names)->sum_repeats(lhs, lhs_names, lhs_counts, result_names + rhs_names)
A:jax.numpy.lax_numpy.(rhs, rhs_names)->sum_repeats(rhs, rhs_names, rhs_counts, result_names + lhs_names)
A:jax.numpy.lax_numpy.(lhs_batch, rhs_batch)->unzip2(((lhs_names.find(n), rhs_names.find(n)) for n in batch_names))
A:jax.numpy.lax_numpy.lhs->lhs.reshape(lhs.shape[:nbatch] + (-1,) + lhs.shape[-1:]).reshape(lhs.shape[:nbatch] + (-1,) + lhs.shape[-1:])
A:jax.numpy.lax_numpy.lhs_names->_movechars(lhs_names, lhs_batch, batch_dims)
A:jax.numpy.lax_numpy.rhs->rhs.reshape(rhs.shape[:nbatch] + (-1,) + rhs.shape[-1:]).reshape(rhs.shape[:nbatch] + (-1,) + rhs.shape[-1:])
A:jax.numpy.lax_numpy.rhs_names->_movechars(rhs_names, rhs_batch, batch_dims)
A:jax.numpy.lax_numpy.batch_names->''.join((lhs_names[i] for i in range(len(lhs_names)) if i in batch_dims))
A:jax.numpy.lax_numpy.(lhs_cont, rhs_cont)->unzip2(((lhs_names.index(n), rhs_names.index(n)) for n in contracted_names))
A:jax.numpy.lax_numpy.nbatch->len(batch_names)
A:jax.numpy.lax_numpy.ncont->len(lhs_cont)
A:jax.numpy.lax_numpy.lhs_cdims->tuple(range(lhs.ndim - ncont, lhs.ndim))
A:jax.numpy.lax_numpy.rhs_cdims->tuple(range(rhs.ndim - ncont, rhs.ndim))
A:jax.numpy.lax_numpy.b_ndims->len(shape(b))
A:jax.numpy.lax_numpy.axisa->_canonicalize_axis(axisa, a_ndims)
A:jax.numpy.lax_numpy.axisb->_canonicalize_axis(axisb, b_ndims)
A:jax.numpy.lax_numpy.b_shape->lax.broadcast_shapes(shift.shape, axis.shape, (1,))
A:jax.numpy.lax_numpy.c->lax.complex(real_part, complex_part)
A:jax.numpy.lax_numpy.c_ndims->len(shape(c))
A:jax.numpy.lax_numpy.axisc->_canonicalize_axis(axisc, c_ndims)
A:jax.numpy.lax_numpy.a_reshaped->reshape(a, [i for d in shape(a) for i in (d, 1)])
A:jax.numpy.lax_numpy.b_reshaped->reshape(b, [i for d in shape(b) for i in (1, d)])
A:jax.numpy.lax_numpy.out_shape->lax.broadcast_shapes(idx_shape, tuple(arr_shape))
A:jax.numpy.lax_numpy.x_shape->shape(x)
A:jax.numpy.lax_numpy.iota->lax.broadcast_in_dim(iota, gather_index_shape, (j,))
A:jax.numpy.lax_numpy.idxs->numpy.arange(a.shape[axis]).reshape(shape)
A:jax.numpy.lax_numpy.mask_idxs->where(lax._eq_meet(a, op(a, axis, keepdims=True)), idxs, maxval)
A:jax.numpy.lax_numpy.(_, perm)->lax.sort_key_val(a, iota, dimension=axis)
A:jax.numpy.lax_numpy.shift->asarray(shift)
A:jax.numpy.lax_numpy.indices->mod(indices, _constant_like(indices, a.shape[axis]))
A:jax.numpy.lax_numpy.index_dims->len(shape(indices))
A:jax.numpy.lax_numpy.slice_sizes->list(a_shape)
A:jax.numpy.lax_numpy.dnums->lax.GatherDimensionNumbers(offset_dims=tuple(range(q_ndim, len(a_shape) + q_ndim if keepdims else len(a_shape) + q_ndim - 1)), collapsed_slice_dims=() if keepdims else (axis,), start_index_map=(axis,))
A:jax.numpy.lax_numpy.arr_shape->list(shape(arr))
A:jax.numpy.lax_numpy.idx_shape->shape(indices)
A:jax.numpy.lax_numpy.gather_indices->concatenate((gather_indices, i), len(gather_indices_shape))
A:jax.numpy.lax_numpy.indexer->_index_to_gather(shape(arr), idx)
A:jax.numpy.lax_numpy._Indexer->collections.namedtuple('_Indexer', ['slice_shape', 'gather_slice_shape', 'gather_indices', 'dnums', 'reversed_y_dims', 'newaxis_dims'])
A:jax.numpy.lax_numpy.idx->tuple(idx)
A:jax.numpy.lax_numpy.(advanced_indexes, idx_advanced_axes, x_advanced_axes)->zip(*advanced_pairs)
A:jax.numpy.lax_numpy.advanced_axes_are_contiguous->numpy.all(onp.diff(idx_advanced_axes) == 1)
A:jax.numpy.lax_numpy.advanced_indexes->broadcast_arrays(*advanced_indexes)
A:jax.numpy.lax_numpy.ndim->len(shape)
A:jax.numpy.lax_numpy.abstract_i->core.get_aval(i)
A:jax.numpy.lax_numpy.(start, limit, stride, needs_rev)->_static_idx(i, x_shape[x_axis])
A:jax.numpy.lax_numpy.len_without_none->_sum((1 for e in idx if e is not None and e is not Ellipsis))
A:jax.numpy.lax_numpy.ellipsis_index->next(ellipses, None)
A:jax.numpy.lax_numpy.(start, stop, step)->tuple(idx).indices(size)
A:jax.numpy.lax_numpy.(gcd, _)->lax.while_loop(cond_fn, body_fn, (x1, x2))
A:jax.numpy.lax_numpy.X->array(m, ndmin=2, dtype=result_type(m, onp.float64), copy=False)
A:jax.numpy.lax_numpy.w->asarray(fweights)
A:jax.numpy.lax_numpy.(avg, w_sum)->average(X, axis=1, weights=w, returned=True)
A:jax.numpy.lax_numpy.stddev->sqrt(real(d))
A:jax.numpy.lax_numpy.real_part->clip(real(c), -1, 1)
A:jax.numpy.lax_numpy.complex_part->clip(imag(c), -1, 1)
A:jax.numpy.lax_numpy.q->true_divide(asarray(q), float32(100.0))
A:jax.numpy.lax_numpy.q_ndim->ndim(q)
A:jax.numpy.lax_numpy.(a, q)->_promote_dtypes(a, q)
A:jax.numpy.lax_numpy.low->lax.convert_element_type(low, int64)
A:jax.numpy.lax_numpy.high->lax.convert_element_type(high, int64)
A:jax.numpy.lax_numpy.high_weight->lax.broadcast_in_dim(high_weight, high_value.shape, broadcast_dimensions=(0,))
A:jax.numpy.lax_numpy.low_weight->lax.broadcast_in_dim(low_weight, low_value.shape, broadcast_dimensions=(0,))
A:jax.numpy.lax_numpy.low_value->lax.gather(a, low, dimension_numbers=dnums, slice_sizes=slice_sizes)
A:jax.numpy.lax_numpy.high_value->lax.gather(a, high, dimension_numbers=dnums, slice_sizes=slice_sizes)
A:jax.numpy.lax_numpy.globals()[func.__name__]->_not_implemented(func)
jax.numpy._ArrayMeta(type(onp.ndarray))
jax.numpy._ArrayMeta.__instancecheck__(self,instance)
jax.numpy._argminmax(op,a,axis)
jax.numpy._canonicalize_axis(axis,num_dims)
jax.numpy._canonicalize_tuple_index(arr_ndim,idx)
jax.numpy._check_arraylike(fun_name,*args)
jax.numpy._comparison_op(numpy_fn,lax_fn)
jax.numpy._constant_like(x,const)
jax.numpy._dot_general(lhs,rhs,lhs_cont,rhs_cont,nbatch)
jax.numpy._dtype_info(dtype)
jax.numpy._einsum(operands,contractions)
jax.numpy._eliminate_deprecated_list_indexing(idx)
jax.numpy._expand_bool_indices(idx)
jax.numpy._float_divmod(x1,x2)
jax.numpy._index_to_gather(x_shape,idx)
jax.numpy._is_advanced_int_indexer(idx)
jax.numpy._is_int_arraylike(x)
jax.numpy._is_slice_none(idx)
jax.numpy._isposneginf(infinity,x)
jax.numpy._logical_op(np_op,bitwise_op)
jax.numpy._make_cumulative_reduction(onp_reduction,window_reduce,init_val,squash_nan=False)
jax.numpy._make_nan_reduction(onp_reduction,np_reduction,init_val,nan_if_all_nan)
jax.numpy._make_reduction(np_fun,op,init_val,preproc=None)
jax.numpy._movechars(s,src,dst)
jax.numpy._not_implemented(fun)
jax.numpy._one_to_one_binop(numpy_fn,lax_fn,promote_like=False)
jax.numpy._one_to_one_unop(numpy_fn,lax_fn,promote_like=False)
jax.numpy._pad(array,pad_width,mode,constant_values)
jax.numpy._promote_args(fun_name,*args)
jax.numpy._promote_args_like(op,*args)
jax.numpy._promote_dtypes(*args)
jax.numpy._promote_shapes(*args)
jax.numpy._promote_to_result_dtype(op,*args)
jax.numpy._reduction_dims(a,axis)
jax.numpy._reduction_init_val(a,init_val)
jax.numpy._reshape(a,newshape,order='C')
jax.numpy._reshape_method(a,*newshape,**kwargs)
jax.numpy._result_dtype(op,*args)
jax.numpy._rewriting_take(arr,idx)
jax.numpy._should_unpack_list_index(x)
jax.numpy._split_on_axis(onp_fun,axis)
jax.numpy._static_idx(idx,size)
jax.numpy._swap_args(f)
jax.numpy._take_along_axis(arr,indices,axis)
jax.numpy._unimplemented_setitem(self,i,x)
jax.numpy._wraps(fun)
jax.numpy.allclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.angle(x)
jax.numpy.append(arr,values,axis=None)
jax.numpy.arange(start,stop=None,step=None,dtype=None)
jax.numpy.argmax(a,axis=None)
jax.numpy.argmin(a,axis=None)
jax.numpy.argsort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.array(object,dtype=None,copy=True,order='K',ndmin=0)
jax.numpy.array_equal(a1,a2)
jax.numpy.asarray(a,dtype=None,order=None)
jax.numpy.atleast_1d(*arys)
jax.numpy.atleast_2d(*arys)
jax.numpy.atleast_3d(*arys)
jax.numpy.average(a,axis=None,weights=None,returned=False)
jax.numpy.broadcast_arrays(*args)
jax.numpy.broadcast_to(arr,shape)
jax.numpy.cbrt(x)
jax.numpy.clip(a,a_min=None,a_max=None)
jax.numpy.column_stack(tup)
jax.numpy.concatenate(arrays,axis=0)
jax.numpy.conjugate(x)
jax.numpy.corrcoef(x,y=None,rowvar=True,bias=None,ddof=None)
jax.numpy.count_nonzero(a,axis=None)
jax.numpy.cov(m,y=None,rowvar=True,bias=False,ddof=None,fweights=None,aweights=None)
jax.numpy.cross(a,b,axisa=-1,axisb=-1,axisc=-1,axis=None)
jax.numpy.deg2rad(x)
jax.numpy.diag(v,k=0)
jax.numpy.diagonal(a,offset=0,axis1=0,axis2=1)
jax.numpy.diff(a,n=1,axis=-1)
jax.numpy.divide(x1,x2)
jax.numpy.divmod(x1,x2)
jax.numpy.dot(a,b)
jax.numpy.dstack(tup)
jax.numpy.einsum(*operands,**kwargs)
jax.numpy.einsum_path(subscripts,*operands,**kwargs)
jax.numpy.exp2(x)
jax.numpy.expand_dims(a,axis)
jax.numpy.eye(N,M=None,k=None,dtype=onp.dtype('float64'))
jax.numpy.fix(x,out=None)
jax.numpy.flip(m,axis)
jax.numpy.fliplr(m)
jax.numpy.flipud(m)
jax.numpy.floor_divide(x1,x2)
jax.numpy.full(shape,fill_value,dtype=None)
jax.numpy.full_like(a,fill_value,dtype=None)
jax.numpy.gcd(x1,x2)
jax.numpy.heaviside(x,y)
jax.numpy.hstack(tup)
jax.numpy.hypot(x,y)
jax.numpy.identity(n,dtype=None)
jax.numpy.imag(x)
jax.numpy.inner(a,b)
jax.numpy.isclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.iscomplex(x)
jax.numpy.isfinite(x)
jax.numpy.isinf(x)
jax.numpy.isnan(x)
jax.numpy.isreal(x)
jax.numpy.isrealobj(a)
jax.numpy.ix_(*args)
jax.numpy.kron(a,b)
jax.numpy.lax_numpy._ArrayMeta(type(onp.ndarray))
jax.numpy.lax_numpy._ArrayMeta.__instancecheck__(self,instance)
jax.numpy.lax_numpy._argminmax(op,a,axis)
jax.numpy.lax_numpy._canonicalize_axis(axis,num_dims)
jax.numpy.lax_numpy._canonicalize_tuple_index(arr_ndim,idx)
jax.numpy.lax_numpy._check_arraylike(fun_name,*args)
jax.numpy.lax_numpy._comparison_op(numpy_fn,lax_fn)
jax.numpy.lax_numpy._constant_like(x,const)
jax.numpy.lax_numpy._dot_general(lhs,rhs,lhs_cont,rhs_cont,nbatch)
jax.numpy.lax_numpy._dtype_info(dtype)
jax.numpy.lax_numpy._einsum(operands,contractions)
jax.numpy.lax_numpy._eliminate_deprecated_list_indexing(idx)
jax.numpy.lax_numpy._expand_bool_indices(idx)
jax.numpy.lax_numpy._float_divmod(x1,x2)
jax.numpy.lax_numpy._index_to_gather(x_shape,idx)
jax.numpy.lax_numpy._is_advanced_int_indexer(idx)
jax.numpy.lax_numpy._is_int_arraylike(x)
jax.numpy.lax_numpy._is_slice_none(idx)
jax.numpy.lax_numpy._isposneginf(infinity,x)
jax.numpy.lax_numpy._logical_op(np_op,bitwise_op)
jax.numpy.lax_numpy._make_cumulative_reduction(onp_reduction,window_reduce,init_val,squash_nan=False)
jax.numpy.lax_numpy._make_nan_reduction(onp_reduction,np_reduction,init_val,nan_if_all_nan)
jax.numpy.lax_numpy._make_reduction(np_fun,op,init_val,preproc=None)
jax.numpy.lax_numpy._movechars(s,src,dst)
jax.numpy.lax_numpy._not_implemented(fun)
jax.numpy.lax_numpy._one_to_one_binop(numpy_fn,lax_fn,promote_like=False)
jax.numpy.lax_numpy._one_to_one_unop(numpy_fn,lax_fn,promote_like=False)
jax.numpy.lax_numpy._pad(array,pad_width,mode,constant_values)
jax.numpy.lax_numpy._promote_args(fun_name,*args)
jax.numpy.lax_numpy._promote_args_like(op,*args)
jax.numpy.lax_numpy._promote_dtypes(*args)
jax.numpy.lax_numpy._promote_shapes(*args)
jax.numpy.lax_numpy._promote_to_result_dtype(op,*args)
jax.numpy.lax_numpy._reduction_dims(a,axis)
jax.numpy.lax_numpy._reduction_init_val(a,init_val)
jax.numpy.lax_numpy._reshape(a,newshape,order='C')
jax.numpy.lax_numpy._reshape_method(a,*newshape,**kwargs)
jax.numpy.lax_numpy._result_dtype(op,*args)
jax.numpy.lax_numpy._rewriting_take(arr,idx)
jax.numpy.lax_numpy._should_unpack_list_index(x)
jax.numpy.lax_numpy._split_on_axis(onp_fun,axis)
jax.numpy.lax_numpy._static_idx(idx,size)
jax.numpy.lax_numpy._swap_args(f)
jax.numpy.lax_numpy._take_along_axis(arr,indices,axis)
jax.numpy.lax_numpy._unimplemented_setitem(self,i,x)
jax.numpy.lax_numpy._wraps(fun)
jax.numpy.lax_numpy.allclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.lax_numpy.angle(x)
jax.numpy.lax_numpy.append(arr,values,axis=None)
jax.numpy.lax_numpy.arange(start,stop=None,step=None,dtype=None)
jax.numpy.lax_numpy.argmax(a,axis=None)
jax.numpy.lax_numpy.argmin(a,axis=None)
jax.numpy.lax_numpy.argsort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.lax_numpy.array(object,dtype=None,copy=True,order='K',ndmin=0)
jax.numpy.lax_numpy.array_equal(a1,a2)
jax.numpy.lax_numpy.asarray(a,dtype=None,order=None)
jax.numpy.lax_numpy.atleast_1d(*arys)
jax.numpy.lax_numpy.atleast_2d(*arys)
jax.numpy.lax_numpy.atleast_3d(*arys)
jax.numpy.lax_numpy.average(a,axis=None,weights=None,returned=False)
jax.numpy.lax_numpy.broadcast_arrays(*args)
jax.numpy.lax_numpy.broadcast_to(arr,shape)
jax.numpy.lax_numpy.cbrt(x)
jax.numpy.lax_numpy.clip(a,a_min=None,a_max=None)
jax.numpy.lax_numpy.column_stack(tup)
jax.numpy.lax_numpy.concatenate(arrays,axis=0)
jax.numpy.lax_numpy.conjugate(x)
jax.numpy.lax_numpy.corrcoef(x,y=None,rowvar=True,bias=None,ddof=None)
jax.numpy.lax_numpy.count_nonzero(a,axis=None)
jax.numpy.lax_numpy.cov(m,y=None,rowvar=True,bias=False,ddof=None,fweights=None,aweights=None)
jax.numpy.lax_numpy.cross(a,b,axisa=-1,axisb=-1,axisc=-1,axis=None)
jax.numpy.lax_numpy.deg2rad(x)
jax.numpy.lax_numpy.diag(v,k=0)
jax.numpy.lax_numpy.diagonal(a,offset=0,axis1=0,axis2=1)
jax.numpy.lax_numpy.diff(a,n=1,axis=-1)
jax.numpy.lax_numpy.divide(x1,x2)
jax.numpy.lax_numpy.divmod(x1,x2)
jax.numpy.lax_numpy.dot(a,b)
jax.numpy.lax_numpy.dstack(tup)
jax.numpy.lax_numpy.einsum(*operands,**kwargs)
jax.numpy.lax_numpy.einsum_path(subscripts,*operands,**kwargs)
jax.numpy.lax_numpy.exp2(x)
jax.numpy.lax_numpy.expand_dims(a,axis)
jax.numpy.lax_numpy.eye(N,M=None,k=None,dtype=onp.dtype('float64'))
jax.numpy.lax_numpy.fix(x,out=None)
jax.numpy.lax_numpy.flip(m,axis)
jax.numpy.lax_numpy.fliplr(m)
jax.numpy.lax_numpy.flipud(m)
jax.numpy.lax_numpy.floor_divide(x1,x2)
jax.numpy.lax_numpy.full(shape,fill_value,dtype=None)
jax.numpy.lax_numpy.full_like(a,fill_value,dtype=None)
jax.numpy.lax_numpy.gcd(x1,x2)
jax.numpy.lax_numpy.heaviside(x,y)
jax.numpy.lax_numpy.hstack(tup)
jax.numpy.lax_numpy.hypot(x,y)
jax.numpy.lax_numpy.identity(n,dtype=None)
jax.numpy.lax_numpy.imag(x)
jax.numpy.lax_numpy.inner(a,b)
jax.numpy.lax_numpy.isclose(a,b,rtol=1e-05,atol=1e-08)
jax.numpy.lax_numpy.iscomplex(x)
jax.numpy.lax_numpy.isfinite(x)
jax.numpy.lax_numpy.isinf(x)
jax.numpy.lax_numpy.isnan(x)
jax.numpy.lax_numpy.isreal(x)
jax.numpy.lax_numpy.isrealobj(a)
jax.numpy.lax_numpy.ix_(*args)
jax.numpy.lax_numpy.kron(a,b)
jax.numpy.lax_numpy.lcm(x1,x2)
jax.numpy.lax_numpy.log10(x)
jax.numpy.lax_numpy.log2(x)
jax.numpy.lax_numpy.logaddexp(x1,x2)
jax.numpy.lax_numpy.logaddexp2(x1,x2)
jax.numpy.lax_numpy.matmul(a,b)
jax.numpy.lax_numpy.mean(a,axis=None,dtype=None,out=None,keepdims=False)
jax.numpy.lax_numpy.median(a,axis=None,out=None,overwrite_input=False,keepdims=False)
jax.numpy.lax_numpy.moveaxis(a,source,destination)
jax.numpy.lax_numpy.nan_to_num(x,copy=True)
jax.numpy.lax_numpy.ndarray(shape,dtype=None,buffer=None,offset=0,strides=None,order=None)
jax.numpy.lax_numpy.ndarray.__init__(shape,dtype=None,buffer=None,offset=0,strides=None,order=None)
jax.numpy.lax_numpy.ones(shape,dtype=onp.dtype('float64'))
jax.numpy.lax_numpy.ones_like(x,dtype=None)
jax.numpy.lax_numpy.outer(a,b,out=None)
jax.numpy.lax_numpy.pad(array,pad_width,mode='constant',constant_values=0)
jax.numpy.lax_numpy.percentile(a,q,axis=None,out=None,overwrite_input=False,interpolation='linear',keepdims=False)
jax.numpy.lax_numpy.polyval(p,x)
jax.numpy.lax_numpy.power(x1,x2)
jax.numpy.lax_numpy.ptp(a,axis=None,out=None,keepdims=False)
jax.numpy.lax_numpy.quantile(a,q,axis=None,out=None,overwrite_input=False,interpolation='linear',keepdims=False)
jax.numpy.lax_numpy.rad2deg(x)
jax.numpy.lax_numpy.ravel(a,order='C')
jax.numpy.lax_numpy.real(x)
jax.numpy.lax_numpy.reciprocal(x)
jax.numpy.lax_numpy.remainder(x1,x2)
jax.numpy.lax_numpy.repeat(a,repeats,axis=None)
jax.numpy.lax_numpy.reshape(a,newshape,order='C')
jax.numpy.lax_numpy.roll(a,shift,axis=None)
jax.numpy.lax_numpy.rot90(m,k=1,axes=(0,1))
jax.numpy.lax_numpy.round(a,decimals=0)
jax.numpy.lax_numpy.select(condlist,choicelist,default=0)
jax.numpy.lax_numpy.sinc(x)
jax.numpy.lax_numpy.sort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.lax_numpy.split(ary,indices_or_sections,axis=0)
jax.numpy.lax_numpy.square(x)
jax.numpy.lax_numpy.squeeze(a,axis=None)
jax.numpy.lax_numpy.stack(arrays,axis=0)
jax.numpy.lax_numpy.std(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.lax_numpy.swapaxes(a,axis1,axis2)
jax.numpy.lax_numpy.take(a,indices,axis=None,out=None,mode=None)
jax.numpy.lax_numpy.take_along_axis(arr,indices,axis)
jax.numpy.lax_numpy.tensordot(a,b,axes=2)
jax.numpy.lax_numpy.tile(a,reps)
jax.numpy.lax_numpy.trace(a,offset=0,axis1=0,axis2=1,dtype=None,out=None)
jax.numpy.lax_numpy.transpose(x,axes=None)
jax.numpy.lax_numpy.tri(N,M=None,k=0,dtype=None)
jax.numpy.lax_numpy.tril(m,k=0)
jax.numpy.lax_numpy.triu(m,k=0)
jax.numpy.lax_numpy.true_divide(x1,x2)
jax.numpy.lax_numpy.vander(x,N=None,increasing=False)
jax.numpy.lax_numpy.var(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.lax_numpy.vdot(a,b)
jax.numpy.lax_numpy.vstack(tup)
jax.numpy.lax_numpy.where(condition,x=None,y=None)
jax.numpy.lax_numpy.zeros(shape,dtype=onp.dtype('float64'))
jax.numpy.lax_numpy.zeros_like(x,dtype=None)
jax.numpy.lcm(x1,x2)
jax.numpy.log10(x)
jax.numpy.log2(x)
jax.numpy.logaddexp(x1,x2)
jax.numpy.logaddexp2(x1,x2)
jax.numpy.matmul(a,b)
jax.numpy.mean(a,axis=None,dtype=None,out=None,keepdims=False)
jax.numpy.median(a,axis=None,out=None,overwrite_input=False,keepdims=False)
jax.numpy.moveaxis(a,source,destination)
jax.numpy.nan_to_num(x,copy=True)
jax.numpy.ndarray(shape,dtype=None,buffer=None,offset=0,strides=None,order=None)
jax.numpy.ones(shape,dtype=onp.dtype('float64'))
jax.numpy.ones_like(x,dtype=None)
jax.numpy.outer(a,b,out=None)
jax.numpy.pad(array,pad_width,mode='constant',constant_values=0)
jax.numpy.percentile(a,q,axis=None,out=None,overwrite_input=False,interpolation='linear',keepdims=False)
jax.numpy.polyval(p,x)
jax.numpy.power(x1,x2)
jax.numpy.ptp(a,axis=None,out=None,keepdims=False)
jax.numpy.quantile(a,q,axis=None,out=None,overwrite_input=False,interpolation='linear',keepdims=False)
jax.numpy.rad2deg(x)
jax.numpy.ravel(a,order='C')
jax.numpy.real(x)
jax.numpy.reciprocal(x)
jax.numpy.remainder(x1,x2)
jax.numpy.repeat(a,repeats,axis=None)
jax.numpy.reshape(a,newshape,order='C')
jax.numpy.roll(a,shift,axis=None)
jax.numpy.rot90(m,k=1,axes=(0,1))
jax.numpy.round(a,decimals=0)
jax.numpy.select(condlist,choicelist,default=0)
jax.numpy.sinc(x)
jax.numpy.sort(a,axis=-1,kind='quicksort',order=None)
jax.numpy.split(ary,indices_or_sections,axis=0)
jax.numpy.square(x)
jax.numpy.squeeze(a,axis=None)
jax.numpy.stack(arrays,axis=0)
jax.numpy.std(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.swapaxes(a,axis1,axis2)
jax.numpy.take(a,indices,axis=None,out=None,mode=None)
jax.numpy.take_along_axis(arr,indices,axis)
jax.numpy.tensordot(a,b,axes=2)
jax.numpy.tile(a,reps)
jax.numpy.trace(a,offset=0,axis1=0,axis2=1,dtype=None,out=None)
jax.numpy.transpose(x,axes=None)
jax.numpy.tri(N,M=None,k=0,dtype=None)
jax.numpy.tril(m,k=0)
jax.numpy.triu(m,k=0)
jax.numpy.true_divide(x1,x2)
jax.numpy.vander(x,N=None,increasing=False)
jax.numpy.var(a,axis=None,dtype=None,out=None,ddof=0,keepdims=False)
jax.numpy.vdot(a,b)
jax.numpy.vstack(tup)
jax.numpy.where(condition,x=None,y=None)
jax.numpy.zeros(shape,dtype=onp.dtype('float64'))
jax.numpy.zeros_like(x,dtype=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/tools/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/tools/jax_to_hlo.py----------------------------------------
A:jax.tools.jax_to_hlo.shape_with_default_layout->jax.lib.xla_client.Shape.array_shape(shape.xla_element_type(), shape.dimensions()).with_major_to_minor_layout_if_absent()
A:jax.tools.jax_to_hlo.fn_curried->functools.partial(fn, **constants)
A:jax.tools.jax_to_hlo.comp->jax.api.xla_computation(ordered_wrapper)(*args)
A:jax.tools.jax_to_hlo.(module_name, fn_name)->FLAGS.fn.rsplit('.', 1)
A:jax.tools.jax_to_hlo.module->importlib.import_module(module_name)
A:jax.tools.jax_to_hlo.fn->getattr(module, fn_name)
A:jax.tools.jax_to_hlo.v->jax.numpy.asarray(v)
A:jax.tools.jax_to_hlo.(hlo_proto, hlo_text)->jax_to_hlo(fn, input_shapes, constants)
jax.tools.jax_to_hlo.jax_to_hlo(fn,input_shapes,constants=None)
jax.tools.jax_to_hlo.main(argv)
jax.tools.jax_to_hlo.set_up_flags()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/ops/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/ops/scatter.py----------------------------------------
A:jax.ops.scatter.x->numpy.lax_numpy.asarray(x)
A:jax.ops.scatter.y->lax.rev(y, indexer.reversed_y_dims)
A:jax.ops.scatter.indexer->numpy.lax_numpy._index_to_gather(np.shape(x), idx)
A:jax.ops.scatter.dnums->lax.ScatterDimensionNumbers(update_window_dims=indexer.dnums.offset_dims, inserted_window_dims=indexer.dnums.collapsed_slice_dims, scatter_dims_to_operand_dims=indexer.dnums.start_index_map)
A:jax.ops.scatter.index->_Indexable()
A:jax.ops.scatter.num_segments->int(num_segments)
A:jax.ops.scatter.out->numpy.lax_numpy.zeros((num_segments,) + data.shape[1:], dtype=data.dtype)
A:jax.ops.scatter.segment_ids->numpy.lax_numpy.mod(segment_ids, num_segments)
jax.ops.index_add(x,idx,y)
jax.ops.index_max(x,idx,y)
jax.ops.index_min(x,idx,y)
jax.ops.index_update(x,idx,y)
jax.ops.scatter._Indexable(object)
jax.ops.scatter._Indexable.__getitem__(self,index)
jax.ops.scatter._scatter_update(x,idx,y,scatter_op)
jax.ops.scatter.index_add(x,idx,y)
jax.ops.scatter.index_max(x,idx,y)
jax.ops.scatter.index_min(x,idx,y)
jax.ops.scatter.index_update(x,idx,y)
jax.ops.scatter.segment_sum(data,segment_ids,num_segments=None)
jax.ops.segment_sum(data,segment_ids,num_segments=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/ad.py----------------------------------------
A:jax.interpreters.ad.(fun, aux)->jvp_subtrace_aux(fun, instantiate)
A:jax.interpreters.ad.out_tangent->instantiate_zeros_at(instantiate, out_primal, out_tangent)
A:jax.interpreters.ad.trace->JVPTrace(master, core.cur_sublevel())
A:jax.interpreters.ad.out_tracer->JVPTrace(master, core.cur_sublevel()).full_raise(ans)
A:jax.interpreters.ad.(out_tracer, aux_tracer)->map(trace.full_raise, (ans, aux))
A:jax.interpreters.ad.has_aux->kwargs.pop('has_aux', False)
A:jax.interpreters.ad.jvpfun->pack_output(jvpfun)
A:jax.interpreters.ad.(jvpfun, aux)->jvp(traceable, has_aux=True)
A:jax.interpreters.ad.(jaxpr, out_pval, consts)->pe.trace_to_jaxpr(jvpfun, in_pvals)
A:jax.interpreters.ad.(pval_primal, pval_tangent)->unpair_pval(out_pval)
A:jax.interpreters.ad.(out_primal, pval, jaxpr, consts)->linearize(traceable, *primals)
A:jax.interpreters.ad.(out_primal, pval, jaxpr, consts, aux)->linearize(traceable, *primals, has_aux=True)
A:jax.interpreters.ad.ct->tuple(map(recursively_pack, ct))
A:jax.interpreters.ad.dummy_primal_and_ct->pack((core.unit, ct))
A:jax.interpreters.ad.(_, arg_cts)->backward_pass(jaxpr, consts, (), dummy_args, dummy_primal_and_ct)
A:jax.interpreters.ad.cts_in->map(read_cotangent, eqn.outvars)
A:jax.interpreters.ad.invals->map(read_primal, eqn.invars)
A:jax.interpreters.ad.(subjaxprs, sub_consts, sub_freevar_vals)->unzip3([(subjaxpr, map(read_primal, const_vars), map(read_primal, bound_vars)) for (subjaxpr, const_vars, bound_vars) in eqn.bound_subjaxprs])
A:jax.interpreters.ad.(cts_out, ct_free_vars_out)->get_primitive_transpose(eqn.primitive)(eqn.params, subjaxprs, sub_consts, sub_freevar_vals, invals, ct_in)
A:jax.interpreters.ad.cts_out->get_primitive_transpose(eqn.primitive)(ct_in, *invals, **eqn.params)
A:jax.interpreters.ad.freevar_cts->tree_map(lambda x: x.sum(0), freevar_cts)
A:jax.interpreters.ad.cotangents_out->tuple(map(pack_cotangents_like_caller, args, cotangents_out))
A:jax.interpreters.ad.(primal_out, tangent_out)->core.Primitive('{name}_jvp'.format(name=name)).bind(pack(xs), pack(ts), **params)
A:jax.interpreters.ad.(nonzero_tangents, in_tree_def)->tree_to_jaxtuples(tangents)
A:jax.interpreters.ad.(f_jvp, out_tree_def)->traceable(jvp_subtrace(f, self.master), in_tree_def)
A:jax.interpreters.ad.result->call_primitive.bind(f_jvp, pack(primals), nonzero_tangents, **params)
A:jax.interpreters.ad.(out_jtuple, tree_def)->tree_to_jaxtuples((cotangents_out, freevar_cts))
A:jax.interpreters.ad.xt->TangentTuple((zero,) * len(yt))
A:jax.interpreters.ad.yt->TangentTuple((zero,) * len(xt))
A:jax.interpreters.ad.primals->pack((t.primal for t in tracers))
A:jax.interpreters.ad.tangents->map(instantiate_zeros, primals, tangents)
A:jax.interpreters.ad.primal_aval->raise_to_shaped(get_aval(primal))
A:jax.interpreters.ad.tangent_aval->raise_to_shaped(get_aval(tangent))
A:jax.interpreters.ad.primitive_jvps[primitive]->partial(zero_jvp, primitive)
A:jax.interpreters.ad.primitive_transposes[primitive]->partial(linear_transpose, transpose_rule)
A:jax.interpreters.ad.val_out->primitive.bind(*primals, **params)
A:jax.interpreters.ad.params['vjp_argnums']->tuple((i for (i, t) in enumerate(ts) if t is not zero))
A:jax.interpreters.ad.ts->map(instantiate_zeros, xs, ts)
A:jax.interpreters.ad.fun_jvp_p->core.Primitive('{name}_jvp'.format(name=name))
A:jax.interpreters.ad.argnums->params.pop('vjp_argnums')
A:jax.interpreters.ad.(primal_out, vjp_py)->custom_vjp(argnums, *primals_tracer, **params)
A:jax.interpreters.ad.in_aval->raise_to_shaped(get_aval(primal_out))
A:jax.interpreters.ad.ct_pval->pe.PartialVal((in_aval, core.unit))
A:jax.interpreters.ad.(vjp_jaxpr, out_pval, residuals)->pe.trace_unwrapped_to_jaxpr(lambda ct: pack(vjp_py(ct)), (ct_pval,), instantiate=False)
A:jax.interpreters.ad.tangent_out->core.Primitive('{name}_lin'.format(name=name)).bind(out_const, pack(residuals), tangents_tracer, in_aval=in_aval, out_pv=out_pv, vjp_jaxpr=vjp_jaxpr)
A:jax.interpreters.ad.fun_lin_p->core.Primitive('{name}_lin'.format(name=name))
A:jax.interpreters.ad.ans->primitive.bind(fun, all_args, **params)
A:jax.interpreters.ad.out->pe.merge_pvals(ans, pe.PartialVal((out_pv, out_const)))
A:jax.interpreters.ad.primitive_transposes[prim]->partial(bilinear_transpose, lhs_rule, rhs_rule)
A:jax.interpreters.ad.defbilinear->partial(defbilinear_broadcasting, lambda g, x: g)
A:jax.interpreters.ad.t->type(instantiate)
A:jax.interpreters.ad.new_tangents->build_tree(in_tree_def, new_tangents)
A:jax.interpreters.ad.(args, ct, freevar_vals)->build_tree(in_tree_def, (args, ct, freevar_vals))
A:jax.interpreters.ad.((args, ct, freevar_vals), in_tree_def)->tree_to_jaxtuples((args, ct, freevar_vals))
A:jax.interpreters.ad.fun->wrap_init(backward_pass)
A:jax.interpreters.ad.(fun, out_tree_def)->transposed_mapped(fun, jaxpr, in_tree_def, tuple(freevar_vals))
A:jax.interpreters.ad.all_args->pack((pack(args), pack(consts), ct))
A:jax.interpreters.ad.(args, ct)->build_tree(in_tree_def, (args, ct))
A:jax.interpreters.ad.((args, ct), in_tree_def)->tree_to_jaxtuples((args, ct))
A:jax.interpreters.ad.(cts_out, freevar_cts)->build_tree(out_tree_def(), ans)
A:jax.interpreters.ad.(primals, tangents)->unzip2(primal_tangent_pairs)
A:jax.interpreters.ad.tangents_zeros->map(partial(put_zeros, TangentTuple), nonzero_components, tangents)
A:jax.interpreters.ad.nonzeros_out->get_nonzeros(tangent_out)
A:jax.interpreters.ad.tangent_out_nonzero->strip_zeros(core.unit, pack, nonzeros_out, tangent_out)
A:jax.interpreters.ad.f->wrap_init(core.jaxpr_as_fun(jaxpr))
A:jax.interpreters.ad.(f_jvp, out_nonzeros)->f_jvp_traceable(jvp(f, instantiate=instantiate), nonzeros)
A:jax.interpreters.ad.tangent_avals->map(partial(strip_zeros, core.AbstractTuple(()), core.AbstractTuple), nonzeros, jaxpr.in_avals)
A:jax.interpreters.ad.(jaxpr_out, pval_out, literals_out)->pe.trace_to_jaxpr(f_jvp, pt_pvals, instantiate=True)
A:jax.interpreters.ad.in_avals->tuple(map(core.AbstractTuple, zip(jaxpr.in_avals, tangent_avals)))
A:jax.interpreters.ad.jaxpr_out->core.TypedJaxpr(jaxpr_out, literals_out, in_avals, out_aval)
A:jax.interpreters.ad.primitive_transposes[core.call_p]->partial(call_transpose, call_p)
A:jax.interpreters.ad.tree_to_jaxtuples->partial(process_pytree, pack)
jax.interpreters.ad.JVPTrace(Trace)
jax.interpreters.ad.JVPTrace.join(self,xt,yt)
jax.interpreters.ad.JVPTrace.lift(self,val)
jax.interpreters.ad.JVPTrace.pack(self,tracers)
jax.interpreters.ad.JVPTrace.post_process_call(self,call_primitive,out_tracer,params)
jax.interpreters.ad.JVPTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.ad.JVPTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.ad.JVPTrace.pure(self,val)
jax.interpreters.ad.JVPTrace.sublift(self,val)
jax.interpreters.ad.JVPTracer(self,trace,primal,tangent)
jax.interpreters.ad.JVPTracer.__init__(self,trace,primal,tangent)
jax.interpreters.ad.JVPTracer.aval(self)
jax.interpreters.ad.JVPTracer.full_lower(self)
jax.interpreters.ad.JVPTracer.unpack(self)
jax.interpreters.ad.TangentTuple(tuple)
jax.interpreters.ad._primal_tangent_shapes_match(primal,tangent)
jax.interpreters.ad.add_tangents(x,y)
jax.interpreters.ad.backward_pass(jaxpr,consts,freevar_vals,args,cotangent_in)
jax.interpreters.ad.bilinear_transpose(lhs_rule,rhs_rule,cotangent,x,y,**kwargs)
jax.interpreters.ad.call_transpose(primitive,params,jaxpr,consts,freevar_vals,args,ct)
jax.interpreters.ad.defbilinear_broadcasting(bcast,prim,lhs_rule,rhs_rule)
jax.interpreters.ad.defjvp(primitive,*jvprules)
jax.interpreters.ad.defjvp2(primitive,*jvprules)
jax.interpreters.ad.defjvp_zero(primitive)
jax.interpreters.ad.deflinear(primitive,transpose_rule)
jax.interpreters.ad.defvjp(prim,*vjps)
jax.interpreters.ad.defvjp2(prim,*vjps)
jax.interpreters.ad.defvjp_all(prim,custom_vjp)
jax.interpreters.ad.defvjp_argnums(prim,custom_vjp)
jax.interpreters.ad.f_jvp_traceable(nonzero_components,*primal_tangent_pairs)
jax.interpreters.ad.get_nonzeros(tangent)
jax.interpreters.ad.get_primitive_transpose(p)
jax.interpreters.ad.identity(x)
jax.interpreters.ad.ignore_consts(ct,pval)
jax.interpreters.ad.instantiate_zeros(example,tangent)
jax.interpreters.ad.instantiate_zeros_at(instantiate,example,tangent)
jax.interpreters.ad.instantiate_zeros_aval(aval,tangent)
jax.interpreters.ad.jvp(fun,has_aux=False,instantiate=True)
jax.interpreters.ad.jvp_jaxpr(jaxpr,nonzeros,instantiate)
jax.interpreters.ad.jvp_subtrace(master,primals,tangents)
jax.interpreters.ad.jvp_subtrace_aux(instantiate,master,primals,tangents)
jax.interpreters.ad.jvpfun(instantiate,primals,tangents)
jax.interpreters.ad.linear_jvp(primitive,primals,tangents,**params)
jax.interpreters.ad.linear_transpose(transpose_rule,cotangent,*args,**kwargs)
jax.interpreters.ad.linearize(traceable,*primals,**kwargs)
jax.interpreters.ad.map_transpose(primitive,params,jaxpr,consts,freevar_vals,args,ct)
jax.interpreters.ad.pack_cotangents_like_caller(arg,ct)
jax.interpreters.ad.pack_output(*args)
jax.interpreters.ad.put_zeros(pack,isnonzero,x)
jax.interpreters.ad.recursively_pack(ct)
jax.interpreters.ad.standard_jvp(jvprules,primitive,primals,tangents,**params)
jax.interpreters.ad.standard_jvp2(jvprules,primitive,primals,tangents,**params)
jax.interpreters.ad.strip_zeros(unit,pack,isnonzero,x)
jax.interpreters.ad.traceable(in_tree_def,new_primals,new_tangents)
jax.interpreters.ad.transposed_fun(jaxpr,in_tree_def,args)
jax.interpreters.ad.transposed_mapped(jaxpr,in_tree_def,freevar_vals,args)
jax.interpreters.ad.unpair_pval(pval)
jax.interpreters.ad.vjp(traceable,primals,has_aux=False)
jax.interpreters.ad.zero_jvp(primitive,primals,tangents,**params)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/batching.py----------------------------------------
A:jax.interpreters.batching.sizes->reduce(set.union, map(dimsize, in_dims, in_vals))
A:jax.interpreters.batching.sz->(dimsize(bdx, x) | dimsize(bdy, y)).pop()
A:jax.interpreters.batching.trace->BatchTrace(master, core.cur_sublevel())
A:jax.interpreters.batching.in_tracers->map(partial(BatchTracer, trace), vals, in_dims)
A:jax.interpreters.batching.out_tracer->BatchTrace(master, core.cur_sublevel()).full_raise(ans)
A:jax.interpreters.batching.batched_aval->get_aval(self.val)
A:jax.interpreters.batching.t->type(batched)
A:jax.interpreters.batching.dims->tuple(map(partial(bools_to_bdims, 0), is_batched))
A:jax.interpreters.batching.(vals_in, dims_in)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.batched_primitive->get_primitive_batcher(primitive)
A:jax.interpreters.batching.(val_out, dim_out)->batched_primitive(vals_in, dims_in, **params)
A:jax.interpreters.batching.(vals, dims)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.(f, dim_out)->batch_subtrace(f, self.master, dims)
A:jax.interpreters.batching.val_out->map_primitive.bind(f, *vals, **params)
A:jax.interpreters.batching.(size,)->reduce(set.union, map(dimsize, dims, vals))
A:jax.interpreters.batching.is_batched->tuple(map(where_batched, dims))
A:jax.interpreters.batching.vals->map(partial(instantiate_bdim, size, 1), is_batched, dims, vals)
A:jax.interpreters.batching.unbatched_shape->tuple(onp.delete(aval.shape, bdim))
A:jax.interpreters.batching.batched_shape->tuple(onp.insert(onp.asarray(aval.shape, onp.intp), bdim, size))
A:jax.interpreters.batching.primitive_batchers[prim]->partial(reducer_batcher, prim)
A:jax.interpreters.batching.args->map(partial(handle_scalar_broadcasting, ndim), args, batch_dims)
A:jax.interpreters.batching.ndim->max(map(onp.ndim, args))
A:jax.interpreters.batching.axes->tuple(onp.where(onp.less(axes, bdim), axes, onp.add(axes, 1)))
A:jax.interpreters.batching.bdim_out->list(onp.delete(onp.arange(operand.ndim), axes)).index(bdim)
A:jax.interpreters.batching.params->dict(params, input_shape=operand.shape)
A:jax.interpreters.batching.(x_aval, y_aval)->map(get_aval, batched_args)
A:jax.interpreters.batching.move_bdim->partial(bdim_at_front, broadcast_size=sz, force_broadcast=True)
A:jax.interpreters.batching.(x, y)->map(move_bdim, batched_args, batch_dims)
A:jax.interpreters.batching.x->broadcast(x, sz, force_broadcast=force_bcast)
A:jax.interpreters.batching.where_batched->partial(_bdim_map, lambda x: x is not None)
A:jax.interpreters.batching.increment_bdim->partial(_bdim_map, lambda x: None if x is None else x + 1)
A:jax.interpreters.batching.f->wrap_init(core.jaxpr_as_fun(jaxpr))
A:jax.interpreters.batching.(f_batched, where_out_batched)->batched_traceable(f, size, is_batched, instantiate)
A:jax.interpreters.batching.in_avals->tuple(map(partial(_promote_aval_rank, size), is_batched, jaxpr.in_avals))
A:jax.interpreters.batching.(jaxpr_out, pval_out, literals_out)->pe.trace_to_jaxpr(f_batched, in_pvals, instantiate=True)
A:jax.interpreters.batching.jaxpr_out->core.TypedJaxpr(jaxpr_out, literals_out, in_avals, out_aval)
A:jax.interpreters.batching.in_dims->bools_to_bdims(0, is_batched)
A:jax.interpreters.batching.out_val->instantiate_bdim(size, 0, instantiate, out_dim, out_val)
jax.interpreters.batching.BatchTrace(Trace)
jax.interpreters.batching.BatchTrace.lift(self,val)
jax.interpreters.batching.BatchTrace.pack(self,tracers)
jax.interpreters.batching.BatchTrace.post_process_call(self,call_primitive,out_tracer,params)
jax.interpreters.batching.BatchTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.batching.BatchTrace.process_map(self,map_primitive,f,tracers,params)
jax.interpreters.batching.BatchTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.batching.BatchTrace.pure(self,val)
jax.interpreters.batching.BatchTrace.sublift(self,val)
jax.interpreters.batching.BatchTracer(self,trace,val,batch_dim)
jax.interpreters.batching.BatchTracer.__init__(self,trace,val,batch_dim)
jax.interpreters.batching.BatchTracer.aval(self)
jax.interpreters.batching.BatchTracer.full_lower(self)
jax.interpreters.batching.BatchTracer.unpack(self)
jax.interpreters.batching._bdim_map(f,bdim)
jax.interpreters.batching._binary_lattice_join(a,b)
jax.interpreters.batching._broadcast(force_bcast,sz,aval,x)
jax.interpreters.batching._broadcast2(size,axis,x,aval)
jax.interpreters.batching._dimsize(dim,aval,x)
jax.interpreters.batching._moveaxis(force_bcast,sz,dst,src,aval,x)
jax.interpreters.batching._moveaxis2(src,dst,x,aval)
jax.interpreters.batching._promote_aval_rank(n,batched,aval)
jax.interpreters.batching.add_batch_dim_to_aval(bdim,size,aval)
jax.interpreters.batching.add_batched(batched_args,batch_dims)
jax.interpreters.batching.batch(fun,in_vals,in_dims,out_dim_dst)
jax.interpreters.batching.batch_jaxpr(jaxpr,size,is_batched,instantiate)
jax.interpreters.batching.batch_subtrace(master,dims,*vals)
jax.interpreters.batching.batch_transform(size,in_dims,out_dim_dst,vals)
jax.interpreters.batching.batched_traceable(size,is_batched,instantiate,*vals)
jax.interpreters.batching.bdim_at_front(x,bdim,broadcast_size=1,force_broadcast=False)
jax.interpreters.batching.bools_to_bdims(bdim,batched_indicator_tree)
jax.interpreters.batching.broadcast(x,sz,force_broadcast=False)
jax.interpreters.batching.broadcast2(size,axis,x)
jax.interpreters.batching.broadcast_batcher(prim,batched_args,batch_dims,**params)
jax.interpreters.batching.defbroadcasting(prim)
jax.interpreters.batching.defreducer(prim)
jax.interpreters.batching.defvectorized(prim)
jax.interpreters.batching.dimsize(dim,x)
jax.interpreters.batching.get_aval(x)
jax.interpreters.batching.get_primitive_batcher(p)
jax.interpreters.batching.handle_scalar_broadcasting(nd,x,bdim)
jax.interpreters.batching.instantiate_bdim(size,axis,instantiate,bdim,x)
jax.interpreters.batching.move_dim_to_front(x,dim)
jax.interpreters.batching.moveaxis(sz,dst,src,x,force_broadcast=True)
jax.interpreters.batching.moveaxis2(src,dst,x)
jax.interpreters.batching.reducer_batcher(prim,batched_args,batch_dims,axes,**params)
jax.interpreters.batching.remove_batch_dim_from_aval(bdim,aval)
jax.interpreters.batching.shaped_aval(x)
jax.interpreters.batching.shaped_jaxtuple(xs)
jax.interpreters.batching.vectorized_batcher(prim,batched_args,batch_dims,**params)
jax.interpreters.batching.zeros_like_batched(batched_args,batch_dims)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/xla.py----------------------------------------
A:jax.interpreters.xla.abstract_args->map(abstractify, args)
A:jax.interpreters.xla.compiled_fun->_xla_callable(fun, device_assignment, device_values, *map(abstractify, args))
A:jax.interpreters.xla.shapes->tuple(map(xla_shape, abstract_args))
A:jax.interpreters.xla.built_c->_jaxpr_computation(jaxpr, axis_env, consts, (), *xla_shapes)
A:jax.interpreters.xla.result_shape->xla_shape_to_result_shape(xla_shape(a))
A:jax.interpreters.xla.handle_result->_pyval_result_handler(result_shape)
A:jax.interpreters.xla.compiled->lib.xla_bridge.make_computation_builder('constant_instantiating_computation').Build(xla_const).Compile((), xb.get_compile_options(), backend=xb.get_backend())
A:jax.interpreters.xla.c->lib.xla_bridge.make_computation_builder('constant_instantiating_computation')
A:jax.interpreters.xla.xla_args->map(c.ParameterWithShape, shapes)
A:jax.interpreters.xla.(device_num,)->lib.xla_bridge.make_computation_builder('constant_instantiating_computation').Build(xla_const).Compile((), xb.get_compile_options(), backend=xb.get_backend()).DeviceOrdinals()
A:jax.interpreters.xla.out_buf->lib.xla_bridge.make_computation_builder('constant_instantiating_computation').Build(xla_const).Compile((), xb.get_compile_options(), backend=xb.get_backend()).Execute(input_bufs)
A:jax.interpreters.xla.pyval->buf.to_py()
A:jax.interpreters.xla.x->_canonicalize_pyval_dtype(x)
A:jax.interpreters.xla.t->type(result_shape)
A:jax.interpreters.xla.element_bufs->tuple(map(partial(device_put, device_num=device_num), x))
A:jax.interpreters.xla.aval->_aval_from_xla_shape(xla_shape)
A:jax.interpreters.xla.result_shapes->tuple(map(xla_shape_to_result_shape, xla_shape.tuple_shapes()))
A:jax.interpreters.xla.arg_shapes->list(map(xla_shape, abstract_args))
A:jax.interpreters.xla.compile_opts->lib.xla_bridge.get_compile_options(num_replicas=axis_env.nreps, device_assignment=device_assignment)
A:jax.interpreters.xla.compiled_c->_jaxpr_computation(jaxpr, axis_env, consts, (), *xla_shapes).Compile(arg_shapes, compile_opts, backend=xb.get_backend())
A:jax.interpreters.xla.axis_env->AxisEnv(jaxpr_replicas(jaxpr), [], [])
A:jax.interpreters.xla.all_freevars->itertools.chain(jaxpr.constvars, jaxpr.freevars)
A:jax.interpreters.xla.in_nodes->list(map(read, eqn.invars))
A:jax.interpreters.xla.ans->rule(c, subjaxpr, axis_env, env_nodes, in_nodes, **eqn.params)
A:jax.interpreters.xla.replica_groups->axis_groups(axis_env, eqn.params['axis_name'])
A:jax.interpreters.xla.env_nodes->list(map(read, const_bindings + freevar_bindings))
A:jax.interpreters.xla.num_elements->len(c.GetShape(ans).tuple_shapes())
A:jax.interpreters.xla.AxisEnv->namedtuple('AxisEnv', ['nreps', 'names', 'sizes'])
A:jax.interpreters.xla.mesh_axes->tuple(map(partial(axis_read, axis_env), name))
A:jax.interpreters.xla.(trailing_size, ragged)->divmod(nrep, prod(mesh_spec))
A:jax.interpreters.xla.iota->numpy.arange(prod(full_spec)).reshape(full_spec)
A:jax.interpreters.xla.groups->numpy.reshape(onp.moveaxis(iota, mesh_axes, onp.arange(len(mesh_axes))), (prod(onp.take(full_spec, mesh_axes)), -1))
A:jax.interpreters.xla.xla_shapes->tuple(map(c.GetShape, xla_args))
A:jax.interpreters.xla.avals->map(_aval_from_xla_shape, xla_shapes)
A:jax.interpreters.xla.(jaxpr, _, consts)->pe.trace_unwrapped_to_jaxpr(fun, pvals, instantiate, **params)
A:jax.interpreters.xla.backend_specific_translations->defaultdict(dict)
A:jax.interpreters.xla.(x_shape, y_shape)->map(c.GetShape, (x, y))
A:jax.interpreters.xla.xs->xla_destructure(c, x)
A:jax.interpreters.xla.ys->xla_destructure(c, y)
A:jax.interpreters.xla.bufs->self.device_buffer.destructure()
A:jax.interpreters.xla.handlers->map(_device_persistent_result_handler, self.result_shapes)
A:jax.interpreters.xla.pytype_aval_mappings[DeviceTuple]->operator.attrgetter('aval')
A:jax.interpreters.xla.const->partial(c.Constant, canonicalize_types=canonicalize_types)
A:jax.interpreters.xla._forward_to_value->partial(_forward_method, '_value')
A:jax.interpreters.xla.self._npy_value->self.device_buffer.to_py()
A:jax.interpreters.xla.__str__->partialmethod(_forward_to_value, str)
A:jax.interpreters.xla.__bool____nonzero__->partialmethod(_forward_to_value, bool)
A:jax.interpreters.xla.__float__->partialmethod(_forward_to_value, float)
A:jax.interpreters.xla.__int__->partialmethod(_forward_to_value, int)
A:jax.interpreters.xla.__long__->partialmethod(_forward_to_value, long)
A:jax.interpreters.xla.__complex__->partialmethod(_forward_to_value, complex)
A:jax.interpreters.xla.__hex__->partialmethod(_forward_to_value, hex)
A:jax.interpreters.xla.__oct__->partialmethod(_forward_to_value, oct)
A:jax.interpreters.xla.__index__->partialmethod(_forward_to_value, op.index)
A:jax.interpreters.xla.__reduce__->partialmethod(_forward_to_value, op.methodcaller('__reduce__'))
A:jax.interpreters.xla.xla_const->partial(c.Constant, canonicalize_types=canonicalize_types).constant_handler(c, const)
A:jax.interpreters.xla.device_assignment->params.pop('device_assignment')
A:jax.interpreters.xla.(jaxpr, (pval, consts, env))->pe.trace_to_subjaxpr(fun, master, False).call_wrapped(pvals)
A:jax.interpreters.xla.(compiled, result_shape)->_compile_jaxpr(jaxpr, device_assignment, axis_env, consts, *abstract_args)
A:jax.interpreters.xla.xla_call_p->core.Primitive('xla_call')
A:jax.interpreters.xla.xla_call->partial(core.call_bind, xla_call_p)
A:jax.interpreters.xla.subc->_jaxpr_computation(jaxpr, axis_env, (), _map(c.GetShape, env_nodes), *map(c.GetShape, in_nodes))
A:jax.interpreters.xla.ad.primitive_transposes[xla_call_p]->partial(ad.call_transpose, xla_call_p)
A:jax.interpreters.xla.a->abstractify(x)
A:jax.interpreters.xla.handler->_device_persistent_result_handler(result_shape)
A:jax.interpreters.xla.device_put_p->core.Primitive('device_put')
jax.interpreters.xla.DeviceArray(self,result_shape,device_buffer)
jax.interpreters.xla.DeviceArray.__array__(self,dtype=None,context=None)
jax.interpreters.xla.DeviceArray.__eq__(self,other)
jax.interpreters.xla.DeviceArray.__format__(self,format_spec)
jax.interpreters.xla.DeviceArray.__hash__(self)
jax.interpreters.xla.DeviceArray.__init__(self,result_shape,device_buffer)
jax.interpreters.xla.DeviceArray.__iter__(self)
jax.interpreters.xla.DeviceArray.__len__(self)
jax.interpreters.xla.DeviceArray.__repr__(self)
jax.interpreters.xla.DeviceArray.__reversed__(self)
jax.interpreters.xla.DeviceArray._value(self)
jax.interpreters.xla.DeviceArray.copy(self)
jax.interpreters.xla.DeviceArray.copy_to_host_async(self)
jax.interpreters.xla.DeviceArray.delete(self)
jax.interpreters.xla.DeviceArray.item(self)
jax.interpreters.xla.DeviceConstant(DeviceArray)
jax.interpreters.xla.DeviceConstant.constant_handler(c,constant_instance,canonicalize_types=True)
jax.interpreters.xla.DeviceConstant.copy_to_host_async(self)
jax.interpreters.xla.DeviceTuple(self,result_shape,device_buffer)
jax.interpreters.xla.DeviceTuple.__eq__(self,other)
jax.interpreters.xla.DeviceTuple.__init__(self,result_shape,device_buffer)
jax.interpreters.xla.DeviceTuple.__iter__(self)
jax.interpreters.xla.DeviceTuple.__len__(self)
jax.interpreters.xla.DeviceTuple.__repr__(self)
jax.interpreters.xla.DeviceValue(self,device_buffer)
jax.interpreters.xla.DeviceValue.__init__(self,device_buffer)
jax.interpreters.xla.DeviceValue._check_if_deleted(self)
jax.interpreters.xla.DeviceValue.block_until_ready(self)
jax.interpreters.xla._ResultArray(tuple)
jax.interpreters.xla._ResultTuple(tuple)
jax.interpreters.xla._abstractify_tuple(tup)
jax.interpreters.xla._add_jaxvals_translation_rule(c,x,y)
jax.interpreters.xla._aval_from_xla_shape(shape)
jax.interpreters.xla._axis_groups(nrep,mesh_spec,mesh_axes)
jax.interpreters.xla._canonicalize_ndarray_dtype(x)
jax.interpreters.xla._canonicalize_pyval_dtype(x)
jax.interpreters.xla._canonicalize_tuple_dtype(tup)
jax.interpreters.xla._check_nans(name,xla_shape,buf)
jax.interpreters.xla._compile_jaxpr(jaxpr,device_assignment,axis_env,const_vals,*abstract_args)
jax.interpreters.xla._device_array_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.xla._device_persistent_result_handler(result_shape)
jax.interpreters.xla._device_put_impl(x,device_num=0)
jax.interpreters.xla._device_tuple_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.xla._execute_compiled(compiled,pval,handle_result,*args)
jax.interpreters.xla._execute_compiled_primitive(name,compiled,result_handler,*args)
jax.interpreters.xla._execute_replicated(compiled,pval,handle_result,*args)
jax.interpreters.xla._forward_method(attrname,self,fun,*args)
jax.interpreters.xla._identity(x)
jax.interpreters.xla._instantiate_device_constant(const,cutoff=1000000.0,device_num=0)
jax.interpreters.xla._jaxpr_computation(jaxpr,axis_env,const_vals,freevar_shapes,*arg_shapes)
jax.interpreters.xla._map(f,*xs)
jax.interpreters.xla._prefetch_jaxpr_literals(jaxpr)
jax.interpreters.xla._pyval_result_handler(result_shape)
jax.interpreters.xla._tuple_constant(c,val,canonicalize_types=True)
jax.interpreters.xla._xla_call_impl(fun,*args,**params)
jax.interpreters.xla._xla_call_translation_rule(c,jaxpr,axis_env,env_nodes,in_nodes,device_values,device_assignment)
jax.interpreters.xla._xla_callable(fun,device_assignment,device_values,*abstract_args)
jax.interpreters.xla._xla_primitive_callable(prim,*abstract_args,**params)
jax.interpreters.xla._zeros_like_translation_rule(c,x)
jax.interpreters.xla.abstractify(x)
jax.interpreters.xla.apply_primitive(prim,*args,**params)
jax.interpreters.xla.axis_groups(axis_env,name)
jax.interpreters.xla.axis_read(axis_env,axis_name)
jax.interpreters.xla.build_jaxpr(jaxpr,axis_env,const_vals,*abstract_args)
jax.interpreters.xla.check_nans(name,buf)
jax.interpreters.xla.device_put(x,device_num=0)
jax.interpreters.xla.eqn_replicas(eqn)
jax.interpreters.xla.extend_axis_env(env,name,size)
jax.interpreters.xla.jaxpr_computation(jaxpr,const_vals,freevar_shapes,*arg_shapes)
jax.interpreters.xla.jaxpr_replicas(jaxpr)
jax.interpreters.xla.lower_fun(fun,instantiate=False,initial_style=False)
jax.interpreters.xla.primitive_computation(prim,*shapes,**params)
jax.interpreters.xla.result_handler(result_shape)
jax.interpreters.xla.xla_destructure(c,ans)
jax.interpreters.xla.xla_pack(c,xs)
jax.interpreters.xla.xla_shape(x)
jax.interpreters.xla.xla_shape_to_result_shape(xla_shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/pxla.py----------------------------------------
A:jax.interpreters.pxla.nrep->len(device_ordinals)
A:jax.interpreters.pxla.assignments->assign_shards_to_replicas(num_bufs, self.axis_size)
A:jax.interpreters.pxla.(_, ids)->numpy.unique(assignments, return_index=True)
A:jax.interpreters.pxla.get_shard->memoize_unary(lambda i: arg.device_buffers[i].to_py())
A:jax.interpreters.pxla.elts->map(_xla_unshard, shape.tuple_shapes(), xla_destructure(c, x))
A:jax.interpreters.pxla.dims->list(shape.dimensions())
A:jax.interpreters.pxla.start_indices->_xla_shard_start_indices(c, axis_size, len(dims) + 1)
A:jax.interpreters.pxla.axis_size->params.pop('axis_size')
A:jax.interpreters.pxla.padded->c.DynamicUpdateSlice(padded, c.Reshape(x, None, [1] + dims), start_indices)
A:jax.interpreters.pxla.idx->c.Rem(c.ReplicaId(), c.Constant(onp.array(axis_size, onp.uint32)))
A:jax.interpreters.pxla.zero->numpy.zeros(ndim - 1, onp.uint32)
A:jax.interpreters.pxla.full_aval->add_axis_to_aval(axis_size, aval)
A:jax.interpreters.pxla.(t,)->set(map(type, replica_results))
A:jax.interpreters.pxla.reduced_aval->remove_axis_from_aval(aval)
A:jax.interpreters.pxla.all_results->zip(*replica_results)
A:jax.interpreters.pxla.(groupsize, ragged)->divmod(nrep, size)
A:jax.interpreters.pxla.indices->numpy.tile(onp.arange(size)[:, None], (1, groupsize))
A:jax.interpreters.pxla.(trailing_size, ragged)->divmod(nrep, prod(mesh_spec))
A:jax.interpreters.pxla.iota->numpy.arange(prod(full_spec)).reshape(full_spec)
A:jax.interpreters.pxla.groups->numpy.reshape(onp.moveaxis(iota, mesh_axes, onp.arange(len(mesh_axes))), (prod(onp.take(full_spec, mesh_axes)), -1))
A:jax.interpreters.pxla.axis_env->xla.AxisEnv(num_replicas, [axis_name], [axis_size])
A:jax.interpreters.pxla.arg_shapes->list(map(xla_shape, abstract_args))
A:jax.interpreters.pxla.built_c->xla._jaxpr_computation(jaxpr, axis_env, consts, (), *arg_shapes)
A:jax.interpreters.pxla.result_shape->xla_shape_to_result_shape(device_buffer.shape())
A:jax.interpreters.pxla.compiled->xla._jaxpr_computation(jaxpr, axis_env, consts, (), *arg_shapes).Compile(arg_shapes, xb.get_compile_options(num_replicas), backend=xb.get_backend())
A:jax.interpreters.pxla.dynamic_axis_env->DynamicAxisEnv()
A:jax.interpreters.pxla.mapped->prod((frame.hard_size for frame in dynamic_axis_env))
A:jax.interpreters.pxla.(unmapped, ragged)->divmod(xb.device_count(), mapped)
A:jax.interpreters.pxla.axis_name->params.pop('axis_name')
A:jax.interpreters.pxla.shape->tuple((logical_size(dynamic_axis_env[name]) for name in axis_name))
A:jax.interpreters.pxla.dummy_arg->frame.soft_trace.pure(dummy_arg)
A:jax.interpreters.pxla.out_aval->ShapedArray((), onp.uint32)
A:jax.interpreters.pxla.eqn->pe.JaxprEqn([], None, axis_index_p, (), False, False, params)
A:jax.interpreters.pxla.axis_index_p->core.Primitive('axis_index')
A:jax.interpreters.pxla.all_bufs->zip(*[buf.destructure() for buf in self.device_buffers])
A:jax.interpreters.pxla.handlers->map(partial(tuple_element_handler, self.axis_size), self.aval)
A:jax.interpreters.pxla.t->type(aval)
A:jax.interpreters.pxla.xla.pytype_aval_mappings[ShardedDeviceTuple]->operator.attrgetter('aval')
A:jax.interpreters.pxla.batching.pytype_aval_mappings[ShardedDeviceTuple]->operator.attrgetter('aval')
A:jax.interpreters.pxla._collect->staticmethod(onp.concatenate)
A:jax.interpreters.pxla.num_bufs->len(self.device_buffers)
A:jax.interpreters.pxla.ids->self._ids()
A:jax.interpreters.pxla.self._npy_value->self._collect([self.device_buffers[i].to_py() for i in ids])
A:jax.interpreters.pxla.handler->xla._device_persistent_result_handler(result_shape)
A:jax.interpreters.pxla.abstract_args->map(partial(abstractify, axis_size), args)
A:jax.interpreters.pxla.compiled_fun->parallel_callable(fun, axis_name, axis_size, *abstract_args)
A:jax.interpreters.pxla.pval->PartialVal((core.AbstractTuple(()), core.unit))
A:jax.interpreters.pxla.(jaxpr, (out_pval, consts, env))->trace_to_subjaxpr(dynamic_fun, master, False).call_wrapped([pval] + pvals)
A:jax.interpreters.pxla.result_handler->sharded_result_handler(axis_size, xla.abstractify(out_const))
A:jax.interpreters.pxla.out->compile_replicated(jaxpr, axis_name, axis_size, consts, *avals)
A:jax.interpreters.pxla.handle_arg->partial(shard_arg, compiled.DeviceOrdinals(), axis_size)
A:jax.interpreters.pxla.handle_replica_result->xla.result_handler(shard_result_shape)
A:jax.interpreters.pxla.handle_full_result->sharded_result_handler(axis_size, merged_aval(out_pval))
A:jax.interpreters.pxla.out_bufs->xla._jaxpr_computation(jaxpr, axis_env, consts, (), *arg_shapes).Compile(arg_shapes, xb.get_compile_options(num_replicas), backend=xb.get_backend()).ExecutePerReplica(list(input_bufs))
A:jax.interpreters.pxla.xla_pmap_p->core.Primitive('xla_pmap')
A:jax.interpreters.pxla.xla_pmap->partial(core.call_bind, xla_pmap_p)
A:jax.interpreters.pxla.new_env->xla.extend_axis_env(axis_env, axis_name, axis_size)
A:jax.interpreters.pxla.in_nodes_sharded->list(map(partial(xla_shard, c, new_env.sizes), in_nodes))
A:jax.interpreters.pxla.subc->xla._jaxpr_computation(jaxpr, new_env, (), tuple(map(c.GetShape, env_nodes)), *map(c.GetShape, in_nodes_sharded))
A:jax.interpreters.pxla.sharded_result->c.Call(subc, env_nodes + in_nodes_sharded)
A:jax.interpreters.pxla.ad.primitive_transposes[xla_pmap_p]->partial(ad.map_transpose, xla_pmap_p)
A:jax.interpreters.pxla.trace->SplitAxisTrace(master, core.cur_sublevel())
A:jax.interpreters.pxla.in_tracers->map(partial(SplitAxisTracer, trace, axis_name), args)
A:jax.interpreters.pxla.out_tracer->SplitAxisTrace(master, core.cur_sublevel()).full_raise(ans)
A:jax.interpreters.pxla.out_val->batching.broadcast2(chunk_size, 0, out_val)
A:jax.interpreters.pxla.aval->batching.get_aval(self.val)
A:jax.interpreters.pxla.names->list(self.name)
A:jax.interpreters.pxla.(vals_in, names_in)->unzip2(((t.val, t.axis_name) for t in tracers))
A:jax.interpreters.pxla.hard_idx->primitive.bind(dummy, **params)
A:jax.interpreters.pxla.(name,)->set((n for n in names_in if n is not not_mapped))
A:jax.interpreters.pxla.(val_out, is_mapped)->rule(vals_in, which_mapped, **params)
A:jax.interpreters.pxla.val_out->transpose_mapped(1, 0, name_out(), val_out_transposed)
A:jax.interpreters.pxla.rule->batching.get_primitive_batcher(primitive)
A:jax.interpreters.pxla.(val_out, axis_out)->rule(vals_in, axes_in, **params)
A:jax.interpreters.pxla.(vals, names)->unzip2(((t.val, t.axis_name) for t in tracers))
A:jax.interpreters.pxla.(f, name_out)->split_axis_subtrace(f, self.master, names)
A:jax.interpreters.pxla.vals_transposed->map(partial(transpose_mapped, 0, 1), names, vals)
A:jax.interpreters.pxla.val_out_transposed->map_primitive.bind(f, *vals_transposed, **params)
jax.interpreters.pxla.ChunkedDeviceArray(self,axis_size,aval,device_buffers)
jax.interpreters.pxla.ChunkedDeviceArray.__getitem__(self,idx)
jax.interpreters.pxla.ChunkedDeviceArray.__init__(self,axis_size,aval,device_buffers)
jax.interpreters.pxla.DynamicAxisEnv(list)
jax.interpreters.pxla.DynamicAxisEnv.__contains__(self,axis_name)
jax.interpreters.pxla.DynamicAxisEnv.__getitem__(self,axis_name)
jax.interpreters.pxla.DynamicAxisEnvFrame(self,name,pmap_trace,hard_size)
jax.interpreters.pxla.DynamicAxisEnvFrame.__init__(self,name,pmap_trace,hard_size)
jax.interpreters.pxla.NotMapped(object)
jax.interpreters.pxla.ShardedDeviceArray(self,aval,device_buffers)
jax.interpreters.pxla.ShardedDeviceArray.__getitem__(self,idx)
jax.interpreters.pxla.ShardedDeviceArray.__init__(self,aval,device_buffers)
jax.interpreters.pxla.ShardedDeviceArray._ids(self)
jax.interpreters.pxla.ShardedDeviceArray._value(self)
jax.interpreters.pxla.ShardedDeviceArray.copy_to_host_async(self)
jax.interpreters.pxla.ShardedDeviceArray.delete(self)
jax.interpreters.pxla.ShardedDeviceTuple(self,axis_size,aval,device_buffers)
jax.interpreters.pxla.ShardedDeviceTuple.__init__(self,axis_size,aval,device_buffers)
jax.interpreters.pxla.ShardedDeviceTuple.__iter__(self)
jax.interpreters.pxla.ShardedDeviceTuple.__len__(self)
jax.interpreters.pxla.ShardedDeviceTuple.__repr__(self)
jax.interpreters.pxla.ShardedDeviceValue(xla.DeviceValue)
jax.interpreters.pxla.ShardedDeviceValue._check_if_deleted(self)
jax.interpreters.pxla.ShardedDeviceValue.block_until_ready(self)
jax.interpreters.pxla.SplitAxisTrace(core.Trace)
jax.interpreters.pxla.SplitAxisTrace.lift(self,val)
jax.interpreters.pxla.SplitAxisTrace.pack(self,tracers)
jax.interpreters.pxla.SplitAxisTrace.post_process_call(self,call_primitive,out_tracer,params)
jax.interpreters.pxla.SplitAxisTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.pxla.SplitAxisTrace.process_map(self,map_primitive,f,tracers,params)
jax.interpreters.pxla.SplitAxisTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.pxla.SplitAxisTrace.pure(self,val)
jax.interpreters.pxla.SplitAxisTrace.sublift(self,val)
jax.interpreters.pxla.SplitAxisTracer(self,trace,axis_name,val)
jax.interpreters.pxla.SplitAxisTracer.__init__(self,trace,axis_name,val)
jax.interpreters.pxla.SplitAxisTracer.aval(self)
jax.interpreters.pxla.SplitAxisTracer.full_lower(self)
jax.interpreters.pxla.SplitAxisTracer.unpack(self)
jax.interpreters.pxla.SplitAxisTuple(tuple)
jax.interpreters.pxla._axis_index_partial_eval(trace,_,**params)
jax.interpreters.pxla._shard_aval(axis_size,aval)
jax.interpreters.pxla._slice(x,i)
jax.interpreters.pxla._xla_pmap_translation_rule(c,jaxpr,axis_env,env_nodes,in_nodes,axis_name,axis_size)
jax.interpreters.pxla._xla_shard_start_indices(c,axis_size,ndim)
jax.interpreters.pxla.abstractify(axis_size,x)
jax.interpreters.pxla.add_axis_to_aval(n,aval)
jax.interpreters.pxla.add_chunk_to_axis_env(axis_name,soft_trace,soft_size)
jax.interpreters.pxla.apply_parallel_primitive(prim,*args,**params)
jax.interpreters.pxla.assign_shards_to_replicas(nrep,size)
jax.interpreters.pxla.axis_index(axis_name)
jax.interpreters.pxla.compile_replicated(jaxpr,axis_name,axis_size,consts,*abstract_args)
jax.interpreters.pxla.execute_replicated(compiled,pval,nrep,handle_in,handle_replica_result,handle_full_result,*args)
jax.interpreters.pxla.extend_dynamic_axis_env(axis_name,pmap_trace,hard_size)
jax.interpreters.pxla.identity(x)
jax.interpreters.pxla.merged_aval(pval)
jax.interpreters.pxla.parallel_callable(fun,axis_name,axis_size,*avals)
jax.interpreters.pxla.remove_axis_from_aval(aval)
jax.interpreters.pxla.replica_groups(nrep,mesh_spec,mesh_axes)
jax.interpreters.pxla.shard_arg(device_ordinals,axis_size,arg)
jax.interpreters.pxla.sharded_array_result_handler(aval,replica_results)
jax.interpreters.pxla.sharded_result_handler(axis_size,aval)
jax.interpreters.pxla.sharded_tuple_result_handler(axis_size,aval,replica_results)
jax.interpreters.pxla.split_axis(axis_name,chunk_size,*args)
jax.interpreters.pxla.split_axis_subtrace(master,names,*vals)
jax.interpreters.pxla.transpose_mapped(src,dst,name,x)
jax.interpreters.pxla.tuple_element_handler(axis_size,aval)
jax.interpreters.pxla.unmapped_device_count()
jax.interpreters.pxla.xla_pmap_impl(fun,*args,**params)
jax.interpreters.pxla.xla_shard(c,sizes,x)
jax.interpreters.pxla.xla_unshard(c,replica_groups,x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/partial_eval.py----------------------------------------
A:jax.interpreters.partial_eval.(pvs, consts)->unzip2(pvals)
A:jax.interpreters.partial_eval.tracers->map(self.instantiate_const, tracers)
A:jax.interpreters.partial_eval.out_aval->primitive.abstract_eval(*avals, **params)
A:jax.interpreters.partial_eval.eqn->JaxprEqn([self], [None] * n, core.identity_p, (), False, True, {})
A:jax.interpreters.partial_eval.pval->pack_pvals([t.pval for t in tracers])
A:jax.interpreters.partial_eval.(in_pvs, in_consts)->unzip2([t.pval for t in tracers])
A:jax.interpreters.partial_eval.(fun, aux)->partial_eval(f, self, reduced_pvs)
A:jax.interpreters.partial_eval.(out_pv_const, consts)->call_primitive.bind(fun, *in_consts, **params)
A:jax.interpreters.partial_eval.(out_pv, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.const_tracers->map(trace.new_instantiated_const, consts)
A:jax.interpreters.partial_eval.reduced_pvs->map(remove_axis_from_pv, in_pvs)
A:jax.interpreters.partial_eval.(out_const, consts)->map_primitive.bind(fun, *in_consts, **params)
A:jax.interpreters.partial_eval.(out_pv_reduced, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.out_pv->add_axis_to_pv(params['axis_size'], out_pv_reduced)
A:jax.interpreters.partial_eval.jaxpr_converted->Jaxpr(const_vars, env_vars, invars, var(out_tracer), eqns).copy()
A:jax.interpreters.partial_eval.jaxpr_converted.invars->list(it.chain(jaxpr.constvars, jaxpr.invars))
A:jax.interpreters.partial_eval.invars->map(var, in_tracers)
A:jax.interpreters.partial_eval.(jaxpr, consts, env)->tracers_to_jaxpr(in_tracers, out_tracer)
A:jax.interpreters.partial_eval.out->pack((out_const, pack(consts)))
A:jax.interpreters.partial_eval.trace->JaxprTrace(master, core.cur_sublevel())
A:jax.interpreters.partial_eval.env_tracers->map(trace.full_raise, env)
A:jax.interpreters.partial_eval.map_primitives->set()
A:jax.interpreters.partial_eval.f->lu.wrap_init(core.jaxpr_as_fun(jaxpr))
A:jax.interpreters.partial_eval.(_, pval_out, _)->trace_to_jaxpr(lu.wrap_init(fun, params), pvals_in, instantiate=True)
A:jax.interpreters.partial_eval.n->len(pv)
A:jax.interpreters.partial_eval.key->object()
A:jax.interpreters.partial_eval.d->Destructuring(i, eqn, key)
A:jax.interpreters.partial_eval.Destructuring->namedtuple('Destructuring', ['i', 'eqn', 'key'])
A:jax.interpreters.partial_eval.abstract_unit->core.AbstractTuple()
A:jax.interpreters.partial_eval.aval->core.lattice_join(pv1, pv2)
A:jax.interpreters.partial_eval.(pv1, const1)->explode(pv1, const1)
A:jax.interpreters.partial_eval.(pv2, const2)->explode(pv2, const2)
A:jax.interpreters.partial_eval.(join_pvs, join_consts)->unzip2(map(join_pvals, pvals1, pvals2))
A:jax.interpreters.partial_eval.pv_out->JaxprTracerTuple(pvs)
A:jax.interpreters.partial_eval.instantiate->kwargs.pop('instantiate', False)
A:jax.interpreters.partial_eval.fun->trace_to_subjaxpr(fun, master, instantiate)
A:jax.interpreters.partial_eval.(jaxpr, (out_pval, consts, env))->trace_to_subjaxpr(fun, master, instantiate).call_wrapped(pvals)
A:jax.interpreters.partial_eval.in_tracers->map(trace.new_arg, pvals)
A:jax.interpreters.partial_eval.out_tracer->JaxprTrace(master, core.cur_sublevel()).full_raise(out_tracer)
A:jax.interpreters.partial_eval.t->type(second_component)
A:jax.interpreters.partial_eval.FreeVar->namedtuple('FreeVar', ['val'])
A:jax.interpreters.partial_eval.ConstVar->namedtuple('ConstVar', ['val'])
A:jax.interpreters.partial_eval.LambdaBinding->namedtuple('LambdaBinding', [])
A:jax.interpreters.partial_eval.newvar->gensym('')
A:jax.interpreters.partial_eval.t_to_var->defaultdict(newvar)
A:jax.interpreters.partial_eval.sorted_tracers->toposort(out_tracer)
A:jax.interpreters.partial_eval.const_to_var->defaultdict(newvar)
A:jax.interpreters.partial_eval.(env_vars, env_vals)->unzip2(env.items())
A:jax.interpreters.partial_eval.(const_vars, const_vals)->unzip2(consts.items())
A:jax.interpreters.partial_eval.jaxpr->Jaxpr(const_vars, env_vars, invars, var(out_tracer), eqns)
A:jax.interpreters.partial_eval.counter->itertools.count()
A:jax.interpreters.partial_eval.lifted_jaxpr->Jaxpr(const_vars, env_vars, invars, var(out_tracer), eqns).copy()
A:jax.interpreters.partial_eval.pvals->map(as_pval2, jaxpr.in_avals, second_components)
A:jax.interpreters.partial_eval.(jaxpr_2, out_pval, consts_2)->trace_to_jaxpr(f, pvals, instantiate=instantiate)
A:jax.interpreters.partial_eval.(jaxpr_1, out_pval, consts_1)->trace_to_jaxpr(lu.wrap_init(fun), pvals, instantiate=True)
A:jax.interpreters.partial_eval.lifted_jaxpr_2->_closure_convert_jaxpr(jaxpr_2)
A:jax.interpreters.partial_eval.doubly_lifted_jaxpr_2->_move_and_pair_arg(lifted_jaxpr_2)
A:jax.interpreters.partial_eval.(in_avals_1, in_avals_2)->unzip2(map(_split_avals, second_components, jaxpr.in_avals))
A:jax.interpreters.partial_eval.(out_aval_1, out_aval_2)->_split_avals(sc_out, jaxpr.out_aval)
A:jax.interpreters.partial_eval.lifted_out_aval_1->AbstractTuple((c1, AbstractTuple((b1, res))))
A:jax.interpreters.partial_eval.typed_jaxpr_1->TypedJaxpr(jaxpr_1, consts_1, in_avals_1, lifted_out_aval_1)
A:jax.interpreters.partial_eval.typed_jaxpr_2->TypedJaxpr(doubly_lifted_jaxpr_2, (), lifted_in_avals_2, out_aval_2)
A:jax.interpreters.partial_eval.moved_jaxpr->Jaxpr(const_vars, env_vars, invars, var(out_tracer), eqns).copy()
A:jax.interpreters.partial_eval.(avals1, avals2)->unzip2(map(_split_avals, second_component, aval))
jax.interpreters.partial_eval.JaxprTrace(Trace)
jax.interpreters.partial_eval.JaxprTrace.instantiate_const(self,tracer)
jax.interpreters.partial_eval.JaxprTrace.lift(self,val)
jax.interpreters.partial_eval.JaxprTrace.new_arg(self,pval)
jax.interpreters.partial_eval.JaxprTrace.new_const(self,val)
jax.interpreters.partial_eval.JaxprTrace.new_instantiated_const(self,val)
jax.interpreters.partial_eval.JaxprTrace.new_instantiated_literal(self,val)
jax.interpreters.partial_eval.JaxprTrace.pack(self,tracers)
jax.interpreters.partial_eval.JaxprTrace.post_process_call(self,call_primitive,out_tracer,params)
jax.interpreters.partial_eval.JaxprTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_map(self,map_primitive,f,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.pure(self,val)
jax.interpreters.partial_eval.JaxprTrace.sublift(self,val)
jax.interpreters.partial_eval.JaxprTracer(self,trace,pval,recipe)
jax.interpreters.partial_eval.JaxprTracer.__init__(self,trace,pval,recipe)
jax.interpreters.partial_eval.JaxprTracer.__repr__(self)
jax.interpreters.partial_eval.JaxprTracer.aval(self)
jax.interpreters.partial_eval.JaxprTracer.full_lower(self)
jax.interpreters.partial_eval.JaxprTracer.ispure(self)
jax.interpreters.partial_eval.JaxprTracer.parents(self)
jax.interpreters.partial_eval.JaxprTracer.unpack(self)
jax.interpreters.partial_eval.JaxprTracerTuple(tuple)
jax.interpreters.partial_eval.PartialVal(cls,xs)
jax.interpreters.partial_eval.PartialVal.__new__(cls,xs)
jax.interpreters.partial_eval.Var(self,count,suffix)
jax.interpreters.partial_eval.Var.__init__(self,count,suffix)
jax.interpreters.partial_eval.Var.__repr__(self)
jax.interpreters.partial_eval._closure_convert_jaxpr(jaxpr)
jax.interpreters.partial_eval._move_and_pair_arg(jaxpr)
jax.interpreters.partial_eval._pack_eqn(invars,outvar)
jax.interpreters.partial_eval._split_avals(second_component,aval)
jax.interpreters.partial_eval._unpack_eqn(invar,outvars)
jax.interpreters.partial_eval.abstract_eval_fun(fun,*avals,**params)
jax.interpreters.partial_eval.abstractify(x)
jax.interpreters.partial_eval.add_axis_to_aval(size,aval)
jax.interpreters.partial_eval.add_axis_to_pv(size,pv)
jax.interpreters.partial_eval.as_abstract_val(pv)
jax.interpreters.partial_eval.as_pval(aval,is_unknown,val)
jax.interpreters.partial_eval.as_pval2(aval,is_unknown)
jax.interpreters.partial_eval.eqn_parents(eqn)
jax.interpreters.partial_eval.eqn_tracer_to_var(var,outvars,eqn)
jax.interpreters.partial_eval.gensym(suffix)
jax.interpreters.partial_eval.identity(x)
jax.interpreters.partial_eval.instantiate_const_at(trace,instantiate,tracer)
jax.interpreters.partial_eval.join_pvals(pval1,pval2)
jax.interpreters.partial_eval.merge_pvals(val,pval)
jax.interpreters.partial_eval.pack_pvals(pvals)
jax.interpreters.partial_eval.partial_eval(f,trace,pvs)
jax.interpreters.partial_eval.partial_eval_jaxpr(jaxpr,second_components,instantiate)
jax.interpreters.partial_eval.partial_eval_wrapper(avals,*consts)
jax.interpreters.partial_eval.partial_val_aval(pv,const)
jax.interpreters.partial_eval.remove_axis_from_aval(aval)
jax.interpreters.partial_eval.remove_axis_from_pv(pv)
jax.interpreters.partial_eval.trace_to_jaxpr(fun,pvals,**kwargs)
jax.interpreters.partial_eval.trace_to_subjaxpr(master,instantiate,pvals)
jax.interpreters.partial_eval.trace_unwrapped_to_jaxpr(fun,pvals,instantiate,**kwargs)
jax.interpreters.partial_eval.tracers_to_jaxpr(in_tracers,out_tracer)
jax.interpreters.partial_eval.unknown(x)
jax.interpreters.partial_eval.unzip_tracer_tuple(pvals)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/interpreters/parallel.py----------------------------------------
A:jax.interpreters.parallel.(fun, _)->papply_transform(fun, name, axis_size)
A:jax.interpreters.parallel.trace->PapplyTrace(master, core.cur_sublevel())
A:jax.interpreters.parallel.in_tracers->map(partial(PapplyTracer, trace, name, axis_size, axis=0), args)
A:jax.interpreters.parallel.out_tracer->PapplyTrace(master, core.cur_sublevel()).full_raise(ans)
A:jax.interpreters.parallel.batched_aval->batching.get_aval(self.val)
A:jax.interpreters.parallel.(names, vals, axes)->unzip3(((t.name, t.val, t.axis) for t in tracers))
A:jax.interpreters.parallel.(val_out, axis_out)->rule(name, size, vals, axes, **params)
A:jax.interpreters.parallel.(f_papply, axis_out)->papply_subtrace(f, self.master, name, size, axes)
A:jax.interpreters.parallel.val_out->call_primitive.bind(f_papply, *vals, **params)
A:jax.interpreters.parallel.vals->core.pack([t.val for t in tracers])
A:jax.interpreters.parallel.axis->tuple((t.axis for t in tracers))
A:jax.interpreters.parallel.name->tuple((t.name for t in tracers))
A:jax.interpreters.parallel.size->tuple((t.axis_size for t in tracers))
jax.interpreters.parallel.PapplyTrace(Trace)
jax.interpreters.parallel.PapplyTrace.lift(self,val)
jax.interpreters.parallel.PapplyTrace.pack(self,tracers)
jax.interpreters.parallel.PapplyTrace.post_process_call(self,call_primitive,out_tracer)
jax.interpreters.parallel.PapplyTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.parallel.PapplyTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.parallel.PapplyTrace.pure(self,val)
jax.interpreters.parallel.PapplyTrace.sublift(self,val)
jax.interpreters.parallel.PapplyTracer(self,trace,name,axis_size,val,axis)
jax.interpreters.parallel.PapplyTracer.__init__(self,trace,name,axis_size,val,axis)
jax.interpreters.parallel.PapplyTracer.aval(self)
jax.interpreters.parallel.PapplyTracer.full_lower(self)
jax.interpreters.parallel.PapplyTracer.unpack(self)
jax.interpreters.parallel._match_axis(src,dst,x,aval)
jax.interpreters.parallel.identity(x)
jax.interpreters.parallel.match_axis(src,dst,x)
jax.interpreters.parallel.papply(fun,name,in_vals,axis_size)
jax.interpreters.parallel.papply_subtrace(master,name,axis_size,axes,*vals)
jax.interpreters.parallel.papply_transform(name,axis_size,*args)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax/lax_control_flow.py----------------------------------------
A:jax.lax.lax_control_flow.(_, result)->while_loop(while_cond_fun, while_body_fun, (lower, init_val))
A:jax.lax.lax_control_flow.(init_val_flat, in_tree)->pytree_to_jaxtupletree(init_val)
A:jax.lax.lax_control_flow.(flat_body_fun, out_tree)->pytree_fun_to_jaxtupletree_fun(lu.wrap_init(body_fun), (in_tree,))
A:jax.lax.lax_control_flow.(flat_cond_fun, _)->pytree_fun_to_jaxtupletree_fun(lu.wrap_init(cond_fun), (in_tree,))
A:jax.lax.lax_control_flow.carry_pval_flat(carry_aval, _)->_abstractify(init_val_flat)
A:jax.lax.lax_control_flow.(cond_jaxpr, cond_pval_out, cond_consts)->jax.interpreters.partial_eval.trace_to_jaxpr(flat_cond_fun, (carry_pval_flat,))
A:jax.lax.lax_control_flow.(body_jaxpr, body_pval_out, body_consts)->jax.interpreters.partial_eval.trace_to_jaxpr(flat_body_fun, (carry_pval_flat,), instantiate=True)
A:jax.lax.lax_control_flow.out_flat->jax.lax.lax.Primitive('while').bind(init_val_flat, core.pack(cond_consts), core.pack(body_consts), aval_out=carry_aval_out, cond_jaxpr=cond_jaxpr, body_jaxpr=body_jaxpr)
A:jax.lax.lax_control_flow.cond_fun->partial(core.eval_jaxpr, cond_jaxpr, cond_consts, ())
A:jax.lax.lax_control_flow.body_fun->partial(core.eval_jaxpr, body_jaxpr, body_consts, ())
A:jax.lax.lax_control_flow.val->body_fun(val)
A:jax.lax.lax_control_flow.loop_carry->c.Tuple(init_val, cond_consts, body_consts)
A:jax.lax.lax_control_flow.shape->numpy.shape(xs)
A:jax.lax.lax_control_flow.loop_carry_var->jax.interpreters.partial_eval.Var(0, 'loop_carry')
A:jax.lax.lax_control_flow.outvar->_scan_newvar()
A:jax.lax.lax_control_flow.cond_var->jax.interpreters.partial_eval.Var(0, 'cond_consts')
A:jax.lax.lax_control_flow.body_var->jax.interpreters.partial_eval.Var(0, 'body_consts')
A:jax.lax.lax_control_flow.cond_jaxpr_converted->cond_jaxpr.copy()
A:jax.lax.lax_control_flow.body_jaxpr_converted->body_jaxpr.copy()
A:jax.lax.lax_control_flow.cond_c->jax.interpreters.xla._jaxpr_computation(cond_jaxpr_converted, axis_env, (), (), shape)
A:jax.lax.lax_control_flow.body_c->jax.interpreters.xla._jaxpr_computation(body_jaxpr_converted, axis_env, (), (), shape)
A:jax.lax.lax_control_flow.full_ans->c.While(cond_c, body_c, loop_carry)
A:jax.lax.lax_control_flow.sizes->jax.lax.lax._reduce(set.union, map(batching.dimsize, batch_dims, batched_args))
A:jax.lax.lax_control_flow.size->jax.lax.lax._reduce(set.union, map(batching.dimsize, batch_dims, batched_args)).pop()
A:jax.lax.lax_control_flow.init_val->jax.interpreters.batching.bdim_at_front(init_val, init_val_bd, size, force_broadcast=True)
A:jax.lax.lax_control_flow.f->jax.interpreters.batching.batch_transform(lifted, size, (init_val_bd, cond_consts_bd, body_consts_bd), init_val_bd)
A:jax.lax.lax_control_flow.preds->jax.interpreters.batching.batch_transform(lifted, size, (init_val_bd, cond_consts_bd, body_consts_bd), init_val_bd).call_wrapped((batched_loop_carry, cond_consts))
A:jax.lax.lax_control_flow.pred->jax.core.eval_jaxpr(cond_jaxpr, cond_consts, (), loop_carry)
A:jax.lax.lax_control_flow.new_loop_carry->jax.core.eval_jaxpr(body_jaxpr, body_consts, (), loop_carry)
A:jax.lax.lax_control_flow.aval->jax.core.get_aval(on_true)
A:jax.lax.lax_control_flow.while_p->jax.lax.lax.Primitive('while')
A:jax.lax.lax_control_flow.(op_flat, in_tree)->pytree_to_flatjaxtuple(operand)
A:jax.lax.lax_control_flow.(fun_flat, out_tree)->pytree_fun_to_flatjaxtuple_fun(lu.wrap_init(fun), (in_tree,))
A:jax.lax.lax_control_flow.(jaxpr, pvout, consts)->jax.interpreters.partial_eval.trace_to_jaxpr(fun_flat, (_abstractify(op_flat),))
A:jax.lax.lax_control_flow.true_data->trace_jaxpr(true_fun, true_operand)
A:jax.lax.lax_control_flow.false_data->trace_jaxpr(false_fun, false_operand)
A:jax.lax.lax_control_flow.joined_pval->jax.interpreters.partial_eval.join_pvals(true_pval, false_pval)
A:jax.lax.lax_control_flow.revis->_revise_cond_jaxpr(joined_pval, false_pval, false_jaxpr, false_consts)
A:jax.lax.lax_control_flow.out->jax.core.Primitive('scan').bind(core.unit, carry_ct, core.pack((ct_bs, res)), forward=not forward, length=length, jaxpr=jaxpr_trans)
A:jax.lax.lax_control_flow.new_jaxpr->typed_jaxpr.jaxpr.copy().copy()
A:jax.lax.lax_control_flow.newvar->jax.interpreters.partial_eval.gensym('_cond')
A:jax.lax.lax_control_flow.(new_constvars, new_constvals)->unzip2([(newvar(), c) for (new, old, c) in zip(new_pv, old_pv, old_const) if old is None and new is not None])
A:jax.lax.lax_control_flow.newvars->iter(new_constvars)
A:jax.lax.lax_control_flow.true_fun->partial(core.eval_jaxpr, true_jaxpr, true_consts, ())
A:jax.lax.lax_control_flow.false_fun->partial(core.eval_jaxpr, false_jaxpr, false_consts, ())
A:jax.lax.lax_control_flow.arg_var->jax.interpreters.partial_eval.Var(0, 'arg')
A:jax.lax.lax_control_flow.consts_var->jax.interpreters.partial_eval.Var(0, 'consts')
A:jax.lax.lax_control_flow.jaxpr_converted->typed_jaxpr.jaxpr.copy().copy()
A:jax.lax.lax_control_flow.true_arg->c.Tuple(true_op, true_consts)
A:jax.lax.lax_control_flow.true_comp->make_computation(true_jaxpr, true_arg)
A:jax.lax.lax_control_flow.false_arg->c.Tuple(false_op, false_consts)
A:jax.lax.lax_control_flow.false_comp->make_computation(false_jaxpr, false_arg)
A:jax.lax.lax_control_flow.cond_p->jax.lax.lax.Primitive('cond')
A:jax.lax.lax_control_flow.t->type(is_unknown)
A:jax.lax.lax_control_flow.x->_index_arrays(idx, x_aval, xs)
A:jax.lax.lax_control_flow.((init, xs), in_trees)->unzip2(map(pytree_to_jaxtupletree, (init, xs)))
A:jax.lax.lax_control_flow.(f, out_tree)->pytree_fun_to_jaxtupletree_fun(lu.wrap_init(f), in_trees)
A:jax.lax.lax_control_flow.carry_pval(carry_aval, _)->_abstractify(init)
A:jax.lax.lax_control_flow.(xs_aval, _)->_abstractify(xs)
A:jax.lax.lax_control_flow.x_aval->_demote_aval_rank(xs_aval)
A:jax.lax.lax_control_flow.x_pval->jax.interpreters.partial_eval.PartialVal((x_aval, core.unit))
A:jax.lax.lax_control_flow.(jaxpr, pval_out, consts)->jax.interpreters.partial_eval.trace_to_jaxpr(traceable, pvals, instantiate=True)
A:jax.lax.lax_control_flow.lifted_jaxpr->jax.interpreters.partial_eval._closure_convert_jaxpr(jaxpr)
A:jax.lax.lax_control_flow.(consts_aval, _)->_abstractify(core.pack(consts))
A:jax.lax.lax_control_flow.out_aval->jax.core.AbstractTuple((core.AbstractTuple((CTc_aval, CTd_aval)), CTa_aval))
A:jax.lax.lax_control_flow.jaxpr->typed_jaxpr.jaxpr.copy()
A:jax.lax.lax_control_flow.length->kwargs.pop('length')
A:jax.lax.lax_control_flow.ys_aval->_promote_aval_rank(length, y_aval)
A:jax.lax.lax_control_flow.(carry_out, y)->jax.core.jaxpr_as_fun(jaxpr)(consts, carry, x)
A:jax.lax.lax_control_flow.ys_out->_update_arrays(idx, y_aval, ys, y)
A:jax.lax.lax_control_flow.ys_init->_empty_arrays(ys_aval)
A:jax.lax.lax_control_flow.(carry, ys)->fori_loop(0, length, body_fun, (init, ys_init))
A:jax.lax.lax_control_flow.consts_nonzeros->jax.interpreters.ad.get_nonzeros(consts_dot)
A:jax.lax.lax_control_flow.init_nonzeros->jax.interpreters.ad.get_nonzeros(init_dot)
A:jax.lax.lax_control_flow.xs_nonzeros->jax.interpreters.ad.get_nonzeros(xs_dot)
A:jax.lax.lax_control_flow.(jaxpr_jvp, nonzeros_out)->jax.interpreters.ad.jvp_jaxpr(jaxpr, nonzeros, instantiate=(carry_nonzeros, False))
A:jax.lax.lax_control_flow.carry_nonzeros->_binary_lattice_join(carry_nonzeros_out, carry_nonzeros)
A:jax.lax.lax_control_flow.nonzero_init_dot->_convert_zeros(carry_nonzeros, init, init_dot)
A:jax.lax.lax_control_flow.nonzero_consts_dot->_convert_zeros(consts_nonzeros, consts, consts_dot)
A:jax.lax.lax_control_flow.nonzero_xs_dot->_convert_zeros(xs_nonzeros, xs, xs_dot)
A:jax.lax.lax_control_flow.consts_dual->jax.core.pack((consts, nonzero_consts_dot))
A:jax.lax.lax_control_flow.init_dual->jax.core.pack((init, nonzero_init_dot))
A:jax.lax.lax_control_flow.xs_dual->jax.core.pack((xs, nonzero_xs_dot))
A:jax.lax.lax_control_flow.(carry_out_dual, ys_dual)->jax.core.Primitive('scan').bind(consts_dual, init_dual, xs_dual, forward=forward, length=length, jaxpr=jaxpr_jvp)
A:jax.lax.lax_control_flow.ys_dot->jax.interpreters.ad.put_zeros(ad.TangentTuple, ys_nonzeros, ys_dot)
A:jax.lax.lax_control_flow.carry_out_dot->jax.interpreters.ad.put_zeros(ad.TangentTuple, carry_nonzeros_out, carry_out_dot)
A:jax.lax.lax_control_flow.recur->partial(_binary_lattice_fold, f, pack)
A:jax.lax.lax_control_flow._binary_lattice_join->partial(_binary_lattice_fold, operator.or_, tuple)
A:jax.lax.lax_control_flow._binary_lattice_eq->partial(_binary_lattice_fold, operator.eq, all)
A:jax.lax.lax_control_flow.forward->kwargs.pop('forward')
A:jax.lax.lax_control_flow.(in_pvs, _)->unzip2([t.pval for t in tracers])
A:jax.lax.lax_control_flow.(sc_consts, sc_init, sc_xs)->map(pe.unknown, in_pvs)
A:jax.lax.lax_control_flow.(jaxpr_1, jaxpr_2, sc_out)->jax.interpreters.partial_eval.partial_eval_jaxpr(jaxpr, second_components, instantiate=(sc_carry, False))
A:jax.lax.lax_control_flow.sc_carry->_binary_lattice_join(sc_carry, sc_carry_out)
A:jax.lax.lax_control_flow.lifted_init_tracer->_lift_tracer(trace, init_tracer, sc_carry)
A:jax.lax.lax_control_flow.(in_pvs, in_consts)->unzip2([t.pval for t in lifted_tracers])
A:jax.lax.lax_control_flow.out_pv->_put_known_pvs(sc_out, out_aval)
A:jax.lax.lax_control_flow.(out_carry, (ys, residuals))->jax.core.Primitive('scan').bind(*in_consts, forward=forward, length=length, jaxpr=jaxpr_1)
A:jax.lax.lax_control_flow.out_const->jax.core.pack((out_carry, ys))
A:jax.lax.lax_control_flow.residuals_tracer->trace.new_instantiated_const(core.pack(residuals))
A:jax.lax.lax_control_flow.eqn->jax.core.JaxprEqn(new_tracers, None, scan_p, (), True, False, dict(forward=forward, length=length, jaxpr=jaxpr_2))
A:jax.lax.lax_control_flow.tracers->map(trace.full_raise, tracer)
A:jax.lax.lax_control_flow.jaxpr_lifted->rearrange_binders(lambda d, c, a_res: (a_res[1], (d, c, a_res[0])), jaxpr)
A:jax.lax.lax_control_flow.jaxpr_lifted_trans->_transpose_jaxpr(jaxpr_lifted)
A:jax.lax.lax_control_flow.jaxpr_trans->_move_stuff_and_add_add(jaxpr_lifted_trans)
A:jax.lax.lax_control_flow.bs_aval->_promote_aval_rank(length, b_aval)
A:jax.lax.lax_control_flow.ct_d->jax.ad_util.zeros_like_aval(d_aval)
A:jax.lax.lax_control_flow.(ct_c, ct_bs)->jax.interpreters.ad.instantiate_zeros_aval(core.AbstractTuple((c_aval, bs_aval)), ct)
A:jax.lax.lax_control_flow.carry_ct->jax.core.pack((ct_c, ct_d))
A:jax.lax.lax_control_flow.jaxpr.invars->f(*jaxpr.invars)
A:jax.lax.lax_control_flow.in_avals->f(*typed_jaxpr.in_avals)
A:jax.lax.lax_control_flow._scan_newvar->jax.interpreters.partial_eval.gensym('_scan')
A:jax.lax.lax_control_flow.CTc_in->_scan_newvar()
A:jax.lax.lax_control_flow.CTb_in->_scan_newvar()
A:jax.lax.lax_control_flow.CTd_in->_scan_newvar()
A:jax.lax.lax_control_flow.CTd_new->_scan_newvar()
A:jax.lax.lax_control_flow.CTd_sum->_scan_newvar()
A:jax.lax.lax_control_flow.CTc->_scan_newvar()
A:jax.lax.lax_control_flow.CTa->_scan_newvar()
A:jax.lax.lax_control_flow.partial_out->_scan_newvar()
A:jax.lax.lax_control_flow.(_, (_, a_bar))->jax.interpreters.ad.backward_pass(jaxpr.jaxpr, jaxpr.literals, (), (res, None), b_bar)
A:jax.lax.lax_control_flow.a_bar->jax.interpreters.ad.instantiate_zeros_aval(jaxpr.in_avals[1], a_bar)
A:jax.lax.lax_control_flow.transposed_jaxpr->_make_typed_jaxpr(transposed, (jaxpr.in_avals[0], jaxpr.out_aval))
A:jax.lax.lax_control_flow.consts_batched->jax.interpreters.batching.instantiate_bdim(size, 0, consts_batched, consts_bdim, consts)
A:jax.lax.lax_control_flow.init_batched->jax.interpreters.batching.instantiate_bdim(size, 0, carry_batched, init_bdim, init)
A:jax.lax.lax_control_flow.xs_batched->jax.interpreters.batching.instantiate_bdim(size, 1, xs_batched, xs_bdim, xs)
A:jax.lax.lax_control_flow.(jaxpr_batched, batched_out)->jax.interpreters.batching.batch_jaxpr(jaxpr, size, which_batched, instantiate=(carry_batched, False))
A:jax.lax.lax_control_flow.carry_batched->_binary_lattice_join(carry_batched_out, carry_batched)
A:jax.lax.lax_control_flow.(carry_out, ys)->jax.core.Primitive('scan').bind(consts_batched, init_batched, xs_batched, forward=forward, length=length, jaxpr=jaxpr_batched)
A:jax.lax.lax_control_flow.carry_out_bdim->jax.interpreters.batching.bools_to_bdims(0, carry_batched)
A:jax.lax.lax_control_flow.ys_bdim->jax.interpreters.batching.bools_to_bdims(1, ys_batched)
A:jax.lax.lax_control_flow.scan_p->jax.core.Primitive('scan')
A:jax.lax.lax_control_flow.xla.initial_style_translations[scan_p]->jax.interpreters.xla.lower_fun(_scan_impl, initial_style=True)
jax.lax.FixedPointError(Exception)
jax.lax._add_any_eqn(tot,a,b)
jax.lax._binary_lattice_fold(f,pack,a,b)
jax.lax._cond_abstract_eval(pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax._cond_impl(pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax._cond_translation_rule(c,axis_env,pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax._convert_zeros(instantiate,example,tangent)
jax.lax._demote_aval_rank(xs)
jax.lax._empty_arrays(aval)
jax.lax._index_arrays(i,aval,xs)
jax.lax._jaxtupletree_select(pred,on_true,on_false)
jax.lax._leading_dim_size(xs)
jax.lax._lift_tracer(trace,tracer,is_unknown)
jax.lax._make_typed_jaxpr(traceable,in_avals)
jax.lax._maybe_tracer_tuple_to_abstract_tuple(tup)
jax.lax._move_stuff_and_add_add(typed_jaxpr)
jax.lax._pack_eqn(invars,outvar)
jax.lax._promote_aval_rank(n,xs)
jax.lax._put_known_pvs(is_unknown,aval)
jax.lax._revise_cond_jaxpr(new_pval,old_pval,jaxpr,consts)
jax.lax._scan_batching_rule(batched_args,batch_dims,forward,length,jaxpr)
jax.lax._scan_impl(consts,init,xs,forward,length,jaxpr)
jax.lax._scan_jvp(primals,tangents,forward,length,jaxpr)
jax.lax._scan_partial_eval(trace,*tracers,**kwargs)
jax.lax._scan_transpose(ct,consts,init,xs,forward,length,jaxpr)
jax.lax._transpose_jaxpr(jaxpr)
jax.lax._unpack_eqn(invar,outvars)
jax.lax._update_arrays(i,aval,xs,x)
jax.lax._while_loop_abstract_eval(init_val,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax._while_loop_batching_rule(batched_args,batch_dims,aval_out,cond_jaxpr,body_jaxpr)
jax.lax._while_loop_impl(init_val,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax._while_loop_translation_rule(c,axis_env,init_val,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax.cond(pred,true_operand,true_fun,false_operand,false_fun)
jax.lax.fori_loop(lower,upper,body_fun,init_val)
jax.lax.lax_control_flow.FixedPointError(Exception)
jax.lax.lax_control_flow._add_any_eqn(tot,a,b)
jax.lax.lax_control_flow._binary_lattice_fold(f,pack,a,b)
jax.lax.lax_control_flow._cond_abstract_eval(pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax.lax_control_flow._cond_impl(pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax.lax_control_flow._cond_translation_rule(c,axis_env,pred,true_op,true_consts,false_op,false_consts,aval_out,true_jaxpr,false_jaxpr)
jax.lax.lax_control_flow._convert_zeros(instantiate,example,tangent)
jax.lax.lax_control_flow._demote_aval_rank(xs)
jax.lax.lax_control_flow._empty_arrays(aval)
jax.lax.lax_control_flow._index_arrays(i,aval,xs)
jax.lax.lax_control_flow._jaxtupletree_select(pred,on_true,on_false)
jax.lax.lax_control_flow._leading_dim_size(xs)
jax.lax.lax_control_flow._lift_tracer(trace,tracer,is_unknown)
jax.lax.lax_control_flow._make_typed_jaxpr(traceable,in_avals)
jax.lax.lax_control_flow._maybe_tracer_tuple_to_abstract_tuple(tup)
jax.lax.lax_control_flow._move_stuff_and_add_add(typed_jaxpr)
jax.lax.lax_control_flow._pack_eqn(invars,outvar)
jax.lax.lax_control_flow._promote_aval_rank(n,xs)
jax.lax.lax_control_flow._put_known_pvs(is_unknown,aval)
jax.lax.lax_control_flow._revise_cond_jaxpr(new_pval,old_pval,jaxpr,consts)
jax.lax.lax_control_flow._scan_batching_rule(batched_args,batch_dims,forward,length,jaxpr)
jax.lax.lax_control_flow._scan_impl(consts,init,xs,forward,length,jaxpr)
jax.lax.lax_control_flow._scan_jvp(primals,tangents,forward,length,jaxpr)
jax.lax.lax_control_flow._scan_partial_eval(trace,*tracers,**kwargs)
jax.lax.lax_control_flow._scan_transpose(ct,consts,init,xs,forward,length,jaxpr)
jax.lax.lax_control_flow._transpose_jaxpr(jaxpr)
jax.lax.lax_control_flow._unpack_eqn(invar,outvars)
jax.lax.lax_control_flow._update_arrays(i,aval,xs,x)
jax.lax.lax_control_flow._while_loop_abstract_eval(init_val,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax.lax_control_flow._while_loop_batching_rule(batched_args,batch_dims,aval_out,cond_jaxpr,body_jaxpr)
jax.lax.lax_control_flow._while_loop_impl(init_val,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax.lax_control_flow._while_loop_translation_rule(c,axis_env,init_val,cond_consts,body_consts,aval_out,cond_jaxpr,body_jaxpr)
jax.lax.lax_control_flow.cond(pred,true_operand,true_fun,false_operand,false_fun)
jax.lax.lax_control_flow.fori_loop(lower,upper,body_fun,init_val)
jax.lax.lax_control_flow.rearrange_binders(f,typed_jaxpr)
jax.lax.lax_control_flow.scan(f,init,xs)
jax.lax.lax_control_flow.scan_bind(consts,init,xs,forward,length,jaxpr)
jax.lax.lax_control_flow.while_loop(cond_fun,body_fun,init_val)
jax.lax.rearrange_binders(f,typed_jaxpr)
jax.lax.scan(f,init,xs)
jax.lax.scan_bind(consts,init,xs,forward,length,jaxpr)
jax.lax.while_loop(cond_fun,body_fun,init_val)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax/lax_parallel.py----------------------------------------
A:jax.lax.lax_parallel.prim->jax.core.Primitive(name)
A:jax.lax.lax_parallel.dtype->c.GetShape(val).numpy_dtype()
A:jax.lax.lax_parallel.scalar->jax.lib.xla_client.Shape.array_shape(dtype, ())
A:jax.lax.lax_parallel.computation->jax.interpreters.xla.primitive_computation(prim, scalar, scalar)
A:jax.lax.lax_parallel.psum_p->standard_pmap_primitive('psum')
A:jax.lax.lax_parallel.pxla.split_axis_rules[psum_p]->partial(_allreduce_split_axis_rule, psum_p, lax._reduce_sum)
A:jax.lax.lax_parallel.xla.parallel_translations[psum_p]->partial(_allreduce_translation_rule, lax.add_p)
A:jax.lax.lax_parallel.pmax_p->standard_pmap_primitive('pmax')
A:jax.lax.lax_parallel.xla.parallel_translations[pmax_p]->partial(_allreduce_translation_rule, lax.max_p)
A:jax.lax.lax_parallel.pxla.split_axis_rules[pmax_p]->partial(_allreduce_split_axis_rule, pmax_p, lax._reduce_max)
A:jax.lax.lax_parallel.pmin_p->standard_pmap_primitive('pmin')
A:jax.lax.lax_parallel.xla.parallel_translations[pmin_p]->partial(_allreduce_translation_rule, lax.min_p)
A:jax.lax.lax_parallel.pxla.split_axis_rules[pmin_p]->partial(_allreduce_split_axis_rule, pmin_p, lax._reduce_min)
A:jax.lax.lax_parallel.group_size->len(replica_groups[0])
A:jax.lax.lax_parallel.(srcs, dsts)->unzip2(perm)
A:jax.lax.lax_parallel.grp->list(sorted(grp))
A:jax.lax.lax_parallel.inverse_perm->list(zip(dsts, srcs))
A:jax.lax.lax_parallel.ppermute_p->standard_pmap_primitive('ppermute')
A:jax.lax.lax_parallel.stacked->standard_pmap_primitive('all_to_all').bind(x, split_axis=split_axis + 1, concat_axis=0, axis_name=axis_name)
A:jax.lax.lax_parallel.out->jax.lax.lax.gather(operand, start_indices, dimension_numbers=dnums, slice_sizes=slice_sizes)
A:jax.lax.lax_parallel.all_to_all_p->standard_pmap_primitive('all_to_all')
A:jax.lax.lax_parallel.shape->list(x.shape)
A:jax.lax.lax_parallel.x->jax.lax.lax.psplit_like(x, y, name)
A:jax.lax.lax_parallel.y->jax.lax.lax.psplit_like(y, x, name)
A:jax.lax.lax_parallel.parallel.papply_primitive_rules[prim]->partial(_identity_papply, prim, argnum)
A:jax.lax.lax_parallel.result->jax.core.Primitive(name).bind(operand, axes=tuple(other_axes), **kwargs)
A:jax.lax.lax_parallel.xbatch->adjust_dims(xbatch, xdim)
A:jax.lax.lax_parallel.xcontract->adjust_dims(xcontract, xdim)
A:jax.lax.lax_parallel.ybatch->adjust_dims(ybatch, ydim)
A:jax.lax.lax_parallel.ycontract->adjust_dims(ycontract, ydim)
A:jax.lax.lax_parallel.z->jax.lax.lax.dot_general(x, y, sub_dims(xdim, None, xc, yc, xb, yb), precision)
A:jax.lax.lax_parallel.(ok, out)->cases(x, y, xdim, ydim, lhs_contract, rhs_contract, lhs_batch, rhs_batch)
A:jax.lax.lax_parallel.left->numpy.prod(old_sizes[:old_axis])
A:jax.lax.lax_parallel.new_axis->find_new_axis(axis, old_sizes, new_sizes)
A:jax.lax.lax_parallel.lhs->jax.lax.lax.reshape(lhs, tuple(onp.insert(lhs.shape, lhs_dim, 1)))
A:jax.lax.lax_parallel.sub_bdims->tuple(onp.delete(broadcast_dimensions, dim))
A:jax.lax.lax_parallel.sub_shape->tuple(onp.delete(shape, out_dim))
A:jax.lax.lax_parallel.padding_config->list(padding_config)
A:jax.lax.lax_parallel.padded->jax.lax.lax.pad(operand, padding_value, padding_config[:operand_dim] + padding_config[operand_dim + 1:])
A:jax.lax.lax_parallel.start_indices->list(start_indices)
A:jax.lax.lax_parallel.limit_indices->list(limit_indices)
A:jax.lax.lax_parallel.offset_dims->tuple((i - 1 if i > start_indices_dim else i for i in dimension_numbers.offset_dims))
A:jax.lax.lax_parallel.dnums->jax.lax.lax.GatherDimensionNumbers(offset_dims=offset_dims, collapsed_slice_dims=dimension_numbers.collapsed_slice_dims, start_index_map=dimension_numbers.start_index_map)
jax.lax._add_jaxvals_papply_rule(name,size,vals,dims)
jax.lax._all_to_all_split_axis_rule(vals,which_mapped,split_axis,concat_axis,axis_name)
jax.lax._all_to_all_translation_rule(c,x,split_axis,concat_axis,replica_groups)
jax.lax._allgather(x,dim,size,axis_name)
jax.lax._allreduce_split_axis_rule(prim,reducer,vals,which_mapped,axis_name)
jax.lax._allreduce_translation_rule(prim,c,val,replica_groups)
jax.lax._broadcast_in_dim_papply_rule(name,size,vals,dims,shape,broadcast_dimensions)
jax.lax._broadcasting_papply(prim,name,size,vals,axes,**params)
jax.lax._conv_general_dilated_papply_rule(name,size,vals,dims,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,precision,**unused_kwargs)
jax.lax._convert_element_type_papply_rule(name,size,vals,dims,new_dtype,**params)
jax.lax._defbroadcasting(prim)
jax.lax._defidentity(prim,argnum=0)
jax.lax._defreducer(prim,collective_prim)
jax.lax._defvectorized(prim)
jax.lax._dot_general_papply_rule(name,size,vals,dims,dimension_numbers,precision)
jax.lax._dot_papply_rule(name,size,vals,dims,precision)
jax.lax._drop(x,dim,axis_name)
jax.lax._gather_papply_rule(name,size,vals,dims,dimension_numbers,slice_sizes,operand_shape)
jax.lax._identity_papply(prim,argnum,name,size,vals,axes,**params)
jax.lax._moveaxis(src,dst,x)
jax.lax._pad_papply_rule(name,size,vals,dims,padding_config)
jax.lax._ppermute_translation_rule(c,x,replica_groups,perm)
jax.lax._ppermute_transpose_rule(t,perm,axis_name)
jax.lax._reducer_papply(prim,cprim,name,size,vals,papply_axes,axes,**kwargs)
jax.lax._reshape_papply_rule(name,size,vals,axes,new_sizes,dimensions,old_sizes)
jax.lax._select_papply_rule(name,size,vals,dims)
jax.lax._slice_papply_rule(name,size,vals,dims,start_indices,limit_indices,strides,**kwargs)
jax.lax._transpose_papply_rule(name,size,vals,dims,permutation)
jax.lax._vectorized_papply(prim,name,size,vals,axes,**params)
jax.lax.all_to_all(x,axis_name,split_axis,concat_axis)
jax.lax.lax_parallel._add_jaxvals_papply_rule(name,size,vals,dims)
jax.lax.lax_parallel._all_to_all_split_axis_rule(vals,which_mapped,split_axis,concat_axis,axis_name)
jax.lax.lax_parallel._all_to_all_translation_rule(c,x,split_axis,concat_axis,replica_groups)
jax.lax.lax_parallel._allgather(x,dim,size,axis_name)
jax.lax.lax_parallel._allreduce_split_axis_rule(prim,reducer,vals,which_mapped,axis_name)
jax.lax.lax_parallel._allreduce_translation_rule(prim,c,val,replica_groups)
jax.lax.lax_parallel._broadcast_in_dim_papply_rule(name,size,vals,dims,shape,broadcast_dimensions)
jax.lax.lax_parallel._broadcasting_papply(prim,name,size,vals,axes,**params)
jax.lax.lax_parallel._conv_general_dilated_papply_rule(name,size,vals,dims,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,precision,**unused_kwargs)
jax.lax.lax_parallel._convert_element_type_papply_rule(name,size,vals,dims,new_dtype,**params)
jax.lax.lax_parallel._defbroadcasting(prim)
jax.lax.lax_parallel._defidentity(prim,argnum=0)
jax.lax.lax_parallel._defreducer(prim,collective_prim)
jax.lax.lax_parallel._defvectorized(prim)
jax.lax.lax_parallel._dot_general_papply_rule(name,size,vals,dims,dimension_numbers,precision)
jax.lax.lax_parallel._dot_papply_rule(name,size,vals,dims,precision)
jax.lax.lax_parallel._drop(x,dim,axis_name)
jax.lax.lax_parallel._gather_papply_rule(name,size,vals,dims,dimension_numbers,slice_sizes,operand_shape)
jax.lax.lax_parallel._identity_papply(prim,argnum,name,size,vals,axes,**params)
jax.lax.lax_parallel._moveaxis(src,dst,x)
jax.lax.lax_parallel._pad_papply_rule(name,size,vals,dims,padding_config)
jax.lax.lax_parallel._ppermute_translation_rule(c,x,replica_groups,perm)
jax.lax.lax_parallel._ppermute_transpose_rule(t,perm,axis_name)
jax.lax.lax_parallel._reducer_papply(prim,cprim,name,size,vals,papply_axes,axes,**kwargs)
jax.lax.lax_parallel._reshape_papply_rule(name,size,vals,axes,new_sizes,dimensions,old_sizes)
jax.lax.lax_parallel._select_papply_rule(name,size,vals,dims)
jax.lax.lax_parallel._slice_papply_rule(name,size,vals,dims,start_indices,limit_indices,strides,**kwargs)
jax.lax.lax_parallel._transpose_papply_rule(name,size,vals,dims,permutation)
jax.lax.lax_parallel._vectorized_papply(prim,name,size,vals,axes,**params)
jax.lax.lax_parallel.all_to_all(x,axis_name,split_axis,concat_axis)
jax.lax.lax_parallel.pmax(x,axis_name)
jax.lax.lax_parallel.pmin(x,axis_name)
jax.lax.lax_parallel.ppermute(x,axis_name,perm)
jax.lax.lax_parallel.psum(x,axis_name)
jax.lax.lax_parallel.pswapaxes(x,axis_name,axis)
jax.lax.lax_parallel.standard_pmap_primitive(name)
jax.lax.pmax(x,axis_name)
jax.lax.pmin(x,axis_name)
jax.lax.ppermute(x,axis_name,perm)
jax.lax.psum(x,axis_name)
jax.lax.pswapaxes(x,axis_name,axis)
jax.lax.standard_pmap_primitive(name)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax/lax_fft.py----------------------------------------
A:jax.lax.lax_fft.fft_lengths->tuple(fft_lengths)
A:jax.lax.lax_fft.x->interpreters.batching.bdim_at_front(x, bd)
A:jax.lax.lax_fft.fft_p->Primitive('fft')
jax.lax.fft(x,fft_type,fft_lengths=None)
jax.lax.fft_abstract_eval(x,fft_type,fft_lengths)
jax.lax.fft_batching_rule(batched_args,batch_dims,fft_type,fft_lengths)
jax.lax.fft_impl(x,fft_type,fft_lengths)
jax.lax.fft_translation_rule(c,x,fft_type,fft_lengths)
jax.lax.fft_transpose_rule(t,fft_type,fft_lengths)
jax.lax.lax_fft.fft(x,fft_type,fft_lengths=None)
jax.lax.lax_fft.fft_abstract_eval(x,fft_type,fft_lengths)
jax.lax.lax_fft.fft_batching_rule(batched_args,batch_dims,fft_type,fft_lengths)
jax.lax.lax_fft.fft_impl(x,fft_type,fft_lengths)
jax.lax.lax_fft.fft_translation_rule(c,x,fft_type,fft_lengths)
jax.lax.lax_fft.fft_transpose_rule(t,fft_type,fft_lengths)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.1.40/lib/python3.6/site-packages/jax/lax/lax.py----------------------------------------
A:jax.lax.lax.ndim->_max((len(shape) for shape in shapes))
A:jax.lax.lax.shapes->numpy.array([operand.shape for operand in operands])
A:jax.lax.lax.min_shape->numpy.min(shapes, axis=0)
A:jax.lax.lax.max_shape->numpy.max(shapes, axis=0)
A:jax.lax.lax.result_shape->numpy.floor_divide(onp.add(onp.subtract(limit_indices, start_indices), strides) - 1, strides)
A:jax.lax.lax.new_dtype->lib.xla_bridge.canonicalize_dtype(new_dtype)
A:jax.lax.lax.old_dtype->_dtype(operand)
A:jax.lax.lax.operand->interpreters.batching.move_dim_to_front(operand, o_bdims)
A:jax.lax.lax.dimension_numbers->_conv_general_proto(dimension_numbers)
A:jax.lax.lax.padding->list(map(onp.sum, padding))
A:jax.lax.lax.lhs_shape->numpy.shape(lhs)
A:jax.lax.lax.lhs_ndim->len(lhs_shape)
A:jax.lax.lax.rhs_ndim->numpy.ndim(rhs)
A:jax.lax.lax.lhs->broadcast(lhs, (rhs.shape[rbd],))
A:jax.lax.lax.rhs->broadcast(rhs, (lhs.shape[lbd],))
A:jax.lax.lax.contract_dims->tuple(map(tuple, contract_dims))
A:jax.lax.lax.batch_dims->tuple(map(tuple, batch_dims))
A:jax.lax.lax.lhs_noncontract_dims->tuple(sorted(set(range(onp.ndim(lhs))) - set(lhs_batch_dims) - set(lhs_contract_dims)))
A:jax.lax.lax.rhs_noncontract_dims->tuple(sorted(set(range(onp.ndim(rhs))) - set(rhs_batch_dims) - set(rhs_contract_dims)))
A:jax.lax.lax.new_lhs_shape->numpy.insert(onp.shape(lhs), len(lhs_batch_dims) + len(lhs_noncontract_dims), (1,) * len(rhs_noncontract_dims))
A:jax.lax.lax.new_rhs_shape->numpy.insert(onp.shape(rhs), len(lhs_batch_dims), (1,) * len(lhs_noncontract_dims))
A:jax.lax.lax.new_sizes->_canonicalize_shape(new_sizes)
A:jax.lax.lax.start_indices->concatenate([reshape(i, [1]) for i in start_indices], 0)
A:jax.lax.lax.(jaxpr, consts)->_reduction_jaxpr(mul, init_value)
A:jax.lax.lax.indices->concatenate([reshape(i, [i.shape[0], 1]) for i in idxs], 1)
A:jax.lax.lax.slice_sizes->iter(onp.delete(slice_sizes, dimension_numbers.collapsed_slice_dims))
A:jax.lax.lax.offset_dims->tuple(onp.add(1, dimension_numbers.offset_dims))
A:jax.lax.lax.dnums->ScatterDimensionNumbers(update_window_dims=update_window_dims, inserted_window_dims=inserted_window_dims, scatter_dims_to_operand_dims=scatter_dims_to_operand_dims)
A:jax.lax.lax.permutation->tuple(permutation)
A:jax.lax.lax.monoid_reducer->_get_monoid_window_reducer(computation, init_value)
A:jax.lax.lax.pval->_abstractify(init_value)
A:jax.lax.lax.(jaxpr, _, consts)->interpreters.partial_eval.trace_unwrapped_to_jaxpr(computation, (pval, pval), instantiate=False)
A:jax.lax.lax.aval->ShapedArray(new_sizes, operand.dtype)
A:jax.lax.lax.dtype->lib.xla_bridge.canonicalize_dtype(dtype)
A:jax.lax.lax.init_value->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Constant(onp.array(0, dtype))
A:jax.lax.lax.(select_jaxpr, select_consts)->_reduction_jaxpr(select)
A:jax.lax.lax.(scatter_jaxpr, scatter_consts)->_reduction_jaxpr(scatter)
A:jax.lax.lax.result->numpy.asarray(_reduce(operator.and_, eyes), self.dtype)
A:jax.lax.lax.shape->numpy.asarray(list(map(int, operand.shape)), start_indices.dtype)
A:jax.lax.lax.val->numpy.asarray(fill_value, dtype)
A:jax.lax.lax.dimension->kwargs.pop('dimension')
A:jax.lax.lax.axes->tuple(onp.delete(range(len(shape)), broadcast_dimensions))
A:jax.lax.lax.pads->padtype_to_pads(lhs_shape[2:], rhs_shape[2:], strides, pads)
A:jax.lax.lax.pad_a->int(onp.ceil(pad_len / 2))
A:jax.lax.lax.x->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').ParameterWithShape(xla_client.Shape.array_shape(onp.dtype(double_word_dtype), ()))
A:jax.lax.lax.ndims->len(lhs.shape)
A:jax.lax.lax.dn->conv_dimension_numbers(lhs.shape, rhs.shape, dimension_numbers)
A:jax.lax.lax.k_shape->numpy.take(rhs.shape, dn.rhs_spec)
A:jax.lax.lax.out->sort_key_val(keys, new_values, new_dimension)
A:jax.lax.lax.size->next((x.shape[ax] for (x, ax) in zip(batched_args, batch_dims) if ax is not None))
A:jax.lax.lax.limit_indices->list(operand.shape)
A:jax.lax.lax.axis->int(axis)
A:jax.lax.lax.start_indices[axis]->reshape(rem(start_index, axis_size), [1])
A:jax.lax.lax.limit_indices[axis]->int(limit_index)
A:jax.lax.lax.strides[axis]->int(stride)
A:jax.lax.lax.axis_size->_const(start_index, operand.shape[axis])
A:jax.lax.lax.slice_sizes[axis]->int(slice_size)
A:jax.lax.lax.update->reshape(update, operand.shape[:ax] + (1,) + operand.shape[ax + 1:])
A:jax.lax.lax.batch->tuple(range(lhs.ndim - 2))
A:jax.lax.lax.log_half->_const(x, onp.log(0.5))
A:jax.lax.lax.a->convert_element_type(a, b_dtype)
A:jax.lax.lax.sqrt_max_value->numpy.sqrt(onp.finfo(_dtype(x)).max)
A:jax.lax.lax.ShapedArray.broadcast->core.aval_method(broadcast)
A:jax.lax.lax.ShapedArray.transpose->core.aval_method(transpose)
A:jax.lax.lax.ShapedArray.reshape->core.aval_method(reshape)
A:jax.lax.lax.ShapedArray._iter->staticmethod(_iter)
A:jax.lax.lax.prim->standard_primitive(shape_rule, dtype_rule, name, translation_rule=translation_rule)
A:jax.lax.lax.least_specialized->_max(map(type, args), key=operator.attrgetter('array_abstraction_level'))
A:jax.lax.lax.xla_opname->''.join((term.capitalize() for term in name.split('_')))
A:jax.lax.lax.typename->str(onp.dtype(aval_dtype).name)
A:jax.lax.lax.dtype_rule->partial(binop_dtype_rule, result_dtype, accepted_dtypes, name)
A:jax.lax.lax.standard_unop->partial(unop, _identity)
A:jax.lax.lax.typenames->', '.join((str(onp.dtype(t).name) for t in types))
A:jax.lax.lax.shape_rule->partial(_broadcasting_shape_rule, name)
A:jax.lax.lax.standard_binop->partial(binop, _input_dtype)
A:jax.lax.lax.x_shape->numpy.shape(x)
A:jax.lax.lax.(broadcast_dimensions,)->numpy.where(onp.equal(x_shape, shape))
A:jax.lax.lax.(squeezed_dimensions,)->numpy.where(onp.not_equal(x_shape, shape))
A:jax.lax.lax.inshape->numpy.delete(x_shape, squeezed_dimensions)
A:jax.lax.lax.neg_p->standard_unop(_num, 'neg')
A:jax.lax.lax.sign_p->standard_unop(_num, 'sign')
A:jax.lax.lax.floor_p->standard_unop(_float, 'floor')
A:jax.lax.lax.ceil_p->standard_unop(_float, 'ceil')
A:jax.lax.lax.round_p->standard_unop(_float, 'round')
A:jax.lax.lax.is_finite_p->unop(_fixed_dtype(onp.bool_), _float, 'is_finite')
A:jax.lax.lax.exp_p->standard_unop(_float | _complex, 'exp')
A:jax.lax.lax.log_p->standard_unop(_float | _complex, 'log')
A:jax.lax.lax.expm1_p->standard_unop(_float | _complex, 'expm1')
A:jax.lax.lax.log1p_p->standard_unop(_float | _complex, 'log1p')
A:jax.lax.lax.tanh_p->standard_unop(_float | _complex, 'tanh')
A:jax.lax.lax.sin_p->standard_unop(_float | _complex, 'sin')
A:jax.lax.lax.cos_p->standard_unop(_float | _complex, 'cos')
A:jax.lax.lax.atan2_p->standard_binop([_float, _float], 'atan2')
A:jax.lax.lax.lgamma_p->standard_unop(_float, 'lgamma')
A:jax.lax.lax.digamma_p->standard_unop(_float, 'digamma')
A:jax.lax.lax.erf_p->standard_unop(_float, 'erf')
A:jax.lax.lax.erfc_p->standard_unop(_float, 'erfc')
A:jax.lax.lax.erf_inv_p->standard_unop(_float, 'erf_inv')
A:jax.lax.lax.real_p->unop(_complex_basetype, _complex, 'real')
A:jax.lax.lax.imag_p->unop(_complex_basetype, _complex, 'imag')
A:jax.lax.lax.complex_p->binop(_complex_dtype, [_complex_elem_types, _complex_elem_types], 'complex')
A:jax.lax.lax.conj_p->unop(_complex_dtype, _float | _complex, 'conj')
A:jax.lax.lax.ad.primitive_jvps[conj_p]->partial(ad.linear_jvp, conj_p)
A:jax.lax.lax.abs_p->unop(_complex_basetype, _num, 'abs')
A:jax.lax.lax.sqrt_p->standard_unop(_float | _complex, 'sqrt')
A:jax.lax.lax.pow_p->standard_binop([_float | _complex, _float | _complex], 'pow')
A:jax.lax.lax.jac->mul(y, pow(x, select(eq(y, _zeros(y)), _ones(y), sub(y, _ones(y)))))
A:jax.lax.lax.not_p->standard_unop(_int | _bool, 'not')
A:jax.lax.lax.and_p->standard_binop([_any, _any], 'and')
A:jax.lax.lax.or_p->standard_binop([_any, _any], 'or')
A:jax.lax.lax.xor_p->standard_binop([_any, _any], 'xor')
A:jax.lax.lax.add_p->standard_binop([_num, _num], 'add')
A:jax.lax.lax.sub_p->standard_binop([_num, _num], 'sub')
A:jax.lax.lax.mul_p->standard_binop([_num, _num], 'mul')
A:jax.lax.lax.zero->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Constant(onp.array(0, dtype))
A:jax.lax.lax.out_shape->numpy.ceil(onp.true_divide(in_shape, window_strides)).astype(int)
A:jax.lax.lax.safe_mul_p->standard_binop([_num, _num], 'safe_mul', translation_rule=_safe_mul_translation_rule)
A:jax.lax.lax.div_p->standard_binop([_num, _num], 'div')
A:jax.lax.lax.rem_p->standard_binop([_num, _num], 'rem')
A:jax.lax.lax.which->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').BroadcastInDim(which, out_shape, bcast_dims(which_shape))
A:jax.lax.lax.y->tie_in(*batched_args)
A:jax.lax.lax.comparator->cmp(c)
A:jax.lax.lax.rx->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Real(x)
A:jax.lax.lax.ry->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').Real(y)
A:jax.lax.lax.max_p->standard_binop([_any, _any], 'max', translation_rule=partial(_minmax_translation_rule, minmax=lambda c: c.Max, cmp=lambda c: c.Gt))
A:jax.lax.lax.min_p->standard_binop([_any, _any], 'min', translation_rule=partial(_minmax_translation_rule, minmax=lambda c: c.Min, cmp=lambda c: c.Lt))
A:jax.lax.lax.shift_left_p->standard_binop([_int, _int], 'shift_left')
A:jax.lax.lax.shift_right_arithmetic_p->standard_binop([_int, _int], 'shift_right_arithmetic')
A:jax.lax.lax.shift_right_logical_p->standard_binop([_int, _int], 'shift_right_logical')
A:jax.lax.lax.eq_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'eq')
A:jax.lax.lax.ne_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'ne')
A:jax.lax.lax.ge_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'ge')
A:jax.lax.lax.gt_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'gt')
A:jax.lax.lax.le_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'le')
A:jax.lax.lax.lt_p->binop(_fixed_dtype(onp.bool_), [_any, _any], 'lt')
A:jax.lax.lax.new_etype->lib.xla_bridge.dtype_to_etype(new_dtype)
A:jax.lax.lax.convert_element_type_p->standard_primitive(_convert_element_type_shape_rule, _convert_element_type_dtype_rule, 'convert_element_type', _convert_element_type_translation_rule)
A:jax.lax.lax.bitcast_convert_type_p->standard_primitive(_bitcast_convert_type_shape_rule, _bitcast_convert_type_dtype_rule, 'bitcast_convert_type', _bitcast_convert_type_translation_rule)
A:jax.lax.lax.(quot, rem)->divmod(lhs_feature_count, feature_group_count)
A:jax.lax.lax.lhs_trans->numpy.take(lhs_shape, lhs_perm)
A:jax.lax.lax.rhs_trans->numpy.take(rhs_shape, rhs_perm)
A:jax.lax.lax.out_trans->tuple((lhs_trans[0], rhs_trans[0]) + tuple(out_space))
A:jax.lax.lax.(lhs_sdims, rhs_sdims, out_sdims)->map(_conv_sdims, dimension_numbers)
A:jax.lax.lax.t_rhs_spec->_conv_spec_transpose(rhs_spec)
A:jax.lax.lax.trans_dimension_numbers->ConvDimensionNumbers(lhs_trans, out_trans, rhs_trans)
A:jax.lax.lax.revd_weights->rev(rhs, rhs_sdims)
A:jax.lax.lax.(lhs_trans, rhs_trans, out_trans)->map(_conv_spec_transpose, dimension_numbers)
A:jax.lax.lax.new_lhs->_reshape_axis_into(lhs_bdim, lhs_spec[0], lhs)
A:jax.lax.lax.new_rhs->_reshape_axis_into(rhs_spec[0], rhs_spec[0], new_rhs)
A:jax.lax.lax.conv_general_dilated_p->standard_primitive(_conv_general_dilated_shape_rule, _conv_general_dilated_dtype_rule, 'conv_general_dilated', _conv_general_dilated_translation_rule)
A:jax.lax.lax.new_shape->list(onp.delete(x.shape, src))
A:jax.lax.lax.(size2, ragged)->divmod(shape[src], size1)
A:jax.lax.lax.config->lib.xla_client.PrecisionConfig()
A:jax.lax.lax._dot_dtype_rule->partial(binop_dtype_rule, _input_dtype, [_num, _num], 'dot')
A:jax.lax.lax.dot_p->standard_primitive(_dot_shape_rule, _dot_dtype_rule, 'dot', _dot_translation_rule)
A:jax.lax.lax.lhs_batch_shape->numpy.take(lhs.shape, lhs_batch)
A:jax.lax.lax.rhs_batch_shape->numpy.take(rhs.shape, rhs_batch)
A:jax.lax.lax.lhs_contracting_shape->numpy.take(lhs.shape, lhs_contracting)
A:jax.lax.lax.rhs_contracting_shape->numpy.take(rhs.shape, rhs_contracting)
A:jax.lax.lax.batch_shape->tuple(onp.take(lhs.shape, lhs_batch))
A:jax.lax.lax.lhs_tensored_shape->tuple(onp.delete(lhs.shape, lhs_contract_or_batch))
A:jax.lax.lax.rhs_tensored_shape->tuple(onp.delete(rhs.shape, rhs_contract_or_batch))
A:jax.lax.lax.x_kept->remaining(range(x_ndim), x_contract, x_batch)
A:jax.lax.lax.y_kept->remaining(range(y.ndim), y_contract, y_batch)
A:jax.lax.lax.(ans_batch, ans_y, _)->ranges_like(x_batch, y_kept, x_kept)
A:jax.lax.lax.(ans_batch, _, ans_y)->ranges_like(x_batch, x_kept, y_kept)
A:jax.lax.lax.x_contract_sorted_by_y->list(onp.take(x_contract, onp.argsort(y_contract)))
A:jax.lax.lax.out_axes->numpy.argsort(list(x_batch) + x_kept + x_contract_sorted_by_y)
A:jax.lax.lax.lhs_contract->tuple(onp.add(1, lhs_contract))
A:jax.lax.lax.rhs_contract->tuple(onp.add(1, rhs_contract))
A:jax.lax.lax.batched_out->dot_general(lhs, rhs, new_dimension_numbers, precision=precision)
A:jax.lax.lax.dot_general_p->standard_primitive(_dot_general_shape_rule, _dot_general_dtype_rule, 'dot_general', _dot_general_translation_rule)
A:jax.lax.lax.broadcast_p->standard_primitive(_broadcast_shape_rule, _input_dtype, 'broadcast')
A:jax.lax.lax.new_operand->pad(new_operand, _zero(operand), ((0, 1, 0),) + tuple(((0, 0, 0) for _ in operand_shape)))
A:jax.lax.lax.broadcast_in_dim_p->standard_primitive(_broadcast_in_dim_shape_rule, _input_dtype, 'broadcast_in_dim')
A:jax.lax.lax._clamp_dtype_rule->partial(binop_dtype_rule, _input_dtype, [_any, _any, _any], 'clamp')
A:jax.lax.lax.clamp_p->standard_primitive(_clamp_shape_rule, _clamp_dtype_rule, 'clamp')
A:jax.lax.lax.op->next((op for op in operands if not isinstance(op, UnshapedArray)))
A:jax.lax.lax.concat_size->sum((o.shape[dimension] for o in operands))
A:jax.lax.lax.operand_shapes->kwargs.pop('operand_shapes')
A:jax.lax.lax.limit_points->numpy.cumsum([shape[dimension] for shape in operand_shapes])
A:jax.lax.lax.starts->numpy.zeros((len(operands), t.ndim), dtype=int)
A:jax.lax.lax.limits->numpy.tile(t.shape, (len(operands), 1))
A:jax.lax.lax.concatenate_p->standard_primitive(_concatenate_shape_rule, _concatenate_dtype_rule, 'concatenate', _concatenate_translation_rule)
A:jax.lax.lax.(lo, hi, interior)->zip(*padding_config)
A:jax.lax.lax.unpad_config->zip(onp.negative(lo), onp.negative(hi), onp.zeros_like(interior))
A:jax.lax.lax.unpadded->pad(t, onp.array(0.0, t.dtype), unpad_config)
A:jax.lax.lax.padding_config->list(padding_config)
A:jax.lax.lax.pad_p->standard_primitive(_pad_shape_rule, _input_dtype, 'pad')
A:jax.lax.lax.reshape_p->standard_primitive(_reshape_shape_rule, _reshape_dtype_rule, 'reshape', _reshape_translation_rule)
A:jax.lax.lax.rev_p->standard_primitive(_rev_shape_rule, _input_dtype, 'rev')
A:jax.lax.lax.transpose_p->standard_primitive(_transpose_shape_rule, _input_dtype, 'transpose')
A:jax.lax.lax.zeros->full(operand_shape, tie_in(t, _zero(t)))
A:jax.lax.lax.pred->broadcast_in_dim(pred, on_true.shape, [0])
A:jax.lax.lax.on_false->interpreters.batching.bdim_at_front(on_false, of_bdim, size, force_broadcast=True)
A:jax.lax.lax.on_true->interpreters.batching.bdim_at_front(on_true, ot_bdim, size, force_broadcast=True)
A:jax.lax.lax.select_p->standard_primitive(_select_shape_rule, _select_dtype_rule, 'select')
A:jax.lax.lax.strides->numpy.ones(operand.ndim, onp.int32)
A:jax.lax.lax.real_limits->numpy.add(onp.add(start_indices, 1), onp.multiply(onp.subtract(t.shape, 1), strides))
A:jax.lax.lax.new_start_indices->list(start_indices)
A:jax.lax.lax.new_limit_indices->list(limit_indices)
A:jax.lax.lax.new_strides->list(strides)
A:jax.lax.lax.slice_p->standard_primitive(_slice_shape_rule, _input_dtype, 'slice', _slice_translation_rule)
A:jax.lax.lax.dims->tuple(range(len(update_shape)))
A:jax.lax.lax.dynamic_slice_p->standard_primitive(_dynamic_slice_shape_rule, _input_dtype, 'dynamic_slice', _dynamic_slice_translation_rule)
A:jax.lax.lax.val_out->sort_key_val(keys, values, dimension)
A:jax.lax.lax.g_operand->interpreters.ad.instantiate_zeros(operand, g_operand)
A:jax.lax.lax.g_update->interpreters.ad.instantiate_zeros(update, g_update)
A:jax.lax.lax.tangent_out->_select_and_gather_add(g_source, operand, select_prim, window_dimensions, window_strides, padding)
A:jax.lax.lax.dynamic_update_slice_p->standard_primitive(_dynamic_update_slice_shape_rule, _dynamic_update_slice_dtype_rule, 'dynamic_update_slice', _dynamic_update_slice_translation_rule)
A:jax.lax.lax.proto->lib.xla_client.ConvolutionDimensionNumbers()
A:jax.lax.lax.msg->'slice_sizes must have rank equal to the gather operand; operand.shape={}, slice_sizes={}'.format(operand_shape, slice_sizes)
A:jax.lax.lax.start_indices_shape->iter(start_indices.shape[:-1])
A:jax.lax.lax.indices_shape->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').GetShape(scatter_indices)
A:jax.lax.lax.scatter_dnums->ScatterDimensionNumbers(update_window_dims=dimension_numbers.offset_dims, inserted_window_dims=dimension_numbers.collapsed_slice_dims, scatter_dims_to_operand_dims=dimension_numbers.start_index_map)
A:jax.lax.lax.collapsed_slice_dims->tuple(onp.add(1, dimension_numbers.collapsed_slice_dims))
A:jax.lax.lax.start_index_map->tuple(onp.add(1, dimension_numbers.start_index_map))
A:jax.lax.lax.count_shape->list(scatter_indices.shape)
A:jax.lax.lax.counts->_reduce_sum(location_indicators, axes)
A:jax.lax.lax.gather_p->standard_primitive(_gather_shape_rule, _gather_dtype_rule, 'gather', _gather_translation_rule)
A:jax.lax.lax.update_computation->_reduction_computation(c, update_jaxpr, update_consts, init_value)
A:jax.lax.lax.g_updates->interpreters.ad.instantiate_zeros(updates, g_updates)
A:jax.lax.lax.gather_dnums->GatherDimensionNumbers(offset_dims=dnums.update_window_dims, collapsed_slice_dims=dnums.inserted_window_dims, start_index_map=dnums.scatter_dims_to_operand_dims)
A:jax.lax.lax.update_t->gather(t, scatter_indices, dimension_numbers=gather_dnums, slice_sizes=slice_sizes)
A:jax.lax.lax.updates->reshape(updates, (1,) + updates_shape)
A:jax.lax.lax.inserted_window_dims->tuple(onp.add(1, dimension_numbers.inserted_window_dims))
A:jax.lax.lax.scatter_dims_to_operand_dims->tuple(onp.add(1, dimension_numbers.scatter_dims_to_operand_dims))
A:jax.lax.lax.scatter_indices->concatenate([counts, scatter_indices], len(count_shape) - 1)
A:jax.lax.lax.update_window_dims->tuple(onp.add(1, dimension_numbers.update_window_dims))
A:jax.lax.lax.scatter_add_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-add', _scatter_translation_rule)
A:jax.lax.lax.batching.primitive_batchers[scatter_add_p]->partial(_scatter_batching_rule, scatter_add)
A:jax.lax.lax.scatter_min_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-min', _scatter_translation_rule)
A:jax.lax.lax.batching.primitive_batchers[scatter_min_p]->partial(_scatter_batching_rule, scatter_min)
A:jax.lax.lax.scatter_max_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-max', _scatter_translation_rule)
A:jax.lax.lax.batching.primitive_batchers[scatter_max_p]->partial(_scatter_batching_rule, scatter_max)
A:jax.lax.lax.updates_dtype->_dtype(updates)
A:jax.lax.lax.ids_shape->numpy.array(updates_shape)
A:jax.lax.lax.num_ids->numpy.prod(ids_shape)
A:jax.lax.lax.update_ids->add(reshape(iota(updates_dtype, num_ids), ids_shape), _ones(updates))
A:jax.lax.lax.reshaped_update_ids->reshape(update_ids, (1,) + updates_shape)
A:jax.lax.lax.updates_and_ids->concatenate((updates, reshaped_update_ids), 0)
A:jax.lax.lax.new_dnums->ScatterDimensionNumbers(update_window_dims=(0,) + tuple((d + 1 for d in dnums.update_window_dims)), inserted_window_dims=tuple((d + 1 for d in dnums.inserted_window_dims)), scatter_dims_to_operand_dims=tuple((d + 1 for d in dnums.scatter_dims_to_operand_dims)))
A:jax.lax.lax.outputs->concatenate(outputs, 0)
A:jax.lax.lax.scattered_ids->index_in_dim(outputs, 1, keepdims=False)
A:jax.lax.lax.gathered_update_ids->gather(scattered_ids, scatter_indices, dimension_numbers=gather_dnums, slice_sizes=slice_sizes)
A:jax.lax.lax.masked_g_operand->select(eq(scattered_ids, _zeros(scattered_ids)), g_operand, _zeros(g_operand))
A:jax.lax.lax.masked_g_updates->select(eq(update_ids, gathered_update_ids), g_updates, _zeros(g_updates))
A:jax.lax.lax.scatter_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter', _scatter_translation_rule)
A:jax.lax.lax.batching.primitive_batchers[scatter_p]->partial(_scatter_batching_rule, scatter)
A:jax.lax.lax.xla_computation->_reduction_computation(c, jaxpr, consts, init_value)
A:jax.lax.lax.reduce_p->standard_primitive(_reduce_shape_rule, _input_dtype, 'reduce', _reduce_translation_rule)
A:jax.lax.lax.scalar->lib.xla_client.Shape.array_shape(dtype, ())
A:jax.lax.lax.broadcast_dimensions->numpy.delete(onp.arange(keys.ndim), keys_bdim)
A:jax.lax.lax.reduce_sum_p->standard_primitive(_reduce_sum_shape_rule, _input_dtype, 'reduce_sum', _reduce_sum_translation_rule)
A:jax.lax.lax.input_shape->numpy.array(operand.shape)
A:jax.lax.lax.n->numpy.prod(input_shape[list(axes)])
A:jax.lax.lax.non_axes->numpy.delete(onp.arange(len(input_shape)), axes)
A:jax.lax.lax.tangent->reshape(tangent, new_shape, permutation)
A:jax.lax.lax.one->_const(operand, 1)
A:jax.lax.lax.left_products->_reduce_window_prod(pad(operand, one, left_padding), window_dims, window_strides, xla_client.PaddingType.VALID)
A:jax.lax.lax.right_products->_reduce_window_prod(pad(operand, one, right_padding), window_dims, window_strides, xla_client.PaddingType.VALID)
A:jax.lax.lax.reduce_prod_p->standard_primitive(_reduce_prod_shape_rule, _input_dtype, 'reduce_prod', _reduce_prod_translation_rule)
A:jax.lax.lax.location_indicators->convert_element_type(_eq_meet(operand, reshape(ans, shape)), g.dtype)
A:jax.lax.lax._reduce_max_translation_rule->partial(_reduce_chooser_translation_rule, max_p, _get_max_identity)
A:jax.lax.lax.reduce_max_p->standard_primitive(_reduce_chooser_shape_rule, _input_dtype, 'reduce_max', _reduce_max_translation_rule)
A:jax.lax.lax._reduce_min_translation_rule->partial(_reduce_chooser_translation_rule, min_p, _get_min_identity)
A:jax.lax.lax.reduce_min_p->standard_primitive(_reduce_chooser_shape_rule, _input_dtype, 'reduce_min', _reduce_min_translation_rule)
A:jax.lax.lax._reduce_or_translation_rule->partial(_reduce_logical_translation_rule, or_p, _get_max_identity)
A:jax.lax.lax.reduce_or_p->standard_primitive(_reduce_logical_shape_rule, _fixed_dtype(onp.bool_), 'reduce_or', _reduce_or_translation_rule)
A:jax.lax.lax._reduce_and_translation_rule->partial(_reduce_logical_translation_rule, and_p, _get_min_identity)
A:jax.lax.lax.reduce_and_p->standard_primitive(_reduce_logical_shape_rule, _fixed_dtype(onp.bool_), 'reduce_and', _reduce_and_translation_rule)
A:jax.lax.lax.reduce_window_p->standard_primitive(_reduce_window_shape_rule, _input_dtype, 'reduce_window', _reduce_window_translation_rule)
A:jax.lax.lax.in_pads->padtype_to_pads(input_shape, window_dimensions, window_strides, padding)
A:jax.lax.lax.pad_cotangent->pad(cotangent, _zero(cotangent), padding_config)
A:jax.lax.lax.reduce_window_sum_p->standard_primitive(_reduce_window_sum_shape_rule, _input_dtype, 'reduce_window_sum', _reduce_window_sum_translation_rule)
A:jax.lax.lax.batching.primitive_batchers[reduce_window_sum_p]->partial(_reduce_window_batch_rule, _reduce_window_sum)
A:jax.lax.lax.operand_padded->numpy.add(operand_shape, onp.add(*zip(*pads)))
A:jax.lax.lax._reduce_window_max_translation_rule->partial(_reduce_window_chooser_translation_rule, max_p, _get_max_identity)
A:jax.lax.lax.reduce_window_max_p->standard_primitive(_common_reduce_window_shape_rule, _input_dtype, 'reduce_window_max', _reduce_window_max_translation_rule)
A:jax.lax.lax.batching.primitive_batchers[reduce_window_max_p]->partial(_reduce_window_batch_rule, _reduce_window_max)
A:jax.lax.lax._reduce_window_min_translation_rule->partial(_reduce_window_chooser_translation_rule, min_p, _get_min_identity)
A:jax.lax.lax.reduce_window_min_p->standard_primitive(_common_reduce_window_shape_rule, _input_dtype, 'reduce_window_min', _reduce_window_min_translation_rule)
A:jax.lax.lax._reduce_window_min_batch_rule->partial(_reduce_window_batch_rule, _reduce_window_min)
A:jax.lax.lax.batching.primitive_batchers[reduce_window_min_p]->partial(_reduce_window_batch_rule, _reduce_window_min)
A:jax.lax.lax.select->interpreters.xla.primitive_computation(select_prim, scalar, scalar)
A:jax.lax.lax.scatter->interpreters.xla.primitive_computation(add_p, scalar, scalar)
A:jax.lax.lax.select_and_scatter_p->standard_primitive(_select_and_scatter_shape_rule, _input_dtype, 'select_and_scatter', _select_and_scatter_translation)
A:jax.lax.lax.source_t->_select_and_gather_add(t, operand, select_prim, window_dimensions, window_strides, padding)
A:jax.lax.lax.source->interpreters.batching.move_dim_to_front(source, s_bdims)
A:jax.lax.lax.select_and_scatter_add_p->standard_primitive(_select_and_scatter_add_shape_rule, _input_dtype, 'select_and_scatter_add', _select_and_scatter_add_translation)
A:jax.lax.lax.etype->lib.xla_bridge.dtype_to_etype(diag_const.dtype)
A:jax.lax.lax.word_type->lib.xla_client.dtype_to_etype(word_dtype)
A:jax.lax.lax.double_word_type->lib.xla_client.dtype_to_etype(double_word_dtype)
A:jax.lax.lax.b->convert_element_type(b, a_dtype)
A:jax.lax.lax.st->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer').And(t, const(c, word_dtype, (1 << r_nbits) - 1 << r_nbits))
A:jax.lax.lax.c->lib.xla_bridge.make_computation_builder('select_and_gather_pair_reducer')
A:jax.lax.lax.select_and_gather_add_p->standard_primitive(_select_and_gather_add_shape_rule, _input_dtype, 'select_and_gather_add', _select_and_gather_add_translation)
A:jax.lax.lax.xla.backend_specific_translations['tpu'][select_and_gather_add_p]->partial(_select_and_gather_add_translation, max_bits=32)
A:jax.lax.lax.(_, g_out)->sort_key_val(operand, g, dimension)
A:jax.lax.lax.sort_p->standard_primitive(sort_shape, _input_dtype, 'sort')
A:jax.lax.lax.keys_tangents_out->_sort_jvp_rule(keys_tangents, keys, dimension)
A:jax.lax.lax.values_tangents_out->_sort_jvp_rule(values_tangents, keys, dimension)
A:jax.lax.lax.iota->tuple(range(len(lhs_shape)))
A:jax.lax.lax.(_, perm)->sort_key_val(keys, iota)
A:jax.lax.lax.keys_trans->interpreters.batching.moveaxis(keys.shape[keys_bdim], values_bdim, keys_bdim, keys)
A:jax.lax.lax.new_keys->broadcast_in_dim(keys, values.shape, broadcast_dimensions)
A:jax.lax.lax.new_values->broadcast_in_dim(values, keys.shape, broadcast_dimensions)
A:jax.lax.lax.sort_key_val_p->Primitive('sort_key_val')
A:jax.lax.lax.xla.translations[sort_key_val_p]->partial(standard_translate, 'sort_key_val')
A:jax.lax.lax.tie_in_p->Primitive('tie_in')
A:jax.lax.lax.shaped_identity_p->Primitive('shape_id')
A:jax.lax.lax.self.dtype->numpy.dtype(dtype)
A:jax.lax.lax.self.ndim->len(shape)
A:jax.lax.lax.self.size->prod(shape)
A:jax.lax.lax.self._npy_value->numpy.broadcast_to(result, self.shape)
A:jax.lax.lax.stop_gradient_p->Primitive('stop_gradient')
A:jax.lax.lax.dtypes->list(map(onp.dtype, dtypes))
A:jax.lax.lax.lhs_padded->numpy.add(lhs_shape[2:], onp.add(*zip(*pads)))
A:jax.lax.lax.out_space->numpy.sum([unpad_out_space, padding], axis=0).tolist()
A:jax.lax.lax.(lhs_perm, rhs_perm, out_perm)->map(getperm, dimension_numbers, charpairs)
A:jax.lax.lax.obj_arr->numpy.array(obj)
A:jax.lax.lax._zeros->partial(full_like, fill_value=0)
A:jax.lax.lax._zero->partial(full_like, shape=(), fill_value=0)
A:jax.lax.lax._ones->partial(full_like, fill_value=1)
A:jax.lax.lax._one->partial(full_like, shape=(), fill_value=1)
A:jax.lax.lax._twos->partial(full_like, fill_value=2)
A:jax.lax.lax._two->partial(full_like, shape=(), fill_value=2)
A:jax.lax.lax.x_len->len(x)
A:jax.lax.lax.blacklist->set(itertools.chain(*removed_lists))
A:jax.lax.lax.(lhs_spec, rhs_spec, out_spec)->conv_general_permutations(dimension_numbers)
A:jax.lax.lax.spatial->sorted(spatial, key=lambda i: rhs_spec.index(spec[i]))
A:jax.lax.lax.lhs_dilated_shape->_dilate_shape(in_shape, lhs_dilation)
A:jax.lax.lax.rhs_dilated_shape->_dilate_shape(window_dimensions, rhs_dilation)
A:jax.lax.lax.out_dilated_shape->_dilate_shape(out_shape, window_strides)
A:jax.lax.lax.higher_dtype->numpy.promote_types(a_dtype, b_dtype)
A:jax.lax.lax.lst->list(lst)
jax.ConvDimensionNumbers(collections.namedtuple('ConvDimensionNumbers',['lhs_spec','rhs_spec','out_spec']))
jax.GatherDimensionNumbers(collections.namedtuple('GatherDimensionNumbers',['offset_dims','collapsed_slice_dims','start_index_map']))
jax.ScatterDimensionNumbers(collections.namedtuple('ScatterDimensionNumbers',['update_window_dims','inserted_window_dims','scatter_dims_to_operand_dims']))
jax._EyeConstant(self,shape,axes,dtype)
jax._EyeConstant._value(self)
jax._EyeConstant.constant_handler(c,diag_const,canonicalize_types=True)
jax._FilledConstant(self,fill_value,shape)
jax._FilledConstant._value(self)
jax._FilledConstant.constant_handler(c,filled_const,canonicalize_types=True)
jax._IotaConstant(self,dtype,shape,axis)
jax._IotaConstant._value(self)
jax._IotaConstant.constant_handler(c,iota_constant,canonicalize_types=True)
jax._add_transpose(t,x,y)
jax._balanced_eq(x,z,y)
jax._bitcast_convert_type_dtype_rule(operand,new_dtype)
jax._bitcast_convert_type_shape_rule(operand,new_dtype)
jax._bitcast_convert_type_translation_rule(c,operand,new_dtype)
jax._brcast(x,*others)
jax._brcast_to(x,shape)
jax._broadcast_batch_rule(batched_args,batch_dims,sizes)
jax._broadcast_in_dim_batch_rule(batched_args,batch_dims,shape,broadcast_dimensions)
jax._broadcast_in_dim_shape_rule(operand,shape,broadcast_dimensions)
jax._broadcast_in_dim_transpose_rule(t,shape,broadcast_dimensions)
jax._broadcast_shape_rule(operand,sizes)
jax._broadcasting_shape_rule(name,*avals)
jax._canonicalize_precision(precision)
jax._canonicalize_shape(shape)
jax._check_conv_shapes(name,lhs_shape,rhs_shape,window_strides)
jax._check_same_dtypes(name,ignore_fp_precision,*dtypes)
jax._check_shapelike(fun_name,arg_name,obj)
jax._clamp_shape_rule(min,operand,max)
jax._common_reduce_window_shape_rule(operand,window_dimensions,window_strides,padding)
jax._concatenate_batch_rule(batched_args,batch_dims,dimension,operand_shapes)
jax._concatenate_dtype_rule(*operands,**kwargs)
jax._concatenate_shape_rule(*operands,**kwargs)
jax._concatenate_translation_rule(c,*operands,**kwargs)
jax._concatenate_transpose_rule(t,*operands,**kwargs)
jax._conj_transpose_rule(t,x,input_dtype)
jax._conv_general_dilated_batch_rule(batched_args,batch_dims,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,precision,**unused_kwargs)
jax._conv_general_dilated_dtype_rule(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,**unused_kwargs)
jax._conv_general_dilated_shape_rule(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,**unused_kwargs)
jax._conv_general_dilated_translation_rule(c,lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,precision,**unused_kwargs)
jax._conv_general_dilated_transpose_lhs(g,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,lhs_shape,rhs_shape,precision)
jax._conv_general_dilated_transpose_rhs(g,lhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,lhs_shape,rhs_shape,precision)
jax._conv_general_proto(dimension_numbers)
jax._conv_general_vjp_lhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax._conv_general_vjp_rhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax._conv_transpose_padding(k,s,padding)
jax._convert_element_type_dtype_rule(operand,new_dtype,old_dtype)
jax._convert_element_type_shape_rule(operand,new_dtype,old_dtype)
jax._convert_element_type_translation_rule(c,operand,new_dtype,old_dtype)
jax._dilate_shape(shape,dilation)
jax._div_transpose_rule(cotangent,x,y)
jax._dot_batch_rule(batched_args,batch_dims,precision=None)
jax._dot_general_batch_rule(batched_args,batch_dims,dimension_numbers,precision)
jax._dot_general_dtype_rule(lhs,rhs,dimension_numbers,precision)
jax._dot_general_shape_rule(lhs,rhs,dimension_numbers,precision)
jax._dot_general_translation_rule(c,lhs,rhs,dimension_numbers,precision)
jax._dot_general_transpose_lhs(g,y,dimension_numbers,precision,swap_ans=False)
jax._dot_general_transpose_rhs(g,x,dimension_numbers,precision)
jax._dot_shape_rule(lhs,rhs,precision)
jax._dot_translation_rule(c,lhs,rhs,precision)
jax._dot_transpose_lhs(t,rhs,precision)
jax._dot_transpose_rhs(t,lhs,precision)
jax._dynamic_slice_batching_rule(batched_args,batch_dims,slice_sizes,operand_shape)
jax._dynamic_slice_indices(operand,start_indices)
jax._dynamic_slice_jvp_rule(g,operand,start_indices,slice_sizes,operand_shape)
jax._dynamic_slice_shape_rule(operand,start_indices,slice_sizes,operand_shape)
jax._dynamic_slice_translation_rule(c,operand,start_indices,slice_sizes,operand_shape)
jax._dynamic_slice_transpose_rule(t,operand,start_indices,slice_sizes,operand_shape)
jax._dynamic_update_slice_batching_rule(batched_args,batch_dims,update_shape)
jax._dynamic_update_slice_dtype_rule(operand,update,start_indices,update_shape)
jax._dynamic_update_slice_jvp(primals,tangents,update_shape)
jax._dynamic_update_slice_shape_rule(operand,update,start_indices,update_shape)
jax._dynamic_update_slice_translation_rule(c,operand,update,start_indices,update_shape)
jax._dynamic_update_slice_transpose_rule(t,operand,update,start_indices,update_shape)
jax._flip_axes(x,axes)
jax._gather_batching_rule(batched_args,batch_dims,dimension_numbers,slice_sizes,operand_shape)
jax._gather_dimensions_proto(indices_shape,dimension_numbers)
jax._gather_dtype_rule(operand,start_indices,**kwargs)
jax._gather_jvp_rule(g,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax._gather_shape_rule(operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax._gather_translation_rule(c,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax._gather_transpose_rule(t,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax._generic_reduce_window_batch_rule(batched_args,batch_dims,jaxpr,consts,window_dimensions,window_strides,padding)
jax._get_max_identity(dtype)
jax._get_min_identity(dtype)
jax._get_monoid_reducer(monoid_op,x)
jax._get_monoid_window_reducer(monoid_op,x)
jax._identity(x)
jax._is_axis_merge(s1,s2)
jax._is_axis_split(s1,s2)
jax._iter(tracer)
jax._minmax_translation_rule(c,x,y,minmax=None,cmp=None)
jax._ndim(x)
jax._outer(x,y)
jax._pad_batch_rule(batched_args,batch_dims,padding_config)
jax._pad_shape_rule(operand,padding_value,padding_config)
jax._pad_transpose(t,operand,padding_value,padding_config)
jax._pow_jvp_lhs(g,x,y)
jax._pow_jvp_rhs(g,x,y)
jax._precision_config(precision)
jax._reduce_batch_rule(batched_args,batch_dims,computation,jaxpr,consts,dimensions)
jax._reduce_chooser_jvp_rule(g,ans,operand,axes)
jax._reduce_chooser_shape_rule(operand,axes)
jax._reduce_chooser_translation_rule(prim,identity,c,operand,axes)
jax._reduce_logical_shape_rule(operand,axes)
jax._reduce_logical_translation_rule(prim,identity,c,operand,axes)
jax._reduce_prod(operand,axes)
jax._reduce_prod_jvp_rule(tangent,operand,axes)
jax._reduce_prod_shape_rule(operand,axes)
jax._reduce_prod_translation_rule(c,operand,axes)
jax._reduce_shape_rule(operand,init_value,computation,jaxpr,consts,dimensions)
jax._reduce_translation_rule(c,operand,init_value,computation,jaxpr,consts,dimensions)
jax._reduce_window_batch_rule(reduce_window,batched_args,bdims,window_dimensions,window_strides,padding,input_shape=None)
jax._reduce_window_chooser_jvp_rule(prim,g,operand,window_dimensions,window_strides,padding)
jax._reduce_window_chooser_translation_rule(prim,identity,c,operand,window_dimensions,window_strides,padding)
jax._reduce_window_shape_rule(operand,init_value,jaxpr,consts,window_dimensions,window_strides,padding)
jax._reduce_window_translation_rule(c,operand,init_value,jaxpr,consts,window_dimensions,window_strides,padding)
jax._reduction_computation(c,jaxpr,consts,init_value)
jax._reduction_jaxpr(computation,init_value)
jax._reshape_axis_into(src,dst,x)
jax._reshape_axis_out_of(src,size1,x)
jax._reshape_batch_rule(batched_args,batch_dims,new_sizes,dimensions,**unused)
jax._reshape_dtype_rule(operand,new_sizes,dimensions,**unused_kwargs)
jax._reshape_impl(operand,new_sizes,dimensions,old_sizes)
jax._reshape_shape_rule(operand,new_sizes,dimensions,**unused_kwargs)
jax._reshape_translation_rule(c,operand,new_sizes,dimensions,old_sizes)
jax._reshape_transpose_rule(t,new_sizes,dimensions,old_sizes)
jax._rev_batch_rule(batched_args,batch_dims,dimensions)
jax._rev_shape_rule(operand,dimensions)
jax._scatter_add_jvp(primals,tangents,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax._scatter_add_transpose_rule(t,operand,scatter_indices,updates,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax._scatter_batching_rule(scatter_op,batched_args,batch_dims,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax._scatter_dimensions_proto(indices_shape,dimension_numbers)
jax._scatter_dtype_rule(operand,scatter_indices,updates,**kwargs)
jax._scatter_jvp(primals,tangents,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax._scatter_shape_rule(operand,scatter_indices,updates,**kwargs)
jax._scatter_translation_rule(c,operand,scatter_indices,updates,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax._select_and_gather_add(tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_gather_add_jvp(primals,tangents,select_prim,window_dimensions,window_strides,padding)
jax._select_and_gather_add_shape_rule(tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_gather_add_translation(c,tangents,operand,select_prim,window_dimensions,window_strides,padding,max_bits=64)
jax._select_and_gather_add_transpose(t,tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_scatter(operand,select,window_dimensions,window_strides,padding,source,init_value,scatter)
jax._select_and_scatter_add(source,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_scatter_add_batch_rule(batched_args,batch_dims,**kwargs)
jax._select_and_scatter_add_jvp(primals,tangents,select_prim,window_dimensions,window_strides,padding)
jax._select_and_scatter_add_shape_rule(source,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_scatter_add_translation(c,source,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_scatter_add_transpose(t,source,operand,select_prim,window_dimensions,window_strides,padding)
jax._select_and_scatter_shape_rule(operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax._select_and_scatter_translation(c,operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax._select_batch_rule(batched_args,batch_dims,**unused_kwargs)
jax._select_dtype_rule(pred,on_true,on_false)
jax._select_shape_rule(pred,on_true,on_false)
jax._select_transpose_rule(t,pred,on_true,on_false)
jax._slice_batching_rule(batched_args,batch_dims,start_indices,limit_indices,strides,**unused_kwargs)
jax._slice_shape_rule(operand,start_indices,limit_indices,strides,operand_shape)
jax._slice_translation_rule(c,operand,start_indices,limit_indices,strides,operand_shape)
jax._slice_transpose_rule(t,start_indices,limit_indices,strides,operand_shape)
jax._sort_batch_rule(batched_args,batch_dims,dimension)
jax._sort_jvp_rule(g,operand,dimension)
jax._sort_key_val_abstract_eval(keys,values,dimension)
jax._sort_key_val_batch_rule(batched_args,batch_dims,dimension)
jax._sort_key_val_impl(keys,values,dimension)
jax._sort_key_val_jvp(primals,tangents,dimension)
jax._sort_key_val_transpose_rule(t,keys,values,dimension)
jax._stop_gradient_batch_rule(batched_args,batch_dims)
jax._stop_gradient_jvp_rule(primals,tangents)
jax._sub_transpose(t,x,y)
jax._tie_in_batch_rule(batched_args,batch_dims)
jax._tie_in_transpose_rule(t)
jax._transpose_batch_rule(batched_args,batch_dims,permutation)
jax._transpose_shape_rule(operand,permutation)
jax.abs(x)
jax.acos(x)
jax.acosh(x)
jax.add(x,y)
jax.asin(x)
jax.asinh(x)
jax.atan(x)
jax.atan2(x,y)
jax.atanh(x)
jax.batch_matmul(lhs,rhs)
jax.binop(result_dtype,accepted_dtypes,name,translation_rule=None)
jax.binop_dtype_rule(result_dtype,accepted_dtypes,name,*avals,**kwargs)
jax.bitcast_convert_type(operand,new_dtype)
jax.bitwise_and(x,y)
jax.bitwise_not(x)
jax.bitwise_or(x,y)
jax.bitwise_xor(x,y)
jax.broadcast(operand,sizes)
jax.broadcast_in_dim(operand,shape,broadcast_dimensions)
jax.broadcast_shapes(*shapes)
jax.broadcasted_eye(dtype,shape,axes)
jax.broadcasted_iota(dtype,shape,dimension)
jax.ceil(x)
jax.clamp(min,x,max)
jax.collapse(operand,start_dimension,stop_dimension)
jax.complex(x,y)
jax.concatenate(operands,dimension)
jax.conj(x)
jax.conv(lhs,rhs,window_strides,padding,precision=None)
jax.conv_dimension_numbers(lhs_shape,rhs_shape,dimension_numbers)
jax.conv_general_dilated(lhs,rhs,window_strides,padding,lhs_dilation=None,rhs_dilation=None,dimension_numbers=None,feature_group_count=1,precision=None)
jax.conv_general_permutations(dimension_numbers)
jax.conv_general_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax.conv_shape_tuple(lhs_shape,rhs_shape,strides,pads)
jax.conv_transpose(lhs,rhs,strides,padding,dimension_numbers=None,transpose_kernel=False,precision=None)
jax.conv_transpose_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax.conv_with_general_padding(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,precision=None)
jax.convert_element_type(operand,new_dtype)
jax.cos(x)
jax.cosh(x)
jax.digamma(x)
jax.div(x,y)
jax.dot(lhs,rhs,precision=None)
jax.dot_general(lhs,rhs,dimension_numbers,precision=None)
jax.dynamic_index_in_dim(operand,index,axis=0,keepdims=True)
jax.dynamic_slice(operand,start_indices,slice_sizes)
jax.dynamic_slice_in_dim(operand,start_index,slice_size,axis=0)
jax.dynamic_update_index_in_dim(operand,update,index,axis)
jax.dynamic_update_slice(operand,update,start_indices)
jax.dynamic_update_slice_in_dim(operand,update,start_index,axis)
jax.eq(x,y)
jax.erf(x)
jax.erf_inv(x)
jax.erfc(x)
jax.exp(x)
jax.expm1(x)
jax.eye(dtype,size)
jax.floor(x)
jax.full(shape,fill_value,dtype=None)
jax.full_like(x,fill_value,dtype=None,shape=None)
jax.gather(operand,start_indices,dimension_numbers,slice_sizes)
jax.ge(x,y)
jax.gt(x,y)
jax.imag(x)
jax.index_in_dim(operand,index,axis=0,keepdims=True)
jax.index_take(src,idxs,axes)
jax.iota(dtype,size)
jax.is_finite(x)
jax.lax._abstractify(x)
jax.lax._broadcasting_select(c,which,x,y)
jax.lax._const(example,val)
jax.lax._eq_meet(a,b)
jax.lax._reduce_and(operand,axes)
jax.lax._reduce_max(operand,axes)
jax.lax._reduce_min(operand,axes)
jax.lax._reduce_or(operand,axes)
jax.lax._reduce_sum(operand,axes)
jax.lax._reduce_sum_shape_rule(operand,axes,input_shape)
jax.lax._reduce_sum_translation_rule(c,operand,axes,input_shape)
jax.lax._reduce_sum_transpose_rule(cotangent,input_shape,axes)
jax.lax._reduce_window_max(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_min(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_prod(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_sum(operand,window_dimensions,window_strides,padding)
jax.lax._reduce_window_sum_shape_rule(operand,window_dimensions,window_strides,padding,input_shape)
jax.lax._reduce_window_sum_translation_rule(c,operand,window_dimensions,window_strides,padding,input_shape)
jax.lax._reduce_window_sum_transpose_rule(cotangent,window_dimensions,window_strides,padding,input_shape)
jax.lax._safe_mul(x,y)
jax.lax._safe_mul_translation_rule(c,x,y)
jax.lax.lax.ConvDimensionNumbers(collections.namedtuple('ConvDimensionNumbers',['lhs_spec','rhs_spec','out_spec']))
jax.lax.lax.GatherDimensionNumbers(collections.namedtuple('GatherDimensionNumbers',['offset_dims','collapsed_slice_dims','start_index_map']))
jax.lax.lax.ScatterDimensionNumbers(collections.namedtuple('ScatterDimensionNumbers',['update_window_dims','inserted_window_dims','scatter_dims_to_operand_dims']))
jax.lax.lax._EyeConstant(self,shape,axes,dtype)
jax.lax.lax._EyeConstant.__init__(self,shape,axes,dtype)
jax.lax.lax._EyeConstant._value(self)
jax.lax.lax._EyeConstant.constant_handler(c,diag_const,canonicalize_types=True)
jax.lax.lax._FilledConstant(self,fill_value,shape)
jax.lax.lax._FilledConstant.__init__(self,fill_value,shape)
jax.lax.lax._FilledConstant._value(self)
jax.lax.lax._FilledConstant.constant_handler(c,filled_const,canonicalize_types=True)
jax.lax.lax._IotaConstant(self,dtype,shape,axis)
jax.lax.lax._IotaConstant.__init__(self,dtype,shape,axis)
jax.lax.lax._IotaConstant._value(self)
jax.lax.lax._IotaConstant.constant_handler(c,iota_constant,canonicalize_types=True)
jax.lax.lax._abstractify(x)
jax.lax.lax._add_transpose(t,x,y)
jax.lax.lax._balanced_eq(x,z,y)
jax.lax.lax._bitcast_convert_type_dtype_rule(operand,new_dtype)
jax.lax.lax._bitcast_convert_type_shape_rule(operand,new_dtype)
jax.lax.lax._bitcast_convert_type_translation_rule(c,operand,new_dtype)
jax.lax.lax._brcast(x,*others)
jax.lax.lax._brcast_to(x,shape)
jax.lax.lax._broadcast_batch_rule(batched_args,batch_dims,sizes)
jax.lax.lax._broadcast_in_dim_batch_rule(batched_args,batch_dims,shape,broadcast_dimensions)
jax.lax.lax._broadcast_in_dim_shape_rule(operand,shape,broadcast_dimensions)
jax.lax.lax._broadcast_in_dim_transpose_rule(t,shape,broadcast_dimensions)
jax.lax.lax._broadcast_shape_rule(operand,sizes)
jax.lax.lax._broadcasting_select(c,which,x,y)
jax.lax.lax._broadcasting_shape_rule(name,*avals)
jax.lax.lax._canonicalize_precision(precision)
jax.lax.lax._canonicalize_shape(shape)
jax.lax.lax._check_conv_shapes(name,lhs_shape,rhs_shape,window_strides)
jax.lax.lax._check_same_dtypes(name,ignore_fp_precision,*dtypes)
jax.lax.lax._check_shapelike(fun_name,arg_name,obj)
jax.lax.lax._clamp_shape_rule(min,operand,max)
jax.lax.lax._common_reduce_window_shape_rule(operand,window_dimensions,window_strides,padding)
jax.lax.lax._concatenate_batch_rule(batched_args,batch_dims,dimension,operand_shapes)
jax.lax.lax._concatenate_dtype_rule(*operands,**kwargs)
jax.lax.lax._concatenate_shape_rule(*operands,**kwargs)
jax.lax.lax._concatenate_translation_rule(c,*operands,**kwargs)
jax.lax.lax._concatenate_transpose_rule(t,*operands,**kwargs)
jax.lax.lax._conj_transpose_rule(t,x,input_dtype)
jax.lax.lax._const(example,val)
jax.lax.lax._conv_general_dilated_batch_rule(batched_args,batch_dims,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,precision,**unused_kwargs)
jax.lax.lax._conv_general_dilated_dtype_rule(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,**unused_kwargs)
jax.lax.lax._conv_general_dilated_shape_rule(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,**unused_kwargs)
jax.lax.lax._conv_general_dilated_translation_rule(c,lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,precision,**unused_kwargs)
jax.lax.lax._conv_general_dilated_transpose_lhs(g,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,lhs_shape,rhs_shape,precision)
jax.lax.lax._conv_general_dilated_transpose_rhs(g,lhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,lhs_shape,rhs_shape,precision)
jax.lax.lax._conv_general_proto(dimension_numbers)
jax.lax.lax._conv_general_vjp_lhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax.lax.lax._conv_general_vjp_rhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax.lax.lax._conv_transpose_padding(k,s,padding)
jax.lax.lax._convert_element_type_dtype_rule(operand,new_dtype,old_dtype)
jax.lax.lax._convert_element_type_shape_rule(operand,new_dtype,old_dtype)
jax.lax.lax._convert_element_type_translation_rule(c,operand,new_dtype,old_dtype)
jax.lax.lax._dilate_shape(shape,dilation)
jax.lax.lax._div_transpose_rule(cotangent,x,y)
jax.lax.lax._dot_batch_rule(batched_args,batch_dims,precision=None)
jax.lax.lax._dot_general_batch_rule(batched_args,batch_dims,dimension_numbers,precision)
jax.lax.lax._dot_general_dtype_rule(lhs,rhs,dimension_numbers,precision)
jax.lax.lax._dot_general_shape_rule(lhs,rhs,dimension_numbers,precision)
jax.lax.lax._dot_general_translation_rule(c,lhs,rhs,dimension_numbers,precision)
jax.lax.lax._dot_general_transpose_lhs(g,y,dimension_numbers,precision,swap_ans=False)
jax.lax.lax._dot_general_transpose_rhs(g,x,dimension_numbers,precision)
jax.lax.lax._dot_shape_rule(lhs,rhs,precision)
jax.lax.lax._dot_translation_rule(c,lhs,rhs,precision)
jax.lax.lax._dot_transpose_lhs(t,rhs,precision)
jax.lax.lax._dot_transpose_rhs(t,lhs,precision)
jax.lax.lax._dynamic_slice_batching_rule(batched_args,batch_dims,slice_sizes,operand_shape)
jax.lax.lax._dynamic_slice_indices(operand,start_indices)
jax.lax.lax._dynamic_slice_jvp_rule(g,operand,start_indices,slice_sizes,operand_shape)
jax.lax.lax._dynamic_slice_shape_rule(operand,start_indices,slice_sizes,operand_shape)
jax.lax.lax._dynamic_slice_translation_rule(c,operand,start_indices,slice_sizes,operand_shape)
jax.lax.lax._dynamic_slice_transpose_rule(t,operand,start_indices,slice_sizes,operand_shape)
jax.lax.lax._dynamic_update_slice_batching_rule(batched_args,batch_dims,update_shape)
jax.lax.lax._dynamic_update_slice_dtype_rule(operand,update,start_indices,update_shape)
jax.lax.lax._dynamic_update_slice_jvp(primals,tangents,update_shape)
jax.lax.lax._dynamic_update_slice_shape_rule(operand,update,start_indices,update_shape)
jax.lax.lax._dynamic_update_slice_translation_rule(c,operand,update,start_indices,update_shape)
jax.lax.lax._dynamic_update_slice_transpose_rule(t,operand,update,start_indices,update_shape)
jax.lax.lax._eq_meet(a,b)
jax.lax.lax._flip_axes(x,axes)
jax.lax.lax._gather_batching_rule(batched_args,batch_dims,dimension_numbers,slice_sizes,operand_shape)
jax.lax.lax._gather_dimensions_proto(indices_shape,dimension_numbers)
jax.lax.lax._gather_dtype_rule(operand,start_indices,**kwargs)
jax.lax.lax._gather_jvp_rule(g,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax.lax._gather_shape_rule(operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax.lax._gather_translation_rule(c,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax.lax._gather_transpose_rule(t,operand,start_indices,dimension_numbers,slice_sizes,operand_shape)
jax.lax.lax._generic_reduce_window_batch_rule(batched_args,batch_dims,jaxpr,consts,window_dimensions,window_strides,padding)
jax.lax.lax._get_max_identity(dtype)
jax.lax.lax._get_min_identity(dtype)
jax.lax.lax._get_monoid_reducer(monoid_op,x)
jax.lax.lax._get_monoid_window_reducer(monoid_op,x)
jax.lax.lax._identity(x)
jax.lax.lax._is_axis_merge(s1,s2)
jax.lax.lax._is_axis_split(s1,s2)
jax.lax.lax._iter(tracer)
jax.lax.lax._minmax_translation_rule(c,x,y,minmax=None,cmp=None)
jax.lax.lax._ndim(x)
jax.lax.lax._outer(x,y)
jax.lax.lax._pad_batch_rule(batched_args,batch_dims,padding_config)
jax.lax.lax._pad_shape_rule(operand,padding_value,padding_config)
jax.lax.lax._pad_transpose(t,operand,padding_value,padding_config)
jax.lax.lax._pow_jvp_lhs(g,x,y)
jax.lax.lax._pow_jvp_rhs(g,x,y)
jax.lax.lax._precision_config(precision)
jax.lax.lax._reduce_and(operand,axes)
jax.lax.lax._reduce_batch_rule(batched_args,batch_dims,computation,jaxpr,consts,dimensions)
jax.lax.lax._reduce_chooser_jvp_rule(g,ans,operand,axes)
jax.lax.lax._reduce_chooser_shape_rule(operand,axes)
jax.lax.lax._reduce_chooser_translation_rule(prim,identity,c,operand,axes)
jax.lax.lax._reduce_logical_shape_rule(operand,axes)
jax.lax.lax._reduce_logical_translation_rule(prim,identity,c,operand,axes)
jax.lax.lax._reduce_max(operand,axes)
jax.lax.lax._reduce_min(operand,axes)
jax.lax.lax._reduce_or(operand,axes)
jax.lax.lax._reduce_prod(operand,axes)
jax.lax.lax._reduce_prod_jvp_rule(tangent,operand,axes)
jax.lax.lax._reduce_prod_shape_rule(operand,axes)
jax.lax.lax._reduce_prod_translation_rule(c,operand,axes)
jax.lax.lax._reduce_shape_rule(operand,init_value,computation,jaxpr,consts,dimensions)
jax.lax.lax._reduce_sum(operand,axes)
jax.lax.lax._reduce_sum_shape_rule(operand,axes,input_shape)
jax.lax.lax._reduce_sum_translation_rule(c,operand,axes,input_shape)
jax.lax.lax._reduce_sum_transpose_rule(cotangent,input_shape,axes)
jax.lax.lax._reduce_translation_rule(c,operand,init_value,computation,jaxpr,consts,dimensions)
jax.lax.lax._reduce_window_batch_rule(reduce_window,batched_args,bdims,window_dimensions,window_strides,padding,input_shape=None)
jax.lax.lax._reduce_window_chooser_jvp_rule(prim,g,operand,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_chooser_translation_rule(prim,identity,c,operand,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_max(operand,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_min(operand,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_prod(operand,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_shape_rule(operand,init_value,jaxpr,consts,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_sum(operand,window_dimensions,window_strides,padding)
jax.lax.lax._reduce_window_sum_shape_rule(operand,window_dimensions,window_strides,padding,input_shape)
jax.lax.lax._reduce_window_sum_translation_rule(c,operand,window_dimensions,window_strides,padding,input_shape)
jax.lax.lax._reduce_window_sum_transpose_rule(cotangent,window_dimensions,window_strides,padding,input_shape)
jax.lax.lax._reduce_window_translation_rule(c,operand,init_value,jaxpr,consts,window_dimensions,window_strides,padding)
jax.lax.lax._reduction_computation(c,jaxpr,consts,init_value)
jax.lax.lax._reduction_jaxpr(computation,init_value)
jax.lax.lax._reshape_axis_into(src,dst,x)
jax.lax.lax._reshape_axis_out_of(src,size1,x)
jax.lax.lax._reshape_batch_rule(batched_args,batch_dims,new_sizes,dimensions,**unused)
jax.lax.lax._reshape_dtype_rule(operand,new_sizes,dimensions,**unused_kwargs)
jax.lax.lax._reshape_impl(operand,new_sizes,dimensions,old_sizes)
jax.lax.lax._reshape_shape_rule(operand,new_sizes,dimensions,**unused_kwargs)
jax.lax.lax._reshape_translation_rule(c,operand,new_sizes,dimensions,old_sizes)
jax.lax.lax._reshape_transpose_rule(t,new_sizes,dimensions,old_sizes)
jax.lax.lax._rev_batch_rule(batched_args,batch_dims,dimensions)
jax.lax.lax._rev_shape_rule(operand,dimensions)
jax.lax.lax._safe_mul(x,y)
jax.lax.lax._safe_mul_translation_rule(c,x,y)
jax.lax.lax._scatter_add_jvp(primals,tangents,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax.lax._scatter_add_transpose_rule(t,operand,scatter_indices,updates,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax.lax._scatter_batching_rule(scatter_op,batched_args,batch_dims,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax.lax._scatter_dimensions_proto(indices_shape,dimension_numbers)
jax.lax.lax._scatter_dtype_rule(operand,scatter_indices,updates,**kwargs)
jax.lax.lax._scatter_jvp(primals,tangents,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax.lax._scatter_shape_rule(operand,scatter_indices,updates,**kwargs)
jax.lax.lax._scatter_translation_rule(c,operand,scatter_indices,updates,update_jaxpr,update_consts,dimension_numbers,updates_shape)
jax.lax.lax._select_and_gather_add(tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_gather_add_jvp(primals,tangents,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_gather_add_shape_rule(tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_gather_add_translation(c,tangents,operand,select_prim,window_dimensions,window_strides,padding,max_bits=64)
jax.lax.lax._select_and_gather_add_transpose(t,tangents,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter(operand,select,window_dimensions,window_strides,padding,source,init_value,scatter)
jax.lax.lax._select_and_scatter_add(source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter_add_batch_rule(batched_args,batch_dims,**kwargs)
jax.lax.lax._select_and_scatter_add_jvp(primals,tangents,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter_add_shape_rule(source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter_add_translation(c,source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter_add_transpose(t,source,operand,select_prim,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter_shape_rule(operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax.lax.lax._select_and_scatter_translation(c,operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax.lax.lax._select_batch_rule(batched_args,batch_dims,**unused_kwargs)
jax.lax.lax._select_dtype_rule(pred,on_true,on_false)
jax.lax.lax._select_shape_rule(pred,on_true,on_false)
jax.lax.lax._select_transpose_rule(t,pred,on_true,on_false)
jax.lax.lax._slice_batching_rule(batched_args,batch_dims,start_indices,limit_indices,strides,**unused_kwargs)
jax.lax.lax._slice_shape_rule(operand,start_indices,limit_indices,strides,operand_shape)
jax.lax.lax._slice_translation_rule(c,operand,start_indices,limit_indices,strides,operand_shape)
jax.lax.lax._slice_transpose_rule(t,start_indices,limit_indices,strides,operand_shape)
jax.lax.lax._sort_batch_rule(batched_args,batch_dims,dimension)
jax.lax.lax._sort_jvp_rule(g,operand,dimension)
jax.lax.lax._sort_key_val_abstract_eval(keys,values,dimension)
jax.lax.lax._sort_key_val_batch_rule(batched_args,batch_dims,dimension)
jax.lax.lax._sort_key_val_impl(keys,values,dimension)
jax.lax.lax._sort_key_val_jvp(primals,tangents,dimension)
jax.lax.lax._sort_key_val_transpose_rule(t,keys,values,dimension)
jax.lax.lax._stop_gradient_batch_rule(batched_args,batch_dims)
jax.lax.lax._stop_gradient_jvp_rule(primals,tangents)
jax.lax.lax._sub_transpose(t,x,y)
jax.lax.lax._tie_in_batch_rule(batched_args,batch_dims)
jax.lax.lax._tie_in_transpose_rule(t)
jax.lax.lax._transpose_batch_rule(batched_args,batch_dims,permutation)
jax.lax.lax._transpose_shape_rule(operand,permutation)
jax.lax.lax.abs(x)
jax.lax.lax.acos(x)
jax.lax.lax.acosh(x)
jax.lax.lax.add(x,y)
jax.lax.lax.asin(x)
jax.lax.lax.asinh(x)
jax.lax.lax.atan(x)
jax.lax.lax.atan2(x,y)
jax.lax.lax.atanh(x)
jax.lax.lax.batch_matmul(lhs,rhs)
jax.lax.lax.binop(result_dtype,accepted_dtypes,name,translation_rule=None)
jax.lax.lax.binop_dtype_rule(result_dtype,accepted_dtypes,name,*avals,**kwargs)
jax.lax.lax.bitcast_convert_type(operand,new_dtype)
jax.lax.lax.bitwise_and(x,y)
jax.lax.lax.bitwise_not(x)
jax.lax.lax.bitwise_or(x,y)
jax.lax.lax.bitwise_xor(x,y)
jax.lax.lax.broadcast(operand,sizes)
jax.lax.lax.broadcast_in_dim(operand,shape,broadcast_dimensions)
jax.lax.lax.broadcast_shapes(*shapes)
jax.lax.lax.broadcasted_eye(dtype,shape,axes)
jax.lax.lax.broadcasted_iota(dtype,shape,dimension)
jax.lax.lax.ceil(x)
jax.lax.lax.clamp(min,x,max)
jax.lax.lax.collapse(operand,start_dimension,stop_dimension)
jax.lax.lax.complex(x,y)
jax.lax.lax.concatenate(operands,dimension)
jax.lax.lax.conj(x)
jax.lax.lax.conv(lhs,rhs,window_strides,padding,precision=None)
jax.lax.lax.conv_dimension_numbers(lhs_shape,rhs_shape,dimension_numbers)
jax.lax.lax.conv_general_dilated(lhs,rhs,window_strides,padding,lhs_dilation=None,rhs_dilation=None,dimension_numbers=None,feature_group_count=1,precision=None)
jax.lax.lax.conv_general_permutations(dimension_numbers)
jax.lax.lax.conv_general_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax.lax.lax.conv_shape_tuple(lhs_shape,rhs_shape,strides,pads)
jax.lax.lax.conv_transpose(lhs,rhs,strides,padding,dimension_numbers=None,transpose_kernel=False,precision=None)
jax.lax.lax.conv_transpose_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax.lax.lax.conv_with_general_padding(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,precision=None)
jax.lax.lax.convert_element_type(operand,new_dtype)
jax.lax.lax.cos(x)
jax.lax.lax.cosh(x)
jax.lax.lax.digamma(x)
jax.lax.lax.div(x,y)
jax.lax.lax.dot(lhs,rhs,precision=None)
jax.lax.lax.dot_general(lhs,rhs,dimension_numbers,precision=None)
jax.lax.lax.dynamic_index_in_dim(operand,index,axis=0,keepdims=True)
jax.lax.lax.dynamic_slice(operand,start_indices,slice_sizes)
jax.lax.lax.dynamic_slice_in_dim(operand,start_index,slice_size,axis=0)
jax.lax.lax.dynamic_update_index_in_dim(operand,update,index,axis)
jax.lax.lax.dynamic_update_slice(operand,update,start_indices)
jax.lax.lax.dynamic_update_slice_in_dim(operand,update,start_index,axis)
jax.lax.lax.eq(x,y)
jax.lax.lax.erf(x)
jax.lax.lax.erf_inv(x)
jax.lax.lax.erfc(x)
jax.lax.lax.exp(x)
jax.lax.lax.expm1(x)
jax.lax.lax.eye(dtype,size)
jax.lax.lax.floor(x)
jax.lax.lax.full(shape,fill_value,dtype=None)
jax.lax.lax.full_like(x,fill_value,dtype=None,shape=None)
jax.lax.lax.gather(operand,start_indices,dimension_numbers,slice_sizes)
jax.lax.lax.ge(x,y)
jax.lax.lax.gt(x,y)
jax.lax.lax.imag(x)
jax.lax.lax.index_in_dim(operand,index,axis=0,keepdims=True)
jax.lax.lax.index_take(src,idxs,axes)
jax.lax.lax.iota(dtype,size)
jax.lax.lax.is_finite(x)
jax.lax.lax.le(x,y)
jax.lax.lax.lgamma(x)
jax.lax.lax.log(x)
jax.lax.lax.log1p(x)
jax.lax.lax.lt(x,y)
jax.lax.lax.max(x,y)
jax.lax.lax.min(x,y)
jax.lax.lax.mul(x,y)
jax.lax.lax.ne(x,y)
jax.lax.lax.neg(x)
jax.lax.lax.pad(operand,padding_value,padding_config)
jax.lax.lax.padtype_to_pads(in_shape,window_shape,window_strides,padding)
jax.lax.lax.pow(x,y)
jax.lax.lax.ranges_like(*xs)
jax.lax.lax.real(x)
jax.lax.lax.reciprocal(x)
jax.lax.lax.reduce(operand,init_value,computation,dimensions)
jax.lax.lax.reduce_window(operand,init_value,computation,window_dimensions,window_strides,padding)
jax.lax.lax.reduce_window_shape_tuple(operand_shape,window_dimensions,window_strides,padding)
jax.lax.lax.rem(x,y)
jax.lax.lax.remaining(original,*removed_lists)
jax.lax.lax.reshape(operand,new_sizes,dimensions=None)
jax.lax.lax.rev(operand,dimensions)
jax.lax.lax.round(x)
jax.lax.lax.rsqrt(x)
jax.lax.lax.scatter(operand,scatter_indices,updates,dimension_numbers)
jax.lax.lax.scatter_add(operand,scatter_indices,updates,dimension_numbers)
jax.lax.lax.scatter_max(operand,scatter_indices,updates,dimension_numbers)
jax.lax.lax.scatter_min(operand,scatter_indices,updates,dimension_numbers)
jax.lax.lax.select(pred,on_true,on_false)
jax.lax.lax.shaped_identity(x)
jax.lax.lax.shift_left(x,y)
jax.lax.lax.shift_right_arithmetic(x,y)
jax.lax.lax.shift_right_logical(x,y)
jax.lax.lax.sign(x)
jax.lax.lax.sin(x)
jax.lax.lax.sinh(x)
jax.lax.lax.slice(operand,start_indices,limit_indices,strides=None)
jax.lax.lax.slice_in_dim(operand,start_index,limit_index,stride=1,axis=0)
jax.lax.lax.sort(operand,dimension=-1)
jax.lax.lax.sort_key_val(keys,values,dimension=-1)
jax.lax.lax.sqrt(x)
jax.lax.lax.square(x)
jax.lax.lax.standard_abstract_eval(shape_rule,dtype_rule,*args,**kwargs)
jax.lax.lax.standard_primitive(shape_rule,dtype_rule,name,translation_rule=None)
jax.lax.lax.standard_translate(name,c,*args,**kwargs)
jax.lax.lax.stop_gradient(x)
jax.lax.lax.sub(x,y)
jax.lax.lax.subvals(lst,replace)
jax.lax.lax.tan(x)
jax.lax.lax.tanh(x)
jax.lax.lax.tie_in(x,y)
jax.lax.lax.transpose(operand,permutation)
jax.lax.lax.unop(result_dtype,accepted_dtypes,name)
jax.lax.lax.unop_dtype_rule(result_dtype,accepted_dtypes,name,aval,**kwargs)
jax.lax.lax.zeros_like_array(x)
jax.le(x,y)
jax.lgamma(x)
jax.log(x)
jax.log1p(x)
jax.lt(x,y)
jax.max(x,y)
jax.min(x,y)
jax.mul(x,y)
jax.ne(x,y)
jax.neg(x)
jax.pad(operand,padding_value,padding_config)
jax.padtype_to_pads(in_shape,window_shape,window_strides,padding)
jax.pow(x,y)
jax.ranges_like(*xs)
jax.real(x)
jax.reciprocal(x)
jax.reduce(operand,init_value,computation,dimensions)
jax.reduce_window(operand,init_value,computation,window_dimensions,window_strides,padding)
jax.reduce_window_shape_tuple(operand_shape,window_dimensions,window_strides,padding)
jax.rem(x,y)
jax.remaining(original,*removed_lists)
jax.reshape(operand,new_sizes,dimensions=None)
jax.rev(operand,dimensions)
jax.round(x)
jax.rsqrt(x)
jax.scatter(operand,scatter_indices,updates,dimension_numbers)
jax.scatter_add(operand,scatter_indices,updates,dimension_numbers)
jax.scatter_max(operand,scatter_indices,updates,dimension_numbers)
jax.scatter_min(operand,scatter_indices,updates,dimension_numbers)
jax.select(pred,on_true,on_false)
jax.shaped_identity(x)
jax.shift_left(x,y)
jax.shift_right_arithmetic(x,y)
jax.shift_right_logical(x,y)
jax.sign(x)
jax.sin(x)
jax.sinh(x)
jax.slice(operand,start_indices,limit_indices,strides=None)
jax.slice_in_dim(operand,start_index,limit_index,stride=1,axis=0)
jax.sort(operand,dimension=-1)
jax.sort_key_val(keys,values,dimension=-1)
jax.sqrt(x)
jax.square(x)
jax.standard_abstract_eval(shape_rule,dtype_rule,*args,**kwargs)
jax.standard_primitive(shape_rule,dtype_rule,name,translation_rule=None)
jax.standard_translate(name,c,*args,**kwargs)
jax.stop_gradient(x)
jax.sub(x,y)
jax.subvals(lst,replace)
jax.tan(x)
jax.tanh(x)
jax.tie_in(x,y)
jax.transpose(operand,permutation)
jax.unop(result_dtype,accepted_dtypes,name)
jax.unop_dtype_rule(result_dtype,accepted_dtypes,name,aval,**kwargs)
jax.zeros_like_array(x)

