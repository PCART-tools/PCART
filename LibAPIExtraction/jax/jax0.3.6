
----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/ad_checkpoint.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/stages.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/api_util.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/custom_transpose.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/flatten_util.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/core.py----------------------------------------
A:jax.core.self.constvars->list(constvars)
A:jax.core.self.invars->list(invars)
A:jax.core.self.outvars->list(outvars)
A:jax.core.self.eqns->list(eqns)
A:jax.core.doc->pp_jaxpr(self, JaxprPpContext(), JaxprPpSettings(source_info=source_info, print_shapes=print_shapes, custom_pp_eqn_rules=custom_pp_eqn_rules, name_stack=name_stack))
A:jax.core.self.consts->list(consts)
A:jax.core.settings->JaxprPpSettings(source_info=source_info, print_shapes=print_shapes, name_stack=name_stack, custom_pp_eqn_rules=custom_pp_eqn_rules)
A:jax.core.self.aval->raise_to_shaped(aval)
A:jax.core.all_vars->itertools.chain.from_iterable((_jaxpr_vars(j) for j in jaxprs))
A:jax.core.counter->itertools.count(start=start)
A:jax.core.self.hash->hash((val.item(), val.dtype))
A:jax.core.out->ans._trace.main.with_cur_sublevel().process_primitive(self, map(trace.full_raise, args), params)
A:jax.core.self.abstract_eval->_effect_free_abstract_eval(abstract_eval)
A:jax.core.(subfuns, bind_params)->eqn.primitive.get_bind_params(eqn.params)
A:jax.core.ans->max(tracers, key=lambda x: x._trace.level)
A:jax.core.dbg->getattr(tracer._trace.main, 'debug_info', None)
A:jax.core.line_info->getattr(tracer, '_line_info', None)
A:jax.core.attr->getattr(self.aval, name)
A:jax.core.t->ref(sublevel)
A:jax.core.base->jax._src.pretty_printer.group(pp.nest(2, pp.concat([base, pp.text(' with'), pp.brk(), pp.join(pp.brk(), [pp.text('{} = '.format(name)) + pp_payload for (name, pp_payload) in contents])])))
A:jax.core.aval_property->namedtuple('aval_property', ['fget'])
A:jax.core.aval_method->namedtuple('aval_method', ['fun'])
A:jax.core.eval_trace->MainTrace(0, EvalTrace)
A:jax.core.stack_str->map('  {}\n'.format, self.stack[::-1])
A:jax.core.new->self.__new__(TraceState)
A:jax.core.AxisEnvFrame->namedtuple('AxisEnvFrame', ['name', 'size', 'main_trace'])
A:jax.core.no_axis_name->object()
A:jax.core.self.trace_stack->TraceStack()
A:jax.core.new.trace_stack->self.trace_stack.copy()
A:jax.core.copy->MainTrace(dynamic.level, dynamic.trace_type, **dynamic.payload)
A:jax.core.self.trace_state->TraceState()
A:jax.core.thread_local_state->ThreadLocalState()
A:jax.core.traces->list(filter(lambda x: isinstance(x, Trace), gc.get_referrers(x)))
A:jax.core.tracers->map(top_trace.full_raise, args)
A:jax.core.msgs->'\n\n'.join((f'{tracer}{tracer._origin_msg()}' for tracer in tracers))
A:jax.core.level->stack.next_level()
A:jax.core.main->MainTrace(0, trace_type)
A:jax.core.leaked_tracers->maybe_find_leaked_tracers(t())
A:jax.core.sublevel->Sublevel(len(thread_local_state.trace_state.substack))
A:jax.core.top_tracer->max((x for x in xs if isinstance(x, Tracer)), default=None, key=attrgetter('_trace.level'))
A:jax.core.bot->Bot()
A:jax.core.abstract_unit->AbstractUnit()
A:jax.core.handler->_SPECIAL_DIMENSION_HANDLERS.get(type(v))
A:jax.core.unitvar->UnitVar()
A:jax.core.fname->getattr(fun, '__name__', fun)
A:jax.core.self.dtype->numpy.dtype(dtype)
A:jax.core._bool_nonzero->partialmethod(_forward_to_value, bool)
A:jax.core._float->concretization_function_error(float, True)
A:jax.core._int->partialmethod(_forward_to_value, int)
A:jax.core._complex->concretization_function_error(complex, True)
A:jax.core._hex->partialmethod(_forward_to_value, hex)
A:jax.core._oct->partialmethod(_forward_to_value, oct)
A:jax.core.ndim->property(lambda self: len(self.shape))
A:jax.core.size->property(lambda self: prod(self.shape))
A:jax.core.dtype->_short_dtype_name(a.dtype)
A:jax.core.self.shape->canonicalize_shape(shape)
A:jax.core.named_shape->dict(aval.named_shape)
A:jax.core.shapestr->','.join(map(str, self.shape))
A:jax.core.named_shapestr->','.join((f'{k}:{v}' for (k, v) in self.named_shape.items()))
A:jax.core.aval_type->type(aval)
A:jax.core.weak_type->getattr(aval, 'weak_type', False)
A:jax.core.sz1->int(np.prod(s1))
A:jax.core.sz2->int(np.prod(s2))
A:jax.core._dimension_handler_int->DimensionHandler()
A:jax.core.special_handlers->set()
A:jax.core.(handler, ds)->_dim_handler_and_canonical(d)
A:jax.core.self.__positional->canonicalize_shape(args)
A:jax.core.self.__named->dict(kwargs)
A:jax.core.idx->operator.index(idx)
A:jax.core.named->frozenset(self.__named.items())
A:jax.core.new_params->dict(params)
A:jax.core.jaxpr->dict(params).pop('call_jaxpr')
A:jax.core.subfun->jax.linear_util.hashable_partial(lu.wrap_init(eval_jaxpr), jaxpr, ())
A:jax.core.top_trace->find_top_trace(args)
A:jax.core.(fun_, env_trace_todo)->process_env_traces_call(fun, primitive, top_trace and top_trace.level, tuple(params.items()))
A:jax.core.fun_->jax.linear_util.annotate(fun_, fun.in_type)
A:jax.core.outs->map(trace.full_raise, outs)
A:jax.core.params->subst_axis_names(eqn.primitive, eqn.params, subst)
A:jax.core.trace->max(tracers, key=lambda x: x._trace.level)._trace.main.with_cur_sublevel()
A:jax.core.(outs, cur_todo)->max(tracers, key=lambda x: x._trace.level)._trace.main.with_cur_sublevel().post_process_call(primitive, outs, params)
A:jax.core.todos_list->list(todos)
A:jax.core.axes->dict(params).pop('out_axes')
A:jax.core.new_params['out_axes_thunk']->HashableFunction(lambda : axes, closure=axes)
A:jax.core.out_axes->t(out_axes)
A:jax.core.(_, out_axes_transforms)->todo_and_xforms()
A:jax.core.(fun, todo_and_xforms)->process_env_traces_map(fun, primitive, top_trace and top_trace.level, tuple(params.items()))
A:jax.core.(env_trace_todo, _)->todo_and_xforms()
A:jax.core.(outs, (cur_todo, cur_xform))->primitive.post_process(trace, outs, params)
A:jax.core.(handler, _)->aval_mapping_handlers.get(type(aval), (None, None))
A:jax.core.(_, handler)->aval_mapping_handlers.get(type(aval), (None, None))
A:jax.core.frame->AxisEnvFrame(axis_name, size, tag)
A:jax.core.self.id->id(obj)
A:jax.core.self.axis_names->set()
A:jax.core.subst->NameGatheringSubst()
A:jax.core.new_params[name]->subst_axis_names_jaxpr(jaxpr, shadowed_subst)
A:jax.core.names->tuple(it.chain.from_iterable((subst(name) for name in v.aval.named_shape)))
A:jax.core.new_v->Var(v.count, v.suffix, v.aval.update(named_shape=named_shape))
A:jax.core.new_jaxpr->Jaxpr(constvars, invars, outvars, eqns, jaxpr.effects)
A:jax.core.axis_main->max((axis_frame(a).main_trace for a in used_axis_names(self, params)), default=None, key=lambda t: getattr(t, 'level', -1))
A:jax.core.ctx->JaxprPpContext()
A:jax.core.pp_settings->JaxprPpSettings()
A:jax.core.(ctx, pp_settings)->ctx_factory()
A:jax.core.jaxpr_str->str(pp_jaxpr_eqn_range(jaxpr, 0, 20, ctx, pp_settings))
A:jax.core.msg->'\n\n'.join([msg, 'in equation:', str(pp.nest(2, pp_eqn(eqn, ctx, settings))), f'from source: {src}'])
A:jax.core.(ctx, _)->ctx_factory()
A:jax.core.in_avals->map(read, eqn.invars)
A:jax.core.(out_avals, effects)->prim.abstract_eval(*in_avals, **params)
A:jax.core.(ctx, settings)->ctx_factory()
A:jax.core.src->jax._src.source_info_util.summarize(eqn.source_info)
A:jax.core.self.var_ids->collections.defaultdict(it.count().__next__, {unitvar: -1})
A:jax.core.pp_v->jax._src.pretty_printer.text(str(v))
A:jax.core.lhs->pp_vars(eqn.outvars, context, print_shapes=settings.print_shapes)
A:jax.core.rule->pp_eqn_rules.get(eqn.primitive)
A:jax.core.rhs->rule(eqn, context, settings)
A:jax.core.kvs->' '.join((f'{k}={v}' for (k, v) in params.items() if _compact_eqn_should_include(k, v)))
A:jax.core.constvars->pp_vars(jaxpr.constvars, context, print_shapes=settings.print_shapes)
A:jax.core.invars->pp_vars(jaxpr.invars, context, print_shapes=settings.print_shapes)
A:jax.core.eqns->eqns_fn()
A:jax.core.outvars->jax._src.pretty_printer.concat([pp.text('('), pp_vars(jaxpr.outvars, context, separator=','), pp.text(')' if len(jaxpr.outvars) != 1 else ',)')])
A:jax.core.lo->max(lo, 0)
A:jax.core.hi->max(lo, min(hi, len(jaxpr.eqns)))
jax.core.AbstractBInt(self,bound)
jax.core.AbstractBInt.__eq__(self,other)
jax.core.AbstractBInt.__hash__(self)->int
jax.core.AbstractBInt.__init__(self,bound)
jax.core.AbstractBInt.str_short(self,short_dtypes=False)->str
jax.core.AbstractToken(AbstractValue)
jax.core.AbstractToken.at_least_vspace(self)
jax.core.AbstractToken.join(self,other)
jax.core.AbstractToken.str_short(self,short_dtypes=False)
jax.core.AbstractUnit(AbstractValue)
jax.core.AbstractUnit._eq(self,self_traced,other)
jax.core.AbstractUnit.at_least_vspace(self)
jax.core.AbstractUnit.join(self,other)
jax.core.AbstractUnit.str_short(self,short_dtypes=False)
jax.core.AbstractValue
jax.core.AbstractValue.__repr__(self)
jax.core.AbstractValue.at_least_vspace(self)
jax.core.AbstractValue.join(self,other)
jax.core.AbstractValue.str_short(self,short_dtypes=False)
jax.core.AbstractValue.strip_named_shape(self)->AbstractValue
jax.core.AbstractValue.strip_weak_type(self)->AbstractValue
jax.core.AbstractValue.update(self,**kwargs)
jax.core.AxisPrimitive(Primitive)
jax.core.AxisPrimitive.bind(self,*args,**params)
jax.core.Bot(AbstractValue)
jax.core.CallPrimitive(Primitive)
jax.core.CallPrimitive.bind(self,fun,*args,**params)
jax.core.CallPrimitive.get_bind_params(self,params)
jax.core.ClosedJaxpr(self,jaxpr:Jaxpr,consts:Sequence)
jax.core.ClosedJaxpr.__init__(self,jaxpr:Jaxpr,consts:Sequence)
jax.core.ClosedJaxpr.__repr__(self)
jax.core.ClosedJaxpr.__str__(self)
jax.core.ClosedJaxpr._repr_pretty_(self,p,cycle)
jax.core.ClosedJaxpr.effects(self)->Effects
jax.core.ClosedJaxpr.eqns(self)
jax.core.ClosedJaxpr.in_avals(self)
jax.core.ClosedJaxpr.literals(self)
jax.core.ClosedJaxpr.map_jaxpr(self,f)
jax.core.ClosedJaxpr.out_avals(self)
jax.core.ClosedJaxpr.pretty_print(self,*,source_info=False,print_shapes=True,name_stack=False,custom_pp_eqn_rules=True,**kw)
jax.core.ClosedJaxpr.replace(self,*,jaxpr=None,consts=None)
jax.core.ConcreteArray(self,dtype,val,weak_type=None)
jax.core.ConcreteArray.__eq__(self,other)
jax.core.ConcreteArray.__hash__(self)
jax.core.ConcreteArray.__init__(self,dtype,val,weak_type=None)
jax.core.ConcreteArray.join(self,other)->AbstractValue
jax.core.ConcreteArray.str_short(self,short_dtypes=False)->str
jax.core.ConcreteArray.update(self,dtype=None,val=None,weak_type=None)
jax.core.DShapedArray(self,shape,dtype,weak_type)
jax.core.DShapedArray.__eq__(self,other)
jax.core.DShapedArray.__hash__(self)
jax.core.DShapedArray.__init__(self,shape,dtype,weak_type)
jax.core.DShapedArray.str_short(self,short_dtypes=False)->str
jax.core.DShapedArray.update(self,shape=None,dtype=None,weak_type=None)
jax.core.DimensionHandler
jax.core.DimensionHandler.as_value(self,d:DimSize)
jax.core.DimensionHandler.diff(self,d1:DimSize,d2:DimSize)->DimSize
jax.core.DimensionHandler.dilate(self,d:DimSize,dilation:int)->DimSize
jax.core.DimensionHandler.divide_shape_sizes(self,s1:Shape,s2:Shape)->DimSize
jax.core.DimensionHandler.greater_equal(self,d1:DimSize,d2:DimSize)->bool
jax.core.DimensionHandler.is_constant(self,d:DimSize)->bool
jax.core.DimensionHandler.stride(self,d:DimSize,window_size:DimSize,window_stride:DimSize)->DimSize
jax.core.DimensionHandler.sum(self,*ds:DimSize)->DimSize
jax.core.DimensionHandler.symbolic_equal(self,d1:DimSize,d2:DimSize)->bool
jax.core.DropVar(self,aval:AbstractValue)
jax.core.DropVar.__init__(self,aval:AbstractValue)
jax.core.DropVar.__repr__(self)
jax.core.DuplicateAxisNameError(self,var)
jax.core.DuplicateAxisNameError.__init__(self,var)
jax.core.EvalTrace(Trace)
jax.core.EvalTrace.process_call(self,primitive,f,tracers,params)
jax.core.EvalTrace.process_custom_jvp_call(self,primitive,fun,jvp,tracers)
jax.core.EvalTrace.process_custom_transpose(self,primitive,call,tracers,**_)
jax.core.EvalTrace.process_custom_vjp_call(self,primitive,fun,fwd,bwd,tracers,**_)
jax.core.EvalTrace.process_primitive(self,primitive,tracers,params)
jax.core.EvalTrace.pure(self,x)
jax.core.InconclusiveDimensionOperation(Exception)
jax.core.Jaxpr(self,constvars:Sequence[Var],invars:Sequence[Var],outvars:Sequence[Atom],eqns:Sequence[JaxprEqn],effects:Effects=no_effects)
jax.core.Jaxpr.__init__(self,constvars:Sequence[Var],invars:Sequence[Var],outvars:Sequence[Atom],eqns:Sequence[JaxprEqn],effects:Effects=no_effects)
jax.core.Jaxpr.__str__(self)
jax.core.Jaxpr._repr_pretty_(self,p,cycle)
jax.core.Jaxpr.pretty_print(self,*,source_info=False,print_shapes=True,custom_pp_eqn_rules=True,name_stack=False,**kw)
jax.core.Jaxpr.replace(self,*,constvars=None,invars=None,outvars=None,eqns=None,effects=None)
jax.core.JaxprEqn(NamedTuple)
jax.core.JaxprEqn.__repr__(self)
jax.core.JaxprEqn.replace(self,*args,**kwargs)
jax.core.JaxprPpContext(self)
jax.core.JaxprPpContext.__init__(self)
jax.core.JaxprPpSettings(NamedTuple)
jax.core.JaxprTypeError(TypeError)
jax.core.Literal(self,val,aval)
jax.core.Literal.__init__(self,val,aval)
jax.core.Literal.__repr__(self)
jax.core.MainTrace(self,level,trace_type,**payload)
jax.core.MainTrace.__eq__(self,other:object)->bool
jax.core.MainTrace.__hash__(self)->int
jax.core.MainTrace.__init__(self,level,trace_type,**payload)
jax.core.MainTrace.__repr__(self)->str
jax.core.MainTrace.with_cur_sublevel(self)
jax.core.MapPrimitive(Primitive)
jax.core.MapPrimitive.bind(self,fun,*args,**params)
jax.core.MapPrimitive.get_bind_params(self,params)
jax.core.MapPrimitive.post_process(self,trace,out_tracers,params)
jax.core.MapPrimitive.process(self,trace,fun,tracers,params)
jax.core.NameGatheringSubst(self)
jax.core.NameGatheringSubst.__init__(self)
jax.core.NamedShape(self,*args,**kwargs)
jax.core.NamedShape.__eq__(self,other)
jax.core.NamedShape.__getitem__(self,idx)
jax.core.NamedShape.__hash__(self)
jax.core.NamedShape.__init__(self,*args,**kwargs)
jax.core.NamedShape.__str__(self)
jax.core.NamedShape.named_items(self)
jax.core.NamedShape.named_rank(self)
jax.core.NamedShape.named_sizes(self)
jax.core.NamedShape.names(self)
jax.core.NamedShape.positional(self)
jax.core.NamedShape.positional_rank(self)
jax.core.NamedShape.rank(self)
jax.core.NamedShape.total(self)
jax.core.Primitive(self,name:str)
jax.core.Primitive.__init__(self,name:str)
jax.core.Primitive.__repr__(self)
jax.core.Primitive.abstract_eval(self,*args,**params)
jax.core.Primitive.bind(self,*args,**params)
jax.core.Primitive.bind_with_trace(self,trace,args,params)
jax.core.Primitive.def_abstract_eval(self,abstract_eval)
jax.core.Primitive.def_custom_bind(self,bind)
jax.core.Primitive.def_effectful_abstract_eval(self,effectful_abstract_eval)
jax.core.Primitive.def_impl(self,impl)
jax.core.Primitive.get_bind_params(self,params)
jax.core.Primitive.impl(self,*args,**params)
jax.core.ShapedArray(self,shape,dtype,weak_type=False,named_shape=None)
jax.core.ShapedArray.__eq__(self,other)
jax.core.ShapedArray.__hash__(self)
jax.core.ShapedArray.__init__(self,shape,dtype,weak_type=False,named_shape=None)
jax.core.ShapedArray._len(self,ignored_tracer)
jax.core.ShapedArray.at_least_vspace(self)
jax.core.ShapedArray.join(self,other)
jax.core.ShapedArray.str_short(self,short_dtypes=False)
jax.core.ShapedArray.strip_named_shape(self)
jax.core.ShapedArray.update(self,shape=None,dtype=None,weak_type=None,named_shape=None)
jax.core.Sublevel(self,level:int)
jax.core.Sublevel.__eq__(self,other)
jax.core.Sublevel.__init__(self,level:int)
jax.core.Sublevel.__lt__(self,other)
jax.core.Sublevel.__repr__(self)
jax.core.ThreadLocalState(self)
jax.core.ThreadLocalState.__init__(self)
jax.core.Token(object)
jax.core.Trace(self,main:MainTrace,sublevel:Sublevel)
jax.core.Trace.__init__(self,main:MainTrace,sublevel:Sublevel)
jax.core.Trace.__repr__(self)
jax.core.Trace.full_raise(self,val)->Tracer
jax.core.Trace.lift(self,tracer)
jax.core.Trace.process_call(self,call_primitive,f,tracers,params)
jax.core.Trace.process_custom_jvp_call(self,primitive,fun,jvp,tracers)
jax.core.Trace.process_custom_transpose(self,prim,call,tracers,**params)
jax.core.Trace.process_custom_vjp_call(self,primitive,fun,fwd,bwd,tracers,out_trees)
jax.core.Trace.process_map(self,map_primitive,f,tracers,params)
jax.core.Trace.process_primitive(self,primitive,tracers,params)
jax.core.Trace.pure(self,val)
jax.core.Trace.sublift(self,tracer)
jax.core.TraceStack(self)
jax.core.TraceStack.__init__(self)
jax.core.TraceStack.__repr__(self)->str
jax.core.TraceStack.copy(self)
jax.core.TraceStack.next_level(self)->int
jax.core.TraceStack.pop(self)->None
jax.core.TraceStack.push(self,main_trace:MainTrace)->None
jax.core.TraceState(self)
jax.core.TraceState.__init__(self)
jax.core.TraceState.copy(self)
jax.core.Tracer(self,trace:Trace)
jax.core.Tracer.__abs__(self)
jax.core.Tracer.__add__(self,other)
jax.core.Tracer.__and__(self,other)
jax.core.Tracer.__array__(self,*args,**kw)
jax.core.Tracer.__array_module__(self,types)
jax.core.Tracer.__bool__(self)
jax.core.Tracer.__complex__(self)
jax.core.Tracer.__copy__(self)
jax.core.Tracer.__deepcopy__(self,unused_memo)
jax.core.Tracer.__div__(self,other)
jax.core.Tracer.__divmod__(self,other)
jax.core.Tracer.__eq__(self,other)
jax.core.Tracer.__float__(self)
jax.core.Tracer.__floordiv__(self,other)
jax.core.Tracer.__ge__(self,other)
jax.core.Tracer.__getattr__(self,name)
jax.core.Tracer.__getitem__(self,idx)
jax.core.Tracer.__gt__(self,other)
jax.core.Tracer.__hex__(self)
jax.core.Tracer.__index__(self)
jax.core.Tracer.__init__(self,trace:Trace)
jax.core.Tracer.__int__(self)
jax.core.Tracer.__invert__(self)
jax.core.Tracer.__iter__(self)
jax.core.Tracer.__le__(self,other)
jax.core.Tracer.__len__(self)
jax.core.Tracer.__long__(self)
jax.core.Tracer.__lshift__(self,other)
jax.core.Tracer.__lt__(self,other)
jax.core.Tracer.__matmul__(self,other)
jax.core.Tracer.__mod__(self,other)
jax.core.Tracer.__mul__(self,other)
jax.core.Tracer.__ne__(self,other)
jax.core.Tracer.__neg__(self)
jax.core.Tracer.__nonzero__(self)
jax.core.Tracer.__oct__(self)
jax.core.Tracer.__or__(self,other)
jax.core.Tracer.__pos__(self)
jax.core.Tracer.__pow__(self,other)
jax.core.Tracer.__radd__(self,other)
jax.core.Tracer.__rand__(self,other)
jax.core.Tracer.__rdiv__(self,other)
jax.core.Tracer.__rdivmod__(self,other)
jax.core.Tracer.__repr__(self)
jax.core.Tracer.__rfloordiv__(self,other)
jax.core.Tracer.__rlshift__(self,other)
jax.core.Tracer.__rmatmul__(self,other)
jax.core.Tracer.__rmod__(self,other)
jax.core.Tracer.__rmul__(self,other)
jax.core.Tracer.__ror__(self,other)
jax.core.Tracer.__rpow__(self,other)
jax.core.Tracer.__rrshift__(self,other)
jax.core.Tracer.__rshift__(self,other)
jax.core.Tracer.__rsub__(self,other)
jax.core.Tracer.__rtruediv__(self,other)
jax.core.Tracer.__rxor__(self,other)
jax.core.Tracer.__setitem__(self,idx,val)
jax.core.Tracer.__sub__(self,other)
jax.core.Tracer.__truediv__(self,other)
jax.core.Tracer.__xor__(self,other)
jax.core.Tracer._assert_live(self)->None
jax.core.Tracer._contents(self)
jax.core.Tracer._origin_msg(self)->str
jax.core.Tracer._pretty_print(self)
jax.core.Tracer.aval(self)
jax.core.Unit
jax.core.Unit.__repr__(self)
jax.core.UnitVar(self)
jax.core.UnitVar.__init__(self)
jax.core.UnitVar.__repr__(self)
jax.core.UnitVar.aval(self)
jax.core.UnshapedArray(self,dtype,weak_type=False)
jax.core.UnshapedArray.__eq__(self,other)
jax.core.UnshapedArray.__hash__(self)
jax.core.UnshapedArray.__init__(self,dtype,weak_type=False)
jax.core.UnshapedArray.__ne__(self,other)
jax.core.UnshapedArray.__repr__(self)
jax.core.UnshapedArray.at_least_vspace(self)->AbstractValue
jax.core.UnshapedArray.join(self,other)
jax.core.UnshapedArray.shape(self)
jax.core.UnshapedArray.str_short(self,short_dtypes=False)->str
jax.core.UnshapedArray.strip_weak_type(self)
jax.core.UnshapedArray.update(self,dtype=None,weak_type=None)
jax.core.Var(self,count:int,suffix:str,aval:AbstractValue)
jax.core.Var.__init__(self,count:int,suffix:str,aval:AbstractValue)
jax.core.Var.__lt__(self,other)
jax.core.Var.__repr__(self)
jax.core._TempAxisName(self,obj)
jax.core._TempAxisName.__eq__(self,other)
jax.core._TempAxisName.__hash__(self)
jax.core._TempAxisName.__init__(self,obj)
jax.core._TempAxisName.__lt__(self,other)
jax.core._TempAxisName.__repr__(self)
jax.core._canonicalize_dimension(dim:DimSize)->DimSize
jax.core._check_jaxpr(ctx_factory:Callable[[],Tuple[JaxprPpContext,JaxprPpSettings]],jaxpr:Jaxpr,in_avals:Sequence[AbstractValue])->None
jax.core._compact_eqn_should_include(k:str,v:Any)->bool
jax.core._dim_handler_and_canonical(*dlist:DimSize)->Tuple[DimensionHandler, Tuple[DimSize, ...]]
jax.core._effect_free_abstract_eval(abstract_eval)
jax.core._encode_digits_alphabetic(n)
jax.core._forward_to_value(self,fun,ignored_tracer,*args)
jax.core._invalid_shape_error(shape:Shape,context:str='')
jax.core._jaxpr_vars(jaxpr)
jax.core._map_dshaped_array(size:Union[int,Tracer],axis:Optional[int],aval:ShapedArray)->ShapedArray
jax.core._map_shaped_array(size:int,axis:Optional[int],aval:ShapedArray)->ShapedArray
jax.core._map_unit(*_)->AbstractUnit
jax.core._param_uses_outfeed(param)
jax.core._short_dtype_name(dtype)
jax.core._unmap_dshaped_array(size:Union[int,Tracer],axis_name,axis:Optional[int],aval:DShapedArray)->DShapedArray
jax.core._unmap_shaped_array(size:int,axis_name,axis:Optional[int],aval:ShapedArray)->ShapedArray
jax.core._update_thread_local_jit_state(dynamic)
jax.core.apply_todos(todos,outs)
jax.core.as_named_shape(shape)->NamedShape
jax.core.axis_frame(axis_name)
jax.core.call_bind(primitive:CallPrimitive,fun,*args,**params)
jax.core.call_impl(f:lu.WrappedFun,*args,**params)
jax.core.canonicalize_dim(d:DimSize,context:str='')->DimSize
jax.core.canonicalize_shape(shape:Shape,context:str='')->Shape
jax.core.check_call(ctx_factory,prim,in_avals,params)
jax.core.check_eqn(prim,in_avals,params)
jax.core.check_jaxpr(jaxpr:Jaxpr)
jax.core.check_map(ctx_factory,prim,in_avals,params)
jax.core.check_valid_jaxtype(x)
jax.core.concrete_aval(x)
jax.core.concrete_or_error(force:Any,val:Any,context='')
jax.core.concretization_function_error(fun,suggest_astype=False)
jax.core.cur_sublevel()->Sublevel
jax.core.diff_dim(d1:DimSize,d2:DimSize)->DimSize
jax.core.diff_shape(s1:Shape,s2:Shape)->Shape
jax.core.dilate_dim(d:DimSize,dilation:DimSize)->DimSize
jax.core.dilate_shape(s:Shape,dilations:Sequence[int])->Shape
jax.core.dimension_as_value(d:DimSize)
jax.core.divide_shape_sizes(s1:Shape,s2:Shape)->DimSize
jax.core.do_subst_axis_names_jaxpr(jaxpr:Union[Jaxpr,ClosedJaxpr],subst:AxisSubst)
jax.core.ensure_compile_time_eval()
jax.core.escaped_tracer_error(tracer,detail=None)
jax.core.eval_jaxpr(jaxpr:Jaxpr,consts,*args)
jax.core.extend_axis_env(axis_name:AxisName,size:int,tag:Any)
jax.core.extend_axis_env_nd(axes:Iterable[Tuple[AxisName,int]])
jax.core.find_top_trace(xs)->Trace
jax.core.full_lower(val)
jax.core.gensym(jaxprs:Optional[Sequence[Jaxpr]]=None,suffix:str='')->Callable[[AbstractValue], Var]
jax.core.get_aval(x)
jax.core.greater_equal_dim(d1:DimSize,d2:DimSize)->bool
jax.core.greater_equal_shape(s1:Shape,s2:Shape)->bool
jax.core.is_constant_dim(d:DimSize)->bool
jax.core.is_empty_shape(s:Shape)->bool
jax.core.is_special_dim_size(v:Any)->bool
jax.core.jaxpr_as_fun(closed_jaxpr:ClosedJaxpr,*args)
jax.core.jaxpr_uses_outfeed(jaxpr:Jaxpr)->bool
jax.core.jaxprs_in_params(params)->Iterator[Jaxpr]
jax.core.join_effects(*effects:Effect)->Effects
jax.core.join_named_shapes(*named_shapes)
jax.core.lattice_join(x:Optional[AbstractValue],y:Optional[AbstractValue])->AbstractValue
jax.core.leaked_tracer_error(name:str,t,tracers:List[Tracer])->Exception
jax.core.map_bind(primitive:MapPrimitive,fun,*args,out_axes_thunk,**params)
jax.core.mapped_aval(size:int,axis:Optional[int],aval:AbstractValue)->AbstractValue
jax.core.maybe_find_leaked_tracers(x:Optional[Union[MainTrace,Sublevel]])->List[Tracer]
jax.core.new_base_main(trace_type:Type[Trace])->Generator[MainTrace, None, None]
jax.core.new_jaxpr_eqn(invars,outvars,primitive,params,effects,source_info=None)
jax.core.new_main(trace_type:Type[Trace],dynamic:bool=False,**payload)->Generator[MainTrace, None, None]
jax.core.new_sublevel()->Generator[None, None, None]
jax.core.pp_aval(a:AbstractValue,context:JaxprPpContext)->str
jax.core.pp_eqn(eqn,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_eqns(eqns,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_jaxpr(jaxpr,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_jaxpr_eqn_range(jaxpr:Jaxpr,lo:int,hi:int,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_jaxpr_skeleton(jaxpr,eqns_fn,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_jaxprs(jaxprs,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_kv_pair(k:str,v:Any,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_kv_pairs(kv_pairs,context:JaxprPpContext,settings:JaxprPpSettings)->pp.Doc
jax.core.pp_var(v:Var,context:JaxprPpContext)->str
jax.core.pp_vars(vs:Sequence[Any],context:JaxprPpContext,*,separator='',print_shapes:bool=False)->pp.Doc
jax.core.primal_dtype_to_tangent_dtype(primal_dtype)
jax.core.primitive_uses_outfeed(prim:Primitive,params:Dict)->bool
jax.core.process_env_traces_call(primitive:CallPrimitive,level:Optional[int],params_tuple:tuple,*args)
jax.core.process_env_traces_map(primitive:MapPrimitive,level:int,params_tuple:tuple,*args)
jax.core.raise_to_shaped(aval:AbstractValue,weak_type=None)
jax.core.reset_trace_state()->bool
jax.core.same_shape_sizes(s1:Shape,s2:Shape)->bool
jax.core.str_eqn_compact(primitive_name:str,params:Dict)->str
jax.core.stride_dim(d:DimSize,window_size:DimSize,window_stride:DimSize)->DimSize
jax.core.stride_shape(s:Shape,window_size:Shape,window_stride:Shape)->Shape
jax.core.subjaxprs(jaxpr:Jaxpr)->Iterator[Jaxpr]
jax.core.subst_axis_names(primitive:Primitive,params:ParamDict,subst:AxisSubst,traverse:bool=True)->ParamDict
jax.core.subst_axis_names_eqn(eqn:JaxprEqn,subst:AxisSubst,var_map:Dict[Var,Var])->JaxprEqn
jax.core.subst_axis_names_jaxpr(jaxpr:Union[Jaxpr,ClosedJaxpr],subst:AxisSubst)
jax.core.subst_axis_names_var(v:Var,subst:AxisSubst,var_map:Dict[Var,Var])->Var
jax.core.sum_dim(*ds:DimSize)->DimSize
jax.core.sum_shapes(*ss:Shape)->Shape
jax.core.symbolic_equal_dim(d1:DimSize,d2:DimSize)->bool
jax.core.symbolic_equal_one_of_dim(d1:DimSize,dlist:Sequence[DimSize])->bool
jax.core.symbolic_equal_shape(s1:Shape,s2:Shape)->bool
jax.core.trace_state_clean()->bool
jax.core.traverse_jaxpr_params(f,params)
jax.core.typecheck(aval:AbstractValue,x)->bool
jax.core.typecompat(aval_ref:AbstractValue,aval:AbstractValue)->bool
jax.core.typematch(aval1:AbstractValue,aval2:AbstractValue)->bool
jax.core.unmapped_aval(size:int,axis_name,axis:Optional[int],aval:AbstractValue)->AbstractValue
jax.core.used_axis_names(primitive:Primitive,params:ParamDict)->Set[AxisName]
jax.core.used_axis_names_jaxpr(jaxpr:Union[Jaxpr,ClosedJaxpr])
jax.core.valid_jaxtype(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/dtypes.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/custom_batching.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/version.py----------------------------------------
A:jax.version.__version_info__->_version_as_tuple(__version__)
A:jax.version._minimum_jaxlib_version_info->_version_as_tuple(_minimum_jaxlib_version)
jax.version._version_as_tuple(version_str)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/prng.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/config.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/tree_util.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/dlpack.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/profiler.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/cloud_tpu_init.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/distributed.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/linear_util.py----------------------------------------
A:jax.linear_util._EMPTY_STORE_VALUE->EmptyStoreValue()
A:jax.linear_util.gen->gen(*gen_static_args + tuple(args), **kwargs)
A:jax.linear_util.(args, kwargs)->next(gen)
A:jax.linear_util.ans->call(fun, *args)
A:jax.linear_util.(gen, out_store)->stack.pop()
A:jax.linear_util.transformation_stack->map(transform_to_str, enumerate(self.transforms))
A:jax.linear_util.out_store->Store()
A:jax.linear_util.cache->fun_caches.setdefault(fun.f, {})
A:jax.linear_util.result->most_recent_entry()
A:jax.linear_util.thread_local.most_recent_entry->weakref.ref(ans)
A:jax.linear_util.out1->aux1()
A:jax.linear_util.out2->aux2()
jax.linear_util.EmptyStoreValue
jax.linear_util.Store(self)
jax.linear_util.Store.__init__(self)
jax.linear_util.Store.__nonzero__(self)
jax.linear_util.Store.reset(self)
jax.linear_util.Store.store(self,val)
jax.linear_util.Store.val(self)
jax.linear_util.StoreException(Exception)
jax.linear_util.WrappedFun(self,f,transforms,stores,params,in_type)
jax.linear_util.WrappedFun.__eq__(self,other)
jax.linear_util.WrappedFun.__hash__(self)
jax.linear_util.WrappedFun.__init__(self,f,transforms,stores,params,in_type)
jax.linear_util.WrappedFun.__name__(self)
jax.linear_util.WrappedFun.__repr__(self)
jax.linear_util.WrappedFun.call_wrapped(self,*args,**kwargs)
jax.linear_util.WrappedFun.populate_stores(self,stores)
jax.linear_util.WrappedFun.wrap(self,gen,gen_static_args,out_store)->'WrappedFun'
jax.linear_util._CacheLocalContext(self)
jax.linear_util._CacheLocalContext.__init__(self)
jax.linear_util._copy_main_traces(x)
jax.linear_util.annotate(f:WrappedFun,in_type:Optional[Tuple[Tuple[core.AbstractValue,bool],...]])->WrappedFun
jax.linear_util.cache(call:Callable)
jax.linear_util.fun_name(f)
jax.linear_util.hashable_partial(x,*args)
jax.linear_util.merge_linear_aux(aux1,aux2)
jax.linear_util.transformation(gen,fun:WrappedFun,*gen_static_args)->WrappedFun
jax.linear_util.transformation_with_aux(gen,fun:WrappedFun,*gen_static_args)->Tuple[WrappedFun, Any]
jax.linear_util.wrap_init(f,params=None)->WrappedFun


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/errors.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/test_util.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/random.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/util.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/jaxpr_util.py----------------------------------------
A:jax.jaxpr_util.d->collections.defaultdict(lambda : 0)
A:jax.jaxpr_util.src->jax._src.source_info_util.summarize(eqn.source_info)
A:jax.jaxpr_util.subs->map(var_defs_and_refs, core.subjaxprs(jaxpr))
A:jax.jaxpr_util.count_width->max((len(str(v)) for v in histogram.values()))
A:jax.jaxpr_util.s->collections.defaultdict(itertools.count(1).__next__)
A:jax.jaxpr_util.func->collections.defaultdict(itertools.count(1).__next__)
A:jax.jaxpr_util.loc->collections.defaultdict(itertools.count(1).__next__)
A:jax.jaxpr_util.raw_frames->zip(*tb.raw_frames())
A:jax.jaxpr_util.json_profile->json.dumps({'string_table': list(s.keys()), 'location': locations, 'function': functions, 'sample_type': sample_type, 'sample': samples})
jax.jaxpr_util._pprof_profile(profile:Dict[Tuple[Optional[xla_client.Traceback],core.Primitive],int])->bytes
jax.jaxpr_util.all_eqns(jaxpr:core.Jaxpr)
jax.jaxpr_util.collect_eqns(jaxpr:core.Jaxpr,key:Callable)
jax.jaxpr_util.histogram(jaxpr:core.Jaxpr,key:Callable,key_fmt:Callable=lambdax:x)
jax.jaxpr_util.pprof_equation_profile(jaxpr:core.Jaxpr)->bytes
jax.jaxpr_util.primitives(jaxpr:core.Jaxpr)
jax.jaxpr_util.primitives_by_shape(jaxpr:core.Jaxpr)
jax.jaxpr_util.primitives_by_source(jaxpr:core.Jaxpr)
jax.jaxpr_util.print_histogram(histogram:Dict[Any,int])
jax.jaxpr_util.source_locations(jaxpr:core.Jaxpr)
jax.jaxpr_util.var_defs_and_refs(jaxpr:core.Jaxpr)
jax.jaxpr_util.vars_by_fanout(jaxpr:core.Jaxpr)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/custom_derivatives.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/abstract_arrays.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/multihost_utils.py----------------------------------------
A:jax.experimental.multihost_utils.in_tree->jax.device_get(_psum(in_tree))
A:jax.experimental.multihost_utils.h->numpy.int32(zlib.crc32(name.encode()))
A:jax.experimental.multihost_utils.devices->numpy.array(jax.devices()).reshape(jax.process_count(), jax.local_device_count())
A:jax.experimental.multihost_utils.global_mesh->jax.experimental.maps.Mesh(devices, ('processes', 'local_devices'))
A:jax.experimental.multihost_utils.in_axis_resources->P('processes')
A:jax.experimental.multihost_utils.inp->numpy.expand_dims(inp, axis=0)
A:jax.experimental.multihost_utils.out->pjit(lambda x: x, in_axis_resources=in_axis_resources, out_axis_resources=None)(inp)
A:jax.experimental.multihost_utils.expected->broadcast_one_to_all(in_tree)
jax.experimental.multihost_utils._psum(x:PyTreeDef)->PyTreeDef
jax.experimental.multihost_utils.assert_equal(in_tree,fail_message:str='')
jax.experimental.multihost_utils.broadcast_one_to_all(in_tree:PyTreeDef,is_source:Optional[bool]=None)->PyTreeDef
jax.experimental.multihost_utils.process_allgather(in_tree:PyTreeDef,tiled:bool=False)->PyTreeDef
jax.experimental.multihost_utils.sync_global_devices(name:str)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/loops.py----------------------------------------
A:jax.experimental.loops.start->int(first)
A:jax.experimental.loops.stop->int(first)
A:jax.experimental.loops.step->int(third)
A:jax.experimental.loops.pred_dtype->numpy.result_type(pred)
A:jax.experimental.loops.mt_val->self._mutable_state.get(key)
A:jax.experimental.loops.(flat_values, flat_tree)->jax.tree_util.tree_flatten(value)
A:jax.experimental.loops.new_aval->flat_new_tree.unflatten(safe_map(_BodyTracer.abstractify, flat_new_values))
A:jax.experimental.loops.level->jax.core.thread_local_state.trace_state.trace_stack.next_level()
A:jax.experimental.loops.name_stack->jax._src.source_info_util.current_name_stack()
A:jax.experimental.loops.main->jax.core.MainTrace(level, pe.JaxprTrace, name_stack=name_stack)
A:jax.experimental.loops.self.stack->traceback.StackSummary.from_list(cast(List[Any], traceback.extract_stack()[:-2]))
A:jax.experimental.loops.self.trace->self.scope.start_subtrace()
A:jax.experimental.loops.self.carried_state_names->sorted(self.scope._mutable_state.keys())
A:jax.experimental.loops.(flat_init_vals, init_tree)->jax.tree_util.tree_flatten(init_val)
A:jax.experimental.loops.flat_init_avals->safe_map(_BodyTracer.abstractify, flat_init_vals)
A:jax.experimental.loops.flat_init_pvals->safe_map(pe.PartialVal.unknown, flat_init_avals)
A:jax.experimental.loops.flat_init_vars->safe_map(self.trace.new_arg, flat_init_pvals)
A:jax.experimental.loops.self.scope._mutable_state[key]->init_tree.unflatten(flat_init_vars)
A:jax.experimental.loops.self.scope._mutable_state_aval[key]->init_tree.unflatten(flat_init_avals)
A:jax.experimental.loops.self.carried_state_initial[key]->init_tree.unflatten(flat_init_vals)
A:jax.experimental.loops.index_var_aval->_BodyTracer.abstractify(0)
A:jax.experimental.loops.index_var_pval->jax.interpreters.partial_eval.PartialVal.unknown(index_var_aval)
A:jax.experimental.loops.self._index_var->self.trace.new_arg(index_var_pval)
A:jax.experimental.loops.in_tracers->tuple(itertools.chain(*[self.carried_state_vars[ms] for ms in self.carried_state_names]))
A:jax.experimental.loops.(flat_new_values, flat_new_tree)->jax.tree_util.tree_flatten(new_val)
A:jax.experimental.loops.(body_closed_jaxpr, body_const_vals)->_BodyTracer.trace_to_jaxpr_finalize(in_tracers=in_tracers, out_tracers=body_out_tracers, trace=self.trace)
A:jax.experimental.loops.carried_init_val->tuple([self.carried_state_initial[ms] for ms in self.carried_state_names])
A:jax.experimental.loops.(carried_init_vals, carried_tree)->jax.tree_util.tree_flatten(carried_init_val)
A:jax.experimental.loops.carried_out_vals->self.loop_builder.build_output_vals(self.scope, self.carried_state_names, carried_tree, carried_init_vals, body_closed_jaxpr, body_const_vals)
A:jax.experimental.loops.carried_mutable_state_unflattened->jax.tree_util.tree_unflatten(carried_tree, carried_out_vals)
A:jax.experimental.loops.out_tracers->safe_map(partial(pe.instantiate_const_at, trace), instantiate, out_tracers)
A:jax.experimental.loops.(jaxpr, consts, env)->jax.interpreters.partial_eval.tracers_to_jaxpr(in_tracers, out_tracers)
A:jax.experimental.loops.closed_jaxpr->jax.core.ClosedJaxpr(pe.convert_constvars_jaxpr(jaxpr), ())
A:jax.experimental.loops.arange_val->numpy.arange(self.start, stop=self.stop, step=self.step)
A:jax.experimental.loops.self.index->jax.lax.convert_element_type(pred, np.int32)
A:jax.experimental.loops.(in_vals, in_tree)->jax.tree_util.tree_flatten((body_const_vals, tree_util.tree_unflatten(carried_tree, init_vals)))
A:jax.experimental.loops.in_avals->safe_map(_BodyTracer.abstractify, in_vals)
A:jax.experimental.loops.(pass_through_closed_jaxpr, pass_through_const_vals, _)->jax._src.lax.control_flow._initial_style_jaxpr(lambda *args: args[1], in_tree, tuple(in_avals))
A:jax.experimental.loops.res->self.cond_func()
A:jax.experimental.loops.init_avals->safe_map(_BodyTracer.abstractify, init_vals)
A:jax.experimental.loops.(cond_jaxpr, cond_consts, cond_tree)->jax._src.lax.control_flow._initial_style_jaxpr(cond_func_wrapped, carried_tree, tuple(init_avals))
jax.experimental.loops.Scope(self)
jax.experimental.loops.Scope.__enter__(self)
jax.experimental.loops.Scope.__exit__(self,exc_type,exc_val,exc_tb)
jax.experimental.loops.Scope.__getattr__(self,key)
jax.experimental.loops.Scope.__init__(self)
jax.experimental.loops.Scope.__setattr__(self,key,value)
jax.experimental.loops.Scope._error_premature_exit_range(self)
jax.experimental.loops.Scope._pop_range(self,range_)
jax.experimental.loops.Scope._push_range(self,range_)
jax.experimental.loops.Scope.cond_range(self,pred)
jax.experimental.loops.Scope.end_subtrace(self)
jax.experimental.loops.Scope.range(self,first,second=None,third=None)
jax.experimental.loops.Scope.start_subtrace(self)
jax.experimental.loops.Scope.while_range(self,cond_func)
jax.experimental.loops._BodyTracer(self,scope,loop_builder)
jax.experimental.loops._BodyTracer.__init__(self,scope,loop_builder)
jax.experimental.loops._BodyTracer.__iter__(self)
jax.experimental.loops._BodyTracer.__next__(self)
jax.experimental.loops._BodyTracer.abstractify(x)
jax.experimental.loops._BodyTracer.end_tracing_body(self)
jax.experimental.loops._BodyTracer.location(self)
jax.experimental.loops._BodyTracer.next(self)
jax.experimental.loops._BodyTracer.start_tracing_body(self)
jax.experimental.loops._BodyTracer.trace_to_jaxpr_finalize(in_tracers,out_tracers,trace,instantiate=True)
jax.experimental.loops._BoundedLoopBuilder(self,start,stop,step)
jax.experimental.loops._BoundedLoopBuilder.__init__(self,start,stop,step)
jax.experimental.loops._BoundedLoopBuilder.build_output_vals(self,scope,carried_state_names,carried_tree,init_vals,body_closed_jaxpr,body_const_vals)
jax.experimental.loops._BoundedLoopBuilder.can_use_index_var(self)
jax.experimental.loops._CondBuilder(self,pred)
jax.experimental.loops._CondBuilder.__init__(self,pred)
jax.experimental.loops._CondBuilder.build_output_vals(self,scope,carried_state_names,carried_tree,init_vals,body_closed_jaxpr,body_const_vals)
jax.experimental.loops._CondBuilder.can_use_index_var(self)
jax.experimental.loops._LoopBuilder(object)
jax.experimental.loops._LoopBuilder.__str__(self)
jax.experimental.loops._LoopBuilder.build_output_vals(self,scope,carried_state_names,carried_tree,init_vals,body_closed_jaxpr,body_const_vals)
jax.experimental.loops._LoopBuilder.can_use_index_var(self)
jax.experimental.loops._WhileBuilder(self,cond_func)
jax.experimental.loops._WhileBuilder.__init__(self,cond_func)
jax.experimental.loops._WhileBuilder.build_output_vals(self,scope,carried_state_names,carried_tree,init_vals,body_closed_jaxpr,body_const_vals)
jax.experimental.loops._WhileBuilder.can_use_index_var(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/mesh_utils.py----------------------------------------
A:jax.experimental.mesh_utils.assignable_physical_mesh->list(physical_mesh.shape)
A:jax.experimental.mesh_utils.axes->itertools.combinations(assignable_physical_mesh, num_axes)
A:jax.experimental.mesh_utils.indices->itertools.combinations(range(len(assignable_physical_mesh)), num_axes)
A:jax.experimental.mesh_utils.local_topology->_bounds_from_last_device(jax_local_devices_from_process_0[-1])
A:jax.experimental.mesh_utils.physical_topology->_bounds_from_last_device(jax_devices[-1])
A:jax.experimental.mesh_utils.jax_devices_array->jax_devices_array.reshape((g_z, g_y, g_x)).reshape((g_z, g_y, g_x))
A:jax.experimental.mesh_utils.mesh_shape->tuple(mesh_shape)
A:jax.experimental.mesh_utils.process_0_devices->jax.local_devices(process_index=0)
A:jax.experimental.mesh_utils.global_devices->jax.devices()
A:jax.experimental.mesh_utils.device_mesh->numpy.asarray(global_devices).reshape(mesh_shape)
A:jax.experimental.mesh_utils.perm->numpy.array(_TRAY_RING_ORDER)
A:jax.experimental.mesh_utils.physical_mesh->_transpose_trick(physical_mesh, mesh_shape)
A:jax.experimental.mesh_utils.(device_mesh, assignment)->_create_device_mesh_for_tpu_v4(physical_mesh, mesh_shape)
jax.experimental.mesh_utils._bounds_from_last_device(last_device)->Sequence[int]
jax.experimental.mesh_utils._create_device_mesh(process_0_devices,global_devices,device_kind,mesh_shape:Sequence[int],contiguous_submeshes:bool=False)->np.ndarray
jax.experimental.mesh_utils._create_device_mesh_for_tpu_v4(physical_mesh:np.ndarray,mesh_shape:Sequence[int])->Tuple[np.ndarray, Tuple[Tuple[int, ...], ...]]
jax.experimental.mesh_utils._jax_devices_order_normalized(jax_local_devices_from_process_0:Sequence[Any],jax_devices:Sequence[Any])->np.ndarray
jax.experimental.mesh_utils._transpose_trick(physical_mesh:np.ndarray,mesh_shape:Sequence[int])->np.ndarray
jax.experimental.mesh_utils.create_device_mesh(mesh_shape:Sequence[int],contiguous_submeshes:bool=False)->np.ndarray


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/pjit.py----------------------------------------
A:jax.experimental.pjit.FROM_GDA->_FromGdaSingleton()
A:jax.experimental.pjit.in_axis_resources->tuple((spec.insert_axis_partitions(0, new_parts) if is_mapped else spec for (is_mapped, spec) in zip(is_mapped_in, in_axis_resources)))
A:jax.experimental.pjit.(in_axis_resources, _, _, in_all_auto)->_prepare_axis_resources(in_axis_resources, 'in_axis_resources')
A:jax.experimental.pjit.(out_axis_resources, _, _, _)->_prepare_axis_resources(out_axis_resources, 'out_axis_resources')
A:jax.experimental.pjit.static_argnums->_ensure_index_tuple(static_argnums)
A:jax.experimental.pjit.donate_argnums->rebase_donate_argnums(donate_argnums, static_argnums)
A:jax.experimental.pjit.f->jax.core.jaxpr_as_fun(jaxpr)
A:jax.experimental.pjit.(f, dyn_args)->argnums_partial_except(f, static_argnums, args, allow_invalid=False)
A:jax.experimental.pjit.(args_flat, in_tree)->tree_flatten(dyn_args)
A:jax.experimental.pjit.(flat_fun, out_tree)->flatten_fun_nokwargs(f, in_tree)
A:jax.experimental.pjit.donated_invars->donation_vector(donate_argnums, dyn_args, ())
A:jax.experimental.pjit.local_in_avals->treedef_tuple([in_tree, tree_flatten({})[1]]).unflatten(flat_local_in_avals)
A:jax.experimental.pjit.in_positional_semantics->tuple(tree_map(partial(_get_in_positional_semantics, _global_avals), args_flat))
A:jax.experimental.pjit.(global_in_avals, canonicalized_in_axis_resources_flat)->_process_in_axis_resources(mesh, local_in_avals, hashable_pytree(in_axis_resources), in_tree, in_positional_semantics, tuple((isinstance(a, GDA) for a in args_flat)))
A:jax.experimental.pjit.(jaxpr, canonicalized_out_axis_resources_flat)->_pjit_jaxpr(flat_fun, mesh, global_in_avals, HashableFunction(out_tree, closure=()), hashable_pytree(out_axis_resources))
A:jax.experimental.pjit.canonicalized_in_axis_resources_flat->tree_map(_create_cpspec, in_axis_resources_flat)
A:jax.experimental.pjit.params->dict(jaxpr=jaxpr, in_axis_resources=canonicalized_in_axis_resources_flat, out_axis_resources=canonicalized_out_axis_resources_flat, resource_env=resource_env, donated_invars=donated_invars, name=getattr(flat_fun, '__name__', '<unnamed function>'), in_positional_semantics=in_positional_semantics, out_positional_semantics=out_positional_semantics)
A:jax.experimental.pjit.(args_flat, _, params, _, out_tree, _)->infer_params(*args, **kwargs)
A:jax.experimental.pjit.out->jax.core.Primitive('pjit').bind(*args_flat, **params)
A:jax.experimental.pjit.(args_flat, flat_local_in_avals, params, in_tree, out_tree, donate_argnums)->infer_params(*args, _global_avals=_global_avals, **kwargs)
A:jax.experimental.pjit.in_is_global->_calc_is_global_sequence(known_params['in_positional_semantics'], known_params['in_axis_resources'])
A:jax.experimental.pjit.lowering->_pjit_lower(params['jaxpr'], params['in_axis_resources'], params['out_axis_resources'], params['resource_env'], params['donated_invars'], params['name'], in_is_global)
A:jax.experimental.pjit.args_kwargs_in_tree->treedef_tuple([in_tree, tree_flatten({})[1]])
A:jax.experimental.pjit.(vals, treedef)->tree_flatten(pytree)
A:jax.experimental.pjit.vals->tuple(vals)
A:jax.experimental.pjit.axis_tree->tree_map(lambda parsed: parsed.user_spec, axis_resources)
A:jax.experimental.pjit.dummy_tree->tree_unflatten(tree, [PytreeLeaf()] * tree.num_leaves)
A:jax.experimental.pjit.errors->prefix_errors(axis_tree, dummy_tree)
A:jax.experimental.pjit.in_axis_resources_flat->flatten_axis_resources('pjit in_axis_resources', in_tree, in_axis_resources_thunk(), tupled_args=True)
A:jax.experimental.pjit.global_in_avals->local_to_global(in_positional_semantics, mesh, local_in_avals, canonicalized_in_axis_resources_flat)
A:jax.experimental.pjit.(jaxpr, global_out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(fun, global_in_avals)
A:jax.experimental.pjit.jaxpr->jax.core.ClosedJaxpr(jaxpr, consts)
A:jax.experimental.pjit.out_axis_resources_flat->flatten_axis_resources('pjit out_axis_resources', out_tree(), out_axis_resources_thunk(), tupled_args=False)
A:jax.experimental.pjit.canonicalized_out_axis_resources_flat->tree_map(_create_cpspec, out_axis_resources_flat)
A:jax.experimental.pjit.self.partitions->tuple(partitions)
A:jax.experimental.pjit.new_partitions->tuple_insert(parts, dim, val)
A:jax.experimental.pjit.axis_spec->tuple(axis_spec)
A:jax.experimental.pjit.partitions->list(parsed_pspec.partitions)
A:jax.experimental.pjit.REPLICATED->CanonicalizedParsedPartitionSpec(ParsedPartitionSpec(None, ()))
A:jax.experimental.pjit.(entries, treedef)->tree_flatten(axis_resources, is_leaf=lambda x: x is None)
A:jax.experimental.pjit.all_auto->jax.interpreters.pxla._check_if_all_or_none_auto(entries, arg_name)
A:jax.experimental.pjit.resource_counts->Counter(it.chain.from_iterable(constrained_dims))
A:jax.experimental.pjit.size->int(np.prod([mesh_shape[resource] for resource in axis_resources], dtype=np.int64))
A:jax.experimental.pjit.pjit_p->jax.core.Primitive('pjit')
A:jax.experimental.pjit.compiled->_pjit_lower(known_params['jaxpr'], known_params['in_axis_resources'], known_params['out_axis_resources'], known_params['resource_env'], known_params['donated_invars'], known_params['name'], in_is_global).compile(_allow_propagation_to_outputs=True, _allow_compile_replicated=False)
A:jax.experimental.pjit.fun->jax.linear_util.wrap_init(f)
A:jax.experimental.pjit.subc->subc.build(xops.Tuple(subc, out_nodes)).build(xops.Tuple(subc, out_nodes))
A:jax.experimental.pjit.arg->jax.interpreters.xla.parameter(subc, i, ctx.builder.GetShape(n))
A:jax.experimental.pjit.sub_ctx->ctx.module_context.replace(name_stack=xla.extend_name_stack(ctx.module_context.name_stack, wrap_name(name, 'pjit')))
A:jax.experimental.pjit.out_nodes->jax.interpreters.xla.jaxpr_subcomp(sub_ctx, jaxpr.jaxpr, xla._xla_consts(subc, jaxpr.consts), *args)
A:jax.experimental.pjit.output_types->safe_map(mlir.aval_to_ir_types, ctx.avals_out)
A:jax.experimental.pjit.flat_output_types->jax._src.util.flatten(output_types)
A:jax.experimental.pjit.func->jax.interpreters.mlir.lower_jaxpr_to_fun(sub_ctx, f'pjit_{name}', jaxpr, arg_shardings=arg_shardings, result_shardings=result_shardings, use_sharding_annotations=False)
A:jax.experimental.pjit.call->jax._src.lib.mlir.dialects.func.CallOp(flat_output_types, ir.FlatSymbolRefAttr.get(func.name.value), mlir.flatten_lowering_ir_args(args))
A:jax.experimental.pjit.(new_jaxpr, is_mapped_out)->jax.interpreters.batching.batch_jaxpr(jaxpr, axis_size, is_mapped_in, instantiate=False, axis_name=axis_name, main_type=main_type)
A:jax.experimental.pjit.out_axis_resources->tuple((spec.insert_axis_partitions(0, new_parts) if is_mapped else spec for (is_mapped, spec) in zip(is_mapped_out, out_axis_resources)))
A:jax.experimental.pjit.vals_out->jax.core.Primitive('pjit').bind(*vals_in, jaxpr=new_jaxpr, in_axis_resources=in_axis_resources, out_axis_resources=out_axis_resources, resource_env=resource_env, donated_invars=donated_invars, name=name, in_positional_semantics=in_positional_semantics, out_positional_semantics=out_positional_semantics)
A:jax.experimental.pjit.batching.axis_primitive_batchers[pjit_p]->partial(_pjit_batcher, False)
A:jax.experimental.pjit.pxla.spmd_primitive_batchers[pjit_p]->partial(_pjit_batcher, True)
A:jax.experimental.pjit.(jaxpr_jvp, is_nz_tangents_out)->jax.interpreters.ad.jvp_jaxpr(jaxpr, is_nz_tangents_in, instantiate=False)
A:jax.experimental.pjit._filter_zeros_in->partial(_filter_zeros, is_nz_tangents_in)
A:jax.experimental.pjit._filter_zeros_out->partial(_filter_zeros, is_nz_tangents_out)
A:jax.experimental.pjit.outputs->jax.core.Primitive('pjit').bind(*primals_in, *_filter_zeros_in(tangents_in), jaxpr=jaxpr_jvp, in_axis_resources=(*in_axis_resources, *_filter_zeros_in(in_axis_resources)), out_axis_resources=(*out_axis_resources, *_filter_zeros_out(out_axis_resources)), resource_env=resource_env, donated_invars=(*donated_invars, *_filter_zeros_in(donated_invars)), name=wrap_name(name, 'jvp'), in_positional_semantics=(*in_positional_semantics, *_filter_zeros_in(in_positional_semantics)), out_positional_semantics=out_positional_semantics)
A:jax.experimental.pjit.(primals_out, tangents_out)->split_list(outputs, [len(jaxpr.jaxpr.outvars)])
A:jax.experimental.pjit.tangents_out_it->iter(tangents_out)
A:jax.experimental.pjit.known_ins->tuple((pv.is_known() for pv in in_pvals))
A:jax.experimental.pjit.unknown_ins->tuple((not k for k in known_ins))
A:jax.experimental.pjit.(raw_known_jaxpr, raw_unknown_jaxpr, unknown_outs)->jax.interpreters.partial_eval.partial_eval_jaxpr(jaxpr, unknown_ins, instantiate=False)
A:jax.experimental.pjit.unknown_outs->tuple(unknown_outs)
A:jax.experimental.pjit.known_outs->tuple((not uk for uk in unknown_outs))
A:jax.experimental.pjit.known_jaxpr->raw_known_jaxpr.map_jaxpr(lambda jaxpr: pe._drop_vars(jaxpr, drop_ins=unknown_ins, drop_outs=unknown_outs + (False,) * num_residuals))
A:jax.experimental.pjit.known_params->dict(jaxpr=known_jaxpr, in_axis_resources=keep_where(in_axis_resources, known_ins), out_axis_resources=keep_where(out_axis_resources, known_outs) + (REPLICATED,) * num_residuals, resource_env=resource_env, donated_invars=keep_where(donated_invars, known_ins), name=name, in_positional_semantics=keep_where(in_positional_semantics, known_ins), out_positional_semantics=out_positional_semantics)
A:jax.experimental.pjit.(_, output_ppspec)->_get_ppspec_from_executable(compiled.xla_executable, mesh)
A:jax.experimental.pjit.residual_specs->tuple(output_ppspec[-num_residuals:])
A:jax.experimental.pjit.all_known_outs->jax.core.Primitive('pjit').bind(*(pv.get_known() for pv in in_pvals if pv.is_known()), **known_params)
A:jax.experimental.pjit.(known_out_vals, residual_vals)->split_list(all_known_outs, [-num_residuals])
A:jax.experimental.pjit.unknown_jaxpr->raw_unknown_jaxpr.map_jaxpr(lambda jaxpr: pe._drop_vars(jaxpr, drop_ins=known_ins + (False,) * num_residuals, drop_outs=known_outs))
A:jax.experimental.pjit.unknown_params->dict(jaxpr=unknown_jaxpr, in_axis_resources=keep_where(in_axis_resources, unknown_ins) + residual_specs, out_axis_resources=keep_where(out_axis_resources, unknown_outs), resource_env=resource_env, donated_invars=keep_where(donated_invars, unknown_ins) + (False,) * num_residuals, name=name, in_positional_semantics=keep_where(in_positional_semantics, unknown_ins) + (out_positional_semantics,) * num_residuals, out_positional_semantics=out_positional_semantics)
A:jax.experimental.pjit.eqn->jax.interpreters.partial_eval.new_eqn_recipe((*unknown_tracers_in, *residual_tracers), unknown_tracers_out, pjit_p, unknown_params, unknown_jaxpr.effects, source_info_util.current())
A:jax.experimental.pjit.body->jax.linear_util.hashable_partial(body, jaxpr, reduce_axes, False)
A:jax.experimental.pjit.(primals_and_nz_cts_in, in_treedef)->tree_flatten((primals_in, cts_in))
A:jax.experimental.pjit.(body, cts_out_treedef_thunk)->flatten_fun_nokwargs(body, in_treedef)
A:jax.experimental.pjit.global_cts_in_avals->local_to_global(transpose_in_positional_semantics, mesh, [core.raise_to_shaped(core.get_aval(ct)) for ct in primals_and_nz_cts_in], transpose_in_axis_resources)
A:jax.experimental.pjit.(transpose_jaxpr, global_cts_out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(body, global_cts_in_avals)
A:jax.experimental.pjit.transpose_jaxpr->jax.core.ClosedJaxpr(transpose_jaxpr, consts)
A:jax.experimental.pjit.cts_out_treedef->cts_out_treedef_thunk()
A:jax.experimental.pjit.transpose_out_axis_resources->prune_type(ad.Zero, in_axis_resources, tree_unflatten(cts_out_treedef, [object()] * cts_out_treedef.num_leaves))
A:jax.experimental.pjit.nz_cts_out->jax.core.Primitive('pjit').bind(*primals_and_nz_cts_in, jaxpr=transpose_jaxpr, in_axis_resources=transpose_in_axis_resources, out_axis_resources=transpose_out_axis_resources, resource_env=resource_env, donated_invars=(False,) * len(primals_and_nz_cts_in), name=name, in_positional_semantics=transpose_in_positional_semantics, out_positional_semantics=out_positional_semantics)
A:jax.experimental.pjit.pjit_resources->set(it.chain.from_iterable([d for d in pos_axis_resources if d is not None]))
A:jax.experimental.pjit.aval_resources->set(it.chain.from_iterable((named_axis_resources[a] for a in aval.named_shape)))
A:jax.experimental.pjit.(x_flat, tree)->tree_flatten(x)
A:jax.experimental.pjit.(parsed_axis_resources, entries, _, _)->_prepare_axis_resources(axis_resources, 'axis_resources', allow_unconstrained_dims=True)
A:jax.experimental.pjit.axis_resources_flat->tuple(flatten_axes('with_sharding_constraint axis_resources', tree, parsed_axis_resources))
A:jax.experimental.pjit.sharding_constraint_p->jax.core.Primitive('sharding_constraint')
A:jax.experimental.pjit.y->jax.core.Primitive('sharding_constraint').bind(x, axis_resources=axis_resources.insert_axis_partitions(d, new_parts), resource_env=resource_env)
A:jax.experimental.pjit.batching.axis_primitive_batchers[sharding_constraint_p]->partial(_sharding_constraint_batcher, False)
A:jax.experimental.pjit.pxla.spmd_primitive_batchers[sharding_constraint_p]->partial(_sharding_constraint_batcher, True)
A:jax.experimental.pjit.array_mapping->get_array_mapping(axis_resources)
A:jax.experimental.pjit.sharding_spec->jax.interpreters.pxla.mesh_sharding_specs(mesh.shape, mesh.axis_names, allow_uneven_axes=True)(aval, array_mapping)
A:jax.experimental.pjit.gda_cpspec->CanonicalizedParsedPartitionSpec(ParsedPartitionSpec.from_user_input(arg.mesh_axes, arg_name='GDA mesh_axes'))
A:jax.experimental.pjit.sizes->numpy.fromiter(named_sizes.values(), dtype=np.int64)
A:jax.experimental.pjit.strides->strides_for_sizes(sizes)
A:jax.experimental.pjit.dims->list(reversed(dims))
A:jax.experimental.pjit.flat_assignment->numpy.asarray(assignment, dtype=np.int64)
A:jax.experimental.pjit.mesh_axis_order->unflatten_array(mesh.shape, op_sharding.tile_assignment_devices)
A:jax.experimental.pjit.mesh_axis->iter(mesh_axis_order)
A:jax.experimental.pjit.axis->next(mesh_axis)
A:jax.experimental.pjit.out_ppspec->parse_flatten_op_sharding(output_op_sharding, mesh)
A:jax.experimental.pjit.(in_ppspec, out_ppspec)->_get_ppspec_from_executable(executable, mesh)
A:jax.experimental.pjit.out_partition_spec->_get_partition_spec(out_ppspec)
A:jax.experimental.pjit.in_partition_spec->_get_partition_spec(in_ppspec)
jax.experimental.pjit.CanonicalizedParsedPartitionSpec(self,parsed_pspec:ParsedPartitionSpec)
jax.experimental.pjit.CanonicalizedParsedPartitionSpec.__init__(self,parsed_pspec:ParsedPartitionSpec)
jax.experimental.pjit.CanonicalizedParsedPartitionSpec.__repr__(self)
jax.experimental.pjit.ParsedPartitionSpec(self,user_spec,partitions,sync=SpecSync.IN_SYNC)
jax.experimental.pjit.ParsedPartitionSpec.__eq__(self,other)
jax.experimental.pjit.ParsedPartitionSpec.__getitem__(self,i)
jax.experimental.pjit.ParsedPartitionSpec.__hash__(self)
jax.experimental.pjit.ParsedPartitionSpec.__init__(self,user_spec,partitions,sync=SpecSync.IN_SYNC)
jax.experimental.pjit.ParsedPartitionSpec.__iter__(self)
jax.experimental.pjit.ParsedPartitionSpec.__len__(self)
jax.experimental.pjit.ParsedPartitionSpec.__repr__(self)
jax.experimental.pjit.ParsedPartitionSpec.from_user_input(cls,entry,arg_name,allow_unconstrained_dims=False)
jax.experimental.pjit.ParsedPartitionSpec.insert_axis_partitions(self,dim,val)
jax.experimental.pjit.ParsedPartitionSpec.unsynced_user_spec(self,min_sync)
jax.experimental.pjit.ParsedPartitionSpec.user_spec(self)
jax.experimental.pjit.PytreeLeaf
jax.experimental.pjit.PytreeLeaf.__repr__(self)
jax.experimental.pjit.SpecSync(IntEnum)
jax.experimental.pjit._FromGdaSingleton
jax.experimental.pjit._ListWithW(list)
jax.experimental.pjit._calc_is_global_sequence(in_positional_semantics,in_axis_resources)
jax.experimental.pjit._check_resources_against_named_axes(what,aval,pos_axis_resources,named_axis_resources)
jax.experimental.pjit._check_resources_mismatch(in_axis_resources_flat,is_gda)
jax.experimental.pjit._check_shapes_against_resources(what:str,is_global_shape:bool,mesh_shape,flat_avals,flat_axis_resources,allow_uneven_sharding:bool)
jax.experimental.pjit._check_unique_resources(axis_resources,arg_name)
jax.experimental.pjit._create_cpspec(x)
jax.experimental.pjit._get_in_positional_semantics(global_avals:bool,arg)->maps._PositionalSemantics
jax.experimental.pjit._get_partition_spec(ppspec:Sequence[ParsedPartitionSpec])->Sequence[PartitionSpec]
jax.experimental.pjit._get_ppspec_from_executable(executable,mesh)->Tuple[Sequence[ParsedPartitionSpec], Sequence[ParsedPartitionSpec]]
jax.experimental.pjit._get_sharding_from_executable(executable,mesh:pxla.Mesh)->Tuple[Tuple[PartitionSpec, ...], Tuple[PartitionSpec, ...]]
jax.experimental.pjit._is_from_gda(x)
jax.experimental.pjit._maybe_check_pjit_gda_mesh(args,mesh)
jax.experimental.pjit._maybe_replace_from_gda_with_pspec(in_axis_resources_flat:Union[CanonicalizedParsedPartitionSpec,_AUTOAxisResource],arg)->Union[CanonicalizedParsedPartitionSpec, _AUTOAxisResource]
jax.experimental.pjit._pjit_abstract_eval(*args,jaxpr,out_axis_resources,resource_env,out_positional_semantics,**_)
jax.experimental.pjit._pjit_batcher(insert_axis,axis_size,axis_name,main_type,vals_in,dims_in,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,name,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._pjit_call_impl(*args,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,name,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._pjit_jaxpr(fun,mesh,global_in_avals,out_tree,out_axis_resources_thunk)
jax.experimental.pjit._pjit_jvp(primals_in,tangents_in,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,name,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._pjit_lower(jaxpr:core.ClosedJaxpr,in_axis_resources:Tuple[CanonicalizedParsedPartitionSpec,...],out_axis_resources:Tuple[CanonicalizedParsedPartitionSpec,...],resource_env,donated_invars,name:str,in_is_global:Sequence[bool])
jax.experimental.pjit._pjit_lowering(ctx,*args,name,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._pjit_partial_eval(trace,*in_tracers,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,name,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._pjit_translation_rule(ctx,avals_in,avals_out,*in_nodes,name,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._pjit_transpose(reduce_axes,cts_in,*primals_in,jaxpr,in_axis_resources,out_axis_resources,resource_env,donated_invars,name,in_positional_semantics,out_positional_semantics)
jax.experimental.pjit._prepare_axis_resources(axis_resources,arg_name,allow_unconstrained_dims=False)
jax.experimental.pjit._process_in_axis_resources(mesh,local_in_avals,in_axis_resources_thunk,in_tree,in_positional_semantics,is_gda)
jax.experimental.pjit._resource_typing_pjit(avals,params,source_info,resource_env,named_axis_resources)
jax.experimental.pjit._resource_typing_sharding_constraint(avals,params,source_info,resource_env,named_axis_resources)
jax.experimental.pjit._sharding_constraint_batcher(insert_axis,axis_size,axis_name,main_type,vals_in,dims_in,axis_resources,resource_env)
jax.experimental.pjit._sharding_constraint_impl(x,axis_resources,resource_env)
jax.experimental.pjit._sharding_constraint_mhlo_lowering(ctx,x_node,*,axis_resources,resource_env)
jax.experimental.pjit._sharding_constraint_translation_rule(ctx,avals_in,avals_out,x_node,*,axis_resources,resource_env)
jax.experimental.pjit.explode_superdims(sizes,dims)
jax.experimental.pjit.flatten_axis_resources(what,tree,axis_resources,tupled_args)
jax.experimental.pjit.get_array_mapping(axis_resources:Union[ParsedPartitionSpec,_AUTOAxisResource])->pxla.ArrayMappingOrAuto
jax.experimental.pjit.get_aval_sharding_proto(aval:core.AbstractValue,axis_resources:ParsedPartitionSpec,mesh:maps.Mesh,axis_ctx:Optional[mlir.SPMDAxisContext]=None,allow_uneven_axes:bool=False)->xc.OpSharding
jax.experimental.pjit.get_unconstrained_dims(axis_resources:ParsedPartitionSpec)
jax.experimental.pjit.global_to_local(positional_semantics,mesh,avals,axes)
jax.experimental.pjit.hashable_pytree(pytree)
jax.experimental.pjit.local_to_global(positional_semantics,mesh,avals,axes)
jax.experimental.pjit.parse_flatten_op_sharding(op_sharding:xc.OpSharding,mesh:pxla.Mesh)->Sequence[ParsedPartitionSpec]
jax.experimental.pjit.pjit(fun:Callable,in_axis_resources,out_axis_resources,static_argnums:Union[int,Sequence[int]]=(),donate_argnums:Union[int,Sequence[int]]=())->stages.Wrapped
jax.experimental.pjit.strides_for_sizes(sizes)
jax.experimental.pjit.unflatten_array(named_sizes,assignment)
jax.experimental.pjit.unflatten_superdims(assignment)
jax.experimental.pjit.with_sharding_constraint(x,axis_resources)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jet.py----------------------------------------
A:jax.experimental.jet.(order,)->set(map(len, series))
A:jax.experimental.jet.treedef->tree_structure(t)
A:jax.experimental.jet.(f, out_tree)->flatten_fun_output(lu.wrap_init(fun))
A:jax.experimental.jet.(out_primals, out_terms)->unzip2(((t.primal, t.terms) for t in out_tracers))
A:jax.experimental.jet.trace->JetTrace(main, core.cur_sublevel())
A:jax.experimental.jet.in_tracers->map(partial(JetTracer, trace), primals, series)
A:jax.experimental.jet.out_tracers->map(trace.full_raise, ans)
A:jax.experimental.jet.(primals_in, series_in)->unzip2(((t.primal, t.terms) for t in tracers))
A:jax.experimental.jet.(out_flat, out_tree_def)->tree_flatten((primals_out, series_out))
A:jax.experimental.jet.(primal_out, terms_out)->rule(primals_in, series_in, **params)
A:jax.experimental.jet.(primals_and_series, in_tree_def)->tree_flatten((primals_in, series_in))
A:jax.experimental.jet.(f_jet, out_tree_def)->traceable(jet_subtrace(f, self.main), in_tree_def)
A:jax.experimental.jet.update_params->call_param_updaters.get(call_primitive)
A:jax.experimental.jet.result->call_primitive.bind(f_jet, *primals_and_series, **new_params)
A:jax.experimental.jet.(primals_out, series_out)->tree_unflatten(out_tree_def(), result)
A:jax.experimental.jet.(primals, series)->tree_unflatten(treedef, x)
A:jax.experimental.jet.(out, treedef)->tree_flatten((primals, series))
A:jax.experimental.jet.zero_term->ZeroTerm()
A:jax.experimental.jet.zero_series->ZeroSeries()
A:jax.experimental.jet.jet_rules[prim]->partial(jet, comp)
A:jax.experimental.jet.primal_out->bind(operand, scatter_indices, updates)
A:jax.experimental.jet.jet_rules[lax.cumprod_p]->partial(_cumulative_jet_rule, combine_fn=lax.mul)
A:jax.experimental.jet.jet_rules[lax.cummax_p]->partial(_cumulative_jet_rule, combine_fn=lax.max)
A:jax.experimental.jet.jet_rules[lax.cummin_p]->partial(_cumulative_jet_rule, combine_fn=lax.min)
A:jax.experimental.jet.(c0, cs)->jet(lambda x: lax.div(1, 1 + lax.square(x)), (x,), (series,))
A:jax.experimental.jet.k->len(series)
A:jax.experimental.jet.(x, series)->jet(lax.div, primals_in, series_in)
A:jax.experimental.jet.vu->sum((_scale(k, j) * v[k - j] * u[j] for j in range(1, k + 1)))
A:jax.experimental.jet.uv->sum((_scale(k, j) * u[k - j] * v[j] for j in range(1, k)))
A:jax.experimental.jet.v[k]->jax.numpy.where(x == 0, 0, fact(k - 1) * (y * vu - uv) / x)
A:jax.experimental.jet.(primal_out, series_out)->_expit_taylor((primals_in,), (series_in,))
A:jax.experimental.jet.conv->sum([scale(k, j) * v[j] * w[k - j] for j in range(0, k)])
A:jax.experimental.jet.jet_rules[lax.sin_p]->_get_ind(partial(_sinusoidal_rule, -1, (lax.sin, lax.cos)), 0)
A:jax.experimental.jet.jet_rules[lax.cos_p]->_get_ind(partial(_sinusoidal_rule, -1, (lax.sin, lax.cos)), 1)
A:jax.experimental.jet.jet_rules[lax.sinh_p]->_get_ind(partial(_sinusoidal_rule, 1, (lax.sinh, lax.cosh)), 0)
A:jax.experimental.jet.jet_rules[lax.cosh_p]->_get_ind(partial(_sinusoidal_rule, 1, (lax.sinh, lax.cosh)), 1)
A:jax.experimental.jet.op->partial(prim.bind, **params)
A:jax.experimental.jet.jet_rules[lax.dot_general_p]->partial(_bilinear_taylor_rule, lax.dot_general_p)
A:jax.experimental.jet.jet_rules[lax.mul_p]->partial(_bilinear_taylor_rule, lax.mul_p)
A:jax.experimental.jet.jet_rules[lax.conv_general_dilated_p]->partial(_bilinear_taylor_rule, lax.conv_general_dilated_p)
A:jax.experimental.jet.axes->params.pop('axes', None)
A:jax.experimental.jet.location_indicators->jax.lax.convert_element_type(lax_internal._eq_meet(operand, lax.reshape(primal_out, shape)), primal_dtype)
A:jax.experimental.jet.counts->jax._src.lax.lax._reduce_sum(location_indicators, axes)
A:jax.experimental.jet.jet_rules[lax.reduce_max_p]->_gen_reduce_choose_taylor_rule(lax_internal._reduce_max)
A:jax.experimental.jet.jet_rules[lax.reduce_min_p]->_gen_reduce_choose_taylor_rule(lax_internal._reduce_min)
A:jax.experimental.jet.zero->jax.lax.full_like(x, 0, shape=())
A:jax.experimental.jet.negs->jax.lax.select(lax.lt(x, zero), lax.full_like(x, -1), lax.full_like(x, 1.0))
A:jax.experimental.jet.max_i->jax.lax.select(xey, (x_i + y_i) / 2, max_i)
A:jax.experimental.jet.min_i->jax.lax.select(xey, (x_i + y_i) / 2, min_i)
A:jax.experimental.jet.bind->partial(lax.scatter_add_p.bind, update_jaxpr=update_jaxpr, update_consts=update_consts, dimension_numbers=dimension_numbers, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)
jax.experimental.jet.JetTrace(core.Trace)
jax.experimental.jet.JetTrace.lift(self,val)
jax.experimental.jet.JetTrace.post_process_call(self,call_primitive,out_tracers,params)
jax.experimental.jet.JetTrace.process_call(self,call_primitive,f,tracers,params)
jax.experimental.jet.JetTrace.process_custom_jvp_call(self,primitive,fun,jvp,tracers)
jax.experimental.jet.JetTrace.process_custom_vjp_call(self,primitive,fun,fwd,bwd,tracers,out_trees)
jax.experimental.jet.JetTrace.process_primitive(self,primitive,tracers,params)
jax.experimental.jet.JetTrace.pure(self,val)
jax.experimental.jet.JetTrace.sublift(self,val)
jax.experimental.jet.JetTracer(self,trace,primal,terms)
jax.experimental.jet.JetTracer.__init__(self,trace,primal,terms)
jax.experimental.jet.JetTracer.aval(self)
jax.experimental.jet.JetTracer.full_lower(self)
jax.experimental.jet.ZeroSeries
jax.experimental.jet.ZeroTerm
jax.experimental.jet._abs_taylor_rule(x,series_in,**params)
jax.experimental.jet._atan2_taylor(primals_in,series_in)
jax.experimental.jet._bilinear_taylor_rule(prim,primals_in,series_in,**params)
jax.experimental.jet._cumulative_jet_rule(primals_in,series_in,*,axis:int,reverse:bool,combine_fn:Callable)
jax.experimental.jet._custom_jvp_call_jaxpr_rule(primals_in,series_in,*,fun_jaxpr,jvp_jaxpr_thunk)
jax.experimental.jet._div_taylor_rule(primals_in,series_in)
jax.experimental.jet._erf_inv_rule(primals_in,series_in)
jax.experimental.jet._exp_taylor(primals_in,series_in)
jax.experimental.jet._expit_taylor(primals_in,series_in)
jax.experimental.jet._gather_taylor_rule(primals_in,series_in,**params)
jax.experimental.jet._gen_reduce_choose_taylor_rule(chooser_fun)
jax.experimental.jet._get_ind(f,ind)
jax.experimental.jet._integer_pow_taylor(primals_in,series_in,*,y)
jax.experimental.jet._lax_max_taylor_rule(primal_in,series_in)
jax.experimental.jet._lax_min_taylor_rule(primal_in,series_in)
jax.experimental.jet._log_taylor(primals_in,series_in)
jax.experimental.jet._pow_taylor(primals_in,series_in)
jax.experimental.jet._scale(k,j)
jax.experimental.jet._scale2(k,j)
jax.experimental.jet._scatter_add_rule(primals_in,series_in,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax.experimental.jet._select_n_taylor_rule(primal_in,series_in,**params)
jax.experimental.jet._sinusoidal_rule(sign,prims,primals_in,series_in)
jax.experimental.jet._tanh_taylor(primals_in,series_in)
jax.experimental.jet._xla_call_param_updater(params,num_inputs)
jax.experimental.jet.def_comp(prim,comp)
jax.experimental.jet.def_deriv(prim,deriv)
jax.experimental.jet.deflinear(prim)
jax.experimental.jet.defzero(prim)
jax.experimental.jet.deriv_prop(prim,deriv,primals_in,series_in)
jax.experimental.jet.fact(n)
jax.experimental.jet.jet(fun,primals,series)
jax.experimental.jet.jet_fun(order,primals,series)
jax.experimental.jet.jet_subtrace(main,primals,series)
jax.experimental.jet.linear_prop(prim,primals_in,series_in,**params)
jax.experimental.jet.traceable(in_tree_def,*primals_and_series)
jax.experimental.jet.zero_prop(prim,primals_in,series_in,**params)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/global_device_array.py----------------------------------------
A:jax.experimental.global_device_array.(parsed_pspec, _, _, _)->_prepare_axis_resources(mesh_axes, 'GDA mesh_axes')
A:jax.experimental.global_device_array.array_mapping->_get_array_mapping(mesh_axes)
A:jax.experimental.global_device_array.aval->jax.core.ShapedArray(global_shape, np.float32)
A:jax.experimental.global_device_array.sharding_spec->_get_sharding_spec(global_shape, global_mesh, mesh_axes)
A:jax.experimental.global_device_array.indices->_get_indices(global_shape, global_mesh, mesh_axes)
A:jax.experimental.global_device_array.h_index->_hashed_index(index)
A:jax.experimental.global_device_array.shard_shape->get_shard_shape(global_shape, global_mesh, mesh_axes)
A:jax.experimental.global_device_array.expected_unique_shards->prod([g // s for (g, s) in safe_zip(global_shape, shard_shape) if g != 0 or s != 0])
A:jax.experimental.global_device_array.m->prod([global_mesh.shape[ma] for ma in mesh_axis])
A:jax.experimental.global_device_array.val.aval->jax.core.ShapedArray(val.shape, val.dtype)
A:jax.experimental.global_device_array.self._current_process->jax._src.lib.xla_bridge.process_index()
A:jax.experimental.global_device_array.ss->get_shard_shape(self._global_shape, self._global_mesh, self.mesh_axes)
A:jax.experimental.global_device_array.global_indices_rid->get_shard_indices_replica_ids(global_shape, global_mesh, mesh_axes)
A:jax.experimental.global_device_array.db->_set_aval(db)
A:jax.experimental.global_device_array.device->_set_aval(db).device()
A:jax.experimental.global_device_array.device_to_buffer->dict(((db.device(), db) for db in self._device_buffers))
A:jax.experimental.global_device_array.buf.aval->jax.core.ShapedArray(buf.shape, buf.dtype)
A:jax.experimental.global_device_array.sh->Shard(device, index, rid, buf)
A:jax.experimental.global_device_array.local_arrays->data_callback(local_indices)
A:jax.experimental.global_device_array.dbs->data_callback(cb_inp)
A:jax.experimental.global_device_array.global_idx_rid->get_shard_indices_replica_ids(global_aval.shape, global_mesh, out_axis_resources)
A:jax.experimental.global_device_array.fast_path_args->_GdaFastPathArgs(global_idx_rid, local_devices)
jax.experimental.global_device_array.GlobalDeviceArray(self,global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes,device_buffers:Sequence[DeviceArray],_gda_fast_path_args:Optional[_GdaFastPathArgs]=None,_enable_checks:bool=True)
jax.experimental.global_device_array.GlobalDeviceArray.__eq__(self,other:object)
jax.experimental.global_device_array.GlobalDeviceArray.__init__(self,global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes,device_buffers:Sequence[DeviceArray],_gda_fast_path_args:Optional[_GdaFastPathArgs]=None,_enable_checks:bool=True)
jax.experimental.global_device_array.GlobalDeviceArray.__repr__(self)
jax.experimental.global_device_array.GlobalDeviceArray.__str__(self)
jax.experimental.global_device_array.GlobalDeviceArray._create_local_shards(self)->Sequence[Shard]
jax.experimental.global_device_array.GlobalDeviceArray.block_until_ready(self)
jax.experimental.global_device_array.GlobalDeviceArray.from_batched_callback(cls,global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes,data_callback:Callable[[Sequence[Index]],Sequence[ArrayLike]])
jax.experimental.global_device_array.GlobalDeviceArray.from_batched_callback_with_devices(cls,global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes,data_callback:Callable[[Sequence[Tuple[Index,Tuple[Device,...]]]],Sequence[DeviceArray]])
jax.experimental.global_device_array.GlobalDeviceArray.from_callback(cls,global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes,data_callback:Callable[[Index],ArrayLike])
jax.experimental.global_device_array.GlobalDeviceArray.global_shards(self)->Sequence[Shard]
jax.experimental.global_device_array.GlobalDeviceArray.is_fully_replicated(self)->bool
jax.experimental.global_device_array.GlobalDeviceArray.local_data(self,index)->DeviceArray
jax.experimental.global_device_array.GlobalDeviceArray.local_shards(self)->Sequence[Shard]
jax.experimental.global_device_array.GlobalDeviceArray.mesh(self)
jax.experimental.global_device_array.GlobalDeviceArray.mesh_axes(self)->MeshAxes
jax.experimental.global_device_array.GlobalDeviceArray.ndim(self)
jax.experimental.global_device_array.GlobalDeviceArray.shape(self)->Shape
jax.experimental.global_device_array.GlobalDeviceArray.size(self)
jax.experimental.global_device_array.Shard
jax.experimental.global_device_array._GdaFastPathArgs(NamedTuple)
jax.experimental.global_device_array._convert_list_args_to_tuple(f)
jax.experimental.global_device_array._gda_array_result_handler(global_aval,out_axis_resources,global_mesh)
jax.experimental.global_device_array._gda_shard_arg(x,devices,indices)
jax.experimental.global_device_array._get_array_mapping(mesh_axes)
jax.experimental.global_device_array._get_indices(global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes)->Tuple[Index, ...]
jax.experimental.global_device_array._get_shard_indices_replica_ids_uncached(global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes)->Mapping[Device, Tuple[Index, int]]
jax.experimental.global_device_array._get_sharding_spec(global_shape,global_mesh,mesh_axes)
jax.experimental.global_device_array._set_aval(val)
jax.experimental.global_device_array.get_shard_indices(global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes)->Mapping[Device, Index]
jax.experimental.global_device_array.get_shard_indices_replica_ids(global_shape:Shape,global_mesh:pxla.Mesh,mesh_axes:MeshAxes)->Mapping[Device, Tuple[Index, int]]
jax.experimental.global_device_array.get_shard_shape(global_shape,global_mesh,mesh_axes)->Shape


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/optimizers.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/stax.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/host_callback.py----------------------------------------
A:jax.experimental.host_callback.(flat_results, result_treedef)->jax._src.lib.pytree.flatten(result)
A:jax.experimental.host_callback.call_res->_call(tap_func, arg, call_with_device=tap_with_device, result_shape=None, identity=True)
A:jax.experimental.host_callback.(call_flat_results, _)->jax._src.lib.pytree.flatten(call_res)
A:jax.experimental.host_callback.printer->functools.partial(_print_tap_func, output_stream=output_stream, threshold=threshold, **kwargs)
A:jax.experimental.host_callback.(flat_args, arg_treedef)->jax._src.lib.pytree.flatten(arg)
A:jax.experimental.host_callback.params['callback']->_CallbackWrapper(callback_func, identity, call_with_device)
A:jax.experimental.host_callback.(flat_results_shape, result_treedef)->jax._src.lib.pytree.flatten(result_shape)
A:jax.experimental.host_callback.params['flat_results_aval']->tuple(flat_results_aval)
A:jax.experimental.host_callback.flat_results->jax.core.Primitive('outside_call').bind(*flat_args, **params)
A:jax.experimental.host_callback._print_tap_lock->threading.Lock()
A:jax.experimental.host_callback.kv_pairs->' '.join([f'{k}: {v}' for (k, v) in sorted(kwargs.items())])
A:jax.experimental.host_callback.id_tap_dep_p->jax.core.Primitive('id_tap_dep')
A:jax.experimental.host_callback.tangents_instantiated->tuple(map(_instantiate_zeros, tangents, primals))
A:jax.experimental.host_callback.ct_res->_instantiate_zeros(cts, arg_res)
A:jax.experimental.host_callback.ct_tap->jax.interpreters.ad.Zero(arg_tap.aval)
A:jax.experimental.host_callback.outside_call_p->jax.core.Primitive('outside_call')
A:jax.experimental.host_callback.results->list(args_to_outfeed)
A:jax.experimental.host_callback.non_empty_flat_results_aval->list(filter(lambda aval: not _aval_is_empty(aval), flat_results_aval))
A:jax.experimental.host_callback.use_outfeed->_use_outfeed(ctx.platform)
A:jax.experimental.host_callback.callback_id->_CallbackHandlerData().callback_registry.get(callback)
A:jax.experimental.host_callback.next_token->_CallbackHandlerData().receiver.add_outfeed(comp, current_token, callback_id, args_to_outfeed)
A:jax.experimental.host_callback.after_outfeed_itoken->xops.AfterAll(comp, [current_itoken, next_token])
A:jax.experimental.host_callback.array_sharding_proto->jax._src.lib.xla_client.OpSharding()
A:jax.experimental.host_callback.token_sharding_proto->jax._src.lib.xla_client.OpSharding()
A:jax.experimental.host_callback.infeed_sharding_proto->jax.interpreters.xla.tuple_sharding_proto([array_sharding_proto] * len(non_empty_flat_results_aval) + [token_sharding_proto])
A:jax.experimental.host_callback.build_infeed->functools.partial(xops.InfeedWithToken, after_outfeed_itoken, xla_client.Shape.tuple_shape(shape))
A:jax.experimental.host_callback.outs_and_token->jax.interpreters.xla.with_sharding_proto(comp, infeed_sharding_proto, build_infeed)
A:jax.experimental.host_callback.outs->xops.GetTupleElement(outs_and_token, 0)
A:jax.experimental.host_callback.next_itoken->xops.GetTupleElement(outs_and_token, 1)
A:jax.experimental.host_callback.replica_id->jax._src.lib.xla_client.ops.ReplicaId(comp)
A:jax.experimental.host_callback.result_arrays->_outside_call_run_callback(arrays, xb.local_devices()[replica_id], send_infeed=False, identity=identity, flat_results_aval=flat_results_aval, **params)
A:jax.experimental.host_callback.backend->jax._src.lib.xla_bridge.get_backend(ctx.platform)
A:jax.experimental.host_callback.(token_and_results_op, keep_alive)->jax._src.lib.xla_bridge.get_backend(ctx.platform).emit_python_callback(wrapped_callback, comp, callback_operands, result_shapes, operand_layouts=None, has_side_effects=True)
A:jax.experimental.host_callback.arg->jax._src.api.tree_unflatten(arg_treedef, arrays)
A:jax.experimental.host_callback.unpacked_transforms->_unpack_transforms(transforms)
A:jax.experimental.host_callback.res->jax.core.Primitive('outside_call').bind(*batched_args, **new_params)
A:jax.experimental.host_callback.(actual_flat_results, actual_result_treedef)->jax._src.lib.pytree.flatten(res)
A:jax.experimental.host_callback.canonical_flat_results->tuple(util.safe_map(xla.canonicalize_dtype, actual_flat_results))
A:jax.experimental.host_callback.actual_flat_results_aval->_values_to_avals(canonical_flat_results)
A:jax.experimental.host_callback.non_empty_canonical_flat_results->tuple(filter(lambda r: not _aval_is_empty(r), canonical_flat_results))
A:jax.experimental.host_callback.aval->jax.core.raise_to_shaped(core.get_aval(arg))
A:jax.experimental.host_callback.(jvp_flat_args, jvp_arg_treedef)->jax._src.api.tree_flatten((arg_treedef.unflatten(primals), arg_treedef.unflatten(tangents_instantiated)))
A:jax.experimental.host_callback.out_all->jax.core.Primitive('outside_call').bind(*jvp_flat_args, **dict(_add_transform(params, 'jvp'), arg_treedef=jvp_arg_treedef))
A:jax.experimental.host_callback.(out_primals_tapped, out_tangents_tapped)->jax._src.util.split_list(out_all, [len(primals)])
A:jax.experimental.host_callback.out_primals_tapped->jax.core.Primitive('outside_call').bind(*primals, **params)
A:jax.experimental.host_callback.transforms->params.get('transforms', ())
A:jax.experimental.host_callback.(primals, tangents)->jax._src.util.split_list(args, [nr_primals])
A:jax.experimental.host_callback.all_primals_known->all((p.is_known() for p in primals))
A:jax.experimental.host_callback.some_tangents_unknown->any((not t.is_known() for t in tangents))
A:jax.experimental.host_callback.(prims, _)->params['arg_treedef'].unflatten(args)
A:jax.experimental.host_callback.(_, primals_treedef)->jax._src.api.tree_flatten(prims)
A:jax.experimental.host_callback.outs_known->trace.default_process_primitive(outside_call_p, primals, dict(params, arg_treedef=primals_treedef, transforms=transforms[:-1]))
A:jax.experimental.host_callback.outs_all_unknown->trace.default_process_primitive(outside_call_p, args, params)
A:jax.experimental.host_callback.(outs_primals_unknown, outs_tangents_unknown)->jax._src.util.split_list(outs_all_unknown, [nr_primals])
A:jax.experimental.host_callback.cts_instantiated->tuple(map(_instantiate_zeros, cts, args))
A:jax.experimental.host_callback.(args_unflat, tan_unflat)->params['arg_treedef'].unflatten(args)
A:jax.experimental.host_callback.(_, vjp_arg_treedef)->jax._src.api.tree_flatten(args_unflat)
A:jax.experimental.host_callback.(cts_primals, cts_tangents)->jax._src.util.split_list(cts_instantiated, [nr_primals])
A:jax.experimental.host_callback.cts_tangents_through_tap->jax.core.Primitive('outside_call').bind(*cts_tangents, **dict(_add_transform(params, 'transpose'), arg_treedef=vjp_arg_treedef))
A:jax.experimental.host_callback.new_params->_add_transform(params, 'batch', batch_dims)
A:jax.experimental.host_callback.(packed_operands, packed_arg_tree)->jax._src.api.tree_flatten((api.tree_unflatten(arg_treedef, operands), api.tree_unflatten(arg_treedef, operands_logical_shapes)))
A:jax.experimental.host_callback.packed_results->jax.core.Primitive('outside_call').bind(*packed_operands, **dict(_add_transform(params, 'mask'), arg_treedef=packed_arg_tree))
A:jax.experimental.host_callback.new_jaxpr->_rewrite_closed_jaxpr(carry_jaxpr, True, True)
A:jax.experimental.host_callback.mk_new_var->jax.core.gensym([jaxpr])
A:jax.experimental.host_callback.last_token_var->mk_new_var(core.abstract_token)
A:jax.experimental.host_callback.last_itoken_var->mk_new_var(core.abstract_token)
A:jax.experimental.host_callback.output_token_var->mk_new_var(last_token_var.aval)
A:jax.experimental.host_callback.output_itoken_var->mk_new_var(last_itoken_var.aval)
A:jax.experimental.host_callback.(cond_jaxpr, _, body_jaxpr, _)->jax._src.util.split_dict(eqn.params, ['cond_jaxpr', 'cond_nconsts', 'body_jaxpr', 'body_nconsts'])
A:jax.experimental.host_callback.(branches, linear)->jax._src.util.split_dict(eqn.params, ['branches', 'linear'])
A:jax.experimental.host_callback.(num_consts, num_carry, carry_jaxpr, linear, _, _, _)->jax._src.util.split_dict(eqn.params, ['num_consts', 'num_carry', 'jaxpr', 'linear', 'reverse', 'length', 'unroll'])
A:jax.experimental.host_callback.call_jaxpr->cast(core.Jaxpr, eqn.params['call_jaxpr'])
A:jax.experimental.host_callback.jaxpr->cast(core.ClosedJaxpr, eqn.params['jaxpr'])
A:jax.experimental.host_callback.(cond_jaxpr, cond_nconsts, body_jaxpr, body_nconsts)->jax._src.util.split_dict(eqn.params, ['cond_jaxpr', 'cond_nconsts', 'body_jaxpr', 'body_nconsts'])
A:jax.experimental.host_callback.transformed_cond_jaxpr->_rewrite_closed_jaxpr(cond_jaxpr, True, True)
A:jax.experimental.host_callback.new_cond_pred_invar->mk_new_var(cond_jaxpr.out_avals[0])
A:jax.experimental.host_callback.new_cond_jaxpr->jax.core.ClosedJaxpr(core.Jaxpr([], new_cond_invars, [new_cond_pred_invar], [], set()), [])
A:jax.experimental.host_callback.transformed_body_jaxpr->_rewrite_closed_jaxpr(body_jaxpr, True, True)
A:jax.experimental.host_callback.new_body_invars_pred->mk_new_var(cond_jaxpr.out_avals[0])
A:jax.experimental.host_callback.new_body_invars_token->mk_new_var(input_token_var.aval)
A:jax.experimental.host_callback.new_body_invars_itoken->mk_new_var(input_itoken_var.aval)
A:jax.experimental.host_callback.new_body_token2->mk_new_var(input_token_var.aval)
A:jax.experimental.host_callback.new_body_itoken2->mk_new_var(input_itoken_var.aval)
A:jax.experimental.host_callback.new_body_pred2->mk_new_var(cond_jaxpr.out_avals[0])
A:jax.experimental.host_callback.new_body_token3->mk_new_var(input_token_var.aval)
A:jax.experimental.host_callback.new_body_itoken3->mk_new_var(input_itoken_var.aval)
A:jax.experimental.host_callback.effects->jax.core.join_effects(*(eqn.effects for eqn in new_body_eqns))
A:jax.experimental.host_callback.new_body_jaxpr->jax.core.ClosedJaxpr(core.Jaxpr([], new_body_invars_cond_constvars + new_body_invars_body_constvars + [new_body_invars_pred] + new_body_invars_carry + [new_body_invars_token, new_body_invars_itoken], [new_body_pred2] + new_body_carry2 + [new_body_token3, new_body_itoken3], new_body_eqns, effects), [])
A:jax.experimental.host_callback.pred_out->mk_new_var(cond_jaxpr.out_avals[0])
A:jax.experimental.host_callback.id_p->jax.core.Primitive('id')
A:jax.experimental.host_callback.self.lock->threading.Lock()
A:jax.experimental.host_callback.self.callback_registry->dict()
A:jax.experimental.host_callback.self.callback_registry_by_id->dict()
A:jax.experimental.host_callback._callback_handler_data->_CallbackHandlerData()
A:jax.experimental.host_callback.callback->_CallbackHandlerData().callback_registry_by_id.get(consumer_id)
A:jax.experimental.host_callback.formatted_e->traceback.format_exc()
A:jax.experimental.host_callback.devices->list(itertools.chain(*[backend.local_devices() for backend in clients]))
A:jax.experimental.host_callback.devices_with_outfeed->list(itertools.chain(*[backend.local_devices() for backend in clients_with_outfeed]))
A:jax.experimental.host_callback._callback_handler_data.receiver->outfeed_receiver_module.start(_callback_input_received, tuple(clients_with_outfeed), max_callback_queue_size_bytes)
A:jax.experimental.host_callback.lock->threading.Lock()
A:jax.experimental.host_callback.cv->threading.Condition(lock=lock)
A:jax.experimental.host_callback.x_on_dev->jax._src.api.device_put(d_idx, device=d)
jax.experimental.host_callback.CallbackException(Exception)
jax.experimental.host_callback._CallbackHandlerData(self)
jax.experimental.host_callback._CallbackHandlerData.__init__(self)
jax.experimental.host_callback._CallbackHandlerData.stop(self)
jax.experimental.host_callback._CallbackWrapper(self,callback_func,identity,call_with_device)
jax.experimental.host_callback._CallbackWrapper.__eq__(self,other)
jax.experimental.host_callback._CallbackWrapper.__hash__(self)
jax.experimental.host_callback._CallbackWrapper.__init__(self,callback_func,identity,call_with_device)
jax.experimental.host_callback._add_transform(params:Dict,name:str,*transform_params)->Dict
jax.experimental.host_callback._aval_is_empty(aval)->bool
jax.experimental.host_callback._call(callback_func:Callable,arg,*,result_shape=None,call_with_device=False,identity=False)
jax.experimental.host_callback._callback_input_received(device,consumer_id,arrays:Tuple)
jax.experimental.host_callback._id_tap_dep_batching_rule(batched_args,batch_dims)
jax.experimental.host_callback._id_tap_dep_jvp_rule(primals,tangents)
jax.experimental.host_callback._id_tap_dep_masking_rule(operands,operands_logical_shapes)
jax.experimental.host_callback._id_tap_dep_transpose_rule(cts,arg_res,arg_tap)
jax.experimental.host_callback._initialize_outfeed_receiver(max_callback_queue_size_bytes:int=int(256*1000000.0))
jax.experimental.host_callback._inline_host_callback()->bool
jax.experimental.host_callback._instantiate_zeros(tan,arg)
jax.experimental.host_callback._outside_call_abstract_eval(*args_a:pe.AbstractValue,identity,**params)->Sequence[pe.AbstractValue]
jax.experimental.host_callback._outside_call_batching_rule(batched_args,batch_dims,**params)
jax.experimental.host_callback._outside_call_impl(*args,**params)
jax.experimental.host_callback._outside_call_jvp_rule(primals,tangents,**params)
jax.experimental.host_callback._outside_call_masking_rule(operands,operands_logical_shapes,**params)
jax.experimental.host_callback._outside_call_partial_eval_rule(trace,*args,**params)
jax.experimental.host_callback._outside_call_run_callback(arrays,device,*,send_infeed=True,callback,arg_treedef,identity,result_treedef=None,flat_results_aval=None,transforms=(),has_token=False)
jax.experimental.host_callback._outside_call_translation_rule(ctx,avals_in,avals_out,*args_op:XlaOp,has_token,identity,flat_results_aval=(),**params)
jax.experimental.host_callback._outside_call_transpose_rule(cts,*args,**params)
jax.experimental.host_callback._print_tap_func(arg,transforms,*,device=None,output_stream=None,threshold=1024,**kwargs)
jax.experimental.host_callback._register_callback(callback:Callable)->int
jax.experimental.host_callback._rewrite_closed_jaxpr(cjaxpr:core.ClosedJaxpr,has_input_token:bool,has_output_token:bool)->core.ClosedJaxpr
jax.experimental.host_callback._rewrite_eqn(eqn:core.JaxprEqn,eqns:List[core.JaxprEqn],input_token_var:core.Var,output_token_var:core.Var,input_itoken_var:core.Var,output_itoken_var:core.Var,mk_new_var:Callable[[core.AbstractValue],core.Var])
jax.experimental.host_callback._rewrite_jaxpr(jaxpr:core.Jaxpr,has_input_token:bool,has_output_token:bool)->core.Jaxpr
jax.experimental.host_callback._rewrite_while_outfeed_cond(eqn:core.JaxprEqn,eqns:List[core.JaxprEqn],input_token_var:core.Var,output_token_var:core.Var,input_itoken_var:core.Var,output_itoken_var:core.Var,mk_new_var:Callable)
jax.experimental.host_callback._use_outfeed(platform:str)->bool
jax.experimental.host_callback._values_to_avals(vals)->Sequence[core.ShapedArray]
jax.experimental.host_callback.barrier_wait(logging_name:Optional[str]=None)
jax.experimental.host_callback.call(callback_func:Callable,arg,*,result_shape=None,call_with_device=False)
jax.experimental.host_callback.id_print(arg,*,result=None,tap_with_device=False,output_stream=None,threshold=None,**kwargs)
jax.experimental.host_callback.id_tap(tap_func,arg,*,result=None,tap_with_device=False,**kwargs)
jax.experimental.host_callback.stop_outfeed_receiver()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/x64_context.py----------------------------------------
jax.experimental.disable_x64()
jax.experimental.enable_x64(new_val:bool=True)
jax.experimental.x64_context.disable_x64()
jax.experimental.x64_context.enable_x64(new_val:bool=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/ode.py----------------------------------------
A:jax.experimental.ode.y->unravel(y_flat)
A:jax.experimental.ode.(ans_flat, _)->ravel_pytree(ans)
A:jax.experimental.ode.dps_c_mid->jax.numpy.array([6025192743 / 30085553152 / 2, 0, 51252292925 / 65400821598 / 2, -2691868925 / 45128329728 / 2, 187940372067 / 1594534317056 / 2, -1776094331 / 19743644256 / 2, 11237099 / 235043384 / 2], dtype=y0.dtype)
A:jax.experimental.ode.d0->jax.numpy.linalg.norm(y0 / scale)
A:jax.experimental.ode.d1->jax.numpy.linalg.norm(f0 / scale)
A:jax.experimental.ode.h0->jax.numpy.where((d0 < 1e-05) | (d1 < 1e-05), 1e-06, 0.01 * d0 / d1)
A:jax.experimental.ode.f1->fun(y1, t0 + h0)
A:jax.experimental.ode.h1->jax.numpy.where((d1 <= 1e-15) & (d2 <= 1e-15), jnp.maximum(1e-06, h0 * 0.001), (0.01 / jnp.max(d1 + d2)) ** (1.0 / (order + 1.0)))
A:jax.experimental.ode.alpha->jax.numpy.array([1 / 5, 3 / 10, 4 / 5, 8 / 9, 1.0, 1.0, 0], dtype=dt.dtype)
A:jax.experimental.ode.beta->jax.numpy.array([[1 / 5, 0, 0, 0, 0, 0, 0], [3 / 40, 9 / 40, 0, 0, 0, 0, 0], [44 / 45, -56 / 15, 32 / 9, 0, 0, 0, 0], [19372 / 6561, -25360 / 2187, 64448 / 6561, -212 / 729, 0, 0, 0], [9017 / 3168, -355 / 33, 46732 / 5247, 49 / 176, -5103 / 18656, 0, 0], [35 / 384, 0, 500 / 1113, 125 / 192, -2187 / 6784, 11 / 84, 0]], dtype=f0.dtype)
A:jax.experimental.ode.c_sol->jax.numpy.array([35 / 384, 0, 500 / 1113, 125 / 192, -2187 / 6784, 11 / 84, 0], dtype=f0.dtype)
A:jax.experimental.ode.c_error->jax.numpy.array([35 / 384 - 1951 / 21600, 0, 500 / 1113 - 22642 / 50085, 125 / 192 - 451 / 720, -2187 / 6784 - -12231 / 42400, 11 / 84 - 649 / 6300, -1.0 / 60.0], dtype=f0.dtype)
A:jax.experimental.ode.ft->func(yi, ti)
A:jax.experimental.ode.k->jax.lax.fori_loop(1, 7, body_fun, k)
A:jax.experimental.ode.dfactor->jax.numpy.where(mean_error_ratio < 1, 1.0, dfactor)
A:jax.experimental.ode.factor->jax.numpy.minimum(ifactor, jnp.maximum(mean_error_ratio ** (-1.0 / order) * safety, dfactor))
A:jax.experimental.ode.(converted, consts)->jax.custom_derivatives.closure_convert(func, y0, t[0], *args)
A:jax.experimental.ode.(y0, unravel)->ravel_pytree(y0)
A:jax.experimental.ode.func->ravel_first_arg(func, unravel)
A:jax.experimental.ode.out->_odeint(func, rtol, atol, mxstep, y0, ts, *args)
A:jax.experimental.ode.(next_y, next_f, next_y_error, k)->runge_kutta_step(func_, y, f, t, dt)
A:jax.experimental.ode.error_ratio->mean_error_ratio(next_y_error, rtol, atol, y, next_y)
A:jax.experimental.ode.new_interp_coeff->interp_fit_dopri(y, next_y, k, dt)
A:jax.experimental.ode.dt->initial_step_size(func_, ts[0], y0, 4, rtol, atol, f0)
A:jax.experimental.ode.(_, *carry)->jax.lax.while_loop(cond_fun, body_fun, [0] + carry)
A:jax.experimental.ode.y_target->jax.numpy.polyval(interp_coeff, relative_output_time)
A:jax.experimental.ode.f0->func_(y0, ts[0])
A:jax.experimental.ode.interp_coeff->jax.numpy.array([y0] * 5)
A:jax.experimental.ode.(_, ys)->jax.lax.scan(scan_fun, init_carry, ts[1:])
A:jax.experimental.ode.ys->_odeint(func, rtol, atol, mxstep, y0, ts, *args)
A:jax.experimental.ode.(y_dot, vjpfun)->jax.vjp(func, y, -t, *args)
A:jax.experimental.ode.(_, y_bar, t0_bar, args_bar)->odeint(aug_dynamics, (ys[i], y_bar, t0_bar, args_bar), jnp.array([-ts[i], -ts[i - 1]]), *args, rtol=rtol, atol=atol, mxstep=mxstep)
A:jax.experimental.ode.(y_bar, t0_bar, args_bar)->tree_map(op.itemgetter(1), (y_bar, t0_bar, args_bar))
A:jax.experimental.ode.((y_bar, t0_bar, args_bar), rev_ts_bar)->jax.lax.scan(scan_fun, init_carry, jnp.arange(len(ts) - 1, 0, -1))
A:jax.experimental.ode.ts_bar->jax.numpy.concatenate([jnp.array([t0_bar]), rev_ts_bar[::-1]])
jax.experimental.ode._odeint(func,rtol,atol,mxstep,y0,ts,*args)
jax.experimental.ode._odeint_fwd(func,rtol,atol,mxstep,y0,ts,*args)
jax.experimental.ode._odeint_rev(func,rtol,atol,mxstep,res,g)
jax.experimental.ode._odeint_wrapper(func,rtol,atol,mxstep,y0,ts,*args)
jax.experimental.ode.abs2(x)
jax.experimental.ode.fit_4th_order_polynomial(y0,y1,y_mid,dy0,dy1,dt)
jax.experimental.ode.initial_step_size(fun,t0,y0,order,rtol,atol,f0)
jax.experimental.ode.interp_fit_dopri(y0,y1,k,dt)
jax.experimental.ode.mean_error_ratio(error_estimate,rtol,atol,y0,y1)
jax.experimental.ode.odeint(func,y0,t,*args,rtol=1.4e-08,atol=1.4e-08,mxstep=jnp.inf)
jax.experimental.ode.optimal_step_size(last_step,mean_error_ratio,safety=0.9,ifactor=10.0,dfactor=0.2,order=5.0)
jax.experimental.ode.ravel_first_arg(f,unravel)
jax.experimental.ode.ravel_first_arg_(unravel,y_flat,*args)
jax.experimental.ode.runge_kutta_step(func,y0,f0,t0,dt)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/callback.py----------------------------------------
A:jax.experimental.callback.(args_flat, in_tree)->tree_flatten(args)
A:jax.experimental.callback.f->callback_subtrace(f, self.main)
A:jax.experimental.callback.(flat_fun, out_tree)->flatten_fun_nokwargs(f, in_tree)
A:jax.experimental.callback.out_flat->callback_fun(flat_fun, args_flat, callback, strip_calls)
A:jax.experimental.callback.vals->tuple(it.chain(new_consts, carry_vals, xs_vals))
A:jax.experimental.callback.fun->callback_subtrace(fun, self.main)
A:jax.experimental.callback.trace->main.with_cur_sublevel()
A:jax.experimental.callback.out_tracers->map(trace.full_raise, outs)
A:jax.experimental.callback.(jaxpr_out, consts)->jax.custom_derivatives._initial_style_jaxpr(fun, avals_in)
A:jax.experimental.callback.vals_out->call_primitive.bind(f, *vals_in, **params)
A:jax.experimental.callback.jvp->callback_subtrace(jvp, self.main)
A:jax.experimental.callback.out->primitive.bind(*it.chain(new_consts, vals), fun_jaxpr=closed_fun_jaxpr, num_consts=new_num_consts, **params)
A:jax.experimental.callback.fwd->callback_subtrace(fwd, self.main)
A:jax.experimental.callback.bwd->callback_subtrace(bwd, self.main)
A:jax.experimental.callback.(const_tracers, carry_tracers, xs_tracers)->split_list(tracers, [num_consts, num_carry])
A:jax.experimental.callback.(carry_avals, xs_avals)->tree_map(lambda x: x.aval, (carry_tracers, xs_tracers))
A:jax.experimental.callback.(const_vals, carry_vals, xs_vals)->tree_map(lambda x: x.val, (const_tracers, carry_tracers, xs_tracers))
A:jax.experimental.callback.body_fun->jaxpr_as_fun(body_jaxpr)
A:jax.experimental.callback.(out_carry, y)->split_list(out, [num_carry])
A:jax.experimental.callback.new_body->callback_transform(body, trace.callback, strip_calls=trace.strip_calls)
A:jax.experimental.callback.in_tree->tree_structure(init_avals)
A:jax.experimental.callback.(new_jaxpr, new_consts, _)->jax._src.lax.control_flow._initial_style_jaxpr(new_body, in_tree, tuple(carry_avals + x_avals))
A:jax.experimental.callback.out_vals->jax.lax.scan_p.bind(*vals, reverse=reverse, length=length, num_consts=len(new_consts), num_carry=num_carry, jaxpr=new_jaxpr, linear=linear, unroll=unroll)
A:jax.experimental.callback.(cond_const_tracers, body_const_tracers, init_tracers)->split_list(tracers, [cond_nconsts, body_nconsts])
A:jax.experimental.callback.init_avals->safe_map(lambda x: x.aval, init_tracers)
A:jax.experimental.callback.(cond_const_vals, body_const_vals, init_vals)->tree_map(lambda x: x.val, (cond_const_tracers, body_const_tracers, init_tracers))
A:jax.experimental.callback.cond_fun->jaxpr_as_fun(cond_jaxpr)
A:jax.experimental.callback.new_cond->callback_transform(cond, trace.callback, strip_calls=trace.strip_calls)
A:jax.experimental.callback.(new_cond_jaxpr, new_cond_consts, _)->jax._src.lax.control_flow._initial_style_jaxpr(new_cond, in_tree, tuple(init_avals))
A:jax.experimental.callback.(new_body_jaxpr, new_body_consts, _)->jax._src.lax.control_flow._initial_style_jaxpr(new_body, in_tree, tuple(init_avals))
A:jax.experimental.callback.new_closed_jaxpr->callback_jaxpr(fun_jaxpr, trace.callback, strip_calls=trace.strip_calls)
A:jax.experimental.callback.params['bwd']->callback_subtrace(params['bwd'], main)
A:jax.experimental.callback.thunk->params.pop(thunk_name)
A:jax.experimental.callback.thunk_jaxpr->jax.core.ClosedJaxpr(*thunk())
A:jax.experimental.callback.closed_jaxpr->callback_jaxpr(thunk_jaxpr, trace.callback, trace.strip_calls)
A:jax.experimental.callback.closed_fun_jaxpr->jax.core.ClosedJaxpr(pe.convert_constvars_jaxpr(new_fun_jaxpr), ())
A:jax.experimental.callback.custom_callback_rules[cd.custom_jvp_call_jaxpr_p]->partial(_custom_derivative_call_jaxpr_callback_rule, cd.custom_jvp_call_jaxpr_p)
A:jax.experimental.callback.custom_callback_rules[cd.custom_vjp_call_jaxpr_p]->partial(_custom_derivative_call_jaxpr_callback_rule, cd.custom_vjp_call_jaxpr_p)
jax.experimental.callback.CallbackTrace(self,*args,callback,strip_calls)
jax.experimental.callback.CallbackTrace.__init__(self,*args,callback,strip_calls)
jax.experimental.callback.CallbackTrace.lift(self,val)
jax.experimental.callback.CallbackTrace.process_call(self,call_primitive,f:lu.WrappedFun,tracers,params)
jax.experimental.callback.CallbackTrace.process_custom_jvp_call(self,primitive,fun,jvp,tracers)
jax.experimental.callback.CallbackTrace.process_custom_vjp_call(self,primitive,fun,fwd,bwd,tracers,out_trees)
jax.experimental.callback.CallbackTrace.process_primitive(self,primitive,tracers,params)
jax.experimental.callback.CallbackTrace.pure(self,val)
jax.experimental.callback.CallbackTrace.sublift(self,val)
jax.experimental.callback.CallbackTracer(self,trace,val)
jax.experimental.callback.CallbackTracer.__init__(self,trace,val)
jax.experimental.callback.CallbackTracer.aval(self)
jax.experimental.callback.CallbackTracer.full_lower(self)
jax.experimental.callback.FoundValue(Exception)
jax.experimental.callback._callback_fun(callback,strip_calls,*in_vals,**params)
jax.experimental.callback._check_callable(fun)
jax.experimental.callback._contains_query(vals,query)
jax.experimental.callback._custom_derivative_call_jaxpr_callback_rule(primitive,trace,*tracers,fun_jaxpr,num_consts,**params)
jax.experimental.callback._scan_callback_rule(trace,*tracers,reverse,length,num_consts,num_carry,jaxpr,linear,unroll)
jax.experimental.callback._while_callback_rule(trace,*tracers,cond_jaxpr,body_jaxpr,cond_nconsts,body_nconsts)
jax.experimental.callback.callback_fun(fun:lu.WrappedFun,in_vals,callback,strip_calls)
jax.experimental.callback.callback_jaxpr(closed_jaxpr,callback,strip_calls)
jax.experimental.callback.callback_subtrace(main,*in_vals,**params)
jax.experimental.callback.callback_transform(fun:Callable,callback:Callable,strip_calls:bool=False)->Callable
jax.experimental.callback.find_by_value(fun:Callable,queries)->Callable
jax.experimental.callback.rewrite(fun:Callable,rules)->Callable


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/maps.py----------------------------------------
A:jax.experimental.maps._positional_semantics->_PSThreadLocalState()
A:jax.experimental.maps.self.contents->dict(*args, **kwargs)
A:jax.experimental.maps.thread_resources.env->old_env.with_mesh(Mesh(np.asarray(devices, dtype=object), axis_names))
A:jax.experimental.maps.result->jax.interpreters.pxla.vtile_by_mesh(f, mesh, mesh_in_axes, mesh_out_axes).call_wrapped(*(_slice_tile(arg, spec.get(loop_name, None), i, loop_length) for (arg, spec) in zip(args, loop_in_axes)))
A:jax.experimental.maps.num_mapped_dims->sum((name is not None for name in entry))
A:jax.experimental.maps.user_repr->str(entry)
A:jax.experimental.maps.constr->partial(AxisNamePosWithRank, expected_rank=len(entry))
A:jax.experimental.maps.(entries, treedef)->tree_flatten(axes, is_leaf=_is_axes_leaf)
A:jax.experimental.maps.entries->map(partial(_parse_entry, arg_name), entries)
A:jax.experimental.maps.in_axes->tree_map(lambda i: {i: axis_name} if i is not proxy else {}, in_axes)
A:jax.experimental.maps.(in_axes, in_axes_entries, _)->_prepare_axes(in_axes, 'in_axes')
A:jax.experimental.maps.(out_axes, out_axes_entries, out_axes_treedef)->_prepare_axes(out_axes, 'out_axes')
A:jax.experimental.maps.out_axes_entries->tuple(out_axes_entries)
A:jax.experimental.maps.axis_sizes_names->set(axis_sizes.keys())
A:jax.experimental.maps.in_axes_names->set(it.chain(*(spec.keys() for spec in in_axes_entries)))
A:jax.experimental.maps.out_axes_names->set(it.chain(*(spec.keys() for spec in out_axes_entries)))
A:jax.experimental.maps.name->fresh_resource_name()
A:jax.experimental.maps.resources->axis_resources.get(axis, ())
A:jax.experimental.maps.normalized_axis_resources[axis]->tuple(unsafe_map(normalize_resource, resources))
A:jax.experimental.maps.frozen_axis_resources->FrozenDict(normalized_axis_resources)
A:jax.experimental.maps.necessary_resources->set(it.chain(*frozen_axis_resources.values()))
A:jax.experimental.maps.axes_with_resources->set(frozen_axis_resources.keys())
A:jax.experimental.maps.donate_argnums->_ensure_index_tuple(donate_argnums)
A:jax.experimental.maps.has_input_rank_assertions->any((spec.expected_rank is not None for spec in in_axes_entries))
A:jax.experimental.maps.has_output_rank_assertions->any((spec.expected_rank is not None for spec in out_axes_entries))
A:jax.experimental.maps.available_resources->set(resource_env.shape.keys())
A:jax.experimental.maps.(args_flat, in_tree)->tree_flatten(args)
A:jax.experimental.maps.(fun_flat, out_tree)->flatten_fun_nokwargs(lu.wrap_init(fun), in_tree)
A:jax.experimental.maps.donated_invars->donation_vector(donate_argnums, args, ())
A:jax.experimental.maps.in_axes_flat->_flatten_axes('xmap in_axes', in_tree, in_axes, tupled_args=True)
A:jax.experimental.maps.out_axes_thunk->HashableFunction(lambda : tuple(_flatten_axes('xmap out_axes', out_tree(), out_axes, tupled_args=False)), closure=(out_axes_entries, out_axes_treedef))
A:jax.experimental.maps.in_positional_semantics->tuple((_PositionalSemantics.GLOBAL if isinstance(a, GlobalDeviceArray) else _positional_semantics.val for a in args_flat))
A:jax.experimental.maps.axis_resource_count->_get_axis_resource_count(axis_resources, resource_env, in_positional_semantics)
A:jax.experimental.maps.frozen_global_axis_sizes->_get_axis_sizes(args_flat, in_axes_flat, axis_sizes, axis_resource_count, in_positional_semantics)
A:jax.experimental.maps.params->dict(name=getattr(fun, '__name__', '<unnamed function>'), in_axes=tuple(in_axes_flat), out_axes_thunk=out_axes_thunk, donated_invars=donated_invars, global_axis_sizes=frozen_global_axis_sizes, axis_resources=frozen_axis_resources, resource_env=resource_env, backend=backend, spmd_in_axes=None, spmd_out_axes_thunk=None, in_positional_semantics=in_positional_semantics, out_positional_semantics=out_positional_semantics)
A:jax.experimental.maps.f->jax.interpreters.pxla.vtile_by_mesh(f, mesh, mesh_in_axes, mesh_out_axes)
A:jax.experimental.maps.(fun_flat, args_flat, params, _, out_tree)->infer_params(*args)
A:jax.experimental.maps.out_flat->XMapPrimitive().bind(fun, *all_args, **new_params)
A:jax.experimental.maps.(fun_flat, args_flat, params, in_tree, out_tree)->infer_params(*args)
A:jax.experimental.maps.computation->make_xmap_callable(fun_flat, params['name'], params['in_axes'], params['out_axes_thunk'], params['donated_invars'], params['global_axis_sizes'], params['axis_resources'], params['resource_env'], params['backend'], params['spmd_in_axes'], params['spmd_out_axes_thunk'], params['in_positional_semantics'], params['out_positional_semantics'], *avals_flat)
A:jax.experimental.maps.in_tree->treedef_tuple([in_tree, tree_flatten({})[1]])
A:jax.experimental.maps.in_avals->treedef_tuple([in_tree, tree_flatten({})[1]]).unflatten(avals_flat)
A:jax.experimental.maps.plan->EvaluationPlan.from_axis_resources(axis_resources, resource_env, global_axis_sizes, in_positional_semantics)
A:jax.experimental.maps.(jaxpr, out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_final(fun, mapped_in_avals)
A:jax.experimental.maps.out_axes->params['out_axes_thunk']()
A:jax.experimental.maps.jaxpr->convert_constvars_jaxpr(jaxpr)
A:jax.experimental.maps.(mesh_in_axes, mesh_out_axes)->EvaluationPlan.from_axis_resources(axis_resources, resource_env, global_axis_sizes, in_positional_semantics).to_mesh_axes(in_axes, out_axes)
A:jax.experimental.maps.manual_mesh_axes->frozenset(it.chain.from_iterable(plan.physical_axis_resources.values()))
A:jax.experimental.maps.tiling_method->jax.interpreters.pxla.TileVectorize()
A:jax.experimental.maps.env->dict(self.resource_env.shape)
A:jax.experimental.maps.(physical_axis_resources, loop_axis_resources)->_unzip_axis_resources(axis_resources, resource_env)
A:jax.experimental.maps.axis_subst_dict->dict(axis_resources)
A:jax.experimental.maps.map_in_axes->tuple(unsafe_map(lambda spec: spec.get(naxis, None), in_axes))
A:jax.experimental.maps.map_out_axes->tuple(unsafe_map(lambda spec: spec.get(naxis, None), out_axes))
A:jax.experimental.maps.used_loops->set(it.chain.from_iterable(self.loop_axis_resources.values()))
A:jax.experimental.maps.loop_in_axes->_to_resource_axes(in_axes, self.loop_axis_resources)
A:jax.experimental.maps.loop_out_axes->_to_resource_axes(out_axes, self.loop_axis_resources)
A:jax.experimental.maps.(_, stacked_results)->jax.lax.scan(body, 0, (), length=loop_length)
A:jax.experimental.maps.new_params->dict(params, in_axes=new_in_axes, out_axes_thunk=new_out_axes_thunk, spmd_in_axes=new_spmd_in_axes, spmd_out_axes_thunk=new_spmd_out_axes_thunk)
A:jax.experimental.maps.subfun->jax.linear_util.hashable_partial(lu.wrap_init(core.eval_jaxpr), jaxpr, ())
A:jax.experimental.maps.axes->dict(params, in_axes=new_in_axes, out_axes_thunk=new_out_axes_thunk, spmd_in_axes=new_spmd_in_axes, spmd_out_axes_thunk=new_spmd_out_axes_thunk).pop('out_axes')
A:jax.experimental.maps.new_params['out_axes_thunk']->HashableFunction(lambda : axes, closure=axes)
A:jax.experimental.maps.spmd_axes->dict(params, in_axes=new_in_axes, out_axes_thunk=new_out_axes_thunk, spmd_in_axes=new_spmd_in_axes, spmd_out_axes_thunk=new_spmd_out_axes_thunk).pop('spmd_out_axes')
A:jax.experimental.maps.new_params['spmd_out_axes_thunk']->HashableFunction(lambda : spmd_axes, closure=spmd_axes)
A:jax.experimental.maps.xmap_p->XMapPrimitive()
A:jax.experimental.maps.new_jaxpr->jax.core.subst_axis_names_jaxpr(params['call_jaxpr'], shadowed_subst)
A:jax.experimental.maps.(all_args, in_tree_def)->tree_flatten(((), args, cts_in))
A:jax.experimental.maps.fun->jax.linear_util.hashable_partial(lu.wrap_init(ad.backward_pass), call_jaxpr, reduce_axes + tuple(params['global_axis_sizes'].keys()), False)
A:jax.experimental.maps.(fun, nz_arg_cts)->jax.interpreters.ad.nonzero_outputs(fun)
A:jax.experimental.maps.(fun, out_tree)->flatten_fun_nokwargs(fun, in_tree_def)
A:jax.experimental.maps.arg_cts->tree_unflatten(out_tree(), out_flat)
A:jax.experimental.maps.inner_axis_resources->dict(outer_axis_resources)
A:jax.experimental.maps.used_resources->set()
A:jax.experimental.maps.baxis_resources->set(inner_axis_resources[baxis])
A:jax.experimental.maps.partitioning_axes->set((resource_to_axis[raxis] for raxis in overlap))
A:jax.experimental.maps.(jaxpr, mapped_out_avals, consts)->trace_to_subjaxpr_dynamic(f, self.main, mapped_in_avals)
A:jax.experimental.maps.spmd_out_axes->spmd_out_axes_thunk()
A:jax.experimental.maps.source_info->jax._src.source_info_util.current()
A:jax.experimental.maps.invars->map(self.getvar, tracers)
A:jax.experimental.maps.constvars->map(self.getvar, map(self.instantiate_const, consts))
A:jax.experimental.maps.outvars->map(self.makevar, out_tracers)
A:jax.experimental.maps.call_jaxpr->convert_constvars_jaxpr(jaxpr)
A:jax.experimental.maps.eqn->new_eqn_recipe((*const_tracers, *unknown_tracers_in), unknown_tracers_out, primitive, new_params, jaxpr.effects, source_info_util.current())
A:jax.experimental.maps.(donated_invars_known, _)->jax.interpreters.partial_eval.partition_list(unks_in, params_known['donated_invars'])
A:jax.experimental.maps.(in_axes_known, _)->jax.interpreters.partial_eval.partition_list(unks_in, params_known['in_axes'])
A:jax.experimental.maps.(_, out_axes_known)->jax.interpreters.partial_eval.partition_list(kept_outs_known, params_known['out_axes'])
A:jax.experimental.maps.new_params_known->dict(params_known, in_axes=tuple(in_axes_known), out_axes=(*out_axes_known, *residual_axes), donated_invars=tuple(donated_invars_known))
A:jax.experimental.maps.(_, out_axes_staged)->jax.interpreters.partial_eval.partition_list(kept_outs_staged, params_staged['out_axes'])
A:jax.experimental.maps.new_params_staged->dict(params_staged, in_axes=(*residual_axes, *params_staged['in_axes']), out_axes=tuple(out_axes_staged), donated_invars=donated_invars_staged)
A:jax.experimental.maps.pe.partial_eval_jaxpr_custom_rules[xmap_p]->partial(pe.call_partial_eval_custom_rule, 'call_jaxpr', _xmap_partial_eval_custom_params_updater)
A:jax.experimental.maps.vals_it->iter(vals)
A:jax.experimental.maps.const_axes_s->jax.linear_util.Store()
A:jax.experimental.maps.(args_no_units, in_units)->filter_units(args)
A:jax.experimental.maps.(f, out_units)->hide_units(f, tuple(in_units))
A:jax.experimental.maps.(f, out_named_shapes)->out_local_named_shapes(f, frozenset(global_axis_sizes))
A:jax.experimental.maps.(axes_units, const_units)->split_list(out_units(), [len(out_axes)])
A:jax.experimental.maps.num_consts->len(const_units)
A:jax.experimental.maps.pe_params->dict(params, in_axes=tuple((a for (a, u) in zip(in_axes, in_units) if not u)), donated_invars=tuple((a for (a, u) in zip(donated_invars, in_units) if not u)), out_axes_thunk=new_out_axes_thunk)
A:jax.experimental.maps.outs_no_units->primitive.bind(f, *args_no_units, **pe_params)
A:jax.experimental.maps.(jaxpr, out_pvals, consts, env_tracers)->self.partial_eval(f, in_pvals, app, instantiate=False)
A:jax.experimental.maps.in_knowns->tuple((t.pval.is_known() for t in it.chain(env_tracers, tracers)))
A:jax.experimental.maps.out_unknowns->tuple((not pval.is_known() for pval in out_pvals))
A:jax.experimental.maps.const_tracers->map(self.new_instantiated_const, consts)
A:jax.experimental.maps.new_out_axes->tuple((axis for (axis, pval) in zip(out_axes, out_pvals) if not pval.is_known()))
A:jax.experimental.maps.new_spmd_in_axes->tuple((spmd_axes if d is not_mapped else insert_spmd_axis(spmd_axes, d) for (spmd_axes, d) in zip(spmd_in_axes, dims)))
A:jax.experimental.maps.dims_out->dims_out_thunk()
A:jax.experimental.maps.(vals, dims)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.experimental.maps.new_in_axes->tuple((fmap_dims(in_axes, lambda a: a + (d is not not_mapped and d <= a)) for (d, in_axes) in zip(dims, params['in_axes'])))
A:jax.experimental.maps.mapped_dims_in->tuple((d if d is not_mapped else d - sum((a < d for a in in_axis.values())) for (d, in_axis) in zip(dims, params['in_axes'])))
A:jax.experimental.maps.(f, mapped_dims_out)->jax.interpreters.batching.batch_subtrace(f, self.main, mapped_dims_in)
A:jax.experimental.maps.(new_spmd_in_axes, new_spmd_out_axes_thunk)->_batch_trace_update_spmd_axes(params['spmd_in_axes'], params['spmd_out_axes_thunk'], self.axis_name, dims, dims_out_thunk)
A:jax.experimental.maps.vals_out->primitive.bind(f, *vals, **new_params)
A:jax.experimental.maps.batching.BatchTrace.process_xmap->partialmethod(_batch_trace_process_xmap, False)
A:jax.experimental.maps.pxla.SPMDBatchTrace.process_xmap->partialmethod(_batch_trace_process_xmap, True)
A:jax.experimental.maps.resource_call_jaxpr->EvaluationPlan.from_axis_resources(axis_resources, resource_env, global_axis_sizes, in_positional_semantics).subst_axes_with_resources(call_jaxpr)
A:jax.experimental.maps.(vectorized_jaxpr, out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(f, local_avals)
A:jax.experimental.maps.sub_ctx->ctx.replace(name_stack=xla.extend_name_stack(ctx.name_stack, xla.wrap_name(name, 'xmap')))
A:jax.experimental.maps.tiled_outs->jax.interpreters.xla.jaxpr_subcomp(sub_ctx, vectorized_jaxpr, (), *tiled_ins)
A:jax.experimental.maps.(vectorized_jaxpr, global_out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(f, global_in_avals)
A:jax.experimental.maps.global_sharding_spec->jax.interpreters.pxla.mesh_sharding_specs(mesh.shape, mesh.axis_names)
A:jax.experimental.maps.global_out_nodes->jax.interpreters.xla.jaxpr_subcomp(sub_ctx, vectorized_jaxpr, (), *sharded_global_in_nodes)
A:jax.experimental.maps.zero->numpy.zeros((), dtype=np.int32)
A:jax.experimental.maps.axis_index->jax.lax.axis_index(name)
A:jax.experimental.maps.stride_c->numpy.array(strides[axis], np.int32)
A:jax.experimental.maps.linear_idxs[axis]->jax.lax.add(linear_idxs[axis], lax.mul(axis_index, stride_c))
A:jax.experimental.maps.tile_shape->list(x.shape)
A:jax.experimental.maps.base_idxs->_tile_base_indices(tile_shape, out_axes, axis_sizes)
A:jax.experimental.maps.x->jax.lax.convert_element_type(x, np.dtype(np.float32))
A:jax.experimental.maps.shape->list(x_moved.shape)
A:jax.experimental.maps.padded->jax.lax.dynamic_update_slice(padded, x, base_idxs)
A:jax.experimental.maps.out->jax.lax.convert_element_type(nonzero, np.dtype(np.bool_))
A:jax.experimental.maps.nonzero->jax.lax.ne(out, np.array(0, dtype=np.float32))
A:jax.experimental.maps.sharding_proto->global_sharding_spec(aval, aval_axes).sharding_proto()
A:jax.experimental.maps.unspecified_dims->set(range(aval.ndim))
A:jax.experimental.maps.named_shape->dict(aval.named_shape)
A:jax.experimental.maps.nlocal->int(np.prod(map(local_res_shape.get, resources), dtype=np.int64))
A:jax.experimental.maps.resource_count_map[axis]->ResourceCount(int(np.prod(map(global_res_shape.get, resources), dtype=np.int64)), nlocal, distributed)
A:jax.experimental.maps.global_axis_sizes->dict(global_axis_sizes)
A:jax.experimental.maps.global_dim_size->axis_resources.get(axis, ()).to_global(ips, local_dim_size)
A:jax.experimental.maps.expected_local_dim_size->axis_resources.get(axis, ()).to_local(ips, global_axis_sizes[name])
A:jax.experimental.maps.arg->arg.squeeze(dim).squeeze(dim)
A:jax.experimental.maps.squeezed_args->map(_squeeze_mapped_axes, flat_args, flat_in_axes)
A:jax.experimental.maps.updates->jax.core.traverse_jaxpr_params(partial(_jaxpr_resources, resource_env=resource_env), eqn.params).values()
A:jax.experimental.maps.x_moved->moveaxis(x, 0, axis)
A:jax.experimental.maps.(tile_size, rem)->divmod(x.shape[dim], n)
A:jax.experimental.maps.defined_axes->set(global_axis_sizes)
A:jax.experimental.maps.undeclared_axes_str->sorted([str(axis) for axis in undeclared_axes])
A:jax.experimental.maps.mesh_in_axes->EvaluationPlan.from_axis_resources(axis_resources, resource_env, global_axis_sizes, in_positional_semantics).to_mesh_axes(in_axes_flat)
A:jax.experimental.maps.gda_array_mapping->_get_array_mapping(arg.mesh_axes)
A:jax.experimental.maps.rec->partial(_check_no_loop_collectives, loop_axis_resources=loop_axis_resources)
A:jax.experimental.maps.gen_fresh_name->jax.core.gensym([jaxpr])
A:jax.experimental.maps.new_jaxpr_params->jax.core.traverse_jaxpr_params(rec, eqn.params)
A:jax.experimental.maps.proxy->object()
A:jax.experimental.maps.mesh_devices->numpy.array(xb.local_devices())
jax.experimental.maps.AxisNamePos(self,*args,user_repr,**kwargs)
jax.experimental.maps.AxisNamePos.__init__(self,*args,user_repr,**kwargs)
jax.experimental.maps.AxisNamePosWithRank(self,*args,expected_rank,**kwargs)
jax.experimental.maps.AxisNamePosWithRank.__init__(self,*args,expected_rank,**kwargs)
jax.experimental.maps.DotDotDotRepr
jax.experimental.maps.DotDotDotRepr.__repr__(self)
jax.experimental.maps.EvaluationPlan(NamedTuple)
jax.experimental.maps.EvaluationPlan.axis_subst(self)->core.AxisSubst
jax.experimental.maps.EvaluationPlan.from_axis_resources(cls,axis_resources:Dict[AxisName,Tuple[ResourceAxisName,...]],resource_env:ResourceEnv,global_axis_sizes:Dict[AxisName,int],in_positional_semantics:Sequence[bool])
jax.experimental.maps.EvaluationPlan.resource_axis_env(self)
jax.experimental.maps.EvaluationPlan.subst_axes_with_resources(self,jaxpr)
jax.experimental.maps.EvaluationPlan.to_mesh_axes(self,in_axes,out_axes=None)
jax.experimental.maps.EvaluationPlan.vectorize_and_loop(self,f:lu.WrappedFun,in_axes,out_axes)->lu.WrappedFun
jax.experimental.maps.FrozenDict(self,*args,**kwargs)
jax.experimental.maps.FrozenDict.__eq__(self,other)
jax.experimental.maps.FrozenDict.__getitem__(self,name)
jax.experimental.maps.FrozenDict.__hash__(self)
jax.experimental.maps.FrozenDict.__init__(self,*args,**kwargs)
jax.experimental.maps.FrozenDict.__iter__(self)
jax.experimental.maps.FrozenDict.__len__(self)
jax.experimental.maps.FrozenDict.__repr__(self)
jax.experimental.maps.NoQuotesStr(str)
jax.experimental.maps.ResourceCount(NamedTuple)
jax.experimental.maps.ResourceCount.to_global(self,semantics,local_size)
jax.experimental.maps.ResourceCount.to_local(self,semantics,global_size)
jax.experimental.maps.SerialLoop(self,length)
jax.experimental.maps.SerialLoop.__eq__(self,other)
jax.experimental.maps.SerialLoop.__hash__(self)
jax.experimental.maps.SerialLoop.__init__(self,length)
jax.experimental.maps.XMapPrimitive(self)
jax.experimental.maps.XMapPrimitive.__init__(self)
jax.experimental.maps.XMapPrimitive.bind(self,fun,*args,in_axes,**params)
jax.experimental.maps.XMapPrimitive.get_bind_params(self,params)
jax.experimental.maps.XMapPrimitive.post_process(self,trace,out_tracers,params)
jax.experimental.maps.XMapPrimitive.process(self,trace,fun,tracers,params)
jax.experimental.maps._PSThreadLocalState(self)
jax.experimental.maps._PSThreadLocalState.__init__(self)
jax.experimental.maps._PositionalSemantics(Enum)
jax.experimental.maps._UniqueResourceName(self,uid,tag=None)
jax.experimental.maps._UniqueResourceName.__eq__(self,other)
jax.experimental.maps._UniqueResourceName.__hash__(self)
jax.experimental.maps._UniqueResourceName.__init__(self,uid,tag=None)
jax.experimental.maps._UniqueResourceName.__repr__(self)
jax.experimental.maps._batch_trace_process_xmap(self,is_spmd,primitive,f:lu.WrappedFun,tracers,params)
jax.experimental.maps._batch_trace_update_spmd_axes(spmd_in_axes,spmd_out_axes_thunk,axis_name,dims,dims_out_thunk)
jax.experimental.maps._check_gda_xmap_partitioning(axis_resources,resource_env,global_axis_sizes,in_axes_flat,in_positional_semantics,args_flat)
jax.experimental.maps._check_no_loop_collectives(jaxpr,loop_axis_resources)
jax.experimental.maps._check_out_avals_vs_out_axes(out_avals:Sequence[core.AbstractValue],out_axes:Sequence[AxisNamePos],global_axis_sizes:Dict[AxisName,int])
jax.experimental.maps._clear_compilation_cache(_)
jax.experimental.maps._delete_aval_axes(aval,axes:AxisNamePos,global_axis_sizes)
jax.experimental.maps._dynamic_jaxpr_process_xmap(self,primitive,f,tracers,params)
jax.experimental.maps._ensure_spmd_and(f)
jax.experimental.maps._ensure_supports_manual_and(f)
jax.experimental.maps._fix_inferred_spmd_sharding(jaxpr,resource_env,gen_fresh_name=None)
jax.experimental.maps._flatten_axes(what,tree,axes,tupled_args)
jax.experimental.maps._get_axis_resource_count(axis_resources,resource_env,in_positional_semantics)->Dict[ResourceAxisName, ResourceCount]
jax.experimental.maps._get_axis_sizes(args_flat:Iterable[Any],in_axes_flat:Iterable[AxisNamePos],global_axis_sizes:Dict[AxisName,int],axis_resource_count:Dict[AxisName,ResourceCount],in_positional_semantics:Sequence[bool])
jax.experimental.maps._insert_aval_axes(aval,axes:AxisNamePos,local_axis_sizes)
jax.experimental.maps._is_axes_leaf(entry)
jax.experimental.maps._jaxpr_resources(jaxpr,resource_env)->Set[ResourceAxisName]
jax.experimental.maps._jaxpr_trace_process_xmap(self,primitive,f:lu.WrappedFun,tracers,params)
jax.experimental.maps._merge_leading_axis(x,axis:Optional[int])
jax.experimental.maps._parse_entry(arg_name,entry)
jax.experimental.maps._prepare_axes(axes,arg_name)
jax.experimental.maps._process_xmap_default(self,call_primitive,f,tracers,params)
jax.experimental.maps._resource_typing_xmap(avals,params,source_info:source_info_util.SourceInfo,resource_env,outer_axis_resources)
jax.experimental.maps._slice_tile(x,dim:Optional[int],i,n:int)
jax.experimental.maps._thread_local_flag_unsupported(_)
jax.experimental.maps._tile(x,in_axes,axis_sizes)
jax.experimental.maps._tile_base_indices(tile_shape,axes,axis_sizes)
jax.experimental.maps._to_resource_axes(axes_specs:Sequence[AxisNamePos],axis_resources:Dict[AxisName,Tuple[ResourceAxisName,...]])
jax.experimental.maps._typecheck_xmap(*in_avals,call_jaxpr,name,in_axes,out_axes,donated_invars,global_axis_sizes,axis_resources,resource_env,backend,spmd_in_axes,spmd_out_axes,in_positional_semantics,out_positional_semantics)
jax.experimental.maps._untile(x,out_axes,axis_sizes,platform)
jax.experimental.maps._unzip_axis_resources(axis_resources:Dict[AxisName,Tuple[ResourceAxisName,...]],resource_env:ResourceEnv)
jax.experimental.maps._xmap_axis_subst(params,subst,traverse)
jax.experimental.maps._xmap_lowering_rule(ctx,*args,**kwargs)
jax.experimental.maps._xmap_lowering_rule_replica(ctx,*in_nodes,call_jaxpr,name,in_axes,out_axes,donated_invars,global_axis_sizes,spmd_in_axes,spmd_out_axes,in_positional_semantics,out_positional_semantics,axis_resources,resource_env,backend)
jax.experimental.maps._xmap_lowering_rule_spmd(ctx,*global_in_nodes,call_jaxpr,name,in_axes,out_axes,donated_invars,global_axis_sizes,spmd_in_axes,spmd_out_axes,in_positional_semantics,out_positional_semantics,axis_resources,resource_env,backend)
jax.experimental.maps._xmap_lowering_rule_spmd_manual(ctx,*global_in_nodes,call_jaxpr,name,in_axes,out_axes,donated_invars,global_axis_sizes,spmd_in_axes,spmd_out_axes,in_positional_semantics,out_positional_semantics,axis_resources,resource_env,backend)
jax.experimental.maps._xmap_partial_eval_custom_params_updater(unks_in:Sequence[bool],kept_outs_known:Sequence[bool],kept_outs_staged:Sequence[bool],num_res:int,params_known:dict,params_staged:dict)->Tuple[dict, dict]
jax.experimental.maps._xmap_translation_rule(*args,**kwargs)
jax.experimental.maps._xmap_translation_rule_replica(ctx,avals_in,avals_out,*in_nodes,call_jaxpr,name,in_axes,out_axes,donated_invars,global_axis_sizes,spmd_in_axes,spmd_out_axes,in_positional_semantics,out_positional_semantics,axis_resources,resource_env,backend)
jax.experimental.maps._xmap_translation_rule_spmd(ctx,avals_in,avals_out,*global_in_nodes,call_jaxpr,name,in_axes,out_axes,donated_invars,global_axis_sizes,spmd_in_axes,spmd_out_axes,in_positional_semantics,out_positional_semantics,axis_resources,resource_env,backend)
jax.experimental.maps._xmap_transpose(params,call_jaxpr,args,cts_in,cts_in_avals,reduce_axes)
jax.experimental.maps.filter_units(vals)
jax.experimental.maps.fresh_resource_name(tag=None)
jax.experimental.maps.hide_mapped_axes(flat_in_axes,flat_out_axes,*flat_args)
jax.experimental.maps.hide_units(unit_args,*args,**kwargs)
jax.experimental.maps.lookup_exactly_one_of(d:AxisNamePos,names:Set[AxisName])->Optional[int]
jax.experimental.maps.make_xmap_callable(fun:lu.WrappedFun,name,in_axes,out_axes_thunk,donated_invars,global_axis_sizes,axis_resources,resource_env,backend,spmd_in_axes,spmd_out_axes_thunk,in_positional_semantics,out_positional_semantics,*in_avals)
jax.experimental.maps.mesh(devices:np.ndarray,axis_names:Sequence[ResourceAxisName])
jax.experimental.maps.out_local_named_shapes(local_axes,*args,**kwargs)
jax.experimental.maps.restore_units(is_unit,vals)
jax.experimental.maps.serial_loop(name:ResourceAxisName,length:int)
jax.experimental.maps.soft_pmap(fun:Callable,axis_name:Optional[AxisName]=None,in_axes=0)->Callable
jax.experimental.maps.xmap(fun:Callable,in_axes,out_axes,*,axis_sizes:Dict[AxisName,int]={},axis_resources:Dict[AxisName,ResourceSet]={},donate_argnums:Union[int,Sequence[int]]=(),backend:Optional[str]=None)->stages.Wrapped
jax.experimental.maps.xmap_impl(fun:lu.WrappedFun,*args,name,in_axes,out_axes_thunk,donated_invars,global_axis_sizes,axis_resources,resource_env,backend,spmd_in_axes,spmd_out_axes_thunk,in_positional_semantics,out_positional_semantics)
jax.soft_pmap(fun:Callable,axis_name:Optional[AxisName]=None,in_axes=0)->Callable


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/gda_serialization/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/gda_serialization/serialization.py----------------------------------------
A:jax.experimental.gda_serialization.serialization.global_idx_rid->jax.experimental.global_device_array.get_shard_indices_replica_ids(global_shape, global_mesh, mesh_axes)
A:jax.experimental.gda_serialization.serialization.m->re.fullmatch('^gs://([^/]*)/(.*)$', ckpt_path, re.DOTALL)
A:jax.experimental.gda_serialization.serialization.gcs_bucket->re.fullmatch('^gs://([^/]*)/(.*)$', ckpt_path, re.DOTALL).group(1)
A:jax.experimental.gda_serialization.serialization.path_without_bucket->re.fullmatch('^gs://([^/]*)/(.*)$', ckpt_path, re.DOTALL).group(2)
A:jax.experimental.gda_serialization.serialization.tensorstore_spec['metadata']->_get_metadata(gda_inp)
A:jax.experimental.gda_serialization.serialization.future_write_state->jax.tree_util.tree_map(_write_array, tuple(gda_inp.local_shards))
A:jax.experimental.gda_serialization.serialization.future_writer->jax.tree_map(async_serialize, gdas, tensorstore_specs)
A:jax.experimental.gda_serialization.serialization.t->tensorstore.open(ts.Spec(tensorstore_spec), open=True).result()
A:jax.experimental.gda_serialization.serialization.new_shard_shape->jax.experimental.global_device_array.get_shard_shape(shape, mesh, mesh_axes)
A:jax.experimental.gda_serialization.serialization.out->numpy.zeros(new_shard_shape, dtype=t.dtype.numpy_dtype)
A:jax.experimental.gda_serialization.serialization.restricted_domain->tensorstore.open(ts.Spec(tensorstore_spec), open=True).result().domain.intersect(requested_domain)
A:jax.experimental.gda_serialization.serialization.future_gdas->jax.tree_map(async_deserialize, global_meshes, mesh_axes, tensorstore_specs, [None] * len(tensorstore_specs) if global_shapes is None else global_shapes)
jax.experimental.gda_serialization.serialization._get_metadata(gda)
jax.experimental.gda_serialization.serialization._spec_has_metadata(tree)
jax.experimental.gda_serialization.serialization.async_deserialize(mesh,mesh_axes,tensorstore_spec,global_shape=None)
jax.experimental.gda_serialization.serialization.async_serialize(gda_inp:gda.GlobalDeviceArray,tensorstore_spec)
jax.experimental.gda_serialization.serialization.create_async_gda_from_callback(global_shape:gda.Shape,global_mesh:Mesh,mesh_axes:gda.MeshAxes,data_callback:Callable[[gda.Index],asyncio.Future])
jax.experimental.gda_serialization.serialization.get_tensorstore_spec(ckpt_path:str)
jax.experimental.gda_serialization.serialization.run_deserialization(global_meshes,mesh_axes,tensorstore_specs,global_shapes=None)
jax.experimental.gda_serialization.serialization.run_serialization(gdas,tensorstore_specs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/gda_serialization/serialization_test.py----------------------------------------
A:jax.experimental.gda_serialization.serialization_test.size->jax._src.util.prod(mesh_shape)
A:jax.experimental.gda_serialization.serialization_test.mesh_devices->numpy.array(jax.devices()[:size]).reshape(mesh_shape)
A:jax.experimental.gda_serialization.serialization_test.global_mesh->create_global_mesh((2, 2), ('x', 'y'))
A:jax.experimental.gda_serialization.serialization_test.mesh_axes->P('x', 'y')
A:jax.experimental.gda_serialization.serialization_test.num->jax._src.util.prod(global_input_shape)
A:jax.experimental.gda_serialization.serialization_test.global_input_data1->numpy.arange(num).reshape(global_input_shape)
A:jax.experimental.gda_serialization.serialization_test.gda1->jax.experimental.global_device_array.GlobalDeviceArray.from_callback(global_input_shape, global_mesh, P('x', 'y'), cb1)
A:jax.experimental.gda_serialization.serialization_test.ckpt_dir1->pathlib.Path(self.create_tempdir('first').full_path)
A:jax.experimental.gda_serialization.serialization_test.global_input_data2->numpy.arange(num, num + num).reshape(global_input_shape)
A:jax.experimental.gda_serialization.serialization_test.gda2->jax.experimental.global_device_array.GlobalDeviceArray.from_callback(global_input_shape, global_mesh, mesh_axes, cb2)
A:jax.experimental.gda_serialization.serialization_test.ckpt_dir2->pathlib.Path(self.create_tempdir('second').full_path)
A:jax.experimental.gda_serialization.serialization_test.global_mesh1d->create_global_mesh((8,), ('x',))
A:jax.experimental.gda_serialization.serialization_test.gda3->jax.experimental.global_device_array.GlobalDeviceArray.from_callback((0,), global_mesh1d, P(None), cb3)
A:jax.experimental.gda_serialization.serialization_test.ckpt_dir3->pathlib.Path(self.create_tempdir('third').full_path)
A:jax.experimental.gda_serialization.serialization_test.tspecs->jax.tree_map(serialization.get_tensorstore_spec, ckpt_paths)
A:jax.experimental.gda_serialization.serialization_test.(m1, m2, m3)->jax.experimental.gda_serialization.serialization.run_deserialization([global_mesh, global_mesh, global_mesh1d], [mesh_axes, P('x'), P(None)], tspecs)
A:jax.experimental.gda_serialization.serialization_test.(m1,)->jax.experimental.gda_serialization.serialization.run_deserialization([create_global_mesh((4, 2), ('x', 'y'))], [P('x', 'y')], tspecs, [(12, 2)])
jax.experimental.gda_serialization.serialization_test.CheckpointTest(jtu.JaxTestCase)
jax.experimental.gda_serialization.serialization_test.CheckpointTest.test_checkpointing(self)
jax.experimental.gda_serialization.serialization_test.CheckpointTest.test_checkpointing_with_bigger_shape(self)
jax.experimental.gda_serialization.serialization_test.CheckpointTest.test_empty_spec_has_no_metadata(self)
jax.experimental.gda_serialization.serialization_test.CheckpointTest.test_spec_has_metadata(self)
jax.experimental.gda_serialization.serialization_test.CheckpointTest.test_spec_has_no_metadata(self)
jax.experimental.gda_serialization.serialization_test.create_global_mesh(mesh_shape,axis_names)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/checkify/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/checkify/checkify_impl.py----------------------------------------
A:jax.experimental.checkify.checkify_impl.val->getattr(obj, attrname)
A:jax.experimental.checkify.checkify_impl.sentinel->object()
A:jax.experimental.checkify.checkify_impl.init_payload->numpy.ones((3,), np.int32)
A:jax.experimental.checkify.checkify_impl.err->self.get()
A:jax.experimental.checkify.checkify_impl.init_error->Error(False, 0, {})
A:jax.experimental.checkify.checkify_impl.code->next_code()
A:jax.experimental.checkify.checkify_impl.out_code->jax.lax.select(error.err, error.code, code)
A:jax.experimental.checkify.checkify_impl.out_payload->jax.lax.select(error.err, error.payload, payload)
A:jax.experimental.checkify.checkify_impl.aval->property(lambda self: core.get_aval(self.val))
A:jax.experimental.checkify.checkify_impl.rule->error_checks.get(primitive)
A:jax.experimental.checkify.checkify_impl.(out, self.main.error)->rule(self.main.error, self.main.enabled_errors, *in_vals, **params)
A:jax.experimental.checkify.checkify_impl.out->tree_unflatten(out_tree(), out_flat)
A:jax.experimental.checkify.checkify_impl.e->popattr(self.main, 'error')
A:jax.experimental.checkify.checkify_impl.(f, msgs)->checkify_subtrace(f)
A:jax.experimental.checkify.checkify_impl.params->dict(params, donated_invars=(False, False, False, *params['donated_invars']))
A:jax.experimental.checkify.checkify_impl.(err, code, payload, *out_vals)->prim.bind(fun, jvp, e.err, e.code, e.payload, *in_vals)
A:jax.experimental.checkify.checkify_impl.params_->dict(params, in_axes=(None, None, None, *params['in_axes']), out_axes_thunk=new_out_axes_thunk, donated_invars=(False, False, False, *params['donated_invars']))
A:jax.experimental.checkify.checkify_impl.(errs, codes, payloads, *outs)->primitive.bind(f, e.err, e.code, e.payload, *in_vals, **params_)
A:jax.experimental.checkify.checkify_impl.(err, code, payload)->_reduce_any_error(error.err, error.code, error.payload)
A:jax.experimental.checkify.checkify_impl.trace->main.with_cur_sublevel()
A:jax.experimental.checkify.checkify_impl.msgs->tuple(e.msgs.items())
A:jax.experimental.checkify.checkify_impl.(fun, msgs1)->checkify_subtrace(fun, self.main, msgs)
A:jax.experimental.checkify.checkify_impl.(jvp, msgs2)->checkify_custom_jvp_subtrace(jvp, self.main, msgs)
A:jax.experimental.checkify.checkify_impl.(fst, out_msgs)->jax.linear_util.merge_linear_aux(msgs1, msgs2)
A:jax.experimental.checkify.checkify_impl.(fwd, msgs2)->checkify_custom_vjp_subtrace(fwd, self.main, msgs)
A:jax.experimental.checkify.checkify_impl.(fun, msgs)->checkify_subtrace(fun)
A:jax.experimental.checkify.checkify_impl.fun->checkify_traceable(fun, tuple(init_error.msgs.items()), enabled_errors)
A:jax.experimental.checkify.checkify_impl.(err, code, payload, *outvals)->checkify_traceable(fun, tuple(init_error.msgs.items()), enabled_errors).call_wrapped(init_error.err, init_error.code, init_error.payload, *args)
A:jax.experimental.checkify.checkify_impl.out_tracers->map(trace.full_raise, out)
A:jax.experimental.checkify.checkify_impl.(n, ragged)->divmod(len(args), 2)
A:jax.experimental.checkify.checkify_impl.((err,), (code,), (payload,), primals)->split_list(args[:n], [1, 1, 1])
A:jax.experimental.checkify.checkify_impl.((err_dot,), (code_dot,), (pl_dot,), tangents)->split_list(args[n:], [1, 1, 1])
A:jax.experimental.checkify.checkify_impl.(m, ragged)->divmod(len(outs), 2)
A:jax.experimental.checkify.checkify_impl.f->checkify_traceable(f, tuple(error.msgs.items()), enabled_errors)
A:jax.experimental.checkify.checkify_impl.err_aval->jax.core.raise_to_shaped(core.get_aval(error.err))
A:jax.experimental.checkify.checkify_impl.code_aval->jax.core.raise_to_shaped(core.get_aval(error.code))
A:jax.experimental.checkify.checkify_impl.payload_aval->jax.core.raise_to_shaped(core.get_aval(error.payload))
A:jax.experimental.checkify.checkify_impl.(jaxpr_out, _, literals_out)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(f, avals_in)
A:jax.experimental.checkify.checkify_impl.assert_p->jax.core.Primitive('assert')
A:jax.experimental.checkify.checkify_impl.no_nans->jax.numpy.logical_not(jnp.any(jnp.isnan(out)))
A:jax.experimental.checkify.checkify_impl.operand_dims->numpy.array(operand.shape)
A:jax.experimental.checkify.checkify_impl.upper_bound->jax.lax.broadcast_in_dim(upper_bound, indices.shape, (len(indices.shape) - 1,))
A:jax.experimental.checkify.checkify_impl.flat_idx->jax.numpy.argmin(in_bounds)
A:jax.experimental.checkify.checkify_impl.multi_idx->jax.numpy.unravel_index(flat_idx, start_indices.shape)
A:jax.experimental.checkify.checkify_impl.payload->jax.numpy.array([oob_index, oob_axis, oob_axis_size], dtype=jnp.int32)
A:jax.experimental.checkify.checkify_impl.all_nonzero->jax.numpy.logical_not(jnp.any(jnp.equal(y, 0)))
A:jax.experimental.checkify.checkify_impl.error->assert_func(error, all_nonzero, msg, None)
A:jax.experimental.checkify.checkify_impl.lower_in_bounds->jax.numpy.all(jnp.greater_equal(indices, 0))
A:jax.experimental.checkify.checkify_impl.upper_in_bounds->jax.numpy.all(jnp.less_equal(indices, upper_bound))
A:jax.experimental.checkify.checkify_impl.in_bounds->scatter_in_bounds(operand, indices, updates, dimension_numbers)
A:jax.experimental.checkify.checkify_impl.oob_error->assert_func(error, in_bounds, oob_msg, None)
A:jax.experimental.checkify.checkify_impl.error_checks[lax.scatter_p]->partial(scatter_error_check, lax.scatter_p)
A:jax.experimental.checkify.checkify_impl.error_checks[lax.scatter_add_p]->partial(scatter_error_check, lax.scatter_add_p)
A:jax.experimental.checkify.checkify_impl.error_checks[lax.scatter_mul_p]->partial(scatter_error_check, lax.scatter_mul_p)
A:jax.experimental.checkify.checkify_impl.error_checks[lax.scatter_min_p]->partial(scatter_error_check, lax.scatter_min_p)
A:jax.experimental.checkify.checkify_impl.error_checks[lax.scatter_max_p]->partial(scatter_error_check, lax.scatter_max_p)
A:jax.experimental.checkify.checkify_impl.(new_branches, msgs_)->unzip2((checkify_jaxpr(jxpr, error, enabled_errors) for jxpr in branches))
A:jax.experimental.checkify.checkify_impl.(err, code, payload, *outs)->jax.lax.scan_p.bind(*new_in_flat, reverse=reverse, length=length, jaxpr=checked_jaxpr, num_consts=len(consts), num_carry=len(carry) + 3, linear=new_linear, unroll=unroll)
A:jax.experimental.checkify.checkify_impl.(consts, carry, xs)->split_list(in_flat, [num_consts, num_carry])
A:jax.experimental.checkify.checkify_impl.(checked_jaxpr_, msgs_)->checkify_jaxpr(jaxpr, error, enabled_errors)
A:jax.experimental.checkify.checkify_impl.checked_jaxpr->jax.interpreters.partial_eval.move_binders_to_front(checked_jaxpr_, tomove)
A:jax.experimental.checkify.checkify_impl.cond_f->jax.core.jaxpr_as_fun(cond_jaxpr)
A:jax.experimental.checkify.checkify_impl.body_f->jax.core.jaxpr_as_fun(body_jaxpr)
A:jax.experimental.checkify.checkify_impl._->cond_f(*c_consts, *out)
A:jax.experimental.checkify.checkify_impl.new_vars->jax.core.gensym([jaxpr])
A:jax.experimental.checkify.checkify_impl.new_jaxpr->jaxpr.replace(invars=new_invars)
A:jax.experimental.checkify.checkify_impl.(c_consts, b_consts, carry)->split_list(in_flat, [cond_nconsts, body_nconsts])
A:jax.experimental.checkify.checkify_impl.(cond_jaxpr_, msgs_cond)->checkify_jaxpr(cond_jaxpr, error, enabled_errors)
A:jax.experimental.checkify.checkify_impl.(cond_err, cond_code, cond_payload, _)->jax.core.jaxpr_as_fun(cond_jaxpr_)(error.err, error.code, error.payload, *c_consts, *carry)
A:jax.experimental.checkify.checkify_impl.(checked_body_jaxpr_, msgs_body)->checkify_while_body_jaxpr(cond_jaxpr, body_jaxpr, error, enabled_errors, c_consts)
A:jax.experimental.checkify.checkify_impl.checked_body_jaxpr->jax.interpreters.partial_eval.move_binders_to_front(checked_body_jaxpr_, to_move)
A:jax.experimental.checkify.checkify_impl.compat_cond_jaxpr_->ignore_errors_jaxpr(cond_jaxpr, error)
A:jax.experimental.checkify.checkify_impl.compat_cond_jaxpr->jax.interpreters.partial_eval.move_binders_to_front(compat_cond_jaxpr_, to_move)
A:jax.experimental.checkify.checkify_impl.(err, code, payload, *out)->jax.lax.while_p.bind(*new_in_flat, cond_nconsts=cond_nconsts, cond_jaxpr=compat_cond_jaxpr, body_nconsts=body_nconsts, body_jaxpr=checked_body_jaxpr)
A:jax.experimental.checkify.checkify_impl.error_checks[prim]->partial(nan_error_check, prim)
A:jax.experimental.checkify.checkify_impl.ErrorCategory->enum.Enum('ErrorCategory', ['NAN', 'OOB', 'DIV', 'USER_CHECK'])
A:jax.experimental.checkify.checkify_impl.user_checks->frozenset({ErrorCategory.USER_CHECK})
A:jax.experimental.checkify.checkify_impl.nan_checks->frozenset({ErrorCategory.NAN})
A:jax.experimental.checkify.checkify_impl.index_checks->frozenset({ErrorCategory.OOB})
A:jax.experimental.checkify.checkify_impl.div_checks->frozenset({ErrorCategory.DIV})
A:jax.experimental.checkify.checkify_impl.Out->TypeVar('Out')
A:jax.experimental.checkify.checkify_impl.(args_flat, in_tree)->tree_flatten((args, kwargs))
A:jax.experimental.checkify.checkify_impl.(f, out_tree)->flatten_fun(lu.wrap_init(fun), in_tree)
A:jax.experimental.checkify.checkify_impl.((err, code, payload, out_flat), msgs)->checkify_flat(f, errors, *args_flat)
jax.experimental.checkify.Error
jax.experimental.checkify.Error.get(self)->Optional[str]
jax.experimental.checkify.Error.throw(self)
jax.experimental.checkify.check(pred:Bool,msg:str)->None
jax.experimental.checkify.check_error(error:Error)->None
jax.experimental.checkify.checkify(fun:Callable[...,Out],errors:FrozenSet[ErrorCategory]=user_checks)->Callable[..., Tuple[Error, Out]]
jax.experimental.checkify.checkify_custom_jvp_subtrace(main,msgs,*args)
jax.experimental.checkify.checkify_custom_vjp_subtrace(main,msgs,err,code,payload,*args)
jax.experimental.checkify.checkify_flat(fun:lu.WrappedFun,enabled_errors:FrozenSet['ErrorCategory'],*args)
jax.experimental.checkify.checkify_fun_to_jaxpr(f,error,enabled_errors,in_avals)
jax.experimental.checkify.checkify_impl.CheckifyTrace(self,main:core.MainTrace,sublevel:core.Sublevel,enabled_errors:FrozenSet['ErrorCategory'])
jax.experimental.checkify.checkify_impl.CheckifyTrace.__init__(self,main:core.MainTrace,sublevel:core.Sublevel,enabled_errors:FrozenSet['ErrorCategory'])
jax.experimental.checkify.checkify_impl.CheckifyTrace.post_process_call(self,primitive,tracers,params)
jax.experimental.checkify.checkify_impl.CheckifyTrace.post_process_custom_jvp_call(self,out_tracers,jvp_was_run)
jax.experimental.checkify.checkify_impl.CheckifyTrace.post_process_map(self,primitive,tracers,params)
jax.experimental.checkify.checkify_impl.CheckifyTrace.process_call(self,primitive,f,tracers,params)
jax.experimental.checkify.checkify_impl.CheckifyTrace.process_custom_jvp_call(self,prim,fun,jvp,tracers)
jax.experimental.checkify.checkify_impl.CheckifyTrace.process_custom_vjp_call(self,prim,fun,fwd,bwd,tracers,out_trees)
jax.experimental.checkify.checkify_impl.CheckifyTrace.process_map(self,primitive,f,tracers,params)
jax.experimental.checkify.checkify_impl.CheckifyTrace.process_primitive(self,primitive,tracers,params)
jax.experimental.checkify.checkify_impl.CheckifyTrace.sublift(self,tracer)
jax.experimental.checkify.checkify_impl.CheckifyTracer(self,trace,val)
jax.experimental.checkify.checkify_impl.CheckifyTracer.__init__(self,trace,val)
jax.experimental.checkify.checkify_impl.Error
jax.experimental.checkify.checkify_impl.Error.get(self)->Optional[str]
jax.experimental.checkify.checkify_impl.Error.throw(self)
jax.experimental.checkify.checkify_impl._format_msg(msg,payloads)
jax.experimental.checkify.checkify_impl._reduce_any_error(errs,codes,payloads)
jax.experimental.checkify.checkify_impl.add_nan_check(prim)
jax.experimental.checkify.checkify_impl.assert_abstract_eval(pred,code,payload,*,msgs)
jax.experimental.checkify.checkify_impl.assert_discharge_rule(error,enabled_errors,pred,code,payload,*,msgs)
jax.experimental.checkify.checkify_impl.assert_func(error:Error,pred:Bool,msg:str,payload:Optional[Payload])->Error
jax.experimental.checkify.checkify_impl.assert_impl(pred,code,payload,*,msgs)
jax.experimental.checkify.checkify_impl.check(pred:Bool,msg:str)->None
jax.experimental.checkify.checkify_impl.check_error(error:Error)->None
jax.experimental.checkify.checkify_impl.checkify(fun:Callable[...,Out],errors:FrozenSet[ErrorCategory]=user_checks)->Callable[..., Tuple[Error, Out]]
jax.experimental.checkify.checkify_impl.checkify_custom_jvp_subtrace(main,msgs,*args)
jax.experimental.checkify.checkify_impl.checkify_custom_vjp_subtrace(main,msgs,err,code,payload,*args)
jax.experimental.checkify.checkify_impl.checkify_flat(fun:lu.WrappedFun,enabled_errors:FrozenSet['ErrorCategory'],*args)
jax.experimental.checkify.checkify_impl.checkify_fun_to_jaxpr(f,error,enabled_errors,in_avals)
jax.experimental.checkify.checkify_impl.checkify_jaxpr(jaxpr,error,enabled_errors)
jax.experimental.checkify.checkify_impl.checkify_subtrace(main,msgs,err,code,payload,*args)
jax.experimental.checkify.checkify_impl.checkify_traceable(msgs,enabled_errors,err,code,payload,*args)
jax.experimental.checkify.checkify_impl.checkify_while_body_jaxpr(cond_jaxpr,body_jaxpr,error,enabled_errors,c_consts)
jax.experimental.checkify.checkify_impl.cond_error_check(error,enabled_errors,index,*ops,branches,linear)
jax.experimental.checkify.checkify_impl.div_error_check(error,enabled_errors,x,y)
jax.experimental.checkify.checkify_impl.gather_error_check(error,enabled_errors,operand,start_indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax.experimental.checkify.checkify_impl.ignore_errors_jaxpr(jaxpr,error)
jax.experimental.checkify.checkify_impl.is_scalar_pred(pred)->bool
jax.experimental.checkify.checkify_impl.nan_error_check(prim,error,enabled_errors,*in_vals,**params)
jax.experimental.checkify.checkify_impl.popattr(obj,attrname)
jax.experimental.checkify.checkify_impl.scan_error_check(error,enabled_errors,*in_flat,reverse,length,jaxpr,num_consts,num_carry,linear,unroll)
jax.experimental.checkify.checkify_impl.scatter_error_check(prim,error,enabled_errors,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax.experimental.checkify.checkify_impl.scatter_in_bounds(operand,indices,updates,dnums)
jax.experimental.checkify.checkify_impl.setnewattr(obj,name,val)
jax.experimental.checkify.checkify_impl.summary()->str
jax.experimental.checkify.checkify_impl.while_loop_error_check(error,enabled_errors,*in_flat,cond_nconsts,cond_jaxpr,body_nconsts,body_jaxpr)
jax.experimental.checkify.checkify_jaxpr(jaxpr,error,enabled_errors)
jax.experimental.checkify.checkify_subtrace(main,msgs,err,code,payload,*args)
jax.experimental.checkify.checkify_traceable(msgs,enabled_errors,err,code,payload,*args)
jax.experimental.checkify.checkify_while_body_jaxpr(cond_jaxpr,body_jaxpr,error,enabled_errors,c_consts)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/impl_no_xla.py----------------------------------------
A:jax.experimental.jax2tf.impl_no_xla.lhs->tensorflow.expand_dims(lhs, lhs_ndim - 1)
A:jax.experimental.jax2tf.impl_no_xla.rhs->tensorflow.expand_dims(rhs, rhs_ndim)
A:jax.experimental.jax2tf.impl_no_xla.pads->jax.lax.padtype_to_pads(in_shape, window_shape, window_strides, pad_str)
A:jax.experimental.jax2tf.impl_no_xla.no_pad->tensorflow.constant([[0, 0]])
A:jax.experimental.jax2tf.impl_no_xla.padding->tensorflow.concat([no_pad, padding, no_pad], 0)
A:jax.experimental.jax2tf.impl_no_xla.in_shape->tensorflow.pad(in_shape, padding)
A:jax.experimental.jax2tf.impl_no_xla.out_shape->jax.experimental.jax2tf.jax2tf._aval_to_tf_shape(_out_aval)
A:jax.experimental.jax2tf.impl_no_xla.(lhs, rhs)->_transpose_for_tf_conv(lhs, rhs, dimension_numbers)
A:jax.experimental.jax2tf.impl_no_xla.padding_type->pads_to_padtype(lhs.shape[1:3], rhs_dilated_shape, window_strides, padding)
A:jax.experimental.jax2tf.impl_no_xla.output->tensorflow.transpose(output, inverse_perm)
A:jax.experimental.jax2tf.impl_no_xla.rhs_t->tensorflow.transpose(rhs_t, (0, 1, 3, 2))
A:jax.experimental.jax2tf.impl_no_xla.tf_out_shape->tuple((tf_out_shape[i] for i in (0, 2, 3, 1)))
A:jax.experimental.jax2tf.impl_no_xla.inverse_perm->tuple((output_perm.index(i) for i in range(4)))
A:jax.experimental.jax2tf.impl_no_xla.result->tensorflow.squeeze(result, axis=1)
A:jax.experimental.jax2tf.impl_no_xla.new_id->iter(string.ascii_letters)
A:jax.experimental.jax2tf.impl_no_xla.shared_id->next(new_id)
A:jax.experimental.jax2tf.impl_no_xla.out_axis_ids->list(filter(not_none, batch_ids + lhs_out_axis_ids + rhs_out_axis_ids))
A:jax.experimental.jax2tf.impl_no_xla.spec->'{},{}->{}'.format(''.join(lhs_axis_ids), ''.join(rhs_axis_ids), ''.join(out_axis_ids))
A:jax.experimental.jax2tf.impl_no_xla.expansion[d]->slice(None, None, None)
A:jax.experimental.jax2tf.impl_no_xla.indices_cartesian->tensorflow.concat(indices_by_dim, axis=len(operand_shape))
A:jax.experimental.jax2tf.impl_no_xla.scattered->tensorflow.scatter_nd(indices_cartesian, operand, output_shape)
A:jax.experimental.jax2tf.impl_no_xla.mask->tensorflow.scatter_nd(indices_cartesian, tf.ones_like(operand, dtype=np.bool_), output_shape)
A:jax.experimental.jax2tf.impl_no_xla.(low, high, interior)->jax._src.util.unzip3(padding_config)
A:jax.experimental.jax2tf.impl_no_xla.operand->tensorflow.slice(operand, begins, output_shape)
A:jax.experimental.jax2tf.impl_no_xla.output_shape->jax.experimental.jax2tf.jax2tf._eval_shape(_out_aval.shape)
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.argmin_p]->partial(_argminmax, True)
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.argmax_p]->partial(_argminmax, False)
A:jax.experimental.jax2tf.impl_no_xla.tf_padding->pads_to_padtype(operand.shape, window_dimensions, window_strides, padding)
A:jax.experimental.jax2tf.impl_no_xla.tf_window_dimensions->list(window_dimensions)
A:jax.experimental.jax2tf.impl_no_xla.tf_window_strides->list(window_strides)
A:jax.experimental.jax2tf.impl_no_xla.tf_operand->tensorflow.expand_dims(tf_operand, -1)
A:jax.experimental.jax2tf.impl_no_xla.avg->tensorflow.nn.avg_pool(tf_operand, tf_window_dimensions, tf_window_strides, tf_padding, tf_data_format)
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.reduce_window_sum_p]->partial(_reduce_window, name='reduce_window_sum')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.reduce_window_max_p]->partial(_reduce_window, name='reduce_window_max')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.reduce_window_min_p]->_unimplemented('reduce_window_min')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.reduce_window_p]->_unimplemented('reduce_window')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.reduce_p]->_unimplemented('reduce')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.select_and_scatter_add_p]->_unimplemented('select_and_scatter_add')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.rng_bit_generator_p]->_unimplemented('rng_bit_generator')
A:jax.experimental.jax2tf.impl_no_xla.max_start->tensorflow.cast(tf.subtract(max_indices, slice_sizes), dtype=tf.int32)
A:jax.experimental.jax2tf.impl_no_xla.indices->tensorflow.expand_dims(args.dnums.start_index_map, 1)
A:jax.experimental.jax2tf.impl_no_xla.op_shape->jax.experimental.jax2tf.jax2tf._eval_shape(_in_avals[0].shape)
A:jax.experimental.jax2tf.impl_no_xla.slice_sizes_tf->jax.experimental.jax2tf.jax2tf._eval_shape(slice_sizes)
A:jax.experimental.jax2tf.impl_no_xla.begin->_clip(op_shape, begin, slice_sizes_tf)
A:jax.experimental.jax2tf.impl_no_xla.shrink_mask->sum((2 ** x for x in args.dnums.collapsed_slice_dims))
A:jax.experimental.jax2tf.impl_no_xla.res->tensorflow.strided_slice(args.operand, begin, end, shrink_axis_mask=shrink_mask)
A:jax.experimental.jax2tf.impl_no_xla.expected_offset_dims->tuple(list(range(axis)) + list(range(axis + index_dims, len(op_shape) + index_dims - 1)))
A:jax.experimental.jax2tf.impl_no_xla.squeezed_indices->tensorflow.squeeze(args.start_indices, -1)
A:jax.experimental.jax2tf.impl_no_xla.start_indices->_clip(op_shape, start_indices, update_shape_tf)
A:jax.experimental.jax2tf.impl_no_xla.batch_dims->tuple((x for x in range(len(args.out_aval.shape)) if x not in args.dnums.offset_dims))
A:jax.experimental.jax2tf.impl_no_xla.gather_fill_fn->jax.experimental.jax2tf.jax2tf._convert_jax_impl(lax_slicing._gather_fill, multiple_results=False)
A:jax.experimental.jax2tf.impl_no_xla.gather_args->GatherArgs(operand=operand, start_indices=start_indices, dnums=dimension_numbers, slice_sizes=slice_sizes, op_shape=_in_avals[0].shape, start_indices_shape=_in_avals[1].shape, out_aval=_out_aval)
A:jax.experimental.jax2tf.impl_no_xla.operand_shape->jax.experimental.jax2tf.jax2tf._eval_shape(_in_avals[0].shape)
A:jax.experimental.jax2tf.impl_no_xla.op_size->tensorflow.size(operand)
A:jax.experimental.jax2tf.impl_no_xla.update_shape_tf->jax.experimental.jax2tf.jax2tf._eval_shape(_in_avals[1].shape)
A:jax.experimental.jax2tf.impl_no_xla.end_indices->tensorflow.add(start_indices, update_shape_tf)
A:jax.experimental.jax2tf.impl_no_xla.id_tensor->tensorflow.reshape(tf.range(op_size), op_shape)
A:jax.experimental.jax2tf.impl_no_xla.scattered_indices->tensorflow.strided_slice(id_tensor, start_indices, end_indices)
A:jax.experimental.jax2tf.impl_no_xla.flat_indices->tensorflow.expand_dims(flatten(scattered_indices), -1)
A:jax.experimental.jax2tf.impl_no_xla.flat_update->flatten(update)
A:jax.experimental.jax2tf.impl_no_xla.update->tensorflow.reshape(update, op_shape)
A:jax.experimental.jax2tf.impl_no_xla.update_mask->tensorflow.reshape(update_mask, op_shape)
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.scatter_p]->_unimplemented('scatter')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.scatter_min_p]->_unimplemented('scatter min')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.scatter_max_p]->_unimplemented('scatter max')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.scatter_mul_p]->_unimplemented('scatter mul')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.scatter_add_p]->_unimplemented('scatter add')
A:jax.experimental.jax2tf.impl_no_xla.tf_impl_no_xla[lax.sort_p]->_unimplemented('sort')
jax.experimental.jax2tf.impl_no_xla.GatherArgs
jax.experimental.jax2tf.impl_no_xla.GatherArgs.__post_init__(self)
jax.experimental.jax2tf.impl_no_xla.GatherArgs.__repr__(self)
jax.experimental.jax2tf.impl_no_xla._argminmax(is_min:bool,operand:TfVal,axes:Sequence[int],index_dtype:DType,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._clip(max_indices:Sequence[TfVal],start_indices:Sequence[TfVal],slice_sizes:Sequence[TfVal])
jax.experimental.jax2tf.impl_no_xla._conv_general_dilated(lhs,rhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers:lax.ConvDimensionNumbers,feature_group_count:int,batch_group_count:int,lhs_shape:Sequence[int],rhs_shape:Sequence[int],precision:Optional[Tuple[PrecisionType,PrecisionType]],preferred_element_type:Optional[DType],_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._dot_general(lhs,rhs,*,dimension_numbers,precision:Optional[Tuple[PrecisionType,PrecisionType]],preferred_element_type:Optional[DType],_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._dynamic_slice(operand,*start_indices,slice_sizes:core.Shape,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._dynamic_update_slice(operand,update,*start_indices,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._gather(operand,start_indices,*,dimension_numbers,slice_sizes:core.Shape,indices_are_sorted,unique_indices,mode,fill_value,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._gather_for_multidim_indexing(args:GatherArgs)
jax.experimental.jax2tf.impl_no_xla._gather_for_scalar_indexing(args:GatherArgs)
jax.experimental.jax2tf.impl_no_xla._gather_with_batch_dims(args:GatherArgs)
jax.experimental.jax2tf.impl_no_xla._interior_padding(operand,padding_value,padding_config,operand_shape)
jax.experimental.jax2tf.impl_no_xla._is_valid_padding(kernel_sdims,strides,padding)
jax.experimental.jax2tf.impl_no_xla._pad(operand,padding_value,*,padding_config,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.impl_no_xla._pad_spatial_dims(in_shape,padding)
jax.experimental.jax2tf.impl_no_xla._pre_gather_for_multidim_indexing(args:GatherArgs)
jax.experimental.jax2tf.impl_no_xla._pre_gather_for_scalar_indexing(args:GatherArgs)
jax.experimental.jax2tf.impl_no_xla._pre_gather_with_batch_dims(args:GatherArgs)
jax.experimental.jax2tf.impl_no_xla._reduce_window(operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation,_in_avals,_out_aval,name=None)->TfVal
jax.experimental.jax2tf.impl_no_xla._transpose_for_tf_conv(lhs,rhs,dimension_numbers)
jax.experimental.jax2tf.impl_no_xla._unimplemented(name)
jax.experimental.jax2tf.impl_no_xla._xla_disabled_error(primitive_name:str,extra_msg:Optional[str]=None)->Exception
jax.experimental.jax2tf.impl_no_xla.gather_precondition(precondition_fn:Callable[[GatherArgs],None])
jax.experimental.jax2tf.impl_no_xla.pads_to_padtype(in_shape,window_shape,window_strides,padding)->str


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/shape_poly.py----------------------------------------
A:jax.experimental.jax2tf.shape_poly.items->self.monomials()
A:jax.experimental.jax2tf.shape_poly.d->collections.Counter(self)
A:jax.experimental.jax2tf.shape_poly.acc->set()
A:jax.experimental.jax2tf.shape_poly.coeffs->self._coeffs.copy()
A:jax.experimental.jax2tf.shape_poly.other->_ensure_poly(other)
A:jax.experimental.jax2tf.shape_poly.mon->mon1.mul(mon2)
A:jax.experimental.jax2tf.shape_poly.power->int(power)
A:jax.experimental.jax2tf.shape_poly.(lb, ub)->_ensure_poly(self - other).bounds()
A:jax.experimental.jax2tf.shape_poly.divisor->_ensure_poly(divisor)
A:jax.experimental.jax2tf.shape_poly.qmon->mon1.mul(mon2).divide(dmon)
A:jax.experimental.jax2tf.shape_poly.(qcount, rcount)->divmod(count, dcount)
A:jax.experimental.jax2tf.shape_poly.q->_DimPolynomial.from_coeffs({qmon: qcount})
A:jax.experimental.jax2tf.shape_poly.dividend->int(dividend)
A:jax.experimental.jax2tf.shape_poly.(q, r)->_ensure_poly(d - window_size).divmod(window_stride)
A:jax.experimental.jax2tf.shape_poly.lbub->self._coeffs.get(_DimMon(), 0)
A:jax.experimental.jax2tf.shape_poly.sz1->numpy.prod(s1)
A:jax.experimental.jax2tf.shape_poly.sz2->numpy.prod(s2)
A:jax.experimental.jax2tf.shape_poly.core._SPECIAL_DIMENSION_HANDLERS[_DimPolynomial]->DimensionHandlerPoly()
A:jax.experimental.jax2tf.shape_poly.shape->numpy.shape(operand)
A:jax.experimental.jax2tf.shape_poly.(contract_fake_ops, contractions)->opt_einsum.contract_path(*fake_ops, **kwargs)
A:jax.experimental.jax2tf.shape_poly.idx->tuple((i for (i, fake_op) in enumerate(fake_ops) if operand is fake_op))
A:jax.experimental.jax2tf.shape_poly.dim_as_value_p->jax.core.Primitive('dim_as_value')
A:jax.experimental.jax2tf.shape_poly.spec_->spec_.rstrip(',').rstrip(',')
A:jax.experimental.jax2tf.shape_poly.spec_tuple->tuple(map(lambda s: ... if isinstance(s, str) and s.strip() == '...' else s, spec_tuple))
A:jax.experimental.jax2tf.shape_poly.ds_ellipses->tuple((ds for ds in spec_tuple if ds == ...))
A:jax.experimental.jax2tf.shape_poly.dim_spec->dim_spec.strip().strip()
A:jax.experimental.jax2tf.shape_poly.terms->dim_spec.strip().strip().split('+')
A:jax.experimental.jax2tf.shape_poly.term_spec->term_spec.strip().strip()
A:jax.experimental.jax2tf.shape_poly.factors->term_spec.strip().strip().split('*')
A:jax.experimental.jax2tf.shape_poly.factor_spec->factor_spec.strip().strip()
A:jax.experimental.jax2tf.shape_poly.m->re.match('^([a-zA-Z]\\w*)(\\^(\\d+))?$', factor_spec)
A:jax.experimental.jax2tf.shape_poly.var->_DimPolynomial.from_var(m.group(1))
A:jax.experimental.jax2tf.shape_poly.dim_poly->_parse_dim(dim_spec)
A:jax.experimental.jax2tf.shape_poly.dim_size->int(dim_size)
A:jax.experimental.jax2tf.shape_poly.dims->tuple([_process_dim(i, ds) for (i, ds) in enumerate(spec_tuple)])
A:jax.experimental.jax2tf.shape_poly.vint->int(v.val)
A:jax.experimental.jax2tf.shape_poly.dimension_size_p->jax.core.Primitive('dimension_size')
A:jax.experimental.jax2tf.shape_poly.shape_env_jax->dict(zip(dim_vars, dim_values))
A:jax.experimental.jax2tf.shape_poly.aval_shape->_parse_spec(polymorphic_shape, arg_shape)
A:jax.experimental.jax2tf.shape_poly.avals->tuple(map(input_aval, arg_shapes, arg_jax_dtypes, polymorphic_shapes))
A:jax.experimental.jax2tf.shape_poly.dim_vars->dim_vars.union(d.get_vars()).union(d.get_vars())
A:jax.experimental.jax2tf.shape_poly.dim_env->_solve_dim_equations(dim_equations)
A:jax.experimental.jax2tf.shape_poly.mon_value->mon1.mul(mon2).evaluate(shapeenv)
A:jax.experimental.jax2tf.shape_poly.v->mon1.mul(mon2).to_var()
A:jax.experimental.jax2tf.shape_poly.var_value->jax._src.lax.lax.div(dim_expr, np.int32(factor_var))
A:jax.experimental.jax2tf.shape_poly.var_remainder->jax._src.lax.lax.rem(dim_expr, np.int32(factor_var))
A:jax.experimental.jax2tf.shape_poly.var_remainder_int->_is_known_constant(var_remainder)
A:jax.experimental.jax2tf.shape_poly.var_value_int->_is_known_constant(var_value)
A:jax.experimental.jax2tf.shape_poly.dim_expr_int->_is_known_constant(dim_expr)
A:jax.experimental.jax2tf.shape_poly.nr_eqns->len(eqns)
A:jax.experimental.jax2tf.shape_poly.unsolved_vars->unsolved_vars.difference(shapeenv.keys()).difference(shapeenv.keys())
A:jax.experimental.jax2tf.shape_poly.eqns_str->'\n  '.join([str(eqn.poly) for eqn in eqns])
jax.experimental.jax2tf.shape_poly.DimEquation
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly(core.DimensionHandler)
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly.as_value(self,d:DimSize)
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly.divide_shape_sizes(self,s1:Shape,s2:Shape)->DimSize
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly.greater_equal(self,d1:DimSize,d2:DimSize)
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly.is_constant(self,d:DimSize)->bool
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly.stride(self,d:DimSize,window_size:DimSize,window_stride:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly.DimensionHandlerPoly.symbolic_equal(self,d1:core.DimSize,d2:core.DimSize)->bool
jax.experimental.jax2tf.shape_poly.InconclusiveDimensionOperation(self,message:str)
jax.experimental.jax2tf.shape_poly.InconclusiveDimensionOperation.__init__(self,message:str)
jax.experimental.jax2tf.shape_poly.PolyShape(self,*dim_specs)
jax.experimental.jax2tf.shape_poly.PolyShape.__init__(self,*dim_specs)
jax.experimental.jax2tf.shape_poly._DimMon(dict)
jax.experimental.jax2tf.shape_poly._DimMon.__hash__(self)
jax.experimental.jax2tf.shape_poly._DimMon.__lt__(self,other:'_DimMon')
jax.experimental.jax2tf.shape_poly._DimMon.__str__(self)
jax.experimental.jax2tf.shape_poly._DimMon.degree(self)
jax.experimental.jax2tf.shape_poly._DimMon.divide(self,divisor:'_DimMon')->'_DimMon'
jax.experimental.jax2tf.shape_poly._DimMon.evaluate(self,env:ShapeEnv)
jax.experimental.jax2tf.shape_poly._DimMon.from_var(cls,v:str)->'_DimMon'
jax.experimental.jax2tf.shape_poly._DimMon.get_vars(self)->Set[str]
jax.experimental.jax2tf.shape_poly._DimMon.mul(self,other:'_DimMon')->'_DimMon'
jax.experimental.jax2tf.shape_poly._DimMon.to_var(self)->Optional[str]
jax.experimental.jax2tf.shape_poly._DimPolynomial(self,coeffs:Dict[_DimMon,int])
jax.experimental.jax2tf.shape_poly._DimPolynomial.__add__(self,other:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__floordiv__(self,divisor:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__gt__(self,other:DimSize)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__hash__(self)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__init__(self,coeffs:Dict[_DimMon,int])
jax.experimental.jax2tf.shape_poly._DimPolynomial.__int__(self)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__le__(self,other:DimSize)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__lt__(self,other:DimSize)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__mod__(self,divisor:DimSize)->int
jax.experimental.jax2tf.shape_poly._DimPolynomial.__mul__(self,other:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__ne__(self,other:DimSize)->bool
jax.experimental.jax2tf.shape_poly._DimPolynomial.__neg__(self)->'_DimPolynomial'
jax.experimental.jax2tf.shape_poly._DimPolynomial.__pow__(self,power,modulo=None)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__radd__(self,other:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__rdivmod__(self,other:DimSize)->Tuple[DimSize, int]
jax.experimental.jax2tf.shape_poly._DimPolynomial.__repr__(self)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__rfloordiv__(self,other)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__rmul__(self,other:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__rsub__(self,other:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__rtruediv__(self,dividend:DimSize)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__str__(self)
jax.experimental.jax2tf.shape_poly._DimPolynomial.__sub__(self,other:DimSize)->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.__truediv__(self,divisor:DimSize)
jax.experimental.jax2tf.shape_poly._DimPolynomial.bounds(self)->Tuple[Optional[int], Optional[int]]
jax.experimental.jax2tf.shape_poly._DimPolynomial.divmod(self,divisor:DimSize)->Tuple[DimSize, int]
jax.experimental.jax2tf.shape_poly._DimPolynomial.eq(self,other:DimSize)->bool
jax.experimental.jax2tf.shape_poly._DimPolynomial.evaluate(self,env:ShapeEnv)
jax.experimental.jax2tf.shape_poly._DimPolynomial.from_coeffs(cls,coeffs:Dict[_DimMon,int])->DimSize
jax.experimental.jax2tf.shape_poly._DimPolynomial.from_var(cls,v:str)->'_DimPolynomial'
jax.experimental.jax2tf.shape_poly._DimPolynomial.ge(self,other:DimSize)->bool
jax.experimental.jax2tf.shape_poly._DimPolynomial.get_vars(self)->Set[str]
jax.experimental.jax2tf.shape_poly._DimPolynomial.is_constant(self)
jax.experimental.jax2tf.shape_poly._DimPolynomial.leading_term(self)->Tuple[_DimMon, int]
jax.experimental.jax2tf.shape_poly._DimPolynomial.monomials(self)->Iterable[Tuple[_DimMon, int]]
jax.experimental.jax2tf.shape_poly._DimPolynomial.to_var(self)->Optional[str]
jax.experimental.jax2tf.shape_poly._add(v1,v2)
jax.experimental.jax2tf.shape_poly._dim_as_value(dim:DimSize)
jax.experimental.jax2tf.shape_poly._dim_as_value_abstract(dim:DimSize)->core.AbstractValue
jax.experimental.jax2tf.shape_poly._dimension_size_abstract(aval:core.AbstractValue,**_)->core.AbstractValue
jax.experimental.jax2tf.shape_poly._dimension_size_impl(arg,*,dimension)
jax.experimental.jax2tf.shape_poly._einsum_contract_path(*operands,**kwargs)
jax.experimental.jax2tf.shape_poly._ensure_poly(p:DimSize)->_DimPolynomial
jax.experimental.jax2tf.shape_poly._is_known_constant(v)->Optional[int]
jax.experimental.jax2tf.shape_poly._multiply(v1,v2)
jax.experimental.jax2tf.shape_poly._parse_spec(spec:Optional[Union[str,PolyShape]],arg_shape:Sequence[Optional[int]])->Tuple[DimSize, ...]
jax.experimental.jax2tf.shape_poly._solve_dim_equations(eqns:List[DimEquation])->ShapeEnv
jax.experimental.jax2tf.shape_poly.args_avals(arg_shapes:Sequence[Sequence[Optional[int]]],arg_jax_dtypes:Sequence[DType],polymorphic_shapes:Sequence[Optional[Union[str,PolyShape]]])->Sequence[core.ShapedArray]
jax.experimental.jax2tf.shape_poly.get_shape_evaluator(dim_vars:Sequence[str],shape:Sequence[DimSize])->Tuple[Callable, Sequence[core.AbstractValue]]
jax.experimental.jax2tf.shape_poly.is_poly_dim(p:DimSize)->bool
jax.experimental.jax2tf.shape_poly.prepare_dim_var_env(args_avals:Sequence[core.AbstractValue])->Tuple[Sequence[str], Callable]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/call_tf.py----------------------------------------
A:jax.experimental.jax2tf.call_tf.(args_flat_jax, args_treedef)->jax.tree_util.tree_flatten(args_jax)
A:jax.experimental.jax2tf.call_tf.dtype->jax.dtypes.canonicalize_dtype(v.dtype)
A:jax.experimental.jax2tf.call_tf.v->v.astype(dtype).astype(dtype)
A:jax.experimental.jax2tf.call_tf.args_flat_jax->tuple(map(canonical_arg, args_flat_jax))
A:jax.experimental.jax2tf.call_tf.a_tf_dtype->jax.experimental.jax2tf.jax2tf._to_tf_dtype(a_jax.dtype)
A:jax.experimental.jax2tf.call_tf.args_flat_sig_tf->tuple(map(make_tensorspec, args_flat_jax))
A:jax.experimental.jax2tf.call_tf.args_tf->args_treedef.unflatten(args_tf_flat)
A:jax.experimental.jax2tf.call_tf.res_tf->xops.Call(builder, xla_comp, args_op + tuple(captured_ops))
A:jax.experimental.jax2tf.call_tf.(res_tf_flat, res_treedef_now)->jax.tree_util.tree_flatten(res_tf)
A:jax.experimental.jax2tf.call_tf.function_flat_tf->tensorflow.function(callable_flat_tf, autograph=False, jit_compile=True)
A:jax.experimental.jax2tf.call_tf.res_jax_flat->jax.core.Primitive('call_tf').bind(*args_flat_jax, callable_flat_tf=callable_flat_tf, function_flat_tf=function_flat_tf, args_flat_sig_tf=args_flat_sig_tf)
A:jax.experimental.jax2tf.call_tf.watched_args_tf->tensorflow.nest.map_structure(replace_non_float, args_tf)
A:jax.experimental.jax2tf.call_tf.res->callable_tf(*args_tf)
A:jax.experimental.jax2tf.call_tf.dres_darg->tape.gradient(tf.nest.map_structure(replace_non_float, res), sources=watched_args_tf, output_gradients=ct_res_tf, unconnected_gradients=tf.UnconnectedGradients.ZERO)
A:jax.experimental.jax2tf.call_tf.ct_args_jax->call_tf(tf_vjp_fun)(args_jax, ct_res_jax)
A:jax.experimental.jax2tf.call_tf.arg_dtype->jax.dtypes.result_type(arg_jax)
A:jax.experimental.jax2tf.call_tf.ct_arg_dtype->jax.core.primal_dtype_to_tangent_dtype(arg_dtype)
A:jax.experimental.jax2tf.call_tf.ct_args_jax_fixed->jax.tree_util.tree_map(fix_float0, args_jax, ct_args_jax)
A:jax.experimental.jax2tf.call_tf.call_tf_p->jax.core.Primitive('call_tf')
A:jax.experimental.jax2tf.call_tf.arg_dlpack->jax.dlpack.to_dlpack(arg_jax, take_ownership=False)
A:jax.experimental.jax2tf.call_tf.args_tf_flat->tuple(map(_arg_jax_to_tf, args_jax_flat))
A:jax.experimental.jax2tf.call_tf.res_tf_flat->callable_flat_tf(*args)
A:jax.experimental.jax2tf.call_tf.(res_tf, _)->jax.experimental.jax2tf.jax2tf._tfval_to_tensor_jax_dtype(res_tf)
A:jax.experimental.jax2tf.call_tf.res_jax_platform->res_tf_platform.lower()
A:jax.experimental.jax2tf.call_tf.res_dlpack->tensorflow.experimental.dlpack.to_dlpack(res_tf)
A:jax.experimental.jax2tf.call_tf.(_, result_avals)->_code_generator_and_avals(function_flat_tf, args_flat_sig_tf, code_gen_optional=True)
A:jax.experimental.jax2tf.call_tf.(code_gen, _)->_code_generator_and_avals(function_flat_tf, args_flat_sig_tf, code_gen_optional=False)
A:jax.experimental.jax2tf.call_tf.concrete_function_flat_tf->tensorflow.function(callable_flat_tf, autograph=False, jit_compile=True).get_concrete_function(*args_flat_sig_tf)
A:jax.experimental.jax2tf.call_tf.func_tf_hlo->tensorflow.function(callable_flat_tf, autograph=False, jit_compile=True).experimental_get_compiler_ir(*args_tf_flat)(stage='hlo_serialized', device_name=tf_device_name)
A:jax.experimental.jax2tf.call_tf.xla_comp->jax._src.lib.xla_client.XlaComputation(func_tf_hlo)
A:jax.experimental.jax2tf.call_tf.xla_comp_parameter_shapes->jax._src.lib.xla_client.XlaComputation(func_tf_hlo).program_shape().parameter_shapes()
A:jax.experimental.jax2tf.call_tf.res_dtype->res_shape.numpy_dtype()
A:jax.experimental.jax2tf.call_tf.jax_res_dtype->jax.dtypes.canonicalize_dtype(res_dtype)
A:jax.experimental.jax2tf.call_tf.result_shape->jax._src.lib.xla_client.XlaComputation(func_tf_hlo).program_shape().result_shape()
A:jax.experimental.jax2tf.call_tf.result_shapes->jax._src.lib.xla_client.XlaComputation(func_tf_hlo).program_shape().result_shape().tuple_shapes()
A:jax.experimental.jax2tf.call_tf.result_avals->tuple(map(canonical_res_aval, result_shapes))
A:jax.experimental.jax2tf.call_tf.res_op->xops.ConvertElementType(res_op, new_element_type=xla.dtype_to_primitive_type(res_aval.dtype))
jax.experimental.jax2tf.call_tf(callable_tf:Callable)->Callable
jax.experimental.jax2tf.call_tf._call_tf_abstract_eval(*_,function_flat_tf,args_flat_sig_tf,**__)
jax.experimental.jax2tf.call_tf._call_tf_impl(*args_jax_flat,callable_flat_tf,**_)
jax.experimental.jax2tf.call_tf._call_tf_translation_rule(ctx,avals_in,avals_out,*args_op,function_flat_tf,args_flat_sig_tf,**_)
jax.experimental.jax2tf.call_tf._code_generator_and_avals(function_flat_tf,args_flat_sig_tf,code_gen_optional=False)->Tuple[Optional[Callable[[xla.XlaBuilder, Sequence[xla.XlaOp]], Sequence[xla.XlaOp]]], Sequence[core.ShapedArray]]
jax.experimental.jax2tf.call_tf._jax2tf_call_tf(*args:TfVal,callable_flat_tf:Callable,**_)->TfVal
jax.experimental.jax2tf.call_tf.call_tf(callable_tf:Callable)->Callable


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/jax2tf.py----------------------------------------
A:jax.experimental.jax2tf.jax2tf._VALID_SCOPE_REGEX->re.compile('^[A-Za-z0-9.][A-Za-z0-9_.\\/>-]*$')
A:jax.experimental.jax2tf.jax2tf._INVALID_SCOPE_CHAR->re.compile('[^A-Za-z0-9_.\\/>-]')
A:jax.experimental.jax2tf.jax2tf.scope_name->'.{}'.format(scope_name)
A:jax.experimental.jax2tf.jax2tf._thread_local_state->_ThreadLocalState()
A:jax.experimental.jax2tf.jax2tf.fun_name->getattr(fun, '__name__', 'unknown')
A:jax.experimental.jax2tf.jax2tf.nr_positional_args->len(args)
A:jax.experimental.jax2tf.jax2tf.kw_names->dict(kwargs, _in_avals=_in_avals_cast, _out_aval=_out_aval_cast).keys()
A:jax.experimental.jax2tf.jax2tf.(args_flat, in_tree)->jax.tree_util.tree_flatten((args, {}))
A:jax.experimental.jax2tf.jax2tf.args_and_dtypes_flat->tuple(map(_tfval_to_tensor_jax_dtype, args_flat))
A:jax.experimental.jax2tf.jax2tf.(args_flat, arg_dtypes_flat)->jax._src.util.unzip2(args_and_dtypes_flat)
A:jax.experimental.jax2tf.jax2tf.args_flat->tuple((_apply_name(a, i) for (i, a) in enumerate(args_flat)))
A:jax.experimental.jax2tf.jax2tf.polymorphic_shapes_flat->tuple(api_util.flatten_axes('jax2tf.convert polymorphic_shapes', in_tree.children()[0], polymorphic_shapes_))
A:jax.experimental.jax2tf.jax2tf.tf_arg_shape->numpy.shape(arg)
A:jax.experimental.jax2tf.jax2tf.args_shapes_flat->tuple((fix_tf1_shape(a) for a in args_flat))
A:jax.experimental.jax2tf.jax2tf.args_avals_flat->jax.experimental.jax2tf.shape_poly.args_avals(args_shapes_flat, arg_dtypes_flat, polymorphic_shapes_flat)
A:jax.experimental.jax2tf.jax2tf.(dim_vars, get_dim_values)->jax.experimental.jax2tf.shape_poly.prepare_dim_var_env(args_avals_flat)
A:jax.experimental.jax2tf.jax2tf.(dim_values, _)->jax._src.util.unzip2(_interpret_fun(lu.wrap_init(get_dim_values), args_flat, args_avals_flat, ''))
A:jax.experimental.jax2tf.jax2tf.shape_env->zip(dim_vars, dim_values)
A:jax.experimental.jax2tf.jax2tf.f->jax.linear_util.wrap_init(fun_no_kwargs)
A:jax.experimental.jax2tf.jax2tf.(flat_fun, out_tree_thunk)->jax._src.api_util.flatten_fun(f, in_tree)
A:jax.experimental.jax2tf.jax2tf.out_tree->out_tree_thunk()
A:jax.experimental.jax2tf.jax2tf.out_cts_flat_polymorphic_shapes->tuple((str(out_aval.shape) for out_aval in _out_cts_avals))
A:jax.experimental.jax2tf.jax2tf.(args_jax, kwargs_jax)->jax.tree_util.tree_unflatten(in_tree, args_flat_jax)
A:jax.experimental.jax2tf.jax2tf.(_, pullback_jax)->jax.vjp(fun_no_kwargs, *args_jax)
A:jax.experimental.jax2tf.jax2tf.out_cts_fixed_flat->tuple(map(fix_out_ct, out_cts_flat_jax, _out_cts_avals))
A:jax.experimental.jax2tf.jax2tf.out_cts_fixed->jax.tree_util.tree_unflatten(out_tree, out_cts_fixed_flat)
A:jax.experimental.jax2tf.jax2tf.in_cts_jax->pullback_jax(out_cts_fixed)
A:jax.experimental.jax2tf.jax2tf.(in_cts_flat_jax, in_cts_tree)->jax.tree_util.tree_flatten(in_cts_jax)
A:jax.experimental.jax2tf.jax2tf.in_cts_fixed_flat_jax->tuple(map(fix_in_ct, in_cts_flat_jax, args_avals_flat))
A:jax.experimental.jax2tf.jax2tf.in_cts_flat->convert(fun_vjp_jax, with_gradient=False, polymorphic_shapes=vjp_polymorphic_shapes)(args_flat, out_cts_flat)
A:jax.experimental.jax2tf.jax2tf.out_with_avals->_interpret_fun(fun, args, jaxpr.in_avals, extra_name_stack)
A:jax.experimental.jax2tf.jax2tf.(outs, out_avals)->jax._src.util.unzip2(out_with_avals)
A:jax.experimental.jax2tf.jax2tf.out_flat->converted_fun_flat_with_custom_gradient(*args_flat)
A:jax.experimental.jax2tf.jax2tf.out->tensorflow.stop_gradient(out)
A:jax.experimental.jax2tf.jax2tf.(tval, _)->_tfval_to_tensor_jax_dtype(val)
A:jax.experimental.jax2tf.jax2tf._thread_local_state.name_stack->jax._src.util.extend_name_stack(_thread_local_state.name_stack, extra_name_stack)
A:jax.experimental.jax2tf.jax2tf.fun->_interpret_subtrace(fun, main, in_avals)
A:jax.experimental.jax2tf.jax2tf.jax_results->jax_impl(*jax_args, **kwargs)
A:jax.experimental.jax2tf.jax2tf.tf_results_with_avals->_interpret_fun(lu.wrap_init(jax_impl_jax_args), tf_args, _in_avals, extra_name_stack)
A:jax.experimental.jax2tf.jax2tf.(tf_results, _)->jax._src.util.unzip2(tf_results_with_avals)
A:jax.experimental.jax2tf.jax2tf.trace->TensorFlowTrace(main, core.cur_sublevel())
A:jax.experimental.jax2tf.jax2tf.in_tracers->tuple((TensorFlowTracer(trace, val, aval) for (val, aval) in zip(in_vals, in_avals)))
A:jax.experimental.jax2tf.jax2tf.conversion_dtype->promote_tf_dtype(operand.dtype)
A:jax.experimental.jax2tf.jax2tf.(_, tf_val)->_ThreadLocalState().constant_cache.get(const_key, (None, None))
A:jax.experimental.jax2tf.jax2tf.val->numpy.zeros(np.shape(val), conversion_dtype.as_numpy_dtype)
A:jax.experimental.jax2tf.jax2tf.tf_val->tensorflow.convert_to_tensor(val, dtype=conversion_dtype)
A:jax.experimental.jax2tf.jax2tf.(dim_vars, dim_values)->jax._src.util.unzip2(_thread_local_state.shape_env)
A:jax.experimental.jax2tf.jax2tf.(eval_shape, dim_avals)->jax.experimental.jax2tf.shape_poly.get_shape_evaluator(dim_vars, shape)
A:jax.experimental.jax2tf.jax2tf.(shape_values, _)->jax._src.util.unzip2(_interpret_fun(lu.wrap_init(eval_shape), dim_values, dim_avals, ''))
A:jax.experimental.jax2tf.jax2tf.aval_int->int(_eval_shape([aval_dim]))
A:jax.experimental.jax2tf.jax2tf.(tf_val, jax_dtype)->_tfval_to_tensor_jax_dtype(val, memoize_constants=True)
A:jax.experimental.jax2tf.jax2tf.(impl, impl_needs_avals)->self.get_primitive_impl(primitive)
A:jax.experimental.jax2tf.jax2tf.(out_aval, _)->primitive.abstract_eval(*args_avals, **params)
A:jax.experimental.jax2tf.jax2tf.op_metadata->jax.interpreters.xla.make_op_metadata(primitive, params, name_stack=_get_current_name_stack(), source_info=source_info_util.current())
A:jax.experimental.jax2tf.jax2tf.op_metadata_proto->tensorflow.compiler.xla.xla_data_pb2.OpMetadata(op_type=op_metadata.op_type, op_name=op_metadata.op_name, source_file=op_metadata.source_file, source_line=op_metadata.source_line)
A:jax.experimental.jax2tf.jax2tf.val_out->invoke_impl()
A:jax.experimental.jax2tf.jax2tf.interpreted_fun->_interpret_subtrace(fun, self.main, avals)
A:jax.experimental.jax2tf.jax2tf.extra_name_stack->jax._src.util.wrap_name(params['name'], 'jit')
A:jax.experimental.jax2tf.jax2tf.(tf_res_vals, tf_res_avals)->jax._src.util.unzip2(tf_res_out)
A:jax.experimental.jax2tf.jax2tf.tf_vals_out->tensorflow.function(f_tf, autograph=False, jit_compile=True)(*vals)
A:jax.experimental.jax2tf.jax2tf.vals_out->_interpret_subtrace(fun, self.main, avals).call_wrapped(*vals)
A:jax.experimental.jax2tf.jax2tf.vals->tuple((t.val for t in out_tracers))
A:jax.experimental.jax2tf.jax2tf.tf_impl[unexpected]->partial(_unexpected_primitive, unexpected)
A:jax.experimental.jax2tf.jax2tf.x_signed->tensorflow.cast(x, signed_dtype)
A:jax.experimental.jax2tf.jax2tf.res_signed->tensorflow.math.negative(x_signed)
A:jax.experimental.jax2tf.jax2tf.sign->_sign(operand)
A:jax.experimental.jax2tf.jax2tf.floor->tensorflow.math.floor(operand)
A:jax.experimental.jax2tf.jax2tf.cond->tensorflow.math.equal(operand, tf.constant(np.array(0.5), operand.dtype))
A:jax.experimental.jax2tf.jax2tf.rounding_fun->_convert_jax_impl(lax_internal._round_to_nearest_even, multiple_results=False)
A:jax.experimental.jax2tf.jax2tf.x->tensorflow.cast(x, unsigned_dtype)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.acos_p]->_convert_jax_impl(lax_internal.acos_impl, multiple_results=False)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.asin_p]->_convert_jax_impl(lax_internal.asin_impl, multiple_results=False)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.atan_p]->_convert_jax_impl(lax_internal.atan_impl, multiple_results=False)
A:jax.experimental.jax2tf.jax2tf.complex_component_dtype->{tf.complex64: tf.float32, tf.complex128: tf.float64}.get(y.dtype)
A:jax.experimental.jax2tf.jax2tf.zero->tensorflow.constant(0, complex_component_dtype)
A:jax.experimental.jax2tf.jax2tf.one->tensorflow.constant(1, complex_component_dtype)
A:jax.experimental.jax2tf.jax2tf.i->tensorflow.complex(zero, one)
A:jax.experimental.jax2tf.jax2tf.dtype->_to_tf_dtype(dtype)
A:jax.experimental.jax2tf.jax2tf.shape_tf->_eval_shape(shape)
A:jax.experimental.jax2tf.jax2tf.vec->tensorflow.range(tf.cast(shape_tf[dimension], tf.int32), dtype=tf.int32)
A:jax.experimental.jax2tf.jax2tf.quotient->tensorflow.math.floordiv(lhs, rhs)
A:jax.experimental.jax2tf.jax2tf.select->tensorflow.math.logical_and(tf.not_equal(_sign(lhs), _sign(rhs)), tf.not_equal(tf.math.floormod(lhs, rhs), 0))
A:jax.experimental.jax2tf.jax2tf.aval->jax.core.ShapedArray((), _to_jax_dtype(x.dtype))
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.max_p]->partial(_minmax, is_min=False)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.min_p]->partial(_minmax, is_min=True)
A:jax.experimental.jax2tf.jax2tf.y->tensorflow.cast(y, unsigned_dtype)
A:jax.experimental.jax2tf.jax2tf.res->tensorflow.stop_gradient(res)
A:jax.experimental.jax2tf.jax2tf.clamp_y->tensorflow.where(_shift_in_bounds(x, y), y, x_bits - 1)
A:jax.experimental.jax2tf.jax2tf.y_lt_x_bits->tensorflow.math.less(y_comp, x_bits)
A:jax.experimental.jax2tf.jax2tf.y_ge_0->tensorflow.math.greater_equal(y_comp, 0)
A:jax.experimental.jax2tf.jax2tf.argnums->tensorflow.nest.flatten(argnums)
A:jax.experimental.jax2tf.jax2tf._out_aval_cast->tensorflow.nest.map_structure(cast_aval, kwargs['_out_aval'])
A:jax.experimental.jax2tf.jax2tf.kwargs->dict(kwargs, _in_avals=_in_avals_cast, _out_aval=_out_aval_cast)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.or_p]->handle_boolean_args(tf.bitwise.bitwise_or, argnums=(0, 1), boolean_f=tf.logical_or)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.and_p]->handle_boolean_args(tf.bitwise.bitwise_and, argnums=(0, 1), boolean_f=tf.logical_and)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.xor_p]->handle_boolean_args(tf.bitwise.bitwise_xor, argnums=(0, 1), boolean_f=tf.math.logical_xor)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.gt_p]->handle_boolean_args(tf.math.greater, argnums=(0, 1), boolean_f=boolean_greater)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.lt_p]->handle_boolean_args(tf.math.less, argnums=(0, 1), boolean_f=boolean_less)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.ge_p]->handle_boolean_args(tf.math.greater_equal, argnums=(0, 1), boolean_f=boolean_greater_or_equal)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.le_p]->handle_boolean_args(tf.math.less_equal, argnums=(0, 1), boolean_f=boolean_less_or_equal)
A:jax.experimental.jax2tf.jax2tf.operand->tensorflow.linalg.adjoint(operand)
A:jax.experimental.jax2tf.jax2tf.op_shape_tf_val->_eval_shape(_in_avals[1].shape)
A:jax.experimental.jax2tf.jax2tf.maxval->tensorflow.broadcast_to(maxval, op_shape_tf_val)
A:jax.experimental.jax2tf.jax2tf.minval->tensorflow.math.minimum(tf.broadcast_to(minval, op_shape_tf_val), maxval)
A:jax.experimental.jax2tf.jax2tf.proto->_scatter_dimensions_proto(scatter_indices.shape, dimension_numbers)
A:jax.experimental.jax2tf.jax2tf.out_tf_shape->_aval_to_tf_shape(_out_aval)
A:jax.experimental.jax2tf.jax2tf.dnums_proto->tensorflow.compiler.xla.xla_data_pb2.DotDimensionNumbers()
A:jax.experimental.jax2tf.jax2tf.precision_config_proto->_precision_config_proto(precision)
A:jax.experimental.jax2tf.jax2tf.tf_version->tuple((int(v) for v in tf.__version__.split('.')[:2]))
A:jax.experimental.jax2tf.jax2tf.k1->gen_conv(_add(lhs_real, lhs_imag), rhs_real, preferred_float_et)
A:jax.experimental.jax2tf.jax2tf.k2->gen_conv(lhs_real, tf.math.subtract(rhs_imag, rhs_real), preferred_float_et)
A:jax.experimental.jax2tf.jax2tf.k3->gen_conv(lhs_imag, _add(rhs_real, rhs_imag), preferred_float_et)
A:jax.experimental.jax2tf.jax2tf.with_1s->tensorflow.reshape(operand, _eval_shape(add_1s_shape))
A:jax.experimental.jax2tf.jax2tf.dimensions->tensorflow.range(tf.rank(operand))
A:jax.experimental.jax2tf.jax2tf.new_sizes_tf->_eval_shape(new_sizes)
A:jax.experimental.jax2tf.jax2tf.new_shape->tuple((d for (i, d) in enumerate(op_shape) if i not in dimensions))
A:jax.experimental.jax2tf.jax2tf.new_shape_tf->_eval_shape(new_shape)
A:jax.experimental.jax2tf.jax2tf.(low, high, interior)->jax._src.util.unzip3(padding_config)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.reduce_sum_p]->axes_to_axis(tf.reduce_sum)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.reduce_prod_p]->axes_to_axis(tf.reduce_prod)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.reduce_max_p]->handle_boolean_args(axes_to_axis(tf.reduce_max), argnums=[0], boolean_f=axes_to_axis(tf.reduce_any))
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.reduce_min_p]->handle_boolean_args(axes_to_axis(tf.reduce_min), argnums=[0], boolean_f=axes_to_axis(tf.reduce_all))
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.reduce_or_p]->axes_to_axis(tf.reduce_any)
A:jax.experimental.jax2tf.jax2tf.tf_impl[lax.reduce_and_p]->axes_to_axis(tf.reduce_all)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.argmin_p]->partial(_argminmax, True)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.argmax_p]->partial(_argminmax, False)
A:jax.experimental.jax2tf.jax2tf._add_fn->tensorflow.function(_add, autograph=False)
A:jax.experimental.jax2tf.jax2tf._ge_fn->tensorflow.function(tf.math.greater_equal, autograph=False)
A:jax.experimental.jax2tf.jax2tf.a->tensorflow.math.conj(a)
A:jax.experimental.jax2tf.jax2tf.b->tensorflow.transpose(b, transpose_dimensions)
A:jax.experimental.jax2tf.jax2tf.st->_shift_right_logical(t, const(double_word_dtype, nbits))
A:jax.experimental.jax2tf.jax2tf.o_spec->tensorflow.TensorSpec((), dtype=op.dtype)
A:jax.experimental.jax2tf.jax2tf.reducer_fn->tensorflow.function(reducer, autograph=False).get_concrete_function(o_spec, o_spec)
A:jax.experimental.jax2tf.jax2tf.init_val->tensorflow.constant(init_val, operand.dtype)
A:jax.experimental.jax2tf.jax2tf.(operands, init_values)->jax._src.util.split_list(args, [len(args) // 2])
A:jax.experimental.jax2tf.jax2tf.closed_jaxpr->jax.core.ClosedJaxpr(update_jaxpr, update_consts)
A:jax.experimental.jax2tf.jax2tf.(res,)->_interpret_jaxpr(closed_jaxpr, arg1, arg2, extra_name_stack=None)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.reduce_window_sum_p]->partial(_specialized_reduce_window, _add, lambda x: 0, name='reduce_window_sum')
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.reduce_window_min_p]->partial(_specialized_reduce_window, partial(_minmax_scalar, is_min=True), _get_min_identity, name='reduce_window_min')
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.reduce_window_max_p]->partial(_specialized_reduce_window, partial(_minmax_scalar, is_min=False), _get_max_identity, name='reduce_window_max')
A:jax.experimental.jax2tf.jax2tf.reducer_arg_spec->tuple([tf.TensorSpec((), op.dtype) for op in init_vals] * 2)
A:jax.experimental.jax2tf.jax2tf.xla_reducer_computation->tensorflow.function(reducer_computation, autograph=False).get_concrete_function(*reducer_arg_spec)
A:jax.experimental.jax2tf.jax2tf.outs->tuple((tf.stop_gradient(out) for out in outs))
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.cummax_p]->_cumred(lax_reduce_window_fn=lax_windowed_reductions._reduce_window_max, lax_reduce_fn=lax.max, extra_name_stack='cummax')
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.cummin_p]->_cumred(lax_reduce_window_fn=lax_windowed_reductions._reduce_window_min, lax_reduce_fn=lax.min, extra_name_stack='cummin')
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.cumsum_p]->_cumred(lax_reduce_window_fn=lax_windowed_reductions._reduce_window_sum, lax_reduce_fn=lax.add, extra_name_stack='cumsum')
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.cumprod_p]->_cumred(lax_reduce_window_fn=lax_windowed_reductions._reduce_window_prod, lax_reduce_fn=lax.mul, extra_name_stack='cumprod')
A:jax.experimental.jax2tf.jax2tf.init_value->tensorflow.zeros((), operand.dtype)
A:jax.experimental.jax2tf.jax2tf.select_fn->tensorflow.function(tf_impl[select_prim], autograph=False).get_concrete_function(init_value, init_value)
A:jax.experimental.jax2tf.jax2tf.scatter_fn->tensorflow.function(_add, autograph=False).get_concrete_function(init_value, init_value)
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[random.random_gamma_p]->_convert_jax_impl(partial(jax._src.random._gamma_impl, use_vmap=True), multiple_results=False, extra_name_stack='random_gamma')
A:jax.experimental.jax2tf.jax2tf.key->tensorflow.compiler.tf2xla.python.xla.bitcast_convert_type(key, _to_tf_dtype(jnp.uint64))
A:jax.experimental.jax2tf.jax2tf.(new_key, res)->tensorflow.compiler.tf2xla.python.xla.rng_bit_generator(algorithm_tf.value, key, shape_tf, dtype=_to_tf_dtype(dtype))
A:jax.experimental.jax2tf.jax2tf.new_key->tensorflow.stop_gradient(new_key)
A:jax.experimental.jax2tf.jax2tf.gather_fill_fn->_convert_jax_impl(lax_slicing._gather_fill, multiple_results=False)
A:jax.experimental.jax2tf.jax2tf.slice_sizes_tf->_eval_shape(slice_sizes)
A:jax.experimental.jax2tf.jax2tf.slices->tuple(map(slice, _eval_shape(start_indices), _eval_shape(limit_indices), _eval_shape(strides)))
A:jax.experimental.jax2tf.jax2tf.start_indices->tensorflow.stack(start_indices)
A:jax.experimental.jax2tf.jax2tf.clip_fn->_convert_jax_impl(lax_slicing._clamp_scatter_indices, multiple_results=False)
A:jax.experimental.jax2tf.jax2tf.scatter_indices->clip_fn(operand, scatter_indices, updates, dnums=dimension_numbers, _in_avals=_in_avals, _out_aval=_in_avals[1])
A:jax.experimental.jax2tf.jax2tf.xla_update_computation->tensorflow.function(update_computation, autograph=False).get_concrete_function(o_spec, o_spec)
A:jax.experimental.jax2tf.jax2tf.(cond_consts, body_consts, init_carry)->jax._src.util.split_list(args, [cond_nconsts, body_nconsts])
A:jax.experimental.jax2tf.jax2tf.(pred,)->_interpret_jaxpr(cond_jaxpr, *cond_consts, *args, extra_name_stack='while/cond')
A:jax.experimental.jax2tf.jax2tf.body_tf_func->partial(_interpret_jaxpr, body_jaxpr, *body_consts, extra_name_stack='while/body')
A:jax.experimental.jax2tf.jax2tf.(init_pred_b,)->_interpret_jaxpr(cond_jaxpr, *cond_consts, *init_carry, extra_name_stack='while/body_pred')
A:jax.experimental.jax2tf.jax2tf.pred->tensorflow.reduce_any(pred_b, axis=list(range(len(pred_b.shape))))
A:jax.experimental.jax2tf.jax2tf.pred_b_bcast->_broadcast_in_dim(pred_b, shape=c_aval.shape, broadcast_dimensions=list(range(len(pred_b.shape))), _in_avals=cond_jaxpr.out_avals, _out_aval=core.ShapedArray(c_aval.shape, np.bool_))
A:jax.experimental.jax2tf.jax2tf.(next_pred_b,)->_interpret_jaxpr(cond_jaxpr, *cond_consts, *selected_carry, extra_name_stack='body_pred')
A:jax.experimental.jax2tf.jax2tf.(_, *res_carry)->tensorflow.while_loop(new_cond_tf_func, new_body_tf_func, (init_pred_b, *init_carry))
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[lax.scan_p]->_convert_jax_impl(lax_control_flow._scan_impl, extra_name_stack='scan')
A:jax.experimental.jax2tf.jax2tf.tf_impl_with_avals[ad_checkpoint.remat_p]->_convert_jax_impl(partial(lax_control_flow._remat_translation_rule, platform='cpu'), multiple_results=True, extra_name_stack='checkpoint')
A:jax.experimental.jax2tf.jax2tf.(values, indices)->tensorflow.math.top_k(tf.dtypes.cast(operand, conversion_dtype), k=k, sorted=True)
A:jax.experimental.jax2tf.jax2tf.o_aval->jax.core.ShapedArray((), _to_jax_dtype(op.dtype))
A:jax.experimental.jax2tf.jax2tf.xla_comparator_computation->tensorflow.function(lexicographic_comparator, autograph=False).get_concrete_function(*comparator_spec)
A:jax.experimental.jax2tf.jax2tf.results->_interpret_jaxpr(jaxpr, *sharded_args, extra_name_stack=util.wrap_name(name, 'pjit'))
A:jax.experimental.jax2tf.jax2tf.(FFT, IFFT, RFFT, IRFFT)->list(map(xla_client.FftType, [0, 1, 2, 3]))
A:jax.experimental.jax2tf.jax2tf.result->tensorflow.transpose(result, transpose_dimensions)
A:jax.experimental.jax2tf.jax2tf.(wH, vl)->tensorflow.linalg.eig(tf.linalg.adjoint(operand))
A:jax.experimental.jax2tf.jax2tf.wHH->tensorflow.math.conj(wH)
A:jax.experimental.jax2tf.jax2tf.(w, v)->tensorflow.linalg.eigh(operand)
A:jax.experimental.jax2tf.jax2tf.cast_type->{tf.complex64: tf.float32, tf.complex128: tf.float64}.get(operand.dtype)
A:jax.experimental.jax2tf.jax2tf.w->tensorflow.cast(w, cast_type)
A:jax.experimental.jax2tf.jax2tf.a_shape->_eval_shape(a_aval.shape)
A:jax.experimental.jax2tf.jax2tf.rank->len(a.shape)
A:jax.experimental.jax2tf.jax2tf.num_partition_splits->numpy.prod(partition_dimensions)
A:jax.experimental.jax2tf.jax2tf.tile_assignment->numpy.arange(num_partition_splits).reshape(partition_dimensions)
A:jax.experimental.jax2tf.jax2tf.shard_value_for_mesh->partial(_shard_value, resource_env.physical_mesh)
A:jax.experimental.jax2tf.jax2tf.(dim_tf,)->_eval_shape((dim,))
A:jax.experimental.jax2tf.jax2tf.m->tensorflow.Module()
A:jax.experimental.jax2tf.jax2tf.tuple_wrapper->type(m.a)
A:jax.experimental.jax2tf.jax2tf.list_wrapper->type(m.b)
A:jax.experimental.jax2tf.jax2tf.dict_wrapper->type(m.c)
jax.experimental.jax2tf.convert(fun:Callable,*,polymorphic_shapes=None,with_gradient=True,enable_xla=True)->Callable
jax.experimental.jax2tf.dtype_of_val(val:TfVal)->DType
jax.experimental.jax2tf.jax2tf.TensorFlowTrace(core.Trace)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.get_primitive_impl(self,p:core.Primitive)->Tuple[Callable, bool]
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.lift(self,val:core.Tracer)->TensorFlowTracer
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.post_process_call(self,call_primitive:core.Primitive,out_tracers:Sequence[TensorFlowTracer],params)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.post_process_custom_jvp_call(self,out_tracers,_)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.post_process_custom_vjp_call(self,out_tracers,_)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.post_process_custom_vjp_call_fwd(self,*_,**__)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.post_process_map(self,map_primitive,out_tracers,params)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.process_call(self,call_primitive:core.Primitive,fun:lu.WrappedFun,tracers:Sequence[TensorFlowTracer],params)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.process_custom_jvp_call(self,prim,fun,jvp,tracers)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.process_custom_vjp_call(self,prim,fun,fwd,bwd,tracers,out_trees)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.process_map(self,map_primitive,f,tracers,params)
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.process_primitive(self,primitive:core.Primitive,tracers:Sequence[TensorFlowTracer],params)->TensorFlowTracer
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.pure(self,val:Union[TfVal,core.Unit])->TensorFlowTracer
jax.experimental.jax2tf.jax2tf.TensorFlowTrace.sublift(self,val:TensorFlowTracer)->TensorFlowTracer
jax.experimental.jax2tf.jax2tf.TensorFlowTracer(self,trace:'TensorFlowTrace',val:TfVal,aval:core.AbstractValue)
jax.experimental.jax2tf.jax2tf.TensorFlowTracer.__init__(self,trace:'TensorFlowTrace',val:TfVal,aval:core.AbstractValue)
jax.experimental.jax2tf.jax2tf.TensorFlowTracer.aval(self)
jax.experimental.jax2tf.jax2tf.TensorFlowTracer.full_lower(self)
jax.experimental.jax2tf.jax2tf._ThreadLocalState(self)
jax.experimental.jax2tf.jax2tf._ThreadLocalState.__init__(self)
jax.experimental.jax2tf.jax2tf._abs(x:TfVal)->TfVal
jax.experimental.jax2tf.jax2tf._add(x:TfVal,y:TfVal)->TfVal
jax.experimental.jax2tf.jax2tf._approx_top_k(operand:TfVal,k:int,reduction_dimension:int,recall_target:float,is_max_k:bool,reduction_input_size_override:int,aggregate_to_topk:bool)->Tuple[TfVal, TfVal]
jax.experimental.jax2tf.jax2tf._argminmax(is_min:bool,operand:TfVal,axes:Sequence[int],index_dtype:DType,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._atan2(y,x,**kwargs)
jax.experimental.jax2tf.jax2tf._aval_to_tf_shape(aval:core.ShapedArray)->Tuple[Optional[int], ...]
jax.experimental.jax2tf.jax2tf._batched_cond_while(*args:TfVal,cond_nconsts:int,cond_jaxpr:core.ClosedJaxpr,body_nconsts:int,body_jaxpr:core.ClosedJaxpr)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._bitcast_convert_type(operand,new_dtype)
jax.experimental.jax2tf.jax2tf._broadcast_in_dim(operand,*,shape,broadcast_dimensions,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._call_wrapped_with_new_constant_cache(fun:lu.WrappedFun,in_vals:Sequence[TfVal],fresh_constant_cache:bool=False)->Sequence[Tuple[TfVal, core.ShapedArray]]
jax.experimental.jax2tf.jax2tf._cbrt(x)
jax.experimental.jax2tf.jax2tf._clamp(minval,operand,maxval,*,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._common_reduce_window(operand,init_val,reducer,window_dimensions,window_strides,padding,base_dilation,window_dilation,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._concatenate(*operands,dimension)
jax.experimental.jax2tf.jax2tf._cond(index:TfVal,*operands:TfVal,branches:Sequence[core.ClosedJaxpr],linear:Sequence[bool])->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._conj(x,**kwargs)
jax.experimental.jax2tf.jax2tf._conv_general_dilated(lhs,rhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers:lax.ConvDimensionNumbers,feature_group_count:int,batch_group_count:int,lhs_shape:Sequence[int],rhs_shape:Sequence[int],precision:Optional[Tuple[PrecisionType,PrecisionType]],preferred_element_type:Optional[DType],_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._conv_general_dimension_numbers_proto(dimension_numbers)
jax.experimental.jax2tf.jax2tf._convert_element_type(operand,*,new_dtype,weak_type=False)
jax.experimental.jax2tf.jax2tf._convert_jax_impl(jax_impl:Callable,*,multiple_results=True,extra_name_stack:Optional[str]=None)->Callable
jax.experimental.jax2tf.jax2tf._cumred(lax_reduce_fn:Callable,lax_reduce_window_fn:Callable,extra_name_stack:str)
jax.experimental.jax2tf.jax2tf._custom_jvp_call_jaxpr(*args:TfVal,fun_jaxpr:core.ClosedJaxpr,jvp_jaxpr_thunk:Callable,num_consts:int)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._custom_lin(*args:TfVal,**_)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._custom_vjp_call_jaxpr(*args:TfVal,fun_jaxpr:core.ClosedJaxpr,**_)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._dim_as_value_jax2tf(dim:shape_poly.DimSize)
jax.experimental.jax2tf.jax2tf._dimension_size_jax2tf(op:TfVal,*,dimension)
jax.experimental.jax2tf.jax2tf._div(lhs,rhs)
jax.experimental.jax2tf.jax2tf._dot_general(lhs,rhs,*,dimension_numbers,precision:Optional[Tuple[PrecisionType,PrecisionType]],preferred_element_type:Optional[DType],_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._dynamic_slice(operand,*start_indices,slice_sizes:core.Shape,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._dynamic_update_slice(operand,update,*start_indices,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._eig(operand:TfVal,compute_left_eigenvectors:bool,compute_right_eigenvectors:bool)
jax.experimental.jax2tf.jax2tf._eigh(operand:TfVal,lower:bool,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._eval_shape(shape:Sequence[shape_poly.DimSize])->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._extended_name_stack(extra_name_stack:Optional[str])
jax.experimental.jax2tf.jax2tf._fft(x,fft_type,fft_lengths)
jax.experimental.jax2tf.jax2tf._gather(operand,start_indices,*,dimension_numbers,slice_sizes:core.Shape,indices_are_sorted,unique_indices,mode,fill_value,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._gather_dimensions_proto(indices_shape,dimension_numbers)
jax.experimental.jax2tf.jax2tf._get_current_name_stack()
jax.experimental.jax2tf.jax2tf._get_max_identity(tf_dtype)
jax.experimental.jax2tf.jax2tf._get_min_identity(tf_dtype)
jax.experimental.jax2tf.jax2tf._get_shape_from_tensor_or_array(x)
jax.experimental.jax2tf.jax2tf._integer_pow(x,*,y:int,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._interpret_fun(fun:lu.WrappedFun,in_vals:Sequence[TfVal],in_avals:Sequence[core.ShapedArray],extra_name_stack:Optional[str],fresh_constant_cache:bool=False)->Sequence[Tuple[TfVal, core.ShapedArray]]
jax.experimental.jax2tf.jax2tf._interpret_jaxpr(jaxpr:core.ClosedJaxpr,*args:TfVal,extra_name_stack:Optional[str])->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._interpret_subtrace(main:core.MainTrace,in_avals:Sequence[core.ShapedArray],*in_vals:TfVal)
jax.experimental.jax2tf.jax2tf._iota(*,dtype,shape,dimension)
jax.experimental.jax2tf.jax2tf._is_tfval(v:TfVal)->bool
jax.experimental.jax2tf.jax2tf._linear_solve(*args:TfVal,const_lengths,jaxprs,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._lu(operand:TfVal,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._minmax(x:TfVal,y:TfVal,*,is_min:bool,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)->TfVal
jax.experimental.jax2tf.jax2tf._minmax_scalar(x:TfVal,y:TfVal,*,is_min:bool)->TfVal
jax.experimental.jax2tf.jax2tf._neg(x:TfVal)->TfVal
jax.experimental.jax2tf.jax2tf._not(x)
jax.experimental.jax2tf.jax2tf._pad(operand,padding_value,*,padding_config,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._pjit(*args:TfVal,jaxpr:core.ClosedJaxpr,in_axis_resources:Sequence[pjit.ParsedPartitionSpec],out_axis_resources:Sequence[pjit.ParsedPartitionSpec],resource_env:maps.ResourceEnv,donated_invars,name:str,in_positional_semantics,out_positional_semantics,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)->TfVal
jax.experimental.jax2tf.jax2tf._pjit_sharding_constraint(arg:TfVal,*,axis_resources:pjit.ParsedPartitionSpec,resource_env:maps.ResourceEnv,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray,**kwargs)->TfVal
jax.experimental.jax2tf.jax2tf._population_count(x)
jax.experimental.jax2tf.jax2tf._precision__config_module_proto(precision:Optional[Tuple[PrecisionType,PrecisionType]])
jax.experimental.jax2tf.jax2tf._precision_config_proto(precision:Optional[Tuple[PrecisionType,PrecisionType]])
jax.experimental.jax2tf.jax2tf._qr(operand,full_matrices)
jax.experimental.jax2tf.jax2tf._reduce(*operands:TfVal,computation:Callable,jaxpr:core.Jaxpr,consts:Sequence[Any],dimensions:Sequence[int],_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._reduce_window(*args,jaxpr,consts,window_dimensions,window_strides,padding,base_dilation,window_dilation,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._register_checkpoint_pytrees()
jax.experimental.jax2tf.jax2tf._rem(lhs,rhs)
jax.experimental.jax2tf.jax2tf._reshape(operand,*,new_sizes,dimensions)
jax.experimental.jax2tf.jax2tf._rev(operand,*,dimensions)
jax.experimental.jax2tf.jax2tf._rng_bit_generator(key:TfVal,*,shape,dtype,algorithm)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf._rng_uniform(minval:TfVal,maxval:TfVal,*,shape)->TfVal
jax.experimental.jax2tf.jax2tf._round(operand,*,rounding_method,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._sanitize_scope_name(name)
jax.experimental.jax2tf.jax2tf._scatter(operand,scatter_indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._scatter_dimensions_proto(indices_shape,dimension_numbers)
jax.experimental.jax2tf.jax2tf._select_and_gather_add(tangents:TfVal,operand:TfVal,select_prim:core.Primitive,window_dimensions:Sequence[int],window_strides:Sequence[int],base_dilation:Sequence[int],window_dilation:Sequence[int],padding:Sequence[Tuple[int,int]],_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._select_and_scatter(operand,source,init_value,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax.experimental.jax2tf.jax2tf._select_and_scatter_add(source,operand,*,select_prim,window_dimensions,window_strides,padding,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._shard_value(mesh:maps.Mesh,val:TfVal,aval:core.ShapedArray,axis_resources:pjit.ParsedPartitionSpec)->TfVal
jax.experimental.jax2tf.jax2tf._shift_in_bounds(x:TfVal,y:TfVal)->TfVal
jax.experimental.jax2tf.jax2tf._shift_left(x,y)
jax.experimental.jax2tf.jax2tf._shift_right_arithmetic(x,y)
jax.experimental.jax2tf.jax2tf._shift_right_arithmetic_raw(x,y)
jax.experimental.jax2tf.jax2tf._shift_right_logical(x,y)
jax.experimental.jax2tf.jax2tf._shift_right_logical_raw(x,y)
jax.experimental.jax2tf.jax2tf._sign(x:TfVal)->TfVal
jax.experimental.jax2tf.jax2tf._slice(operand,start_indices,limit_indices,strides,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._sort(*operands:TfVal,dimension:int,is_stable:bool,num_keys:int)->Tuple[TfVal, ...]
jax.experimental.jax2tf.jax2tf._specialized_reduce_window(reducer,identity,operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation,_in_avals,_out_aval,name=None)
jax.experimental.jax2tf.jax2tf._squeeze(operand,*,dimensions,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._svd(operand,full_matrices,compute_uv)
jax.experimental.jax2tf.jax2tf._tfval_to_tensor_jax_dtype(val:TfVal,jax_dtype:Optional[DType]=None,memoize_constants=False)->Tuple[TfVal, DType]
jax.experimental.jax2tf.jax2tf._threefry2x32_jax_impl(*args:TfVal,_in_avals,_out_aval)
jax.experimental.jax2tf.jax2tf._to_jax_dtype(tf_dtype)
jax.experimental.jax2tf.jax2tf._to_tf_dtype(jax_dtype)
jax.experimental.jax2tf.jax2tf._top_k(operand:TfVal,k:int)->Tuple[TfVal, TfVal]
jax.experimental.jax2tf.jax2tf._transpose(operand,*,permutation)
jax.experimental.jax2tf.jax2tf._triangular_solve(a:TfVal,b:TfVal,*,left_side:bool,lower:bool,transpose_a:bool,conjugate_a:bool,unit_diagonal:bool,_in_avals:Sequence[core.ShapedArray],_out_aval:core.ShapedArray)
jax.experimental.jax2tf.jax2tf._tridiagonal_solve(*args:TfVal,_in_avals,_out_aval,**params)
jax.experimental.jax2tf.jax2tf._unexpected_primitive(p:core.Primitive,*args,**kwargs)
jax.experimental.jax2tf.jax2tf._where(which,*cases)
jax.experimental.jax2tf.jax2tf._while(*args:TfVal,cond_nconsts:int,cond_jaxpr:core.ClosedJaxpr,body_nconsts:int,body_jaxpr:core.ClosedJaxpr)->Sequence[TfVal]
jax.experimental.jax2tf.jax2tf.convert(fun:Callable,*,polymorphic_shapes=None,with_gradient=True,enable_xla=True)->Callable
jax.experimental.jax2tf.jax2tf.dtype_of_val(val:TfVal)->DType
jax.experimental.jax2tf.jax2tf.handle_boolean_args(f,argnums:Sequence[int],boolean_f=None)
jax.experimental.jax2tf.jax2tf.inside_call_tf()
jax.experimental.jax2tf.jax2tf.split_to_logical_devices(tensor:TfVal,partition_dimensions:pxla.PartitionsOrReplicated)
jax.experimental.jax2tf.split_to_logical_devices(tensor:TfVal,partition_dimensions:pxla.PartitionsOrReplicated)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/jax2tf_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, res_tf)->self.ConvertAndCompare(f_jax, 0.7)
A:jax.experimental.jax2tf.tests.jax2tf_test.xs->numpy.ones((8, 256), dtype=np.float32)
A:jax.experimental.jax2tf.tests.jax2tf_test.y->jax.numpy.tanh(x)
A:jax.experimental.jax2tf.tests.jax2tf_test.cf->f_tf(inputs).get_concrete_function([1.0, 2.0, 3.0], 4.0)
A:jax.experimental.jax2tf.tests.jax2tf_test.f_tf->tensorflow.function(f_tf)
A:jax.experimental.jax2tf.tests.jax2tf_test.v->tensorflow.Variable(0.7, dtype=jax2tf.dtype_of_val(0.7))
A:jax.experimental.jax2tf.tests.jax2tf_test.f_jax->jax.jit(lambda x: jnp.sin(jnp.cos(x)))
A:jax.experimental.jax2tf.tests.jax2tf_test.f_conc->tensorflow.function(f_tf, autograph=True).get_concrete_function(tf.convert_to_tensor(x))
A:jax.experimental.jax2tf.tests.jax2tf_test.x->numpy.ones((2, 3), np.float32)
A:jax.experimental.jax2tf.tests.jax2tf_test.n->jax.local_device_count()
A:jax.experimental.jax2tf.tests.jax2tf_test.result->jax.experimental.jax2tf.convert(f_jax)(a, b)
A:jax.experimental.jax2tf.tests.jax2tf_test.big_const->numpy.full((5,), 2 ** 33, dtype=dtype)
A:jax.experimental.jax2tf.tests.jax2tf_test.f_conv->tensorflow.function(f_conv)
A:jax.experimental.jax2tf.tests.jax2tf_test._->tape.gradient(y, x)
A:jax.experimental.jax2tf.tests.jax2tf_test.default_float_type->jax.experimental.jax2tf.dtype_of_val(4.0)
A:jax.experimental.jax2tf.tests.jax2tf_test.(u, v)->f_tf(x, y)
A:jax.experimental.jax2tf.tests.jax2tf_test.default_float_dtype->jax.experimental.jax2tf.dtype_of_val(4.0)
A:jax.experimental.jax2tf.tests.jax2tf_test.uv->f_tf((x, y))
A:jax.experimental.jax2tf.tests.jax2tf_test.inputs->OrderedDict()
A:jax.experimental.jax2tf.tests.jax2tf_test.u->f_tf(inputs)
A:jax.experimental.jax2tf.tests.jax2tf_test.primal_out->f(x)
A:jax.experimental.jax2tf.tests.jax2tf_test.grad_g->jax.grad(g, allow_int=True)
A:jax.experimental.jax2tf.tests.jax2tf_test.d_dx_jax->grad_g(x)
A:jax.experimental.jax2tf.tests.jax2tf_test.d_dx_tf->jax.experimental.jax2tf.convert(grad_g)(x)
A:jax.experimental.jax2tf.tests.jax2tf_test.res->f_tf(x=xv)
A:jax.experimental.jax2tf.tests.jax2tf_test.g_tf_native->tape.gradient(res, xs)
A:jax.experimental.jax2tf.tests.jax2tf_test.g_tf_native_0->tape.gradient(res, xs, unconnected_gradients=tf.UnconnectedGradients.ZERO)
A:jax.experimental.jax2tf.tests.jax2tf_test.conv_fn->tensorflow.function(conv_fn, autograph=False)
A:jax.experimental.jax2tf.tests.jax2tf_test.g_jax2tf->tape.gradient(res, xs, unconnected_gradients=tf.UnconnectedGradients.ZERO)
A:jax.experimental.jax2tf.tests.jax2tf_test.state->dict(float_used=np.array([0.7, 0.9], dtype=np.float32), float_passthrough=np.float16(1.0), float_unused=np.array([1.1, 2.2, 3.3], dtype=np.float32), int_used=np.int16(5), int_passthrough=np.int8(7), int_unused=np.array([1, 2, 3], dtype=np.uint32), bool_used=np.array([True, False, False, True], dtype=np.bool_), bool_passthrough=np.array([True, False, False, True, False], dtype=np.bool_), bool_unused=np.array([[True, False], [False, True]], dtype=np.bool_))
A:jax.experimental.jax2tf.tests.jax2tf_test.res_jax->jax_f(*args)
A:jax.experimental.jax2tf.tests.jax2tf_test.(vjp_jax_fun, args_vjp)->jax.experimental.jax2tf.tests.tf_test_util.TransformJaxVJP(jax_f, args, res_jax)
A:jax.experimental.jax2tf.tests.jax2tf_test.(grad_jax,)->vjp_jax_fun(*args_vjp)
A:jax.experimental.jax2tf.tests.jax2tf_test.what_keys->set(what.keys())
A:jax.experimental.jax2tf.tests.jax2tf_test.expected_keys->set(expected.keys())
A:jax.experimental.jax2tf.tests.jax2tf_test.e->numpy.ones_like(w)
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, (grad_tf_0,))->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(jax_f, args, unconnected_gradients=tf.UnconnectedGradients.ZERO)
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, (grad_tf_None,))->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(jax_f, args, unconnected_gradients=tf.UnconnectedGradients.NONE)
A:jax.experimental.jax2tf.tests.jax2tf_test.f_tf_jax->tensorflow.function(f_tf_jax, autograph=False)
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, (grad_tf_jax_0,))->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(f_tf_jax, args)
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, (grad_tf_jax_None,))->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(f_tf_jax, args, unconnected_gradients=tf.UnconnectedGradients.NONE)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_vjp_jax_fun->jax.experimental.jax2tf.convert(vjp_jax_fun)
A:jax.experimental.jax2tf.tests.jax2tf_test.(grad_tf_vjp_jax,)->tf_vjp_jax_fun(*args_vjp)
A:jax.experimental.jax2tf.tests.jax2tf_test.xv->tensorflow.nest.map_structure(tf.Variable, x)
A:jax.experimental.jax2tf.tests.jax2tf_test.m->tensorflow.Module()
A:jax.experimental.jax2tf.tests.jax2tf_test.x2->jax.numpy.sin(x1)
A:jax.experimental.jax2tf.tests.jax2tf_test.x3->jax.numpy.sin(x2)
A:jax.experimental.jax2tf.tests.jax2tf_test.x4->jax.numpy.sin(x3)
A:jax.experimental.jax2tf.tests.jax2tf_test.arg->numpy.array(3.0)
A:jax.experimental.jax2tf.tests.jax2tf_test.f_tf_graph->tensorflow.function(f_tf).get_concrete_function().graph.as_graph_def()
A:jax.experimental.jax2tf.tests.jax2tf_test.sin_1->jax.experimental.jax2tf.convert(jnp.sin)(1.0)
A:jax.experimental.jax2tf.tests.jax2tf_test.out->jax.experimental.jax2tf.convert(caller, with_gradient=False)(2.0)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fn_scalar->jax.experimental.jax2tf.convert(jax_fn_scalar)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fn_array->jax.experimental.jax2tf.convert(jax_fn_array)
A:jax.experimental.jax2tf.tests.jax2tf_test.const->numpy.ones((16, 16))
A:jax.experimental.jax2tf.tests.jax2tf_test.f_tf_nr_consts->self.CountLargeTfConstants(jax2tf.convert(f), const)
A:jax.experimental.jax2tf.tests.jax2tf_test.f1_nr_consts->self.CountLargeTfConstants(jax2tf.convert(f1), xs)
A:jax.experimental.jax2tf.tests.jax2tf_test.f2_nr_consts->self.CountLargeTfConstants(jax2tf.convert(f2), xs)
A:jax.experimental.jax2tf.tests.jax2tf_test.(res, _)->jax.lax.scan(lambda carry, x: (carry + x + const, None), np.zeros((256,), dtype=np.float32), xs)
A:jax.experimental.jax2tf.tests.jax2tf_test.f_tf_graph_nr_consts->self.CountLargeTfConstants(jax2tf.convert(f), const)
A:jax.experimental.jax2tf.tests.jax2tf_test.mul->jax.jit(jnp.multiply)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fn->jax.experimental.jax2tf.convert(lambda x: mul(x, 2.0))
A:jax.experimental.jax2tf.tests.jax2tf_test.grad_tf->tape.gradient(res, xv)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fun_with_xla->jax.experimental.jax2tf.convert(fun, enable_xla=True)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fun_without_xla->jax.experimental.jax2tf.convert(fun, enable_xla=False)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fun2_without_xla->jax.experimental.jax2tf.convert(lambda x: fun(x), enable_xla=False)
A:jax.experimental.jax2tf.tests.jax2tf_test.tf_fun2_with_xla->jax.experimental.jax2tf.convert(lambda x: fun(x), enable_xla=True)
A:jax.experimental.jax2tf.tests.jax2tf_test.user_frame->jax._src.source_info_util.user_frame(source_info_util.current())
A:jax.experimental.jax2tf.tests.jax2tf_test.z->jax.named_call(f_callee, name='callee')(y)
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, acc)->jax.lax.while_loop(lambda i_acc: i_acc[0] <= 5, body_fun, (0, x))
A:jax.experimental.jax2tf.tests.jax2tf_test.new_carry->jax.numpy.sin(carry)
A:jax.experimental.jax2tf.tests.jax2tf_test.(_, carry)->jax.lax.while_loop(lambda carry: jnp.all(carry <= x), body_fun, x)
A:jax.experimental.jax2tf.tests.jax2tf_test.jax_comp->jax.xla_computation(f_while)(x)
A:jax.experimental.jax2tf.tests.jax2tf_test.backend->jax._src.lib.xla_bridge.get_backend()
A:jax.experimental.jax2tf.tests.jax2tf_test.modules->jax._src.lib.xla_bridge.get_backend().compile(jax_comp).hlo_modules()
A:jax.experimental.jax2tf.tests.jax2tf_test.jax_opt_hlo->modules[0].to_string()
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_64bit_behavior_enable_x64(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_64bit_behavior_not_enable_x64(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_argument_eager_tensor(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_basics(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_bfloat16_constant(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_bfloat16_passed_by_tf(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_bfloat16_returned_by_jax(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_bfloat16_tf_grad(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_checkpoint_wrapper_types(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_argument_non_callable_error(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_argument_non_tensor_error(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_nullary_func(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_of_nested_dependent_jit(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_of_nested_independent_jit(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_under_transform_error(self,transform='vmap')
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_convert_under_transform_error_non_tracer(self,transform='vmap')
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_converts_64bit(self,dtype=np.int64,with_function=False)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_converts_jax_arrays(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_custom_jvp(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_custom_vjp(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_device_array_arg(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_enable_xla(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_function(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_grad_kwargs(self,with_function=False)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradient_with_float0_intermediate(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradient_with_float0_result(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_disabled(self,with_function=False)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_int_argument(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_pytree(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_unused_argument_readme(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_with_custom_jvp(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_with_custom_vjp(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_gradients_with_ordered_dict_input(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_input_output_naming(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_jit(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_kwargs(self,with_function=True)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_name_scope(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_nested_convert_error(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_nested_convert_error_non_tracer(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_nested_jit(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_nested_jit_is_compiled(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_op_metadata_batched_while(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_op_metadata_disabled(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_op_metadata_named(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_op_metadata_simple(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_op_metadata_sub_jit(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_op_metadata_while_and_cond(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_pytrees(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_randint(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_readme_gradient_int(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_remat(self,flavor='old')
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_remat_free_var(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_shared_constants(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_shared_constants_under_cond(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_shared_constants_under_jit(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_shared_constants_under_scan(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_variable_input(self)
jax.experimental.jax2tf.tests.jax2tf_test.Jax2TfTest.test_weak_types(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/savedmodel_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.savedmodel_test.f_jax->jax.jit(lambda x: jnp.sin(jnp.cos(x)))
A:jax.experimental.jax2tf.tests.savedmodel_test.model->tensorflow.Module()
A:jax.experimental.jax2tf.tests.savedmodel_test.model.f->tensorflow.function(prediction_tf, jit_compile=True)
A:jax.experimental.jax2tf.tests.savedmodel_test.x->numpy.array(0.7, dtype=jnp.float32)
A:jax.experimental.jax2tf.tests.savedmodel_test.restored_model->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadModel(model, save_gradients=False)
A:jax.experimental.jax2tf.tests.savedmodel_test.primal_out->f_jax(x)
A:jax.experimental.jax2tf.tests.savedmodel_test.xv->tensorflow.Variable(x)
A:jax.experimental.jax2tf.tests.savedmodel_test.y->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadModel(model, save_gradients=False).f(xv)
A:jax.experimental.jax2tf.tests.savedmodel_test._->tensorflow.saved_model.save(model, save_dir, options=options)
A:jax.experimental.jax2tf.tests.savedmodel_test.params_vars->tensorflow.nest.map_structure(tf.Variable, params)
A:jax.experimental.jax2tf.tests.savedmodel_test.model._variables->tensorflow.nest.flatten(params_vars)
A:jax.experimental.jax2tf.tests.savedmodel_test.state->numpy.array([1], dtype=np.int32)
A:jax.experimental.jax2tf.tests.savedmodel_test.params->numpy.ones((3, 3), dtype=np.float32)
A:jax.experimental.jax2tf.tests.savedmodel_test.res_out->tensorflow.zeros((batch_size, 2), dtype=tf.float32)
A:jax.experimental.jax2tf.tests.savedmodel_test.(res, state_out)->converted_fun_with_custom_gradient(params, state)
A:jax.experimental.jax2tf.tests.savedmodel_test.params_v->tensorflow.Variable(params)
A:jax.experimental.jax2tf.tests.savedmodel_test.loss->tensorflow.reduce_mean(preds)
A:jax.experimental.jax2tf.tests.savedmodel_test.g->tape.gradient(loss, params_v)
A:jax.experimental.jax2tf.tests.savedmodel_test.model.fn->tensorflow.function(tf_predict, autograph=False)
A:jax.experimental.jax2tf.tests.savedmodel_test.save_dir->os.path.join(absltest.get_default_test_tmpdir(), str(id(model)))
A:jax.experimental.jax2tf.tests.savedmodel_test.options->tensorflow.saved_model.SaveOptions(experimental_custom_gradients=True)
A:jax.experimental.jax2tf.tests.savedmodel_test.restored_module->tensorflow.saved_model.load(save_dir)
A:jax.experimental.jax2tf.tests.savedmodel_test.f_tf->jax.experimental.jax2tf.convert(f_jax)
A:jax.experimental.jax2tf.tests.savedmodel_test.res->f_tf(*args)
A:jax.experimental.jax2tf.tests.savedmodel_test.(restored_f, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(composed_fn, input_args=[x_str])
A:jax.experimental.jax2tf.tests.savedmodel_test.res_restored->restored_f(*args)
A:jax.experimental.jax2tf.tests.savedmodel_test.arr->numpy.arange(10, dtype=np.float32)
A:jax.experimental.jax2tf.tests.savedmodel_test.numbers_f32->tensorflow.strings.to_number(x_str, out_type=tf.float32)
A:jax.experimental.jax2tf.tests.savedmodel_test.numbers_f16->tensorflow.cast(numbers_f32, tf.float16)
A:jax.experimental.jax2tf.tests.savedmodel_test.x_str->numpy.array(['3.14', '2.78'])
A:jax.experimental.jax2tf.tests.savedmodel_test.res_tf->composed_fn(x_str)
A:jax.experimental.jax2tf.tests.savedmodel_test.res_tf_restored->restored_f(x_str)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest._compare_with_saved_model(self,f_jax,*args)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_eval(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_gradient(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_gradient_disabled(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_gradient_nested(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_save_grad_integers(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_save_without_embedding_params(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_save_without_gradients(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_tf_mix_jax_with_uncompileable(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_xla_context_preserved_gather(self)
jax.experimental.jax2tf.tests.savedmodel_test.SavedModelTest.test_xla_context_preserved_slice(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/stax_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.stax_test.this_dir->os.path.dirname(os.path.abspath(__file__))
A:jax.experimental.jax2tf.tests.stax_test.examples_dir->os.path.abspath(os.path.join(this_dir, '..', '..', '..', '..', 'examples'))
A:jax.experimental.jax2tf.tests.stax_test.resnet50->from_examples_import_resnet50()
A:jax.experimental.jax2tf.tests.stax_test.key->jax.random.PRNGKey(0)
A:jax.experimental.jax2tf.tests.stax_test.(init_fn, apply_fn)->from_examples_import_resnet50().ResNet50(1000)
A:jax.experimental.jax2tf.tests.stax_test.(_, params)->init_fn(key, shape)
A:jax.experimental.jax2tf.tests.stax_test.infer->functools.partial(apply_fn, params)
A:jax.experimental.jax2tf.tests.stax_test.images->numpy.array(jax.random.normal(key, shape))
jax.experimental.jax2tf.tests.stax_test.StaxTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.stax_test.StaxTest.test_res_net(self)
jax.experimental.jax2tf.tests.stax_test.from_examples_import_resnet50()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/sharding_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.sharding_test.jax_comp->jax.xla_computation(f_jax)(*args)
A:jax.experimental.jax2tf.tests.sharding_test.jax_hlo->jax.xla_computation(f_jax)(*args).as_hlo_text()
A:jax.experimental.jax2tf.tests.sharding_test.backend->jax._src.lib.xla_bridge.get_backend()
A:jax.experimental.jax2tf.tests.sharding_test.device_assignment->numpy.reshape(device_assignment, (-1, num_partitions))
A:jax.experimental.jax2tf.tests.sharding_test.compile_options->jax._src.lib.xla_bridge.get_compile_options(num_replicas=num_replicas, num_partitions=num_partitions, device_assignment=device_assignment, use_spmd_partitioning=use_spmd_partitioning)
A:jax.experimental.jax2tf.tests.sharding_test.jax_optimized_hlo->jax._src.lib.xla_bridge.get_backend().compile(jax_comp, compile_options).hlo_modules()[0].to_string()
A:jax.experimental.jax2tf.tests.sharding_test.f_tf->jax.experimental.jax2tf.convert(f_jax)
A:jax.experimental.jax2tf.tests.sharding_test.tf_hlo->tensorflow.function(f_tf, jit_compile=True, autograph=False).experimental_get_compiler_ir(*args)(stage='hlo', device_name=device_name)
A:jax.experimental.jax2tf.tests.sharding_test.tf_optimized_hlo->tensorflow.function(f_tf, jit_compile=True).experimental_get_compiler_ir(*args)(stage='optimized_hlo', device_name=device_name)
A:jax.experimental.jax2tf.tests.sharding_test.x->numpy.arange(np.prod(shape), dtype=np.float32).reshape(shape)
A:jax.experimental.jax2tf.tests.sharding_test.hlo->jax.xla_computation(jax_func)(x, x).as_hlo_text()
A:jax.experimental.jax2tf.tests.sharding_test.y->jax.experimental.pjit.with_sharding_constraint(y, P('x', 'y'))
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest.AssertShardingAnnotations(self,what:str,hlo:str,expected:Sequence[str])
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest._check_sharding_annotations(self,f_jax,args:Sequence[Any],*,expected:Sequence[str],expected_opt:Sequence[str],num_partitions=2)
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest.test_pjit_ShardingConstraint(self)
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest.test_pjit_TwoMeshAxisSharding(self)
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest.test_pjit_basic1D(self)
jax.experimental.jax2tf.tests.sharding_test.ShardedJitHloTest.test_pjit_basic2D(self)
jax.experimental.jax2tf.tests.sharding_test.setUpModule()
jax.experimental.jax2tf.tests.sharding_test.tearDownModule()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/jax_primitives_coverage_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.jax_primitives_coverage_test.all_dtypes->set(jtu.dtypes.all)
A:jax.experimental.jax2tf.tests.jax_primitives_coverage_test.dtypes_tested->dtypes_tested.union({h.dtype}).union({h.dtype})
A:jax.experimental.jax2tf.tests.jax_primitives_coverage_test.devices->', '.join(l.devices)
A:jax.experimental.jax2tf.tests.jax_primitives_coverage_test.template->f.read()
A:jax.experimental.jax2tf.tests.jax_primitives_coverage_test.output_file->os.path.join(os.path.dirname(__file__), '../g3doc/jax_primitives_coverage.md')
jax.experimental.jax2tf.tests.jax_primitives_coverage_test.JaxPrimitiveTest(jtu.JaxTestCase)
jax.experimental.jax2tf.tests.jax_primitives_coverage_test.JaxPrimitiveTest.test_generate_primitives_coverage_doc(self)
jax.experimental.jax2tf.tests.jax_primitives_coverage_test.JaxPrimitiveTest.test_jax_implemented(self,harness:primitive_harness.Harness)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/jax2tf_limitations.py----------------------------------------
A:jax.experimental.jax2tf.tests.jax2tf_limitations.group_method->getattr(cls, harness.group_name, None)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.limitations->group_method(harness)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.supported_dtypes->jax._src.test_util.supported_dtypes()
A:jax.experimental.jax2tf.tests.jax2tf_limitations.nr_special_cases->numpy.count_nonzero(special_cases)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.norm->numpy.linalg.norm(x, axis=(-2, -1))
A:jax.experimental.jax2tf.tests.jax2tf_limitations.rank->len(a.shape)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.aH->jax.numpy.conj(a.transpose(list(range(rank - 2)) + [rank - 1, rank - 2]))
A:jax.experimental.jax2tf.tests.jax2tf_limitations.wC->jax.numpy.conj(w)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.closest_diff->min(abs(eigenvalues_array - eigenvalue))
A:jax.experimental.jax2tf.tests.jax2tf_limitations.result->numpy.reshape(np.array(result, dtype=dtype), [*batch_dims, m, m])
A:jax.experimental.jax2tf.tests.jax2tf_limitations.k->min(m, n)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.p_mat->_make_permutation_matrix(perm)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.mask->numpy.isnan(result_jax)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.operand_jax->reconstruct_operand(r_jax)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.operand_tf->reconstruct_operand(r_tf)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.error_norm->jax.numpy.linalg.norm(operand_jax - operand_tf, axis=(-2, -1))
A:jax.experimental.jax2tf.tests.jax2tf_limitations.max_backward_error->jax.numpy.amax(backward_error)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.forward_diff->jax.numpy.diff(s, axis=-1, append=forward_appendant)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.absolute_gap->compute_absolute_gap(r_jax[0], m, n)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.sum_of_ratios->jax.numpy.sum(jnp.divide(y, x), -2, keepdims=True)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.phases->jax.numpy.divide(sum_of_ratios, jnp.abs(sum_of_ratios))
A:jax.experimental.jax2tf.tests.jax2tf_limitations.output->jax.numpy.sum(jnp.einsum('...ij,...ij->...ij', a.conj(), b, precision=lax.Precision.HIGHEST), axis=-2)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.cos_angular_diff->jax.numpy.clip(cos_angular_diff, a_min=0.0, a_max=1.0)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.angular_diff->jax.numpy.arccos(cos_angular_diff)
A:jax.experimental.jax2tf.tests.jax2tf_limitations.v_jax->jax.numpy.swapaxes(r_jax[2][..., :rank, :], -2, -1).conj()
A:jax.experimental.jax2tf.tests.jax2tf_limitations.v_tf->jax.numpy.swapaxes(r_tf[2][..., :rank, :], -2, -1).conj()
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation(self,description:str,*,devices:Union[str,Sequence[str]]=('cpu','gpu','tpu'),dtypes:Union[DType,Sequence[DType]]=(),enabled:bool=True,modes=('eager','graph','compiled'),skip_tf_run=False,expect_tf_error:bool=True,skip_comparison=False,custom_assert:Optional[Callable]=None,tol=None)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.__init__(self,description:str,*,devices:Union[str,Sequence[str]]=('cpu','gpu','tpu'),dtypes:Union[DType,Sequence[DType]]=(),enabled:bool=True,modes=('eager','graph','compiled'),skip_tf_run=False,expect_tf_error:bool=True,skip_comparison=False,custom_assert:Optional[Callable]=None,tol=None)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation._pow_test_util(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.acos(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.acosh(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.approx_max_k(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.argmax(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.argmin(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.asin(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.asinh(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.atan(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.atanh(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.bessel_i0e(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.bessel_i1e(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.cholesky(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.conv_general_dilated(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.cumprod(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.cumsum(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.custom_linear_solve(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.digamma(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.div(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.dot_general(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.eig(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.eigh(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.erf(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.erf_inv(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.erfc(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.expm1(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.fft(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.filter(self,dtype:Optional[DType]=None,device:Optional[str]=None,mode:Optional[str]=None)->bool
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.get_max_tolerance_limitation(self,limitations:Sequence['Jax2TfLimitation'])->Optional['Jax2TfLimitation']
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.helper_get_trig_custom_limitation(cls,np_inverse)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.igamma(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.igammac(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.integer_pow(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.lgamma(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.limitations_for_harness(cls,harness:primitive_harness.Harness)->Sequence['Jax2TfLimitation']
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.log1p(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.lu(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.max(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.min(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.nextafter(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.pow(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.qr(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.random_gamma(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.reduce_max(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.reduce_min(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.regularized_incomplete_beta(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.rem(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.rng_bit_generator(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.round(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.scatter_add(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.scatter_mul(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.select_and_gather_add(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.sort(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.svd(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.tan(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.tanh(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.top_k(cls,harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.triangular_solve(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.tridiagonal_solve(cls,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.jax2tf_limitations.custom_numeric(*,description='customnumericcomparison',dtypes=(),modes=('eager','graph'),devices=('cpu','gpu','tpu'),custom_assert=None,enabled=True,tol=None)->Jax2TfLimitation
jax.experimental.jax2tf.tests.jax2tf_limitations.missing_tf_kernel(*,description='opnotdefinedfordtype',dtypes,modes=('eager','graph','compiled'),devices=('cpu','gpu','tpu'),enabled=True)->Jax2TfLimitation


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/control_flow_ops_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.control_flow_ops_test.res->jax.lax.cond(True, lambda op: op * x, lambda op: op + x, x)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.primal_out->f(x)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.cond_const->numpy.ones(3, dtype=np.float32)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.body_const1->numpy.full_like(cond_const, 1.0)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.body_const2->numpy.full_like(cond_const, 2.0)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.xs->numpy.arange(4, dtype=np.int32)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.ys->numpy.arange(5, dtype=np.int32)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.body_const->numpy.ones((2,), dtype=np.float32)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.arg->numpy.full((5,), 0.7)
A:jax.experimental.jax2tf.tests.control_flow_ops_test.(c_out, _)->jax.lax.scan(body, 0.0, (xs, ys))
A:jax.experimental.jax2tf.tests.control_flow_ops_test.(res1, res2)->jax.lax.scan(body_fun, 0.0, xs + 1.0)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_cond(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_cond_custom_jvp(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_cond_custom_vjp(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_cond_multiple_results(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_cond_partial_eval(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_cond_units(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_scan(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_scan_custom_jvp(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_scan_custom_vjp(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_scan_partial_eval(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_scan_remat(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_while(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_while_batched_cond(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_while_custom_jvp(self)
jax.experimental.jax2tf.tests.control_flow_ops_test.ControlFlowOpsTest.test_while_single_carry(self)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/primitive_harness.py----------------------------------------
A:jax.experimental.jax2tf.tests.primitive_harness.all_args->self._args_from_dynargs(dyn_args)
A:jax.experimental.jax2tf.tests.primitive_harness.names->set([np.dtype(dt).name for dt in dtype_list])
A:jax.experimental.jax2tf.tests.primitive_harness.group_name->str(group_name)
A:jax.experimental.jax2tf.tests.primitive_harness.h->Harness(group_name, name, fun, arg_descriptors, rng_factory=rng_factory, jax_unimplemented=jax_unimplemented, dtype=dtype, **params)
A:jax.experimental.jax2tf.tests.primitive_harness.devices->tuple(devices)
A:jax.experimental.jax2tf.tests.primitive_harness.dtypes->tuple(dtypes)
A:jax.experimental.jax2tf.tests.primitive_harness.cases->tuple((dict(testcase_name=harness.fullname if one_containing is None else '', harness=harness) for harness in harnesses if harness.filter(jtu.device_under_test(), one_containing=one_containing, include_jax_unimpl=include_jax_unimpl)))
A:jax.experimental.jax2tf.tests.primitive_harness.operand->jax._src.test_util.rand_default(rng)(shape, dtype)
A:jax.experimental.jax2tf.tests.primitive_harness._LAX_COMPARATORS->dict(eq=jnp.equal, ne=jnp.not_equal, ge=jnp.greater_equal, gt=jnp.greater, le=jnp.less_equal, lt=jnp.less)
A:jax.experimental.jax2tf.tests.primitive_harness.arg->numpy.array([-1, -2, 0, 1], dtype=dtype)
A:jax.experimental.jax2tf.tests.primitive_harness.index_dtype->tuple(dtypes).canonicalize_dtype(index_dtype)
A:jax.experimental.jax2tf.tests.primitive_harness._min_max_special_cases->tuple(((lhs, rhs) for dtype in jtu.dtypes.all_floating + jtu.dtypes.complex for (lhs, rhs) in [(np.array([np.inf, np.inf], dtype=dtype), np.array([np.nan, np.nan], dtype=dtype)), (np.array([-np.inf, -np.inf], dtype=dtype), np.array([np.nan, np.nan], dtype=dtype))]))
A:jax.experimental.jax2tf.tests.primitive_harness.indices->numpy.array(2, dtype=np.int32)
A:jax.experimental.jax2tf.tests.primitive_harness._gather_input->numpy.arange(1000, dtype=np.float32).reshape((10, 10, 10))
A:jax.experimental.jax2tf.tests.primitive_harness.dnums_2d->jax.lax.GatherDimensionNumbers(offset_dims=(1,), collapsed_slice_dims=(0,), start_index_map=(0, 1))
A:jax.experimental.jax2tf.tests.primitive_harness.dnums_3d->jax.lax.GatherDimensionNumbers(offset_dims=(1, 2), collapsed_slice_dims=(0,), start_index_map=(0, 1, 2))
A:jax.experimental.jax2tf.tests.primitive_harness.start_indices->numpy.array(start_indices)
A:jax.experimental.jax2tf.tests.primitive_harness.dimension_numbers->jax.lax.ScatterDimensionNumbers(*dimension_numbers)
A:jax.experimental.jax2tf.tests.primitive_harness._lax_sort_multiple_array_first_arg->numpy.random.uniform(0, 2, _lax_sort_multiple_array_shape).astype(np.int32)
A:jax.experimental.jax2tf.tests.primitive_harness.a->jax._src.test_util.rand_default(rng)(shape, dtype)
A:jax.experimental.jax2tf.tests.primitive_harness.matvec->partial(lax.dot, a, precision=lax.Precision.HIGHEST)
A:jax.experimental.jax2tf.tests.primitive_harness.padding->tuple(lax.padtype_to_pads(shape, window_dimensions, window_strides, padding))
A:jax.experimental.jax2tf.tests.primitive_harness.init_val->numpy.array(init_value, dtype=dtype)
A:jax.experimental.jax2tf.tests.primitive_harness.maxval->{np.uint8: 256}.get(dtype, 5)
A:jax.experimental.jax2tf.tests.primitive_harness.shapes_str->'_'.join((jtu.format_shape_dtype_string(s, dtype) for s in shapes))
jax.experimental.jax2tf.tests.primitive_harness.CustomArg(NamedTuple)
jax.experimental.jax2tf.tests.primitive_harness.Harness(self,group_name,name,fun,arg_descriptors,*,dtype,rng_factory=jtu.rand_default,jax_unimplemented:Sequence['Limitation']=(),**params)
jax.experimental.jax2tf.tests.primitive_harness.Harness.__init__(self,group_name,name,fun,arg_descriptors,*,dtype,rng_factory=jtu.rand_default,jax_unimplemented:Sequence['Limitation']=(),**params)
jax.experimental.jax2tf.tests.primitive_harness.Harness.__str__(self)
jax.experimental.jax2tf.tests.primitive_harness.Harness._arg_maker(self,arg_descriptor,rng:Rng)
jax.experimental.jax2tf.tests.primitive_harness.Harness._args_from_dynargs(self,dyn_args:Sequence)->Sequence
jax.experimental.jax2tf.tests.primitive_harness.Harness.args_maker(self,rng:Rng)->Sequence
jax.experimental.jax2tf.tests.primitive_harness.Harness.dyn_args_maker(self,rng:Rng)->Sequence
jax.experimental.jax2tf.tests.primitive_harness.Harness.dyn_fun(self,*dyn_args)
jax.experimental.jax2tf.tests.primitive_harness.Harness.filter(self,device_under_test:str,*,include_jax_unimpl:bool=False,one_containing:Optional[str]=None)->bool
jax.experimental.jax2tf.tests.primitive_harness.Harness.fullname(self)
jax.experimental.jax2tf.tests.primitive_harness.Limitation(self,description:str,*,enabled:bool=True,devices:Union[str,Sequence[str]]=('cpu','gpu','tpu'),dtypes:Union[DType,Sequence[DType]]=(),skip_run:bool=False)
jax.experimental.jax2tf.tests.primitive_harness.Limitation.__init__(self,description:str,*,enabled:bool=True,devices:Union[str,Sequence[str]]=('cpu','gpu','tpu'),dtypes:Union[DType,Sequence[DType]]=(),skip_run:bool=False)
jax.experimental.jax2tf.tests.primitive_harness.Limitation.__str__(self)
jax.experimental.jax2tf.tests.primitive_harness.Limitation.filter(self,device:Optional[str]=None,dtype:Optional[DType]=None)->bool
jax.experimental.jax2tf.tests.primitive_harness.RandArg(NamedTuple)
jax.experimental.jax2tf.tests.primitive_harness.StaticArg(NamedTuple)
jax.experimental.jax2tf.tests.primitive_harness._can_bitcast(dtype,target_dtype)
jax.experimental.jax2tf.tests.primitive_harness._get_max_identity(dtype)
jax.experimental.jax2tf.tests.primitive_harness._get_min_identity(dtype)
jax.experimental.jax2tf.tests.primitive_harness._make_add_any_harness(name,*,shapes=((2,),(2,)),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_argminmax_harness(prim,name,*,shape=(15,),dtype=jnp.float32,axes=(0,),index_dtype=np.int32,arr=None,works_without_xla=True)
jax.experimental.jax2tf.tests.primitive_harness._make_binary_elementwise_harnesses(prim,dtypes,default_dtype=np.float32,broadcasting_dtypes=None,jax_unimplemented=lambda**kwargs:[])
jax.experimental.jax2tf.tests.primitive_harness._make_bitcast_convert_type_harness(name,*,shape=(2,3),dtype=np.float32,new_dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_broadcast_in_dim_harness(name,*,dtype=np.float32,shape=(2,),outshape=(2,),broadcast_dimensions=(0,))
jax.experimental.jax2tf.tests.primitive_harness._make_cholesky_arg(shape,dtype,rng)
jax.experimental.jax2tf.tests.primitive_harness._make_clamp_harness(name,*,min_shape=(),operand_shape=(2,3),max_shape=(),dtype=np.float32,min_max=None)
jax.experimental.jax2tf.tests.primitive_harness._make_comparator_harness(name,*,dtype=np.float32,op=lax.eq_p,op_name='eq',lhs_shape=(),rhs_shape=())
jax.experimental.jax2tf.tests.primitive_harness._make_complex_harness(name,*,shapes=((3,4),(3,4)),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_concatenate_harness(name,*,shapes=[(2,3),(2,3)],dimension=0,dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_conj_harness(name,*,shape=(3,4),dtype=np.float32,**kwargs)
jax.experimental.jax2tf.tests.primitive_harness._make_conv_harness(name,*,lhs_shape=(2,3,9,10),rhs_shape=(3,3,4,5),dtype=np.float32,window_strides=(1,1),precision=None,padding=((0,0),(0,0)),lhs_dilation=(1,1),rhs_dilation=(1,1),feature_group_count=1,dimension_numbers=('NCHW','OIHW','NCHW'),batch_group_count=1,preferred_element_type=None,works_without_xla=False)
jax.experimental.jax2tf.tests.primitive_harness._make_convert_element_type_harness(name,*,shape=(100,100),dtype=np.float32,new_dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_cumreduce_harness(name,*,f_jax=lax_control_flow.cummin,shape=(8,9),dtype=np.float32,axis=0,reverse=False)
jax.experimental.jax2tf.tests.primitive_harness._make_device_put_harness(name,*,shape=(3,4),dtype=np.float32,device=None)
jax.experimental.jax2tf.tests.primitive_harness._make_div_rem_harness(prim,name,*,shapes=((2,),(2,)),dtype=np.float32,arrs=(None,None))
jax.experimental.jax2tf.tests.primitive_harness._make_dot_general_harness(name,*,lhs_shape=(3,4),rhs_shape=(4,2),dtype=np.float32,precision=None,dimension_numbers=(((1,),(0,)),((),())),preferred_element_type=None)
jax.experimental.jax2tf.tests.primitive_harness._make_dynamic_slice_harness(name,shape=(3,),start_indices=(1,),limit_indices=(2,),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_dynamic_update_slice_harness(name,shape=(3,),start_indices=(1,),dtype=np.float32,update_shape=(1,))
jax.experimental.jax2tf.tests.primitive_harness._make_fft_harness(name,*,shape=(14,15,16,17),dtype=np.float32,fft_type=xla_client.FftType.FFT,fft_lengths=(17,))
jax.experimental.jax2tf.tests.primitive_harness._make_integer_pow_harness(name,*,shape=(20,30),dtype=np.int32,y=3)
jax.experimental.jax2tf.tests.primitive_harness._make_iota_harness(name,*,shape=(2,3),dtype=np.float32,dimension=0)
jax.experimental.jax2tf.tests.primitive_harness._make_linear_solve_harnesses()
jax.experimental.jax2tf.tests.primitive_harness._make_pow_harness(name,*,shapes=((20,30),(20,30)),dtype=np.float32,lhs=None,rhs=None)
jax.experimental.jax2tf.tests.primitive_harness._make_real_imag_harness(prim,name,*,shape=(2,3),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_reduce_harness(name,*,shape=(4,6),nr_operands=1,computation=lax.add,dimensions:Sequence[int]=(0,),init_value=0,dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_reduce_window_harness(name,*,shape=(4,6),base_dilation=(1,1),computation=lax.add,window_dimensions=(2,2),window_dilation=(1,1),init_value=0,window_strides=(1,1),dtype=np.float32,padding=((0,0),(0,0)),requires_xla=True)
jax.experimental.jax2tf.tests.primitive_harness._make_reducer_harness(prim,name,*,shape=(2,3),axes=(0,),dtype=np.int32)
jax.experimental.jax2tf.tests.primitive_harness._make_reshape_harness(name,*,shape=(2,3),new_sizes=(3,2),dimensions=(0,1),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_rev_harness(name,*,shape=(4,5),dtype=np.float32,dimensions=(0,))
jax.experimental.jax2tf.tests.primitive_harness._make_round_harness(name,*,shape=(100,100),dtype=np.float32,rounding_method=lax.RoundingMethod.AWAY_FROM_ZERO,operand=None)
jax.experimental.jax2tf.tests.primitive_harness._make_scatter_harness(name,*,shape=(5,),f_lax=lax.scatter_min,indices_are_sorted=False,unique_indices=False,scatter_indices=np.array([[0],[2]]),update_shape=(2,),mode=lax.GatherScatterMode.FILL_OR_DROP,dtype=np.float32,dimension_numbers=((),(0,),(0,)))
jax.experimental.jax2tf.tests.primitive_harness._make_select_and_gather_add_harness(name,*,shape=(4,6),dtype=np.float32,select_prim=lax.le_p,padding='VALID',window_dimensions=(2,2),window_strides=(1,1),base_dilation=(1,1),window_dilation=(1,1))
jax.experimental.jax2tf.tests.primitive_harness._make_select_and_scatter_add_harness(name,*,shape=(2,4,6),dtype=np.float32,select_prim=lax.ge_p,window_dimensions=(2,2,2),window_strides=(1,1,1),padding=((0,0),(0,0),(0,0)),nb_inactive_dims=0)
jax.experimental.jax2tf.tests.primitive_harness._make_select_n_harness(name,*,shape_pred=(2,3),shape_args=(2,3),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_slice_harness(name,shape=(3,),start_indices=(1,),limit_indices=(2,),strides=None,dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_sort_harness(name,*,operands=None,shape=(5,7),dtype=np.float32,dimension=0,is_stable=False,num_keys=1)
jax.experimental.jax2tf.tests.primitive_harness._make_squeeze_harness(name,shape=(1,2),dimensions=(0,),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_top_k_harness(name,*,operand=None,shape=(5,3),dtype=np.float32,k=2)
jax.experimental.jax2tf.tests.primitive_harness._make_transpose_harness(name,*,shape=(2,3),permutation=(1,0),dtype=np.float32)
jax.experimental.jax2tf.tests.primitive_harness._make_triangular_eigh_operand(shape,dtype,lower:bool,rng:Rng)
jax.experimental.jax2tf.tests.primitive_harness._make_triangular_solve_harness(name,*,left_side=True,lower=False,ab_shapes=((4,4),(4,1)),dtype=np.float32,transpose_a=False,conjugate_a=False,unit_diagonal=False)
jax.experimental.jax2tf.tests.primitive_harness._make_unary_elementwise_harness(*,prim,shape=(20,20),dtype)
jax.experimental.jax2tf.tests.primitive_harness.define(group_name,name,fun,arg_descriptors,*,dtype,rng_factory=jtu.rand_default,jax_unimplemented:Sequence['Limitation']=(),**params)
jax.experimental.jax2tf.tests.primitive_harness.dtypes_to_str(dtype_list:Sequence[DType],empty_means_all=False)->str
jax.experimental.jax2tf.tests.primitive_harness.parameterized(harnesses:Iterable[Harness],*,one_containing:Optional[str]=None,include_jax_unimpl:bool=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/call_tf_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.call_tf_test._parameterized_jit->absl.testing.parameterized.named_parameters((_named_test(with_jit=with_jit) for with_jit in [True, False]))
A:jax.experimental.jax2tf.tests.call_tf_test._->tensorflow.add(1, 1)
A:jax.experimental.jax2tf.tests.call_tf_test.res->reloaded_f(x)
A:jax.experimental.jax2tf.tests.call_tf_test.x->numpy.array(0.7, dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.fun_jax->jax.experimental.jax2tf.call_tf(fun_tf)
A:jax.experimental.jax2tf.tests.call_tf_test.f_jax->jax.experimental.jax2tf.call_tf(f_tf_non_compileable)
A:jax.experimental.jax2tf.tests.call_tf_test.(_, acc)->tensorflow.while_loop(c, b, [tf.constant(0), tf.constant(0.0)])
A:jax.experimental.jax2tf.tests.call_tf_test.y->numpy.concatenate([x, x])
A:jax.experimental.jax2tf.tests.call_tf_test.res_call_tf->_maybe_jit(with_jit, jax2tf.call_tf(f_tf))(x)
A:jax.experimental.jax2tf.tests.call_tf_test.res_jax->f_jax(x)
A:jax.experimental.jax2tf.tests.call_tf_test.res_call_tf_jit->jax.jit(jax2tf.call_tf(f_tf))(x)
A:jax.experimental.jax2tf.tests.call_tf_test.outer_var_array->numpy.array([3.0, 4.0], dtype=np.float64)
A:jax.experimental.jax2tf.tests.call_tf_test.outer_var->tensorflow.Variable(np.array([3.0], dtype=np.float32))
A:jax.experimental.jax2tf.tests.call_tf_test.v->tensorflow.Variable((4.0, 2.0), dtype=tf.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.tf_out->tf_func(x)
A:jax.experimental.jax2tf.tests.call_tf_test.jax_func->jax.jit(jax2tf.call_tf(tf_func))
A:jax.experimental.jax2tf.tests.call_tf_test.jax_out->jax_func(x)
A:jax.experimental.jax2tf.tests.call_tf_test.outer_tensor->tensorflow.constant(3.0, dtype=np.float64)
A:jax.experimental.jax2tf.tests.call_tf_test.outer_val->numpy.array(3.0, dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.v2->tensorflow.Variable(2.0, dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.v3->tensorflow.Variable(3.0, dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.t4->tensorflow.constant(4.0, dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.t5->tensorflow.constant(5.0, dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.grad_x->_maybe_jit(with_jit, jax.grad(jax2tf.call_tf(func_square_tf)))(x)
A:jax.experimental.jax2tf.tests.call_tf_test.b->numpy.array([[11.0, 12.0, 13.0], [21.0, 22.0, 23.0]], dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.c->numpy.array([[31.0, 32.0], [41.0, 42.0], [51.0, 52.0], [61.0, 62.0]], dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.x_dict->dict(b=b, c=c)
A:jax.experimental.jax2tf.tests.call_tf_test.prediction->inference_fn(params, rng, inputs)
A:jax.experimental.jax2tf.tests.call_tf_test.weights->numpy.array([1.0, 2.0, 3.0, 4.0], dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.weighted_pred->jax.numpy.matmul(weights, prediction['r'])
A:jax.experimental.jax2tf.tests.call_tf_test.g_fun_with_tf->jax.grad(partial(loss, jax2tf.call_tf(f_tf)))
A:jax.experimental.jax2tf.tests.call_tf_test.g_fun_with_jax->jax.grad(partial(loss, f_jax))
A:jax.experimental.jax2tf.tests.call_tf_test.g_tf->tape.gradient(res, xv)
A:jax.experimental.jax2tf.tests.call_tf_test.g_jax->grad_g(x, y)
A:jax.experimental.jax2tf.tests.call_tf_test.param->numpy.array([1.0, 2.0], dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.state->dict(array=np.float32(1.0), counter=7, truth=True)
A:jax.experimental.jax2tf.tests.call_tf_test.f_call_tf->jax.experimental.jax2tf.call_tf(f)
A:jax.experimental.jax2tf.tests.call_tf_test.g_call_tf->grad_g_call_tf(x, y)
A:jax.experimental.jax2tf.tests.call_tf_test.g->jax.grad(lambda *args: jnp.sum(f(*args)[0]))(param, state, x)
A:jax.experimental.jax2tf.tests.call_tf_test.inputs->numpy.ones((batch_size, 3), dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.rng->numpy.array([1, 2], dtype=np.uint32)
A:jax.experimental.jax2tf.tests.call_tf_test.params->numpy.float32(0.5)
A:jax.experimental.jax2tf.tests.call_tf_test.tf_model->jax.experimental.jax2tf.convert(jax_model, with_gradient=True)
A:jax.experimental.jax2tf.tests.call_tf_test.jax_loss_fn->partial(_loss_fn, jax_model)
A:jax.experimental.jax2tf.tests.call_tf_test.jax_grad->jax.grad(jax_loss_fn)(params, rng, inputs)
A:jax.experimental.jax2tf.tests.call_tf_test.paramsv->tensorflow.Variable(params)
A:jax.experimental.jax2tf.tests.call_tf_test.tf_prediction->tf_model(paramsv, rng, inputs)
A:jax.experimental.jax2tf.tests.call_tf_test.tf_loss->tensorflow.reduce_mean(tf_prediction)
A:jax.experimental.jax2tf.tests.call_tf_test.tf_grad->tape.gradient(tf_loss, paramsv)
A:jax.experimental.jax2tf.tests.call_tf_test.call_tf_loss_fn->partial(_loss_fn, jax2tf.call_tf(tf_model))
A:jax.experimental.jax2tf.tests.call_tf_test.call_tf_grad->jax.grad(call_tf_loss_fn)(params, rng, inputs)
A:jax.experimental.jax2tf.tests.call_tf_test.grad_g->jax.grad(partial(wrapper, f_jax), allow_int=True, argnums=(0, 1))
A:jax.experimental.jax2tf.tests.call_tf_test.grad_g_call_tf->jax.grad(partial(wrapper, jax2tf.call_tf(f_tf)), allow_int=True, argnums=(0, 1))
A:jax.experimental.jax2tf.tests.call_tf_test.grad_jax->jax.grad(grad_jax)
A:jax.experimental.jax2tf.tests.call_tf_test.grad_jax_pure->jax.grad(grad_jax_pure)
A:jax.experimental.jax2tf.tests.call_tf_test.res1->jax.experimental.jax2tf.call_tf(fun_tf)(x)
A:jax.experimental.jax2tf.tests.call_tf_test.hlo->tensorflow.function(fun_tf, jit_compile=True).experimental_get_compiler_ir(x)()
A:jax.experimental.jax2tf.tests.call_tf_test.outer_ct->numpy.array([3.0], dtype=np.float32)
A:jax.experimental.jax2tf.tests.call_tf_test.x_const->tensorflow.constant(0, shape=x.shape, dtype=x.dtype)
A:jax.experimental.jax2tf.tests.call_tf_test.f_tf->jax.experimental.jax2tf.convert(f_jax, polymorphic_shapes=['(b, ...)'])
A:jax.experimental.jax2tf.tests.call_tf_test.(f_tf_rt, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f_tf, input_args=[x])
A:jax.experimental.jax2tf.tests.call_tf_test.f_jax2->jax.experimental.jax2tf.call_tf(f_tf_rt)
A:jax.experimental.jax2tf.tests.call_tf_test.f_tf2->jax.experimental.jax2tf.convert(f_jax2)
A:jax.experimental.jax2tf.tests.call_tf_test.f_jax_rt->jax.experimental.jax2tf.call_tf(restored_f)
A:jax.experimental.jax2tf.tests.call_tf_test.f_rt->jax.experimental.jax2tf.call_tf(f_tf)
A:jax.experimental.jax2tf.tests.call_tf_test.(restored_tf, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f_tf, input_args=[x])
A:jax.experimental.jax2tf.tests.call_tf_test.restored_jax->jax.experimental.jax2tf.call_tf(restored_model.f)
A:jax.experimental.jax2tf.tests.call_tf_test.param_v->tensorflow.Variable(param)
A:jax.experimental.jax2tf.tests.call_tf_test.(_, restored_model)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(lambda x: f_tf(param_v, x), input_args=[x], variables=[param_v])
A:jax.experimental.jax2tf.tests.call_tf_test.(restored_f, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f_tf, input_signature=[tf.TensorSpec([None], x.dtype)])
A:jax.experimental.jax2tf.tests.call_tf_test.res_jax_y->f_jax(y)
A:jax.experimental.jax2tf.tests.call_tf_test.(g_tf, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(jax2tf.convert(g, with_gradient=True, polymorphic_shapes=['b, ...']), input_signature=[tf.TensorSpec([None], dtype=tf.float32)])
A:jax.experimental.jax2tf.tests.call_tf_test.g_rt->jax.experimental.jax2tf.call_tf(g_tf)
A:jax.experimental.jax2tf.tests.call_tf_test.(f_tf, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(jax2tf.convert(f_jax, with_gradient=True), input_args=[x], save_gradients=False)
A:jax.experimental.jax2tf.tests.call_tf_test.y_jax->jax.numpy.cos(x_jax)
A:jax.experimental.jax2tf.tests.call_tf_test.z_jax->jax.experimental.jax2tf.call_tf(f_tf_inner)(y_jax)
A:jax.experimental.jax2tf.tests.call_tf_test.y_tf->tensorflow.math.sin(x_tf)
A:jax.experimental.jax2tf.tests.call_tf_test.z_tf->jax.experimental.jax2tf.convert(f_jax)(y_tf)
A:jax.experimental.jax2tf.tests.call_tf_test.xv->tensorflow.Variable(x)
A:jax.experimental.jax2tf.tests.call_tf_test.(_, gf)->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(f_tf_outer, (x,))
A:jax.experimental.jax2tf.tests.call_tf_test.expected_res->numpy.sin(np.cos(np.sin(np.cos(np.sin(x)))))
A:jax.experimental.jax2tf.tests.call_tf_test.fun_tf_rt->jax.experimental.jax2tf.convert(fun_jax, polymorphic_shapes=['b, ...'])
A:jax.experimental.jax2tf.tests.call_tf_test.(reloaded_f, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(fun_tf_rt, input_args=[x])
A:jax.experimental.jax2tf.tests.call_tf_test.acc->numpy.array(2.0, dtype=x.dtype)
A:jax.experimental.jax2tf.tests.call_tf_test.f2_tf->tensorflow.function(f2_tf, autograph=False)
A:jax.experimental.jax2tf.tests.call_tf_test.(f2_tf, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f2_tf, input_args=[x])
A:jax.experimental.jax2tf.tests.call_tf_test.(_, (g_f2_ft,))->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(f2_tf, [x])
A:jax.experimental.jax2tf.tests.call_tf_test.(_, (g_f4_ft,))->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(f4_tf, [x])
A:jax.experimental.jax2tf.tests.call_tf_test.f4_tf->tensorflow.function(f4_tf, autograph=False)
A:jax.experimental.jax2tf.tests.call_tf_test.(f4_tf, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f4_tf, input_args=[x])
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.setUp(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_bool(self,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_control_flow(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_dtypes(self,dtype=np.int32,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_devicearray_arg(self,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_devicearray_no_copy(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_non_compileable_dynamic_shape(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_non_compileable_strings(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_numpy_arg(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_numpy_no_copy(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_numpy_res(self,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_pytree(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_scalar_arg(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_eval_scalar_res(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_experimental_get_compiler_ir_design_doc(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_function_compile_time_constant_inputs(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad(self,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad_custom(self,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad_int_argument(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad_int_argument_unused(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad_nested(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad_pytree(self,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_grad_with_float0_result(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_higher_order_grad(self,degree=2,with_jit=False)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_module_documentation(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_pmap(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_repro_193754660(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_multiple_capture(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_tensor_capture(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_tensor_capture_x64(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_value_capture(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_var_different_shape(self)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_var_read(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_var_read_x64(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_with_var_write_error(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_x64_input(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.CallTfTest.test_x64_output(self,with_jit=True)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.setUp(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_custom_grad(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_custom_grad_saved_model(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_pytree(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_saved_model_no_gradients(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_saved_model_shape_poly(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_saved_model_simple(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_saved_model_variables(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_shape_poly(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_simple(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToJaxTest.test_without_gradient_saved_model(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest.setUp(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest.test_alternate(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest.test_function_dynamic_shape(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest.test_saved_model(self)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest.test_several_round_trips(self,f2_function=False,f2_saved_model=False,f4_function=False,f4_saved_model=False)
jax.experimental.jax2tf.tests.call_tf_test.RoundTripToTfTest.test_shape_polymorphism_error(self)
jax.experimental.jax2tf.tests.call_tf_test._maybe_jit(with_jit:bool,func:Callable)->Callable
jax.experimental.jax2tf.tests.call_tf_test._named_test(**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/primitives_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.primitives_test.limitations->tuple(filter(lambda l: l.filter(device=device, dtype=harness.dtype), limitations))
A:jax.experimental.jax2tf.tests.primitives_test.device->jax._src.test_util.device_under_test()
A:jax.experimental.jax2tf.tests.primitives_test.args->harness.dyn_args_maker(self.rng())
A:jax.experimental.jax2tf.tests.primitives_test.enable_xla->harness.params.get('enable_xla', True)
A:jax.experimental.jax2tf.tests.primitives_test.associative_scan_reductions->harness.params.get('associative_scan_reductions', False)
A:jax.experimental.jax2tf.tests.primitives_test.tf_not_yet_impl->set(jax.experimental.jax2tf.jax2tf.tf_not_yet_impl)
A:jax.experimental.jax2tf.tests.primitives_test.all_primitives->tuple(sorted(all_primitives, key=str))
A:jax.experimental.jax2tf.tests.primitives_test.tfl->Jax2TfLimitation(description='Not implemented in JAX: ' + l.description, devices=l.devices, dtypes=l.dtypes, expect_tf_error=False, skip_tf_run=True)
A:jax.experimental.jax2tf.tests.primitives_test.tf_numerical_discrepancies_table->list(tf_error_table)
A:jax.experimental.jax2tf.tests.primitives_test.devices->', '.join(sorted(l.devices))
A:jax.experimental.jax2tf.tests.primitives_test.modes->', '.join(sorted(l.modes))
A:jax.experimental.jax2tf.tests.primitives_test.template->f.read()
A:jax.experimental.jax2tf.tests.primitives_test.output_file->os.path.join(os.path.dirname(__file__), '../g3doc/primitives_with_limited_support.md')
A:jax.experimental.jax2tf.tests.primitives_test.x->jax.numpy.array([-4, -3, -1, 0, 1, 3, 6])
A:jax.experimental.jax2tf.tests.primitives_test.y->numpy.int32(3)
A:jax.experimental.jax2tf.tests.primitives_test.expected->jax.numpy.floor_divide(x, y)
A:jax.experimental.jax2tf.tests.primitives_test.tf1_res->sess.run(jax2tf.convert(jnp.floor_divide)(x, y))
A:jax.experimental.jax2tf.tests.primitives_test.values->numpy.array([True, False, True], dtype=np.bool_)
A:jax.experimental.jax2tf.tests.primitives_test.indices->jax.numpy.array([[1, 1, 2], [0, 1, 0]])
A:jax.experimental.jax2tf.tests.primitives_test.f_jax->jax.jit(lambda v, u: getattr(v.at[::2, 3:], op)(u))
A:jax.experimental.jax2tf.tests.primitives_test.params->jax.numpy.array([[1.0, 1.5, 2.0], [2.0, 2.5, 3.0], [3.0, 3.5, 4.0]])
A:jax.experimental.jax2tf.tests.primitives_test.update->numpy.float32(6.0)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_boolean_gather(self)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_gather_rank_change(self)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_generate_limitations_doc(self)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_integer_div(self)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_prim(self,harness:primitive_harness.Harness)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_primitive_coverage(self)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_reduce_ops_with_boolean_input(self,f_jax)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_reduce_ops_with_numerical_input(self,f_jax)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_scatter_static(self,op)
jax.experimental.jax2tf.tests.primitives_test.JaxPrimitiveTest.test_type_promotion(self,f_jax=jnp.add)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/shape_poly_test.py----------------------------------------
A:jax.experimental.jax2tf.tests.shape_poly_test.(a, b)->jax.experimental.jax2tf.shape_poly._parse_spec('a, b', (2, 3))
A:jax.experimental.jax2tf.tests.shape_poly_test.tshape->tensorflow.TensorShape([None, 3])
A:jax.experimental.jax2tf.tests.shape_poly_test.(a, b, a1)->jax.experimental.jax2tf.shape_poly._parse_spec('a, b, a', (2, 3, 2))
A:jax.experimental.jax2tf.tests.shape_poly_test.(a,)->jax.experimental.jax2tf.shape_poly._parse_spec('a,', (2,))
A:jax.experimental.jax2tf.tests.shape_poly_test.(a, stride)->jax.experimental.jax2tf.shape_poly._parse_spec('a, s', (2, 3))
A:jax.experimental.jax2tf.tests.shape_poly_test.x->self.rng().rand(6, 2, 3)
A:jax.experimental.jax2tf.tests.shape_poly_test.y->jax.numpy.sin(x)
A:jax.experimental.jax2tf.tests.shape_poly_test.f_tf->tensorflow.function(jax2tf.convert(f_jax, polymorphic_shapes=[PS('b', ...)]), autograph=False, jit_compile=True).get_concrete_function(tf.TensorSpec([None, 2, 3], x.dtype))
A:jax.experimental.jax2tf.tests.shape_poly_test.avals->jax.experimental.jax2tf.shape_poly.args_avals(arg_shapes, arg_dtypes, polymorphic_shapes)
A:jax.experimental.jax2tf.tests.shape_poly_test.(dim_vars, get_dim_values)->jax.experimental.jax2tf.shape_poly.prepare_dim_var_env(avals)
A:jax.experimental.jax2tf.tests.shape_poly_test.(dim_values, _)->jax._src.util.unzip2(jax2tf.jax2tf._interpret_fun(lu.wrap_init(get_dim_values), tf_args, avals, ''))
A:jax.experimental.jax2tf.tests.shape_poly_test.shape_env->f_tf(*[tf.ones(a_s, dtype=_f32) for a_s in arg_shapes])
A:jax.experimental.jax2tf.tests.shape_poly_test.res_jax->f_jax(x)
A:jax.experimental.jax2tf.tests.shape_poly_test.res_jax_grad->jax.grad(lambda x: jnp.sum(f(x)))(x)
A:jax.experimental.jax2tf.tests.shape_poly_test.xv->numpy.arange(24.0).reshape((2, 3, 4))
A:jax.experimental.jax2tf.tests.shape_poly_test.res_tf->f_tf(xv)
A:jax.experimental.jax2tf.tests.shape_poly_test.res_tf_grad->tape.gradient(res_tf, xv)
A:jax.experimental.jax2tf.tests.shape_poly_test.(res_tf, res_tf_grad)->tf_value_and_grad(xv)
A:jax.experimental.jax2tf.tests.shape_poly_test.tf_grad->tensorflow.function(tf_value_and_grad, autograph=False).get_concrete_function(tf.TensorSpec([None, 3, 4]))
A:jax.experimental.jax2tf.tests.shape_poly_test.grad_tf->tape.gradient(res_tf, xv)
A:jax.experimental.jax2tf.tests.shape_poly_test.xi->numpy.arange(np.prod(x_shape), dtype=np.int16).reshape(x_shape)
A:jax.experimental.jax2tf.tests.shape_poly_test.yf->numpy.arange(np.prod(x_shape), dtype=np.int16).reshape(x_shape).astype(np.float32)
A:jax.experimental.jax2tf.tests.shape_poly_test.zb->numpy.array([True, False], dtype=np.bool_)
A:jax.experimental.jax2tf.tests.shape_poly_test.(res_tf, g_tf)->jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(f_tf, args)
A:jax.experimental.jax2tf.tests.shape_poly_test.(restored_f, _)->jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f_tf, input_signature=[tf.TensorSpec([None], x.dtype)])
A:jax.experimental.jax2tf.tests.shape_poly_test.f_jax_rt->jax.experimental.jax2tf.call_tf(restored_f)
A:jax.experimental.jax2tf.tests.shape_poly_test.res_jax_rt->f_jax_rt(x)
A:jax.experimental.jax2tf.tests.shape_poly_test.four_ones->numpy.ones((4,))
A:jax.experimental.jax2tf.tests.shape_poly_test.x0->numpy.array([], np.float32)
A:jax.experimental.jax2tf.tests.shape_poly_test.x45->numpy.ones((4, 5), dtype=np.float32)
A:jax.experimental.jax2tf.tests.shape_poly_test.(res_primal, res_tangent)->jax.experimental.jax2tf.convert(lambda x, xt: jax.jvp(f, (x,), (xt,)), polymorphic_shapes=['b', 'b'])(x, np.array([0.1, 0.2, 0.3]))
A:jax.experimental.jax2tf.tests.shape_poly_test.res_vmap->jax.vmap(f, in_axes=1)(xv)
A:jax.experimental.jax2tf.tests.shape_poly_test.res_iter->jax.numpy.stack([f(xv[:, i, :]) for i in range(xv.shape[1])])
A:jax.experimental.jax2tf.tests.shape_poly_test.res_vmap_tf->jax.experimental.jax2tf.convert(jax.vmap(f, in_axes=1), polymorphic_shapes=['b1, b2, ...'])(xv)
A:jax.experimental.jax2tf.tests.shape_poly_test.poly_axes->tuple(map(lambda pa: pa if isinstance(pa, Sequence) or pa is None else (pa,), poly_axes))
A:jax.experimental.jax2tf.tests.shape_poly_test.device->jax._src.test_util.device_under_test()
A:jax.experimental.jax2tf.tests.shape_poly_test.c->collections.Counter([h.dtype for h in hlist])
A:jax.experimental.jax2tf.tests.shape_poly_test.((dtype, _),)->collections.Counter([h.dtype for h in hlist]).most_common(1)
A:jax.experimental.jax2tf.tests.shape_poly_test._NOT_SUPPORTED_YET->frozenset(['lu', 'custom_linear_solve', 'conv_general_dilated', 'tridiagonal_solve', 'iota', 'rng_bit_generator'])
A:jax.experimental.jax2tf.tests.shape_poly_test.arg->ad.make(rng)
A:jax.experimental.jax2tf.tests.shape_poly_test.check_result->all((not l.custom_assert and (not l.skip_comparison) and (l.tol is None) for l in _get_jax2tf_limitations(device, h)))
A:jax.experimental.jax2tf.tests.shape_poly_test.vmap_harness->_make_harness(h.group_name, f'vmap_{h.name}', jax.vmap(h.dyn_fun, in_axes=0, out_axes=0), new_args, poly_axes=[0] * len(new_args), check_result=check_result, **h.params)
A:jax.experimental.jax2tf.tests.shape_poly_test.limitations->jax.experimental.jax2tf.tests.jax2tf_limitations.Jax2TfLimitation.limitations_for_harness(h)
A:jax.experimental.jax2tf.tests.shape_poly_test.args->harness.dyn_args_maker(self.rng())
A:jax.experimental.jax2tf.tests.shape_poly_test.(arg_polymorphic_shapes, arg_tensorspec)->make_arg_polymorphic_shapes(poly_axis)
A:jax.experimental.jax2tf.tests.shape_poly_test.enable_xla->harness.params.get('enable_xla', True)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest.test_concrete_shapes(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest.test_dynamic_shapes(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest.test_error_jax_value(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest.test_errors(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest.test_mean0(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimAsValueTest.test_mean_all_axes(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_core_greater_equal(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_dilate_shape(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_dim_vars(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_dim_vars_symbolic_equal(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_evaluate(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_get_vars(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_parse_poly_spec(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_parse_poly_spec_poly(self,dim_spec='3*a*b*a+-2',dim_poly=3*a*b*a-2)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_parse_poly_spec_shapeenv(self,dim_spec='3*a*b*a+-2',dim_poly=3*a*b*a-2)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_bounds(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_compare(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_compare_overload(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_divmod(self,*,dividend,quotient,divisor,remainder)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_equal(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_int_results(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_truediv(self,*,dividend,divisor,quotient)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_poly_truediv_error(self)
jax.experimental.jax2tf.tests.shape_poly_test.DimPolynomialTest.test_stride_shape(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyPrimitivesTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyPrimitivesTest.test_prim(self,harness:Harness)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyPrimitivesTest.test_reshape_compiled(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyPrimitivesTest.test_vmap_while(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_arg_avals(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_cond(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_forgot_polymorphic_shapes_error(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_grad_int(self,with_function=True)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_grad_not_var_output(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_gradients_pytree(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_kwargs(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_pytree(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_readme_example(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_readme_shape_error(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_saved_model(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_saved_model_constant_gradient(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_saved_model_int_function(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_simple_binary(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_simple_unary(self)
jax.experimental.jax2tf.tests.shape_poly_test.ShapePolyTest.test_with_custom_vjp(self)
jax.experimental.jax2tf.tests.shape_poly_test._add_vmap_primitive_harnesses()
jax.experimental.jax2tf.tests.shape_poly_test._flatten_harnesses(harnesses)
jax.experimental.jax2tf.tests.shape_poly_test._get_jax2tf_limitations(device,h:primitive_harness.Harness)->Sequence[Jax2TfLimitation]
jax.experimental.jax2tf.tests.shape_poly_test._make_harness(group_name:str,name:str,func:Callable,args:primitive_harness.ArgDescriptor,*,poly_axes:Sequence[Optional[Union[int,Sequence[int]]]],check_result=True,skip_jax_run=True,tol=None,enable_and_diable_xla=False,expect_error=(None,None),**params)->Union[Harness, Sequence[Harness]]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/tests/tf_test_util.py----------------------------------------
A:jax.experimental.jax2tf.tests.tf_test_util.model_dir->os.path.join(absltest.get_default_test_tmpdir(), str(id(model)))
A:jax.experimental.jax2tf.tests.tf_test_util.restored_model->tensorflow.saved_model.load(model_dir)
A:jax.experimental.jax2tf.tests.tf_test_util.model->tensorflow.train.Checkpoint()
A:jax.experimental.jax2tf.tests.tf_test_util.input_signature->tensorflow.nest.map_structure(lambda a: tf.TensorSpec(a.shape, a.dtype), input_args)
A:jax.experimental.jax2tf.tests.tf_test_util.model.f->tensorflow.function(f_tf, autograph=False, input_signature=input_signature)
A:jax.experimental.jax2tf.tests.tf_test_util.restored->SaveAndLoadModel(model, save_gradients=save_gradients)
A:jax.experimental.jax2tf.tests.tf_test_util.res_dtype->numpy.result_type(res)
A:jax.experimental.jax2tf.tests.tf_test_util.cts->jax.tree_util.tree_map(make_ct, res_f_of_args)
A:jax.experimental.jax2tf.tests.tf_test_util.(res, pullback)->jax.vjp(f, *args)
A:jax.experimental.jax2tf.tests.tf_test_util.tf_vars->tensorflow.nest.map_structure(tf.Variable, tf_args)
A:jax.experimental.jax2tf.tests.tf_test_util.res_tf->tf_f(*tf_vars)
A:jax.experimental.jax2tf.tests.tf_test_util.grad->tape.gradient(res_tf, tf_vars, unconnected_gradients=unconnected_gradients)
A:jax.experimental.jax2tf.tests.tf_test_util.(f1, args1)->TransformTfValueAndGrad(tf_f, tf_args, unconnected_gradients=unconnected_gradients)
A:jax.experimental.jax2tf.tests.tf_test_util.result_jax->func_jax(*args)
A:jax.experimental.jax2tf.tests.tf_test_util.func_tf->jax.experimental.jax2tf.convert(func_jax, enable_xla=enable_xla)
A:jax.experimental.jax2tf.tests.tf_test_util.jax2tf_limits->tuple(filter(lambda l: l.filter(mode=mode), limitations))
A:jax.experimental.jax2tf.tests.tf_test_util.result_tf->tensorflow.nest.map_structure(lambda t: t.numpy(), result_tf)
A:jax.experimental.jax2tf.tests.tf_test_util.jax_comp->jax.xla_computation(func_jax)(*args)
A:jax.experimental.jax2tf.tests.tf_test_util.jax_hlo->jax.xla_computation(func_jax)(*args).as_hlo_text()
A:jax.experimental.jax2tf.tests.tf_test_util.tf_args_signature->_make_tf_input_signature(*args)
A:jax.experimental.jax2tf.tests.tf_test_util.tf_args_no_scalars->tuple(map(lambda a, sig: tf.convert_to_tensor(a, dtype=sig.dtype), args, tf_args_signature))
A:jax.experimental.jax2tf.tests.tf_test_util.tf_func_compiled->tensorflow.function(func_tf, autograph=False, jit_compile=True, input_signature=tf_args_signature)
A:jax.experimental.jax2tf.tests.tf_test_util.tf_hlo->tensorflow.function(func_tf, autograph=False, jit_compile=True, input_signature=tf_args_signature).experimental_get_compiler_ir(*tf_args_no_scalars)(stage='hlo')
A:jax.experimental.jax2tf.tests.tf_test_util.backend->jax._src.lib.xla_bridge.get_backend()
A:jax.experimental.jax2tf.tests.tf_test_util.modules->jax._src.lib.xla_bridge.get_backend().compile(jax_comp).hlo_modules()
A:jax.experimental.jax2tf.tests.tf_test_util.jax_opt_hlo->modules[0].to_string()
A:jax.experimental.jax2tf.tests.tf_test_util.tf_opt_hlo->tensorflow.function(func_tf, autograph=False, jit_compile=True, input_signature=tf_args_signature).experimental_get_compiler_ir(*tf_args_no_scalars)(stage='optimized_hlo')
A:jax.experimental.jax2tf.tests.tf_test_util.t_arg->numpy.stack([arg] * 4)
A:jax.experimental.jax2tf.tests.tf_test_util.grad_func->jax.grad(lambda x: jnp.sum(jax.vmap(func)(x)))
A:jax.experimental.jax2tf.tests.tf_test_util.f_tf->tensorflow.function(jax2tf.convert(jax_fun, include_xla_op_metadata=include_xla_op_metadata), autograph=False, input_signature=[tf.TensorSpec(x.shape, x.dtype)])
A:jax.experimental.jax2tf.tests.tf_test_util.f_tf_func->tensorflow.function(f_tf, autograph=False, input_signature=input_signature)
A:jax.experimental.jax2tf.tests.tf_test_util.concrete_f_tf->tensorflow.function(f_tf, autograph=False, input_signature=input_signature).get_concrete_function(*input_signature)
A:jax.experimental.jax2tf.tests.tf_test_util.in_spec->jax.interpreters.masking.parse_spec(poly_shape)
A:jax.experimental.jax2tf.tests.tf_test_util.f_tf_graph->tensorflow.function(tf_fun, autograph=False).get_concrete_function(*args).graph.as_graph_def()
A:jax.experimental.jax2tf.tests.tf_test_util.matches->re.findall('tensor_content\\s*:\\s*\\"([^\\"]+)\\"', str(f_tf_graph))
A:jax.experimental.jax2tf.tests.tf_test_util.f_tf_concrete->tensorflow.function(jax2tf.convert(jax_fun, include_xla_op_metadata=include_xla_op_metadata), autograph=False, input_signature=[tf.TensorSpec(x.shape, x.dtype)]).get_concrete_function(tf.convert_to_tensor(x))
A:jax.experimental.jax2tf.tests.tf_test_util.op_metadata->n.get_attr('_XlaOpMetadata')
A:jax.experimental.jax2tf.tests.tf_test_util.op_metadata_proto->tensorflow.compiler.xla.xla_data_pb2.OpMetadata()
A:jax.experimental.jax2tf.tests.tf_test_util.branch->getattr(n, f'_branch_graph_{idx}', None)
jax.experimental.jax2tf.tests.tf_test_util.ComputeTfValueAndGrad(tf_f:Callable,tf_args:Sequence,unconnected_gradients=tf.UnconnectedGradients.ZERO)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase(jtu.JaxTestCase)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.CheckOpMetadata(self,jax_fun,x,expected:Sequence[OpMetadataGraph],include_xla_op_metadata=True)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.CheckShapePolymorphism(self,f_jax:Callable,*,input_signature:Sequence[tf.TensorSpec],polymorphic_shapes:Optional[Sequence[Any]],expected_output_signature:Optional[tf.TensorSpec]=None,enable_xla:bool=True)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.ConvertAndCompare(self,func_jax:Callable,*args,enable_xla:bool=True,limitations:Sequence=())
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.CountLargeTfConstants(self,tf_fun:Callable,*args,at_least=256)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.MakeInputSignature(self,*polymorphic_shapes)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.TransformConvertAndCompare(self,func:Callable,arg,transform:Optional[str])
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.assertDtypesMatch(self,x,y,*,canonicalize_dtypes=True)
jax.experimental.jax2tf.tests.tf_test_util.JaxToTfTestCase.setUp(self)
jax.experimental.jax2tf.tests.tf_test_util.OpMetadataGraph
jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadFunction(f_tf:Callable,*,input_signature:Optional[Sequence[tf.TensorSpec]]=None,input_args:Optional[Sequence[Any]]=None,variables:Sequence[tf.Variable]=(),save_gradients=True)->Tuple[Callable, tf.train.Checkpoint]
jax.experimental.jax2tf.tests.tf_test_util.SaveAndLoadModel(model:tf.Module,save_gradients=True)->tf.Module
jax.experimental.jax2tf.tests.tf_test_util.TransformJaxVJP(f:Callable,args,res_f_of_args)
jax.experimental.jax2tf.tests.tf_test_util.TransformTfValueAndGrad(tf_f:Callable,tf_args,unconnected_gradients=tf.UnconnectedGradients.ZERO)
jax.experimental.jax2tf.tests.tf_test_util._make_tf_input_signature(*tf_args)->List[tf.TensorSpec]
jax.experimental.jax2tf.tests.tf_test_util._run_tf_function(func_tf:Callable,*tf_args,mode:str)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/saved_model_main_test.py----------------------------------------
A:jax.experimental.jax2tf.examples.saved_model_main_test.FLAGS.model_path->os.path.join(absltest.get_default_test_tmpdir(), 'saved_models')
jax.experimental.jax2tf.examples.saved_model_main_test.SavedModelMainTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.examples.saved_model_main_test.SavedModelMainTest.setUp(self)
jax.experimental.jax2tf.examples.saved_model_main_test.SavedModelMainTest.test_train_and_save_features(self,model='mnist_flax')
jax.experimental.jax2tf.examples.saved_model_main_test.SavedModelMainTest.test_train_and_save_full(self,model='mnist_flax',serving_batch_size=-1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/keras_reuse_main.py----------------------------------------
A:jax.experimental.jax2tf.examples.keras_reuse_main.(tf_accelerator, _)->jax.experimental.jax2tf.examples.saved_model_main.tf_accelerator_and_tolerances()
A:jax.experimental.jax2tf.examples.keras_reuse_main.feature_model_dir->jax.experimental.jax2tf.examples.saved_model_main.savedmodel_dir()
A:jax.experimental.jax2tf.examples.keras_reuse_main.strategy->tensorflow.distribute.OneDeviceStrategy(tf_accelerator)
A:jax.experimental.jax2tf.examples.keras_reuse_main.images->tensorflow.keras.layers.Input(mnist_lib.input_shape, batch_size=mnist_lib.train_batch_size)
A:jax.experimental.jax2tf.examples.keras_reuse_main.keras_feature_extractor->tensorflow_hub.KerasLayer(feature_model_dir, trainable=False)
A:jax.experimental.jax2tf.examples.keras_reuse_main.features->keras_feature_extractor(images)
A:jax.experimental.jax2tf.examples.keras_reuse_main.predictor->tensorflow.keras.layers.Dense(10, activation='softmax')
A:jax.experimental.jax2tf.examples.keras_reuse_main.predictions->predictor(features)
A:jax.experimental.jax2tf.examples.keras_reuse_main.keras_model->tensorflow.keras.Model(images, predictions)
A:jax.experimental.jax2tf.examples.keras_reuse_main.train_ds->jax.experimental.jax2tf.examples.mnist_lib.load_mnist(tfds.Split.TRAIN, batch_size=mnist_lib.train_batch_size)
A:jax.experimental.jax2tf.examples.keras_reuse_main.test_ds->jax.experimental.jax2tf.examples.mnist_lib.load_mnist(tfds.Split.TEST, batch_size=mnist_lib.test_batch_size)
jax.experimental.jax2tf.examples.keras_reuse_main.main(_)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/keras_reuse_main_test.py----------------------------------------
A:jax.experimental.jax2tf.examples.keras_reuse_main_test.FLAGS.model_path->os.path.join(absltest.get_default_test_tmpdir(), 'saved_models')
jax.experimental.jax2tf.examples.keras_reuse_main_test.KerasReuseMainTest(tf_test_util.JaxToTfTestCase)
jax.experimental.jax2tf.examples.keras_reuse_main_test.KerasReuseMainTest.setUp(self)
jax.experimental.jax2tf.examples.keras_reuse_main_test.KerasReuseMainTest.test_keras_reuse(self,model='mnist_pure_jax')


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/saved_model_lib.py----------------------------------------
A:jax.experimental.jax2tf.examples.saved_model_lib.tf_fn->jax.experimental.jax2tf.convert(jax_fn, with_gradient=with_gradient, polymorphic_shapes=[None, polymorphic_shapes], enable_xla=enable_xla)
A:jax.experimental.jax2tf.examples.saved_model_lib.param_vars->tensorflow.nest.map_structure(lambda param: tf.Variable(param, trainable=with_gradient), params)
A:jax.experimental.jax2tf.examples.saved_model_lib.tf_graph->tensorflow.function(lambda inputs: tf_fn(param_vars, inputs), autograph=False, jit_compile=compile_model)
A:jax.experimental.jax2tf.examples.saved_model_lib.signatures[tf.saved_model.DEFAULT_SERVING_SIGNATURE_DEF_KEY]->tensorflow.function(lambda inputs: tf_fn(param_vars, inputs), autograph=False, jit_compile=compile_model).get_concrete_function(input_signatures[0])
A:jax.experimental.jax2tf.examples.saved_model_lib.wrapper->_ReusableSavedModelWrapper(tf_graph, param_vars)
A:jax.experimental.jax2tf.examples.saved_model_lib.saved_model_options->tensorflow.saved_model.SaveOptions(experimental_custom_gradients=True)
A:jax.experimental.jax2tf.examples.saved_model_lib.self.variables->tensorflow.nest.flatten(param_vars)
jax.experimental.jax2tf.examples.saved_model_lib._ReusableSavedModelWrapper(self,tf_graph,param_vars)
jax.experimental.jax2tf.examples.saved_model_lib._ReusableSavedModelWrapper.__init__(self,tf_graph,param_vars)
jax.experimental.jax2tf.examples.saved_model_lib.convert_and_save_model(jax_fn:Callable[[Any,Any],Any],params,model_dir:str,*,input_signatures:Sequence[tf.TensorSpec],polymorphic_shapes:Optional[Union[str,jax2tf.PolyShape]]=None,with_gradient:bool=False,enable_xla:bool=True,compile_model:bool=True,saved_model_options:Optional[tf.saved_model.SaveOptions]=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/saved_model_main.py----------------------------------------
A:jax.experimental.jax2tf.examples.saved_model_main.train_ds->jax.experimental.jax2tf.examples.mnist_lib.load_mnist(tfds.Split.TRAIN, batch_size=mnist_lib.train_batch_size)
A:jax.experimental.jax2tf.examples.saved_model_main.test_ds->jax.experimental.jax2tf.examples.mnist_lib.load_mnist(tfds.Split.TEST, batch_size=mnist_lib.test_batch_size)
A:jax.experimental.jax2tf.examples.saved_model_main.the_model_class->pick_model_class()
A:jax.experimental.jax2tf.examples.saved_model_main.model_dir->os.path.join(model_dir, str(FLAGS.model_version))
A:jax.experimental.jax2tf.examples.saved_model_main.model_descr->model_description()
A:jax.experimental.jax2tf.examples.saved_model_main.(predict_fn, predict_params)->pick_model_class().train(train_ds, test_ds, FLAGS.num_epochs, with_classifier=FLAGS.model_classifier_layer)
A:jax.experimental.jax2tf.examples.saved_model_main.(tf_accelerator, tolerances)->tf_accelerator_and_tolerances()
A:jax.experimental.jax2tf.examples.saved_model_main.pure_restored_model->tensorflow.saved_model.load(model_dir)
A:jax.experimental.jax2tf.examples.saved_model_main.test_input->numpy.ones((mnist_lib.test_batch_size,) + mnist_lib.input_shape, dtype=np.float32)
A:jax.experimental.jax2tf.examples.saved_model_main.tolerances->dict(atol=1e-05, rtol=1e-05)
jax.experimental.jax2tf.examples.saved_model_main.model_description()->str
jax.experimental.jax2tf.examples.saved_model_main.pick_model_class()
jax.experimental.jax2tf.examples.saved_model_main.savedmodel_dir(with_version:bool=True)->str
jax.experimental.jax2tf.examples.saved_model_main.tf_accelerator_and_tolerances()
jax.experimental.jax2tf.examples.saved_model_main.train_and_save()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/mnist_lib.py----------------------------------------
A:jax.experimental.jax2tf.examples.mnist_lib.ds->ds.cache().shuffle(1000).batch(batch_size, drop_remainder=True).cache().shuffle(1000).batch(batch_size, drop_remainder=True)
A:jax.experimental.jax2tf.examples.mnist_lib.m->re.search('metadata files were not found in (.+/)mnist/', str(e))
A:jax.experimental.jax2tf.examples.mnist_lib.label->tensorflow.one_hot(x['label'], 10)
A:jax.experimental.jax2tf.examples.mnist_lib.x->flax.linen.log_softmax(x)
A:jax.experimental.jax2tf.examples.mnist_lib.predictions->FlaxMNIST.predict(params, inputs, with_classifier=True)
A:jax.experimental.jax2tf.examples.mnist_lib.target_class->jax.numpy.argmax(labels, axis=1)
A:jax.experimental.jax2tf.examples.mnist_lib.predicted_class->jax.numpy.argmax(predict(params, inputs), axis=1)
A:jax.experimental.jax2tf.examples.mnist_lib.grads->jax.grad(PureJaxMNIST.loss)(params, inputs, labels)
A:jax.experimental.jax2tf.examples.mnist_lib.rng->jax.random.PRNGKey(0)
A:jax.experimental.jax2tf.examples.mnist_lib.start_time->time.time()
A:jax.experimental.jax2tf.examples.mnist_lib.params->jax.jit(PureJaxMNIST.update)(params, inputs, labels)
A:jax.experimental.jax2tf.examples.mnist_lib.train_acc->PureJaxMNIST.accuracy(FlaxMNIST.predict, optimizer.target, train_ds)
A:jax.experimental.jax2tf.examples.mnist_lib.test_acc->PureJaxMNIST.accuracy(FlaxMNIST.predict, optimizer.target, test_ds)
A:jax.experimental.jax2tf.examples.mnist_lib.model->Module()
A:jax.experimental.jax2tf.examples.mnist_lib.grad->jax.grad(FlaxMNIST.loss)(optimizer.target, inputs, labels)
A:jax.experimental.jax2tf.examples.mnist_lib.optimizer->jax.jit(FlaxMNIST.update)(optimizer, inputs, labels)
A:jax.experimental.jax2tf.examples.mnist_lib.init_shape->jax.numpy.ones((1,) + input_shape, jnp.float32)
A:jax.experimental.jax2tf.examples.mnist_lib.optimizer_def->flax.optim.Momentum(learning_rate=step_size, beta=momentum_mass)
A:jax.experimental.jax2tf.examples.mnist_lib.predict_fn->functools.partial(FlaxMNIST.predict, with_classifier=with_classifier)
A:jax.experimental.jax2tf.examples.mnist_lib.fig->matplotlib.pyplot.figure(figsize=(8.0, 4.0), num=title)
A:jax.experimental.jax2tf.examples.mnist_lib.((images, labels),)->list(tfds.as_numpy(ds.take(1)))
A:jax.experimental.jax2tf.examples.mnist_lib.inferred_labels->inference_fn(images)
A:jax.experimental.jax2tf.examples.mnist_lib.digit->matplotlib.pyplot.figure(figsize=(8.0, 4.0), num=title).add_subplot(nr_rows, nr_cols, i + 1)
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST.Module(self,x,with_classifier=True)
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST.Module.__call__(self,x,with_classifier=True)
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST.loss(params,inputs,labels)
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST.predict(params,inputs,with_classifier=True)
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST.train(train_ds,test_ds,num_epochs,with_classifier=True)
jax.experimental.jax2tf.examples.mnist_lib.FlaxMNIST.update(optimizer,inputs,labels)
jax.experimental.jax2tf.examples.mnist_lib.PureJaxMNIST
jax.experimental.jax2tf.examples.mnist_lib.PureJaxMNIST.accuracy(predict:Callable,params,dataset)
jax.experimental.jax2tf.examples.mnist_lib.PureJaxMNIST.loss(params,inputs,labels)
jax.experimental.jax2tf.examples.mnist_lib.PureJaxMNIST.predict(params:Sequence[Tuple[Any,Any]],inputs,with_classifier=True)
jax.experimental.jax2tf.examples.mnist_lib.PureJaxMNIST.train(train_ds,test_ds,num_epochs,with_classifier=True)
jax.experimental.jax2tf.examples.mnist_lib.PureJaxMNIST.update(params,inputs,labels)
jax.experimental.jax2tf.examples.mnist_lib.load_mnist(split:tfds.Split,batch_size:int)
jax.experimental.jax2tf.examples.mnist_lib.plot_images(ds,nr_rows:int,nr_cols:int,title:str,inference_fn:Optional[Callable]=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/serving/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/jax2tf/examples/serving/model_server_request.py----------------------------------------
A:jax.experimental.jax2tf.examples.serving.model_server_request.channel->grpc.insecure_channel(FLAGS.prediction_service_addr)
A:jax.experimental.jax2tf.examples.serving.model_server_request.stub->tensorflow_serving.apis.prediction_service_pb2_grpc.PredictionServiceStub(channel)
A:jax.experimental.jax2tf.examples.serving.model_server_request.request->tensorflow_serving.apis.predict_pb2.PredictRequest()
A:jax.experimental.jax2tf.examples.serving.model_server_request.response->requests.post(predict_url, data=data)
A:jax.experimental.jax2tf.examples.serving.model_server_request.(outputs,)->requests.post(predict_url, data=data).outputs.values()
A:jax.experimental.jax2tf.examples.serving.model_server_request.images_json->json.dumps(images.tolist())
A:jax.experimental.jax2tf.examples.serving.model_server_request.test_ds->jax.experimental.jax2tf.examples.mnist_lib.load_mnist(tfds.Split.TEST, batch_size=FLAGS.serving_batch_size)
A:jax.experimental.jax2tf.examples.serving.model_server_request.images_and_labels->tensorflow_datasets.as_numpy(test_ds.take(FLAGS.count_images // FLAGS.serving_batch_size))
A:jax.experimental.jax2tf.examples.serving.model_server_request.predictions_one_hot->serving_call_mnist(images)
A:jax.experimental.jax2tf.examples.serving.model_server_request.predictions_digit->numpy.argmax(predictions_one_hot, axis=1)
A:jax.experimental.jax2tf.examples.serving.model_server_request.labels_digit->numpy.argmax(labels, axis=1)
jax.experimental.jax2tf.examples.serving.model_server_request.main(_)
jax.experimental.jax2tf.examples.serving.model_server_request.serving_call_mnist(images)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/ad.py----------------------------------------
A:jax.experimental.sparse.ad.allow_int->kwargs.pop('allow_int', False)
A:jax.experimental.sparse.ad.raw_value_and_grad_fun->jax.value_and_grad(fun, argnums=argnums, **kwargs)
A:jax.experimental.sparse.ad.argnums->jax.core.concrete_or_error(_ensure_index, argnums)
A:jax.experimental.sparse.ad.(dyn_args_flat, _)->jax.tree_util.tree_flatten(dyn_args, is_leaf=lambda arg: isinstance(arg, BCOO))
A:jax.experimental.sparse.ad.dtype->numpy.dtype(arg)
A:jax.experimental.sparse.ad.(value, grad)->raw_value_and_grad_fun(*args, **kwargs)
A:jax.experimental.sparse.ad.grad->tuple((maybe_copy_index(args[argnum], g) for (argnum, g) in safe_zip(argnums, grad)))
A:jax.experimental.sparse.ad.value_and_grad_f->value_and_grad(fun, argnums, has_aux=has_aux, **kwargs)
A:jax.experimental.sparse.ad.(_, g)->value_and_grad_f(*args, **kwargs)
A:jax.experimental.sparse.ad.((_, aux), g)->value_and_grad_f(*args, **kwargs)
jax.experimental.sparse.ad.grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux=False,**kwargs)->Callable
jax.experimental.sparse.ad.value_and_grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,**kwargs)->Callable[..., Tuple[Any, Any]]
jax.experimental.sparse.grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux=False,**kwargs)->Callable
jax.experimental.sparse.value_and_grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,**kwargs)->Callable[..., Tuple[Any, Any]]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/csr.py----------------------------------------
A:jax.experimental.sparse.csr.nse->jax.core.concrete_or_error(operator.index, nse, 'nse argument of csr_fromdense()')
A:jax.experimental.sparse.csr.dtype->property(lambda self: self.data.dtype)
A:jax.experimental.sparse.csr.(self.data, self.indices, self.indptr)->_safe_asarray(args)
A:jax.experimental.sparse.csr.shape->tuple(shape)
A:jax.experimental.sparse.csr.data->jax.core.ShapedArray((nse,), mat.dtype)
A:jax.experimental.sparse.csr.indices->jax.core.ShapedArray((nse,), index_dtype)
A:jax.experimental.sparse.csr.indptr->jax.core.ShapedArray((mat.shape[0] + 1,), index_dtype)
A:jax.experimental.sparse.csr.other->jax.numpy.asarray(other)
A:jax.experimental.sparse.csr.(data, other)->_promote_dtypes(self.data, other)
A:jax.experimental.sparse.csr.csr_todense_p->jax.core.Primitive('csr_todense')
A:jax.experimental.sparse.csr._csr_todense_translation_rule->jax.interpreters.xla.lower_fun(_csr_todense_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.csr._csr_todense_lowering->jax.interpreters.mlir.lower_fun(_csr_todense_impl, multiple_results=False)
A:jax.experimental.sparse.csr.csr_fromdense_p->jax.core.Primitive('csr_fromdense')
A:jax.experimental.sparse.csr.mat->jax.numpy.asarray(mat)
A:jax.experimental.sparse.csr.(row, col)->_csr_to_coo(indices, indptr)
A:jax.experimental.sparse.csr.row->jax.numpy.where(true_nonzeros, row, m)
A:jax.experimental.sparse.csr._csr_fromdense_translation_rule->jax.interpreters.xla.lower_fun(_csr_fromdense_impl, multiple_results=True, new_style=True)
A:jax.experimental.sparse.csr.(data, indices, indptr)->jax._src.lib.sparse_apis.csr_fromdense_mhlo(mat, nnz=nse, index_dtype=np.dtype(index_dtype), data_dtype=dtype, index_type=mlir.dtype_to_ir_type(np.dtype(index_dtype)))
A:jax.experimental.sparse.csr._csr_fromdense_lowering->jax.interpreters.mlir.lower_fun(_csr_fromdense_impl, multiple_results=True)
A:jax.experimental.sparse.csr.primals_out->csr_fromdense(M, nse=nse, index_dtype=index_dtype)
A:jax.experimental.sparse.csr.data_dot->_csr_extract(indices, indptr, Mdot)
A:jax.experimental.sparse.csr.csr_matvec_p->jax.core.Primitive('csr_matvec')
A:jax.experimental.sparse.csr._csr_matvec_translation_rule->jax.interpreters.xla.lower_fun(_csr_matvec_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.csr._csr_matvec_lowering->jax.interpreters.mlir.lower_fun(_csr_matvec_impl, multiple_results=False)
A:jax.experimental.sparse.csr.v->jax.numpy.asarray(v)
A:jax.experimental.sparse.csr.csr_matmat_p->jax.core.Primitive('csr_matmat')
A:jax.experimental.sparse.csr._csr_matmat_translation_rule->jax.interpreters.xla.lower_fun(_csr_matmat_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.csr._csr_matmat_lowering->jax.interpreters.mlir.lower_fun(_csr_matmat_impl, multiple_results=False)
A:jax.experimental.sparse.csr.B->jax.numpy.asarray(B)
jax.experimental.sparse.CSC(self,args,*,shape)
jax.experimental.sparse.CSC.__matmul__(self,other)
jax.experimental.sparse.CSC._empty(cls,shape,*,dtype=None,index_dtype='int32')
jax.experimental.sparse.CSC.fromdense(cls,mat,*,nse=None,index_dtype=np.int32)
jax.experimental.sparse.CSC.todense(self)
jax.experimental.sparse.CSC.transpose(self,axes=None)
jax.experimental.sparse.CSC.tree_flatten(self)
jax.experimental.sparse.CSR(self,args,*,shape)
jax.experimental.sparse.CSR.__matmul__(self,other)
jax.experimental.sparse.CSR._empty(cls,shape,*,dtype=None,index_dtype='int32')
jax.experimental.sparse.CSR.fromdense(cls,mat,*,nse=None,index_dtype=np.int32)
jax.experimental.sparse.CSR.todense(self)
jax.experimental.sparse.CSR.transpose(self,axes=None)
jax.experimental.sparse.CSR.tree_flatten(self)
jax.experimental.sparse.csr.CSC(self,args,*,shape)
jax.experimental.sparse.csr.CSC.__init__(self,args,*,shape)
jax.experimental.sparse.csr.CSC.__matmul__(self,other)
jax.experimental.sparse.csr.CSC._empty(cls,shape,*,dtype=None,index_dtype='int32')
jax.experimental.sparse.csr.CSC.fromdense(cls,mat,*,nse=None,index_dtype=np.int32)
jax.experimental.sparse.csr.CSC.todense(self)
jax.experimental.sparse.csr.CSC.transpose(self,axes=None)
jax.experimental.sparse.csr.CSC.tree_flatten(self)
jax.experimental.sparse.csr.CSR(self,args,*,shape)
jax.experimental.sparse.csr.CSR.__init__(self,args,*,shape)
jax.experimental.sparse.csr.CSR.__matmul__(self,other)
jax.experimental.sparse.csr.CSR._empty(cls,shape,*,dtype=None,index_dtype='int32')
jax.experimental.sparse.csr.CSR.fromdense(cls,mat,*,nse=None,index_dtype=np.int32)
jax.experimental.sparse.csr.CSR.todense(self)
jax.experimental.sparse.csr.CSR.transpose(self,axes=None)
jax.experimental.sparse.csr.CSR.tree_flatten(self)
jax.experimental.sparse.csr._csr_fromdense_abstract_eval(mat,*,nse,index_dtype)
jax.experimental.sparse.csr._csr_fromdense_gpu_lowering(ctx,mat,*,nse,index_dtype)
jax.experimental.sparse.csr._csr_fromdense_gpu_translation_rule(ctx,avals_in,avals_out,mat,*,nse,index_dtype)
jax.experimental.sparse.csr._csr_fromdense_impl(mat,*,nse,index_dtype)
jax.experimental.sparse.csr._csr_fromdense_jvp(primals,tangents,*,nse,index_dtype)
jax.experimental.sparse.csr._csr_fromdense_transpose(ct,M,*,nse,index_dtype)
jax.experimental.sparse.csr._csr_matmat_abstract_eval(data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matmat_gpu_lowering(ctx,data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matmat_gpu_translation_rule(ctx,avals_in,avals_out,data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matmat_impl(data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matmat_jvp_left(data_dot,data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matmat_jvp_right(B_dot,data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matmat_transpose(ct,data,indices,indptr,B,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_abstract_eval(data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_gpu_lowering(ctx,data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_gpu_translation_rule(ctx,avals_in,avals_out,data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_impl(data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_jvp_mat(data_dot,data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_jvp_vec(v_dot,data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_matvec_transpose(ct,data,indices,indptr,v,*,shape,transpose)
jax.experimental.sparse.csr._csr_todense_abstract_eval(data,indices,indptr,*,shape)
jax.experimental.sparse.csr._csr_todense_gpu_lowering(ctx,data,indices,indptr,*,shape)
jax.experimental.sparse.csr._csr_todense_gpu_translation_rule(ctx,avals_in,avals_out,data,indices,indptr,*,shape)
jax.experimental.sparse.csr._csr_todense_impl(data,indices,indptr,*,shape)
jax.experimental.sparse.csr._csr_todense_jvp(data_dot,data,indices,indptr,*,shape)
jax.experimental.sparse.csr._csr_todense_transpose(ct,data,indices,indptr,*,shape)
jax.experimental.sparse.csr.csr_fromdense(mat,*,nse,index_dtype=np.int32)
jax.experimental.sparse.csr.csr_matmat(data,indices,indptr,B,*,shape,transpose=False)
jax.experimental.sparse.csr.csr_matvec(data,indices,indptr,v,*,shape,transpose=False)
jax.experimental.sparse.csr.csr_todense(data,indices,indptr,*,shape)
jax.experimental.sparse.csr_fromdense(mat,*,nse,index_dtype=np.int32)
jax.experimental.sparse.csr_matmat(data,indices,indptr,B,*,shape,transpose=False)
jax.experimental.sparse.csr_matvec(data,indices,indptr,v,*,shape,transpose=False)
jax.experimental.sparse.csr_todense(data,indices,indptr,*,shape)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/coo.py----------------------------------------
A:jax.experimental.sparse.coo.nse->jax.core.concrete_or_error(operator.index, nse, 'nse argument of coo_fromdense()')
A:jax.experimental.sparse.coo.dtype->property(lambda self: self.data.dtype)
A:jax.experimental.sparse.coo._info->property(lambda self: COOInfo(shape=self.shape, rows_sorted=self._rows_sorted, cols_sorted=self._cols_sorted))
A:jax.experimental.sparse.coo._bufs->property(lambda self: (self.data, self.row, self.col))
A:jax.experimental.sparse.coo.(self.data, self.row, self.col)->_safe_asarray(args)
A:jax.experimental.sparse.coo.(row, col, data)->jax.lax.sort((self.row, self.col, self.data), num_keys=2)
A:jax.experimental.sparse.coo.shape->tuple(shape)
A:jax.experimental.sparse.coo.data->jax.core.ShapedArray((nse,), mat.dtype)
A:jax.experimental.sparse.coo.rowcol->jax.core.ShapedArray((nse,), index_dtype)
A:jax.experimental.sparse.coo.other->jax.numpy.asarray(other)
A:jax.experimental.sparse.coo.(data, other)->_promote_dtypes(self.data, other)
A:jax.experimental.sparse.coo.self_promoted->COO((data, self.row, self.col), **self._info._asdict())
A:jax.experimental.sparse.coo.coo_todense_p->jax.core.Primitive('coo_todense')
A:jax.experimental.sparse.coo._coo_todense_translation_rule->jax.interpreters.xla.lower_fun(_coo_todense_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.coo.result->jax._src.lib.sparse_apis.coo_todense_mhlo(data, row, col, shape=shape, data_dtype=dtype, index_dtype=row_aval.dtype)
A:jax.experimental.sparse.coo._coo_todense_lowering->jax.interpreters.mlir.lower_fun(_coo_todense_impl, multiple_results=False)
A:jax.experimental.sparse.coo.coo_fromdense_p->jax.core.Primitive('coo_fromdense')
A:jax.experimental.sparse.coo.mat->jax.numpy.asarray(mat)
A:jax.experimental.sparse.coo.(row, col)->jax.numpy.nonzero(mat, size=nse)
A:jax.experimental.sparse.coo._coo_fromdense_translation_rule->jax.interpreters.xla.lower_fun(_coo_fromdense_impl, multiple_results=True, new_style=True)
A:jax.experimental.sparse.coo.(data, row, col)->jax._src.lib.sparse_apis.coo_fromdense_mhlo(mat, nnz=nse, data_dtype=dtype, index_dtype=np.dtype(index_dtype), index_type=mlir.dtype_to_ir_type(np.dtype(index_dtype)))
A:jax.experimental.sparse.coo._coo_fromdense_lowering->jax.interpreters.mlir.lower_fun(_coo_fromdense_impl, multiple_results=True)
A:jax.experimental.sparse.coo.primals_out->_coo_fromdense(M, nse=nse, index_dtype=index_dtype)
A:jax.experimental.sparse.coo.data_dot->_coo_extract(row, col, Mdot)
A:jax.experimental.sparse.coo.coo_matvec_p->jax.core.Primitive('coo_matvec')
A:jax.experimental.sparse.coo.v->jax.numpy.asarray(v)
A:jax.experimental.sparse.coo._coo_matvec_translation_rule->jax.interpreters.xla.lower_fun(_coo_matvec_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.coo._coo_matvec_lowering->jax.interpreters.mlir.lower_fun(_coo_matvec_impl, multiple_results=False)
A:jax.experimental.sparse.coo.coo_matmat_p->jax.core.Primitive('coo_matmat')
A:jax.experimental.sparse.coo.B->jax.numpy.asarray(B)
A:jax.experimental.sparse.coo._coo_matmat_translation_rule->jax.interpreters.xla.lower_fun(_coo_matmat_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.coo._coo_matmat_lowering->jax.interpreters.mlir.lower_fun(_coo_matmat_impl, multiple_results=False)
jax.experimental.sparse.COO(self,args,*,shape,rows_sorted=False,cols_sorted=False)
jax.experimental.sparse.COO.__matmul__(self,other)
jax.experimental.sparse.COO._empty(cls,shape,*,dtype=None,index_dtype='int32')
jax.experimental.sparse.COO._sort_indices(self)
jax.experimental.sparse.COO.fromdense(cls,mat,*,nse=None,index_dtype=np.int32)
jax.experimental.sparse.COO.todense(self)
jax.experimental.sparse.COO.transpose(self,axes=None)
jax.experimental.sparse.COO.tree_flatten(self)
jax.experimental.sparse.COOInfo(NamedTuple)
jax.experimental.sparse.coo.COO(self,args,*,shape,rows_sorted=False,cols_sorted=False)
jax.experimental.sparse.coo.COO.__init__(self,args,*,shape,rows_sorted=False,cols_sorted=False)
jax.experimental.sparse.coo.COO.__matmul__(self,other)
jax.experimental.sparse.coo.COO._empty(cls,shape,*,dtype=None,index_dtype='int32')
jax.experimental.sparse.coo.COO._sort_indices(self)
jax.experimental.sparse.coo.COO.fromdense(cls,mat,*,nse=None,index_dtype=np.int32)
jax.experimental.sparse.coo.COO.todense(self)
jax.experimental.sparse.coo.COO.transpose(self,axes=None)
jax.experimental.sparse.coo.COO.tree_flatten(self)
jax.experimental.sparse.coo.COOInfo(NamedTuple)
jax.experimental.sparse.coo._coo_fromdense(mat,*,nse,index_dtype=jnp.int32)
jax.experimental.sparse.coo._coo_fromdense_abstract_eval(mat,*,nse,index_dtype)
jax.experimental.sparse.coo._coo_fromdense_gpu_lowering(ctx,mat,*,nse,index_dtype)
jax.experimental.sparse.coo._coo_fromdense_gpu_translation_rule(ctx,avals_in,avals_out,mat,*,nse,index_dtype)
jax.experimental.sparse.coo._coo_fromdense_impl(mat,*,nse,index_dtype)
jax.experimental.sparse.coo._coo_fromdense_jvp(primals,tangents,*,nse,index_dtype)
jax.experimental.sparse.coo._coo_fromdense_transpose(ct,M,*,nse,index_dtype)
jax.experimental.sparse.coo._coo_matmat(data,row,col,B,*,spinfo,transpose=False)
jax.experimental.sparse.coo._coo_matmat_abstract_eval(data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matmat_gpu_lowering(ctx,data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matmat_gpu_translation_rule(ctx,avals_in,avals_out,data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matmat_impl(data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matmat_jvp_left(data_dot,data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matmat_jvp_right(B_dot,data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matmat_transpose(ct,data,row,col,B,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec(data,row,col,v,*,spinfo,transpose=False)
jax.experimental.sparse.coo._coo_matvec_abstract_eval(data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec_gpu_lowering(ctx,data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec_gpu_translation_rule(ctx,avals_in,avals_out,data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec_impl(data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec_jvp_mat(data_dot,data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec_jvp_vec(v_dot,data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_matvec_transpose(ct,data,row,col,v,*,spinfo,transpose)
jax.experimental.sparse.coo._coo_todense(data,row,col,*,spinfo)
jax.experimental.sparse.coo._coo_todense_abstract_eval(data,row,col,*,spinfo)
jax.experimental.sparse.coo._coo_todense_gpu_lowering(ctx,data,row,col,*,spinfo)
jax.experimental.sparse.coo._coo_todense_gpu_translation_rule(ctx,avals_in,avals_out,data,row,col,*,spinfo)
jax.experimental.sparse.coo._coo_todense_impl(data,row,col,*,spinfo)
jax.experimental.sparse.coo._coo_todense_jvp(data_dot,data,row,col,*,spinfo)
jax.experimental.sparse.coo._coo_todense_transpose(ct,data,row,col,*,spinfo)
jax.experimental.sparse.coo.coo_fromdense(mat,*,nse=None,index_dtype=jnp.int32)
jax.experimental.sparse.coo.coo_matmat(mat,B,*,transpose=False)
jax.experimental.sparse.coo.coo_matvec(mat,v,transpose=False)
jax.experimental.sparse.coo.coo_todense(mat)
jax.experimental.sparse.coo_fromdense(mat,*,nse=None,index_dtype=jnp.int32)
jax.experimental.sparse.coo_matmat(mat,B,*,transpose=False)
jax.experimental.sparse.coo_matvec(mat,v,transpose=False)
jax.experimental.sparse.coo_todense(mat)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/api.py----------------------------------------
A:jax.experimental.sparse.api.todense_p->jax.core.Primitive('todense')
A:jax.experimental.sparse.api.(bufs, tree)->jax.tree_util.tree_flatten(arr)
A:jax.experimental.sparse.api.arr->jax.tree_util.tree_unflatten(tree, bufs)
A:jax.experimental.sparse.api.primals_out->jax.core.Primitive('todense').bind(*primals, tree=tree)
A:jax.experimental.sparse.api.tangents_out->jax.core.Primitive('todense').bind(tangents[0], *primals[1:], tree=tree)
A:jax.experimental.sparse.api.standin->object()
A:jax.experimental.sparse.api.obj->jax.tree_util.tree_unflatten(tree, [standin] * len(bufs))
jax.experimental.sparse.api._todense_abstract_eval(*bufs,tree)
jax.experimental.sparse.api._todense_batching_rule(batched_args,batch_dims,*,tree)
jax.experimental.sparse.api._todense_impl(*bufs,tree)
jax.experimental.sparse.api._todense_jvp(primals,tangents,*,tree)
jax.experimental.sparse.api._todense_transpose(ct,*bufs,tree)
jax.experimental.sparse.api.empty(shape,dtype=None,index_dtype='int32',sparse_format='bcoo',**kwds)
jax.experimental.sparse.api.todense(arr)
jax.experimental.sparse.empty(shape,dtype=None,index_dtype='int32',sparse_format='bcoo',**kwds)
jax.experimental.sparse.todense(arr)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/bcoo.py----------------------------------------
A:jax.experimental.sparse.bcoo.(args_flat, in_tree)->jax.tree_util.tree_flatten(args)
A:jax.experimental.sparse.bcoo.in_axes_flat->flatten_axes('vmap in_axes', in_tree, in_axes, kws=False)
A:jax.experimental.sparse.bcoo.size->max((arg.shape[i] for (arg, i) in safe_zip(args_flat, in_axes_flat) if i is not None))
A:jax.experimental.sparse.bcoo.(args_flat, in_axes_flat)->zip(*((arg, None) if i is None else (lax.squeeze(arg, (i,)), None) if arg.shape[i] == 1 else (arg, i) for (arg, i) in zip(args_flat, in_axes_flat)))
A:jax.experimental.sparse.bcoo.new_args->jax.tree_util.tree_unflatten(in_tree, args_flat)
A:jax.experimental.sparse.bcoo.new_in_axes->jax.tree_util.tree_unflatten(in_tree, in_axes_flat)
A:jax.experimental.sparse.bcoo.mat->mat.tocoo().tocoo()
A:jax.experimental.sparse.bcoo.mask->jax.numpy.all(lhs_indices[:, None, dims] == rhs_indices[None, :, dims], -1)
A:jax.experimental.sparse.bcoo.props->_validate_bcoo(data, indices, shape)
A:jax.experimental.sparse.bcoo.f->vmap(f)
A:jax.experimental.sparse.bcoo.(data_unique, indices_unique, nse_out)->f(data, indices)
A:jax.experimental.sparse.bcoo.nse->property(lambda self: self.indices.shape[-2])
A:jax.experimental.sparse.bcoo.data_unique->jax.numpy.where(oob_mask[(...,) + props.n_dense * (None,)], 0, data_unique)
A:jax.experimental.sparse.bcoo.indices_unique->jax.numpy.zeros_like(indices, shape=(nse, 0))
A:jax.experimental.sparse.bcoo.fill_value->jax.numpy.expand_dims(jnp.array(shape[n_batch:n_batch + n_sparse]), range(indices.ndim - 1))
A:jax.experimental.sparse.bcoo.out_of_bounds->(indices >= fill_value).any(-1, keepdims=True)
A:jax.experimental.sparse.bcoo.indices->jax.numpy.full((*batch_shape, nse, n_sparse), jnp.array(sparse_shape), index_dtype)
A:jax.experimental.sparse.bcoo.(indices_unique, inv_idx, nse)->_unique(indices, axis=0, return_inverse=True, return_true_size=True, size=props.nse, fill_value=fill_value)
A:jax.experimental.sparse.bcoo.(indices_unique, inv_idx)->jax.numpy.unique(indices, axis=0, return_inverse=True, size=nse, fill_value=fill_value)
A:jax.experimental.sparse.bcoo.oob_mask->jax.numpy.all(indices_unique == fill_value, 1)
A:jax.experimental.sparse.bcoo.(*indices, i)->jax.lax.sort((*idx_cols, lax.iota(indices.dtype, len(data))), num_keys=N)
A:jax.experimental.sparse.bcoo.(*indices, data)->jax.lax.sort((*idx_cols, data), num_keys=N)
A:jax.experimental.sparse.bcoo._bcoo_sort_indices_rule->jax.interpreters.xla.lower_fun(_bcoo_sort_indices, multiple_results=True, new_style=True)
A:jax.experimental.sparse.bcoo._bcoo_sort_indices_mhlo->jax.interpreters.mlir.lower_fun(_bcoo_sort_indices, multiple_results=True)
A:jax.experimental.sparse.bcoo.data->jax.numpy.zeros((*batch_shape, nse, *dense_shape), dtype)
A:jax.experimental.sparse.bcoo.shape->tuple(shape)
A:jax.experimental.sparse.bcoo.bcoo_todense_p->jax.core.Primitive('bcoo_todense')
A:jax.experimental.sparse.bcoo.(n_batch, n_sparse, _, _)->_validate_bcoo(lhs_data, lhs_indices, lhs_spinfo.shape)
A:jax.experimental.sparse.bcoo.ind_slices->tuple((np.zeros(s, int) if i_s == 1 else np.arange(s) for (s, i_s) in zip(mat.shape[:n_batch], indices.shape[:n_batch])))
A:jax.experimental.sparse.bcoo.grid->numpy.meshgrid(*batch_slices, np.arange(1), indexing='ij', sparse=True)
A:jax.experimental.sparse.bcoo.sparse_ind->tuple((indices[grid + (slice(None), i)] for i in range(n_sparse)))
A:jax.experimental.sparse.bcoo.batch_slices->tuple((np.arange(s) for s in mat.shape[:n_batch]))
A:jax.experimental.sparse.bcoo.new_spinfo->BCOOInfo(shape=(max(data.shape[0], indices.shape[0]), *spinfo.shape))
A:jax.experimental.sparse.bcoo.bcoo_fromdense_p->jax.core.Primitive('bcoo_fromdense')
A:jax.experimental.sparse.bcoo._nonzero->vmap(_nonzero, 0)
A:jax.experimental.sparse.bcoo.primals_out->_bcoo_spdot_general(*primals, **kwds)
A:jax.experimental.sparse.bcoo.data_dot->bcoo_extract(indices, Mdot)
A:jax.experimental.sparse.bcoo.bcoo_extract_p->jax.core.Primitive('bcoo_extract')
A:jax.experimental.sparse.bcoo.(n_batch, _, n_dense, nse)->_validate_bcoo_indices(indices, mat.shape)
A:jax.experimental.sparse.bcoo.result_shape->list(mat.shape)
A:jax.experimental.sparse.bcoo.bcoo_transpose_p->jax.core.Primitive('bcoo_transpose')
A:jax.experimental.sparse.bcoo.permutation->tuple([*range(n_batch), *range(n_swap, result.ndim), *range(n_batch, n_swap)])
A:jax.experimental.sparse.bcoo.(n_batch, n_sparse, n_dense, _)->_validate_bcoo(data, indices, shape)
A:jax.experimental.sparse.bcoo.(batch_perm, sparse_perm, dense_perm)->_validate_permutation(data, indices, permutation, spinfo.shape)
A:jax.experimental.sparse.bcoo.n_batch->property(lambda self: self.indices.ndim - 2)
A:jax.experimental.sparse.bcoo.(batch_perm, _, dense_perm)->_validate_permutation(data, indices, permutation, spinfo.shape)
A:jax.experimental.sparse.bcoo.(data_dot_out, _)->_bcoo_transpose(data_dot, indices, permutation=permutation, spinfo=spinfo)
A:jax.experimental.sparse.bcoo.ct_spinfo->BCOOInfo(tuple((spinfo.shape[p] for p in permutation)))
A:jax.experimental.sparse.bcoo.rev_permutation->list(np.argsort(permutation))
A:jax.experimental.sparse.bcoo.dummy_indices->jax.numpy.zeros([1 for i in range(indices.ndim - 2)] + list(indices.shape[-2:]), dtype=int)
A:jax.experimental.sparse.bcoo.(data_trans, _)->_bcoo_transpose(data_ct, dummy_indices, permutation=rev_permutation, spinfo=ct_spinfo)
A:jax.experimental.sparse.bcoo.batch_dims->list(batch_dims)
A:jax.experimental.sparse.bcoo.batch_size->max((0 if dim is None else arg.shape[dim] for (arg, dim) in zip(batched_args, batch_dims)))
A:jax.experimental.sparse.bcoo.batched_spinfo->BCOOInfo((batch_size, *spinfo.shape))
A:jax.experimental.sparse.bcoo.(data, indices)->_bcoo_sort_indices(self.data, self.indices, self.shape)
A:jax.experimental.sparse.bcoo.bcoo_dot_general_p->jax.core.Primitive('bcoo_dot_general')
A:jax.experimental.sparse.bcoo.lhs->_validate_bcoo(lhs_data, lhs_indices, lhs_shape)
A:jax.experimental.sparse.bcoo.rhs->_validate_bcoo(rhs_data, rhs_indices, rhs_shape)
A:jax.experimental.sparse.bcoo.bufs->_bcoo_spdot_general(lhs.data, lhs.indices, rhs.data, rhs.indices, lhs_spinfo=lhs._info, rhs_spinfo=rhs._info, dimension_numbers=dimension_numbers)
A:jax.experimental.sparse.bcoo.result->_bcoo_dot_general(lhs_data, lhs_indices, ct, lhs_spinfo=lhs_spinfo, dimension_numbers=dims)
A:jax.experimental.sparse.bcoo.lhs_data->lhs_data.transpose([*lhs_batch_perm, *range(lhs.n_batch, lhs_data.ndim)]).transpose([*lhs_batch_perm, *range(lhs.n_batch, lhs_data.ndim)])
A:jax.experimental.sparse.bcoo.lhs_indices->lhs_indices.transpose([*lhs_batch_perm, *range(lhs.n_batch, lhs_indices.ndim)]).transpose([*lhs_batch_perm, *range(lhs.n_batch, lhs_indices.ndim)])
A:jax.experimental.sparse.bcoo.out_aval->_bcoo_dot_general_abstract_eval(lhs_data.aval, lhs_indices.aval, rhs.aval, dimension_numbers=dimension_numbers, lhs_spinfo=lhs_spinfo)
A:jax.experimental.sparse.bcoo.(lhs_contracting_b, rhs_contracting_b)->unzip2([(l, r) for (l, r) in safe_zip(lhs_contracting, rhs_contracting) if l < n_batch])
A:jax.experimental.sparse.bcoo.(lhs_contracting_s, rhs_contracting_s)->unzip2([(l, r) for (l, r) in safe_zip(lhs_contracting, rhs_contracting) if l >= n_batch])
A:jax.experimental.sparse.bcoo.sparse_perm->jax.numpy.array([*lhs_contracting_s, *remaining(range(n_sparse), lhs_contracting_s)])
A:jax.experimental.sparse.bcoo.idx->tuple((lhs_indices[..., i] for i in range(n_sparse)))
A:jax.experimental.sparse.bcoo.prod->jax.lax.dot_general(lhs_data, rhs.at[idx_right].get(mode='fill', fill_value=0), (([], []), (batch_dims, batch_dims)))
A:jax.experimental.sparse.bcoo.out_array->jax.numpy.zeros(out_aval.shape, out_aval.dtype)
A:jax.experimental.sparse.bcoo.out_shape->tuple((shape[i] for i in range(len(shape)) if i not in axes))
A:jax.experimental.sparse.bcoo._bcoo_dot_general_default_translation_rule->jax.interpreters.xla.lower_fun(_bcoo_dot_general_impl, multiple_results=False, new_style=True)
A:jax.experimental.sparse.bcoo.rhs_ndim->len(ir.RankedTensorType(rhs.type).shape)
A:jax.experimental.sparse.bcoo.col->_collapse_mhlo(mhlo.SliceOp(lhs_indices, start_indices=mlir.dense_int_elements([0, 1]), limit_indices=mlir.dense_int_elements([lhs_indices_shape[0], 2]), strides=mlir.dense_int_elements([1, 1])).result, start=0, end=1)
A:jax.experimental.sparse.bcoo.row->_collapse_mhlo(mhlo.SliceOp(lhs_indices, start_indices=mlir.dense_int_elements([0, 0]), limit_indices=mlir.dense_int_elements([lhs_indices_shape[0], 1]), strides=mlir.dense_int_elements([1, 1])).result, start=0, end=1)
A:jax.experimental.sparse.bcoo.dot_product->bcoo_dot_general_fn(lhs_data, row, col, rhs, shape=lhs_shape, transpose=lhs_transpose, data_dtype=lhs_data_aval.dtype, index_dtype=lhs_indices_aval.dtype, x_dtype=rhs_aval.dtype)
A:jax.experimental.sparse.bcoo.(n_batch, n_sparse, n_dense, nse)->_validate_bcoo(lhs_data_aval, lhs_indices_aval, lhs_spinfo.shape)
A:jax.experimental.sparse.bcoo.(lhs_data, lhs_indices)->_unbatch_bcoo(lhs_data, lhs_indices, lhs_shape)
A:jax.experimental.sparse.bcoo._bcoo_dot_general_default_lowering->jax.interpreters.mlir.lower_fun(_bcoo_dot_general_impl, multiple_results=False)
A:jax.experimental.sparse.bcoo.x_type->jax._src.lib.mlir.ir.RankedTensorType(x.type)
A:jax.experimental.sparse.bcoo.sub_ctx->jax.interpreters.mlir.LoweringRuleContext(module_context=ctx.module_context, primitive=None, avals_in=ctx.avals_in[:2], avals_out=ctx.avals_in[:2])
A:jax.experimental.sparse.bcoo.((lhs_data,), (lhs_indices,))->_bcoo_sort_indices_mhlo(sub_ctx, lhs_data, lhs_indices, shape=lhs_spinfo.shape)
A:jax.experimental.sparse.bcoo.lhs_ndim->len(lhs_spinfo.shape)
A:jax.experimental.sparse.bcoo.lhs_kept->remaining(range(lhs_ndim), lhs_contract, lhs_batch)
A:jax.experimental.sparse.bcoo.rhs_kept->remaining(range(rhs_ndim), rhs_contract, rhs_batch)
A:jax.experimental.sparse.bcoo.(ans_batch, ans_lhs, ans_rhs)->map(list, ranges_like(lhs_batch, lhs_kept, rhs_kept))
A:jax.experimental.sparse.bcoo.lhs_contract_sorted_by_rhs->list(np.take(lhs_contract, np.argsort(rhs_contract)))
A:jax.experimental.sparse.bcoo.out_axes->list(np.argsort(list(rhs_batch) + rhs_contract_sorted_by_lhs + rhs_kept))
A:jax.experimental.sparse.bcoo.dummy_data->jax.numpy.ones([1 for i in range(lhs_indices.ndim - 2)] + [lhs_indices.shape[-2]])
A:jax.experimental.sparse.bcoo.dummy_spinfo->BCOOInfo(tuple(lhs_indices.shape[:-2]) + tuple((1 for i in range(lhs_indices.shape[-1]))))
A:jax.experimental.sparse.bcoo.(_, lhs_indices_T)->_bcoo_transpose(dummy_data, lhs_indices, permutation=permutation, spinfo=dummy_spinfo)
A:jax.experimental.sparse.bcoo.result_T->bcoo_dot_general_sampled(ct, rhs, lhs_indices_T, dimension_numbers=dims)
A:jax.experimental.sparse.bcoo.(result, _)->_bcoo_transpose(result_T, lhs_indices_T, permutation=out_axes, spinfo=dummy_spinfo)
A:jax.experimental.sparse.bcoo.rhs_contract_sorted_by_lhs->list(np.take(rhs_contract, np.argsort(lhs_contract)))
A:jax.experimental.sparse.bcoo.(new_dimension_numbers, result_batch_dim)->_dot_general_batch_dim_nums((len(lhs_shape), len(rhs_shape)), (batch_dims[0], batch_dims[2]), dimension_numbers)
A:jax.experimental.sparse.bcoo.batched_out->_bcoo_spdot_general(lhs_data, lhs_indices, rhs_data, rhs_indices, dimension_numbers=new_dimension_numbers, lhs_spinfo=BCOOInfo(new_lhs_shape), rhs_spinfo=BCOOInfo(new_rhs_shape))
A:jax.experimental.sparse.bcoo.bcoo_dot_general_sampled_p->jax.core.Primitive('bcoo_dot_general_sampled')
A:jax.experimental.sparse.bcoo.dense_result->jax.lax.dot_general(A, B, dimension_numbers=dimension_numbers)
A:jax.experimental.sparse.bcoo.(dense_result,)->jax.interpreters.partial_eval.abstract_eval_fun(lambda *args: [lax.dot_general(*args, dimension_numbers=dimension_numbers)], A, B)
A:jax.experimental.sparse.bcoo.(sparse_result,)->jax.interpreters.partial_eval.abstract_eval_fun(lambda *args: [bcoo_extract(*args)], indices, dense_result)
A:jax.experimental.sparse.bcoo.mat_shape->_dot_general_validated_shape(A_shape, B_shape, dimension_numbers)
A:jax.experimental.sparse.bcoo.(indices, ct)->_bcoo_extract_transpose(ct, indices, mat)
A:jax.experimental.sparse.bcoo.(A, B)->jax.interpreters.ad.get_primitive_transpose(lax.dot_general_p)(ct, A, B, **kwds)
A:jax.experimental.sparse.bcoo.bcoo_spdot_general_p->jax.core.Primitive('bcoo_spdot_general')
A:jax.experimental.sparse.bcoo.overlap->(lhs_i[:, None] == rhs_i[None, :]).all(-1)
A:jax.experimental.sparse.bcoo.lhs_fill_value->jax.numpy.expand_dims(jnp.array([lhs_shape[d] for d in lhs_contracting]), range(lhs_i.ndim - 1))
A:jax.experimental.sparse.bcoo.rhs_fill_value->jax.numpy.expand_dims(jnp.array([rhs_shape[d] for d in rhs_contracting]), range(rhs_i.ndim - 1))
A:jax.experimental.sparse.bcoo.lhs_valid->(lhs_i < lhs_fill_value).all(-1)
A:jax.experimental.sparse.bcoo.rhs_valid->(rhs_i < rhs_fill_value).all(-1)
A:jax.experimental.sparse.bcoo.out_data->jax.numpy.where(overlap & lhs_valid[:, None] & rhs_valid[None, :], lhs_data[:, None] * rhs_data[None, :], 0).ravel()
A:jax.experimental.sparse.bcoo.out_indices->out_indices.reshape(len(out_data), out_indices.shape[-1]).reshape(len(out_data), out_indices.shape[-1])
A:jax.experimental.sparse.bcoo.(data_aval, indices_aval)->_bcoo_spdot_general_abstract_eval(lhs_data.aval, lhs_indices.aval, rhs_data.aval, rhs_indices.aval, lhs_spinfo=lhs_spinfo, rhs_spinfo=rhs_spinfo, dimension_numbers=dimension_numbers)
A:jax.experimental.sparse.bcoo.rhs_data->rhs_data.transpose([*rhs_batch_perm, *range(rhs.n_batch, rhs_data.ndim)]).transpose([*rhs_batch_perm, *range(rhs.n_batch, rhs_data.ndim)])
A:jax.experimental.sparse.bcoo.rhs_indices->rhs_indices.transpose([*rhs_batch_perm, *range(rhs.n_batch, rhs_indices.ndim)]).transpose([*rhs_batch_perm, *range(rhs.n_batch, rhs_indices.ndim)])
A:jax.experimental.sparse.bcoo.func->broadcasting_vmap(func, in_axes=0)
A:jax.experimental.sparse.bcoo._->_dot_general_validated_shape(lhs_shape, rhs_shape, dimension_numbers)
A:jax.experimental.sparse.bcoo.(batch_dims, sparse_dims, dense_dims)->split_list(broadcast_dimensions, [props.n_batch, props.n_sparse])
A:jax.experimental.sparse.bcoo.new_data->jax.lax.broadcast_in_dim(data, shape=(*shape[:new_n_batch], nse, *shape[new_n_batch + new_n_sparse:]), broadcast_dimensions=(*batch_dims, new_n_batch, *(b + 1 - new_n_sparse for b in dense_dims)))
A:jax.experimental.sparse.bcoo.new_indices->jax.numpy.zeros_like(new_indices, shape=(*shape[:new_n_batch], nse, new_n_sparse)).at[..., jnp.array(sparse_dims, int) - new_n_batch].set(new_indices)
A:jax.experimental.sparse.bcoo.(out_data, out_indices, out_shape)->_bcoo_multiply_sparse(lhs.data, lhs.indices, rhs.data, rhs.indices, lhs_spinfo=lhs._info, rhs_spinfo=rhs._info)
A:jax.experimental.sparse.bcoo.(n_batch, n_sparse, _, nse)->_validate_bcoo(data, indices, shape)
A:jax.experimental.sparse.bcoo.axes->sorted(set(axes))
A:jax.experimental.sparse.bcoo.dense_axes->tuple((ax - n_sparse + 1 for ax in axes if ax >= n_batch + n_sparse))
A:jax.experimental.sparse.bcoo.new_batch_dims->tuple(sorted(set(range(n_batch)) - batch_axes))
A:jax.experimental.sparse.bcoo.new_batch_shape->tuple((data.shape[i] for i in new_batch_dims))
A:jax.experimental.sparse.bcoo.new_nse->int(nse * np.prod([data.shape[i] for i in batch_axes]))
A:jax.experimental.sparse.bcoo._mul->broadcasting_vmap(_mul)
A:jax.experimental.sparse.bcoo.(rhs_data, rhs_indices)->_unbatch_bcoo(rhs_data, rhs_indices, rhs_shape)
A:jax.experimental.sparse.bcoo.dims->jax.numpy.array([i for (i, (s1, s2)) in enumerate(safe_zip(lhs_shape[:lhs.n_sparse], rhs_shape[:rhs.n_sparse])) if s1 != 1 and s2 != 1], dtype=int)
A:jax.experimental.sparse.bcoo.(i_lhs, i_rhs)->jax.numpy.nonzero(mask, size=nse, fill_value=(lhs.nse, rhs.nse))
A:jax.experimental.sparse.bcoo.v->jax.lax.expand_dims(v, range(len(shape) - v.ndim))
A:jax.experimental.sparse.bcoo.ind->tuple((i if s != 1 else 0 for (i, s) in zip(ind, v.shape)))
A:jax.experimental.sparse.bcoo.dtype->property(lambda self: self.data.dtype)
A:jax.experimental.sparse.bcoo.n_sparse->property(lambda self: self.indices.shape[-1])
A:jax.experimental.sparse.bcoo.n_dense->property(lambda self: self.data.ndim - 1 - self.n_batch)
A:jax.experimental.sparse.bcoo._info->property(lambda self: BCOOInfo(self.shape))
A:jax.experimental.sparse.bcoo._bufs->property(lambda self: (self.data, self.indices))
A:jax.experimental.sparse.bcoo.(self.data, self.indices)->_safe_asarray(args)
A:jax.experimental.sparse.bcoo.(batch_shape, sparse_shape, dense_shape)->split_list(shape, [n_batch, n_sparse])
A:jax.experimental.sparse.bcoo.mat_T->bcoo_transpose(self, permutation=axes)
A:jax.experimental.sparse.bcoo.shape_T->tuple((self.shape[i] for i in axes))
jax.experimental.sparse.BCOO(self,args,*,shape)
jax.experimental.sparse.BCOO._dedupe(self)
jax.experimental.sparse.BCOO._empty(cls,shape,*,dtype=None,index_dtype='int32',n_dense=0,n_batch=0,nse=0)
jax.experimental.sparse.BCOO._unbatch(self)
jax.experimental.sparse.BCOO.from_scipy_sparse(cls,mat,*,index_dtype=None,n_dense=0,n_batch=0)
jax.experimental.sparse.BCOO.fromdense(cls,mat,*,nse=None,index_dtype=np.int32,n_dense=0,n_batch=0)
jax.experimental.sparse.BCOO.sort_indices(self)
jax.experimental.sparse.BCOO.sum_duplicates(self,nse=None,remove_zeros=True)
jax.experimental.sparse.BCOO.todense(self)
jax.experimental.sparse.BCOO.transpose(self,axes=None)
jax.experimental.sparse.BCOO.tree_flatten(self)
jax.experimental.sparse.BCOOInfo(NamedTuple)
jax.experimental.sparse.BCOOProperties(NamedTuple)
jax.experimental.sparse.bcoo.BCOO(self,args,*,shape)
jax.experimental.sparse.bcoo.BCOO.__init__(self,args,*,shape)
jax.experimental.sparse.bcoo.BCOO._dedupe(self)
jax.experimental.sparse.bcoo.BCOO._empty(cls,shape,*,dtype=None,index_dtype='int32',n_dense=0,n_batch=0,nse=0)
jax.experimental.sparse.bcoo.BCOO._unbatch(self)
jax.experimental.sparse.bcoo.BCOO.from_scipy_sparse(cls,mat,*,index_dtype=None,n_dense=0,n_batch=0)
jax.experimental.sparse.bcoo.BCOO.fromdense(cls,mat,*,nse=None,index_dtype=np.int32,n_dense=0,n_batch=0)
jax.experimental.sparse.bcoo.BCOO.sort_indices(self)
jax.experimental.sparse.bcoo.BCOO.sum_duplicates(self,nse=None,remove_zeros=True)
jax.experimental.sparse.bcoo.BCOO.todense(self)
jax.experimental.sparse.bcoo.BCOO.transpose(self,axes=None)
jax.experimental.sparse.bcoo.BCOO.tree_flatten(self)
jax.experimental.sparse.bcoo.BCOOInfo(NamedTuple)
jax.experimental.sparse.bcoo.BCOOProperties(NamedTuple)
jax.experimental.sparse.bcoo._add_batch_dim(M)
jax.experimental.sparse.bcoo._bcoo_broadcast_in_dim(data,indices,*,spinfo,shape,broadcast_dimensions)
jax.experimental.sparse.bcoo._bcoo_dot_general(lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_abstract_eval(lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_batch_rule(batched_args,batch_dims,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_cuda_lowering(ctx,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_cuda_translation_rule(ctx,avals_in,avals_out,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_gpu_lowering(ctx,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_gpu_translation_rule(ctx,avals_in,avals_out,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_impl(lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_jvp_lhs(lhs_data_dot,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_jvp_rhs(rhs_dot,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_dot_general_sampled_abstract_eval(A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_dot_general_sampled_batch_rule(batched_args,batch_dims,*,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_dot_general_sampled_impl(A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_dot_general_sampled_jvp_A(A_dot,A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_dot_general_sampled_jvp_B(B_dot,A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_dot_general_sampled_transpose(ct,A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_dot_general_transpose(ct,lhs_data,lhs_indices,rhs,*,dimension_numbers,lhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_extract_abstract_eval(indices,mat)
jax.experimental.sparse.bcoo._bcoo_extract_batching_rule(batched_args,batch_dims)
jax.experimental.sparse.bcoo._bcoo_extract_impl(indices,mat)
jax.experimental.sparse.bcoo._bcoo_extract_jvp(mat_dot,indices,mat)
jax.experimental.sparse.bcoo._bcoo_extract_transpose(ct,indices,mat)
jax.experimental.sparse.bcoo._bcoo_from_elt(cont,axis_size,elt,axis)
jax.experimental.sparse.bcoo._bcoo_fromdense(mat,*,nse,n_batch=0,n_dense=0,index_dtype=jnp.int32)
jax.experimental.sparse.bcoo._bcoo_fromdense_abstract_eval(mat,*,nse,n_batch,n_dense,index_dtype)
jax.experimental.sparse.bcoo._bcoo_fromdense_batching_rule(batched_args,batch_dims,*,nse,n_batch,n_dense,index_dtype)
jax.experimental.sparse.bcoo._bcoo_fromdense_impl(mat,*,nse,n_batch,n_dense,index_dtype)
jax.experimental.sparse.bcoo._bcoo_fromdense_jvp(primals,tangents,*,nse,n_batch,n_dense,index_dtype)
jax.experimental.sparse.bcoo._bcoo_fromdense_transpose(ct,M,*,nse,n_batch,n_dense,index_dtype)
jax.experimental.sparse.bcoo._bcoo_multiply_dense(data,indices,v,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_multiply_sparse(lhs_data,lhs_indices,rhs_data,rhs_indices,*,lhs_spinfo,rhs_spinfo)
jax.experimental.sparse.bcoo._bcoo_multiply_sparse_unbatched(lhs_data,lhs_indices,rhs_data,rhs_indices,*,lhs_shape,rhs_shape)
jax.experimental.sparse.bcoo._bcoo_nse(mat,n_batch=0,n_dense=0)
jax.experimental.sparse.bcoo._bcoo_rdot_general(lhs,rhs_data,rhs_indices,*,dimension_numbers:DotDimensionNumbers,rhs_spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_reduce_sum(data,indices,*,spinfo,axes)
jax.experimental.sparse.bcoo._bcoo_sort_indices(data,indices,shape)
jax.experimental.sparse.bcoo._bcoo_spdot_general(lhs_data,lhs_indices,rhs_data,rhs_indices,*,lhs_spinfo:BCOOInfo,rhs_spinfo:BCOOInfo,dimension_numbers:DotDimensionNumbers)
jax.experimental.sparse.bcoo._bcoo_spdot_general_abstract_eval(lhs_data,lhs_indices,rhs_data,rhs_indices,*,lhs_spinfo:BCOOInfo,rhs_spinfo:BCOOInfo,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_spdot_general_batch_rule(batched_args,batch_dims,*,lhs_spinfo:BCOOInfo,rhs_spinfo:BCOOInfo,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_spdot_general_impl(lhs_data,lhs_indices,rhs_data,rhs_indices,*,lhs_spinfo:BCOOInfo,rhs_spinfo:BCOOInfo,dimension_numbers)
jax.experimental.sparse.bcoo._bcoo_spdot_general_jvp(primals,tangents,**kwds)
jax.experimental.sparse.bcoo._bcoo_spdot_general_unbatched(lhs_data,lhs_indices,rhs_data,rhs_indices,*,lhs_spinfo,rhs_spinfo,lhs_contracting,rhs_contracting)
jax.experimental.sparse.bcoo._bcoo_sum_duplicates(data,indices,shape,nse=None,remove_zeros=True)
jax.experimental.sparse.bcoo._bcoo_sum_duplicates_unbatched(data,indices,*,shape,nse,remove_zeros)
jax.experimental.sparse.bcoo._bcoo_to_elt(cont,_,val,axis)
jax.experimental.sparse.bcoo._bcoo_todense(data,indices,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_todense_abstract_eval(data,indices,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_todense_batching_rule(batched_args,batch_dims,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_todense_impl(data,indices,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_todense_jvp(data_dot,data,indices,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_todense_transpose(ct,data,indices,*,spinfo)
jax.experimental.sparse.bcoo._bcoo_transpose(data,indices,*,permutation:Sequence[int],spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_transpose_abstract_eval(data,indices,*,permutation:Sequence[int],spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_transpose_batch_rule(batched_args,batch_dims,*,permutation:Sequence[int],spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_transpose_impl(data,indices,*,permutation:Sequence[int],spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_transpose_jvp(primals,tangents,*,permutation:Sequence[int],spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._bcoo_transpose_transpose(ct,data,indices,*,permutation:Sequence[int],spinfo:BCOOInfo)
jax.experimental.sparse.bcoo._collapse_mhlo(x,start,end)
jax.experimental.sparse.bcoo._dot_general_validated_shape(lhs_shape:Shape,rhs_shape:Shape,dimension_numbers:DotDimensionNumbers)->Shape
jax.experimental.sparse.bcoo._tuple_replace(tup,ind,val)
jax.experimental.sparse.bcoo._unbatch_bcoo(data,indices,shape)
jax.experimental.sparse.bcoo._validate_bcoo(data:jnp.ndarray,indices:jnp.ndarray,shape:Sequence[int])->BCOOProperties
jax.experimental.sparse.bcoo._validate_bcoo_indices(indices:jnp.ndarray,shape:Sequence[int])->BCOOProperties
jax.experimental.sparse.bcoo._validate_permutation(data,indices,permutation,shape)
jax.experimental.sparse.bcoo.bcoo_add_batch_dim(M)
jax.experimental.sparse.bcoo.bcoo_broadcast_in_dim(mat,*,shape,broadcast_dimensions)
jax.experimental.sparse.bcoo.bcoo_dot_general(lhs,rhs,*,dimension_numbers)
jax.experimental.sparse.bcoo.bcoo_dot_general_sampled(A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo.bcoo_extract(indices,mat)
jax.experimental.sparse.bcoo.bcoo_fromdense(mat,*,nse=None,n_batch=0,n_dense=0,index_dtype=jnp.int32)
jax.experimental.sparse.bcoo.bcoo_multiply_dense(sp_mat,v)
jax.experimental.sparse.bcoo.bcoo_multiply_sparse(lhs,rhs)
jax.experimental.sparse.bcoo.bcoo_reduce_sum(mat,*,axes)
jax.experimental.sparse.bcoo.bcoo_todense(mat)
jax.experimental.sparse.bcoo.bcoo_transpose(mat,*,permutation:Sequence[int])
jax.experimental.sparse.bcoo.broadcasting_vmap(fun,in_axes=0,out_axes=0)
jax.experimental.sparse.bcoo_add_batch_dim(M)
jax.experimental.sparse.bcoo_broadcast_in_dim(mat,*,shape,broadcast_dimensions)
jax.experimental.sparse.bcoo_dot_general(lhs,rhs,*,dimension_numbers)
jax.experimental.sparse.bcoo_dot_general_sampled(A,B,indices,*,dimension_numbers)
jax.experimental.sparse.bcoo_extract(indices,mat)
jax.experimental.sparse.bcoo_fromdense(mat,*,nse=None,n_batch=0,n_dense=0,index_dtype=jnp.int32)
jax.experimental.sparse.bcoo_multiply_dense(sp_mat,v)
jax.experimental.sparse.bcoo_multiply_sparse(lhs,rhs)
jax.experimental.sparse.bcoo_reduce_sum(mat,*,axes)
jax.experimental.sparse.bcoo_todense(mat)
jax.experimental.sparse.bcoo_transpose(mat,*,permutation:Sequence[int])


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/_base.py----------------------------------------
A:jax.experimental.sparse._base.self.shape->tuple(shape)
A:jax.experimental.sparse._base.shape->list(self.shape)
jax.experimental.sparse._base.JAXSparse(self,args,*,shape)
jax.experimental.sparse._base.JAXSparse.T(self)
jax.experimental.sparse._base.JAXSparse.__add__(self,other)
jax.experimental.sparse._base.JAXSparse.__getitem__(self,item)
jax.experimental.sparse._base.JAXSparse.__init__(self,args,*,shape)
jax.experimental.sparse._base.JAXSparse.__matmul__(self,other)
jax.experimental.sparse._base.JAXSparse.__mul__(self,other)
jax.experimental.sparse._base.JAXSparse.__neg__(self)
jax.experimental.sparse._base.JAXSparse.__pos__(self)
jax.experimental.sparse._base.JAXSparse.__radd__(self,other)
jax.experimental.sparse._base.JAXSparse.__repr__(self)
jax.experimental.sparse._base.JAXSparse.__rmatmul__(self,other)
jax.experimental.sparse._base.JAXSparse.__rmul__(self,other)
jax.experimental.sparse._base.JAXSparse.__rsub__(self,other)
jax.experimental.sparse._base.JAXSparse.__sub__(self,other)
jax.experimental.sparse._base.JAXSparse.block_until_ready(self)
jax.experimental.sparse._base.JAXSparse.ndim(self)
jax.experimental.sparse._base.JAXSparse.size(self)
jax.experimental.sparse._base.JAXSparse.sum(self,*args,**kwargs)
jax.experimental.sparse._base.JAXSparse.transpose(self,axes=None)
jax.experimental.sparse._base.JAXSparse.tree_flatten(self)
jax.experimental.sparse._base.JAXSparse.tree_unflatten(cls,aux_data,children)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/random.py----------------------------------------
A:jax.experimental.sparse.random.shape->tuple(map(operator.index, shape))
A:jax.experimental.sparse.random.n_batch->operator.index(n_batch)
A:jax.experimental.sparse.random.n_dense->operator.index(n_dense)
A:jax.experimental.sparse.random.(batch_shape, sparse_shape, dense_shape)->map(tuple, split_list(shape, [n_batch, n_sparse]))
A:jax.experimental.sparse.random.batch_size->numpy.prod(batch_shape)
A:jax.experimental.sparse.random.sparse_size->numpy.prod(sparse_shape)
A:jax.experimental.sparse.random.nse->operator.index(nse)
A:jax.experimental.sparse.random.flat_ind->jax.random.choice(key, sparse_size, shape=(nse,), replace=not unique_indices)
A:jax.experimental.sparse.random.keys->jax.random.split(key, batch_size + 1)
A:jax.experimental.sparse.random.data->generator(data_key, shape=data_shape, dtype=dtype, **kwds)
A:jax.experimental.sparse.random.indices->_indices(index_keys).reshape(indices_shape).astype(indices_dtype)
A:jax.experimental.sparse.random.mat->jax.experimental.sparse.BCOO((data, indices), shape=shape)
jax.experimental.sparse.random.random_bcoo(key,shape,*,dtype=jnp.float_,indices_dtype=jnp.int_,nse=0.2,n_batch=0,n_dense=0,unique_indices=True,sorted_indices=False,generator=random.uniform,**kwds)
jax.experimental.sparse.random_bcoo(key,shape,*,dtype=jnp.float_,indices_dtype=jnp.int_,nse=0.2,n_batch=0,n_dense=0,unique_indices=True,sorted_indices=False,generator=random.uniform,**kwds)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/util.py----------------------------------------
jax.experimental.sparse.CuSparseEfficiencyWarning(UserWarning)
jax.experimental.sparse.util.CuSparseEfficiencyWarning(UserWarning)
jax.experimental.sparse.util._asarray_or_float0(arg)
jax.experimental.sparse.util._coo_extract(row,col,mat)
jax.experimental.sparse.util._csr_extract(indices,indptr,mat)
jax.experimental.sparse.util._csr_to_coo(indices,indptr)
jax.experimental.sparse.util._is_aval(*args)
jax.experimental.sparse.util._is_pytree_placeholder(*args)
jax.experimental.sparse.util._safe_asarray(args)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/sparse/transform.py----------------------------------------
A:jax.experimental.sparse.transform.self._buffers->list(bufs)
A:jax.experimental.sparse.transform.data_ref->self._push(data)
A:jax.experimental.sparse.transform.indices_ref->self._push(indices)
A:jax.experimental.sparse.transform.data->SparsifyEnv().data(arr)
A:jax.experimental.sparse.transform.val->getattr(obj, name)
A:jax.experimental.sparse.transform.(spvalue,)->arrays_to_spvalues(self.main.spenv, [val])
A:jax.experimental.sparse.transform.spenv->SparsifyEnv()
A:jax.experimental.sparse.transform.out_spvalues->arrays_to_spvalues(spenv, out_bufs if primitive.multiple_results else [out_bufs])
A:jax.experimental.sparse.transform.out_bufs->prim.bind(*(spenv.data(val) for val in invals), **eqn.params)
A:jax.experimental.sparse.transform.out_tracers->tuple((SparseTracer(self, spvalue=spvalue) for spvalue in out_spvalues))
A:jax.experimental.sparse.transform.spvalues->arrays_to_spvalues(spenv, args)
A:jax.experimental.sparse.transform.(fun, out_spvalues)->sparsify_subtrace(wrapped_fun, main, spvalues)
A:jax.experimental.sparse.transform.params->eqn.params.copy()
A:jax.experimental.sparse.transform.bufs_out->call_primitive.bind(fun, *in_bufs, **params)
A:jax.experimental.sparse.transform.trace->main.with_cur_sublevel()
A:jax.experimental.sparse.transform.(args_flat, in_tree)->tree_flatten(args)
A:jax.experimental.sparse.transform.(wrapped_fun, out_tree)->flatten_fun_nokwargs(lu.wrap_init(f, params), in_tree)
A:jax.experimental.sparse.transform.out->jax.experimental.sparse.BCOO((spenv.data(spvalue), spenv.indices(spvalue)), shape=spvalue.shape).todense()
A:jax.experimental.sparse.transform.env[var]->SparsifyEnv().dense(a)
A:jax.experimental.sparse.transform.invals->safe_map(read, eqn.invars)
A:jax.experimental.sparse.transform.fun->jax.linear_util.wrap_init(core.jaxpr_as_fun(sp_call_jaxpr))
A:jax.experimental.sparse.transform.(spvalues_flat, in_tree)->tree_flatten(spvalues, is_leaf=_is_spvalue)
A:jax.experimental.sparse.transform.in_avals_flat->spvalues_to_avals(spenv, spvalues_flat)
A:jax.experimental.sparse.transform.(jaxpr, out_avals_flat, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(wrapped_fun, in_avals_flat)
A:jax.experimental.sparse.transform.result->jax.experimental.sparse.BCOO.fromdense(result)
A:jax.experimental.sparse.transform.f_raw->sparsify_raw(f)
A:jax.experimental.sparse.transform.(spvalues_out, out_tree)->f_raw(spenv, *spvalues, **params)
A:jax.experimental.sparse.transform.buf->SparsifyEnv().data(spvalues[0])
A:jax.experimental.sparse.transform.buf_out->prim.bind(buf, **kwargs)
A:jax.experimental.sparse.transform.out_spvalue->SparsifyEnv().sparse(out_shape, mat.data, mat.indices)
A:jax.experimental.sparse.transform.sparse_rules[_prim]->_zero_preserving_unary_op(_prim)
A:jax.experimental.sparse.transform.permutation->tuple(permutation)
A:jax.experimental.sparse.transform.args->spvalues_to_arrays(spenv, spvalues)
A:jax.experimental.sparse.transform.mat->jax.experimental.sparse.bcoo_broadcast_in_dim(operand_promoted, shape=shape, broadcast_dimensions=broadcast_dimensions)
A:jax.experimental.sparse.transform.mat_transposed->jax.experimental.sparse.bcoo_transpose(mat, permutation=permutation)
A:jax.experimental.sparse.transform.out_shape->tuple((s for (i, s) in enumerate(arr.shape) if i not in dimensions))
A:jax.experimental.sparse.transform.spvalue->SparsifyEnv().sparse(out_shape, **kwds)
A:jax.experimental.sparse.transform.out_data->bcoo_multiply_dense(X_promoted, spenv.data(Y))
A:jax.experimental.sparse.transform.out_indices->jax.lax.concatenate([spenv.indices(X), spenv.indices(Y)], dimension=spenv.indices(X).ndim - 2)
A:jax.experimental.sparse.transform.(X_promoted, Y_promoted)->spvalues_to_arrays(spenv, spvalues)
A:jax.experimental.sparse.transform.X_promoted->spvalues_to_arrays(spenv, X)
A:jax.experimental.sparse.transform.operand_promoted->spvalues_to_arrays(spenv, operand)
A:jax.experimental.sparse.transform.dimensions->tuple((canonicalize_axis(dim, arr.ndim) for dim in dimensions))
A:jax.experimental.sparse.transform.indices->SparsifyEnv().indices(arr)
A:jax.experimental.sparse.transform.batch_dims->tuple((d for d in dimensions if d < n_batch))
A:jax.experimental.sparse.transform.sparse_dims->numpy.array([i for i in range(n_sparse) if i + n_batch not in dimensions], dtype=int)
A:jax.experimental.sparse.transform.dense_dims->tuple((d - n_sparse + 1 for d in dimensions if d >= n_batch + n_sparse))
A:jax.experimental.sparse.transform.data_out->jax.lax.squeeze(data, batch_dims + dense_dims)
A:jax.experimental.sparse.transform.indices_out->jax.lax.squeeze(indices[..., sparse_dims], batch_dims)
A:jax.experimental.sparse.transform.(out_flat, out_tree)->tree_flatten(out)
A:jax.experimental.sparse.transform.(sp_jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(wrapped, avals_flat)
A:jax.experimental.sparse.transform.sp_jaxpr->jax.interpreters.partial_eval.ClosedJaxpr(sp_jaxpr, consts)
A:jax.experimental.sparse.transform.(cond_const_spvalues, body_const_spvalues, init_val_spvalues)->split_list(spvalues, [cond_nconsts, body_nconsts])
A:jax.experimental.sparse.transform.(cond_sp_jaxpr, _)->_sparsify_jaxpr(spenv, cond_jaxpr, *cond_const_spvalues, *init_val_spvalues)
A:jax.experimental.sparse.transform.(body_sp_jaxpr, out_tree)->_sparsify_jaxpr(spenv, body_jaxpr, *body_const_spvalues, *init_val_spvalues)
A:jax.experimental.sparse.transform.(cond_consts, _)->tree_flatten(spvalues_to_arrays(spenv, cond_const_spvalues))
A:jax.experimental.sparse.transform.(body_consts, _)->tree_flatten(spvalues_to_arrays(spenv, body_const_spvalues))
A:jax.experimental.sparse.transform.(init_vals, _)->tree_flatten(spvalues_to_arrays(spenv, init_val_spvalues))
A:jax.experimental.sparse.transform.out_flat->jax.lax.cond_p.bind(*args, branches=sp_branches, linear=sp_linear, **params)
A:jax.experimental.sparse.transform.(sp_call_jaxpr, out_tree)->_sparsify_jaxpr(spenv, pe.ClosedJaxpr(call_jaxpr, ()), *spvalues)
A:jax.experimental.sparse.transform.(args_flat, _)->tree_flatten(spvalues_to_arrays(spenv, spvalues))
A:jax.experimental.sparse.transform.donated_invars->tuple((False for arg in args_flat))
A:jax.experimental.sparse.transform.(const_spvalues, carry_spvalues, xs_spvalues)->split_list(spvalues, [num_consts, num_carry])
A:jax.experimental.sparse.transform.(sp_jaxpr, _)->_sparsify_jaxpr(spenv, jaxpr, *const_spvalues, *carry_spvalues, *xs_spvalues)
A:jax.experimental.sparse.transform.(consts, _)->tree_flatten(spvalues_to_arrays(spenv, const_spvalues))
A:jax.experimental.sparse.transform.(carry, carry_tree)->tree_flatten(spvalues_to_arrays(spenv, carry_spvalues))
A:jax.experimental.sparse.transform.(xs, xs_tree)->tree_flatten(spvalues_to_arrays(spenv, xs_spvalues))
A:jax.experimental.sparse.transform.(const_linear, carry_linear, xs_linear)->split_list(params.pop('linear'), [num_consts, num_carry])
A:jax.experimental.sparse.transform.sp_linear->tuple(_duplicate_for_sparse_spvalues(operands, linear))
A:jax.experimental.sparse.transform.carry_out->tree_unflatten(carry_tree, out[:len(carry)])
A:jax.experimental.sparse.transform.xs_out->tree_unflatten(xs_tree, out[len(carry):])
A:jax.experimental.sparse.transform.(sp_branches, treedefs)->zip(*(_sparsify_jaxpr(spenv, jaxpr, *operands) for jaxpr in branches))
A:jax.experimental.sparse.transform.(args, _)->tree_flatten(spvalues_to_arrays(spenv, (pred, *operands)))
A:jax.experimental.sparse.transform.(treedef, static_idx, dynamic_idx)->jax._src.numpy.lax_numpy._split_index_for_jit(idx, arr.shape)
jax.experimental.sparse.SparseTracer(self,trace:core.Trace,*,spvalue)
jax.experimental.sparse.SparseTracer.aval(self)
jax.experimental.sparse.SparseTracer.full_lower(self)
jax.experimental.sparse.SparseTracer.spenv(self)
jax.experimental.sparse.sparsify(f,use_tracer=False)
jax.experimental.sparse.sparsify_fun(wrapped_fun,args:List[ArrayOrSparse])
jax.experimental.sparse.sparsify_raw(f)
jax.experimental.sparse.sparsify_subtrace(main,spvalues,*bufs)
jax.experimental.sparse.transform.SparseTrace(core.Trace)
jax.experimental.sparse.transform.SparseTrace.lift(self,val:core.Tracer)
jax.experimental.sparse.transform.SparseTrace.process_call(self,call_primitive,f:lu.WrappedFun,tracers,params)
jax.experimental.sparse.transform.SparseTrace.process_primitive(self,primitive,tracers,params)
jax.experimental.sparse.transform.SparseTrace.pure(self,val:Any)
jax.experimental.sparse.transform.SparseTrace.sublift(self,val:SparseTracer)
jax.experimental.sparse.transform.SparseTracer(self,trace:core.Trace,*,spvalue)
jax.experimental.sparse.transform.SparseTracer.__init__(self,trace:core.Trace,*,spvalue)
jax.experimental.sparse.transform.SparseTracer.aval(self)
jax.experimental.sparse.transform.SparseTracer.full_lower(self)
jax.experimental.sparse.transform.SparseTracer.spenv(self)
jax.experimental.sparse.transform.SparsifyEnv(self,bufs=())
jax.experimental.sparse.transform.SparsifyEnv.__init__(self,bufs=())
jax.experimental.sparse.transform.SparsifyEnv._push(self,arr:Array)->int
jax.experimental.sparse.transform.SparsifyEnv.data(self,spvalue:'SparsifyValue')->Array
jax.experimental.sparse.transform.SparsifyEnv.dense(self,data)
jax.experimental.sparse.transform.SparsifyEnv.indices(self,spvalue:'SparsifyValue')->Array
jax.experimental.sparse.transform.SparsifyEnv.sparse(self,shape,data=None,indices=None,*,data_ref=None,indices_ref=None)
jax.experimental.sparse.transform.SparsifyEnv.unit(self)
jax.experimental.sparse.transform.SparsifyValue(NamedTuple)
jax.experimental.sparse.transform.SparsifyValue.is_sparse(self)
jax.experimental.sparse.transform.SparsifyValue.is_unit(self)
jax.experimental.sparse.transform.SparsifyValue.ndim(self)
jax.experimental.sparse.transform._add_sparse(spenv,*spvalues)
jax.experimental.sparse.transform._broadcast_in_dim_sparse(spenv,*spvalues,shape,broadcast_dimensions)
jax.experimental.sparse.transform._cond_sparse(spenv,pred,*operands,branches,linear,**params)
jax.experimental.sparse.transform._dot_general_sparse(spenv,*spvalues,dimension_numbers,precision,preferred_element_type)
jax.experimental.sparse.transform._duplicate_for_sparse_spvalues(spvalues,params)
jax.experimental.sparse.transform._mul_sparse(spenv,*spvalues)
jax.experimental.sparse.transform._reduce_sum_sparse(spenv,*spvalues,axes)
jax.experimental.sparse.transform._scan_sparse(spenv,*spvalues,jaxpr,num_consts,num_carry,**params)
jax.experimental.sparse.transform._sparse_rewriting_take(arr,idx,indices_are_sorted=False,unique_indices=False,mode=None,fill_value=None)
jax.experimental.sparse.transform._sparsify_jaxpr(spenv,jaxpr,*spvalues)
jax.experimental.sparse.transform._sparsify_with_interpreter(f)
jax.experimental.sparse.transform._sparsify_with_tracer(fun)
jax.experimental.sparse.transform._squeeze_sparse(spenv,*spvalues,dimensions)
jax.experimental.sparse.transform._sub_sparse(spenv,*spvalues)
jax.experimental.sparse.transform._sum(self,*args,**kwargs)
jax.experimental.sparse.transform._todense_sparse_rule(spenv,spvalue,*,tree)
jax.experimental.sparse.transform._transpose_sparse(spenv,*spvalues,permutation)
jax.experimental.sparse.transform._while_sparse(spenv,*spvalues,cond_jaxpr,cond_nconsts,body_jaxpr,body_nconsts)
jax.experimental.sparse.transform._xla_call_sparse(spenv,*spvalues,call_jaxpr,donated_invars,**params)
jax.experimental.sparse.transform._zero_preserving_unary_op(prim)
jax.experimental.sparse.transform.arrays_to_spvalues(spenv:SparsifyEnv,args:Any)->Any
jax.experimental.sparse.transform.eval_sparse(jaxpr:core.Jaxpr,consts:Sequence[Array],spvalues:Sequence[SparsifyValue],spenv:SparsifyEnv)->Sequence[SparsifyValue]
jax.experimental.sparse.transform.popattr(obj,name)
jax.experimental.sparse.transform.setnewattr(obj,name,val)
jax.experimental.sparse.transform.sparsify(f,use_tracer=False)
jax.experimental.sparse.transform.sparsify_fun(wrapped_fun,args:List[ArrayOrSparse])
jax.experimental.sparse.transform.sparsify_raw(f)
jax.experimental.sparse.transform.sparsify_subtrace(main,spvalues,*bufs)
jax.experimental.sparse.transform.spvalues_to_arrays(spenv:SparsifyEnv,spvalues:Any)->Any
jax.experimental.sparse.transform.spvalues_to_avals(spenv:SparsifyEnv,spvalues:Any)->Any


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/compilation_cache/compilation_cache.py----------------------------------------
A:jax.experimental.compilation_cache.compilation_cache._cache->FileSystemCache(path, max_cache_size_bytes)
A:jax.experimental.compilation_cache.compilation_cache.cache_key->get_cache_key(xla_computation, compile_options, backend)
A:jax.experimental.compilation_cache.compilation_cache.xla_executable_serialized->FileSystemCache(path, max_cache_size_bytes).get(cache_key)
A:jax.experimental.compilation_cache.compilation_cache.xla_executable_deserialized->backend.deserialize_executable(xla_executable_serialized, compile_options)
A:jax.experimental.compilation_cache.compilation_cache.serialized_executable->backend.serialize_executable(executable)
A:jax.experimental.compilation_cache.compilation_cache.fresh_hash_obj->hashlib.sha256()
A:jax.experimental.compilation_cache.compilation_cache.hash_obj->hashlib.sha256()
A:jax.experimental.compilation_cache.compilation_cache.serialized_hlo->xla_computation.as_serialized_hlo_module_proto()
A:jax.experimental.compilation_cache.compilation_cache.scrubbed_hlo->re.sub(b' at 0x[a-f0-9]+>', b' at 0x...>', serialized_hlo)
A:jax.experimental.compilation_cache.compilation_cache.xla_flags_env_var->os.getenv('XLA_FLAGS')
jax.experimental.compilation_cache.compilation_cache._hash_bool(hash_obj,bool_var)
jax.experimental.compilation_cache.compilation_cache._hash_compile_options(hash_obj,compile_options_obj)
jax.experimental.compilation_cache.compilation_cache._hash_computation(hash_obj,xla_computation)
jax.experimental.compilation_cache.compilation_cache._hash_debug_options(hash_obj,debug_obj)
jax.experimental.compilation_cache.compilation_cache._hash_executable_build_options(hash_obj,executable_obj)
jax.experimental.compilation_cache.compilation_cache._hash_int(hash_obj,int_var)
jax.experimental.compilation_cache.compilation_cache._hash_platform(hash_obj,backend)
jax.experimental.compilation_cache.compilation_cache._hash_string(hash_obj,str_var)
jax.experimental.compilation_cache.compilation_cache._hash_xla_flags(hash_obj)
jax.experimental.compilation_cache.compilation_cache._log_cache_key_hash(hash_obj,last_serialized:str,hashfn)
jax.experimental.compilation_cache.compilation_cache.get_cache_key(xla_computation,compile_options,backend)->str
jax.experimental.compilation_cache.compilation_cache.get_executable(xla_computation,compile_options,backend)->Optional[xla_client.Executable]
jax.experimental.compilation_cache.compilation_cache.initialize_cache(path,max_cache_size_bytes=32*2**30)
jax.experimental.compilation_cache.compilation_cache.is_initialized()
jax.experimental.compilation_cache.compilation_cache.put_executable(module_name,xla_computation,compile_options,executable:xla_client.Executable,backend)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/compilation_cache/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/compilation_cache/file_system_cache.py----------------------------------------
A:jax.experimental.compilation_cache.file_system_cache.path_to_key->os.path.join(self._path, key)
A:jax.experimental.compilation_cache.file_system_cache.path_to_new_file->os.path.join(self._path, key)
A:jax.experimental.compilation_cache.file_system_cache.temp_path_to_file->os.path.join(tmpdir, key)
A:jax.experimental.compilation_cache.file_system_cache.new_file_size->len(value)
A:jax.experimental.compilation_cache.file_system_cache.last_time->float('inf')
A:jax.experimental.compilation_cache.file_system_cache.file_to_inspect->os.path.join(self._path, file_name)
jax.experimental.compilation_cache.file_system_cache.FileSystemCache(self,path:str,max_cache_size_bytes=32*2**30)
jax.experimental.compilation_cache.file_system_cache.FileSystemCache.__init__(self,path:str,max_cache_size_bytes=32*2**30)
jax.experimental.compilation_cache.file_system_cache.FileSystemCache._evict_entries_if_necessary(self,key:str,value:bytes)->bool
jax.experimental.compilation_cache.file_system_cache.FileSystemCache._get_cache_directory_size(self)
jax.experimental.compilation_cache.file_system_cache.FileSystemCache.get(self,key:str)->Optional[bytes]
jax.experimental.compilation_cache.file_system_cache.FileSystemCache.put(self,key:str,value:bytes)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/experimental/compilation_cache/cache_interface.py----------------------------------------
jax.experimental.compilation_cache.cache_interface.CacheInterface(ABC)
jax.experimental.compilation_cache.cache_interface.CacheInterface.get(self,key:str)
jax.experimental.compilation_cache.cache_interface.CacheInterface.put(self,key:str,value:bytes)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/example_libraries/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/example_libraries/optimizers.py----------------------------------------
A:jax.example_libraries.optimizers.OptimizerState->namedtuple('OptimizerState', ['packed_state', 'tree_def', 'subtree_defs'])
A:jax.example_libraries.optimizers.(init, update, get_params)->opt_maker(*args, **kwargs)
A:jax.example_libraries.optimizers.(x0_flat, tree)->tree_flatten(x0_tree)
A:jax.example_libraries.optimizers.(states_flat, subtrees)->unzip2(map(tree_flatten, initial_states))
A:jax.example_libraries.optimizers.(grad_flat, tree2)->tree_flatten(grad_tree)
A:jax.example_libraries.optimizers.states->map(tree_unflatten, subtrees, states_flat)
A:jax.example_libraries.optimizers.new_states->map(partial(update, i), grad_flat, states)
A:jax.example_libraries.optimizers.(new_states_flat, subtrees2)->unzip2(map(tree_flatten, new_states))
A:jax.example_libraries.optimizers.params->map(get_params, states)
A:jax.example_libraries.optimizers.step_size->make_schedule(step_size)
A:jax.example_libraries.optimizers.v0->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.g_sq->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.m->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.g_sq_inv_sqrt->jax.numpy.where(g_sq > 0, 1.0 / jnp.sqrt(g_sq), 0.0)
A:jax.example_libraries.optimizers.avg_sq_grad->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.mom->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.m0->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.u0->jax.numpy.zeros_like(x0)
A:jax.example_libraries.optimizers.u->jax.numpy.maximum(b2 * u, jnp.abs(g))
A:jax.example_libraries.optimizers.lst->list(seq)
A:jax.example_libraries.optimizers.idx->splice([None] * ndim, axis, [slice(None)])
A:jax.example_libraries.optimizers.x0->jax.numpy.atleast_1d(x0)
A:jax.example_libraries.optimizers.accum_inv_sqrt->jax.numpy.where(accum > 0, 1.0 / jnp.sqrt(accum), 0)
A:jax.example_libraries.optimizers.step_num->jax.numpy.minimum(step_num, decay_steps)
A:jax.example_libraries.optimizers.boundaries->jax.numpy.array(boundaries)
A:jax.example_libraries.optimizers.values->jax.numpy.array(values)
A:jax.example_libraries.optimizers.(leaves, _)->tree_flatten(tree)
A:jax.example_libraries.optimizers.norm->l2_norm(grad_tree)
A:jax.example_libraries.optimizers.subtrees->map(tree_unflatten, subtree_defs, states_flat)
A:jax.example_libraries.optimizers.(sentinels, tree_def)->tree_flatten(marked_pytree)
A:jax.example_libraries.optimizers.(states_flat, subtree_defs)->unzip2(map(tree_flatten, subtrees))
jax.example_libraries.optimizers.JoinPoint(self,subtree)
jax.example_libraries.optimizers.JoinPoint.__init__(self,subtree)
jax.example_libraries.optimizers.JoinPoint.__iter__(self)
jax.example_libraries.optimizers.Optimizer(NamedTuple)
jax.example_libraries.optimizers.adagrad(step_size,momentum=0.9)
jax.example_libraries.optimizers.adam(step_size,b1=0.9,b2=0.999,eps=1e-08)
jax.example_libraries.optimizers.adamax(step_size,b1=0.9,b2=0.999,eps=1e-08)
jax.example_libraries.optimizers.clip_grads(grad_tree,max_norm)
jax.example_libraries.optimizers.constant(step_size)->Schedule
jax.example_libraries.optimizers.exponential_decay(step_size,decay_steps,decay_rate)
jax.example_libraries.optimizers.inverse_time_decay(step_size,decay_steps,decay_rate,staircase=False)
jax.example_libraries.optimizers.l2_norm(tree)
jax.example_libraries.optimizers.make_schedule(scalar_or_schedule:Union[float,Schedule])->Schedule
jax.example_libraries.optimizers.momentum(step_size:Schedule,mass:float)
jax.example_libraries.optimizers.nesterov(step_size:Schedule,mass:float)
jax.example_libraries.optimizers.optimizer(opt_maker:Callable[...,Tuple[Callable[[Params],State],Callable[[Step,Updates,Params],Params],Callable[[State],Params]]])->Callable[..., Optimizer]
jax.example_libraries.optimizers.pack_optimizer_state(marked_pytree)
jax.example_libraries.optimizers.piecewise_constant(boundaries:Any,values:Any)
jax.example_libraries.optimizers.polynomial_decay(step_size,decay_steps,final_step_size,power=1.0)
jax.example_libraries.optimizers.rmsprop(step_size,gamma=0.9,eps=1e-08)
jax.example_libraries.optimizers.rmsprop_momentum(step_size,gamma=0.9,eps=1e-08,momentum=0.9)
jax.example_libraries.optimizers.sgd(step_size)
jax.example_libraries.optimizers.sm3(step_size,momentum=0.9)
jax.example_libraries.optimizers.unpack_optimizer_state(opt_state)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/example_libraries/stax.py----------------------------------------
A:jax.example_libraries.stax.(k1, k2)->jax.random.split(rng)
A:jax.example_libraries.stax.filter_shape_iter->iter(filter_shape)
A:jax.example_libraries.stax.output_shape->jax.lax.conv_transpose_shape_tuple(input_shape, kernel_shape, strides, padding, dimension_numbers)
A:jax.example_libraries.stax.Conv->functools.partial(GeneralConv, ('NHWC', 'HWIO', 'NHWC'))
A:jax.example_libraries.stax.Conv1DTranspose->functools.partial(GeneralConvTranspose, ('NHC', 'HIO', 'NHC'))
A:jax.example_libraries.stax.ConvTranspose->functools.partial(GeneralConvTranspose, ('NHWC', 'HWIO', 'NHWC'))
A:jax.example_libraries.stax.shape->tuple((d for (i, d) in enumerate(input_shape) if i not in axis))
A:jax.example_libraries.stax.ed->tuple((None if i in axis else slice(None) for i in range(jnp.ndim(x))))
A:jax.example_libraries.stax.z->standardize(x, axis, epsilon=epsilon)
A:jax.example_libraries.stax.Tanh->elementwise(jnp.tanh)
A:jax.example_libraries.stax.Relu->elementwise(relu)
A:jax.example_libraries.stax.Exp->elementwise(jnp.exp)
A:jax.example_libraries.stax.LogSoftmax->elementwise(log_softmax, axis=-1)
A:jax.example_libraries.stax.Softmax->elementwise(softmax, axis=-1)
A:jax.example_libraries.stax.Softplus->elementwise(softplus)
A:jax.example_libraries.stax.Sigmoid->elementwise(sigmoid)
A:jax.example_libraries.stax.Elu->elementwise(elu)
A:jax.example_libraries.stax.LeakyRelu->elementwise(leaky_relu)
A:jax.example_libraries.stax.Selu->elementwise(selu)
A:jax.example_libraries.stax.Gelu->elementwise(gelu)
A:jax.example_libraries.stax.padding_vals->jax.lax.padtype_to_pads(input_shape, window_shape, strides, padding)
A:jax.example_libraries.stax.out_shape->jax.lax.reduce_window_shape_tuple(input_shape, window_shape, strides, padding_vals, ones, ones)
A:jax.example_libraries.stax.out->jax.lax.reduce_window(inputs, init_val, reducer, window_shape, strides, padding)
A:jax.example_libraries.stax.MaxPool->_pooling_layer(lax.max, -jnp.inf)
A:jax.example_libraries.stax.SumPool->_pooling_layer(lax.add, 0.0)
A:jax.example_libraries.stax.spatial_shape->tuple((inputs.shape[i] for i in range(inputs.ndim) if i not in non_spatial_axes))
A:jax.example_libraries.stax.one->jax.numpy.ones(spatial_shape, dtype=inputs.dtype)
A:jax.example_libraries.stax.window_sizes->jax.numpy.expand_dims(window_sizes, i)
A:jax.example_libraries.stax.AvgPool->_pooling_layer(lax.add, 0.0, _normalize_by_window_size)
A:jax.example_libraries.stax.Flatten->Flatten()
A:jax.example_libraries.stax.Identity->Identity()
A:jax.example_libraries.stax.FanInSum->FanInSum()
A:jax.example_libraries.stax.concat_size->sum((shape[ax] for shape in input_shape))
A:jax.example_libraries.stax.rng->kwargs.pop('rng', None)
A:jax.example_libraries.stax.keep->jax.random.bernoulli(rng, rate, inputs.shape)
A:jax.example_libraries.stax.nlayers->len(layers)
A:jax.example_libraries.stax.(init_funs, apply_funs)->zip(*layers)
A:jax.example_libraries.stax.(rng, layer_rng)->jax.random.split(rng)
A:jax.example_libraries.stax.(input_shape, param)->init_fun(layer_rng, input_shape)
A:jax.example_libraries.stax.inputs->fun(param, inputs, rng=rng, **kwargs)
A:jax.example_libraries.stax.rngs->jax.random.split(rng, nlayers)
jax.example_libraries.stax.BatchNorm(axis=(0,1,2),epsilon=1e-05,center=True,scale=True,beta_init=zeros,gamma_init=ones)
jax.example_libraries.stax.Dense(out_dim,W_init=glorot_normal(),b_init=normal())
jax.example_libraries.stax.Dropout(rate,mode='train')
jax.example_libraries.stax.FanInConcat(axis=-1)
jax.example_libraries.stax.FanInSum()
jax.example_libraries.stax.FanOut(num)
jax.example_libraries.stax.Flatten()
jax.example_libraries.stax.GeneralConv(dimension_numbers,out_chan,filter_shape,strides=None,padding='VALID',W_init=None,b_init=normal(1e-06))
jax.example_libraries.stax.GeneralConvTranspose(dimension_numbers,out_chan,filter_shape,strides=None,padding='VALID',W_init=None,b_init=normal(1e-06))
jax.example_libraries.stax.Identity()
jax.example_libraries.stax._normalize_by_window_size(dims,strides,padding)
jax.example_libraries.stax._pooling_layer(reducer,init_val,rescaler=None)
jax.example_libraries.stax.elementwise(fun,**fun_kwargs)
jax.example_libraries.stax.parallel(*layers)
jax.example_libraries.stax.serial(*layers)
jax.example_libraries.stax.shape_dependent(make_layer)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/image/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/fft.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/ndimage.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/special.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/linalg.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/signal.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/sparse/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/sparse/linalg.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/beta.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/multivariate_normal.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/chi2.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/cauchy.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/bernoulli.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/logistic.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/expon.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/nbinom.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/poisson.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/betabinom.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/t.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/laplace.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/geom.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/pareto.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/norm.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/dirichlet.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/gamma.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/stats/uniform.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/optimize/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/scipy/interpolate/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/lib/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/lib/xla_bridge.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/numpy/__init__.py----------------------------------------
A:jax.numpy.__init__.globals()[name]->jax._src.numpy.lax_numpy._not_implemented(func)
jax.numpy.__init__._init()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/numpy/fft.py----------------------------------------
A:jax.numpy.fft.globals()[name]->jax._src.numpy.lax_numpy._not_implemented(func)
jax.numpy.fft._init()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/numpy/linalg.py----------------------------------------
A:jax.numpy.linalg.globals()[name]->jax._src.numpy.lax_numpy._not_implemented(func)
jax.numpy.linalg._init()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/tools/colab_tpu.py----------------------------------------
jax.tools.colab_tpu.setup_tpu(tpu_driver_version='tpu_driver_nightly')


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/tools/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/tools/jax_to_ir.py----------------------------------------
A:jax.tools.jax_to_ir.fn_curried->functools.partial(fn, **constants)
A:jax.tools.jax_to_ir.comp->jax.xla_computation(ordered_wrapper)(*args)
A:jax.tools.jax_to_ir.serialized_proto->f.get_concrete_function(*args).graph.as_graph_def().SerializeToString()
A:jax.tools.jax_to_ir.debug_txt->str(g)
A:jax.tools.jax_to_ir.f->tensorflow.function(f, autograph=False)
A:jax.tools.jax_to_ir.g->tensorflow.function(f, autograph=False).get_concrete_function(*args).graph.as_graph_def()
A:jax.tools.jax_to_ir.args->tuple((tf.identity(a, name=name) for (a, (name, _)) in zip(args, input_shapes)))
A:jax.tools.jax_to_ir.jax_to_hlo->functools.partial(jax_to_ir, format='HLO')
A:jax.tools.jax_to_ir.jax_to_tf->functools.partial(jax_to_ir, format='TF')
A:jax.tools.jax_to_ir.(module_name, fn_name)->FLAGS.fn.rsplit('.', 1)
A:jax.tools.jax_to_ir.module->importlib.import_module(module_name)
A:jax.tools.jax_to_ir.fn->getattr(module, fn_name)
A:jax.tools.jax_to_ir.v->jax.numpy.asarray(v)
A:jax.tools.jax_to_ir.(ir, debug_ir)->jax_to_ir(fn, input_shapes, constants=constants, format=FLAGS.ir_format)
A:jax.tools.jax_to_ir.match->re.compile(f"^({'|'.join(_DT)})\\[\\s*(\\d*[\\s*,\\d+]*)\\s*\\]$").match(s)
A:jax.tools.jax_to_ir.shape->tuple((int(d.strip()) for d in match.group(2).split(',')))
A:jax.tools.jax_to_ir._SHAPE_RE->re.compile(f"^({'|'.join(_DT)})\\[\\s*(\\d*[\\s*,\\d+]*)\\s*\\]$")
jax.tools.jax_to_ir.jax_to_ir(fn,input_shapes,*,constants=None,format)
jax.tools.jax_to_ir.main(argv)
jax.tools.jax_to_ir.parse_shape_str(s)
jax.tools.jax_to_ir.set_up_flags()
jax.tools.jax_to_ir.tf_wrap_with_input_names(f,input_shapes)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/nn/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/nn/initializers.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/iree.py----------------------------------------
A:jax._src.iree.self._npy_value->numpy.asarray(npy_value)
A:jax._src.iree.outputs->self.module_object[self.function_name](*inputs)
A:jax._src.iree.self.iree_config->iree.runtime.system_api.Config(runtime_driver)
A:jax._src.iree.iree_binary->iree.compiler.compile_str(computation, target_backends=['dylib'], input_type='mhlo')
A:jax._src.iree.vm_module->iree.runtime.binding.VmModule.from_flatbuffer(iree_binary)
A:jax._src.iree.module_object->iree.runtime.load_vm_module(vm_module, self.iree_config)
jax._src.iree.IreeBuffer(self,client,device,npy_value)
jax._src.iree.IreeBuffer.__init__(self,client,device,npy_value)
jax._src.iree.IreeBuffer.copy_to_device(self,device)
jax._src.iree.IreeBuffer.device(self)
jax._src.iree.IreeBuffer.platform(self)
jax._src.iree.IreeBuffer.to_iree(self)
jax._src.iree.IreeBuffer.to_py(self)->np.ndarray
jax._src.iree.IreeClient(self,*,compile_target_backends:Sequence[str]=('cpu',),runtime_driver:str='dylib')
jax._src.iree.IreeClient.__init__(self,*,compile_target_backends:Sequence[str]=('cpu',),runtime_driver:str='dylib')
jax._src.iree.IreeClient.buffer_from_pyval(self,argument:Any,device:IreeDevice,force_copy:bool=True,host_buffer_semantics:xla_client.HostBufferSemantics=xla_client.HostBufferSemantics.ZERO_COPY)->IreeBuffer
jax._src.iree.IreeClient.compile(self,computation:str,compile_options:xla_client.CompileOptions)->IreeExecutable
jax._src.iree.IreeClient.device_count(self)->int
jax._src.iree.IreeClient.devices(self)->List[IreeDevice]
jax._src.iree.IreeClient.get_default_device_assignment(self,num_replicas:int)->List[IreeDevice]
jax._src.iree.IreeClient.local_device_count(self)->int
jax._src.iree.IreeClient.local_devices(self)->List[IreeDevice]
jax._src.iree.IreeClient.process_index(self)->int
jax._src.iree.IreeDevice(self,client)
jax._src.iree.IreeDevice.__init__(self,client)
jax._src.iree.IreeDevice.__str__(self)->str
jax._src.iree.IreeDevice.live_buffers(self)->List['IreeBuffer']
jax._src.iree.IreeDevice.transfer_from_outfeed(self,shape:xla_client.Shape)
jax._src.iree.IreeDevice.transfer_to_infeed(self,literal:Any)
jax._src.iree.IreeExecutable(self,client,devices,module_object,function_name)
jax._src.iree.IreeExecutable.__init__(self,client,devices,module_object,function_name)
jax._src.iree.IreeExecutable.execute(self,arguments:Sequence[IreeBuffer])->List[IreeBuffer]
jax._src.iree.IreeExecutable.local_devices(self)->List[IreeDevice]
jax._src.iree.iree_client_factory()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/ad_checkpoint.py----------------------------------------
A:jax._src.ad_checkpoint.name_p->jax.core.Primitive('name')
A:jax._src.ad_checkpoint.names_not_to_save->frozenset(names_not_to_save)
A:jax._src.ad_checkpoint.names_which_can_be_saved->set(names_which_can_be_saved)
A:jax._src.ad_checkpoint.checkpoint_policies->types.SimpleNamespace(everything_saveable=everything_saveable, nothing_saveable=nothing_saveable, checkpoint_dots=checkpoint_dots, checkpoint_dots_with_no_batch_dims=dot_with_no_batch_dims, save_any_names_but_these=save_any_names_but_these, save_only_these_names=save_only_these_names)
A:jax._src.ad_checkpoint.(args_flat, in_tree)->tree_flatten((args, kwargs))
A:jax._src.ad_checkpoint.(flat_fun, out_tree)->flatten_fun(lu.wrap_init(fun), in_tree)
A:jax._src.ad_checkpoint.debug->jax.interpreters.partial_eval.debug_info(fun, in_tree, False, 'checkpoint')
A:jax._src.ad_checkpoint.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(flat_fun, in_avals, debug)
A:jax._src.ad_checkpoint.out_flat->jax.core.Primitive('remat2').bind(*consts, *args_flat, jaxpr=pe.convert_constvars_jaxpr(jaxpr), prevent_cse=prevent_cse, differentiated=False, policy=policy)
A:jax._src.ad_checkpoint.(args, in_tree)->tree_flatten((args, kwargs))
A:jax._src.ad_checkpoint.(args, kwargs)->tree_unflatten(in_tree, args)
A:jax._src.ad_checkpoint.src->jax._src.source_info_util.summarize(eqn.source_info)
A:jax._src.ad_checkpoint.remat_p->jax.core.Primitive('remat2')
A:jax._src.ad_checkpoint.jaxpr_->jax.core.ClosedJaxpr(jaxpr, ())
A:jax._src.ad_checkpoint.(jaxpr_jvp_, out_nonzeros)->jax.interpreters.ad.jvp_jaxpr(jaxpr_, in_nonzeros, False)
A:jax._src.ad_checkpoint.jaxpr_jvp->jax.interpreters.partial_eval.convert_constvars_jaxpr(jaxpr_jvp_.jaxpr)
A:jax._src.ad_checkpoint.outs->jax.core.Primitive('remat2').bind(*jaxpr_jvp_.consts, *primals, *nonzero_tangents, jaxpr=jaxpr_jvp, prevent_cse=prevent_cse, differentiated=differentiated, policy=policy)
A:jax._src.ad_checkpoint.(out_primals, out_tangents_)->split_list(outs, [len(jaxpr.outvars)])
A:jax._src.ad_checkpoint.out_tangents_->iter(out_tangents_)
A:jax._src.ad_checkpoint.(jaxpr_known, jaxpr_unknown, out_unknowns, out_inst, _)->jax.interpreters.partial_eval._partial_eval_jaxpr_custom(jaxpr, in_unknowns, policy)
A:jax._src.ad_checkpoint.(jaxpr_known, in_used_known)->jax.interpreters.partial_eval.dce_jaxpr(jaxpr_known, [True] * len(jaxpr_known.outvars))
A:jax._src.ad_checkpoint.(_, used_outs_unknown)->partition_list(out_inst, out_unknowns)
A:jax._src.ad_checkpoint.(jaxpr_unknown, in_used_unknown)->jax.interpreters.partial_eval.dce_jaxpr(jaxpr_unknown, used_outs_unknown)
A:jax._src.ad_checkpoint.(_, in_consts_)->unzip2((t.pval for t in tracers if t.pval.is_known()))
A:jax._src.ad_checkpoint.(_, in_consts)->partition_list(in_used_known, in_consts_)
A:jax._src.ad_checkpoint.out_consts->jax.core.eval_jaxpr(jaxpr_known, (), *in_consts)
A:jax._src.ad_checkpoint.out_consts_->iter(out_consts)
A:jax._src.ad_checkpoint.residuals->list(out_consts_)
A:jax._src.ad_checkpoint.res_tracers->map(trace.new_instantiated_const, residuals)
A:jax._src.ad_checkpoint.(_, in_jaxpr_tracers)->partition_list(in_used_unknown, in_jaxpr_tracers)
A:jax._src.ad_checkpoint.new_params->dict(params, jaxpr=jaxpr_unknown, differentiated=True)
A:jax._src.ad_checkpoint.recipe->jax.interpreters.partial_eval.new_eqn_recipe(in_jaxpr_tracers, out_jaxpr_tracers, remat_p, new_params, jaxpr_unknown.effects, source_info_util.current())
A:jax._src.ad_checkpoint.pe.partial_eval_jaxpr_custom_rules[remat_p]->partial(pe.call_partial_eval_custom_rule, 'jaxpr', remat_partial_eval_custom_params_updater)
A:jax._src.ad_checkpoint.(in_primals, out_cts)->tree_unflatten(treedef, args)
A:jax._src.ad_checkpoint.primal_fun->jax.linear_util.wrap_init(partial(core.eval_jaxpr, jaxpr, ()))
A:jax._src.ad_checkpoint.(tangent_jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr(primal_fun, in_pvals, False)
A:jax._src.ad_checkpoint.in_cts_->jax.interpreters.ad.backward_pass(tangent_jaxpr, reduce_axes, False, consts, dummy_args, out_cts)
A:jax._src.ad_checkpoint.(in_cts, cell.treedef)->tree_flatten(in_cts_)
A:jax._src.ad_checkpoint.(args, treedef)->tree_flatten((in_primals, out_cts))
A:jax._src.ad_checkpoint.(transposed_jaxpr_, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(transposed, in_avals)
A:jax._src.ad_checkpoint.transposed_jaxpr->jax.interpreters.partial_eval.convert_constvars_jaxpr(transposed_jaxpr_)
A:jax._src.ad_checkpoint.in_cts->jax.core.Primitive('remat2').bind(*consts, *args, jaxpr=transposed_jaxpr, **params)
A:jax._src.ad_checkpoint.(jaxpr_batched_, out_batched)->jax.interpreters.batching.batch_jaxpr(jaxpr_, axis_size, in_batched, instantiate=False, axis_name=axis_name, main_type=main_type)
jax._src.ad_checkpoint.checkpoint(fun:Callable,prevent_cse:bool=True,policy:Optional[Callable[...,bool]]=None)->Callable
jax._src.ad_checkpoint.checkpoint_dots(prim,*_,**__)->bool
jax._src.ad_checkpoint.checkpoint_name(x,name)
jax._src.ad_checkpoint.dot_with_no_batch_dims(prim,*_,**params)->bool
jax._src.ad_checkpoint.everything_saveable(*_,**__)->bool
jax._src.ad_checkpoint.name_batcher(args,dims,*,name)
jax._src.ad_checkpoint.name_jvp(primals,tangents,*,name)
jax._src.ad_checkpoint.nothing_saveable(*_,**__)->bool
jax._src.ad_checkpoint.print_saved_residuals(f,*args,**kwargs)
jax._src.ad_checkpoint.remat_abstract_eval(*args,jaxpr,prevent_cse,differentiated,policy)
jax._src.ad_checkpoint.remat_impl(*args,jaxpr,prevent_cse,differentiated,policy)
jax._src.ad_checkpoint.remat_jvp(primals,tangents,jaxpr,prevent_cse,differentiated,policy)
jax._src.ad_checkpoint.remat_partial_eval(trace,*tracers,jaxpr,**params)
jax._src.ad_checkpoint.remat_partial_eval_custom_params_updater(_,__,___,____,params_known,params_staged)
jax._src.ad_checkpoint.remat_transpose(reduce_axes,out_cts,*in_primals,jaxpr,**params)
jax._src.ad_checkpoint.remat_vmap(axis_size,axis_name,main_type,args,dims,*,jaxpr,**params)
jax._src.ad_checkpoint.save_any_names_but_these(*names_not_to_save)
jax._src.ad_checkpoint.save_only_these_names(*names_which_can_be_saved)
jax._src.ad_checkpoint.saved_residuals(f,*args,**kwargs)->List[Tuple[core.AbstractValue, str]]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/stages.py----------------------------------------
A:jax._src.stages.donate_argnums->frozenset(donate_argnums)
A:jax._src.stages.(flat_avals, _)->jax.tree_util.tree_flatten(in_avals)
A:jax._src.stages.kws->', '.join(kwargs.keys())
A:jax._src.stages.(args_flat, in_tree)->jax.tree_util.tree_flatten((args, kwargs))
A:jax._src.stages.out_flat->self._executable.call(*args_flat)
jax._src.stages.ArgInfo
jax._src.stages.Compiled(self,executable,args_info,out_tree,no_kwargs=False)
jax._src.stages.Compiled.__init__(self,executable,args_info,out_tree,no_kwargs=False)
jax._src.stages.Compiled._xla_executable(self)
jax._src.stages.Compiled.compiler_ir(self)
jax._src.stages.Compiled.runtime_executable(self)
jax._src.stages.Computation(Protocol)
jax._src.stages.Computation.compile(self)->Executable
jax._src.stages.Computation.hlo(self)->Any
jax._src.stages.Computation.mhlo(self)->Any
jax._src.stages.Executable(Protocol)
jax._src.stages.Executable.call(*args_flat)->Sequence[Any]
jax._src.stages.Executable.hlo_modules(self)->Sequence[Any]
jax._src.stages.Executable.runtime_executable(self)->Any
jax._src.stages.Lowered(self,lowering:Computation,args_info,out_tree:tree_util.PyTreeDef,no_kwargs:bool=False)
jax._src.stages.Lowered.__init__(self,lowering:Computation,args_info,out_tree:tree_util.PyTreeDef,no_kwargs:bool=False)
jax._src.stages.Lowered._xla_computation(self)
jax._src.stages.Lowered.compile(self)->Compiled
jax._src.stages.Lowered.compiler_ir(self,dialect:Optional[str]=None)
jax._src.stages.Lowered.from_flat_info(lowering:Computation,in_tree:tree_util.PyTreeDef,in_avals,donate_argnums:Tuple[int],out_tree:tree_util.PyTreeDef,no_kwargs:bool=False)
jax._src.stages.Stage
jax._src.stages.Stage.donate_argnums(self)
jax._src.stages.Stage.in_avals(self)
jax._src.stages.Stage.in_tree(self)
jax._src.stages.Wrapped(self,*args,**kwargs)
jax._src.stages.Wrapped.__call__(self,*args,**kwargs)
jax._src.stages.Wrapped.lower(self,*args,**kwargs)->Lowered
jax._src.stages.make_args_info(in_tree,in_avals,donate_argnums)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/api_util.py----------------------------------------
A:jax._src.api_util.(py_args, py_kwargs)->tree_unflatten(in_tree, args_flat)
A:jax._src.api_util.(args, in_tree)->tree_flatten(py_args)
A:jax._src.api_util.ans->fun(*args)
A:jax._src.api_util.py_args->tree_unflatten(in_tree, args_flat)
A:jax._src.api_util.(ans_flat, ans_tree)->tree_flatten(ans)
A:jax._src.api_util.(aux_flat, aux_tree)->tree_flatten(aux)
A:jax._src.api_util.dyn_argnums->tuple((i for i in range(len(args)) if i not in static_argnums))
A:jax._src.api_util.fixed_args[i]->_HashableWithStrictTypeEquality(static_arg)
A:jax._src.api_util.dyn_args->tuple((args[i] for i in dyn_argnums))
A:jax._src.api_util.fixed_kwargs[k]->Hashable(arg)
A:jax._src.api_util.donate->bool(i in donate_argnums)
A:jax._src.api_util.static_argnums->sorted(set(static_argnums))
A:jax._src.api_util.donate_argnums->sorted(set(donate_argnums))
A:jax._src.api_util.proxy->object()
A:jax._src.api_util.dummy->tree_unflatten(treedef, [object()] * treedef.num_leaves)
A:jax._src.api_util.(treedef, leaf)->treedef_children(treedef)
A:jax._src.api_util.weak_type->getattr(x, 'weak_type', False)
A:jax._src.api_util.named_shape->getattr(x, 'named_shape', {})
jax._src.api_util._HashableWithStrictTypeEquality(self,val)
jax._src.api_util._HashableWithStrictTypeEquality.__eq__(self,other)
jax._src.api_util._HashableWithStrictTypeEquality.__hash__(self)
jax._src.api_util._HashableWithStrictTypeEquality.__init__(self,val)
jax._src.api_util._argnames_partial(fixed_kwargs:WrapKwArgs,*args,**dyn_kwargs)
jax._src.api_util._argnums_partial(dyn_argnums,fixed_args,*dyn_args,**kwargs)
jax._src.api_util._dtype(x)
jax._src.api_util._ensure_index(x:Any)->Union[int, Tuple[int, ...]]
jax._src.api_util._ensure_index_tuple(x:Any)->Tuple[int, ...]
jax._src.api_util._ensure_str(x:str)->str
jax._src.api_util._ensure_str_tuple(x:Union[str,Iterable[str]])->Tuple[str, ...]
jax._src.api_util.api_hook(fun,tag:str)
jax._src.api_util.apply_flat_fun(fun,io_tree,*py_args)
jax._src.api_util.apply_flat_fun_nokwargs(fun,io_tree,py_args)
jax._src.api_util.argnames_partial_except(f:lu.WrappedFun,static_argnames:Tuple[str,...],kwargs:Dict[str,Any])
jax._src.api_util.argnums_partial(f,dyn_argnums,args,require_static_args_hashable=True)
jax._src.api_util.argnums_partial_except(f:lu.WrappedFun,static_argnums:Tuple[int,...],args:Tuple[Any],*,allow_invalid:bool)
jax._src.api_util.donation_vector(donate_argnums,args,kwargs)->Tuple[bool, ...]
jax._src.api_util.flatten_axes(name,treedef,axis_tree,*,kws=False,tupled_args=False)
jax._src.api_util.flatten_fun(in_tree,*args_flat)
jax._src.api_util.flatten_fun_nokwargs(in_tree,*args_flat)
jax._src.api_util.flatten_fun_nokwargs2(in_tree,*args_flat)
jax._src.api_util.flattened_fun_in_tree(fn:lu.WrappedFun)->Optional[Tuple[PyTreeDef, bool]]
jax._src.api_util.is_hashable(arg)
jax._src.api_util.rebase_donate_argnums(donate_argnums,static_argnums)->Tuple[int, ...]
jax._src.api_util.shaped_abstractify(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/device_array.py----------------------------------------
A:jax._src.device_array._forward_to_value->partial(_forward_method, '_value')
A:jax._src.device_array.device_buffer->device_buffer.clone().clone()
A:jax._src.device_array.type_x->type(x)
A:jax._src.device_array.self._npy_value->self.device_buffer.to_py()
A:jax._src.device_array.prefix->'{}('.format(self.__class__.__name__.lstrip('_'))
A:jax._src.device_array.s->numpy.array2string(self._value, prefix=prefix, suffix=',', separator=', ', max_line_width=line_width)
A:jax._src.device_array.deleted_buffer->DeletedBuffer()
jax._src.device_array.DeletedBuffer(object)
jax._src.device_array._DeviceArray(self,aval:core.ShapedArray,device:Optional[Device],device_buffer:Buffer)
jax._src.device_array._DeviceArray.__cuda_array_interface__(self)
jax._src.device_array._DeviceArray.__init__(self,aval:core.ShapedArray,device:Optional[Device],device_buffer:Buffer)
jax._src.device_array._DeviceArray._check_if_deleted(self)
jax._src.device_array._DeviceArray._value(self)
jax._src.device_array._DeviceArray.block_until_ready(self)
jax._src.device_array._DeviceArray.copy_to_host_async(self)
jax._src.device_array._DeviceArray.delete(self)
jax._src.device_array._DeviceArray.device(self)
jax._src.device_array._DeviceArray.dtype(self)
jax._src.device_array._DeviceArray.ndim(self)
jax._src.device_array._DeviceArray.shape(self)
jax._src.device_array._DeviceArray.size(self)
jax._src.device_array._forward_method(attrname,self,fun,*args)
jax._src.device_array.device_array_supports_weakrefs()
jax._src.device_array.make_device_array(aval:core.ShapedArray,device:Optional[Device],device_buffer:Buffer)->Union[Buffer, '_DeviceArray']
jax._src.device_array.type_is_device_array(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/dispatch.py----------------------------------------
A:jax._src.dispatch.aval->jax.interpreters.xla.abstractify(x)
A:jax._src.dispatch.compiled_fun->_xla_callable(fun, device, backend, name, donated_invars, *arg_specs)
A:jax._src.dispatch.(avals, arg_devices)->jax._src.util.unzip2(arg_specs)
A:jax._src.dispatch.device->_xla_callable_device(nreps, backend, device, arg_devices)
A:jax._src.dispatch.out->compiled_fun(*args)
A:jax._src.dispatch.compiled->compile_or_get_cached(backend, xla_computation, options)
A:jax._src.dispatch.arg_specs->unsafe_map(arg_spec, args)
A:jax._src.dispatch.clone->jax.linear_util.WrappedFun(fun.f, fun.transforms, stores, fun.params, fun.in_type)
A:jax._src.dispatch._->jax.linear_util.WrappedFun(fun.f, fun.transforms, stores, fun.params, fun.in_type).call_wrapped(*args)
A:jax._src.dispatch._xla_callable->jax.linear_util.cache(_xla_callable_uncached)
A:jax._src.dispatch.start_time->time.time()
A:jax._src.dispatch.(abstract_args, arg_devices)->jax._src.util.unzip2([a for (i, a) in enumerate(arg_specs) if i in kept_var_idx])
A:jax._src.dispatch.(abstract_args, which_explicit)->jax._src.util.unzip2(fun.in_type)
A:jax._src.dispatch.(jaxpr, out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_final(fun, abstract_args, pe.debug_info_final(fun, 'jit'), which_explicit)
A:jax._src.dispatch.(jaxpr, kept_const_idx, kept_var_idx)->_prune_unused_inputs(jaxpr)
A:jax._src.dispatch.kept_var_idx->set(range(len(abstract_args)))
A:jax._src.dispatch.jaxpr->apply_outfeed_rewriter(jaxpr)
A:jax._src.dispatch.nreps->jaxpr_replicas(jaxpr)
A:jax._src.dispatch.(jaxpr, consts)->jax.interpreters.partial_eval.pad_jaxpr(jaxpr, consts)
A:jax._src.dispatch.axis_env->jax.interpreters.xla.AxisEnv(nreps, (), ())
A:jax._src.dispatch.name_stack->jax.interpreters.xla.new_name_stack(xla.wrap_name(name, 'jit'))
A:jax._src.dispatch.closed_jaxpr->jax.core.ClosedJaxpr(jaxpr, consts)
A:jax._src.dispatch.module->jax.interpreters.mlir.lower_jaxpr_to_module(module_name, closed_jaxpr, backend.platform, mlir.ReplicaAxisContext(axis_env), name_stack, donated_invars)
A:jax._src.dispatch.(kept_const_idx, new_constvars)->jax._src.util.unzip2(((i, v) for (i, v) in enumerate(jaxpr.constvars) if v in used))
A:jax._src.dispatch.(kept_var_idx, new_invars)->jax._src.util.unzip2(((i, v) for (i, v) in enumerate(jaxpr.invars) if v in used))
A:jax._src.dispatch.new_jaxpr->jax.core.Jaxpr(new_constvars, new_invars, jaxpr.outvars, jaxpr.eqns, jaxpr.effects)
A:jax._src.dispatch.call_jaxpr->eqn.params.get('call_jaxpr')
A:jax._src.dispatch.needs_padding->any((type(in_avals[d.val]) is core.AbstractBInt for a in in_avals if type(a) is core.DShapedArray for d in a.shape if type(d) is pe.DBIdx))
A:jax._src.dispatch.explicit_args_->iter(explicit_args)
A:jax._src.dispatch.zeros->jax.lax.full(shape, 0, x.dtype)
A:jax._src.dispatch.(device,)->compile_or_get_cached(backend, xla_computation, options).local_devices()
A:jax._src.dispatch.input_bufs_flat->flatten((device_put(x, device) for (i, x) in enumerate(args) if i in kept_var_idx))
A:jax._src.dispatch.out_bufs_flat->compile_or_get_cached(backend, xla_computation, options).execute(input_bufs_flat)
A:jax._src.dispatch.out_bufs->unflatten(out_bufs_flat, output_buffer_counts)
A:jax._src.dispatch.input_bufs_flip->list(unsafe_zip(*input_bufs))
A:jax._src.dispatch.out_bufs_flat_rep->compile_or_get_cached(backend, xla_computation, options).execute_sharded_on_local_devices(input_bufs_flip)
A:jax._src.dispatch.module_str->xe.mlir.xla_computation_to_mlir_module(self._hlo)
A:jax._src.dispatch.self._executable->XlaCompiledComputation.from_xla_computation(self.name, self._hlo, self._explicit_args, **self.compile_args)
A:jax._src.dispatch._ir_dump_counter->itertools.count()
A:jax._src.dispatch.id->next(_ir_dump_counter)
A:jax._src.dispatch.name->os.path.join(FLAGS.jax_dump_ir_to, name)
A:jax._src.dispatch.computation->jax.interpreters.mlir.module_to_string(computation)
A:jax._src.dispatch.module_name->jax.interpreters.mlir.module_to_string(computation).name()
A:jax._src.dispatch.cached_executable->jax.experimental.compilation_cache.compilation_cache.get_executable(computation, compile_options, backend)
A:jax._src.dispatch.input_handler->_input_handler(explicit_args, in_avals)
A:jax._src.dispatch.result_handlers->map(partial(aval_to_result_handler, device), out_avals)
A:jax._src.dispatch.options->jax._src.lib.xla_bridge.get_compile_options(num_replicas=nreps, num_partitions=1, device_assignment=(sticky_device,) if sticky_device else None)
A:jax._src.dispatch.unsafe_call->partial(_execute_trivial, jaxpr, device, consts, out_avals, result_handlers, kept_var_idx)
A:jax._src.dispatch.ref_avals_fmt->', '.join((str(a) for a in ref_avals))
A:jax._src.dispatch.arg_avals_fmt->', '.join((str(a) for a in arg_avals))
A:jax._src.dispatch.x->_copy_device_array_to_device(x, device)
A:jax._src.dispatch.backend->jax._src.lib.xla_bridge.get_device_backend(device)
A:jax._src.dispatch._scalar_types->jax._src.dtypes.python_scalar_dtypes.keys()
A:jax._src.dispatch.moved_buf->jax._src.lib.xla_bridge.get_device_backend(device).buffer_from_pyval(x.device_buffer.to_py(), device)
A:jax._src.dispatch.a->jax.interpreters.xla.abstractify(x)
A:jax._src.dispatch.device_put_p->jax.core.Primitive('device_put')
jax._src.dispatch.XlaCompiledComputation(self,xla_executable,in_avals,kept_var_idx,unsafe_call)
jax._src.dispatch.XlaCompiledComputation.__init__(self,xla_executable,in_avals,kept_var_idx,unsafe_call)
jax._src.dispatch.XlaCompiledComputation.call(self,*args)
jax._src.dispatch.XlaCompiledComputation.from_trivial_jaxpr(jaxpr,consts,device,in_avals,out_avals,kept_var_idx)->XlaCompiledComputation
jax._src.dispatch.XlaCompiledComputation.from_xla_computation(name:str,xla_computation:Optional[ir.Module],explicit_args:Optional[Sequence[bool]],nreps:int,device:Optional[Device],backend:Backend,tuple_args:bool,in_avals:Sequence[core.AbstractValue],out_avals:Sequence[core.AbstractValue],kept_var_idx:Set[int])->XlaCompiledComputation
jax._src.dispatch.XlaCompiledComputation.hlo_modules(self)
jax._src.dispatch.XlaCompiledComputation.is_trivial(self)
jax._src.dispatch.XlaCompiledComputation.runtime_executable(self)
jax._src.dispatch.XlaCompiledComputation.xla_executable(self)
jax._src.dispatch.XlaComputation(self,name:str,hlo,is_trivial:bool,donated_invars:Optional[Sequence[bool]],explicit_args:Optional[Sequence[bool]],**compile_args)
jax._src.dispatch.XlaComputation.__init__(self,name:str,hlo,is_trivial:bool,donated_invars:Optional[Sequence[bool]],explicit_args:Optional[Sequence[bool]],**compile_args)
jax._src.dispatch.XlaComputation.compile(self)->XlaCompiledComputation
jax._src.dispatch.XlaComputation.hlo(self)->xc.XlaComputation
jax._src.dispatch.XlaComputation.is_trivial(self)
jax._src.dispatch.XlaComputation.mhlo(self)->ir.Module
jax._src.dispatch._check_special(name,xla_shape,buf)
jax._src.dispatch._copy_device_array_to_device(x:Union[device_array.DeviceArrayProtocol,device_array._DeviceArray],device:Optional[xc.Device])->Union[device_array.DeviceArrayProtocol, device_array._DeviceArray]
jax._src.dispatch._device_from_arg_devices(devices:Sequence[Optional[Device]])->Optional[Device]
jax._src.dispatch._device_put_array(x,device:Optional[Device])
jax._src.dispatch._device_put_device_array(x:Union[device_array.DeviceArrayProtocol,device_array._DeviceArray],device:Optional[Device])
jax._src.dispatch._device_put_impl(x,device:Optional[Device]=None)
jax._src.dispatch._device_put_lowering(ctx,x,*,device)
jax._src.dispatch._device_put_scalar(x,device)
jax._src.dispatch._device_put_token(_,device)
jax._src.dispatch._device_put_unit(_,device)
jax._src.dispatch._dump_ir_to_file(name:str,ir:str)
jax._src.dispatch._execute_compiled(name:str,compiled:XlaExecutable,input_handler:Optional[Callable],output_buffer_counts:Optional[Sequence[int]],result_handlers,kept_var_idx,*args)
jax._src.dispatch._execute_replicated(name:str,compiled:XlaExecutable,input_handler:Optional[Callable],output_buffer_counts:Optional[Sequence[int]],result_handlers,kept_var_idx,*args)
jax._src.dispatch._execute_trivial(jaxpr,device:Optional[Device],consts,avals,handlers,kept_var_idx,*args)
jax._src.dispatch._input_handler(which_explicit:Optional[Sequence[bool]],in_avals:Sequence[core.AbstractValue])->Optional[Callable]
jax._src.dispatch._make_string_safe_for_filename(s:str)->str
jax._src.dispatch._pad_arg(shape,x)
jax._src.dispatch._prune_unused_inputs(jaxpr:core.Jaxpr)->Tuple[core.Jaxpr, Set[int], Set[int]]
jax._src.dispatch._xla_call_impl(fun:lu.WrappedFun,*args,device,backend,name,donated_invars,inline)
jax._src.dispatch._xla_callable_device(nreps,backend,device,arg_devices)
jax._src.dispatch._xla_callable_uncached(fun:lu.WrappedFun,device,backend,name,donated_invars,*arg_specs)
jax._src.dispatch.apply_outfeed_rewriter(jaxpr:core.Jaxpr)->core.Jaxpr
jax._src.dispatch.apply_primitive(prim,*args,**params)
jax._src.dispatch.arg_spec(x:Any)->ArgSpec
jax._src.dispatch.array_result_handler(sticky_device:Optional[Device],aval:core.ShapedArray)
jax._src.dispatch.aval_to_num_buffers(aval:core.AbstractValue)->int
jax._src.dispatch.aval_to_result_handler(sticky_device:Optional[Device],aval:core.AbstractValue)->ResultHandler
jax._src.dispatch.backend_compile(backend,built_c,options)
jax._src.dispatch.check_arg_avals_for_call(ref_avals,arg_avals)
jax._src.dispatch.check_special(name,bufs)
jax._src.dispatch.compile_or_get_cached(backend,computation,compile_options)
jax._src.dispatch.device_put(x,device:Optional[Device]=None)->Tuple[Any]
jax._src.dispatch.dynamic_array_result_handler(sticky_device:Optional[Device],aval:core.DShapedArray)
jax._src.dispatch.eqn_replicas(eqn)
jax._src.dispatch.initial_style_primitive_replicas(params)
jax._src.dispatch.jaxpr_has_bints(jaxpr:core.Jaxpr)->bool
jax._src.dispatch.jaxpr_has_pmap(jaxpr)
jax._src.dispatch.jaxpr_literals(jaxpr)
jax._src.dispatch.jaxpr_replicas(jaxpr)->int
jax._src.dispatch.log_elapsed_time(fmt:str)
jax._src.dispatch.lower_xla_callable(fun:lu.WrappedFun,device,backend,name,donated_invars,*arg_specs)
jax._src.dispatch.needs_check_special()
jax._src.dispatch.prefetch(x)
jax._src.dispatch.xla_primitive_callable(prim,*arg_specs:ArgSpec,**params)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/traceback_util.py----------------------------------------
A:jax._src.traceback_util.C->TypeVar('C', bound=Callable[..., Any])
A:jax._src.traceback_util.path->os.path.abspath(path)
A:jax._src.traceback_util.path_prefix->os.path.abspath(path_prefix)
A:jax._src.traceback_util.common->os.path.commonpath([path, path_prefix])
A:jax._src.traceback_util.frames->list(traceback.walk_tb(tb))
A:jax._src.traceback_util.out->types.TracebackType(out, f, f.f_lasti, lineno)
A:jax._src.traceback_util.tb->traceback.extract_stack(e.__traceback__.tb_frame)
A:jax._src.traceback_util.mode->filtering_mode()
A:jax._src.traceback_util.filtered_tb->filter_traceback(e.__traceback__)
A:jax._src.traceback_util.msg->format_exception_only(e)
A:jax._src.traceback_util.unfiltered->UnfilteredStackTrace(msg)
jax._src.traceback_util.UnfilteredStackTrace(Exception)
jax._src.traceback_util.add_call_stack_frames(tb)
jax._src.traceback_util.add_tracebackhide_to_hidden_frames(tb)
jax._src.traceback_util.api_boundary(fun:C)->C
jax._src.traceback_util.filter_traceback(tb)
jax._src.traceback_util.filtering_mode()
jax._src.traceback_util.format_exception_only(e)
jax._src.traceback_util.ignore_known_hidden_frame(f)
jax._src.traceback_util.include_frame(f)
jax._src.traceback_util.ipython_supports_tracebackhide()
jax._src.traceback_util.is_reraiser_frame(f)
jax._src.traceback_util.is_under_reraiser(e)
jax._src.traceback_util.path_starts_with(path,path_prefix)
jax._src.traceback_util.register_exclusion(path)
jax._src.traceback_util.running_under_ipython()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/custom_transpose.py----------------------------------------
A:jax._src.custom_transpose.out_store->StoreEqual()
A:jax._src.custom_transpose.flatten_fun_nokwargs->transformation_with_aux(api_util.flatten_fun_nokwargs.args[0])
A:jax._src.custom_transpose.(_, res_tree)->tree_flatten(res_arg)
A:jax._src.custom_transpose.(_, lin_tree)->tree_flatten(lin_arg)
A:jax._src.custom_transpose.(args_flat, in_tree)->tree_flatten((res_arg, lin_arg))
A:jax._src.custom_transpose.(flat_fun, out_tree2)->flatten_fun_nokwargs(lu.wrap_init(self.fun), in_tree)
A:jax._src.custom_transpose.(out_types_flat, out_tree)->tree_flatten(out_types)
A:jax._src.custom_transpose.out_flat->CustomTransposePrimitive('custom_transpose_call').bind(flat_fun, *args_flat, transpose=self.transpose, out_types=out_types_flat, lin_tree=lin_tree, res_tree=res_tree, out_tree=out_tree)
A:jax._src.custom_transpose.full_tree->tree_fill(0, full_treedef)
A:jax._src.custom_transpose.entire->tree_fill(0, entire)
A:jax._src.custom_transpose.prefix->tree_fill(0, prefix)
A:jax._src.custom_transpose.(transpose_jaxpr, transpose_consts)->thunk()
A:jax._src.custom_transpose.transpose_jaxpr->jax.core.ClosedJaxpr(pe.convert_constvars_jaxpr(transpose_jaxpr), ())
A:jax._src.custom_transpose.args_flat->tree_leaves((res_arg, ct_out))
A:jax._src.custom_transpose.ct_ins->jax.core.jaxpr_as_fun(transpose_jaxpr)(*transpose_consts, *args_flat)
A:jax._src.custom_transpose.top_trace->jax.core.find_top_trace(args)
A:jax._src.custom_transpose.tracers->map(top_trace.full_raise, args)
A:jax._src.custom_transpose.outs->jax.core.find_top_trace(args).process_custom_transpose(self, call, tracers, **params)
A:jax._src.custom_transpose.new_params->dict(params)
A:jax._src.custom_transpose.new_params['transpose']->make_transpose_from_thunk(new_params.pop('transpose_jaxpr_thunk'), new_params['lin_tree'])
A:jax._src.custom_transpose.call->jax.linear_util.wrap_init(core.jaxpr_as_fun(new_params.pop('call_jaxpr')))
A:jax._src.custom_transpose.transpose->make_transpose_from_thunk(params['transpose_jaxpr_thunk'], lin_tree)
A:jax._src.custom_transpose.call_in_tree->treedef_tuple((res_tree, lin_tree))
A:jax._src.custom_transpose.(res_arg, lin_arg)->tree_unflatten(call_in_tree, args)
A:jax._src.custom_transpose.ct_out->tree_unflatten(out_tree, cts)
A:jax._src.custom_transpose.ct_lin->transpose(res_arg, ct_out)
A:jax._src.custom_transpose.(ct_lin_flat, _)->tree_flatten(tree_broadcast(lin_tree, ct_lin, is_leaf=lambda x: x is None), is_leaf=lambda x: x is None)
A:jax._src.custom_transpose.custom_transpose_p->CustomTransposePrimitive('custom_transpose_call')
jax._src.custom_transpose.CustomTransposePrimitive(core.Primitive)
jax._src.custom_transpose.CustomTransposePrimitive.bind(self,call,*args,**params)
jax._src.custom_transpose.CustomTransposePrimitive.get_bind_params(self,params)
jax._src.custom_transpose.StoreEqual(lu.Store)
jax._src.custom_transpose.StoreEqual.store(self,val)
jax._src.custom_transpose.check_transpose_rule_trees(rule,lin_tree,rule_out_tree)
jax._src.custom_transpose.custom_transpose(self,fun:Callable)
jax._src.custom_transpose.custom_transpose.__init__(self,fun:Callable)
jax._src.custom_transpose.custom_transpose.def_transpose(self,transpose:Callable)
jax._src.custom_transpose.custom_transpose_lowering(*args,call_jaxpr,**params)
jax._src.custom_transpose.custom_transpose_transpose_rule(cts,*args,out_types,res_tree,lin_tree,out_tree,**params)
jax._src.custom_transpose.custom_transpose_typecheck(*avals,**params)
jax._src.custom_transpose.is_treedef_prefix(entire,prefix)
jax._src.custom_transpose.make_transpose_from_thunk(thunk,lin_tree)
jax._src.custom_transpose.rule_name(rule)
jax._src.custom_transpose.transformation_with_aux(gen,fun:lu.WrappedFun,*gen_static_args)->Tuple[lu.WrappedFun, Any]
jax._src.custom_transpose.tree_broadcast(full_treedef,tree,is_leaf=None)
jax._src.custom_transpose.tree_fill(x,treedef)
jax._src.custom_transpose.tree_fill_like(x,tree)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/custom_api_util.py----------------------------------------
A:jax._src.custom_api_util._custom_wrapper_types->set()
jax._src.custom_api_util.forward_attr(self_,name)
jax._src.custom_api_util.register_custom_decorator_type(cls)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/flatten_util.py----------------------------------------
A:jax._src.flatten_util.(leaves, treedef)->tree_flatten(pytree)
A:jax._src.flatten_util.(flat, unravel_list)->_ravel_list(leaves)
A:jax._src.flatten_util.to_dtype->jax._src.dtypes.result_type(*from_dtypes)
A:jax._src.flatten_util.(sizes, shapes)->unzip2(((jnp.size(x), jnp.shape(x)) for x in lst))
A:jax._src.flatten_util.indices->numpy.cumsum(sizes)
A:jax._src.flatten_util.chunks->jax.numpy.split(arr, indices[:-1])
A:jax._src.flatten_util.raveled->jax.numpy.concatenate([ravel(e) for e in lst])
A:jax._src.flatten_util.arr_dtype->jax._src.dtypes.dtype(arr)
jax._src.flatten_util._ravel_list(lst)
jax._src.flatten_util.ravel_pytree(pytree)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/source_info_util.py----------------------------------------
A:jax._src.source_info_util.scopes->tuple(map(Scope, name))
A:jax._src.source_info_util.scope->elem.wrap(scope)
A:jax._src.source_info_util.frames->itertools.islice(user_frames(source_info), num_frames)
A:jax._src.source_info_util.self.context->new_source_info()
A:jax._src.source_info_util._source_info_context->_SourceInfoContext()
A:jax._src.source_info_util.source_info->source_info.replace(traceback=xla_client.Traceback.get_traceback()).replace(traceback=xla_client.Traceback.get_traceback())
A:jax._src.source_info_util._source_info_context.context->_SourceInfoContext().context.replace(traceback=c, name_stack=name_stack)
A:jax._src.source_info_util.filtered_tb->jax._src.traceback_util.filter_traceback(c.as_python_traceback())
A:jax._src.source_info_util.msg->jax._src.traceback_util.format_exception_only(e)
A:jax._src.source_info_util.exp->JaxStackTraceBeforeTransformation(msg).with_traceback(filtered_tb)
A:jax._src.source_info_util.new_context->prev_context.replace(name_stack=curr_name_stack.transform(name))
jax._src.source_info_util.Frame(NamedTuple)
jax._src.source_info_util.JaxStackTraceBeforeTransformation(Exception)
jax._src.source_info_util.NameStack
jax._src.source_info_util.NameStack.__add__(self,other:'NameStack')->'NameStack'
jax._src.source_info_util.NameStack.__getitem__(self,idx)->'NameStack'
jax._src.source_info_util.NameStack.__len__(self)
jax._src.source_info_util.NameStack.__radd__(self,other:'NameStack')->'NameStack'
jax._src.source_info_util.NameStack.__str__(self)->str
jax._src.source_info_util.NameStack.extend(self,name:Union[Tuple[str,...],str])->'NameStack'
jax._src.source_info_util.NameStack.transform(self,transform_name:str)->'NameStack'
jax._src.source_info_util.NameStack.wrap_name(self,name:str)->str
jax._src.source_info_util.Scope(NamedTuple)
jax._src.source_info_util.Scope.wrap(self,stack:Tuple[str,...])->Tuple[str, ...]
jax._src.source_info_util.SourceInfo(NamedTuple)
jax._src.source_info_util.SourceInfo.replace(self,*,traceback:Optional[Traceback]=None,name_stack:Optional[NameStack]=None)->'SourceInfo'
jax._src.source_info_util.Transform(NamedTuple)
jax._src.source_info_util.Transform.wrap(self,stack:Tuple[str,...])->Tuple[str, ...]
jax._src.source_info_util._SourceInfoContext(self)
jax._src.source_info_util._SourceInfoContext.__init__(self)
jax._src.source_info_util._raw_frame_to_frame(code:types.CodeType,lasti:int)->Frame
jax._src.source_info_util.current()->SourceInfo
jax._src.source_info_util.current_name_stack()->NameStack
jax._src.source_info_util.extend_name_stack(name:str)->Iterator[NameStack]
jax._src.source_info_util.has_user_context(e)
jax._src.source_info_util.is_user_filename(filename:str)->bool
jax._src.source_info_util.new_source_info()->SourceInfo
jax._src.source_info_util.register_exclusion(path)
jax._src.source_info_util.reset_name_stack()->Iterator[None]
jax._src.source_info_util.set_name_stack(name_stack:NameStack)->Iterator[None]
jax._src.source_info_util.summarize(source_info:SourceInfo,num_frames=1)->str
jax._src.source_info_util.transform_name_stack(name:str)->Iterator[NameStack]
jax._src.source_info_util.user_context(c:Optional[Traceback],*,name_stack:Optional[NameStack]=None)
jax._src.source_info_util.user_frame(source_info:SourceInfo)->Optional[Frame]
jax._src.source_info_util.user_frames(source_info:SourceInfo)->Iterator[Frame]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/dtypes.py----------------------------------------
A:jax._src.dtypes.dtype->_scalar_type_to_dtype(type(x), x)
A:jax._src.dtypes.typ->dtype(x)
A:jax._src.dtypes.smallest_normal->float.fromhex('0x1p-126')
A:jax._src.dtypes.self.smallest_normal->bfloat16(smallest_normal)
A:jax._src.dtypes.tiny->float.fromhex('0x1p-126')
A:jax._src.dtypes.eps->float.fromhex('0x1p-7')
A:jax._src.dtypes.epsneg->float.fromhex('0x1p-8')
A:jax._src.dtypes.max->float.fromhex('0x1.FEp127')
A:jax._src.dtypes.obj->object.__new__(np.finfo)
A:jax._src.dtypes.obj.eps->bfloat16(eps)
A:jax._src.dtypes.obj.epsneg->bfloat16(epsneg)
A:jax._src.dtypes.obj.max->bfloat16(max)
A:jax._src.dtypes.obj.min->bfloat16(-max)
A:jax._src.dtypes.obj.resolution->bfloat16(resolution)
A:jax._src.dtypes.obj._machar->_Bfloat16MachArLike()
A:jax._src.dtypes.obj.tiny->bfloat16(tiny)
A:jax._src.dtypes.obj._str_tiny->float_to_str(tiny)
A:jax._src.dtypes.obj._str_smallest_normal->float_to_str(tiny)
A:jax._src.dtypes.obj._str_max->float_to_str(max)
A:jax._src.dtypes.obj._str_epsneg->float_to_str(epsneg)
A:jax._src.dtypes.obj._str_eps->float_to_str(eps)
A:jax._src.dtypes.obj._str_resolution->float_to_str(resolution)
A:jax._src.dtypes.cls._finfo_cache[_bfloat16_dtype]->cls._bfloat16_finfo()
A:jax._src.dtypes.lattice->_type_promotion_lattice()
A:jax._src.dtypes.new_upper_bounds->set().union(*(lattice[b] for b in upper_bounds[n]))
A:jax._src.dtypes._lattice_upper_bounds->_make_lattice_upper_bounds()
A:jax._src.dtypes.N->set(nodes)
A:jax._src.dtypes.CUB->set.intersection(*(UB[n] for n in N))
A:jax._src.dtypes.dt->numpy.result_type(x)
A:jax._src.dtypes.(dtypes, weak_types)->zip(*(_dtype_and_weaktype(arg) for arg in args))
A:jax._src.dtypes.result_type->_least_upper_bound(*{_jax_type(d, w) for (d, w) in zip(dtypes, weak_types)})
A:jax._src.dtypes.(dtype, weak_type)->_lattice_result_type(*(float_ if arg is None else arg for arg in args))
jax._src.dtypes._Bfloat16MachArLike(self)
jax._src.dtypes._Bfloat16MachArLike.__init__(self)
jax._src.dtypes._canonicalize_dtype(x64_enabled,dtype)
jax._src.dtypes._dtype_and_weaktype(value)
jax._src.dtypes._issubclass(a,b)
jax._src.dtypes._jax_type(dtype,weak_type)
jax._src.dtypes._lattice_result_type(*args)
jax._src.dtypes._least_upper_bound(*nodes)
jax._src.dtypes._make_lattice_upper_bounds()
jax._src.dtypes._scalar_type_to_dtype(typ:type,value:Any=None)
jax._src.dtypes._type_promotion_lattice()
jax._src.dtypes.canonicalize_dtype(dtype)
jax._src.dtypes.coerce_to_array(x,dtype=None)
jax._src.dtypes.dtype(x,*,canonicalize=False)
jax._src.dtypes.finfo(cls,dtype)
jax._src.dtypes.finfo.__new__(cls,dtype)
jax._src.dtypes.finfo._bfloat16_finfo()
jax._src.dtypes.is_python_scalar(x)
jax._src.dtypes.is_weakly_typed(x)
jax._src.dtypes.issubdtype(a,b)
jax._src.dtypes.promote_types(a,b)
jax._src.dtypes.result_type(*args)
jax._src.dtypes.scalar_type_of(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/api.py----------------------------------------
A:jax._src.api._dtype->partial(dtypes.dtype, canonicalize=True)
A:jax._src.api.F->TypeVar('F', bound=Callable)
A:jax._src.api.T->TypeVar('T')
A:jax._src.api.U->TypeVar('U')
A:jax._src.api.leaves->tree_leaves(output)
A:jax._src.api.argnums->_ensure_index(argnums)
A:jax._src.api.argnames->tuple((k for (i, (k, param)) in enumerate(parameters.items()) if param.kind == _POSITIONAL_OR_KEYWORD and i in argnums))
A:jax._src.api.signature->inspect.signature(fun)
A:jax._src.api.f->jax.linear_util.wrap_init(fun)
A:jax._src.api.(f, args)->argnums_partial(f, dyn_argnums, args)
A:jax._src.api.(f, kwargs)->argnames_partial_except(f, static_argnames, kwargs)
A:jax._src.api.(args_flat, in_tree)->tree_flatten((args, kwargs))
A:jax._src.api.donated_invars->donation_vector(donate_tuple, dyn_args, kwargs)
A:jax._src.api.(static_argnums, static_argnames)->_infer_argnums_and_argnames(fun, static_argnums, static_argnames)
A:jax._src.api.static_argnums->_ensure_index_tuple(static_argnums)
A:jax._src.api.donate_argnums->rebase_donate_argnums(donate_argnums, static_argnums)
A:jax._src.api.(closed_fun, in_tree, args_flat, donated_invars)->_prepare_jit(fun, static_argnums, static_argnames, donate_argnums, args, kwargs)
A:jax._src.api.(flat_fun, out_tree)->flatten_fun(lu.wrap_init(fun), in_tree)
A:jax._src.api.in_type->jax.interpreters.partial_eval.infer_lambda_input_type(axes_specs, flat_args)
A:jax._src.api.flat_fun->jax.linear_util.annotate(flat_fun, in_type)
A:jax._src.api.out_flat->jax.core.named_call_p.bind(flat_f, name=name)
A:jax._src.api.f_jitted.lower->_jit_lower(fun, static_argnums, static_argnames, device, backend, donate_argnums, inline)
A:jax._src.api._cpp_jit_cache->jax._src.lib.jax_jit.CompiledFunctionCache()
A:jax._src.api.out_pytree_def->out_tree()
A:jax._src.api.out->jax.interpreters.partial_eval.abstract_eval_fun(wrapped_fun.call_wrapped, *map(shaped_abstractify, args_flat), debug_info=debug_info)
A:jax._src.api.fastpath_data->_PmapFastpathData(version=1, xla_executable=execute_replicated.xla_executable, in_handler=in_handler, out_handler=out_handler, out_pytree_def=out_pytree_def, input_sharding_specs=in_handler.sharding_specs, input_devices=in_handler.local_devices, input_indices=in_handler.input_indices, out_sharding_specs=out_handler.out_specs, out_indices=out_handler.out_indices, out_avals=out_handler.out_avals)
A:jax._src.api.backend_->jax._src.lib.xla_bridge.get_backend(backend)
A:jax._src.api.cpp_jitted_f->jax._src.lib.jax_jit.jit(fun, cache_miss, get_device_info, static_argnums=static_argnums, static_argnames=static_argnames, donate_argnums=donate_argnums, cache=_cpp_jit_cache)
A:jax._src.api.f_jitted->wraps(fun)(cpp_jitted_f)
A:jax._src.api.aval->jax.core.unmapped_aval(len(devices), core.no_axis_name, 0, core.raise_to_shaped(core.get_aval(x)))
A:jax._src.api.arg_specs_and_device->list(unsafe_map(arg_spec, args_flat))
A:jax._src.api.computation->jax.interpreters.pxla.lower_parallel_callable(p.flat_fun, backend, axis_name, axis_size=p.local_axis_size, global_axis_size=axis_size, devices=None if devices is None else tuple(devices), name=p.flat_fun.__name__, in_axes=p.in_axes_flat, out_axes_thunk=p.out_axes_thunk, donated_invars=p.donated_invars, global_arg_shapes=p.global_arg_shapes_flat, avals=abstract_args)
A:jax._src.api.fun_name->getattr(fun, '__name__', 'unknown')
A:jax._src.api.(names, sizes)->unzip2(axis_env)
A:jax._src.api.(f, dyn_args)->argnums_partial(f, dyn_argnums, args)
A:jax._src.api.in_parts_flat->tuple(flatten_axes('xla_computation in_parts', in_tree.children()[0], in_parts))
A:jax._src.api.(jaxtree_fun, out_tree)->flatten_fun(f, in_tree)
A:jax._src.api.avals->map(partial(ShapedArray, dtype=np.float32), in_shapes)
A:jax._src.api.(jaxpr, out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(f, in_avals, keep_inputs=keep_inputs)
A:jax._src.api.jaxpr->jax._src.dispatch.apply_outfeed_rewriter(jaxpr)
A:jax._src.api.axis_env_->make_axis_env(dispatch.jaxpr_replicas(jaxpr))
A:jax._src.api.out_parts_flat->tuple(flatten_axes('xla_computation out_parts', out_tree(), out_parts))
A:jax._src.api.c->jax._src.lib.xla_client.XlaBuilder(f'xla_computation_{fun_name}')
A:jax._src.api.xla_consts->map(partial(xla.pyval_to_ir_constant, c), consts)
A:jax._src.api.(xla_args, donated_invars)->jax.interpreters.xla._xla_callable_args(c, avals, should_tuple, partitions=in_parts_flat, donated_invars=donated_invars)
A:jax._src.api.name_stack->new_name_stack(wrap_name(fun_name, 'xla_computation'))
A:jax._src.api.ctx->jax.interpreters.xla.TranslationContext(c, backend, axis_env_, name_stack)
A:jax._src.api.out_nodes->jax.interpreters.xla.jaxpr_subcomp(ctx, jaxpr, xla_consts, *xla_args)
A:jax._src.api.build_out_tuple->partial(xc.ops.Tuple, c, out_nodes)
A:jax._src.api.out_tuple->build_out_tuple()
A:jax._src.api.built->jax._src.lib.xla_client.XlaBuilder(f'xla_computation_{fun_name}').build(out_tuple)
A:jax._src.api.out_shape->tree_unflatten(out_tree(), out_shapes_flat)
A:jax._src.api.value_and_grad_f->value_and_grad(fun, argnums, has_aux=has_aux, holomorphic=holomorphic, allow_int=allow_int, reduce_axes=reduce_axes)
A:jax._src.api.(_, g)->value_and_grad_f(*args, **kwargs)
A:jax._src.api.((_, aux), g)->value_and_grad_f(*args, **kwargs)
A:jax._src.api.reduce_axes->_ensure_str_tuple(reduce_axes)
A:jax._src.api.(f_partial, dyn_args)->argnums_partial(f, argnums, args, require_static_args_hashable=False)
A:jax._src.api.(ans, vjp_py)->_vjp(f_partial, *dyn_args, reduce_axes=reduce_axes)
A:jax._src.api.(ans, vjp_py, aux)->_vjp(f_partial, *dyn_args, has_aux=True, reduce_axes=reduce_axes)
A:jax._src.api.g->vjp_py(lax_internal._one(ans))
A:jax._src.api._check_input_dtype_grad->partial(_check_input_dtype_revderiv, 'grad')
A:jax._src.api._check_output_dtype_grad->partial(_check_output_dtype_revderiv, 'grad')
A:jax._src.api.pushfwd->partial(_jvp, f_partial, dyn_args, has_aux=True)
A:jax._src.api.(y, jac)->vmap(pushfwd, out_axes=(None, -1))(_std_basis(dyn_args))
A:jax._src.api.(y, jac, aux)->vmap(pushfwd, out_axes=(None, -1, None))(_std_basis(dyn_args))
A:jax._src.api.jac_tree->tree_transpose(tree_structure(example_args), tree_structure(y), jac_tree)
A:jax._src.api.(y, pullback)->_vjp(f_partial, *dyn_args)
A:jax._src.api.(y, pullback, aux)->_vjp(f_partial, *dyn_args, has_aux=True)
A:jax._src.api.jac->vmap(pullback)(_std_basis(y))
A:jax._src.api._check_input_dtype_jacrev->partial(_check_input_dtype_revderiv, 'jacrev')
A:jax._src.api._check_output_dtype_jacrev->partial(_check_output_dtype_revderiv, 'jacrev')
A:jax._src.api.(leaves, _)->tree_flatten(pytree)
A:jax._src.api.ndim->property(lambda self: len(self.shape))
A:jax._src.api.dtype->jax._src.dtypes.result_type(*leaves)
A:jax._src.api.flat_basis->jax.numpy.eye(ndim, dtype=dtype)
A:jax._src.api.(leaves, treedef)->tree_flatten(pytree)
A:jax._src.api.parts->_split(arr, np.cumsum(map(np.size, leaves[:-1])), axis)
A:jax._src.api.in_axes->tuple(in_axes)
A:jax._src.api.in_axes_flat->tuple(flatten_axes('pmap in_axes', in_tree, (dyn_in_axes, 0)))
A:jax._src.api.(args, kwargs)->tree_unflatten(tree, vals)
A:jax._src.api.(tree, leaf)->treedef_children(tree)
A:jax._src.api.sizes->tree_unflatten(tree, sizes)
A:jax._src.api.dyn_in_axes->tuple((in_axes[i] for i in dyn_argnums))
A:jax._src.api.dyn_global_arg_shapes->tuple((global_arg_shapes[i] for i in dyn_argnums))
A:jax._src.api.(args, in_tree)->tree_flatten(py_args)
A:jax._src.api.global_arg_shapes_flat->tuple(flatten_axes('pmap global_arg_shapes', in_tree, (dyn_global_arg_shapes, None), kws=True))
A:jax._src.api.local_axis_size->_mapped_axis_size(in_tree, args, in_axes_flat, 'pmap', kws=True)
A:jax._src.api.out_axes_thunk->HashableFunction(lambda : tuple(flatten_axes('pmap out_axes', out_tree(), tree_unflatten(out_axes_treedef, list(out_axes_leaves)))), closure=(tuple(out_axes_leaves), out_axes_treedef))
A:jax._src.api.(out_axes_leaves, out_axes_treedef)->tree_flatten(out_axes)
A:jax._src.api.p->_prepare_pmap(fun, in_axes, out_axes, static_broadcasted_tuple, donate_tuple, global_arg_shapes, args, kwargs)
A:jax._src.api.static_broadcasted_tuple->_ensure_index_tuple(static_broadcasted_argnums)
A:jax._src.api.donate_tuple->rebase_donate_argnums(_ensure_index_tuple(donate_argnums), static_broadcasted_tuple)
A:jax._src.api.(axis_name, static_broadcasted_tuple, donate_tuple)->_shared_code_pmap(fun, axis_name, static_broadcasted_argnums, donate_argnums, in_axes, out_axes)
A:jax._src.api.f_pmapped_->_get_f_mapped(fun=fun, axis_name=axis_name, in_axes=in_axes, out_axes=out_axes, static_broadcasted_tuple=static_broadcasted_tuple, devices=devices, backend=backend, axis_size=axis_size, global_arg_shapes=global_arg_shapes, donate_tuple=donate_tuple)
A:jax._src.api.(out_tree, out_flat)->f_pmapped_(*args, **kwargs)
A:jax._src.api.pmap_f.lower->_pmap_lower(fun, axis_name, in_axes, out_axes, static_broadcasted_tuple, devices, backend, axis_size, global_arg_shapes, donate_tuple)
A:jax._src.api.execute->jax.interpreters.pxla.parallel_callable.most_recent_entry()
A:jax._src.api.cpp_mapped_f->jax._src.lib.pmap_lib.pmap(fun, cache_miss, static_broadcasted_tuple, pxla._shard_arg)
A:jax._src.api.pmap_f->wraps(fun)(cpp_mapped_f)
A:jax._src.api.abstract_args->list(map(xla.abstractify, p.flat_args))
A:jax._src.api.unique_ids->jax.interpreters.masking.UniqueIds()
A:jax._src.api.(in_specs, in_shapes_tree)->tree_flatten(in_shapes)
A:jax._src.api.in_specs->map(partial(masking.remap_ids, unique_ids), in_specs)
A:jax._src.api.(out_specs, out_spec_tree)->tree_flatten(out_shape)
A:jax._src.api.out_specs->map(masking.parse_spec, out_specs)
A:jax._src.api.in_shapes->map(masking.parse_spec, in_shapes)
A:jax._src.api.padded_env->jax.interpreters.masking.bind_shapes(in_shapes, [x.shape for x in args_flat])
A:jax._src.api.(flat_fun, out_tree_thunk)->flatten_fun_nokwargs(lu.wrap_init(fun), in_tree)
A:jax._src.api.(outs, out_shapes)->jax.interpreters.masking.mask_fun(flat_fun, logical_env, padded_env, args_flat, in_shapes)
A:jax._src.api.out_tree->out_tree()
A:jax._src.api.shape->jax.interpreters.masking.eval_poly_shape(poly_shape, logical_env)
A:jax._src.api.out_logicals->map(logical_shape, out_shapes, outs)
A:jax._src.api.(in_shapes, in_tree)->tree_flatten(in_shapes)
A:jax._src.api.(ps_flat, tree_def)->tree_flatten(primals)
A:jax._src.api.(ts_flat, tree_def_2)->tree_flatten(tangents)
A:jax._src.api.(out_primals, out_tangents)->jvp_fun.call_wrapped(ps_flat, ts_flat)
A:jax._src.api.(flat_fun, out_aux_trees)->flatten_fun_nokwargs2(fun, in_tree)
A:jax._src.api.(jvp_fun, aux)->jax.interpreters.ad.jvp(flat_fun, has_aux=True)
A:jax._src.api.(out_tree, aux_tree)->out_aux_trees()
A:jax._src.api.(primals_flat, in_tree)->tree_flatten(primals)
A:jax._src.api.(out_primals, out_pvals, jaxpr, consts)->jax.interpreters.ad.linearize(jaxtree_fun, *primals_flat)
A:jax._src.api.out_primal_py->tree_unflatten(out_tree, out_primal)
A:jax._src.api.primal_avals->list(map(core.get_aval, primals_flat))
A:jax._src.api.lifted_jvp->Partial(partial(_lift_linearized, jaxpr, primal_avals, (in_tree, out_tree), out_pvals), consts)
A:jax._src.api.tangent_avals->list(map(core.get_aval, tangents))
A:jax._src.api.tangents_out->eval_jaxpr(jaxpr, consts, *tangents)
A:jax._src.api.expected_tangent_dtype->jax.core.primal_dtype_to_tangent_dtype(_dtype(arg))
A:jax._src.api.ans->fun(*args)
A:jax._src.api.(out_primal, out_vjp)->jax.interpreters.ad.vjp(flat_fun, primals_flat, reduce_axes=reduce_axes)
A:jax._src.api.(out_primal, out_vjp, aux)->jax.interpreters.ad.vjp(flat_fun, primals_flat, has_aux=True, reduce_axes=reduce_axes)
A:jax._src.api.vjp_py->Partial(partial(_vjp_pullback_wrapper, ct_dtypes, ct_shapes, (out_tree, in_tree)), out_vjp)
A:jax._src.api.in_avals->map(shaped_abstractify, primals_flat)
A:jax._src.api.in_dtypes->map(dtypes.dtype, in_avals)
A:jax._src.api.in_pvals->map(pe.PartialVal.unknown, in_avals)
A:jax._src.api.(jaxpr, out_pvals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr(flat_fun, in_pvals, instantiate=True)
A:jax._src.api.(out_avals, _)->unzip2(out_pvals)
A:jax._src.api.out_dtypes->map(dtypes.dtype, out_avals)
A:jax._src.api.(out_cotangents, out_tree2)->tree_flatten(out_cotangent)
A:jax._src.api.in_cotangents->map(ad.instantiate_zeros, ad.backward_pass(jaxpr, reduce_axes, True, consts, dummies, out_cotangents))
A:jax._src.api.(flat_args, in_tree)->tree_flatten((args, kwargs))
A:jax._src.api.axes_specs->_flat_axes_specs(abstracted_axes, *args, **kwargs)
A:jax._src.api.(in_avals, keep_inputs)->unzip2(in_type)
A:jax._src.api.(in_avals, in_tree, keep_inputs)->abstractify(args, kwargs)
A:jax._src.api.(f, out_tree)->flatten_fun(f, in_tree)
A:jax._src.api.closed_jaxpr->jax.core.ClosedJaxpr(jaxpr, consts)
A:jax._src.api.(a1, a2)->next(((a1, a2) for (a1, a2) in zip(avals[:-1], avals[1:]) if a1 != a2))
A:jax._src.api.stacked_aval->avals[0].update(shape=(len(devices),) + avals[0].shape)
A:jax._src.api.(buf,)->jax._src.dispatch.device_put(x, devices[0])
A:jax._src.api.self.dtype->numpy.dtype(dtype)
A:jax._src.api.size->property(lambda self: prod(self.shape))
A:jax._src.api.named->frozenset(self.named_shape.items())
A:jax._src.api.(wrapped_fun, out_tree)->flatten_fun(lu.wrap_init(fun), in_tree)
A:jax._src.api.debug_info->jax.interpreters.partial_eval.debug_info(fun, in_tree, True, 'eval_shape')
A:jax._src.api.(_, in_tree)->tree_flatten(())
A:jax._src.api.lu_f->jax.linear_util.wrap_init(lambda : fun(*args, **kwargs))
A:jax._src.api.(flat_f, out_tree)->flatten_fun_nokwargs(lu_f, in_tree)
jax.ShapeDtypeStruct(self,shape,dtype,named_shape=None)
jax.ShapeDtypeStruct.__eq__(self,other)
jax.ShapeDtypeStruct.__hash__(self)
jax.ShapeDtypeStruct.__len__(self)
jax.ShapeDtypeStruct.__repr__(self)
jax._src.api.PmapCallInfo(NamedTuple)
jax._src.api.ShapeDtypeStruct(self,shape,dtype,named_shape=None)
jax._src.api.ShapeDtypeStruct.__eq__(self,other)
jax._src.api.ShapeDtypeStruct.__hash__(self)
jax._src.api.ShapeDtypeStruct.__init__(self,shape,dtype,named_shape=None)
jax._src.api.ShapeDtypeStruct.__len__(self)
jax._src.api.ShapeDtypeStruct.__repr__(self)
jax._src.api._BackendAndDeviceInfo(NamedTuple)
jax._src.api._FastpathData(NamedTuple)
jax._src.api._PmapFastpathData(NamedTuple)
jax._src.api._check_arg(arg)
jax._src.api._check_callable(fun)
jax._src.api._check_input_dtype_jacfwd(holomorphic:bool,x:Any)->None
jax._src.api._check_input_dtype_revderiv(name,holomorphic,allow_int,x)
jax._src.api._check_output_dtype_jacfwd(holomorphic,x)
jax._src.api._check_output_dtype_revderiv(name,holomorphic,x)
jax._src.api._check_scalar(x)
jax._src.api._cpp_jit(fun:Callable,static_argnums:Union[int,Iterable[int],None]=None,static_argnames:Union[str,Iterable[str],None]=None,device:Optional[xc.Device]=None,backend:Optional[str]=None,donate_argnums:Union[int,Iterable[int]]=(),inline:bool=False)->stages.Wrapped
jax._src.api._cpp_pmap(fun:Callable,axis_name:Optional[AxisName]=None,*,in_axes=0,out_axes=0,static_broadcasted_argnums:Union[int,Iterable[int]]=(),devices:Optional[Sequence[xc.Device]]=None,backend:Optional[str]=None,axis_size:Optional[int]=None,donate_argnums:Union[int,Iterable[int]]=(),global_arg_shapes:Optional[Tuple[Tuple[int,...],...]]=None)->Any
jax._src.api._device_get(x)
jax._src.api._flat_axes_specs(abstracted_axes,*args,**kwargs)->List[pe.AbstractedAxesSpec]
jax._src.api._get_f_mapped(*,fun:Callable,axis_name:Optional[AxisName],in_axes=0,out_axes=0,static_broadcasted_tuple:Tuple[int],devices:Optional[Sequence[xc.Device]],backend:Optional[str],axis_size:Optional[int],donate_tuple:Tuple[int],global_arg_shapes:Optional[Tuple[Tuple[int,...],...]])
jax._src.api._infer_argnums_and_argnames(fun:Callable,argnums:Union[int,Iterable[int],None],argnames:Union[str,Iterable[str],None])->Tuple[Tuple[int, ...], Tuple[str, ...]]
jax._src.api._isgeneratorfunction(fun)
jax._src.api._jacfwd_unravel(input_pytree,output_pytree_leaf,arr)
jax._src.api._jacrev_unravel(output_pytree,input_pytree_leaf,arr)
jax._src.api._jit_lower(fun,static_argnums,static_argnames,device,backend,donate_argnums,inline)
jax._src.api._jvp(fun:lu.WrappedFun,primals,tangents,has_aux=False)
jax._src.api._lift_linearized(jaxpr,primal_avals,io_tree,out_pvals,consts,*py_args)
jax._src.api._mapped_axis_size(tree,vals,dims,name,*,kws=False)
jax._src.api._nan_check_posthook(fun,args,kwargs,output)
jax._src.api._pmap_lower(fun,axis_name,in_axes,out_axes,static_broadcasted_tuple,devices,backend,axis_size,global_arg_shapes,donate_tuple)
jax._src.api._possible_downcast(x,example)
jax._src.api._prepare_jit(fun,static_argnums,static_argnames,donate_argnums,args,kwargs)
jax._src.api._prepare_pmap(fun,in_axes,out_axes,static_broadcasted_tuple,donate_tuple,global_arg_shapes,args,kwargs)
jax._src.api._python_jit(fun:Callable,static_argnums:Union[int,Iterable[int],None]=None,static_argnames:Union[str,Iterable[str],None]=None,device:Optional[xc.Device]=None,backend:Optional[str]=None,donate_argnums:Union[int,Iterable[int]]=(),inline:bool=False,abstracted_axes:Optional[PytreeOfAbstractedAxesSpec]=None)->stages.Wrapped
jax._src.api._python_pmap(fun:Callable,axis_name:Optional[AxisName]=None,*,in_axes=0,out_axes=0,static_broadcasted_argnums:Union[int,Iterable[int]]=(),devices:Optional[Sequence[xc.Device]]=None,backend:Optional[str]=None,axis_size:Optional[int]=None,donate_argnums:Union[int,Iterable[int]]=(),global_arg_shapes:Optional[Tuple[Tuple[int,...],...]]=None)->stages.Wrapped
jax._src.api._shared_code_pmap(fun,axis_name,static_broadcasted_argnums,donate_argnums,in_axes,out_axes)
jax._src.api._split(x,indices,axis)
jax._src.api._std_basis(pytree)
jax._src.api._unravel_array_into_pytree(pytree,axis,example,arr)
jax._src.api._update_debug_special_global(_)
jax._src.api._update_debug_special_thread_local(_)
jax._src.api._valid_jaxtype(arg)
jax._src.api._vjp(fun:lu.WrappedFun,*primals,has_aux=False,reduce_axes=())
jax._src.api._vjp_pullback_wrapper(cotangent_dtypes,cotangent_shapes,io_tree,fun,py_args)
jax._src.api.block_until_ready(x)
jax._src.api.checkpoint(fun:Callable,concrete:bool=False,prevent_cse:bool=True,policy:Optional[Callable[...,bool]]=None)->Callable
jax._src.api.device_get(x:Any)
jax._src.api.device_put(x,device:Optional[xc.Device]=None)
jax._src.api.device_put_replicated(x:Any,devices:Sequence[xc.Device])
jax._src.api.device_put_sharded(shards:Sequence[Any],devices:Sequence[xc.Device])
jax._src.api.disable_jit()
jax._src.api.eval_shape(fun:Callable,*args,**kwargs)
jax._src.api.grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False,allow_int:bool=False,reduce_axes:Sequence[AxisName]=())->Callable
jax._src.api.hessian(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False)->Callable
jax._src.api.jacfwd(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False)->Callable
jax._src.api.jacrev(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False,allow_int:bool=False)->Callable
jax._src.api.jit(fun:Callable,*,static_argnums:Union[int,Iterable[int],None]=None,static_argnames:Union[str,Iterable[str],None]=None,device:Optional[xc.Device]=None,backend:Optional[str]=None,donate_argnums:Union[int,Iterable[int]]=(),inline:bool=False,abstracted_axes:Optional[Any]=None)->stages.Wrapped
jax._src.api.jvp(fun:Callable,primals,tangents,has_aux:bool=False)->Tuple[Any, ...]
jax._src.api.linear_transpose(fun:Callable,*primals,reduce_axes=())->Callable
jax._src.api.linearize(fun:Callable,*primals)->Tuple[Any, Callable]
jax._src.api.make_jaxpr(fun:Callable,static_argnums:Union[int,Iterable[int]]=(),axis_env:Optional[Sequence[Tuple[AxisName,int]]]=None,return_shape:bool=False,abstracted_axes:Optional[Any]=None)->Callable[..., core.ClosedJaxpr]
jax._src.api.mask(fun:Callable,in_shapes,out_shape=None)->Callable
jax._src.api.named_call(fun:Callable[...,Any],*,name:Optional[str]=None)->Callable[..., Any]
jax._src.api.pmap(fun:Callable,axis_name:Optional[AxisName]=None,*,in_axes=0,out_axes=0,static_broadcasted_argnums:Union[int,Iterable[int]]=(),devices:Optional[Sequence[xc.Device]]=None,backend:Optional[str]=None,axis_size:Optional[int]=None,donate_argnums:Union[int,Iterable[int]]=(),global_arg_shapes:Optional[Tuple[Tuple[int,...],...]]=None)->Any
jax._src.api.shapecheck(in_shapes,out_shape,fun:Callable)
jax._src.api.value_and_grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False,allow_int:bool=False,reduce_axes:Sequence[AxisName]=())->Callable[..., Tuple[Any, Any]]
jax._src.api.vjp(fun:Callable,*primals,has_aux:bool=False,reduce_axes=())->Union[Tuple[Any, Callable], Tuple[Any, Callable, Any]]
jax._src.api.vmap(fun:F,in_axes=0,out_axes=0,axis_name=None,axis_size=None)->F
jax._src.api.xla_computation(fun:Callable,static_argnums:Union[int,Iterable[int]]=(),axis_env:Optional[Sequence[Tuple[AxisName,int]]]=None,in_parts=None,out_parts=None,backend:Optional[str]=None,tuple_args:bool=False,instantiate_const_outputs:Optional[bool]=None,return_shape:bool=False,donate_argnums:Union[int,Iterable[int]]=())->Callable
jax.block_until_ready(x)
jax.checkpoint(fun:Callable,concrete:bool=False,prevent_cse:bool=True,policy:Optional[Callable[...,bool]]=None)->Callable
jax.device_get(x:Any)
jax.device_put(x,device:Optional[xc.Device]=None)
jax.device_put_replicated(x:Any,devices:Sequence[xc.Device])
jax.device_put_sharded(shards:Sequence[Any],devices:Sequence[xc.Device])
jax.disable_jit()
jax.eval_shape(fun:Callable,*args,**kwargs)
jax.grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False,allow_int:bool=False,reduce_axes:Sequence[AxisName]=())->Callable
jax.hessian(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False)->Callable
jax.jacfwd(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False)->Callable
jax.jacrev(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False,allow_int:bool=False)->Callable
jax.jit(fun:Callable,*,static_argnums:Union[int,Iterable[int],None]=None,static_argnames:Union[str,Iterable[str],None]=None,device:Optional[xc.Device]=None,backend:Optional[str]=None,donate_argnums:Union[int,Iterable[int]]=(),inline:bool=False,abstracted_axes:Optional[Any]=None)->stages.Wrapped
jax.jvp(fun:Callable,primals,tangents,has_aux:bool=False)->Tuple[Any, ...]
jax.linear_transpose(fun:Callable,*primals,reduce_axes=())->Callable
jax.linearize(fun:Callable,*primals)->Tuple[Any, Callable]
jax.make_jaxpr(fun:Callable,static_argnums:Union[int,Iterable[int]]=(),axis_env:Optional[Sequence[Tuple[AxisName,int]]]=None,return_shape:bool=False,abstracted_axes:Optional[Any]=None)->Callable[..., core.ClosedJaxpr]
jax.mask(fun:Callable,in_shapes,out_shape=None)->Callable
jax.named_call(fun:Callable[...,Any],*,name:Optional[str]=None)->Callable[..., Any]
jax.pmap(fun:Callable,axis_name:Optional[AxisName]=None,*,in_axes=0,out_axes=0,static_broadcasted_argnums:Union[int,Iterable[int]]=(),devices:Optional[Sequence[xc.Device]]=None,backend:Optional[str]=None,axis_size:Optional[int]=None,donate_argnums:Union[int,Iterable[int]]=(),global_arg_shapes:Optional[Tuple[Tuple[int,...],...]]=None)->Any
jax.shapecheck(in_shapes,out_shape,fun:Callable)
jax.value_and_grad(fun:Callable,argnums:Union[int,Sequence[int]]=0,has_aux:bool=False,holomorphic:bool=False,allow_int:bool=False,reduce_axes:Sequence[AxisName]=())->Callable[..., Tuple[Any, Any]]
jax.vjp(fun:Callable,*primals,has_aux:bool=False,reduce_axes=())->Union[Tuple[Any, Callable], Tuple[Any, Callable, Any]]
jax.vmap(fun:F,in_axes=0,out_axes=0,axis_name=None,axis_size=None)->F
jax.xla_computation(fun:Callable,static_argnums:Union[int,Iterable[int]]=(),axis_env:Optional[Sequence[Tuple[AxisName,int]]]=None,in_parts=None,out_parts=None,backend:Optional[str]=None,tuple_args:bool=False,instantiate_const_outputs:Optional[bool]=None,return_shape:bool=False,donate_argnums:Union[int,Iterable[int]]=())->Callable


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/custom_batching.py----------------------------------------
A:jax._src.custom_batching.(args_flat, in_tree)->tree_flatten(args)
A:jax._src.custom_batching.(flat_fun, out_tree)->flatten_fun_nokwargs(lu.wrap_init(self.fun), in_tree)
A:jax._src.custom_batching.debug->jax.interpreters.partial_eval.debug_info(self.fun, in_tree, False, 'custom_vmap')
A:jax._src.custom_batching.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(flat_fun, in_avals, debug)
A:jax._src.custom_batching.closed_call->jax.core.ClosedJaxpr(pe.convert_constvars_jaxpr(jaxpr), ())
A:jax._src.custom_batching.out_flat->jax.core.Primitive('custom_vmap_call').bind(*consts, *args_flat, call=closed_call, rule=self.vmap_rule, in_tree=in_tree, out_tree=out_tree())
A:jax._src.custom_batching.(f, out_axes)->jax.interpreters.batching.batch_subtrace(f)
A:jax._src.custom_batching.f->custom_vmap(f)
A:jax._src.custom_batching.outs->jax.core.Primitive('custom_vmap_call').bind(*primals, *tangents, call=jvp_call, rule=jvp_of_rule_rule, in_tree=jvp_in_tree, out_tree=jvp_out_tree)
A:jax._src.custom_batching.args_flat->map(maybe_bdim_at_front, args_flat, dims)
A:jax._src.custom_batching.args->tree_merge(in_batched, mapped_args, bcast_args)
A:jax._src.custom_batching.in_batched->tree_unflatten(in_tree, flat_in_batched)
A:jax._src.custom_batching.(out, out_batched)->call_rule(rule, axis_size, mutually_batched, primals)
A:jax._src.custom_batching.(flat_outs, tree1)->tree_flatten(out)
A:jax._src.custom_batching.(flat_out_batched, tree2)->tree_flatten(out_batched)
A:jax._src.custom_batching.mutually_batched->tree_map(operator.and_, in_batched_ps, in_batched_ts)
A:jax._src.custom_batching.extra_batched_ps->tree_map(lambda pb, tb: 0 if pb and (not tb) else None, in_batched_ps, in_batched_ts)
A:jax._src.custom_batching.extra_batched_ts->tree_map(lambda pb, tb: 0 if tb and (not pb) else None, in_batched_ps, in_batched_ts)
A:jax._src.custom_batching.out_mutually_batched->jax.linear_util.Store()
A:jax._src.custom_batching.(flat_ps_ts, tree_ps_ts)->tree_flatten((primals, tangents))
A:jax._src.custom_batching.(flat_extra_batched_ps_ts, tree_ps_ts2)->tree_flatten((extra_batched_ps, extra_batched_ts), is_leaf=lambda x: x is None)
A:jax._src.custom_batching.(to_vmap_over_extra_batched_dims_flat, out_tree2)->flatten_fun_nokwargs(lu.wrap_init(to_vmap_over_extra_batched_dims), tree_ps_ts)
A:jax._src.custom_batching.(flat_out_ps_ts, flat_out_axes)->vmap_unrestricted(to_vmap_over_extra_batched_dims_flat, *flat_ps_ts, in_axes=flat_extra_batched_ps_ts, axis_name=core.no_axis_name, axis_size=axis_size)
A:jax._src.custom_batching.(n, ragged)->divmod(len(flat_out_ps_ts), 2)
A:jax._src.custom_batching.flat_out_ps->map(maybe_bdim_at_front, flat_out_ps, flat_out_axes_p)
A:jax._src.custom_batching.flat_out_ts->map(maybe_bdim_at_front, flat_out_ts, flat_out_axes_t)
A:jax._src.custom_batching.(out_ps, out_ts)->tree_unflatten(out_tree2(), [*flat_out_ps, *flat_out_ts])
A:jax._src.custom_batching.(out_extra_batched_ps, out_extra_batched_ts)->tree_unflatten(out_tree2(), [*flat_out_extra_batched_ps, *flat_out_extra_batched_ts])
A:jax._src.custom_batching.out_batched_ps->tree_map(operator.or_, out_mutually_batched.val, out_extra_batched_ps)
A:jax._src.custom_batching.out_batched_ts->tree_map(operator.or_, out_mutually_batched.val, out_extra_batched_ts)
A:jax._src.custom_batching.tangents->map(ad.instantiate_zeros, tangents)
A:jax._src.custom_batching.(jvp_call, _)->jax.interpreters.ad.jvp_jaxpr(call, [True] * len(primals), True)
A:jax._src.custom_batching.jvp_in_tree->treedef_tuple((in_tree, in_tree))
A:jax._src.custom_batching.jvp_out_tree->treedef_tuple((out_tree, out_tree))
A:jax._src.custom_batching.(out_primals, out_tangents)->jax._src.util.split_list(outs, [len(outs) // 2])
A:jax._src.custom_batching.custom_vmap_p->jax.core.Primitive('custom_vmap_call')
A:jax._src.custom_batching.lhs->tree_map(lambda l, x: x if l else None, mask, tree)
A:jax._src.custom_batching.rhs->tree_map(lambda l, x: None if l else x, mask, tree)
A:jax._src.custom_batching.(mapped_args, bcast_args)->tree_split(in_batched, list(args))
A:jax._src.custom_batching.out->jax.lax.map(to_map, mapped_args)
A:jax._src.custom_batching.out_batched->tree_map(lambda _: True, out)
jax._src.custom_batching.call_rule(rule,axis_size,in_batched,args)
jax._src.custom_batching.check_vmap_rule_trees(rule,original_out_tree,out_tree,out_batched_tree)
jax._src.custom_batching.custom_vmap(self,fun:Callable)
jax._src.custom_batching.custom_vmap.__init__(self,fun:Callable)
jax._src.custom_batching.custom_vmap.def_vmap(self,vmap_rule:Callable)->Callable
jax._src.custom_batching.custom_vmap_abstract_eval(*in_avals,call,**_)
jax._src.custom_batching.custom_vmap_batching(args_flat,dims,*,call,rule,in_tree,out_tree)
jax._src.custom_batching.custom_vmap_impl(*args,call,rule,in_tree,out_tree)
jax._src.custom_batching.custom_vmap_jvp(primals,tangents,*,call,rule,in_tree,out_tree)
jax._src.custom_batching.ensure_list(xs)
jax._src.custom_batching.maybe_bdim_at_front(x,bdim)
jax._src.custom_batching.rule_name(rule)
jax._src.custom_batching.sequential_vmap(f)
jax._src.custom_batching.tree_merge(mask,lhs_tree,rhs_tree)
jax._src.custom_batching.tree_split(mask,tree)
jax._src.custom_batching.vmap_unrestricted(f:lu.WrappedFun,*args,in_axes,axis_name,axis_size)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax_reference.py----------------------------------------
A:jax._src.lax_reference.quotient->numpy.floor_divide(lhs, rhs)
A:jax._src.lax_reference.select->numpy.logical_and(np.sign(lhs) != np.sign(rhs), np.remainder(lhs, rhs) != 0)
A:jax._src.lax_reference.iinfo->numpy.iinfo(x.dtype)
A:jax._src.lax_reference.x->x.view(f'uint{np.iinfo(x.dtype).bits}').view(f'uint{np.iinfo(x.dtype).bits}')
A:jax._src.lax_reference.m->list(map(np.uint32, m[:-1]))
A:jax._src.lax_reference.bits->(x[..., None] & mask).astype(np.bool_)
A:jax._src.lax_reference.out->numpy.full(operand.shape[:2] + tuple(outspace), fill_value, operand.dtype)
A:jax._src.lax_reference.pads->padtype_to_pads(op.shape, dims, strides, padding)
A:jax._src.lax_reference.(lhs_perm, rhs_perm, out_perm)->_conv_general_permutations(dimension_numbers)
A:jax._src.lax_reference.padding->padtype_to_pads(np.take(lhs.shape, lhs_perm)[2:], np.take(rhs.shape, rhs_perm)[2:], window_strides, padding)
A:jax._src.lax_reference.trans_lhs->transpose(lhs, lhs_perm)
A:jax._src.lax_reference.trans_rhs->transpose(rhs, rhs_perm)
A:jax._src.lax_reference.new_id->itertools.count()
A:jax._src.lax_reference.shared_id->next(new_id)
A:jax._src.lax_reference.out_axis_ids->filter(not_none, batch_ids + lhs_out_axis_ids + rhs_out_axis_ids)
A:jax._src.lax_reference.in_reshape->numpy.ones(len(shape), dtype=np.int32)
A:jax._src.lax_reference.dimensions->frozenset(dimensions)
A:jax._src.lax_reference.(lo, hi, interior)->zip(*padding_config)
A:jax._src.lax_reference.outshape->numpy.add(np.add(np.add(lo_pos, hi_pos), operand.shape), np.multiply(interior, np.subtract(operand.shape, 1)))
A:jax._src.lax_reference.lhs_slices->tuple((_slice(None, None, step) for step in factors))
A:jax._src.lax_reference.trim_slices->tuple((_slice(-l if l < 0 else 0, h if h < 0 else None) for (l, h) in zip(lo, hi)))
A:jax._src.lax_reference.strides->numpy.ones(len(start_indices)).astype(int)
A:jax._src.lax_reference.slices->tuple((_slice(abs(lo) if lo < 0 else 0, hi % dim if hi < 0 else None) for ((lo, hi), dim) in zip(pads, np.shape(arr))))
A:jax._src.lax_reference.idx->tuple((_slice(start, start + size) for (start, size) in zip(start_indices, slice_sizes)))
A:jax._src.lax_reference.updated_operand->numpy.copy(operand)
A:jax._src.lax_reference.reducer->_make_reducer(computation, init_value)
A:jax._src.lax_reference.op->_dilate(op, base_dilation, init_value)
A:jax._src.lax_reference.view->numpy.lib.stride_tricks.as_strided(lhs, view_shape, view_strides)
A:jax._src.lax_reference.idxs->list(np.ix_(*[np.arange(d) for d in keys.shape]))
A:jax._src.lax_reference.idxs[dimension]->numpy.argsort(keys, axis=dimension)
A:jax._src.lax_reference.(view, view_axes, rhs_axes, out_axes)->_conv_view(lhs, rhs.shape, window_strides, pads, 0.0)
A:jax._src.lax_reference.out_shape->numpy.ceil(np.true_divide(in_shape, window_strides)).astype(int)
A:jax._src.lax_reference.lhs->_pad(lhs, [(0, 0)] * 2 + list(pads), pad_value)
A:jax._src.lax_reference.dim->len(filter_shape)
A:jax._src.lax_reference.out_strides->numpy.multiply(window_strides, lhs.strides[2:])
A:jax._src.lax_reference.view_axes->list(range(view.ndim))
A:jax._src.lax_reference.outspace->numpy.add(operand.shape[2:], np.multiply(np.subtract(factors, 1), np.subtract(operand.shape[2:], 1)))
A:jax._src.lax_reference.monoid_record->_monoids.get(getattr(py_binop, '__name__'))
A:jax._src.lax_reference.MonoidRecord->collections.namedtuple('MonoidRecord', ['reducer', 'identity'])
A:jax._src.lax_reference.result->numpy.full(np.delete(np.shape(operand), axis), init_val, dtype=np.asarray(operand).dtype)
A:jax._src.lax_reference.out_idx->tuple(np.delete(idx, axis))
A:jax._src.lax_reference.result[out_idx]->py_binop(result[out_idx], operand[idx])
jax._src.lax_reference._conv(lhs,rhs,window_strides,pads)
jax._src.lax_reference._conv_general_permutations(dimension_numbers)
jax._src.lax_reference._conv_view(lhs,rhs_shape,window_strides,pads,pad_value)
jax._src.lax_reference._dilate(operand,factors,fill_value=0)
jax._src.lax_reference._get_max_identity(dt)
jax._src.lax_reference._get_min_identity(dt)
jax._src.lax_reference._identity_getter(op)
jax._src.lax_reference._make_reducer(py_binop,init_val)
jax._src.lax_reference._pad(arr,pads,pad_value)
jax._src.lax_reference._reducer_from_pyfunc(py_binop,init_val)
jax._src.lax_reference.bessel_i0e(x)
jax._src.lax_reference.bessel_i1e(x)
jax._src.lax_reference.betainc(a,b,x)
jax._src.lax_reference.bitcast_convert_type(operand,dtype)
jax._src.lax_reference.broadcast(operand,sizes)
jax._src.lax_reference.broadcast_in_dim(operand,shape,broadcast_dimensions)
jax._src.lax_reference.clamp(min,operand,max)
jax._src.lax_reference.clz(x)
jax._src.lax_reference.complex(x,y)
jax._src.lax_reference.concatenate(operands,dimension)
jax._src.lax_reference.conj(x)
jax._src.lax_reference.conv(lhs,rhs,window_strides,padding)
jax._src.lax_reference.conv_general_dilated(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers)
jax._src.lax_reference.conv_with_general_padding(lhs,rhs,window_strides,padding,lhs_dilation,rhs_dilation)
jax._src.lax_reference.convert_element_type(operand,dtype)
jax._src.lax_reference.digamma(x)
jax._src.lax_reference.div(lhs,rhs)
jax._src.lax_reference.dot_general(lhs,rhs,dimension_numbers)
jax._src.lax_reference.dynamic_slice(operand,start_indices,slice_sizes)
jax._src.lax_reference.dynamic_update_slice(operand,update,start_indices)
jax._src.lax_reference.erf(x)
jax._src.lax_reference.erf_inv(x)
jax._src.lax_reference.erfc(x)
jax._src.lax_reference.lgamma(x)
jax._src.lax_reference.pad(operand,padding_value,padding_config)
jax._src.lax_reference.padtype_to_pads(in_shape,filter_shape,window_strides,padding)
jax._src.lax_reference.population_count(x)
jax._src.lax_reference.reduce(operand,init_value,computation,dimensions)
jax._src.lax_reference.reduce_window(operand,init_value,computation,window_dimensions,window_strides,padding,base_dilation)
jax._src.lax_reference.rem(lhs,rhs)
jax._src.lax_reference.reshape(operand,new_sizes,dimensions=None)
jax._src.lax_reference.rev(operand,dimensions)
jax._src.lax_reference.round(x)
jax._src.lax_reference.slice(operand,start_indices,limit_indices,strides=None)
jax._src.lax_reference.sort_key_val(keys,values,dimension=-1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/prng.py----------------------------------------
A:jax._src.prng.ndim->len(impl.key_shape)
A:jax._src.prng.base_ndim->len(self.impl.key_shape)
A:jax._src.prng.idx->_canonicalize_tuple_index(ndim, idx, array_name='PRNGKeyArray')
A:jax._src.prng.reshaped_keys->jax.numpy.reshape(self._keys, (*newshape, -1), order=order)
A:jax._src.prng.axis->canonicalize_axis(axis, self.ndim)
A:jax._src.prng.seed_arr->jax.numpy.asarray(seed)
A:jax._src.prng.k1->convert(lax.shift_right_logical(seed_arr, lax_internal._const(seed_arr, 32)))
A:jax._src.prng.k2->convert(jnp.bitwise_and(seed_arr, np.uint32(4294967295)))
A:jax._src.prng.nbits->numpy.array(jnp.iinfo(dtype).bits, dtype)
A:jax._src.prng.d->jax.lax.convert_element_type(d, dtype)
A:jax._src.prng.x->jax.core.Primitive('threefry2x32').bind(key1, key2, x[0], x[1])
A:jax._src.prng.shape->jax.core.as_named_shape(shape)
A:jax._src.prng.named_shape->jax.core.join_named_shapes(*(a.named_shape for a in args))
A:jax._src.prng.aval->jax.core.UnshapedArray(jnp.dtype(jnp.uint32))
A:jax._src.prng.rotate_left->_make_rotate_left(np.uint32)
A:jax._src.prng.v[1]->rotate_left(v[1], rot)
A:jax._src.prng.(x, _, _)->jax.lax.fori_loop(0, 5, rolled_loop_step, (x, rotate_list(ks), rotations))
A:jax._src.prng.rank->len(aval_out.shape)
A:jax._src.prng.zeros->jax.interpreters.mlir.full_like_aval(0, aval_out)
A:jax._src.prng.threefry2x32_p->jax.core.Primitive('threefry2x32')
A:jax._src.prng.out->jax.numpy.concatenate(x)
A:jax._src.prng.counts->jax.lax.iota(np.uint32, num * 2)
A:jax._src.prng.real_size->jax.lax.psum(1, name)
A:jax._src.prng.axis_index->jax.lax.axis_index(name)
A:jax._src.prng.key->threefry_fold_in(key, axis_index)
A:jax._src.prng.size->prod(shape.positional)
A:jax._src.prng.(max_count, r)->divmod(bit_width * size, 32)
A:jax._src.prng.(nblocks, rem)->divmod(max_count, jnp.iinfo(np.uint32).max)
A:jax._src.prng.bits->jax.lax.reshape(bits, (np.uint32(max_count * 32 // bit_width),), (1, 0))
A:jax._src.prng.keys->threefry_split(key, nblocks + 1)
A:jax._src.prng.blocks->vmap(threefry_2x32, in_axes=(0, None))(subkeys, lax.iota(np.uint32, jnp.iinfo(np.uint32).max))
A:jax._src.prng.last->threefry_2x32(last_key, lax.iota(np.uint32, rem))
A:jax._src.prng.threefry_prng_impl->PRNGImpl(key_shape=(2,), seed=threefry_seed, split=threefry_split, random_bits=threefry_random_bits, fold_in=threefry_fold_in)
A:jax._src.prng.halfkey->threefry_seed(seed)
A:jax._src.prng.(_, bits)->jax.lax.rng_bit_generator(key, shape, dtype=UINT_DTYPES[bit_width])
A:jax._src.prng.rbg_prng_impl->PRNGImpl(key_shape=(4,), seed=_rbg_seed, split=_rbg_split, random_bits=_rbg_random_bits, fold_in=_rbg_fold_in)
A:jax._src.prng.(_, keys)->jax.lax.rng_bit_generator(key, (10 * num, 4), dtype='uint32')
A:jax._src.prng.(_, random_bits)->jax.lax.rng_bit_generator(_rbg_seed(data), (10, 4), dtype='uint32')
A:jax._src.prng.unsafe_rbg_prng_impl->PRNGImpl(key_shape=(4,), seed=_rbg_seed, split=_unsafe_rbg_split, random_bits=_rbg_random_bits, fold_in=_unsafe_rbg_fold_in)
jax._src.prng.PRNGImpl(NamedTuple)
jax._src.prng.PRNGImpl.pprint(self)
jax._src.prng.PRNGKeyArray(self,impl,key_data:jnp.ndarray)
jax._src.prng.PRNGKeyArray.__getitem__(self,idx)->'PRNGKeyArray'
jax._src.prng.PRNGKeyArray.__init__(self,impl,key_data:jnp.ndarray)
jax._src.prng.PRNGKeyArray.__iter__(self)->Iterator['PRNGKeyArray']
jax._src.prng.PRNGKeyArray.__len__(self)
jax._src.prng.PRNGKeyArray.__repr__(self)
jax._src.prng.PRNGKeyArray._fold_in(self,data:int)->'PRNGKeyArray'
jax._src.prng.PRNGKeyArray._is_scalar(self)
jax._src.prng.PRNGKeyArray._random_bits(self,bit_width,shape)->jnp.ndarray
jax._src.prng.PRNGKeyArray._shape(self)
jax._src.prng.PRNGKeyArray._split(self,num:int)->'PRNGKeyArray'
jax._src.prng.PRNGKeyArray.broadcast_to(self,shape)
jax._src.prng.PRNGKeyArray.concatenate(self,key_arrs,axis)
jax._src.prng.PRNGKeyArray.dtype(self)
jax._src.prng.PRNGKeyArray.expand_dims(self,dimensions:Sequence[int])
jax._src.prng.PRNGKeyArray.ndim(self)
jax._src.prng.PRNGKeyArray.reshape(self,newshape,order=None)
jax._src.prng.PRNGKeyArray.shape(self)
jax._src.prng.PRNGKeyArray.tree_flatten(self)
jax._src.prng.PRNGKeyArray.tree_unflatten(cls,impl,keys)
jax._src.prng.PRNGKeyArray.unsafe_raw_array(self)
jax._src.prng._bit_stats(bits)
jax._src.prng._check_prng_key_data(impl,key_data:jnp.ndarray)
jax._src.prng._is_threefry_prng_key(key:jnp.ndarray)->bool
jax._src.prng._make_rotate_left(dtype)
jax._src.prng._rbg_fold_in(key:jnp.ndarray,data:int)->jnp.ndarray
jax._src.prng._rbg_random_bits(key:jnp.ndarray,bit_width:int,shape:Sequence[int])->jnp.ndarray
jax._src.prng._rbg_seed(seed:int)->jnp.ndarray
jax._src.prng._rbg_split(key:jnp.ndarray,num:int)->jnp.ndarray
jax._src.prng._threefry2x32_abstract_eval(*args)
jax._src.prng._threefry2x32_gpu_lowering(ctx,k1,k2,x1,x2)
jax._src.prng._threefry2x32_gpu_translation_rule(ctx,avals_in,avals_out,k1,k2,x1,x2)
jax._src.prng._threefry2x32_lowering(key1,key2,x1,x2,use_rolled_loops=True)
jax._src.prng._threefry_fold_in(key,data)
jax._src.prng._threefry_split(key,num)->jnp.ndarray
jax._src.prng._unsafe_rbg_fold_in(key:jnp.ndarray,data:int)->jnp.ndarray
jax._src.prng._unsafe_rbg_split(key:jnp.ndarray,num:int)->jnp.ndarray
jax._src.prng.apply_round(v,rot)
jax._src.prng.rolled_loop_step(i,state)
jax._src.prng.rotate_list(xs)
jax._src.prng.seed_with_impl(impl:PRNGImpl,seed:int)->PRNGKeyArray
jax._src.prng.threefry_2x32(keypair,count)
jax._src.prng.threefry_fold_in(key:jnp.ndarray,data:int)->jnp.ndarray
jax._src.prng.threefry_random_bits(key:jnp.ndarray,bit_width,shape)
jax._src.prng.threefry_seed(seed:int)->jnp.ndarray
jax._src.prng.threefry_split(key:jnp.ndarray,num:int)->jnp.ndarray


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/config.py----------------------------------------
A:jax._src.config.val->getattr(_thread_local_state, name, unset)
A:jax._src.config.self.FLAGS->NameSpace(self.read, self.update)
A:jax._src.config.self._contextmanager_flags->set()
A:jax._src.config.hook->self._update_hooks.get(name, None)
A:jax._src.config.update_hook->kwargs.pop('update_hook', None)
A:jax._src.config.jax_argv->itertools.takewhile(lambda a: a != '--', sys.argv)
A:jax._src.config.name->name.lower().lower()
A:jax._src.config.default->os.getenv(name.upper(), default)
A:jax._src.config.prev_val->getattr(_thread_local_state, self._name, unset)
A:jax._src.config._thread_local_state->threading.local()
A:jax._src.config.unset->_Unset()
A:jax._src.config.config->Config()
A:jax._src.config.gs->jax._src.lib.jax_jit.global_state()
A:jax._src.config.gs.extra_jit_context->context._replace(**kw)
A:jax._src.config.tls->jax._src.lib.jax_jit.thread_local_state()
A:jax._src.config.tls.extra_jit_context->context._replace(**kw)
A:jax._src.config.jax2tf_associative_scan_reductions->Config().define_bool_state(name='jax2tf_associative_scan_reductions', default=False, help='JAX has two separate lowering rules for the cumulative reduction primitives (cumsum, cumprod, cummax, cummin). On CPUs and GPUs it uses a lax.associative_scan, while for TPUs it uses the HLO ReduceWindow. The latter has a slow implementation on CPUs and GPUs. By default, jax2tf uses the TPU lowering. Set this flag to True to use the associative scan lowering usage, and only if it makes a difference for your application. See the jax2tf README.md for more details.')
A:jax._src.config.enable_checks->Config().define_bool_state(name='jax_enable_checks', default=False, help='Turn on invariant checking for JAX internals. Makes things slower.')
A:jax._src.config.check_tracer_leaks->Config().define_bool_state(name='jax_check_tracer_leaks', default=False, help='Turn on checking for leaked tracers as soon as a trace completes. Enabling leak checking may have performance impacts: some caching is disabled, and other overheads may be added. Additionally, be aware that some Python debuggers can cause false positives, so it is recommended to disable any debuggers while leak checking is enabled.')
A:jax._src.config.checking_leaks->functools.partial(check_tracer_leaks, True)
A:jax._src.config.debug_nans->Config().define_bool_state(name='jax_debug_nans', default=False, help='Add nan checks to every operation. When a nan is detected on the output of a jit-compiled computation, call into the un-compiled version in an attempt to more precisely identify the operation which produced the nan.')
A:jax._src.config.debug_infs->Config().define_bool_state(name='jax_debug_infs', default=False, help='Add inf checks to every operation. When an inf is detected on the output of a jit-compiled computation, call into the un-compiled version in an attempt to more precisely identify the operation which produced the inf.')
A:jax._src.config.log_compiles->Config().define_bool_state(name='jax_log_compiles', default=False, help='Log a message each time every time `jit` or `pmap` compiles an XLA computation. Logging is performed with `absl.logging`. When this option is set, the log level is WARNING; otherwise the level is DEBUG.')
A:jax._src.config.parallel_functions_output_gda->Config().define_bool_state(name='jax_parallel_functions_output_gda', default=False, help='If True, pjit will output GSDAs.')
A:jax._src.config.distributed_debug->Config().define_bool_state(name='jax_distributed_debug', default=False, help='Enable logging useful for debugging multi-process distributed computations. Logging is performed with `absl.logging` at WARNING level.')
A:jax._src.config.enable_custom_prng->Config().define_bool_state(name='jax_enable_custom_prng', default=False, upgrade=True, help='Enables an internal upgrade that allows one to define custom pseudo-random number generator implementations.')
A:jax._src.config.default_prng_impl->Config().define_enum_state(name='jax_default_prng_impl', enum_values=['threefry2x32', 'rbg', 'unsafe_rbg'], default='threefry2x32', help='Select the default PRNG implementation, used when one is not explicitly provided at seeding time.')
A:jax._src.config.enable_custom_vjp_by_custom_transpose->Config().define_bool_state(name='jax_enable_custom_vjp_by_custom_transpose', default=False, upgrade=True, help='Enables an internal upgrade that implements `jax.custom_vjp` by reduction to `jax.custom_jvp` and `jax.custom_transpose`.')
A:jax._src.config.hlo_source_file_canonicalization_regex->Config().define_string_state(name='jax_hlo_source_file_canonicalization_regex', default=None, help='Used to canonicalize the source_path metadata of HLO instructions by removing the given regex. If set, re.sub() is called on each source_file with the given regex, and all matches are removed. This can be used to avoid spurious cache misses when using the persistent compilation cache, which includes HLO metadata in the cache key.')
A:jax._src.config.enable_x64->Config().define_bool_state(name='jax_enable_x64', default=False, help='Enable 64-bit types to be used', update_global_hook=_update_x64_global, update_thread_local_hook=_update_x64_thread_local)
A:jax._src.config.disable_jit->Config().define_bool_state(name='jax_disable_jit', default=False, help='Disable JIT compilation and just call original Python.', update_global_hook=_update_disable_jit_global, update_thread_local_hook=_update_disable_jit_thread_local)
A:jax._src.config.numpy_rank_promotion->Config().define_enum_state(name='jax_numpy_rank_promotion', enum_values=['allow', 'warn', 'raise'], default='allow', help='Control NumPy-style automatic rank promotion broadcasting ("allow", "warn", or "raise").', update_global_hook=lambda val: update_global_jit_state(numpy_rank_promotion=val), update_thread_local_hook=lambda val: update_thread_local_jit_state(numpy_rank_promotion=val))
A:jax._src.config.default_matmul_precision->Config().define_enum_state(name='jax_default_matmul_precision', enum_values=['bfloat16', 'tensorfloat32', 'float32'], default=None, help="Control the default matmul and conv precision for 32bit inputs.\n\nSome platforms, like TPU, offer configurable precision levels for matrix multiplication and convolution computations, trading off accuracy for speed. The precision can be controlled for each operation; for example, see the :func:`jax.lax.conv_general_dilated` and :func:`jax.lax.dot` docstrings. But it can be useful to control the default behavior obtained when an operation is not given a specific precision.\n\nThis option can be used to control the default precision level for computations involved in matrix multiplication and convolution on 32bit inputs. The levels roughly describe the precision at which scalar products are computed. The 'bfloat16' option is the fastest and least precise; 'float32' is similar to full float32 precision; 'tensorfloat32' is intermediate.\n\n", update_global_hook=lambda val: update_global_jit_state(default_matmul_precision=val), update_thread_local_hook=lambda val: update_thread_local_jit_state(default_matmul_precision=val))
A:jax._src.config.traceback_filtering->Config().define_enum_state(name='jax_traceback_filtering', enum_values=['off', 'tracebackhide', 'remove_frames', 'auto'], default='auto', help='Controls how JAX filters internal frames out of tracebacks.\n\nValid values are:\n * "off": disables traceback filtering.\n * "auto": use "tracebackhide" if running under a sufficiently new IPython, or "remove_frames" otherwise.\n * "tracebackhide": adds "__tracebackhide__" annotations to  hidden stack frames, which some traceback printers support.\n * "remove_frames": removes hidden frames from tracebacks, and adds  the unfiltered traceback as a __cause__ of the exception.\n')
A:jax._src.config.bcoo_cusparse_lowering->Config().define_bool_state(name='jax_bcoo_cusparse_lowering', default=False, help='Enables lowering BCOO ops to cuSparse.')
A:jax._src.config.state->jax._src.lib.transfer_guard_lib.thread_local_state()
A:jax._src.config.transfer_guard_host_to_device->Config().define_enum_state(name='jax_transfer_guard_host_to_device', enum_values=['allow', 'log', 'disallow', 'log_explicit', 'disallow_explicit'], default=None, help='Select the transfer guard level for host-to-device transfers. Default is "allow".', update_global_hook=lambda val: _update_transfer_guard(transfer_guard_lib.global_state(), 'host_to_device', val), update_thread_local_hook=lambda val: _update_transfer_guard(transfer_guard_lib.thread_local_state(), 'host_to_device', val))
A:jax._src.config.transfer_guard_device_to_device->Config().define_enum_state(name='jax_transfer_guard_device_to_device', enum_values=['allow', 'log', 'disallow', 'log_explicit', 'disallow_explicit'], default=None, help='Select the transfer guard level for device-to-device transfers. Default is "allow".', update_global_hook=lambda val: _update_transfer_guard(transfer_guard_lib.global_state(), 'device_to_device', val), update_thread_local_hook=lambda val: _update_transfer_guard(transfer_guard_lib.thread_local_state(), 'device_to_device', val))
A:jax._src.config.transfer_guard_device_to_host->Config().define_enum_state(name='jax_transfer_guard_device_to_host', enum_values=['allow', 'log', 'disallow', 'log_explicit', 'disallow_explicit'], default=None, help='Select the transfer guard level for device-to-host transfers. Default is "allow".', update_global_hook=lambda val: _update_transfer_guard(transfer_guard_lib.global_state(), 'device_to_host', val), update_thread_local_hook=lambda val: _update_transfer_guard(transfer_guard_lib.thread_local_state(), 'device_to_host', val))
A:jax._src.config._transfer_guard->Config().define_enum_state(name='jax_transfer_guard', enum_values=['allow', 'log', 'disallow', 'log_explicit', 'disallow_explicit'], default=None, help='Select the transfer guard level for all transfers. This option is set-only; the transfer guard level for a specific direction should be read using the per-transfer direction option. Default is "allow".', update_global_hook=_update_all_transfer_guard_global)
jax._src._config_module.Config(self)
jax._src._config_module.Config.DEFINE_bool(self,name,default,*args,**kwargs)
jax._src._config_module.Config.DEFINE_enum(self,name,default,*args,**kwargs)
jax._src._config_module.Config.DEFINE_integer(self,name,default,*args,**kwargs)
jax._src._config_module.Config.DEFINE_string(self,name,default,*args,**kwargs)
jax._src._config_module.Config._config_module_with_absl(self)
jax._src._config_module.Config._read(self,name)
jax._src._config_module.Config._trace_context(self)
jax._src._config_module.Config.add_option(self,name,default,opt_type,meta_args,meta_kwargs,update_hook=None)
jax._src._config_module.Config.check_exists(self,name)
jax._src._config_module.Config.complete_absl__config_module(self,absl_flags)
jax._src._config_module.Config.define_bool_state(self,name:str,default:bool,help:str,*,update_global_hook:Optional[Callable[[bool],None]]=None,update_thread_local_hook:Optional[Callable[[Optional[bool]],None]]=None,upgrade:bool=False,extra_description:str='')
jax._src._config_module.Config.define_enum_state(self,name:str,enum_values:List[str],default:Optional[str],help:str,update_global_hook:Optional[Callable[[str],None]]=None,update_thread_local_hook:Optional[Callable[[Optional[str]],None]]=None)
jax._src._config_module.Config.define_string_state(self,name:str,default:Optional[str],help:str,update_global_hook:Optional[Callable[[str],None]]=None,update_thread_local_hook:Optional[Callable[[Optional[str]],None]]=None)
jax._src._config_module.Config.disable_omnistaging(self)
jax._src._config_module.Config.enable_omnistaging(self)
jax._src._config_module.Config.parse_flags_with_absl(self)
jax._src._config_module.Config.read(self,name)
jax._src._config_module.Config.update(self,name,val)
jax._src._config_module.GlobalJitState(NamedTuple)
jax._src._config_module.NameSpace(self,getter,setter)
jax._src._config_module.NameSpace.__getattr__(self,name)
jax._src._config_module.NameSpace.__setattr__(self,name,val)
jax._src._config_module.ThreadLocalJitState(NamedTuple)
jax._src._config_module._StateContextManager(self,name,help,update_thread_local_hook,validate_new_val_hook:Optional[Callable[[Any],None]]=None,extra_description:str='')
jax._src._config_module._StateContextManager._add_hooks(self,update_global_hook,update_thread_local_hook)
jax._src._config_module._Unset
jax._src._config_module._update_disable_jit_global(val)
jax._src._config_module._update_disable_jit_thread_local(val)
jax._src._config_module._update_x64_global(val)
jax._src._config_module._update_x64_thread_local(val)
jax._src._config_module.bool_env(varname:str,default:bool)->bool
jax._src._config_module.int_env(varname:str,default:int)->int
jax._src._config_module.update_global_jit_state(**kw)
jax._src._config_module.update_thread_local_jit_state(**kw)
jax._src.config.Config(self)
jax._src.config.Config.DEFINE_bool(self,name,default,*args,**kwargs)
jax._src.config.Config.DEFINE_enum(self,name,default,*args,**kwargs)
jax._src.config.Config.DEFINE_integer(self,name,default,*args,**kwargs)
jax._src.config.Config.DEFINE_string(self,name,default,*args,**kwargs)
jax._src.config.Config.__init__(self)
jax._src.config.Config._read(self,name)
jax._src.config.Config._trace_context(self)
jax._src.config.Config.add_option(self,name,default,opt_type,meta_args,meta_kwargs,update_hook=None)
jax._src.config.Config.check_exists(self,name)
jax._src.config.Config.complete_absl_config(self,absl_flags)
jax._src.config.Config.config_with_absl(self)
jax._src.config.Config.define_bool_state(self,name:str,default:bool,help:str,*,update_global_hook:Optional[Callable[[bool],None]]=None,update_thread_local_hook:Optional[Callable[[Optional[bool]],None]]=None,upgrade:bool=False,extra_description:str='')
jax._src.config.Config.define_enum_state(self,name:str,enum_values:List[str],default:Optional[str],help:str,update_global_hook:Optional[Callable[[str],None]]=None,update_thread_local_hook:Optional[Callable[[Optional[str]],None]]=None)
jax._src.config.Config.define_string_state(self,name:str,default:Optional[str],help:str,update_global_hook:Optional[Callable[[str],None]]=None,update_thread_local_hook:Optional[Callable[[Optional[str]],None]]=None)
jax._src.config.Config.disable_omnistaging(self)
jax._src.config.Config.enable_omnistaging(self)
jax._src.config.Config.parse_flags_with_absl(self)
jax._src.config.Config.read(self,name)
jax._src.config.Config.update(self,name,val)
jax._src.config.GlobalJitState(NamedTuple)
jax._src.config.NameSpace(self,getter,setter)
jax._src.config.NameSpace.__getattr__(self,name)
jax._src.config.NameSpace.__init__(self,getter,setter)
jax._src.config.NameSpace.__setattr__(self,name,val)
jax._src.config.ThreadLocalJitState(NamedTuple)
jax._src.config._StateContextManager(self,name,help,update_thread_local_hook,validate_new_val_hook:Optional[Callable[[Any],None]]=None,extra_description:str='')
jax._src.config._StateContextManager.__init__(self,name,help,update_thread_local_hook,validate_new_val_hook:Optional[Callable[[Any],None]]=None,extra_description:str='')
jax._src.config._StateContextManager._add_hooks(self,update_global_hook,update_thread_local_hook)
jax._src.config._Unset
jax._src.config._update_disable_jit_global(val)
jax._src.config._update_disable_jit_thread_local(val)
jax._src.config._update_x64_global(val)
jax._src.config._update_x64_thread_local(val)
jax._src.config.bool_env(varname:str,default:bool)->bool
jax._src.config.int_env(varname:str,default:int)->int
jax._src.config.update_global_jit_state(**kw)
jax._src.config.update_thread_local_jit_state(**kw)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/tree_util.py----------------------------------------
A:jax._src.tree_util.T->TypeVar('T')
A:jax._src.tree_util.U->TypeVar('U')
A:jax._src.tree_util.lst->list(iterable)
A:jax._src.tree_util._Children->TypeVar('_Children', bound=Iterable[Any])
A:jax._src.tree_util._AuxData->TypeVar('_AuxData', bound=Hashable)
A:jax._src.tree_util._registry[nodetype]->_RegistryEntry(flatten_func, unflatten_func)
A:jax._src.tree_util.(leaves, treedef)->jax._src.lib.pytree.flatten(tree)
A:jax._src.tree_util.(flat, treedef)->tree_flatten(pytree_to_transpose)
A:jax._src.tree_util.expected_treedef->outer_treedef.compose(inner_treedef)
A:jax._src.tree_util.flat->iter(flat)
A:jax._src.tree_util.transposed_lol->zip(*lol)
A:jax._src.tree_util.subtrees->map(partial(tree_unflatten, outer_treedef), transposed_lol)
A:jax._src.tree_util._RegistryEntry->collections.namedtuple('_RegistryEntry', ['to_iter', 'from_iter'])
A:jax._src.tree_util.handler->_keypath_registry.get(type(pytree))
A:jax._src.tree_util.(children, metadata)->_keypath_registry.get(type(pytree)).to_iter(tree)
A:jax._src.tree_util.children->iter(tree)
A:jax._src.tree_util.no_initializer->object()
A:jax._src.tree_util.func->_HashableCallableShim(original_func)
A:jax._src.tree_util.out->super(Partial, klass).__new__(klass, func, *args, **kw)
A:jax._src.tree_util.(children, meta)->_keypath_registry.get(type(pytree)).to_iter(pytree)
A:jax._src.tree_util.num_children->len(treedef_children(tree_structure(pytree)))
A:jax._src.tree_util.(prefix_tree_children, prefix_tree_meta)->flatten_one_level(prefix_tree)
A:jax._src.tree_util.(full_tree_children, full_tree_meta)->flatten_one_level(full_tree)
A:jax._src.tree_util.prefix_tree_meta_str->str(prefix_tree_meta)
A:jax._src.tree_util.full_tree_meta_str->str(full_tree_meta)
A:jax._src.tree_util.metadata_diff->textwrap.indent('\n'.join(difflib.ndiff(prefix_tree_meta_str.splitlines(), full_tree_meta_str.splitlines())), prefix='    ')
A:jax._src.tree_util.keys->_child_keys(prefix_tree)
A:jax._src.tree_util.keys_->_child_keys(full_tree)
jax._src.tree_util.AttributeKeyPathEntry(KeyPathEntry)
jax._src.tree_util.AttributeKeyPathEntry.pprint(self)->str
jax._src.tree_util.FlattenedKeyPathEntry(KeyPathEntry)
jax._src.tree_util.FlattenedKeyPathEntry.pprint(self)->str
jax._src.tree_util.GetitemKeyPathEntry(KeyPathEntry)
jax._src.tree_util.GetitemKeyPathEntry.pprint(self)->str
jax._src.tree_util.KeyPath(NamedTuple)
jax._src.tree_util.KeyPath.__add__(self,other)
jax._src.tree_util.KeyPath.pprint(self)->str
jax._src.tree_util.KeyPathEntry(NamedTuple)
jax._src.tree_util.KeyPathEntry.pprint(self)->str
jax._src.tree_util.Partial(klass,func,*args,**kw)
jax._src.tree_util.Partial.__new__(klass,func,*args,**kw)
jax._src.tree_util._HashableCallableShim(self,fun)
jax._src.tree_util._HashableCallableShim.__eq__(self,other)
jax._src.tree_util._HashableCallableShim.__hash__(self)
jax._src.tree_util._HashableCallableShim.__init__(self,fun)
jax._src.tree_util._child_keys(pytree:Any)->List[KeyPathEntry]
jax._src.tree_util._prefix_error(key_path:KeyPath,prefix_tree:Any,full_tree:Any,is_leaf:Optional[Callable[[Any],bool]]=None)->Iterable[Callable[[str], ValueError]]
jax._src.tree_util._process_pytree(process_node,tree)
jax._src.tree_util._replace_nones(sentinel,tree)
jax._src.tree_util.all_leaves(iterable,is_leaf:Optional[Callable[[Any],bool]]=None)
jax._src.tree_util.broadcast_prefix(prefix_tree:Any,full_tree:Any,is_leaf:Optional[Callable[[Any],bool]]=None)->List[Any]
jax._src.tree_util.build_tree(treedef,xs)
jax._src.tree_util.flatten_one_level(pytree:Any)->Tuple[List[Any], Hashable]
jax._src.tree_util.prefix_errors(prefix_tree:Any,full_tree:Any,is_leaf:Optional[Callable[[Any],bool]]=None)->List[Callable[[str], ValueError]]
jax._src.tree_util.register_keypaths(ty:Type,handler:Callable[[Any],List[KeyPathEntry]])->None
jax._src.tree_util.register_pytree_node(nodetype:Type[T],flatten_func:Callable[[T],Tuple[_Children,_AuxData]],unflatten_func:Callable[[_AuxData,_Children],T])
jax._src.tree_util.register_pytree_node_class(cls)
jax._src.tree_util.tree_all(tree)
jax._src.tree_util.tree_flatten(tree,is_leaf:Optional[Callable[[Any],bool]]=None)
jax._src.tree_util.tree_leaves(tree,is_leaf:Optional[Callable[[Any],bool]]=None)
jax._src.tree_util.tree_map(f:Callable[...,Any],tree:Any,*rest:Any,is_leaf:Optional[Callable[[Any],bool]]=None)->Any
jax._src.tree_util.tree_multimap(*args,**kwargs)
jax._src.tree_util.tree_reduce(function:Callable[[T,Any],T],tree:Any,initializer:Any=no_initializer)->T
jax._src.tree_util.tree_structure(tree,is_leaf:Optional[Callable[[Any],bool]]=None)
jax._src.tree_util.tree_transpose(outer_treedef,inner_treedef,pytree_to_transpose)
jax._src.tree_util.tree_unflatten(treedef,leaves)
jax._src.tree_util.treedef_children(treedef)
jax._src.tree_util.treedef_is_leaf(treedef)
jax._src.tree_util.treedef_tuple(treedefs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/pretty_printer.py----------------------------------------
A:jax._src.pretty_printer._nil->_NilDoc()
A:jax._src.pretty_printer.self.children->list(children)
A:jax._src.pretty_printer.Color->enum.Enum('_Color', ['BLACK', 'RED', 'GREEN', 'YELLOW', 'BLUE', 'MAGENTA', 'CYAN', 'WHITE', 'RESET'])
A:jax._src.pretty_printer.Intensity->enum.Enum('_Intensity', ['DIM', 'NORMAL', 'BRIGHT'])
A:jax._src.pretty_printer._BreakMode->enum.Enum('_BreakMode', ['FLAT', 'BREAK'])
A:jax._src.pretty_printer.(i, m, doc)->agenda.pop()
A:jax._src.pretty_printer.doc->agenda.pop()
A:jax._src.pretty_printer.maxlen->max((l.width for l in lines))
A:jax._src.pretty_printer.default_colors->_ColorState(Color.RESET, Color.RESET, Intensity.NORMAL)
A:jax._src.pretty_printer.annotation_colors->_ColorState(Color.RESET, Color.RESET, Intensity.DIM)
A:jax._src.pretty_printer.(i, m, doc, color)->agenda.pop()
A:jax._src.pretty_printer.(color_state, color_str)->_update_color(use_color, color_state, default_colors)
A:jax._src.pretty_printer.color->_ColorState(doc.foreground or color.foreground, doc.background or color.background, doc.intensity or color.intensity)
A:jax._src.pretty_printer.lines->_align_annotations(lines)
A:jax._src.pretty_printer.out->'\n'.join((l.text if l.annotations is None else f'{l.text}{annotation_prefix}{l.annotations}' for l in lines))
A:jax._src.pretty_printer.docs->list(docs)
A:jax._src.pretty_printer.type_annotation->partial(color, intensity=Intensity.NORMAL, foreground=Color.MAGENTA)
A:jax._src.pretty_printer.keyword->partial(color, intensity=Intensity.BRIGHT, foreground=Color.BLUE)
jax._src.pretty_printer.Doc(abc.ABC)
jax._src.pretty_printer.Doc.__add__(self,other:'Doc')->'Doc'
jax._src.pretty_printer.Doc.__str__(self)
jax._src.pretty_printer.Doc.format(self,width:int=80,use_color:bool=False,annotation_prefix='#')->str
jax._src.pretty_printer._BreakDoc(self,text:str)
jax._src.pretty_printer._BreakDoc.__init__(self,text:str)
jax._src.pretty_printer._BreakDoc.__repr__(self)
jax._src.pretty_printer._ColorDoc(self,child:Doc,*,foreground:Optional[Color]=None,background:Optional[Color]=None,intensity:Optional[Intensity]=None)
jax._src.pretty_printer._ColorDoc.__init__(self,child:Doc,*,foreground:Optional[Color]=None,background:Optional[Color]=None,intensity:Optional[Intensity]=None)
jax._src.pretty_printer._ColorState(NamedTuple)
jax._src.pretty_printer._ConcatDoc(self,children:Sequence[Doc])
jax._src.pretty_printer._ConcatDoc.__init__(self,children:Sequence[Doc])
jax._src.pretty_printer._ConcatDoc.__repr__(self)
jax._src.pretty_printer._GroupDoc(self,child:Doc)
jax._src.pretty_printer._GroupDoc.__init__(self,child:Doc)
jax._src.pretty_printer._GroupDoc.__repr__(self)
jax._src.pretty_printer._Line(NamedTuple)
jax._src.pretty_printer._NestDoc(self,n:int,child:Doc)
jax._src.pretty_printer._NestDoc.__init__(self,n:int,child:Doc)
jax._src.pretty_printer._NestDoc.__repr__(self)
jax._src.pretty_printer._NilDoc(Doc)
jax._src.pretty_printer._NilDoc.__repr__(self)
jax._src.pretty_printer._State(NamedTuple)
jax._src.pretty_printer._TextDoc(self,text:str,annotation:Optional[str]=None)
jax._src.pretty_printer._TextDoc.__init__(self,text:str,annotation:Optional[str]=None)
jax._src.pretty_printer._TextDoc.__repr__(self)
jax._src.pretty_printer._align_annotations(lines)
jax._src.pretty_printer._fits(doc:Doc,width:int,agenda:List[Tuple[int,_BreakMode,Doc]])->bool
jax._src.pretty_printer._format(doc:Doc,width:int,*,use_color,annotation_prefix)->str
jax._src.pretty_printer._sparse(doc:Doc)->bool
jax._src.pretty_printer._update_color(use_color:bool,state:_ColorState,update:_ColorState)->Tuple[_ColorState, str]
jax._src.pretty_printer.brk(text:str='')->Doc
jax._src.pretty_printer.color(doc:Doc,*,foreground:Optional[Color]=None,background:Optional[Color]=None,intensity:Optional[Intensity]=None)
jax._src.pretty_printer.concat(docs:Sequence[Doc])->Doc
jax._src.pretty_printer.group(doc:Doc)->Doc
jax._src.pretty_printer.join(sep:Doc,docs:Sequence[Doc])->Doc
jax._src.pretty_printer.nest(n:int,doc:Doc)->Doc
jax._src.pretty_printer.nil()->Doc
jax._src.pretty_printer.text(s:str,annotation:Optional[str]=None)->Doc


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/dlpack.py----------------------------------------
A:jax._src.dlpack.SUPPORTED_DTYPES->frozenset({jnp.int8, jnp.int16, jnp.int32, jnp.int64, jnp.uint8, jnp.uint16, jnp.uint32, jnp.uint64, jnp.float16, jnp.bfloat16, jnp.float32, jnp.float64})
A:jax._src.dlpack.cpu_backend->jax._src.lib.xla_bridge.get_backend('cpu')
A:jax._src.dlpack.gpu_backend->jax._src.lib.xla_bridge.get_backend('gpu')
A:jax._src.dlpack.buf->jax._src.lib.xla_client._xla.dlpack_managed_tensor_to_buffer(dlpack, cpu_backend, gpu_backend)
A:jax._src.dlpack.xla_shape->jax._src.lib.xla_client._xla.dlpack_managed_tensor_to_buffer(dlpack, cpu_backend, gpu_backend).xla_shape()
A:jax._src.dlpack.aval->jax.core.ShapedArray(xla_shape.dimensions(), xla_shape.numpy_dtype())
jax._src.dlpack.from_dlpack(dlpack)
jax._src.dlpack.to_dlpack(x:device_array.DeviceArrayProtocol,take_ownership:bool=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/ad_util.py----------------------------------------
jax._src.ad_util.Zero(self,aval)
jax._src.ad_util.Zero.__init__(self,aval)
jax._src.ad_util.Zero.__repr__(self)
jax._src.ad_util.Zero.from_value(val)
jax._src.ad_util._stop_gradient_impl(x)
jax._src.ad_util.add_abstract(xs,ys)
jax._src.ad_util.add_impl(xs,ys)
jax._src.ad_util.add_jaxvals(x,y)
jax._src.ad_util.zeros_like_aval(aval)
jax._src.ad_util.zeros_like_impl(example)
jax._src.ad_util.zeros_like_jaxval(val)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/profiler.py----------------------------------------
A:jax._src.profiler.self.lock->threading.Lock()
A:jax._src.profiler._profile_state->_ProfileState()
A:jax._src.profiler._profile_state.profile_session->jax._src.lib.xla_client.profiler.ProfilerSession()
A:jax._src.profiler.profile->device_memory_profile(backend)
jax._src.profiler.StepTraceAnnotation(self,name:str,**kwargs)
jax._src.profiler.StepTraceAnnotation.__init__(self,name:str,**kwargs)
jax._src.profiler.StepTraceContext(self,*args,**kwargs)
jax._src.profiler.StepTraceContext.__init__(self,*args,**kwargs)
jax._src.profiler.TraceAnnotation(xla_client.profiler.TraceMe)
jax._src.profiler.TraceContext(self,*args,**kwargs)
jax._src.profiler.TraceContext.__init__(self,*args,**kwargs)
jax._src.profiler._ProfileState(self)
jax._src.profiler._ProfileState.__init__(self)
jax._src.profiler.annotate_function(func:Callable,name:Optional[str]=None,**decorator_kwargs)
jax._src.profiler.device_memory_profile(backend:Optional[str]=None)->bytes
jax._src.profiler.save_device_memory_profile(filename,backend:Optional[str]=None)
jax._src.profiler.start_server(port:int)
jax._src.profiler.start_trace(log_dir)
jax._src.profiler.stop_trace()
jax._src.profiler.trace(log_dir)
jax._src.profiler.trace_function(*args,**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/cloud_tpu_init.py----------------------------------------
A:jax._src.cloud_tpu_init.worker_id->get_metadata('agent-worker-number')
A:jax._src.cloud_tpu_init.accelerator_type->get_metadata('accelerator-type')
A:jax._src.cloud_tpu_init.worker_network_endpoints->get_metadata('worker-network-endpoints')
jax._cloud_tpu_init()
jax._src.cloud_tpu_init.cloud_tpu_init()


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/distributed.py----------------------------------------
A:jax._src.distributed._service->jax._src.lib.xla_extension.get_distributed_runtime_service(coordinator_address, num_processes)
A:jax._src.distributed.client->jax._src.lib.xla_extension.get_distributed_runtime_client(coordinator_address, process_id)
A:jax._src.distributed.factory->functools.partial(xla_client.make_gpu_client, client, process_id)
jax._src.distributed.initialize(coordinator_address:str,num_processes:int,process_id:int)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/errors.py----------------------------------------
jax._src.errors.ConcretizationTypeError(self,tracer:'core.Tracer',context:str='')
jax._src.errors.ConcretizationTypeError.__init__(self,tracer:'core.Tracer',context:str='')
jax._src.errors.JAXIndexError(_JAXErrorMixin,IndexError)
jax._src.errors.JAXTypeError(_JAXErrorMixin,TypeError)
jax._src.errors.NonConcreteBooleanIndexError(self,tracer:'core.Tracer')
jax._src.errors.NonConcreteBooleanIndexError.__init__(self,tracer:'core.Tracer')
jax._src.errors.TracerArrayConversionError(self,tracer:'core.Tracer')
jax._src.errors.TracerArrayConversionError.__init__(self,tracer:'core.Tracer')
jax._src.errors.TracerIntegerConversionError(self,tracer:'core.Tracer')
jax._src.errors.TracerIntegerConversionError.__init__(self,tracer:'core.Tracer')
jax._src.errors.UnexpectedTracerError(self,msg:str)
jax._src.errors.UnexpectedTracerError.__init__(self,msg:str)
jax._src.errors._JAXErrorMixin(self,message:str)
jax._src.errors._JAXErrorMixin.__init__(self,message:str)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/test_util.py----------------------------------------
A:jax._src.test_util.arr->numpy.asarray(arr)
A:jax._src.test_util.dtype->numpy.dtype(dtype)
A:jax._src.test_util.result->func(*args, **kwargs)
A:jax._src.test_util.tol1->_normalize_tolerance(tol1)
A:jax._src.test_util.tol2->_normalize_tolerance(tol2)
A:jax._src.test_util.out[k]->max(v, tol1.get(k, 0))
A:jax._src.test_util.assert_close->partial(_assert_numpy_allclose, err_msg=err_msg)
A:jax._src.test_util.device_tags->_get_device_tags()
A:jax._src.test_util.test_name->getattr(test_method, '__name__', '[unknown test]')
A:jax._src.test_util.prev_xla_flags->os.getenv('XLA_FLAGS')
A:jax._src.test_util.flag_value->jax._src.config.config._read(flag_name)
A:jax._src.test_util.NUMPY_SCALAR_SHAPE->_NumpyScalar()
A:jax._src.test_util.PYTHON_SCALAR_SHAPE->_PythonScalar()
A:jax._src.test_util.shape->tuple(shape)
A:jax._src.test_util.shapestr->','.join((str(dim) for dim in shape))
A:jax._src.test_util.vals->numpy.where(zeros, np.array(0, dtype=dtype), vals)
A:jax._src.test_util.x_ravel->numpy.asarray(x).ravel()
A:jax._src.test_util.base_rand->rand_default(rng)
A:jax._src.test_util.dims->_dims_of_shape(shape)
A:jax._src.test_util.r->numpy.random.RandomState(42).rand(*dims)
A:jax._src.test_util.jaxpr->jax._src.api.make_jaxpr(fun)(*args)
A:jax._src.test_util.msg->'Unexpected precision: {} != {}'.format(expected_precision, precision)
A:jax._src.test_util.xs->list(xs)
A:jax._src.test_util.n->len(xs)
A:jax._src.test_util.k->min(n, FLAGS.num_generated_cases)
A:jax._src.test_util.indices->_CACHED_INDICES.get(n)
A:jax._src.test_util.rng->numpy.random.RandomState(42)
A:jax._src.test_util._CACHED_INDICES[n]indices->numpy.random.RandomState(42).permutation(n)
A:jax._src.test_util.seen->set()
A:jax._src.test_util.x->numpy.asarray(x)
A:jax._src.test_util.cases->list(gen(choose_one))
A:jax._src.test_util.names->super().getTestCaseNames(testCaseClass)
A:jax._src.test_util.pattern->re.compile(FLAGS.exclude_test_targets)
A:jax._src.test_util.self._original_config[key]->jax._src.config.config._read(key)
A:jax._src.test_util.self._rng->numpy.random.RandomState(zlib.adler32(self._testMethodName.encode()))
A:jax._src.test_util.atol->max(tolerance(_dtype(x), atol), tolerance(_dtype(y), atol))
A:jax._src.test_util.rtol->max(tolerance(_dtype(x), rtol), tolerance(_dtype(y), rtol))
A:jax._src.test_util.y->numpy.asarray(y)
A:jax._src.test_util.expected->textwrap.dedent(expected)
A:jax._src.test_util.what->textwrap.dedent(what)
A:jax._src.test_util.ignore_space_re->re.compile('\\s*\\n\\s*')
A:jax._src.test_util.expected_clean->re.sub(ignore_space_re, '\n', expected.strip())
A:jax._src.test_util.what_clean->re.sub(ignore_space_re, '\n', what.strip())
A:jax._src.test_util.args->args_maker()
A:jax._src.test_util.python_ans->fun(*args)
A:jax._src.test_util.python_shapes->tree_map(lambda x: np.shape(x), python_ans)
A:jax._src.test_util.np_shapes->tree_map(lambda x: np.shape(np.asarray(x)), python_ans)
A:jax._src.test_util.cfun->jax._src.api.jit(wrapped_fun)
A:jax._src.test_util.monitored_ans->cfun(*args)
A:jax._src.test_util.compiled_ans->cfun(*args)
A:jax._src.test_util.lax_ans->lax_op(*args)
A:jax._src.test_util.numpy_ans->numpy_reference_op(*args)
A:jax._src.test_util.(axis_names, shape)->unzip2(named_shape)
A:jax._src.test_util.size->prod(mesh_shape)
A:jax._src.test_util.local_devices->list(api.local_devices())
A:jax._src.test_util.mesh_devices->numpy.array(devices[:size]).reshape(mesh_shape)
A:jax._src.test_util.devices->sorted(api.devices(), key=lambda d: d.id)
A:jax._src.test_util.global_mesh->Mesh(mesh_devices, axis_names)
A:jax._src.test_util.null->object()
A:jax._src.test_util.self._value->self._method(obj)
A:jax._src.test_util.compiled->pjitted_fn.lower(*inputs, _global_avals=True).compile()
A:jax._src.test_util.(in_sharding, out_sharding)->jax.experimental.pjit._get_sharding_from_executable(compiled.runtime_executable(), mesh)
A:jax._src.test_util.supported->supported_dtypes()
A:jax._src.test_util.dtypes->_LazyDtypes()
jax._src.test_util.BufferDonationTestCase(JaxTestCase)
jax._src.test_util.BufferDonationTestCase._assertDeleted(self,x,deleted)
jax._src.test_util.DeprecatedBufferDonationTestCase(self,*args,**kwargs)
jax._src.test_util.DeprecatedBufferDonationTestCase.__init__(self,*args,**kwargs)
jax._src.test_util.DeprecatedJaxTestCase(self,*args,**kwargs)
jax._src.test_util.DeprecatedJaxTestCase.__init__(self,*args,**kwargs)
jax._src.test_util.DeprecatedJaxTestLoader(self,*args,**kwargs)
jax._src.test_util.DeprecatedJaxTestLoader.__init__(self,*args,**kwargs)
jax._src.test_util.JaxTestCase(parameterized.TestCase)
jax._src.test_util.JaxTestCase._CheckAgainstNumpy(self,numpy_reference_op,lax_op,args_maker,check_dtypes=True,tol=None,atol=None,rtol=None,canonicalize_dtypes=True)
jax._src.test_util.JaxTestCase._CompileAndCheck(self,fun,args_maker,*,check_dtypes=True,rtol=None,atol=None,check_cache_misses=True)
jax._src.test_util.JaxTestCase.assertAllClose(self,x,y,*,check_dtypes=True,atol=None,rtol=None,canonicalize_dtypes=True,err_msg='')
jax._src.test_util.JaxTestCase.assertArraysAllClose(self,x,y,*,check_dtypes=True,atol=None,rtol=None,err_msg='')
jax._src.test_util.JaxTestCase.assertArraysEqual(self,x,y,*,check_dtypes=True,err_msg='')
jax._src.test_util.JaxTestCase.assertDtypesMatch(self,x,y,*,canonicalize_dtypes=True)
jax._src.test_util.JaxTestCase.assertMultiLineStrippedEqual(self,expected,what)
jax._src.test_util.JaxTestCase.rng(self)
jax._src.test_util.JaxTestCase.setUp(self)
jax._src.test_util.JaxTestCase.tearDown(self)
jax._src.test_util.JaxTestLoader(absltest.TestLoader)
jax._src.test_util.JaxTestLoader.getTestCaseNames(self,testCaseClass)
jax._src.test_util.ScalarShape(object)
jax._src.test_util.ScalarShape.__len__(self)
jax._src.test_util._LazyDtypes
jax._src.test_util._LazyDtypes.all(self)
jax._src.test_util._LazyDtypes.all_floating(self)
jax._src.test_util._LazyDtypes.all_inexact(self)
jax._src.test_util._LazyDtypes.all_integer(self)
jax._src.test_util._LazyDtypes.all_unsigned(self)
jax._src.test_util._LazyDtypes.boolean(self)
jax._src.test_util._LazyDtypes.complex(self)
jax._src.test_util._LazyDtypes.floating(self)
jax._src.test_util._LazyDtypes.inexact(self)
jax._src.test_util._LazyDtypes.integer(self)
jax._src.test_util._LazyDtypes.numeric(self)
jax._src.test_util._LazyDtypes.supported(self,dtypes)
jax._src.test_util._LazyDtypes.unsigned(self)
jax._src.test_util._NumpyScalar(ScalarShape)
jax._src.test_util._PythonScalar(ScalarShape)
jax._src.test_util._XLAShardingInfo(NamedTuple)
jax._src.test_util._cached_property(self,method)
jax._src.test_util._cached_property.__get__(self,obj,cls)
jax._src.test_util._cached_property.__init__(self,method)
jax._src.test_util._cast_to_shape(value,shape,dtype)
jax._src.test_util._dims_of_shape(shape)
jax._src.test_util._format_shape_dtype_string(shape,dtype)
jax._src.test_util._get_device_tags()
jax._src.test_util._normalize_tolerance(tol)
jax._src.test_util._rand_dtype(rand,shape,dtype,scale=1.0,post=lambdax:x)
jax._src.test_util.assert_dot_precision(expected_precision,fun,*args)
jax._src.test_util.assert_num_jit_and_pmap_compilations(times)
jax._src.test_util.cases_from_gens(*gens)
jax._src.test_util.cases_from_list(xs)
jax._src.test_util.check_eq(xs,ys,err_msg='')
jax._src.test_util.check_raises(thunk,err_type,msg)
jax._src.test_util.check_raises_regexp(thunk,err_type,pattern)
jax._src.test_util.compile_and_get_sharding(pjitted_fn,mesh,global_inputs)
jax._src.test_util.count_device_put()
jax._src.test_util.count_jit_and_pmap_compiles()
jax._src.test_util.count_primitive_compiles()
jax._src.test_util.create_global_mesh(mesh_shape,axis_names)
jax._src.test_util.dtype_str(dtype)
jax._src.test_util.format_shape_dtype_string(shape,dtype)
jax._src.test_util.format_test_name_suffix(opname,shapes,dtypes)
jax._src.test_util.if_device_under_test(device_type:Union[str,Sequence[str]],if_true,if_false)
jax._src.test_util.ignore_warning(**kw)
jax._src.test_util.is_device_cuda()
jax._src.test_util.is_device_rocm()
jax._src.test_util.is_sequence(x)
jax._src.test_util.iter_eqns(jaxpr)
jax._src.test_util.join_tolerance(tol1,tol2)
jax._src.test_util.named_cases_from_sampler(gen)
jax._src.test_util.num_float_bits(dtype)
jax._src.test_util.rand_bool(rng)
jax._src.test_util.rand_default(rng,scale=3)
jax._src.test_util.rand_fullrange(rng,standardize_nans=False)
jax._src.test_util.rand_int(rng,low=0,high=None)
jax._src.test_util.rand_nonzero(rng)
jax._src.test_util.rand_not_small(rng,offset=10.0)
jax._src.test_util.rand_positive(rng)
jax._src.test_util.rand_small(rng)
jax._src.test_util.rand_small_positive(rng)
jax._src.test_util.rand_some_equal(rng)
jax._src.test_util.rand_some_inf(rng)
jax._src.test_util.rand_some_inf_and_nan(rng)
jax._src.test_util.rand_some_nan(rng)
jax._src.test_util.rand_some_zero(rng)
jax._src.test_util.rand_uniform(rng,low=0.0,high=1.0)
jax._src.test_util.rand_unique_int(rng,high=None)
jax._src.test_util.restore_spmd_lowering_flag()
jax._src.test_util.restore_spmd_manual_lowering_flag()
jax._src.test_util.set_host_platform_device_count(nr_devices:int)
jax._src.test_util.set_spmd_lowering_flag(val:bool)
jax._src.test_util.set_spmd_manual_lowering_flag(val:bool)
jax._src.test_util.skip_on_devices(*disabled_devices)
jax._src.test_util.skip_on_flag(flag_name,skip_value)
jax._src.test_util.supported_dtypes()
jax._src.test_util.to_default_dtype(arr)
jax._src.test_util.with_and_without_mesh(f)
jax._src.test_util.with_config(**kwds)
jax._src.test_util.with_jax_dtype_defaults(func,use_defaults=True)
jax._src.test_util.with_mesh(named_shape:MeshSpec)->Generator[None, None, None]
jax._src.test_util.with_mesh_from_kwargs(f)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/random.py----------------------------------------
A:jax._src.random.(key, _)->_check_prng_key(key)
A:jax._src.random.impl->default_prng_impl()
A:jax._src.random.key->vmap(prng_impl.split, in_axes=(0, None))(key, prod(a_shape[key_ndim:]))
A:jax._src.random.default_impl->default_prng_impl()
A:jax._src.random.(key, wrapped)->_check_prng_key(key)
A:jax._src.random.shape->jax.core.canonicalize_shape(shape)
A:jax._src.random.shape_->jax.lax.broadcast_shapes(shape.positional, *param_shapes)
A:jax._src.random.dtype->jax._src.dtypes.canonicalize_dtype(dtype)
A:jax._src.random.minval->jax.lax.broadcast_to_rank(minval, len(shape))
A:jax._src.random.maxval->jax.lax.broadcast_to_rank(maxval, len(shape))
A:jax._src.random.finfo->jax.numpy.finfo(dtype)
A:jax._src.random.bits->_random_bits(key, nbits, shape)
A:jax._src.random.float_bits->jax.lax.bitwise_or(lax.shift_right_logical(bits, np.array(nbits - nmant, lax.dtype(bits))), np.array(1.0, dtype).view(UINT_DTYPES[nbits]))
A:jax._src.random.maxval_out_of_range->jax.lax.gt(maxval, _convert_and_clip_integer(jnp.array(jnp.iinfo(dtype).max, dtype), maxval.dtype))
A:jax._src.random.(k1, k2)->_split(key)
A:jax._src.random.span->jax.lax.select(maxval_out_of_range & (maxval > minval), lax.add(span, _lax_const(span, 1)), span)
A:jax._src.random.multiplier->jax.lax.rem(lax.mul(multiplier, multiplier), span)
A:jax._src.random.random_offset->jax.lax.rem(random_offset, span)
A:jax._src.random.axis->canonicalize_axis(axis, np.ndim(a) or 1)
A:jax._src.random.r->jax.core.concrete_or_error(int, x, 'argument x of jax.random.permutation()')
A:jax._src.random.ind->jax.numpy.searchsorted(p_cuml, r)
A:jax._src.random.num_rounds->int(np.ceil(exponent * np.log(max(1, x.size)) / np.log(uint32max)))
A:jax._src.random.(key, subkey)->_split(key)
A:jax._src.random.sort_keys->_random_bits(subkey, 32, x.shape)
A:jax._src.random.(_, x)->jax.lax.sort_key_val(sort_keys, x, axis)
A:jax._src.random.a->jax.numpy.broadcast_to(a, shape)
A:jax._src.random.n_draws->prod(shape)
A:jax._src.random.p_cuml->jax.numpy.cumsum(p)
A:jax._src.random.sqrt2->numpy.array(np.sqrt(2), dtype)
A:jax._src.random.(key_re, key_im)->_split(key)
A:jax._src.random._re->_normal_real(key_re, shape, real_dtype)
A:jax._src.random._im->_normal_real(key_im, shape, real_dtype)
A:jax._src.random.lo->numpy.nextafter(np.array(-1.0, dtype), np.array(0.0, dtype), dtype=dtype)
A:jax._src.random.hi->numpy.array(1.0, dtype)
A:jax._src.random.u->uniform(key, shape, dtype, minval=-1.0 + jnp.finfo(dtype).epsneg, maxval=1.0)
A:jax._src.random.(u, s, _)->svd(cov)
A:jax._src.random.(w, v)->eigh(cov)
A:jax._src.random.factor->cholesky(cov)
A:jax._src.random.normal_samples->normal(key, shape + mean.shape[-1:], dtype)
A:jax._src.random.lower->jax.lax.convert_element_type(lower, dtype)
A:jax._src.random.upper->jax.lax.convert_element_type(upper, dtype)
A:jax._src.random.b->jax.lax.convert_element_type(b, dtype)
A:jax._src.random.p->jax.lax.convert_element_type(p, dtype)
A:jax._src.random.(key_a, key_b)->_split(key)
A:jax._src.random.log_gamma_a->loggamma(key_a, a, shape, dtype)
A:jax._src.random.log_gamma_b->loggamma(key_b, b, shape, dtype)
A:jax._src.random.log_max->jax.lax.max(log_gamma_a, log_gamma_b)
A:jax._src.random.gamma_a_scaled->jax.numpy.exp(log_gamma_a - log_max)
A:jax._src.random.gamma_b_scaled->jax.numpy.exp(log_gamma_b - log_max)
A:jax._src.random.pi->_lax_const(u, np.pi)
A:jax._src.random.alpha->jax.lax.select(boost_mask, alpha, lax.add(alpha, one))
A:jax._src.random.log_gamma_samples->loggamma(key, alpha, shape + np.shape(alpha)[-1:], dtype)
A:jax._src.random.x_max->jax.numpy.max(x, axis, keepdims=True)
A:jax._src.random.unnormalized->jax.numpy.exp(x - lax.stop_gradient(x_max))
A:jax._src.random.zero->jax._src.lax.lax._const(sample, 0)
A:jax._src.random.one->_lax_const(alpha, 1)
A:jax._src.random.minus_one->_lax_const(alpha, -1)
A:jax._src.random.one_over_two->_lax_const(alpha, 0.5)
A:jax._src.random.one_over_three->_lax_const(alpha, 1.0 / 3.0)
A:jax._src.random.squeeze_const->_lax_const(alpha, 0.0331)
A:jax._src.random.boost_mask->jax.lax.ge(alpha, one)
A:jax._src.random.d->jax.lax.sub(alpha, one_over_three)
A:jax._src.random.c->jax.lax.div(one_over_three, lax.sqrt(d))
A:jax._src.random.cond->jax.lax.bitwise_and(lax.ge(U, lax.sub(one, lax.mul(squeeze_const, lax.mul(X, X)))), lax.ge(lax.log(U), lax.add(lax.mul(X, one_over_two), lax.mul(d, lax.add(lax.sub(one, V), lax.log(V))))))
A:jax._src.random.x->uniform(key, shape, dtype, minval=jnp.finfo(dtype).eps, maxval=1.0)
A:jax._src.random.v->uniform(subkey_1, shape, lam.dtype)
A:jax._src.random.(key, x_key, U_key)->_split(key, 3)
A:jax._src.random.(_, x, v)->jax.lax.while_loop(lambda kxv: lax.le(kxv[2], zero), _next_kxv, (x_key, zero, minus_one))
A:jax._src.random.X->jax.lax.mul(x, x)
A:jax._src.random.V->jax.lax.mul(lax.mul(v, v), v)
A:jax._src.random.U->uniform(U_key, (), dtype=dtype)
A:jax._src.random.u_boost->uniform(subkey, (), dtype=dtype)
A:jax._src.random.(_, _, V, _)->jax.lax.while_loop(_cond_fn, _body_fn, (key, zero, one, _lax_const(alpha, 2)))
A:jax._src.random.log_boost->jax.lax.select(boost_mask, zero, lax.mul(lax.log(u_boost), lax.div(one, alpha_orig)))
A:jax._src.random.boost->jax.lax.select(boost_mask, one, lax.pow(u_boost, lax.div(one, alpha_orig)))
A:jax._src.random.z->jax.lax.mul(lax.mul(d, V), boost)
A:jax._src.random.samples->jax.lax.map(lambda args: _gamma_one(*args, log_space=log_space), (keys, alphas))
A:jax._src.random.alphas->jax.numpy.reshape(a, -1)
A:jax._src.random.tiny->jax.lax.full_like(samples, jnp.finfo(samples.dtype).tiny)
A:jax._src.random.grads->vmap(gamma_grad)(alphas, samples)
A:jax._src.random.a_shape->jax.numpy.shape(a)
A:jax._src.random.keys->jax._src.prng.PRNGKeyArray(prng_impl, keys)
A:jax._src.random.size->next((t.shape[i] for (t, i) in zip(batched_args, batch_dims) if i is not None))
A:jax._src.random.k->jax.lax.floor((2 * a / u_shifted + b) * u + lam + 0.43)
A:jax._src.random.random_gamma_p->jax.core.Primitive('random_gamma')
A:jax._src.random.(rng, subkey)->_split(rng)
A:jax._src.random.k_init->jax.lax.full_like(lam, -1, lam.dtype, shape)
A:jax._src.random.log_rate_init->jax.lax.full_like(lam, 0, np.float32, shape)
A:jax._src.random.log_lam->jax.lax.log(lam)
A:jax._src.random.(key, subkey_0, subkey_1)->_split(key, 3)
A:jax._src.random.s->jax.lax.log(v * inv_alpha / (a / (u_shifted * u_shifted) + b))
A:jax._src.random.k_out->jax.lax.select(accept, k, k_out)
A:jax._src.random.accepted->jax.lax.full_like(lam, False, jnp.bool_, shape)
A:jax._src.random.lam_knuth->jax.lax.select(use_knuth, lam, lax.full_like(lam, 0.0))
A:jax._src.random.lam_rejection->jax.lax.select(use_knuth, lax.full_like(lam, 100000.0), lam)
A:jax._src.random.max_iters->jax._src.dtypes.canonicalize_dtype(dtype).type(jnp.iinfo(dtype).max)
A:jax._src.random.result->jax.lax.select(use_knuth, _poisson_knuth(key, lam_knuth, shape, dtype, max_iters), _poisson_rejection(key, lam_rejection, shape, dtype, max_iters))
A:jax._src.random.lam->jax.lax.convert_element_type(lam, np.float32)
A:jax._src.random.batch_shape->tuple(np.delete(logits.shape, axis))
A:jax._src.random.e->exponential(key, shape, dtype)
A:jax._src.random.df->jax.lax.convert_element_type(df, dtype)
A:jax._src.random.(key_n, key_g)->_split(key)
A:jax._src.random.n->normal(key_n, shape, dtype)
A:jax._src.random.two->_lax_const(n, 2)
A:jax._src.random.half_df->jax.lax.div(df, two)
A:jax._src.random.g->gamma(key_n, half_df, shape, dtype)
A:jax._src.random.bernoulli_samples->bernoulli(key=key, p=0.5, shape=shape)
A:jax._src.random.norm_rvs->normal(key=key, shape=shape, dtype=dtype)
A:jax._src.random.params_shapes->jax.lax.broadcast_shapes(np.shape(loc), np.shape(scale))
A:jax._src.random.(maxwell_key, rademacher_key)->_split(key)
A:jax._src.random.maxwell_rvs->maxwell(maxwell_key, shape=shape, dtype=dtype)
A:jax._src.random.random_sign->rademacher(rademacher_key, shape=shape, dtype=dtype)
A:jax._src.random.random_uniform->uniform(key=key, shape=shape, minval=0, maxval=1, dtype=dtype)
jax._src.random.PRNGKey(seed:int)->KeyArray
jax._src.random._bernoulli(key,p,shape)->jnp.ndarray
jax._src.random._beta(key,a,b,shape,dtype)
jax._src.random._cauchy(key,shape,dtype)
jax._src.random._check_default_impl_with_no_custom_prng(impl,name)
jax._src.random._check_prng_key(key)
jax._src.random._check_shape(name,shape:Union[Sequence[int],NamedShape],*param_shapes)
jax._src.random._dirichlet(key,alpha,shape,dtype)
jax._src.random._double_sided_maxwell(key,loc,scale,shape,dtype)
jax._src.random._exponential(key,shape,dtype)
jax._src.random._fold_in(key:KeyArray,data:int)->KeyArray
jax._src.random._gamma(key,a,shape,dtype,log_space=False)
jax._src.random._gamma_batching_rule(batched_args,batch_dims,*,prng_impl,log_space)
jax._src.random._gamma_grad(sample,a,*,prng_impl,log_space)
jax._src.random._gamma_impl(raw_key,a,*,prng_impl,log_space,use_vmap=False)
jax._src.random._gamma_one(key:KeyArray,alpha,log_space)
jax._src.random._gumbel(key,shape,dtype)
jax._src.random._isnan(x)
jax._src.random._laplace(key,shape,dtype)
jax._src.random._logistic(key,shape,dtype)
jax._src.random._maxwell(key,shape,dtype)
jax._src.random._multivariate_normal(key,mean,cov,shape,dtype,method)->jnp.ndarray
jax._src.random._normal(key,shape,dtype)->jnp.ndarray
jax._src.random._normal_real(key,shape,dtype)->jnp.ndarray
jax._src.random._pareto(key,b,shape,dtype)
jax._src.random._poisson(key,lam,shape,dtype)
jax._src.random._poisson_knuth(key,lam,shape,dtype,max_iters)
jax._src.random._poisson_rejection(key,lam,shape,dtype,max_iters)
jax._src.random._rademacher(key,shape,dtype)
jax._src.random._randint(key,shape,minval,maxval,dtype)
jax._src.random._random_bits(key:prng.PRNGKeyArray,bit_width,shape)->jnp.ndarray
jax._src.random._return_prng_keys(was_wrapped,key)
jax._src.random._shuffle(key,x,axis)->jnp.ndarray
jax._src.random._softmax(x,axis)
jax._src.random._split(key:KeyArray,num:int=2)->KeyArray
jax._src.random._t(key,df,shape,dtype)
jax._src.random._truncated_normal(key,lower,upper,shape,dtype)->jnp.ndarray
jax._src.random._uniform(key,shape,dtype,minval,maxval)->jnp.ndarray
jax._src.random._weibull_min(key,scale,concentration,shape,dtype)
jax._src.random.bernoulli(key:KeyArray,p:RealArray=np.float32(0.5),shape:Optional[Union[Sequence[int],NamedShape]]=None)->jnp.ndarray
jax._src.random.beta(key:KeyArray,a:RealArray,b:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.categorical(key:KeyArray,logits:RealArray,axis:int=-1,shape:Optional[Sequence[int]]=None)->jnp.ndarray
jax._src.random.cauchy(key:KeyArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.choice(key:KeyArray,a:Union[int,Array],shape:Sequence[int]=(),replace:bool=True,p:Optional[RealArray]=None,axis:int=0)->jnp.ndarray
jax._src.random.default_prng_impl()
jax._src.random.dirichlet(key:KeyArray,alpha:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.double_sided_maxwell(key:KeyArray,loc:RealArray,scale:RealArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.exponential(key:KeyArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.fold_in(key:KeyArray,data:int)->KeyArray
jax._src.random.gamma(key:KeyArray,a:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.gumbel(key:KeyArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.laplace(key:KeyArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.loggamma(key:KeyArray,a:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.logistic(key:KeyArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.maxwell(key:KeyArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.multivariate_normal(key:KeyArray,mean:RealArray,cov:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeFloat=dtypes.float_,method:str='cholesky')->jnp.ndarray
jax._src.random.normal(key:KeyArray,shape:Union[Sequence[int],NamedShape]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.pareto(key:KeyArray,b:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.permutation(key:KeyArray,x:Union[int,Array],axis:int=0,independent:bool=False)->jnp.ndarray
jax._src.random.poisson(key:KeyArray,lam:RealArray,shape:Optional[Sequence[int]]=None,dtype:DTypeLikeInt=dtypes.int_)->jnp.ndarray
jax._src.random.rademacher(key:KeyArray,shape:Sequence[int],dtype:DTypeLikeInt=dtypes.int_)->jnp.ndarray
jax._src.random.randint(key:KeyArray,shape:Sequence[int],minval:IntegerArray,maxval:IntegerArray,dtype:DTypeLikeInt=dtypes.int_)
jax._src.random.rbg_key(seed:int)->KeyArray
jax._src.random.shuffle(key:KeyArray,x:Array,axis:int=0)->jnp.ndarray
jax._src.random.split(key:KeyArray,num:int=2)->KeyArray
jax._src.random.t(key:KeyArray,df:RealArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.threefry2x32_key(seed:int)->KeyArray
jax._src.random.threefry_2x32(keypair,count)
jax._src.random.truncated_normal(key:KeyArray,lower:RealArray,upper:RealArray,shape:Optional[Union[Sequence[int],NamedShape]]=None,dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray
jax._src.random.uniform(key:KeyArray,shape:Union[Sequence[int],NamedShape]=(),dtype:DTypeLikeFloat=dtypes.float_,minval:RealArray=0.0,maxval:RealArray=1.0)->jnp.ndarray
jax._src.random.unsafe_rbg_key(seed:int)->KeyArray
jax._src.random.weibull_min(key:KeyArray,scale:RealArray,concentration:RealArray,shape:Sequence[int]=(),dtype:DTypeLikeFloat=dtypes.float_)->jnp.ndarray


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/util.py----------------------------------------
A:jax._src.util.T->TypeVar('T')
A:jax._src.util.n->len(args[0])
A:jax._src.util.args->list(args)
A:jax._src.util.lst->list(lst)
A:jax._src.util.sentinel->object()
A:jax._src.util.dct->dict(dct)
A:jax._src.util._unflatten_done->object()
A:jax._src.util.xs_iter->iter(xs)
A:jax._src.util.end_nodes->_remove_duplicates(end_nodes)
A:jax._src.util.stack->list(end_nodes)
A:jax._src.util.node->childless_nodes.pop()
A:jax._src.util.visited->set()
A:jax._src.util.seen->set()
A:jax._src.util.sides->list(map(predicate, xs))
A:jax._src.util.memoize->cache(max_size=None)
A:jax._src.util.CacheInfo->namedtuple('CacheInfo', ['hits', 'misses', 'maxsize', 'currsize'])
A:jax._src.util.lock->threading.Lock()
A:jax._src.util.kwargs_key->tuple(kwargs.items())
A:jax._src.util.tctx->jax.config.config._trace_context()
A:jax._src.util.result->call(weak_arg, *args, **kwargs)
A:jax._src.util.del_k->next(iter(cache))
A:jax._src.util.attr->getattr(module, key)
A:jax._src.util.name_stack->name_stack.extend(name).extend(name)
A:jax._src.util.axis->operator.index(axis)
A:jax._src.util.name->getattr(wrapped, '__name__', '<unnamed function>')
A:jax._src.util.fun.__annotations__->getattr(wrapped, '__annotations__', {})
A:jax._src.util.fun.__name__->namestr.format(fun=name)
A:jax._src.util.fun.__module__->getattr(wrapped, '__module__', '<unknown module>')
A:jax._src.util.fun.__doc__->docstr.format(fun=name, doc=doc, **kwargs)
A:jax._src.util.fun.__qualname__->getattr(wrapped, '__qualname__', fun.__name__)
A:jax._src.util.class_namespace[f]->property(operator.itemgetter(i + 1))
A:jax._src.util.pos->operator.index(axis)
A:jax._src.util.self.elts_set->set()
jax._src.util.Hashable(self,val)
jax._src.util.Hashable.__eq__(self,other)
jax._src.util.Hashable.__hash__(self)
jax._src.util.Hashable.__init__(self,val)
jax._src.util.HashableFunction(self,f,closure)
jax._src.util.HashableFunction.__eq__(self,other)
jax._src.util.HashableFunction.__hash__(self)
jax._src.util.HashableFunction.__init__(self,f,closure)
jax._src.util.HashableFunction.__repr__(self)
jax._src.util.OrderedSet(self)
jax._src.util.OrderedSet.__contains__(self,elt:T)->bool
jax._src.util.OrderedSet.__init__(self)
jax._src.util.OrderedSet.__iter__(self)->Iterator[T]
jax._src.util.OrderedSet.__len__(self)->int
jax._src.util.OrderedSet.add(self,elt:T)->None
jax._src.util.OrderedSet.update(self,elts:Seq[T])->None
jax._src.util.Unhashable(self,val)
jax._src.util.Unhashable.__eq__(self,other)
jax._src.util.Unhashable.__init__(self,val)
jax._src.util.WrapKwArgs(self,val)
jax._src.util.WrapKwArgs.__eq__(self,other)
jax._src.util.WrapKwArgs.__hash__(self)
jax._src.util.WrapKwArgs.__init__(self,val)
jax._src.util._remove_duplicates(node_list)
jax._src.util.as_hashable_function(closure)
jax._src.util.assert_unreachable(x)
jax._src.util.cache(max_size=4096)
jax._src.util.canonicalize_axis(axis,num_dims)->int
jax._src.util.ceil_of_ratio(x,y)
jax._src.util.check_toposort(nodes)
jax._src.util.concatenate(xs:Iterable[Sequence[T]])->List[T]
jax._src.util.curry(f)
jax._src.util.distributed_debug_log(*pairs)
jax._src.util.extend_name_stack(stack,name:str)
jax._src.util.get_module_functions(module)
jax._src.util.maybe_named_axis(axis,if_pos,if_named)
jax._src.util.merge_lists(bs:Sequence[bool],l0:Sequence[T],l1:Sequence[T])->List[T]
jax._src.util.moveaxis(x,src,dst)
jax._src.util.new_name_stack(name:str='')
jax._src.util.partition_list(bs:Sequence[bool],l:Sequence[T])->Tuple[List[T], List[T]]
jax._src.util.prod(xs)
jax._src.util.safe_map(f,*args)
jax._src.util.safe_zip(*args)
jax._src.util.split_dict(dct,names)
jax._src.util.split_list(args:Sequence[T],ns:Sequence[int])->List[List[T]]
jax._src.util.split_merge(predicate,xs)
jax._src.util.subvals(lst,replace)
jax._src.util.taggedtuple(name,fields)->Callable[..., Any]
jax._src.util.toposort(end_nodes)
jax._src.util.tuple_delete(t,idx)
jax._src.util.tuple_insert(t,idx,val)
jax._src.util.unflatten(xs:Iterable[T],ns:Sequence[int])->List[List[T]]
jax._src.util.unzip2(xys)
jax._src.util.unzip3(xyzs)
jax._src.util.weakref_lru_cache(call:Callable,maxsize=2048)
jax._src.util.wrap_name(name,transform_name)
jax._src.util.wraps(wrapped,fun,namestr='{fun}',docstr='{doc}',**kwargs)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/custom_derivatives.py----------------------------------------
A:jax._src.custom_derivatives.ba->inspect.signature(fun).bind(*args, **kwargs)
A:jax._src.custom_derivatives.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(rule, ans_avals)
A:jax._src.custom_derivatives.ReturnValue->TypeVar('ReturnValue')
A:jax._src.custom_derivatives.primal_out->self(*primals)
A:jax._src.custom_derivatives.zeros->_zeros_like_pytree(primal_out)
A:jax._src.custom_derivatives.tangent_out->tree_map(_sum_tangents, primal_out, *all_tangents_out)
A:jax._src.custom_derivatives.args->map(core.full_lower, args)
A:jax._src.custom_derivatives.nondiff_argnums->set(self.nondiff_argnums)
A:jax._src.custom_derivatives.(f_, dyn_args)->argnums_partial(lu.wrap_init(self.fun), dyn_argnums, args, require_static_args_hashable=False)
A:jax._src.custom_derivatives.jvp->jax.linear_util.wrap_init(self.jvp)
A:jax._src.custom_derivatives.(args_flat, in_tree)->tree_flatten(args)
A:jax._src.custom_derivatives.(flat_fun, out_tree1)->flatten_fun_nokwargs(f_, in_tree)
A:jax._src.custom_derivatives.(flat_jvp, out_tree2)->_flatten_jvp(jvp, in_tree)
A:jax._src.custom_derivatives.out_flat->jax.core.eval_jaxpr(jaxpr, consts, *all_args)
A:jax._src.custom_derivatives.(_, out_tree)->jax.linear_util.merge_linear_aux(out_tree1, out_tree2)
A:jax._src.custom_derivatives.extra_args->tuple([arg.val for arg in extra_args])
A:jax._src.custom_derivatives.(primals_in, tangents_in)->split_list(args, [len(args) // 2])
A:jax._src.custom_derivatives.py_primals->tree_unflatten(in_tree, primals_in)
A:jax._src.custom_derivatives.py_tangents->tree_unflatten(in_tree, tangents_in)
A:jax._src.custom_derivatives.(primals_out, out_tree)->tree_flatten(py_primals_out)
A:jax._src.custom_derivatives.(tangents_out, out_tree2)->tree_flatten(py_tangents_out)
A:jax._src.custom_derivatives.top_trace->jax.core.find_top_trace(args)
A:jax._src.custom_derivatives.(fun, env_trace_todo1)->process_env_traces(fun, self, top_trace and top_trace.level, False)
A:jax._src.custom_derivatives.(jvp, env_trace_todo2)->process_env_traces(jvp, self, top_trace and top_trace.level, True)
A:jax._src.custom_derivatives.tracers->map(top_trace.full_raise, args)
A:jax._src.custom_derivatives.outs->map(trace.full_raise, outs)
A:jax._src.custom_derivatives.(_, env_trace_todo)->jax.linear_util.merge_linear_aux(env_trace_todo1, env_trace_todo2)
A:jax._src.custom_derivatives.ans->max(tracers, key=lambda x: x._trace.level)
A:jax._src.custom_derivatives.trace->max(tracers, key=lambda x: x._trace.level)._trace.main.with_cur_sublevel()
A:jax._src.custom_derivatives.(outs, cur_todo)->primitive.post_process(trace, outs, jvp_was_run)
A:jax._src.custom_derivatives.todos_list->list(todos)
A:jax._src.custom_derivatives.custom_jvp_call_p->CustomJVPCallPrimitive('custom_jvp_call')
A:jax._src.custom_derivatives.custom_jvp_call_jaxpr_p->jax.core.AxisPrimitive('custom_jvp_call_jaxpr')
A:jax._src.custom_derivatives.(_, args)->split_list(primals, [num_consts])
A:jax._src.custom_derivatives.(consts_dot, args_dot)->split_list(tangents, [num_consts])
A:jax._src.custom_derivatives.(jvp_jaxpr, jvp_consts)->jvp_jaxpr_thunk()
A:jax._src.custom_derivatives.args_dot->map(ad.replace_float0s, args, args_dot)
A:jax._src.custom_derivatives.(primals_out, tangents_out)->split_list(outs, [len(outs) // 2])
A:jax._src.custom_derivatives.tangents_out->map(ad.recast_to_float0, primals_out, tangents_out)
A:jax._src.custom_derivatives.num_out->len(fun_jaxpr.out_avals)
A:jax._src.custom_derivatives.(batched_fun_jaxpr, out_batched)->jax.interpreters.batching.batch_jaxpr(fun_jaxpr, axis_size, in_batched, False, axis_name, main_type)
A:jax._src.custom_derivatives.jvp_jaxpr->jax.core.ClosedJaxpr(*jvp_jaxpr_thunk())
A:jax._src.custom_derivatives.(_, args_batched)->split_list(in_batched, [num_consts])
A:jax._src.custom_derivatives.(_, all_batched)->jax.interpreters.batching.batch_jaxpr(jvp_jaxpr, axis_size, args_batched * 2, False, axis_name, main_type)
A:jax._src.custom_derivatives.(primals_batched, tangents_batched)->split_list(all_batched, [num_out])
A:jax._src.custom_derivatives.out_batched->map(op.or_, primals_batched, tangents_batched)
A:jax._src.custom_derivatives.(batched_jvp_jaxpr, _)->jax.interpreters.batching.batch_jaxpr(jvp_jaxpr, axis_size, args_batched * 2, out_batched * 2, axis_name, main_type)
A:jax._src.custom_derivatives.batched_outs->jax.core.AxisPrimitive('custom_vjp_call_jaxpr').bind(*args, fun_jaxpr=batched_fun_jaxpr, fwd_jaxpr_thunk=batched_fwd_jaxpr_thunk, bwd=batched_bwd, out_trees=out_trees, num_consts=num_consts)
A:jax._src.custom_derivatives.(fwd, _)->argnums_partial(lu.wrap_init(self.fwd), dyn_argnums, args, require_static_args_hashable=False)
A:jax._src.custom_derivatives.bwd->list(todos).pop()(bwd)
A:jax._src.custom_derivatives.(flat_fun, out_tree)->flatten_fun_nokwargs(f_, in_tree)
A:jax._src.custom_derivatives.(flat_fwd, out_trees)->_flatten_fwd(fwd, in_tree)
A:jax._src.custom_derivatives.flat_bwd->_flatten_bwd(bwd, in_tree, in_avals, out_trees)
A:jax._src.custom_derivatives.(fst, aux)->jax.linear_util.merge_linear_aux(out_tree, out_trees)
A:jax._src.custom_derivatives.py_args->tree_unflatten(in_tree, args)
A:jax._src.custom_derivatives.(out, out_tree)->tree_flatten(py_outs)
A:jax._src.custom_derivatives.(res, res_tree)->tree_flatten(res)
A:jax._src.custom_derivatives.(out_tree, res_tree)->out_trees()
A:jax._src.custom_derivatives.(res, cts_out)->split_list(args, [res_tree.num_leaves])
A:jax._src.custom_derivatives.py_res->tree_unflatten(res_tree, res)
A:jax._src.custom_derivatives.py_cts_out->tree_unflatten(out_tree, cts_out)
A:jax._src.custom_derivatives.zero->object()
A:jax._src.custom_derivatives.dummy->tree_unflatten(in_tree, [object()] * in_tree.num_leaves)
A:jax._src.custom_derivatives.(_, in_tree2)->tree_flatten(py_cts_in)
A:jax._src.custom_derivatives.(fwd, env_trace_todo2)->process_env_traces_fwd(fwd, top_trace and top_trace.level, out_trees)
A:jax._src.custom_derivatives.bwd_->jax.linear_util.wrap_init(lambda *args: bwd.call_wrapped(*args))
A:jax._src.custom_derivatives.(fst, env_trace_todo)->jax.linear_util.merge_linear_aux(env_trace_todo1, env_trace_todo2)
A:jax._src.custom_derivatives.custom_vjp_call_p->CustomVJPCallPrimitive('custom_vjp_call')
A:jax._src.custom_derivatives.(outs, cur_todo, bwd_xform)->max(tracers, key=lambda x: x._trace.level)._trace.main.with_cur_sublevel().post_process_custom_vjp_call_fwd(outs, out_trees)
A:jax._src.custom_derivatives.custom_vjp_call_jaxpr_p->jax.core.AxisPrimitive('custom_vjp_call_jaxpr')
A:jax._src.custom_derivatives.(fwd_jaxpr, fwd_consts)->fwd_jaxpr_thunk()
A:jax._src.custom_derivatives.res_and_primals_out->jax.core.eval_jaxpr(fwd_jaxpr, fwd_consts, *args)
A:jax._src.custom_derivatives.(res, primals_out)->split_list(res_and_primals_out, [res_tree.num_leaves])
A:jax._src.custom_derivatives.fwd_jaxpr->jax.core.ClosedJaxpr(*fwd_jaxpr_thunk())
A:jax._src.custom_derivatives.(batched_fwd_jaxpr, out_batched)->jax.interpreters.batching.batch_jaxpr(fwd_jaxpr, axis_size, args_batched, False, axis_name, main_type)
A:jax._src.custom_derivatives.batched_bwd->jax.interpreters.batching.batch_custom_vjp_bwd(bwd, axis_name, axis_size, fwd_out_dims, fwd_args_batched, main_type)
A:jax._src.custom_derivatives.(ans, _)->fun(*args, **kwargs)
A:jax._src.custom_derivatives.(ans, rule)->fun(*args, **kwargs)
A:jax._src.custom_derivatives.(ans_flat, out_tree)->tree_flatten((ans,))
A:jax._src.custom_derivatives.(rule, in_tree)->flatten_fun_nokwargs(lu.wrap_init(rule), out_tree)
A:jax._src.custom_derivatives.(cts_flat, out_tree_)->tree_flatten((cts,))
A:jax._src.custom_derivatives.cts_out->jax.core.Primitive('linear_call').bind(*t_consts, *f_consts, *operands_res, *cts, callee=transpose, transpose=callee, num_callee_consts=len(t_consts), num_transpose_consts=len(f_consts), num_res=len(operands_res))
A:jax._src.custom_derivatives.(flat_args, in_tree)->tree_flatten(example_args)
A:jax._src.custom_derivatives.in_avals->tuple(map(abstractify, flat_args))
A:jax._src.custom_derivatives.x->jax.core.full_lower(x)
A:jax._src.custom_derivatives.vspace->jax.core.full_lower(x).aval.at_least_vspace()
A:jax._src.custom_derivatives.(wrapped_fun, out_tree)->flatten_fun_nokwargs(lu.wrap_init(fun), in_tree)
A:jax._src.custom_derivatives.(jaxpr, out_pvals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(wrapped_fun, in_avals)
A:jax._src.custom_derivatives.out_tree->out_tree()
A:jax._src.custom_derivatives.((closure_consts, hoisted_consts), merge)->partition_list(_maybe_perturbed, consts)
A:jax._src.custom_derivatives.num_consts->len(hoisted_consts)
A:jax._src.custom_derivatives.(args, hoisted_consts)->split_list(args_hconsts, [num_args])
A:jax._src.custom_derivatives.consts->merge(closure_consts, hoisted_consts)
A:jax._src.custom_derivatives.(all_args, in_tree2)->tree_flatten(tuple(args))
A:jax._src.custom_derivatives.(operands_res, res_tree)->tree_flatten(residual_args)
A:jax._src.custom_derivatives.(operands_lin, lin_tree)->tree_flatten(linear_args)
A:jax._src.custom_derivatives.f_in_tree->treedef_tuple((res_tree, lin_tree))
A:jax._src.custom_derivatives.(f, out_tree)->flatten_fun_nokwargs(lu.wrap_init(fun), f_in_tree)
A:jax._src.custom_derivatives.res_avals->map(abstractify, operands_res)
A:jax._src.custom_derivatives.lin_avals->map(abstractify, operands_lin)
A:jax._src.custom_derivatives.(f_jaxpr, f_consts)->_initial_style_jaxpr(f, (*res_avals, *lin_avals))
A:jax._src.custom_derivatives.f_jaxpr->_close_jaxpr(f_jaxpr)
A:jax._src.custom_derivatives.out_avals->tree_map(core.get_aval, args)
A:jax._src.custom_derivatives.t_in_tree->treedef_tuple((res_tree, out_tree()))
A:jax._src.custom_derivatives.(t, t_out_tree)->flatten_fun_nokwargs(lu.wrap_init(fun_transpose), t_in_tree)
A:jax._src.custom_derivatives.(t_jaxpr, t_consts)->_initial_style_jaxpr(t, (*res_avals, *out_avals))
A:jax._src.custom_derivatives.t_jaxpr->_close_jaxpr(t_jaxpr)
A:jax._src.custom_derivatives.out->unreachable_p.bind(*args_flat, out_avals=out_avals_flat, exc_type=exc_type, message=message)
A:jax._src.custom_derivatives.(consts, _, operands_res, operands_lin)->split_list(args, [num_callee_consts, num_transpose_consts, num_res])
A:jax._src.custom_derivatives.(f_consts, t_consts, operands_res, operands_lin)->split_list(args, [num_callee_consts, num_transpose_consts, num_res])
A:jax._src.custom_derivatives.(_, _, cts_avals)->split_list(transpose.in_avals, [num_transpose_consts, num_res])
A:jax._src.custom_derivatives.linear_call_p->jax.core.Primitive('linear_call')
A:jax._src.custom_derivatives.(out_avals_flat, out_tree)->tree_flatten(out_avals)
A:jax._src.custom_derivatives.disallow_jvp->partial(unreachable, exc_type=TypeError, message="can't apply forward-mode autodiff (jvp) to a custom_vjp function.")
A:jax._src.custom_derivatives.fun->custom_jvp(fun)
A:jax._src.custom_derivatives.(outs, residuals)->fwd(*primals)
A:jax._src.custom_derivatives.tan_out_types->tree_map(lambda o: core.get_aval(o).at_least_vspace(), outs)
A:jax._src.custom_derivatives.tan_fn->custom_transpose(partial(disallow_jvp, out_avals=tan_out_types))
jax._src.custom_derivatives.CustomJVPCallPrimitive(core.CallPrimitive)
jax._src.custom_derivatives.CustomJVPCallPrimitive.bind(self,fun,jvp,*args)
jax._src.custom_derivatives.CustomJVPCallPrimitive.impl(self,fun,_,*args)
jax._src.custom_derivatives.CustomJVPCallPrimitive.post_process(self,trace,out_tracers,jvp_was_run:bool)
jax._src.custom_derivatives.CustomVJPCallPrimitive(core.CallPrimitive)
jax._src.custom_derivatives.CustomVJPCallPrimitive.bind(self,fun,fwd,bwd,*args,out_trees)
jax._src.custom_derivatives.CustomVJPCallPrimitive.impl(self,fun,fwd,bwd,*args,out_trees)
jax._src.custom_derivatives.CustomVJPCallPrimitive.post_process(self,trace,out_tracers,params)
jax._src.custom_derivatives.Residuals(self,jaxpr,in_tree,out_tree,consts)
jax._src.custom_derivatives.Residuals.__init__(self,jaxpr,in_tree,out_tree,consts)
jax._src.custom_derivatives.Residuals.__iter__(self)
jax._src.custom_derivatives.Residuals.tree_flatten(self)
jax._src.custom_derivatives.Residuals.tree_unflatten(cls,aux,consts)
jax._src.custom_derivatives._add_args(f,extra_args)
jax._src.custom_derivatives._add_args_(extra_args,*args,**kwargs)
jax._src.custom_derivatives._apply_bwd_transform(todos,bwd)
jax._src.custom_derivatives._apply_todos(todos,outs)
jax._src.custom_derivatives._check_for_tracers(x)
jax._src.custom_derivatives._close_jaxpr(jaxpr)
jax._src.custom_derivatives._closure_convert_for_avals(fun,in_tree,in_avals)
jax._src.custom_derivatives._custom_jvp_call_jaxpr_abstract_eval(*args,fun_jaxpr:core.ClosedJaxpr,**params)
jax._src.custom_derivatives._custom_jvp_call_jaxpr_impl(*args,fun_jaxpr:core.ClosedJaxpr,**params)
jax._src.custom_derivatives._custom_jvp_call_jaxpr_jvp(primals,tangents,*,fun_jaxpr:core.ClosedJaxpr,jvp_jaxpr_thunk:Callable[[],Tuple[core.Jaxpr,Sequence[Any]]],num_consts:int)
jax._src.custom_derivatives._custom_jvp_call_jaxpr_transpose(reduce_axes,cts,*args,fun_jaxpr,jvp_jaxpr_thunk,num_consts)
jax._src.custom_derivatives._custom_jvp_call_jaxpr_vmap(axis_size,axis_name,main_type,args,in_dims,*,fun_jaxpr:core.ClosedJaxpr,jvp_jaxpr_thunk:Callable[[],Tuple[core.Jaxpr,Sequence[Any]]],num_consts:int)
jax._src.custom_derivatives._custom_vjp_call_jaxpr_abstract_eval(*_,fun_jaxpr,**__)
jax._src.custom_derivatives._custom_vjp_call_jaxpr_impl(*args,fun_jaxpr,**_)
jax._src.custom_derivatives._custom_vjp_call_jaxpr_jvp(primals,tangents,*,fun_jaxpr:core.ClosedJaxpr,fwd_jaxpr_thunk:Callable[[],Tuple[core.Jaxpr,Sequence[Any]]],bwd:lu.WrappedFun,out_trees:Callable,num_consts:int)
jax._src.custom_derivatives._custom_vjp_call_jaxpr_vmap(axis_size,axis_name,main_type,args,in_dims,*,fun_jaxpr:core.ClosedJaxpr,fwd_jaxpr_thunk:Callable[[],Tuple[core.Jaxpr,Sequence[Any]]],bwd:lu.WrappedFun,out_trees:Callable,num_consts:int)
jax._src.custom_derivatives._flatten_bwd(in_tree,in_avals,out_trees,*args)
jax._src.custom_derivatives._flatten_fwd(in_tree,*args)
jax._src.custom_derivatives._flatten_jvp(in_tree,*args)
jax._src.custom_derivatives._initial_style_jaxpr(fun,in_avals)
jax._src.custom_derivatives._initial_style_staging()->bool
jax._src.custom_derivatives._linear_call_abstract_eval(*args,**kwargs)
jax._src.custom_derivatives._linear_call_impl(*args,callee,transpose,num_callee_consts,num_transpose_consts,num_res)
jax._src.custom_derivatives._linear_call_transpose_rule(cts,*args,callee,transpose,num_callee_consts,num_transpose_consts,num_res)
jax._src.custom_derivatives._maybe_perturbed(x:Any)->bool
jax._src.custom_derivatives._resolve_kwargs(fun,args,kwargs)
jax._src.custom_derivatives._stop_gradient(x)
jax._src.custom_derivatives._sum_tangents(_,x,*xs)
jax._src.custom_derivatives._zeros_like_pytree(x)
jax._src.custom_derivatives.abstractify(x)
jax._src.custom_derivatives.closure_convert(fun,*example_args)
jax._src.custom_derivatives.custom_gradient(fun)
jax._src.custom_derivatives.custom_jvp(self,fun:Callable[...,ReturnValue],nondiff_argnums:Tuple[int,...]=())
jax._src.custom_derivatives.custom_jvp.__init__(self,fun:Callable[...,ReturnValue],nondiff_argnums:Tuple[int,...]=())
jax._src.custom_derivatives.custom_jvp.defjvp(self,jvp:Callable[...,Tuple[ReturnValue,ReturnValue]])->Callable[..., Tuple[ReturnValue, ReturnValue]]
jax._src.custom_derivatives.custom_jvp.defjvps(self,*jvps:Optional[Callable[...,ReturnValue]])
jax._src.custom_derivatives.custom_jvp_jaxpr_custom_partial_eval_rule(saveable:Callable[...,bool],unks_in:List[bool],inst_in:List[bool],eqn:core.JaxprEqn)->Tuple[Optional[core.JaxprEqn], core.JaxprEqn, List[bool], List[bool], List[core.Var]]
jax._src.custom_derivatives.custom_vjp(self,fun:Callable[...,ReturnValue],nondiff_argnums:Tuple[int,...]=())
jax._src.custom_derivatives.custom_vjp.__init__(self,fun:Callable[...,ReturnValue],nondiff_argnums:Tuple[int,...]=())
jax._src.custom_derivatives.custom_vjp.defvjp(self,fwd:Callable[...,Tuple[ReturnValue,Any]],bwd:Callable[...,Tuple[Any,...]])->None
jax._src.custom_derivatives.custom_vjp_by_custom_transpose(fun,fwd,bwd)
jax._src.custom_derivatives.linear_call(fun:Callable,fun_transpose:Callable,residual_args,linear_args)
jax._src.custom_derivatives.partition_list(choice,lst)
jax._src.custom_derivatives.process_env_traces(primitive,level:int,jvp_was_run:bool,*args)
jax._src.custom_derivatives.process_env_traces_fwd(level:int,out_trees,*args)
jax._src.custom_derivatives.unreachable(*args,out_avals=None,exc_type=TypeError,message='unreachable')
jax._src.custom_derivatives.unreachable_impl(*_,out_avals,exc_type,message)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/abstract_arrays.py----------------------------------------
A:jax._src.abstract_arrays.dtype->jax._src.dtypes.canonicalize_dtype(dtypes.python_scalar_dtypes[t])
A:jax._src.abstract_arrays.(dtype, weak_type)->jax._src.dtypes._lattice_result_type(x)
A:jax._src.abstract_arrays.aval->jax.core.ShapedArray((), dtype, weak_type=True)
A:jax._src.abstract_arrays.core.pytype_aval_mappings[t]->partial(_make_concrete_python_scalar, t)
A:jax._src.abstract_arrays.ad_util.jaxval_zeros_likers[t]->partial(_zeros_like_python_scalar, t)
jax._src.abstract_arrays._make_concrete_python_scalar(t,x)
jax._src.abstract_arrays._zeros_like_python_scalar(t,x)
jax._src.abstract_arrays.canonical_concrete_aval(val,weak_type=None)
jax._src.abstract_arrays.make_shaped_array(x)
jax._src.abstract_arrays.zeros_like_array(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/public_test_util.py----------------------------------------
A:jax._src.public_test_util.tol->_default_tolerance.copy()
A:jax._src.public_test_util.dtype->_dtype(x)
A:jax._src.public_test_util.atol->_merge_tolerance(atol, default_gradient_tolerance)
A:jax._src.public_test_util.rtol->_merge_tolerance(rtol, default_gradient_tolerance)
A:jax._src.public_test_util.assert_close->partial(_assert_numpy_close, atol=atol, rtol=rtol, err_msg=err_msg)
A:jax._src.public_test_util.add->partial(tree_map, lambda x, y: np.add(x, y, dtype=_dtype(x)))
A:jax._src.public_test_util.sub->partial(tree_map, lambda x, y: np.subtract(x, y, dtype=_dtype(x)))
A:jax._src.public_test_util.safe_sub->partial(tree_map, lambda x, y: _safe_subtract(x, y, dtype=_dtype(x)))
A:jax._src.public_test_util.conj->partial(tree_map, lambda x: np.conj(x, dtype=_dtype(x)))
A:jax._src.public_test_util.shape->numpy.shape(x)
A:jax._src.public_test_util.delta->scalar_mul(tangents, eps)
A:jax._src.public_test_util.f_pos->f(*add(primals, delta))
A:jax._src.public_test_util.f_neg->f(*sub(primals, delta))
A:jax._src.public_test_util.out->default.copy()
A:jax._src.public_test_util.rng->numpy.random.RandomState(0)
A:jax._src.public_test_util.tangent->tree_map(_rand_like, args)
A:jax._src.public_test_util.(v_out, t_out)->f_jvp(args, tangent)
A:jax._src.public_test_util.v_out_expected->f(*args)
A:jax._src.public_test_util.t_out_expected->numerical_jvp(f, args, tangent, eps=eps)
A:jax._src.public_test_util._rand_like->partial(rand_like, np.random.RandomState(0))
A:jax._src.public_test_util.(v_out, vjpfun)->f_vjp(*args)
A:jax._src.public_test_util.tangent_out->numerical_jvp(f, args, tangent, eps=eps)
A:jax._src.public_test_util.cotangent->tree_map(_rand_like, v_out)
A:jax._src.public_test_util.cotangent_out->conj(vjpfun(conj(cotangent)))
A:jax._src.public_test_util.ip->inner_prod(tangent, cotangent_out)
A:jax._src.public_test_util.ip_expected->inner_prod(tangent_out, cotangent)
A:jax._src.public_test_util.args->tuple(args)
A:jax._src.public_test_util._check_jvp->partial(check_jvp, atol=atol, rtol=rtol, eps=eps)
A:jax._src.public_test_util._check_vjp->partial(check_vjp, atol=atol, rtol=rtol, eps=eps)
A:jax._src.public_test_util.(out_primal_py, vjp_py)->jax._src.api.vjp(f, *args)
jax._src.public_test_util._assert_numpy_allclose(a,b,atol=None,rtol=None,err_msg='')
jax._src.public_test_util._assert_numpy_close(a,b,atol=None,rtol=None,err_msg='')
jax._src.public_test_util._check_dtypes_match(xs,ys)
jax._src.public_test_util._dtype(x)
jax._src.public_test_util._merge_tolerance(tol,default)
jax._src.public_test_util._safe_subtract(x,y,*,dtype)
jax._src.public_test_util.check_close(xs,ys,atol=None,rtol=None,err_msg='')
jax._src.public_test_util.check_grads(f,args,order,modes=('fwd','rev'),atol=None,rtol=None,eps=None)
jax._src.public_test_util.check_jvp(f,f_jvp,args,atol=None,rtol=None,eps=EPS,err_msg='')
jax._src.public_test_util.check_vjp(f,f_vjp,args,atol=None,rtol=None,eps=EPS,err_msg='')
jax._src.public_test_util.default_tolerance()
jax._src.public_test_util.device_under_test()
jax._src.public_test_util.inner_prod(xs,ys)
jax._src.public_test_util.numerical_jvp(f,primals,tangents,eps=EPS)
jax._src.public_test_util.rand_like(rng,x)
jax._src.public_test_util.scalar_mul(xs,a)
jax._src.public_test_util.tolerance(dtype,tol=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/image/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/image/scale.py----------------------------------------
A:jax._src.image.scale.out->jax.numpy.where(x >= 1.0, ((-0.5 * x + 2.5) * x - 4.0) * x + 2.0, out)
A:jax._src.image.scale.weights->jax.numpy.where(jnp.abs(total_weight_sum) > 1000.0 * np.finfo(np.float32).eps, jnp.divide(weights, jnp.where(total_weight_sum != 0, total_weight_sum, 1)), 0)
A:jax._src.image.scale.total_weight_sum->jax.numpy.sum(weights, axis=0, keepdims=True)
A:jax._src.image.scale.in_indices->list(range(len(output_shape)))
A:jax._src.image.scale.out_indices->list(range(len(output_shape)))
A:jax._src.image.scale.d->canonicalize_axis(d, x.ndim)
A:jax._src.image.scale.w->compute_weight_mat(m, n, scale[i], translation[i], kernel, antialias).astype(x.dtype)
A:jax._src.image.scale.shape->jax.core.canonicalize_shape(shape)
A:jax._src.image.scale.method->ResizeMethod.from_string(method)
A:jax._src.image.scale.image->jax.lax.convert_element_type(image, jnp.result_type(image, jnp.float32))
A:jax._src.image.scale.scale->jax.lax.convert_element_type(scale, jnp.result_type(scale, jnp.float32))
A:jax._src.image.scale.translation->jax.lax.convert_element_type(translation, jnp.result_type(translation, jnp.float32))
A:jax._src.image.scale.spatial_dims->tuple((i for i in range(len(shape)) if not core.symbolic_equal_dim(image.shape[i], shape[i])))
A:jax._src.image.scale.offsets->jax.numpy.floor(offsets.astype(np.float32)).astype(np.int32)
jax._src.image.scale.ResizeMethod(enum.Enum)
jax._src.image.scale.ResizeMethod.from_string(s:str)
jax._src.image.scale._fill_keys_cubic_kernel(x)
jax._src.image.scale._fill_lanczos_kernel(radius,x)
jax._src.image.scale._fill_triangle_kernel(x)
jax._src.image.scale._resize(image,shape:core.Shape,method:Union[str,ResizeMethod],antialias:bool,precision)
jax._src.image.scale._resize_nearest(x,output_shape:core.Shape)
jax._src.image.scale._scale_and_translate(x,output_shape:core.Shape,spatial_dims:Sequence[int],scale,translation,kernel,antialias:bool,precision)
jax._src.image.scale.compute_weight_mat(input_size:core.DimSize,output_size:core.DimSize,scale,translation,kernel:Callable,antialias:bool)
jax._src.image.scale.resize(image,shape:core.Shape,method:Union[str,ResizeMethod],antialias:bool=True,precision=lax.Precision.HIGHEST)
jax._src.image.scale.scale_and_translate(image,shape:core.Shape,spatial_dims:Sequence[int],scale,translation,method:Union[str,ResizeMethod],antialias:bool=True,precision=lax.Precision.HIGHEST)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/fft.py----------------------------------------
A:jax._src.scipy.fft.v0->jax.lax.slice_in_dim(x, None, None, 2, axis)
A:jax._src.scipy.fft.v1->jax.lax.rev(lax.slice_in_dim(x, 1, None, 2, axis), (axis,))
A:jax._src.scipy.fft.factor->jax.lax.expand_dims(factor, [a for a in range(out.ndim) if a != axis])
A:jax._src.scipy.fft.axis->canonicalize_axis(axis, x.ndim)
A:jax._src.scipy.fft.x->dctn(x, axes=axes_block, norm=norm)
A:jax._src.scipy.fft.v->_dct_interleave(_dct_interleave(x, axis1), axis2)
A:jax._src.scipy.fft.V->jax.numpy.fft.fftn(v, axes=axes)
A:jax._src.scipy.fft.k->jax.lax.expand_dims(jnp.arange(N), [a for a in range(x.ndim) if a != axis])
A:jax._src.scipy.fft.out->_dct_ortho_norm(out, axis)
A:jax._src.scipy.fft.(axis1, axis2)->map(partial(canonicalize_axis, num_dims=x.ndim), axes)
A:jax._src.scipy.fft.k1->jax.lax.expand_dims(jnp.arange(N1), [a for a in range(x.ndim) if a != axis1])
A:jax._src.scipy.fft.k2->jax.lax.expand_dims(jnp.arange(N2), [a for a in range(x.ndim) if a != axis2])
A:jax._src.scipy.fft.axes->range(x.ndim)
jax._src.scipy.fft._W4(N,k)
jax._src.scipy.fft._dct2(x,axes,norm)
jax._src.scipy.fft._dct_interleave(x,axis)
jax._src.scipy.fft._dct_ortho_norm(out,axis)
jax._src.scipy.fft.dct(x,type=2,n=None,axis=-1,norm=None)
jax._src.scipy.fft.dctn(x,type=2,s=None,axes=None,norm=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/ndimage.py----------------------------------------
A:jax._src.scipy.ndimage._nonempty_prod->functools.partial(functools.reduce, operator.mul)
A:jax._src.scipy.ndimage._nonempty_sum->functools.partial(functools.reduce, operator.add)
A:jax._src.scipy.ndimage.index->jax._src.numpy.lax_numpy.floor(coordinate).astype(jnp.int32)
A:jax._src.scipy.ndimage.weight->coordinate.dtype.type(1)
A:jax._src.scipy.ndimage.lower->jax._src.numpy.lax_numpy.floor(coordinate)
A:jax._src.scipy.ndimage.input->jax._src.numpy.lax_numpy.asarray(input)
A:jax._src.scipy.ndimage.cval->jax._src.numpy.lax_numpy.asarray(cval, input.dtype)
A:jax._src.scipy.ndimage.index_fixer->_INDEX_FIXERS.get(mode)
A:jax._src.scipy.ndimage.interp_nodes->interp_fun(coordinate)
A:jax._src.scipy.ndimage.fixed_index->index_fixer(index, size)
A:jax._src.scipy.ndimage.valid->is_valid(index, size)
A:jax._src.scipy.ndimage.(indices, validities, weights)->zip(*items)
A:jax._src.scipy.ndimage.all_valid->functools.reduce(operator.and_, validities)
A:jax._src.scipy.ndimage.contribution->jax._src.numpy.lax_numpy.where(all_valid, input[indices], cval)
A:jax._src.scipy.ndimage.result->_round_half_away_from_zero(result)
jax._src.scipy.ndimage._linear_indices_and_weights(coordinate)
jax._src.scipy.ndimage._map_coordinates(input,coordinates,order,mode,cval)
jax._src.scipy.ndimage._mirror_index_fixer(index,size)
jax._src.scipy.ndimage._nearest_indices_and_weights(coordinate)
jax._src.scipy.ndimage._reflect_index_fixer(index,size)
jax._src.scipy.ndimage._round_half_away_from_zero(a)
jax._src.scipy.ndimage.map_coordinates(input,coordinates,order,mode='constant',cval=0.0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/special.py----------------------------------------
A:jax._src.scipy.special.(x,)->_promote_args_inexact('exp1', x)
A:jax._src.scipy.special.(x, y)->_promote_args_inexact('xlog1py', x, y)
A:jax._src.scipy.special.(a, b, x)->_promote_args_inexact('betainc', a, b, x)
A:jax._src.scipy.special.(a, x)->_promote_args_inexact('gammaincc', a, x)
A:jax._src.scipy.special.x->jax.numpy.array(x)
A:jax._src.scipy.special.one->_c(x, 1)
A:jax._src.scipy.special.(a, b)->_promote_args_inexact('logsumexp', a, b)
A:jax._src.scipy.special.a->jax.numpy.where(b != 0, a, -jnp.inf)
A:jax._src.scipy.special.(a,)->_promote_args_inexact('logsumexp', a)
A:jax._src.scipy.special.(pos_dims, dims)->_reduction_dims(a, axis)
A:jax._src.scipy.special.amax->jax.lax.stop_gradient(lax.select(jnp.isfinite(amax), amax, lax.full_like(amax, 0)))
A:jax._src.scipy.special.out->jax.numpy.where(sign < 0, jnp.array(np.nan, dtype=out.dtype), out)
A:jax._src.scipy.special.sign->jax.lax.stop_gradient(jnp.sign(sumexp))
A:jax._src.scipy.special.expsub->jax.lax.mul(expsub, b)
A:jax._src.scipy.special.sumexp->jax.numpy.sum(expsub, axis=dims, keepdims=keepdims)
A:jax._src.scipy.special.safe_x->jax.numpy.where(x_ok, x, 1.0)
A:jax._src.scipy.special.safe_y->jax.numpy.where(x_ok, y, 1.0)
A:jax._src.scipy.special.d->jax.lax.while_loop(cond, body, init)
A:jax._src.scipy.special.(a, d_)->_promote_args_inexact('multigammaln', a, d)
A:jax._src.scipy.special.constant->jax.lax.mul(lax.mul(lax.mul(_lax_const(a, 0.25), d_), lax.sub(d_, _lax_const(a, 1))), lax.log(_lax_const(a, np.pi)))
A:jax._src.scipy.special.b->jax.lax.div(jnp.arange(d, dtype=d_.dtype), _lax_const(a, 2))
A:jax._src.scipy.special.res->jax.numpy.sum(gammaln(jnp.expand_dims(a, axis=-1) - jnp.expand_dims(b, axis=tuple(range(a.ndim)))), axis=-1)
A:jax._src.scipy.special.(s, a)->_promote_args_inexact('zeta', x, q)
A:jax._src.scipy.special.k->jax.numpy.expand_dims(np.arange(N, dtype=N.dtype), tuple(range(a.ndim)))
A:jax._src.scipy.special.S->jax.numpy.sum((a_ + k) ** (-s_), -1)
A:jax._src.scipy.special.I->jax.lax.div((a + N) ** (dtype(1) - s), s - dtype(1))
A:jax._src.scipy.special.m->jax.core.concrete_or_error(int, m, 'Argument m of lpmn.')
A:jax._src.scipy.special.T1->jax.numpy.clip(T1, a_max=jnp.finfo(dtype).max)
A:jax._src.scipy.special.coefs->numpy.expand_dims(np.array(_BERNOULLI_COEFS[:T1.shape[-1]], dtype=dtype), tuple(range(a.ndim)))
A:jax._src.scipy.special.(n, x)->_promote_args_inexact('expn', n, x)
A:jax._src.scipy.special.shape->jax.numpy.shape(p)
A:jax._src.scipy.special._LOGNDTR_FLOAT64_LOWER->numpy.array(-20, np.float64)
A:jax._src.scipy.special._LOGNDTR_FLOAT32_LOWER->numpy.array(-10, np.float32)
A:jax._src.scipy.special._LOGNDTR_FLOAT64_UPPER->numpy.array(8, np.float64)
A:jax._src.scipy.special._LOGNDTR_FLOAT32_UPPER->numpy.array(5, np.float32)
A:jax._src.scipy.special.dtype->jax.lax.dtype(z)
A:jax._src.scipy.special.z->jax.lax.sqrt(dtype(-2.0) * lax.log(sanitized_mcp))
A:jax._src.scipy.special.y->jax.numpy.cumprod(jnp.broadcast_to(jnp.sqrt(1.0 - x * x), (l_max, x.shape[0])), axis=0)
A:jax._src.scipy.special.p0->list(reversed([-59.96335010141079, 98.00107541859997, -56.67628574690703, 13.931260938727968, -1.2391658386738125]))
A:jax._src.scipy.special.q0->list(reversed([1.0, 1.9544885833814176, 4.676279128988815, 86.36024213908905, -225.46268785411937, 200.26021238006066, -82.03722561683334, 15.90562251262117, -1.1833162112133]))
A:jax._src.scipy.special.p1->list(reversed([4.0554489230596245, 31.525109459989388, 57.16281922464213, 44.08050738932008, 14.684956192885803, 2.1866330685079025, -0.1402560791713545, -0.03504246268278482, -0.0008574567851546854]))
A:jax._src.scipy.special.q1->list(reversed([1.0, 15.779988325646675, 45.39076351288792, 41.3172038254672, 15.04253856929075, 2.504649462083094, -0.14218292285478779, -0.03808064076915783, -0.0009332594808954574]))
A:jax._src.scipy.special.p2->list(reversed([3.2377489177694603, 6.915228890689842, 3.9388102529247444, 1.3330346081580755, 0.20148538954917908, 0.012371663481782003, 0.00030158155350823543, 2.6580697468673755e-06, 6.239745391849833e-09]))
A:jax._src.scipy.special.q2->list(reversed([1.0, 6.02427039364742, 3.6798356385616087, 1.3770209948908132, 0.21623699359449663, 0.013420400608854318, 0.00032801446468212774, 2.8924786474538068e-06, 6.790194080099813e-09]))
A:jax._src.scipy.special.coeffs->numpy.array(coeffs, dtype)
A:jax._src.scipy.special.maybe_complement_p->jax.numpy.where(p > dtype(-np.expm1(-2.0)), dtype(1.0) - p, p)
A:jax._src.scipy.special.sanitized_mcp->jax.numpy.where(maybe_complement_p <= dtype(0.0), jnp.full(shape, dtype(0.5)), maybe_complement_p)
A:jax._src.scipy.special.ww->jax.lax.square(w)
A:jax._src.scipy.special.infinity->jax.numpy.full(shape, dtype(np.inf))
A:jax._src.scipy.special.x_nan_replaced->jax.numpy.where(p <= dtype(0.0), -infinity, jnp.where(p >= dtype(1.0), infinity, x))
A:jax._src.scipy.special.ans->log_ndtr(x, series_order=series_order)
A:jax._src.scipy.special.t_out->jax.lax.mul(t, lax.exp(lax.sub(_norm_logpdf(x), ans)))
A:jax._src.scipy.special.x_2->jax.lax.square(x)
A:jax._src.scipy.special.even_sum->jax.numpy.zeros_like(x)
A:jax._src.scipy.special.odd_sum->jax.numpy.zeros_like(x)
A:jax._src.scipy.special._norm_logpdf_constant->numpy.log(np.sqrt(2 * np.pi))
A:jax._src.scipy.special.neg_half->_lax_const(x, -0.5)
A:jax._src.scipy.special.log_normalizer->_lax_const(x, _norm_logpdf_constant)
A:jax._src.scipy.special.d0->jax.numpy.sqrt((4.0 * c0 - 1.0) / (c0 - c1))
A:jax._src.scipy.special.d1->jax.numpy.sqrt((c2 + 1.0) * (c3 - c1) / ((c2 - 3.0) * (c0 - c1)))
A:jax._src.scipy.special.d0_mask_indices->jax.numpy.triu_indices(l_max + 1, 1)
A:jax._src.scipy.special.d1_mask_indices->jax.numpy.triu_indices(l_max + 1, 2)
A:jax._src.scipy.special.d_zeros->jax.numpy.zeros((l_max + 1, l_max + 1))
A:jax._src.scipy.special.d0_mask->jax.numpy.zeros((l_max + 1, l_max + 1)).at[d0_mask_indices].set(d0[d0_mask_indices])
A:jax._src.scipy.special.d1_mask->jax.numpy.zeros((l_max + 1, l_max + 1)).at[d1_mask_indices].set(d1[d1_mask_indices])
A:jax._src.scipy.special.d0_mask_3d->jax.numpy.einsum('jk,ijk->ijk', d0_mask, mask)
A:jax._src.scipy.special.d1_mask_3d->jax.numpy.einsum('jk,ijk->ijk', d1_mask, mask)
A:jax._src.scipy.special.l_vec->jax.numpy.arange(num_l)
A:jax._src.scipy.special.update_p_p1->jax.numpy.einsum('i,ij->ij', coeff, p_p1)
A:jax._src.scipy.special.p_mm2_lm1->p_mm2_lm1.at[0, 3:num_l, :].set(update_p_p2).at[0, 3:num_l, :].set(update_p_p2)
A:jax._src.scipy.special.update_p_p2->jax.numpy.einsum('i,ij->ij', coeff, p_p2)
A:jax._src.scipy.special.coeff_zeros->jax.numpy.zeros((num_m, num_l))
A:jax._src.scipy.special.upper_0_indices->jax.numpy.triu_indices(num_m, 0, num_l)
A:jax._src.scipy.special.zero_vec->jax.numpy.zeros((num_l,))
A:jax._src.scipy.special.a0_masked->a0_masked.at[1, :].set(zero_vec).at[1, :].set(zero_vec)
A:jax._src.scipy.special.c0_masked->c0_masked.at[1, :].set(zero_vec).at[1, :].set(zero_vec)
A:jax._src.scipy.special.d0_masked->jax.numpy.zeros((num_m, num_l)).at[upper_0_indices].set(d0[upper_0_indices])
A:jax._src.scipy.special.e0_masked->jax.numpy.zeros((num_m, num_l)).at[upper_0_indices].set(e0[upper_0_indices])
A:jax._src.scipy.special.f0_masked->jax.numpy.zeros((num_m, num_l)).at[upper_0_indices].set(f0[upper_0_indices])
A:jax._src.scipy.special.g0->jax.numpy.einsum('i,ij->ij', (l_vec + 1) * l_vec, p[0, :, :])
A:jax._src.scipy.special.p_derivative_m0->jax.numpy.einsum('j,ij->ij', 0.5 / jnp.sqrt(1 - x * x), g0)
A:jax._src.scipy.special.p_derivative->p_derivative.at[1, 0, :].set(jnp.zeros((num_x,))).at[1, 0, :].set(jnp.zeros((num_x,)))
A:jax._src.scipy.special.p->jax.lax.fori_loop(lower=2, upper=l_max + 1, body_fun=body_fun, init_val=p)
A:jax._src.scipy.special.a_idx->jax.numpy.arange(1, l_max + 1)
A:jax._src.scipy.special.b_idx->jax.numpy.arange(l_max)
A:jax._src.scipy.special.f_a->jax.numpy.cumprod(1.0 - 2.0 * a_idx)
A:jax._src.scipy.special.f_b->jax.numpy.sqrt(2.0 * b_idx + 3.0)
A:jax._src.scipy.special.diag_indices->jax.numpy.diag_indices(l_max + 1)
A:jax._src.scipy.special.p_offdiag->jax.numpy.einsum('ij,ij->ij', jnp.einsum('i,j->ij', f_b, x), p[jnp.diag_indices(l_max)])
A:jax._src.scipy.special.(d0_mask_3d, d1_mask_3d)->_gen_recurrence_mask(l_max, is_normalized=is_normalized)
A:jax._src.scipy.special.n->jax.core.concrete_or_error(int, n, 'Argument n of lpmn.')
A:jax._src.scipy.special.p_vals->_gen_associated_legendre(l_max, z, is_normalized)
A:jax._src.scipy.special.p_derivatives->_gen_derivatives(p_vals, z, is_normalized)
A:jax._src.scipy.special.cos_colatitude->jax.numpy.cos(phi)
A:jax._src.scipy.special.legendre->_gen_associated_legendre(n_max, cos_colatitude, True)
A:jax._src.scipy.special.legendre_val->_gen_associated_legendre(n_max, cos_colatitude, True).at[abs(m), n, jnp.arange(len(n))].get(mode='clip')
A:jax._src.scipy.special.vandermonde->jax.lax.complex(jnp.cos(angle), jnp.sin(angle))
A:jax._src.scipy.special.harmonics->jax.numpy.where(m < 0, (-1.0) ** abs(m) * jnp.conjugate(harmonics), harmonics)
A:jax._src.scipy.special.phi->jax.numpy.array([phi])
A:jax._src.scipy.special.n_max->jax.core.concrete_or_error(int, n_max, 'The `n_max` argument of `jnp.scipy.special.sph_harm` must be statically specified to use `sph_harm` within JAX transformations.')
A:jax._src.scipy.special.ret->jax.numpy.piecewise(x, conds, vals)
A:jax._src.scipy.special.zero->_c(x, 0)
A:jax._src.scipy.special.psi->jax.lax.fori_loop(_c(n, 1), n, lambda i, psi: psi + one / i, psi)
A:jax._src.scipy.special.n1->jax.numpy.where(n == _c(n, 1), n + n, n)
A:jax._src.scipy.special.init->dict(k=_c(n, 1), pkm2=one, qkm2=x, pkm1=one, qkm1=x + n, ans=one / (x + n), t=_c(x, jnp.inf), r=zero, x=x)
A:jax._src.scipy.special.d['t']->jax.numpy.where(nz, abs((d['ans'] - r) / r), one)
A:jax._src.scipy.special.BIG->_c(x, 1.4411518807585587e+17)
A:jax._src.scipy.special.yk->jax.numpy.where(odd, one, x)
A:jax._src.scipy.special.xk->jax.numpy.where(odd, n + (k - _c(k, 1)) / _c(k, 2), k / _c(k, 2))
A:jax._src.scipy.special.d['r']r->jax.numpy.where(nz, pk / qk, d['r'])
A:jax._src.scipy.special.d['ans']->jax.numpy.where(nz, r, d['ans'])
A:jax._src.scipy.special.d[key]->jax.numpy.where(is_big, d[key] / BIG, d[key])
jax._src.scipy.special._double_factorial(n)
jax._src.scipy.special._eval_expint_k(A,B,x)
jax._src.scipy.special._expi_pos(x)
jax._src.scipy.special._expint1(x)
jax._src.scipy.special._expint2(x)
jax._src.scipy.special._expint3(x)
jax._src.scipy.special._expint4(x)
jax._src.scipy.special._expint5(x)
jax._src.scipy.special._expint6(x)
jax._src.scipy.special._expint7(x)
jax._src.scipy.special._expn1(n,x)
jax._src.scipy.special._expn2(n,x)
jax._src.scipy.special._expn3(n,x)
jax._src.scipy.special._gen_associated_legendre(l_max:int,x:jnp.ndarray,is_normalized:bool)->jnp.ndarray
jax._src.scipy.special._gen_derivatives(p:jnp.ndarray,x:jnp.ndarray,is_normalized:bool)->jnp.ndarray
jax._src.scipy.special._gen_recurrence_mask(l_max:int,is_normalized:bool=True)->Tuple[jnp.ndarray, jnp.ndarray]
jax._src.scipy.special._log_ndtr_asymptotic_series(x,series_order)
jax._src.scipy.special._log_ndtr_jvp(series_order,primals,tangents)
jax._src.scipy.special._log_ndtr_lower(x,series_order)
jax._src.scipy.special._ndtr(x)
jax._src.scipy.special._ndtri(p)
jax._src.scipy.special._norm_logpdf(x)
jax._src.scipy.special._polygamma(n,x)
jax._src.scipy.special._sph_harm(m:jnp.ndarray,n:jnp.ndarray,theta:jnp.ndarray,phi:jnp.ndarray,n_max:int)->jnp.ndarray
jax._src.scipy.special.betainc(a,b,x)
jax._src.scipy.special.betaln(x,y)
jax._src.scipy.special.digamma(x)
jax._src.scipy.special.entr(x)
jax._src.scipy.special.erf(x)
jax._src.scipy.special.erfc(x)
jax._src.scipy.special.erfinv(x)
jax._src.scipy.special.exp1(x)
jax._src.scipy.special.expi(x)
jax._src.scipy.special.expi_jvp(primals,tangents)
jax._src.scipy.special.expit(x)
jax._src.scipy.special.expn(n,x)
jax._src.scipy.special.expn_jvp(n,primals,tangents)
jax._src.scipy.special.gammainc(a,x)
jax._src.scipy.special.gammaincc(a,x)
jax._src.scipy.special.gammaln(x)
jax._src.scipy.special.i0(x)
jax._src.scipy.special.i0e(x)
jax._src.scipy.special.i1(x)
jax._src.scipy.special.i1e(x)
jax._src.scipy.special.log_ndtr(x,series_order=3)
jax._src.scipy.special.logit(x)
jax._src.scipy.special.logsumexp(a,axis=None,b=None,keepdims=False,return_sign=False)
jax._src.scipy.special.lpmn(m:int,n:int,z:jnp.ndarray)->Tuple[jnp.ndarray, jnp.ndarray]
jax._src.scipy.special.lpmn_values(m:int,n:int,z:jnp.ndarray,is_normalized:bool)->jnp.ndarray
jax._src.scipy.special.multigammaln(a,d)
jax._src.scipy.special.ndtr(x)
jax._src.scipy.special.ndtri(p)
jax._src.scipy.special.polygamma(n,x)
jax._src.scipy.special.sph_harm(m:jnp.ndarray,n:jnp.ndarray,theta:jnp.ndarray,phi:jnp.ndarray,n_max:Optional[int]=None)->jnp.ndarray
jax._src.scipy.special.xlog1py(x,y)
jax._src.scipy.special.xlogy(x,y)
jax._src.scipy.special.zeta(x,q=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/linalg.py----------------------------------------
A:jax._src.scipy.linalg.a->jax.lax.pad(a, dtype.type(0), ((0, 0, 0), (acc.shape[-1], 0, 0)))
A:jax._src.scipy.linalg.l->jax._src.lax.linalg.cholesky(a if lower else jnp.conj(_T(a)), symmetrize_input=False)
A:jax._src.scipy.linalg.(c, b)->jax._src.numpy.linalg._promote_arg_dtypes(jnp.asarray(c), jnp.asarray(b))
A:jax._src.scipy.linalg.b->jax._src.lax.linalg.triangular_solve(c, b, left_side=True, lower=lower, transpose_a=lower, conjugate_a=lower)
A:jax._src.scipy.linalg.(v, w)->jax._src.lax.linalg.eigh(a, lower=lower)
A:jax._src.scipy.linalg.(lu, pivots, _)->jax._src.lax.linalg.lu(a)
A:jax._src.scipy.linalg.perm->jax._src.lax.linalg.lu_pivots_to_permutation(pivots, m)
A:jax._src.scipy.linalg.(lu, pivots, permutation)->jax._src.lax.linalg.lu(a)
A:jax._src.scipy.linalg.dtype->jax.lax.dtype(acc)
A:jax._src.scipy.linalg.(m, n)->jax._src.numpy.lax_numpy.shape(a)
A:jax._src.scipy.linalg.p->jax._src.numpy.lax_numpy.real(jnp.array(permutation[None, :] == jnp.arange(m)[:, None], dtype=dtype))
A:jax._src.scipy.linalg.k->min(m, n)
A:jax._src.scipy.linalg.(q, r)->jax._src.lax.linalg.qr(a, full_matrices)
A:jax._src.scipy.linalg.(a, b)->jax._src.numpy.linalg._promote_arg_dtypes(jnp.asarray(a), jnp.asarray(b))
A:jax._src.scipy.linalg.factors->cho_factor(lax.stop_gradient(a), lower=lower)
A:jax._src.scipy.linalg.custom_solve->partial(lax.custom_linear_solve, lambda x: lax_linalg._matvec_multiply(a, x), solve=lambda _, x: cho_solve(factors, x), symmetric=True)
A:jax._src.scipy.linalg.out->jax._src.lax.linalg.triangular_solve(a, b, left_side=True, lower=lower, transpose_a=transpose_a, conjugate_a=conjugate_a, unit_diagonal=unit_diagonal)
A:jax._src.scipy.linalg._expm_description->textwrap.dedent('\nIn addition to the original NumPy argument(s) listed below,\nalso supports the optional boolean argument ``upper_triangular``\nto specify whether the ``A`` matrix is upper triangular, and the optional\nargument ``max_squarings`` to specify the max number of squarings allowed\nin the scaling-and-squaring approximation method. Return nan if the actual\nnumber of squarings required is more than ``max_squarings``.\n\nThe number of required squarings = max(0, ceil(log2(norm(A)) - c)\nwhere norm() denotes the L1 norm, and\n\n- c=2.42 for float64 or complex128,\n- c=1.97 for float32 or complex64\n')
A:jax._src.scipy.linalg.(P, Q, n_squarings)->_calc_P_Q(A)
A:jax._src.scipy.linalg.R->jax.lax.cond(n_squarings > max_squarings, _nan, _compute, (A, P, Q))
A:jax._src.scipy.linalg.A->jax._src.numpy.lax_numpy.asarray(A)
A:jax._src.scipy.linalg.A_L1->jax._src.numpy.linalg.norm(A, 1)
A:jax._src.scipy.linalg.n_squarings->jax._src.numpy.lax_numpy.maximum(0, jnp.floor(jnp.log2(A_L1 / maxnorm)))
A:jax._src.scipy.linalg.conds->jax._src.numpy.lax_numpy.array([0.4258730016922831, 1.880152677804762])
A:jax._src.scipy.linalg.idx->jax._src.numpy.lax_numpy.digitize(A_L1, conds)
A:jax._src.scipy.linalg.(U, V)->jax.lax.switch(idx, [_pade3, _pade5, _pade7], A)
A:jax._src.scipy.linalg.(res, _)->jax.lax.scan(_scan_f, R, jnp.arange(max_squarings))
A:jax._src.scipy.linalg.ident->jax._src.numpy.lax_numpy.eye(*A.shape, dtype=A.dtype)
A:jax._src.scipy.linalg.A2->_precise_dot(A, A)
A:jax._src.scipy.linalg.U->jax.lax.fori_loop(0, n, j_loop, U)
A:jax._src.scipy.linalg.A4->_precise_dot(A2, A2)
A:jax._src.scipy.linalg.A6->_precise_dot(A4, A2)
A:jax._src.scipy.linalg.A8->_precise_dot(A6, A2)
A:jax._src.scipy.linalg._expm_frechet_description->textwrap.dedent("\nDoes not currently support the Scipy argument ``jax.numpy.asarray_chkfinite``,\nbecause `jax.numpy.asarray_chkfinite` does not exist at the moment. Does not\nsupport the ``method='blockEnlarge'`` argument.\n")
A:jax._src.scipy.linalg.E->jax._src.numpy.lax_numpy.asarray(E)
A:jax._src.scipy.linalg.bound_fun->partial(expm, upper_triangular=False, max_squarings=16)
A:jax._src.scipy.linalg.(expm_A, expm_frechet_AE)->jvp(bound_fun, (A,), (E,))
A:jax._src.scipy.linalg.arrs->jax._src.numpy.lax_numpy._promote_dtypes(*arrs)
A:jax._src.scipy.linalg.acc->jax.lax.concatenate([acc, a], dimension=0)
A:jax._src.scipy.linalg.zeros->jax._src.numpy.lax_numpy.zeros(x.shape, dtype=jnp.int32)
A:jax._src.scipy.linalg.ones->jax._src.numpy.lax_numpy.ones(x.shape, dtype=jnp.int32)
A:jax._src.scipy.linalg.count->jax._src.numpy.lax_numpy.where(q <= pivmin, count + 1, count)
A:jax._src.scipy.linalg.q->jax._src.numpy.lax_numpy.where(q <= pivmin, jnp.minimum(q, -pivmin), q)
A:jax._src.scipy.linalg.(q, count)->sturm_step(start + j, q, count)
A:jax._src.scipy.linalg.(i, q, count)->unrolled_steps((i, q, count))
A:jax._src.scipy.linalg.(_, _, count)->jax.lax.while_loop(cond, unrolled_steps, (i, q, count))
A:jax._src.scipy.linalg.alpha->jax._src.numpy.lax_numpy.real(alpha)
A:jax._src.scipy.linalg.beta->jax._src.numpy.lax_numpy.asarray(e)
A:jax._src.scipy.linalg.beta_sq->jax._src.numpy.lax_numpy.square(beta)
A:jax._src.scipy.linalg.beta_abs->jax._src.numpy.lax_numpy.abs(beta)
A:jax._src.scipy.linalg.off_diag_abs_row_sum->jax._src.numpy.lax_numpy.concatenate([beta_abs[:1], beta_abs[:-1] + beta_abs[1:], beta_abs[-1:]], axis=0)
A:jax._src.scipy.linalg.lambda_est_max->jax._src.numpy.lax_numpy.amax(alpha + off_diag_abs_row_sum)
A:jax._src.scipy.linalg.lambda_est_min->jax._src.numpy.lax_numpy.amin(alpha - off_diag_abs_row_sum)
A:jax._src.scipy.linalg.t_norm->jax._src.numpy.lax_numpy.maximum(jnp.abs(lambda_est_min), jnp.abs(lambda_est_max))
A:jax._src.scipy.linalg.finfo->numpy.finfo(alpha.dtype)
A:jax._src.scipy.linalg.one->numpy.ones([], dtype=alpha.dtype)
A:jax._src.scipy.linalg.safemin->numpy.maximum(one / finfo.max, (one + finfo.eps) * finfo.tiny)
A:jax._src.scipy.linalg.alpha0_perturbation->jax._src.numpy.lax_numpy.broadcast_to(alpha0_perturbation, target_shape)
A:jax._src.scipy.linalg.abs_tol->jax._src.numpy.lax_numpy.maximum(tol, abs_tol)
A:jax._src.scipy.linalg.target_counts->jax._src.numpy.lax_numpy.arange(select_range[0], select_range[1] + 1)
A:jax._src.scipy.linalg.target_shape->jax._src.numpy.lax_numpy.shape(target_counts)
A:jax._src.scipy.linalg.lower->jax._src.numpy.lax_numpy.where(counts <= target_counts, mid, lower)
A:jax._src.scipy.linalg.upper->jax._src.numpy.lax_numpy.where(counts > target_counts, mid, upper)
A:jax._src.scipy.linalg.pivmin->jax._src.numpy.lax_numpy.broadcast_to(pivmin, target_shape)
A:jax._src.scipy.linalg.counts->_sturm(alpha, beta_sq, pivmin, alpha0_perturbation, mid)
A:jax._src.scipy.linalg.(_, _, mid, _)->jax.lax.while_loop(cond, body, (0, lower, mid, upper))
A:jax._src.scipy.linalg.(unitary, posdef, _)->jax._src.lax.polar.polar(a, side=side, method=method, eps=eps, maxiter=maxiter)
A:jax._src.scipy.linalg.diag->jax._src.numpy.lax_numpy.sqrt(jnp.diag(T))
A:jax._src.scipy.linalg.s->jax.lax.fori_loop(i + 1, j, lambda k, val: val + U[i, k] * U[k, j], 0.0)
A:jax._src.scipy.linalg.value->jax._src.numpy.lax_numpy.where(T[i, j] == s, 0.0, (T[i, j] - s) / (diag[i] + diag[j]))
A:jax._src.scipy.linalg.(_, U)->jax.lax.fori_loop(0, j, i_loop, (j, U))
A:jax._src.scipy.linalg.(T, Z)->jax.lax.cond(jnp.abs(T[m, m - 1]) > eps * (jnp.abs(T[m - 1, m - 1]) + jnp.abs(T[m, m])), _update_T_Z, lambda m, T, Z: (T, Z), m, T, Z)
A:jax._src.scipy.linalg.sqrt_T->_sqrtm_triu(T)
A:jax._src.scipy.linalg._no_asarray_chkfinite_doc->textwrap.dedent('\nDoes not currently support the Scipy argument ``jax.numpy.asarray_chkfinite``,\nbecause `jax.numpy.asarray_chkfinite` does not exist at the moment.\n')
A:jax._src.scipy.linalg.T->T.at[m, m - 1].set(0.0).at[m, m - 1].set(0.0)
A:jax._src.scipy.linalg.Z->jax.lax.dynamic_update_slice_in_dim(Z, Z_cols @ G.conj().T, m - 1, axis=1)
A:jax._src.scipy.linalg.common_dtype->jax._src.numpy.lax_numpy.result_type(T, Z, jnp.complex64)
A:jax._src.scipy.linalg.r->jax._src.numpy.linalg.norm([mu[0], T[m, m - 1]])
A:jax._src.scipy.linalg.G->jax._src.numpy.lax_numpy.array([[c.conj(), s], [-s, c]], dtype=common_dtype)
A:jax._src.scipy.linalg.T_rows->jax.lax.dynamic_slice_in_dim(T, m - 1, 2, axis=0)
A:jax._src.scipy.linalg.T_rows_new->jax._src.numpy.lax_numpy.where(~col_mask, T_rows, G_dot_T_zeroed_cols)
A:jax._src.scipy.linalg.T_cols->jax.lax.dynamic_slice_in_dim(T, m - 1, 2, axis=1)
A:jax._src.scipy.linalg.T_cols_new->jax._src.numpy.lax_numpy.where(~row_mask, T_cols, T_zeroed_rows_dot_GH)
A:jax._src.scipy.linalg.Z_cols->jax.lax.dynamic_slice_in_dim(Z, m - 1, 2, axis=1)
jax._src.scipy.linalg._calc_P_Q(A)
jax._src.scipy.linalg._cho_solve(c,b,lower)
jax._src.scipy.linalg._cholesky(a,lower)
jax._src.scipy.linalg._eigh(a,b,lower,eigvals_only,eigvals,type)
jax._src.scipy.linalg._lu(a,permute_l)
jax._src.scipy.linalg._pade13(A)
jax._src.scipy.linalg._pade3(A)
jax._src.scipy.linalg._pade5(A)
jax._src.scipy.linalg._pade7(A)
jax._src.scipy.linalg._pade9(A)
jax._src.scipy.linalg._precise_dot(A,B)
jax._src.scipy.linalg._qr(a,mode,pivoting)
jax._src.scipy.linalg._schur(a,output)
jax._src.scipy.linalg._solve(a,b,sym_pos,lower)
jax._src.scipy.linalg._solve_P_Q(P,Q,upper_triangular=False)
jax._src.scipy.linalg._solve_triangular(a,b,trans,lower,unit_diagonal)
jax._src.scipy.linalg._sqrtm(A)
jax._src.scipy.linalg._sqrtm_triu(T)
jax._src.scipy.linalg._squaring(R,n_squarings,max_squarings)
jax._src.scipy.linalg._svd(a,*,full_matrices,compute_uv)
jax._src.scipy.linalg.block_diag(*arrs)
jax._src.scipy.linalg.cho_factor(a,lower=False,overwrite_a=False,check_finite=True)
jax._src.scipy.linalg.cho_solve(c_and_lower,b,overwrite_b=False,check_finite=True)
jax._src.scipy.linalg.cholesky(a,lower=False,overwrite_a=False,check_finite=True)
jax._src.scipy.linalg.det(a,overwrite_a=False,check_finite=True)
jax._src.scipy.linalg.eigh(a,b=None,lower=True,eigvals_only=False,overwrite_a=False,overwrite_b=False,turbo=True,eigvals=None,type=1,check_finite=True)
jax._src.scipy.linalg.eigh_tridiagonal(d,e,*,eigvals_only=False,select='a',select_range=None,tol=None)
jax._src.scipy.linalg.expm(A,*,upper_triangular=False,max_squarings=16)
jax._src.scipy.linalg.expm_frechet(A,E,*,method=None,compute_expm=True)
jax._src.scipy.linalg.inv(a,overwrite_a=False,check_finite=True)
jax._src.scipy.linalg.lu(a,permute_l=False,overwrite_a=False,check_finite=True)
jax._src.scipy.linalg.lu_factor(a,overwrite_a=False,check_finite=True)
jax._src.scipy.linalg.lu_solve(lu_and_piv,b,trans=0,overwrite_b=False,check_finite=True)
jax._src.scipy.linalg.polar(a,side='right',method='qdwh',eps=None,maxiter=50)
jax._src.scipy.linalg.qr(a,overwrite_a=False,lwork=None,mode='full',pivoting=False,check_finite=True)
jax._src.scipy.linalg.rsf2csf(T,Z,check_finite=True)
jax._src.scipy.linalg.schur(a,output='real')
jax._src.scipy.linalg.solve(a,b,sym_pos=False,lower=False,overwrite_a=False,overwrite_b=False,debug=False,check_finite=True)
jax._src.scipy.linalg.solve_triangular(a,b,trans=0,lower=False,unit_diagonal=False,overwrite_b=False,debug=None,check_finite=True)
jax._src.scipy.linalg.sqrtm(A,blocksize=1)
jax._src.scipy.linalg.svd(a,full_matrices=True,compute_uv=True,overwrite_a=False,check_finite=True,lapack_driver='gesdd')
jax._src.scipy.linalg.tril(m,k=0)
jax._src.scipy.linalg.triu(m,k=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/signal.py----------------------------------------
A:jax._src.scipy.signal.(in1, in2)->_promote_dtypes_inexact(in1, in2)
A:jax._src.scipy.signal.no_swap->all((s1 >= s2 for (s1, s2) in zip(in1.shape, in2.shape)))
A:jax._src.scipy.signal.swap->all((s1 <= s2 for (s1, s2) in zip(in1.shape, in2.shape)))
A:jax._src.scipy.signal.in2->jax._src.numpy.lax_numpy.flip(in2)
A:jax._src.scipy.signal.strides->tuple((1 for s in shape))
A:jax._src.scipy.signal.result->jax._src.numpy.lax_numpy.moveaxis(result, -1, axis)
A:jax._src.scipy.signal.same_shape->all((s1 == s2 for (s1, s2) in zip(in1.shape, in2.shape)))
A:jax._src.scipy.signal.(data,)->_promote_dtypes_inexact(jnp.asarray(data))
A:jax._src.scipy.signal.bp->numpy.sort(np.unique(np.r_[0, bp, N]))
A:jax._src.scipy.signal.data->data.at[sl].add(-jnp.matmul(A, coef, precision=lax.Precision.HIGHEST)).at[sl].add(-jnp.matmul(A, coef, precision=lax.Precision.HIGHEST))
A:jax._src.scipy.signal.sl->slice(bp[m], bp[m + 1])
A:jax._src.scipy.signal.(coef, *_)->jax._src.numpy.linalg.lstsq(A, data[sl])
A:jax._src.scipy.signal.x->jax._src.numpy.lax_numpy.moveaxis(x, -1, time_axis)
A:jax._src.scipy.signal.batch_shape->tuple(batch_shape)
A:jax._src.scipy.signal.left_end->jax.lax.slice_in_dim(x, 0, 1, axis=axis)
A:jax._src.scipy.signal.left_ext->jax._src.numpy.lax_numpy.flip(lax.slice_in_dim(x, 1, n + 1, axis=axis), axis=axis)
A:jax._src.scipy.signal.right_end->jax.lax.slice_in_dim(x, -1, None, axis=axis)
A:jax._src.scipy.signal.right_ext->jax._src.numpy.lax_numpy.flip(lax.slice_in_dim(x, -(n + 1), -1, axis=axis), axis=axis)
A:jax._src.scipy.signal.ext->jax._src.numpy.lax_numpy.concatenate((2 * left_end - left_ext, x, 2 * right_end - right_ext), axis=axis)
A:jax._src.scipy.signal.axis->canonicalize_axis(axis, x.ndim)
A:jax._src.scipy.signal.nperseg->jax.core.concrete_or_error(int, nperseg or n_default, 'nperseg: segment length of STFT')
A:jax._src.scipy.signal.(win, nperseg)->jax._src.third_party.scipy.signal_helper._triage_segments(window, nperseg, input_length=x.shape[axis])
A:jax._src.scipy.signal.noverlap->jax.core.concrete_or_error(int, noverlap or nperseg // 2, 'noverlap of STFT')
A:jax._src.scipy.signal.nfft->jax.core.concrete_or_error(int, nfft, 'nfft of STFT')
A:jax._src.scipy.signal.outdtype->jax.dtypes.canonicalize_dtype(np.result_type(x, y, np.complex64))
A:jax._src.scipy.signal.y->jax._src.numpy.lax_numpy.concatenate((y, jnp.zeros(zeros_shape)), axis=-1)
A:jax._src.scipy.signal.outershape->jax._src.numpy.lax_numpy.broadcast_shapes(tuple_delete(x.shape, axis), tuple_delete(y.shape, axis))
A:jax._src.scipy.signal.outshape->tuple_insert(outershape, min([x.shape[axis], y.shape[axis]]), axis)
A:jax._src.scipy.signal.emptyout->jax._src.numpy.lax_numpy.zeros(outshape)
A:jax._src.scipy.signal.pad_shape->list(y.shape)
A:jax._src.scipy.signal.d->detrend_type(d)
A:jax._src.scipy.signal.win->win.reshape((1,) * (xsubs.ndim - 2) + win.shape + (1,)).reshape((1,) * (xsubs.ndim - 2) + win.shape + (1,))
A:jax._src.scipy.signal.scale->jax._src.numpy.lax_numpy.sqrt(scale)
A:jax._src.scipy.signal.freqs->jax.numpy.fft.rfftfreq(nfft, 1 / fs)
A:jax._src.scipy.signal.result_y->_fft_helper(y, win, detrend_func, nperseg, noverlap, nfft, sides)
A:jax._src.scipy.signal.(freqs, time, Zxx)->_spectral_helper(x, None, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling='spectrum', axis=axis, mode='stft', boundary=boundary, padded=padded)
A:jax._src.scipy.signal.(freqs, _, Pxy)->_spectral_helper(x, y, fs, window, nperseg, noverlap, nfft, detrend, return_onesided, scaling, axis, mode='psd')
A:jax._src.scipy.signal.bias->jax._src.third_party.scipy.signal_helper._median_bias(Pxy.shape[-1]).astype(Pxy.dtype)
A:jax._src.scipy.signal.Pxy->jax._src.numpy.lax_numpy.reshape(Pxy, Pxy.shape[:-1])
A:jax._src.scipy.signal.(freqs, Pxx)->csd(x, None, fs=fs, window=window, nperseg=nperseg, noverlap=noverlap, nfft=nfft, detrend=detrend, return_onesided=return_onesided, scaling=scaling, axis=axis, average=average)
A:jax._src.scipy.signal.step_size->jax.core.concrete_or_error(int, step_size, 'step_size for overlap_and_add')
A:jax._src.scipy.signal.flat_batchsize->numpy.prod(batch_shape, dtype=np.int64)
A:jax._src.scipy.signal.freq_axis->canonicalize_axis(freq_axis, Zxx.ndim)
A:jax._src.scipy.signal.time_axis->canonicalize_axis(time_axis, Zxx.ndim)
A:jax._src.scipy.signal.Zxx->jax._src.numpy.lax_numpy.transpose(Zxx, outer_idxs + (freq_axis, time_axis))
A:jax._src.scipy.signal.outer_idxs->tuple((idx for idx in range(Zxx.ndim) if idx not in {time_axis, freq_axis}))
A:jax._src.scipy.signal.win_squared->jax._src.numpy.lax_numpy.repeat(win * win, xsubs.shape[-1], axis=-1)
A:jax._src.scipy.signal.norm->_overlap_and_add(win_squared.swapaxes(-2, -1), nstep)
jax._src.scipy.signal._convolve_nd(in1,in2,mode,*,precision)
jax._src.scipy.signal._fft_helper(x,win,detrend_func,nperseg,noverlap,nfft,sides)
jax._src.scipy.signal._overlap_and_add(x,step_size)
jax._src.scipy.signal._spectral_helper(x,y,fs=1.0,window='hann',nperseg=None,noverlap=None,nfft=None,detrend_type='constant',return_onesided=True,scaling='density',axis=-1,mode='psd',boundary=None,padded=False)
jax._src.scipy.signal.convolve(in1,in2,mode='full',method='auto',precision=None)
jax._src.scipy.signal.convolve2d(in1,in2,mode='full',boundary='fill',fillvalue=0,precision=None)
jax._src.scipy.signal.correlate(in1,in2,mode='full',method='auto',precision=None)
jax._src.scipy.signal.correlate2d(in1,in2,mode='full',boundary='fill',fillvalue=0,precision=None)
jax._src.scipy.signal.csd(x,y,fs=1.0,window='hann',nperseg=None,noverlap=None,nfft=None,detrend='constant',return_onesided=True,scaling='density',axis=-1,average='mean')
jax._src.scipy.signal.detrend(data,axis=-1,type='linear',bp=0,overwrite_data=None)
jax._src.scipy.signal.istft(Zxx,fs=1.0,window='hann',nperseg=None,noverlap=None,nfft=None,input_onesided=True,boundary=True,time_axis=-1,freq_axis=-2)
jax._src.scipy.signal.odd_ext(x,n,axis=-1)
jax._src.scipy.signal.stft(x,fs=1.0,window='hann',nperseg=256,noverlap=None,nfft=None,detrend=False,return_onesided=True,boundary='zeros',padded=True,axis=-1)
jax._src.scipy.signal.welch(x,fs=1.0,window='hann',nperseg=None,noverlap=None,nfft=None,detrend='constant',return_onesided=True,scaling='density',axis=-1,average='mean')


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/eigh.py----------------------------------------
A:jax._src.scipy.eigh.out->jax.numpy.dot(matrix_out.conj().T, matrix_in, precision=precision)
A:jax._src.scipy.eigh.column_norms->jax.numpy.linalg.norm(P, axis=1)
A:jax._src.scipy.eigh.sort_idxs->jax.numpy.argsort(evals)
A:jax._src.scipy.eigh.H_norm->jax.numpy.linalg.norm(H)
A:jax._src.scipy.eigh.(Q, _)->jax.numpy.linalg.qr(X, mode='complete')
A:jax._src.scipy.eigh.error_matrix->jax.numpy.dot(error_matrix, V1, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.eigh.X->jax.numpy.dot(P, V1, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.eigh.(V1, V2, error)->body_f_after_matmul(X)
A:jax._src.scipy.eigh.one->jax.numpy.ones(1, dtype=jnp.int32)
A:jax._src.scipy.eigh.(V1, V2, _, error)->jax.lax.while_loop(cond_f, body_f, (V1, V2, one, error))
A:jax._src.scipy.eigh.(Vm, Vp)->_projector_subspace(P, H, rank)
A:jax._src.scipy.eigh.Hm->_similarity_transform(H, Vm, precision)
A:jax._src.scipy.eigh.Hp->_similarity_transform(H, Vp, precision)
A:jax._src.scipy.eigh.Vm->jax.numpy.dot(V0, Vm, precision=precision)
A:jax._src.scipy.eigh.Vp->jax.numpy.dot(V0, Vp, precision=precision)
A:jax._src.scipy.eigh.H_shift->_fill_diagonal(H, H.diagonal() - split_point)
A:jax._src.scipy.eigh.(U, _)->jax.scipy.linalg.polar_unitary(H_shift)
A:jax._src.scipy.eigh.rank->int(rank)
A:jax._src.scipy.eigh.(evals, evecs)->_eigh_work(H, precision=precision)
A:jax._src.scipy.eigh.evecs->jax.numpy.hstack((Vm, Vp))
A:jax._src.scipy.eigh.split_point->jax.numpy.median(jnp.diag(H))
A:jax._src.scipy.eigh.(Hm, Vm, Hp, Vp)->split_spectrum(H, split_point, V0=V, precision=precision)
A:jax._src.scipy.eigh.(Hm, Vm)->_eigh_work(Hm, V=Vm, precision=precision, termination_size=termination_size)
A:jax._src.scipy.eigh.(Hp, Vp)->_eigh_work(Hp, V=Vp, precision=precision, termination_size=termination_size)
A:jax._src.scipy.eigh.evals->jax.numpy.hstack((Hm, Hp))
A:jax._src.scipy.eigh.(Up, H)->jax.scipy.linalg.polar(A)
A:jax._src.scipy.eigh.(S, V)->eigh(H, precision=precision)
A:jax._src.scipy.eigh.U->jax.numpy.dot(Up, V, precision=precision)
jax._src.scipy.eigh._eigh_work(H,V=None,precision=lax.Precision.HIGHEST,termination_size=128)
jax._src.scipy.eigh._projector_subspace(P,H,rank,maxiter=2)
jax._src.scipy.eigh._similarity_transform(matrix_in,matrix_out,precision=lax.Precision.HIGHEST)
jax._src.scipy.eigh._split_spectrum_jittable(P,H,V0,rank,precision)
jax._src.scipy.eigh.eigh(H,precision=lax.Precision.HIGHEST,symmetrize=True,termination_size=128)
jax._src.scipy.eigh.split_spectrum(H,split_point,V0=None,precision=lax.Precision.HIGHEST)
jax._src.scipy.eigh.svd(A,precision=lax.Precision.HIGHEST)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/sparse/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/sparse/linalg.py----------------------------------------
A:jax._src.scipy.sparse.linalg._dot->partial(jnp.dot, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.sparse.linalg._vdot->partial(jnp.vdot, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.sparse.linalg._einsum->partial(jnp.einsum, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.sparse.linalg.result->_vdot(x.real, y.real)
A:jax._src.scipy.sparse.linalg.xs->tree_leaves(x)
A:jax._src.scipy.sparse.linalg._add->partial(tree_map, operator.add)
A:jax._src.scipy.sparse.linalg._sub->partial(tree_map, operator.sub)
A:jax._src.scipy.sparse.linalg._dot_tree->partial(tree_map, _dot)
A:jax._src.scipy.sparse.linalg.bs->_vdot_real_tree(b, b)
A:jax._src.scipy.sparse.linalg.atol2->jax.numpy.maximum(jnp.square(tol) * bs, jnp.square(atol))
A:jax._src.scipy.sparse.linalg.Ap->A(p)
A:jax._src.scipy.sparse.linalg.x_->tree_map(partial(jnp.where, exit_early), _add(x, _mul(alpha_, phat)), _add(x, _add(_mul(alpha_, phat), _mul(omega_, shat))))
A:jax._src.scipy.sparse.linalg.r_->tree_map(partial(jnp.where, exit_early), s, _sub(s, _mul(omega_, t)))
A:jax._src.scipy.sparse.linalg.z_->M(r_)
A:jax._src.scipy.sparse.linalg.gamma_->_vdot_real_tree(r_, z_)
A:jax._src.scipy.sparse.linalg.p_->_add(r, _mul(beta, _sub(p, _mul(omega, q))))
A:jax._src.scipy.sparse.linalg.r0->_sub(b, A(x0))
A:jax._src.scipy.sparse.linalg.p0z0->M(r0)
A:jax._src.scipy.sparse.linalg.gamma0->_vdot_real_tree(r0, z0)
A:jax._src.scipy.sparse.linalg.(x_final, *_)->jax.lax.while_loop(cond_fun, body_fun, initial_value)
A:jax._src.scipy.sparse.linalg.rs->_vdot_real_tree(r, r)
A:jax._src.scipy.sparse.linalg.rho_->_vdot_tree(rhat, r)
A:jax._src.scipy.sparse.linalg.phat->M(p_)
A:jax._src.scipy.sparse.linalg.q_->A(phat)
A:jax._src.scipy.sparse.linalg.s->_sub(r, _mul(alpha_, q_))
A:jax._src.scipy.sparse.linalg.shat->M(s)
A:jax._src.scipy.sparse.linalg.t->A(shat)
A:jax._src.scipy.sparse.linalg.k_->jax.numpy.where(rho_ == 0, -10, k_)
A:jax._src.scipy.sparse.linalg.rho0alpha0omega0->jax._src.lax.lax._convert_element_type(1, *dtypes._lattice_result_type(*tree_leaves(b)))
A:jax._src.scipy.sparse.linalg.x0->tree_map(jnp.zeros_like, b)
A:jax._src.scipy.sparse.linalg.(b, x0)->device_put((b, x0))
A:jax._src.scipy.sparse.linalg.size->sum((bi.size for bi in tree_leaves(b)))
A:jax._src.scipy.sparse.linalg.A->_normalize_matvec(A)
A:jax._src.scipy.sparse.linalg.M->_normalize_matvec(M)
A:jax._src.scipy.sparse.linalg.isolve_solve->partial(_isolve_solve, x0=x0, tol=tol, atol=atol, maxiter=maxiter, M=M)
A:jax._src.scipy.sparse.linalg.x->jax.lax.custom_linear_solve(A, b, solve=_solve, transpose_solve=_solve)
A:jax._src.scipy.sparse.linalg.norm->jax.numpy.where(use_norm, norm, 0.0)
A:jax._src.scipy.sparse.linalg.dtype->jax.numpy.result_type(*tree_leaves(b))
A:jax._src.scipy.sparse.linalg.normalized_x->tree_map(lambda y: jnp.where(use_norm, y / norm, 0.0), x)
A:jax._src.scipy.sparse.linalg.v_proj->tree_map(lambda X, y: _einsum('...n,...->n', X.conj(), y), A, v)
A:jax._src.scipy.sparse.linalg.r->jax.lax.rsqrt(1 + abs(t) ** 2)
A:jax._src.scipy.sparse.linalg.h->h.at[k + 1].set(v_norm_1).at[k + 1].set(v_norm_1)
A:jax._src.scipy.sparse.linalg.Qh->tree_map(lambda X: _dot(X, h), Q)
A:jax._src.scipy.sparse.linalg.q->_sub(q, Qh)
A:jax._src.scipy.sparse.linalg.(_, qnorm)->_safe_normalize(q)
A:jax._src.scipy.sparse.linalg.(_, _, q, qnorm_scaled)->jax.lax.while_loop(qnorm_cond, qnorm, init)
A:jax._src.scipy.sparse.linalg.(_, rnorm)->_safe_normalize(r)
A:jax._src.scipy.sparse.linalg.(k, q, r, qnorm_scaled)->body_function((0, q, r, xnorm_scaled))
A:jax._src.scipy.sparse.linalg.(k, q, r, _)->jax.lax.while_loop(cond_function, body_function, (k, q, r, qnorm_scaled))
A:jax._src.scipy.sparse.linalg.v->M(A(v))
A:jax._src.scipy.sparse.linalg.(_, v_norm_0)->_safe_normalize(v)
A:jax._src.scipy.sparse.linalg.(v, h)->_iterative_classical_gram_schmidt(V, v, v_norm_0, max_iterations=2)
A:jax._src.scipy.sparse.linalg.(unit_v, v_norm_1)->_safe_normalize(v, thresh=tol)
A:jax._src.scipy.sparse.linalg.V->tree_map(lambda x: jnp.pad(x[..., None], ((0, 0),) * x.ndim + ((0, restart),)), unit_residual)
A:jax._src.scipy.sparse.linalg.H->jax._src.lax.lax._convert_element_type(jnp.eye(restart, restart + 1, dtype=dtype), weak_type=weak_type)
A:jax._src.scipy.sparse.linalg.cs->jax.numpy.where(b_zero, 1, jnp.where(a_lt_b, r * t, r))
A:jax._src.scipy.sparse.linalg.sn->jax.numpy.where(b_zero, 0, jnp.where(a_lt_b, r, r * t))
A:jax._src.scipy.sparse.linalg.R_row->_rotate_vectors(R_row, k, *givens_factors)
A:jax._src.scipy.sparse.linalg.givens_factors->_givens_rotation(R_row[k], R_row[k + 1])
A:jax._src.scipy.sparse.linalg.givens->jax.numpy.zeros((restart, 2), dtype=dtype)
A:jax._src.scipy.sparse.linalg.R->R.at[k, :].set(R_row).at[k, :].set(R_row)
A:jax._src.scipy.sparse.linalg.beta_vec->jax.numpy.zeros_like(H, shape=(restart + 1,)).at[0].set(residual_norm)
A:jax._src.scipy.sparse.linalg.(V, H, _)->_kth_arnoldi_iteration(k, A, M, V, R)
A:jax._src.scipy.sparse.linalg.(R_row, givens)->_apply_givens_rotations(H[k, :], givens, k)
A:jax._src.scipy.sparse.linalg.err->abs(beta_vec[k + 1])
A:jax._src.scipy.sparse.linalg.carry->jax.lax.while_loop(loop_cond, arnoldi_qr_step, carry)
A:jax._src.scipy.sparse.linalg.y->_lstsq(H.T, beta_vec)
A:jax._src.scipy.sparse.linalg.dx->tree_map(lambda X: _dot(X[..., :-1], y), V)
A:jax._src.scipy.sparse.linalg.residual->M(_sub(b, A(x0)))
A:jax._src.scipy.sparse.linalg.(unit_residual, residual_norm)->_safe_normalize(residual)
A:jax._src.scipy.sparse.linalg.a2->_dot(a.T.conj(), a)
A:jax._src.scipy.sparse.linalg.b2->_dot(a.T.conj(), b)
A:jax._src.scipy.sparse.linalg.(dtype, weak_type)->jax._src.dtypes._lattice_result_type(*tree_leaves(b))
A:jax._src.scipy.sparse.linalg.(V, H, breakdown)->_kth_arnoldi_iteration(k, A, M, V, H)
A:jax._src.scipy.sparse.linalg.(V, H, _, _)->jax.lax.while_loop(loop_cond, arnoldi_process, carry)
A:jax._src.scipy.sparse.linalg.(x, unit_residual, residual_norm)->gmres_func(A, b, x, unit_residual, residual_norm, ptol, restart, M)
A:jax._src.scipy.sparse.linalg.(x_final, k, _, err)->jax.lax.while_loop(cond_fun, body_fun, initialization)
A:jax._src.scipy.sparse.linalg.restart->min(restart, size)
A:jax._src.scipy.sparse.linalg.b_norm->_norm(b)
A:jax._src.scipy.sparse.linalg.atol->jax.numpy.maximum(tol * b_norm, atol)
A:jax._src.scipy.sparse.linalg.Mb->M(b)
A:jax._src.scipy.sparse.linalg.Mb_norm->_norm(Mb)
A:jax._src.scipy.sparse.linalg.failed->jax.numpy.isnan(_norm(x))
A:jax._src.scipy.sparse.linalg.info->jax.numpy.where(failed, x=-1, y=0)
jax._src.scipy.sparse.linalg._apply_givens_rotations(H_row,givens,k)
jax._src.scipy.sparse.linalg._bicgstab_solve(A,b,x0=None,*,maxiter,tol=1e-05,atol=0.0,M=_identity)
jax._src.scipy.sparse.linalg._cg_solve(A,b,x0=None,*,maxiter,tol=1e-05,atol=0.0,M=_identity)
jax._src.scipy.sparse.linalg._div(tree,scalar)
jax._src.scipy.sparse.linalg._givens_rotation(a,b)
jax._src.scipy.sparse.linalg._gmres_batched(A,b,x0,unit_residual,residual_norm,ptol,restart,M)
jax._src.scipy.sparse.linalg._gmres_incremental(A,b,x0,unit_residual,residual_norm,ptol,restart,M)
jax._src.scipy.sparse.linalg._gmres_solve(A,b,x0,atol,ptol,restart,maxiter,M,gmres_func)
jax._src.scipy.sparse.linalg._identity(x)
jax._src.scipy.sparse.linalg._isolve(_isolve_solve,A,b,x0=None,*,tol=1e-05,atol=0.0,maxiter=None,M=None,check_symmetric=False)
jax._src.scipy.sparse.linalg._iterative_classical_gram_schmidt(Q,x,xnorm,max_iterations=2)
jax._src.scipy.sparse.linalg._kth_arnoldi_iteration(k,A,M,V,H)
jax._src.scipy.sparse.linalg._lstsq(a,b)
jax._src.scipy.sparse.linalg._mul(scalar,tree)
jax._src.scipy.sparse.linalg._norm(x)
jax._src.scipy.sparse.linalg._normalize_matvec(f)
jax._src.scipy.sparse.linalg._project_on_columns(A,v)
jax._src.scipy.sparse.linalg._rotate_vectors(H,i,cs,sn)
jax._src.scipy.sparse.linalg._safe_normalize(x,thresh=None)
jax._src.scipy.sparse.linalg._shapes(pytree)
jax._src.scipy.sparse.linalg._vdot_real_part(x,y)
jax._src.scipy.sparse.linalg._vdot_real_tree(x,y)
jax._src.scipy.sparse.linalg._vdot_tree(x,y)
jax._src.scipy.sparse.linalg.bicgstab(A,b,x0=None,*,tol=1e-05,atol=0.0,maxiter=None,M=None)
jax._src.scipy.sparse.linalg.cg(A,b,x0=None,*,tol=1e-05,atol=0.0,maxiter=None,M=None)
jax._src.scipy.sparse.linalg.gmres(A,b,x0=None,*,tol=1e-05,atol=0.0,restart=20,maxiter=None,M=None,solve_method='batched')


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/beta.py----------------------------------------
A:jax._src.scipy.stats.beta.(x, a, b, loc, scale)->_promote_args_inexact('beta.logpdf', x, a, b, loc, scale)
A:jax._src.scipy.stats.beta.one->_lax_const(x, 1)
A:jax._src.scipy.stats.beta.shape_term->jax.lax.neg(betaln(a, b))
A:jax._src.scipy.stats.beta.y->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.beta.log_linear_term->jax.lax.add(xlogy(lax.sub(a, one), y), xlog1py(lax.sub(b, one), lax.neg(y)))
A:jax._src.scipy.stats.beta.log_probs->jax.lax.sub(lax.add(shape_term, log_linear_term), lax.log(scale))
jax._src.scipy.stats.beta.logpdf(x,a,b,loc=0,scale=1)
jax._src.scipy.stats.beta.pdf(x,a,b,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/multivariate_normal.py----------------------------------------
A:jax._src.scipy.stats.multivariate_normal.(x, mean, cov)->_promote_dtypes_inexact(x, mean, cov)
A:jax._src.scipy.stats.multivariate_normal.L->jax.lax.linalg.cholesky(cov)
A:jax._src.scipy.stats.multivariate_normal.y->jax.numpy.vectorize(partial(lax.linalg.triangular_solve, lower=True, transpose_a=True), signature='(n,n),(n)->(n)')(L, x - mean)
jax._src.scipy.stats.multivariate_normal.logpdf(x,mean,cov,allow_singular=None)
jax._src.scipy.stats.multivariate_normal.pdf(x,mean,cov)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/chi2.py----------------------------------------
A:jax._src.scipy.stats.chi2.(x, df, loc, scale)->_promote_args_inexact('chi2.logpdf', x, df, loc, scale)
A:jax._src.scipy.stats.chi2.one->_lax_const(x, 1)
A:jax._src.scipy.stats.chi2.two->_lax_const(x, 2)
A:jax._src.scipy.stats.chi2.y->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.chi2.df_on_two->jax.lax.div(df, two)
A:jax._src.scipy.stats.chi2.kernel->jax.lax.sub(lax.mul(lax.sub(df_on_two, one), lax.log(y)), lax.div(y, two))
A:jax._src.scipy.stats.chi2.nrml_cnst->jax.lax.neg(lax.add(lax.lgamma(df_on_two), lax.div(lax.mul(lax.log(two), df), two)))
A:jax._src.scipy.stats.chi2.log_probs->jax.lax.add(lax.sub(nrml_cnst, lax.log(scale)), kernel)
jax._src.scipy.stats.chi2.logpdf(x,df,loc=0,scale=1)
jax._src.scipy.stats.chi2.pdf(x,df,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/cauchy.py----------------------------------------
A:jax._src.scipy.stats.cauchy.(x, loc, scale)->_promote_args_inexact('cauchy.logpdf', x, loc, scale)
A:jax._src.scipy.stats.cauchy.pi->_lax_const(x, np.pi)
A:jax._src.scipy.stats.cauchy.scaled_x->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.cauchy.normalize_term->jax.lax.log(lax.mul(pi, scale))
jax._src.scipy.stats.cauchy.logpdf(x,loc=0,scale=1)
jax._src.scipy.stats.cauchy.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/bernoulli.py----------------------------------------
A:jax._src.scipy.stats.bernoulli.(k, p, loc)->jax._src.numpy.lax_numpy._promote_args_inexact('bernoulli.logpmf', k, p, loc)
A:jax._src.scipy.stats.bernoulli.zero->_lax_const(k, 0)
A:jax._src.scipy.stats.bernoulli.one->_lax_const(k, 1)
A:jax._src.scipy.stats.bernoulli.x->jax.lax.sub(k, loc)
jax._src.scipy.stats.bernoulli.logpmf(k,p,loc=0)
jax._src.scipy.stats.bernoulli.pmf(k,p,loc=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/logistic.py----------------------------------------
jax._src.scipy.stats.logistic.cdf(x)
jax._src.scipy.stats.logistic.isf(x)
jax._src.scipy.stats.logistic.logpdf(x)
jax._src.scipy.stats.logistic.pdf(x)
jax._src.scipy.stats.logistic.ppf(x)
jax._src.scipy.stats.logistic.sf(x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/expon.py----------------------------------------
A:jax._src.scipy.stats.expon.(x, loc, scale)->_promote_args_inexact('expon.logpdf', x, loc, scale)
A:jax._src.scipy.stats.expon.log_scale->jax.lax.log(scale)
A:jax._src.scipy.stats.expon.linear_term->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.expon.log_probs->jax.lax.neg(lax.add(linear_term, log_scale))
jax._src.scipy.stats.expon.logpdf(x,loc=0,scale=1)
jax._src.scipy.stats.expon.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/nbinom.py----------------------------------------
A:jax._src.scipy.stats.nbinom.(k, n, p, loc)->_promote_args_inexact('nbinom.logpmf', k, n, p, loc)
A:jax._src.scipy.stats.nbinom.one->_lax_const(k, 1)
A:jax._src.scipy.stats.nbinom.y->jax.lax.sub(k, loc)
A:jax._src.scipy.stats.nbinom.comb_term->jax.lax.sub(lax.sub(gammaln(lax.add(y, n)), gammaln(n)), gammaln(lax.add(y, one)))
A:jax._src.scipy.stats.nbinom.log_linear_term->jax.lax.add(xlogy(n, p), xlogy(y, lax.sub(one, p)))
A:jax._src.scipy.stats.nbinom.log_probs->jax.lax.add(comb_term, log_linear_term)
jax._src.scipy.stats.nbinom.logpmf(k,n,p,loc=0)
jax._src.scipy.stats.nbinom.pmf(k,n,p,loc=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/poisson.py----------------------------------------
A:jax._src.scipy.stats.poisson.(k, mu, loc)->jax._src.numpy.lax_numpy._promote_args_inexact('poisson.logpmf', k, mu, loc)
A:jax._src.scipy.stats.poisson.zero->_lax_const(k, 0)
A:jax._src.scipy.stats.poisson.x->jax.lax.sub(k, loc)
A:jax._src.scipy.stats.poisson.p->gammaincc(jnp.floor(1 + x), mu)
jax._src.scipy.stats.poisson.cdf(k,mu,loc=0)
jax._src.scipy.stats.poisson.logpmf(k,mu,loc=0)
jax._src.scipy.stats.poisson.pmf(k,mu,loc=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/betabinom.py----------------------------------------
A:jax._src.scipy.stats.betabinom.scipy_version->tuple(map(int, scipy.version.version.split('.')[:2]))
A:jax._src.scipy.stats.betabinom.(k, n, a, b, loc)->_promote_args_inexact('betabinom.logpmf', k, n, a, b, loc)
A:jax._src.scipy.stats.betabinom.y->jax.lax.sub(lax.floor(k), loc)
A:jax._src.scipy.stats.betabinom.one->_lax_const(y, 1)
A:jax._src.scipy.stats.betabinom.zero->_lax_const(y, 0)
A:jax._src.scipy.stats.betabinom.combiln->jax.lax.neg(lax.add(lax.log1p(n), betaln(lax.add(lax.sub(n, y), one), lax.add(y, one))))
A:jax._src.scipy.stats.betabinom.beta_lns->jax.lax.sub(betaln(lax.add(y, a), lax.add(lax.sub(n, y), b)), betaln(a, b))
A:jax._src.scipy.stats.betabinom.log_probs->where(y_cond, -inf, log_probs)
A:jax._src.scipy.stats.betabinom.y_cond->logical_or(lax.lt(y, lax.neg(loc)), lax.gt(y, lax.sub(n, loc)))
A:jax._src.scipy.stats.betabinom.n_a_b_cond->logical_or(logical_or(lax.lt(n, one), lax.lt(a, zero)), lax.lt(b, zero))
A:jax._src.scipy.stats.betabinom.logpmf->_wraps(osp_stats.betabinom.logpmf, update_doc=False)(logpmf)
A:jax._src.scipy.stats.betabinom.pmf->_wraps(osp_stats.betabinom.pmf, update_doc=False)(pmf)
jax._src.scipy.stats.betabinom.logpmf(k,n,a,b,loc=0)
jax._src.scipy.stats.betabinom.pmf(k,n,a,b,loc=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/t.py----------------------------------------
A:jax._src.scipy.stats.t.(x, df, loc, scale)->_promote_args_inexact('t.logpdf', x, df, loc, scale)
A:jax._src.scipy.stats.t.two->_lax_const(x, 2)
A:jax._src.scipy.stats.t.scaled_x->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.t.df_over_two->jax.lax.div(df, two)
A:jax._src.scipy.stats.t.df_plus_one_over_two->jax.lax.add(df_over_two, _lax_const(x, 0.5))
A:jax._src.scipy.stats.t.normalize_term_const->jax.lax.mul(lax.mul(scale, scale), _lax_const(x, np.pi))
A:jax._src.scipy.stats.t.normalize_term_tmp->jax.lax.div(lax.log(lax.mul(normalize_term_const, df)), two)
A:jax._src.scipy.stats.t.normalize_term->jax.lax.sub(lax.add(lax.lgamma(df_over_two), normalize_term_tmp), lax.lgamma(df_plus_one_over_two))
A:jax._src.scipy.stats.t.quadratic->jax.lax.div(lax.mul(scaled_x, scaled_x), df)
jax._src.scipy.stats.t.logpdf(x,df,loc=0,scale=1)
jax._src.scipy.stats.t.pdf(x,df,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/laplace.py----------------------------------------
A:jax._src.scipy.stats.laplace.(x, loc, scale)->_promote_args_inexact('laplace.cdf', x, loc, scale)
A:jax._src.scipy.stats.laplace.two->_lax_const(x, 2)
A:jax._src.scipy.stats.laplace.linear_term->jax.lax.div(lax.abs(lax.sub(x, loc)), scale)
A:jax._src.scipy.stats.laplace.half->_lax_const(x, 0.5)
A:jax._src.scipy.stats.laplace.one->_lax_const(x, 1)
A:jax._src.scipy.stats.laplace.zero->_lax_const(x, 0)
A:jax._src.scipy.stats.laplace.diff->jax.lax.div(lax.sub(x, loc), scale)
jax._src.scipy.stats.laplace.cdf(x,loc=0,scale=1)
jax._src.scipy.stats.laplace.logpdf(x,loc=0,scale=1)
jax._src.scipy.stats.laplace.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/geom.py----------------------------------------
A:jax._src.scipy.stats.geom.(k, p, loc)->jax._src.numpy.lax_numpy._promote_args_inexact('geom.logpmf', k, p, loc)
A:jax._src.scipy.stats.geom.zero->_lax_const(k, 0)
A:jax._src.scipy.stats.geom.one->_lax_const(k, 1)
A:jax._src.scipy.stats.geom.x->jax.lax.sub(k, loc)
jax._src.scipy.stats.geom.logpmf(k,p,loc=0)
jax._src.scipy.stats.geom.pmf(k,p,loc=0)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/pareto.py----------------------------------------
A:jax._src.scipy.stats.pareto.(x, b, loc, scale)->_promote_args_inexact('pareto.logpdf', x, b, loc, scale)
A:jax._src.scipy.stats.pareto.one->_lax_const(x, 1)
A:jax._src.scipy.stats.pareto.scaled_x->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.pareto.normalize_term->jax.lax.log(lax.div(scale, b))
A:jax._src.scipy.stats.pareto.log_probs->jax.lax.neg(lax.add(normalize_term, lax.mul(lax.add(b, one), lax.log(scaled_x))))
jax._src.scipy.stats.pareto.logpdf(x,b,loc=0,scale=1)
jax._src.scipy.stats.pareto.pdf(x,b,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/norm.py----------------------------------------
A:jax._src.scipy.stats.norm.(x, loc, scale)->_promote_args_inexact('norm.logcdf', x, loc, scale)
A:jax._src.scipy.stats.norm.scale_sqrd->jax.lax.square(scale)
A:jax._src.scipy.stats.norm.log_normalizer->jax.lax.log(lax.mul(_lax_const(x, 2 * np.pi), scale_sqrd))
A:jax._src.scipy.stats.norm.quadratic->jax.lax.div(lax.square(lax.sub(x, loc)), scale_sqrd)
jax._src.scipy.stats.norm.cdf(x,loc=0,scale=1)
jax._src.scipy.stats.norm.logcdf(x,loc=0,scale=1)
jax._src.scipy.stats.norm.logpdf(x,loc=0,scale=1)
jax._src.scipy.stats.norm.pdf(x,loc=0,scale=1)
jax._src.scipy.stats.norm.ppf(q,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/dirichlet.py----------------------------------------
A:jax._src.scipy.stats.dirichlet.x_sum->jax._src.numpy.lax_numpy.sum(x, axis=0)
A:jax._src.scipy.stats.dirichlet.(x, alpha)->_promote_dtypes_inexact(x, alpha)
A:jax._src.scipy.stats.dirichlet.one->_lax_const(x, 1)
A:jax._src.scipy.stats.dirichlet.x->jax._src.numpy.lax_numpy.concatenate([x, lax.sub(one, x.sum(0, keepdims=True))], axis=0)
A:jax._src.scipy.stats.dirichlet.alpha->jax.lax.broadcast_in_dim(alpha, alpha.shape + (1,) * (x.ndim - 1), (0,))
A:jax._src.scipy.stats.dirichlet.log_probs->jax.lax.sub(jnp.sum(xlogy(lax.sub(alpha, one), x), axis=0), normalize_term)
jax._src.scipy.stats.dirichlet._is_simplex(x)
jax._src.scipy.stats.dirichlet.logpdf(x,alpha)
jax._src.scipy.stats.dirichlet.pdf(x,alpha)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/gamma.py----------------------------------------
A:jax._src.scipy.stats.gamma.(x, a, loc, scale)->_promote_args_inexact('gamma.logpdf', x, a, loc, scale)
A:jax._src.scipy.stats.gamma.one->_lax_const(x, 1)
A:jax._src.scipy.stats.gamma.y->jax.lax.div(lax.sub(x, loc), scale)
A:jax._src.scipy.stats.gamma.log_linear_term->jax.lax.sub(xlogy(lax.sub(a, one), y), y)
A:jax._src.scipy.stats.gamma.shape_terms->jax.lax.add(gammaln(a), lax.log(scale))
A:jax._src.scipy.stats.gamma.log_probs->jax.lax.sub(log_linear_term, shape_terms)
jax._src.scipy.stats.gamma.logpdf(x,a,loc=0,scale=1)
jax._src.scipy.stats.gamma.pdf(x,a,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/stats/uniform.py----------------------------------------
A:jax._src.scipy.stats.uniform.(x, loc, scale)->_promote_args_inexact('uniform.logpdf', x, loc, scale)
A:jax._src.scipy.stats.uniform.log_probs->jax.lax.neg(lax.log(scale))
jax._src.scipy.stats.uniform.logpdf(x,loc=0,scale=1)
jax._src.scipy.stats.uniform.pdf(x,loc=0,scale=1)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/optimize/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/optimize/bfgs.py----------------------------------------
A:jax._src.scipy.optimize.bfgs._dot->partial(jnp.dot, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.optimize.bfgs._einsum->partial(jnp.einsum, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.optimize.bfgs.initial_H->jax.numpy.eye(d, dtype=x0.dtype)
A:jax._src.scipy.optimize.bfgs.(f_0, g_0)->jax.value_and_grad(fun)(x0)
A:jax._src.scipy.optimize.bfgs.state->state._replace(status=status)._replace(status=status)
A:jax._src.scipy.optimize.bfgs.line_search_results->line_search(fun, state.x_k, p_k, old_fval=state.f_k, old_old_fval=state.old_old_fval, gfk=state.g_k, maxiter=line_search_maxiter)
A:jax._src.scipy.optimize.bfgs.rho_k->jax.numpy.reciprocal(_dot(y_k, s_k))
A:jax._src.scipy.optimize.bfgs.H_kp1->jax.numpy.where(jnp.isfinite(rho_k), H_kp1, state.H_k)
A:jax._src.scipy.optimize.bfgs.status->jax.numpy.where(state.converged, 0, jnp.where(state.k == maxiter, 1, jnp.where(state.failed, 2 + state.line_search_status, -1)))
jax._src.scipy.optimize.bfgs._BFGSResults(NamedTuple)
jax._src.scipy.optimize.bfgs.minimize_bfgs(fun:Callable,x0:jnp.ndarray,maxiter:Optional[int]=None,norm=jnp.inf,gtol:float=1e-05,line_search_maxiter:int=10)->_BFGSResults


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/optimize/line_search.py----------------------------------------
A:jax._src.scipy.optimize.line_search._dot->partial(jnp.dot, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.optimize.line_search.d1->jax.numpy.array([[dc ** 2, -db ** 2], [-dc ** 3, db ** 3]])
A:jax._src.scipy.optimize.line_search.keys->new_dict.keys()
A:jax._src.scipy.optimize.line_search.out->dict()
A:jax._src.scipy.optimize.line_search.out[key]->jax.numpy.where(replace_bit, new_dict[key], original_dict[key])
A:jax._src.scipy.optimize.line_search.state->jax.lax.while_loop(lambda state: ~state.done & (state.i <= maxiter) & ~state.failed, body, state)
A:jax._src.scipy.optimize.line_search.a->jax.numpy.minimum(state.a_hi, state.a_lo)
A:jax._src.scipy.optimize.line_search.b->jax.numpy.maximum(state.a_hi, state.a_lo)
A:jax._src.scipy.optimize.line_search.threshold->jax.numpy.where(jnp.finfo(dalpha).bits < 64, 1e-05, 1e-10)
A:jax._src.scipy.optimize.line_search.a_j_cubic->_cubicmin(state.a_lo, state.phi_lo, state.dphi_lo, state.a_hi, state.phi_hi, state.a_rec, state.phi_rec)
A:jax._src.scipy.optimize.line_search.a_j_quad->_quadmin(state.a_lo, state.phi_lo, state.dphi_lo, state.a_hi, state.phi_hi)
A:jax._src.scipy.optimize.line_search.a_j->jax.numpy.where(use_bisection, a_j_bisection, a_j)
A:jax._src.scipy.optimize.line_search.(phi_j, dphi_j, g_j)->restricted_func_and_grad(a_j)
A:jax._src.scipy.optimize.line_search.phi_j->phi_j.astype(state.phi_lo.dtype).astype(state.phi_lo.dtype)
A:jax._src.scipy.optimize.line_search.dphi_j->dphi_j.astype(state.dphi_lo.dtype).astype(state.dphi_lo.dtype)
A:jax._src.scipy.optimize.line_search.g_j->g_j.astype(state.g_star.dtype).astype(state.g_star.dtype)
A:jax._src.scipy.optimize.line_search.(phi, g)->jax.value_and_grad(f)(xk + t * pk)
A:jax._src.scipy.optimize.line_search.dphi->jax.numpy.real(_dot(g, pk))
A:jax._src.scipy.optimize.line_search.(phi_0, dphi_0, gfk)->restricted_func_and_grad(0.0)
A:jax._src.scipy.optimize.line_search.dphi_0->jax.numpy.real(_dot(gfk, pk))
A:jax._src.scipy.optimize.line_search.start_value->jax.numpy.where(candidate_start_value > 1, 1.0, candidate_start_value)
A:jax._src.scipy.optimize.line_search.a_i->jax.numpy.where(state.i == 1, start_value, state.a_i1 * 2.0)
A:jax._src.scipy.optimize.line_search.(phi_i, dphi_i, g_i)->restricted_func_and_grad(a_i)
A:jax._src.scipy.optimize.line_search.zoom1->_zoom(restricted_func_and_grad, wolfe_one, wolfe_two, state.a_i1, state.phi_i1, state.dphi_i1, a_i, phi_i, dphi_i, gfk, ~star_to_zoom1)
A:jax._src.scipy.optimize.line_search.zoom2->_zoom(restricted_func_and_grad, wolfe_one, wolfe_two, a_i, phi_i, dphi_i, state.a_i1, state.phi_i1, state.dphi_i1, gfk, ~star_to_zoom2)
A:jax._src.scipy.optimize.line_search.status->jax.numpy.where(state.failed, jnp.array(1), jnp.where(state.i > maxiter, jnp.array(3), jnp.array(0)))
A:jax._src.scipy.optimize.line_search.alpha_k->jax.numpy.where((jnp.finfo(alpha_k).bits != 64) & (jnp.abs(alpha_k) < 1e-08), jnp.sign(alpha_k) * 1e-08, alpha_k)
A:jax._src.scipy.optimize.line_search.results->_LineSearchResults(failed=state.failed | ~state.done, nit=state.i - 1, nfev=state.nfev, ngev=state.ngev, k=state.i, a_k=alpha_k, f_k=state.phi_star, g_k=state.g_star, status=status)
jax._src.scipy.optimize.line_search._LineSearchResults(NamedTuple)
jax._src.scipy.optimize.line_search._LineSearchState(NamedTuple)
jax._src.scipy.optimize.line_search._ZoomState(NamedTuple)
jax._src.scipy.optimize.line_search._binary_replace(replace_bit,original_dict,new_dict,keys=None)
jax._src.scipy.optimize.line_search._cubicmin(a,fa,fpa,b,fb,c,fc)
jax._src.scipy.optimize.line_search._quadmin(a,fa,fpa,b,fb)
jax._src.scipy.optimize.line_search._zoom(restricted_func_and_grad,wolfe_one,wolfe_two,a_lo,phi_lo,dphi_lo,a_hi,phi_hi,dphi_hi,g_0,pass_through)
jax._src.scipy.optimize.line_search.line_search(f,xk,pk,old_fval=None,old_old_fval=None,gfk=None,c1=0.0001,c2=0.9,maxiter=20)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/optimize/_lbfgs.py----------------------------------------
A:jax._src.scipy.optimize._lbfgs._dot->partial(jnp.dot, precision=lax.Precision.HIGHEST)
A:jax._src.scipy.optimize._lbfgs.d->len(x0)
A:jax._src.scipy.optimize._lbfgs.dtype->jax.numpy.dtype(x0)
A:jax._src.scipy.optimize._lbfgs.(f_0, g_0)->jax.value_and_grad(fun)(x0)
A:jax._src.scipy.optimize._lbfgs.state_initial->LBFGSResults(converged=False, failed=False, k=0, nfev=1, ngev=1, x_k=x0, f_k=f_0, g_k=g_0, s_history=jnp.zeros((maxcor, d), dtype=dtype), y_history=jnp.zeros((maxcor, d), dtype=dtype), rho_history=jnp.zeros((maxcor,), dtype=dtype), gamma=1.0, status=0, ls_status=0)
A:jax._src.scipy.optimize._lbfgs.p_k->_two_loop_recursion(state)
A:jax._src.scipy.optimize._lbfgs.ls_results->line_search(f=fun, xk=state.x_k, pk=p_k, old_fval=state.f_k, gfk=state.g_k, maxiter=maxls)
A:jax._src.scipy.optimize._lbfgs.rho_k_inv->jax.numpy.real(_dot(y_k, s_k))
A:jax._src.scipy.optimize._lbfgs.rho_k->jax.numpy.reciprocal(rho_k_inv)
A:jax._src.scipy.optimize._lbfgs.status->jax.numpy.where(ls_results.failed, 5, status)
A:jax._src.scipy.optimize._lbfgs.state->state._replace(converged=converged, failed=(status > 0) & ~converged, k=state.k + 1, nfev=state.nfev + ls_results.nfev, ngev=state.ngev + ls_results.ngev, x_k=x_kp1.astype(state.x_k.dtype), f_k=f_kp1.astype(state.f_k.dtype), g_k=g_kp1.astype(state.g_k.dtype), s_history=_update_history_vectors(history=state.s_history, new=s_k), y_history=_update_history_vectors(history=state.y_history, new=y_k), rho_history=_update_history_scalars(history=state.rho_history, new=rho_k), gamma=gamma, status=jnp.where(converged, 0, status), ls_status=ls_results.status)._replace(converged=converged, failed=(status > 0) & ~converged, k=state.k + 1, nfev=state.nfev + ls_results.nfev, ngev=state.ngev + ls_results.ngev, x_k=x_kp1.astype(state.x_k.dtype), f_k=f_kp1.astype(state.f_k.dtype), g_k=g_kp1.astype(state.g_k.dtype), s_history=_update_history_vectors(history=state.s_history, new=s_k), y_history=_update_history_vectors(history=state.y_history, new=y_k), rho_history=_update_history_scalars(history=state.rho_history, new=rho_k), gamma=gamma, status=jnp.where(converged, 0, status), ls_status=ls_results.status)
A:jax._src.scipy.optimize._lbfgs.his_size->len(state.rho_history)
A:jax._src.scipy.optimize._lbfgs.curr_size->jax.numpy.where(state.k < his_size, state.k, his_size)
A:jax._src.scipy.optimize._lbfgs.a_his->jax.numpy.zeros_like(state.rho_history)
A:jax._src.scipy.optimize._lbfgs._a_his->_a_his.at[i].set(a_i).at[i].set(a_i)
A:jax._src.scipy.optimize._lbfgs.(q, a_his)->jax.lax.fori_loop(0, curr_size, body_fun1, (q, a_his))
A:jax._src.scipy.optimize._lbfgs.q->jax.lax.fori_loop(0, curr_size, body_fun2, q)
jax._src.scipy.optimize._lbfgs.LBFGSResults(NamedTuple)
jax._src.scipy.optimize._lbfgs._minimize_lbfgs(fun:Callable,x0:Array,maxiter:Optional[float]=None,norm=jnp.inf,maxcor:int=10,ftol:float=2.220446049250313e-09,gtol:float=1e-05,maxfun:Optional[float]=None,maxgrad:Optional[float]=None,maxls:int=20)
jax._src.scipy.optimize._lbfgs._two_loop_recursion(state:LBFGSResults)
jax._src.scipy.optimize._lbfgs._update_history_scalars(history,new)
jax._src.scipy.optimize._lbfgs._update_history_vectors(history,new)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/optimize/minimize.py----------------------------------------
A:jax._src.scipy.optimize.minimize.results->_minimize_lbfgs(fun_with_args, x0, **options)
jax._src.scipy.optimize.minimize.OptimizeResults(NamedTuple)
jax._src.scipy.optimize.minimize.minimize(fun:Callable,x0:jnp.ndarray,args:Tuple=(),*,method:str,tol:Optional[float]=None,options:Optional[Mapping[str,Any]]=None)->OptimizeResults


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/scipy/interpolate/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lib/__init__.py----------------------------------------
A:jax._src.lib.__init__.version_regex->re.compile('[0-9]+(?:\\.[0-9]+)*')
A:jax._src.lib.__init__.m->re.compile('[0-9]+(?:\\.[0-9]+)*').match(v)
A:jax._src.lib.__init__._jax_version->_parse_version(jax_version)
A:jax._src.lib.__init__._minimum_jaxlib_version->_parse_version(minimum_jaxlib_version)
A:jax._src.lib.__init__._jaxlib_version->_parse_version(jaxlib_version)
A:jax._src.lib.__init__.version->check_jaxlib_version(jax_version=jax.version.__version__, jaxlib_version=jaxlib.version.__version__, minimum_jaxlib_version=jax.version._minimum_jaxlib_version)
A:jax._src.lib.__init__.xla_extension_version->getattr(xla_client, '_version', 0)
A:jax._src.lib.__init__.mlir_api_version->getattr(xla_client, 'mlir_api_version', 0)
A:jax._src.lib.__init__.cuda_path->os.path.join(os.path.dirname(jaxlib.__file__), 'cuda')
jax._src.lib.__init__.check_jaxlib_version(jax_version:str,jaxlib_version:str,minimum_jaxlib_version:str)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lib/xla_bridge.py----------------------------------------
A:jax._src.lib.xla_bridge.compile_options->jax._src.lib.xla_client.CompileOptions()
A:jax._src.lib.xla_bridge.device_assignment->jax._src.lib.xla_client.DeviceAssignment.create(device_assignment)
A:jax._src.lib.xla_bridge.t->threading.Timer(timer_secs, _log_warning)
A:jax._src.lib.xla_bridge.client->jax._src.lib.xla_client.make_tpu_client()
A:jax._src.lib.xla_bridge._backend_lock->threading.Lock()
A:jax._src.lib.xla_bridge.platforms->FLAGS.jax_platforms.split(',')
A:jax._src.lib.xla_bridge.priorities->range(len(platforms), 0, -1)
A:jax._src.lib.xla_bridge.platforms_and_priorites->zip(platforms, priorities)
A:jax._src.lib.xla_bridge.backend->backends().get(platform, None)
A:jax._src.lib.xla_bridge._backends_errors[platform]->str(err)
A:jax._src.lib.xla_bridge.(factory, unused_priority)->_backend_factories.get(platform, (None, None))
A:jax._src.lib.xla_bridge.bs->backends()
A:jax._src.lib.xla_bridge.process_index->get_backend(backend).process_index()
jax._src.lib.xla_bridge._get_backend_uncached(platform=None)
jax._src.lib.xla_bridge._init_backend(platform)
jax._src.lib.xla_bridge._make_tpu_driver_client()
jax._src.lib.xla_bridge.backends()
jax._src.lib.xla_bridge.default_backend()->str
jax._src.lib.xla_bridge.device_count(backend:Optional[Union[str,XlaBackend]]=None)->int
jax._src.lib.xla_bridge.devices(backend:Optional[Union[str,XlaBackend]]=None)->List[xla_client.Device]
jax._src.lib.xla_bridge.get_backend(platform=None)
jax._src.lib.xla_bridge.get_compile_options(num_replicas:int,num_partitions:int,device_assignment=None,use_spmd_partitioning:bool=True,use_auto_spmd_partitioning:bool=False,auto_spmd_partitioning_mesh_shape=[],auto_spmd_partitioning_mesh_ids=[])->xla_client.CompileOptions
jax._src.lib.xla_bridge.get_device_backend(device=None)
jax._src.lib.xla_bridge.host_count(backend=None)
jax._src.lib.xla_bridge.host_id(backend=None)
jax._src.lib.xla_bridge.host_ids(backend=None)
jax._src.lib.xla_bridge.local_device_count(backend:Optional[Union[str,XlaBackend]]=None)->int
jax._src.lib.xla_bridge.local_devices(process_index:Optional[int]=None,backend:Optional[Union[str,XlaBackend]]=None,host_id:Optional[int]=None)->List[xla_client.Device]
jax._src.lib.xla_bridge.process_count(backend:Optional[Union[str,XlaBackend]]=None)->int
jax._src.lib.xla_bridge.process_index(backend:Optional[Union[str,XlaBackend]]=None)->int
jax._src.lib.xla_bridge.register_backend_factory(name,factory,*,priority=0)
jax._src.lib.xla_bridge.tpu_client_timer_callback(timer_secs:float)
jax._src.lib.xla_bridge.tpu_driver_client_timer_callback(timer_secs:float)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lib/mlir/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lib/mlir/dialects/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/setops.py----------------------------------------
A:jax._src.numpy.setops.ar1->ravel(ar1)
A:jax._src.numpy.setops.ar2->ravel(ar2)
A:jax._src.numpy.setops.size->jax.core.concrete_or_error(operator.index, size, 'The error arose for the size argument of jnp.unique()')
A:jax._src.numpy.setops.fill_value->asarray(fill_value, dtype=result.dtype)
A:jax._src.numpy.setops.mask->zeros(size, dtype=bool)
A:jax._src.numpy.setops.aux->where(isnan(aux), _lax_const(aux, np.nan), aux)
A:jax._src.numpy.setops.flag->concatenate((array([True]), aux[1:] != aux[:-1], array([True])))
A:jax._src.numpy.setops.ar->ar.flatten().flatten()
A:jax._src.numpy.setops.iota->jax.lax.broadcasted_iota(np.int64, np.shape(ar), dimension=0)
A:jax._src.numpy.setops.(aux, indices)->jax.lax.sort_key_val(ar, iota)
A:jax._src.numpy.setops.(ar1, ind1)->unique(ar1, return_index=True)
A:jax._src.numpy.setops.(ar2, ind2)->unique(ar2, return_index=True)
A:jax._src.numpy.setops.(aux, mask, aux_sort_indices)->_intersect1d_sorted_mask(ar1, ar2, return_indices)
A:jax._src.numpy.setops.(aux, mask)->_intersect1d_sorted_mask(ar1, ar2, return_indices)
A:jax._src.numpy.setops.result->moveaxis(result, 0, axis)
A:jax._src.numpy.setops.perm->lexsort(aux.reshape(size, _prod(out_shape)).T[::-1])
A:jax._src.numpy.setops.(aux, mask, perm)->_unique_sorted_mask(ar, axis)
A:jax._src.numpy.setops.valid->jax.lax.expand_dims(arange(size) < mask.sum(), tuple(range(1, result.ndim)))
A:jax._src.numpy.setops.inv_idx->zeros(ar.shape[axis], dtype=int)
A:jax._src.numpy.setops.idx->idx.at[1:].set(where(idx[1:], idx[1:], mask.size)).at[1:].set(where(idx[1:], idx[1:], mask.size))
A:jax._src.numpy.setops.axis->jax.core.concrete_or_error(operator.index, axis, 'axis argument of jnp.unique()')
jax._src.numpy.setops._intersect1d_sorted_mask(ar1,ar2,return_indices=False)
jax._src.numpy.setops._unique(ar,axis,return_index=False,return_inverse=False,return_counts=False,size=None,fill_value=None,return_true_size=False)
jax._src.numpy.setops._unique_sorted_mask(ar,axis)
jax._src.numpy.setops.in1d(ar1,ar2,assume_unique=False,invert=False)
jax._src.numpy.setops.intersect1d(ar1,ar2,assume_unique=False,return_indices=False)
jax._src.numpy.setops.isin(element,test_elements,assume_unique=False,invert=False)
jax._src.numpy.setops.setdiff1d(ar1,ar2,assume_unique=False,*,size=None,fill_value=None)
jax._src.numpy.setops.setxor1d(ar1,ar2,assume_unique=False)
jax._src.numpy.setops.union1d(ar1,ar2,*,size=None,fill_value=None)
jax._src.numpy.setops.unique(ar,return_index=False,return_inverse=False,return_counts=False,axis:Optional[int]=None,*,size=None,fill_value=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/ndarray.py----------------------------------------
jax._src.numpy.ndarray.ArrayMeta(abc.ABCMeta)
jax._src.numpy.ndarray.ArrayMeta.__instancecheck__(self,instance)
jax._src.numpy.ndarray.ndarray(self,shape,dtype=None,buffer=None,offset=0,strides=None,order=None)
jax._src.numpy.ndarray.ndarray.__abs__(self)->Any
jax._src.numpy.ndarray.ndarray.__add__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__and__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__array__(self)->Any
jax._src.numpy.ndarray.ndarray.__bool__(self)->Any
jax._src.numpy.ndarray.ndarray.__complex__(self)->Any
jax._src.numpy.ndarray.ndarray.__divmod__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__eq__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__float__(self)->Any
jax._src.numpy.ndarray.ndarray.__floordiv__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__ge__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__getitem__(self,key,indices_are_sorted=False,unique_indices=False)->Any
jax._src.numpy.ndarray.ndarray.__gt__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__index__(self)->Any
jax._src.numpy.ndarray.ndarray.__init__(self,shape,dtype=None,buffer=None,offset=0,strides=None,order=None)
jax._src.numpy.ndarray.ndarray.__int__(self)->Any
jax._src.numpy.ndarray.ndarray.__invert__(self)->Any
jax._src.numpy.ndarray.ndarray.__iter__(self)->Any
jax._src.numpy.ndarray.ndarray.__le__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__len__(self)->Any
jax._src.numpy.ndarray.ndarray.__lshift__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__lt__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__matmul__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__mod__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__mul__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__ne__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__neg__(self)->Any
jax._src.numpy.ndarray.ndarray.__or__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__pos__(self)->Any
jax._src.numpy.ndarray.ndarray.__pow__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__radd__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rand__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rdivmod__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__reversed__(self)->Any
jax._src.numpy.ndarray.ndarray.__rfloordiv__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rlshift__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rmatmul__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rmod__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rmul__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__ror__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__round__(self,ndigits=None)->Any
jax._src.numpy.ndarray.ndarray.__rpow__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rrshift__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rshift__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rsub__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rtruediv__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__rxor__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__setitem__(self,key,value)->Any
jax._src.numpy.ndarray.ndarray.__sub__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__truediv__(self,other)->Any
jax._src.numpy.ndarray.ndarray.__xor__(self,other)->Any
jax._src.numpy.ndarray.ndarray.all(self,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None)->Any
jax._src.numpy.ndarray.ndarray.any(self,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None)->Any
jax._src.numpy.ndarray.ndarray.argmax(self,axis:Optional[int]=None,out=None,keepdims=None)->Any
jax._src.numpy.ndarray.ndarray.argmin(self,axis:Optional[int]=None,out=None,keepdims=None)->Any
jax._src.numpy.ndarray.ndarray.argpartition(self,kth,axis=-1,kind='introselect',order=None)->Any
jax._src.numpy.ndarray.ndarray.argsort(self,axis:Optional[int]=-1,kind='quicksort',order=None)->Any
jax._src.numpy.ndarray.ndarray.astype(self,dtype)->Any
jax._src.numpy.ndarray.ndarray.at(self)->Any
jax._src.numpy.ndarray.ndarray.aval(self)->Any
jax._src.numpy.ndarray.ndarray.choose(self,choices,out=None,mode='raise')->Any
jax._src.numpy.ndarray.ndarray.clip(self,a_min=None,a_max=None,out=None)->Any
jax._src.numpy.ndarray.ndarray.compress(self,condition,axis:Optional[int]=None,out=None)->Any
jax._src.numpy.ndarray.ndarray.conj(self)->Any
jax._src.numpy.ndarray.ndarray.conjugate(self)->Any
jax._src.numpy.ndarray.ndarray.copy(self)->Any
jax._src.numpy.ndarray.ndarray.cumprod(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None)->Any
jax._src.numpy.ndarray.ndarray.cumsum(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None)->Any
jax._src.numpy.ndarray.ndarray.diagonal(self,offset=0,axis1:int=0,axis2:int=1)->Any
jax._src.numpy.ndarray.ndarray.dot(self,b,*,precision=None)->Any
jax._src.numpy.ndarray.ndarray.flatten(self)->Any
jax._src.numpy.ndarray.ndarray.imag(self)->Any
jax._src.numpy.ndarray.ndarray.item(self,*args)->Any
jax._src.numpy.ndarray.ndarray.max(self,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)->Any
jax._src.numpy.ndarray.ndarray.mean(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=False,*,where=None)->Any
jax._src.numpy.ndarray.ndarray.min(self,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)->Any
jax._src.numpy.ndarray.ndarray.nbytes(self)->Any
jax._src.numpy.ndarray.ndarray.nonzero(self,*,size=None,fill_value=None)->Any
jax._src.numpy.ndarray.ndarray.prod(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)->Any
jax._src.numpy.ndarray.ndarray.ptp(self,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=False)->Any
jax._src.numpy.ndarray.ndarray.ravel(self,order='C')->Any
jax._src.numpy.ndarray.ndarray.real(self)->Any
jax._src.numpy.ndarray.ndarray.repeat(self,repeats,axis:Optional[int]=None,*,total_repeat_length=None)->Any
jax._src.numpy.ndarray.ndarray.reshape(self,*args,order='C')->Any
jax._src.numpy.ndarray.ndarray.round(self,decimals=0,out=None)->Any
jax._src.numpy.ndarray.ndarray.searchsorted(self,v,side='left',sorter=None)->Any
jax._src.numpy.ndarray.ndarray.sort(self,axis:Optional[int]=-1,kind='quicksort',order=None)->Any
jax._src.numpy.ndarray.ndarray.squeeze(self,axis:Optional[Union[int,Tuple[int,...]]]=None)->Any
jax._src.numpy.ndarray.ndarray.std(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,*,where=None)->Any
jax._src.numpy.ndarray.ndarray.sum(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)->Any
jax._src.numpy.ndarray.ndarray.swapaxes(self,axis1:int,axis2:int)->Any
jax._src.numpy.ndarray.ndarray.take(self,indices,axis:Optional[int]=None,out=None,mode=None)->Any
jax._src.numpy.ndarray.ndarray.tobytes(self,order='C')->Any
jax._src.numpy.ndarray.ndarray.tolist(self)->Any
jax._src.numpy.ndarray.ndarray.trace(self,offset=0,axis1:int=0,axis2:int=1,dtype=None,out=None)->Any
jax._src.numpy.ndarray.ndarray.transpose(self,*args)->Any
jax._src.numpy.ndarray.ndarray.var(self,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,*,where=None)->Any
jax._src.numpy.ndarray.ndarray.view(self,dtype=None,type=None)->Any
jax._src.numpy.ndarray.ndarray.weak_type(self)->bool


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/fft.py----------------------------------------
A:jax._src.numpy.fft.s->tuple(map(operator.index, s))
A:jax._src.numpy.fft.axes->tuple(range(x.ndim))
A:jax._src.numpy.fft.a->jax._src.numpy.lax_numpy.pad(a, [(0, x - y) for (x, y) in zip(in_s, a.shape)])
A:jax._src.numpy.fft.in_s->list(a.shape)
A:jax._src.numpy.fft.transformed->jax._src.numpy.lax_numpy.moveaxis(transformed, axes, orig_axes)
A:jax._src.numpy.fft.conj_a->jax._src.numpy.lax_numpy.conj(a)
A:jax._src.numpy.fft.output->_fft_core_1d('ihfft', xla_client.FftType.RFFT, a, n=n, axis=axis, norm=norm)
A:jax._src.numpy.fft.k->jax._src.numpy.lax_numpy.arange(0, (n - 1) // 2 + 1)
A:jax._src.numpy.fft.x->jax._src.numpy.lax_numpy.asarray(x)
jax._src.numpy.fft._axis_check_1d(func_name,axis)
jax._src.numpy.fft._fft_core(func_name,fft_type,a,s,axes,norm)
jax._src.numpy.fft._fft_core_1d(func_name,fft_type,a,n,axis,norm)
jax._src.numpy.fft._fft_core_2d(func_name,fft_type,a,s,axes,norm)
jax._src.numpy.fft._fft_norm(s,func_name,norm)
jax._src.numpy.fft.fft(a,n=None,axis=-1,norm=None)
jax._src.numpy.fft.fft2(a,s=None,axes=(-2,-1),norm=None)
jax._src.numpy.fft.fftfreq(n,d=1.0)
jax._src.numpy.fft.fftn(a,s=None,axes=None,norm=None)
jax._src.numpy.fft.fftshift(x,axes=None)
jax._src.numpy.fft.hfft(a,n=None,axis=-1,norm=None)
jax._src.numpy.fft.ifft(a,n=None,axis=-1,norm=None)
jax._src.numpy.fft.ifft2(a,s=None,axes=(-2,-1),norm=None)
jax._src.numpy.fft.ifftn(a,s=None,axes=None,norm=None)
jax._src.numpy.fft.ifftshift(x,axes=None)
jax._src.numpy.fft.ihfft(a,n=None,axis=-1,norm=None)
jax._src.numpy.fft.irfft(a,n=None,axis=-1,norm=None)
jax._src.numpy.fft.irfft2(a,s=None,axes=(-2,-1),norm=None)
jax._src.numpy.fft.irfftn(a,s=None,axes=None,norm=None)
jax._src.numpy.fft.rfft(a,n=None,axis=-1,norm=None)
jax._src.numpy.fft.rfft2(a,s=None,axes=(-2,-1),norm=None)
jax._src.numpy.fft.rfftfreq(n,d=1.0)
jax._src.numpy.fft.rfftn(a,s=None,axes=None,norm=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/polynomial.py----------------------------------------
A:jax._src.numpy.polynomial.(p,)->_promote_dtypes_inexact(p)
A:jax._src.numpy.polynomial.A->A.at[0, :].set(-p[1:] / p[0]).at[0, :].set(-p[1:] / p[0])
A:jax._src.numpy.polynomial.roots->hstack((roots, zeros(trailing_zeros, p.dtype)))
A:jax._src.numpy.polynomial.start->argmin(is_zero)
A:jax._src.numpy.polynomial.p->atleast_1d(p)
A:jax._src.numpy.polynomial.(start, end)->_nonzero_range(p)
A:jax._src.numpy.polynomial.deg->jax.core.concrete_or_error(int, deg, 'deg must be int')
A:jax._src.numpy.polynomial.rcond->jax.core.concrete_or_error(float, rcond, 'rcond must be float')
A:jax._src.numpy.polynomial.lhs->vander(x, order)
A:jax._src.numpy.polynomial.(w,)->_promote_dtypes_inexact(w)
A:jax._src.numpy.polynomial.scale->sqrt((lhs * lhs).sum(axis=0))
A:jax._src.numpy.polynomial.(c, resids, rank, s)->jax._src.numpy.linalg.lstsq(lhs, rhs, rcond)
A:jax._src.numpy.polynomial.Vbase->jax._src.numpy.linalg.inv(dot(lhs.T, lhs))
A:jax._src.numpy.polynomial.(seq_of_zeros,)->_promote_dtypes_inexact(seq_of_zeros)
A:jax._src.numpy.polynomial.seq_of_zeros->jax._src.numpy.linalg.eigvals(seq_of_zeros)
A:jax._src.numpy.polynomial.a->convolve(a, array([1, -seq_of_zeros[k]], dtype=dt), mode='full')
A:jax._src.numpy.polynomial.(p, x)->_promote_dtypes_inexact(p, x)
A:jax._src.numpy.polynomial.shape->jax.lax.broadcast_shapes(p.shape[1:], x.shape)
A:jax._src.numpy.polynomial.y->jax.lax.full_like(x, 0, shape=shape, dtype=x.dtype)
A:jax._src.numpy.polynomial.(y, _)->jax.lax.scan(lambda y, p: (y * x + p, None), y, p, unroll=unroll)
A:jax._src.numpy.polynomial.(a1, a2)->_promote_dtypes(a1, a2)
A:jax._src.numpy.polynomial.m->jax.core.concrete_or_error(operator.index, m, "'m' argument of jnp.polyder")
A:jax._src.numpy.polynomial.(p, k)->_promote_dtypes_inexact(p, k)
A:jax._src.numpy.polynomial.k->full((m,), k[0])
A:jax._src.numpy.polynomial.coeff->(arange(len(p), m, -1)[np.newaxis, :] - 1 - arange(m)[:, np.newaxis]).prod(0)
A:jax._src.numpy.polynomial.a1->asarray([0.0])
A:jax._src.numpy.polynomial.a2->asarray([0.0])
A:jax._src.numpy.polynomial.val->convolve(a1, a2, mode='full')
jax._src.numpy.polynomial._nonzero_range(arr)
jax._src.numpy.polynomial._roots_no_zeros(p)
jax._src.numpy.polynomial.poly(seq_of_zeros)
jax._src.numpy.polynomial.polyadd(a1,a2)
jax._src.numpy.polynomial.polyder(p,m=1)
jax._src.numpy.polynomial.polyfit(x,y,deg,rcond=None,full=False,w=None,cov=False)
jax._src.numpy.polynomial.polyint(p,m=1,k=None)
jax._src.numpy.polynomial.polymul(a1,a2,*,trim_leading_zeros=False)
jax._src.numpy.polynomial.polysub(a1,a2)
jax._src.numpy.polynomial.polyval(p,x,*,unroll=16)
jax._src.numpy.polynomial.roots(p,*,strip_zeros=True)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/ufuncs.py----------------------------------------
A:jax._src.numpy.ufuncs.fn->jit(fn, inline=True)
A:jax._src.numpy.ufuncs.doc->dedent('\n\n'.join(lax_fn.__doc__.split('\n\n')[1:])).strip()
A:jax._src.numpy.ufuncs.(x1, x2)->_promote_dtypes_inexact(x1, x2)
A:jax._src.numpy.ufuncs.rx->jax.lax.real(x1)
A:jax._src.numpy.ufuncs.ry->jax.lax.real(x2)
A:jax._src.numpy.ufuncs.fabs->_one_to_one_unop(np.fabs, lax.abs, True)
A:jax._src.numpy.ufuncs.bitwise_not->_one_to_one_unop(np.bitwise_not, lax.bitwise_not)
A:jax._src.numpy.ufuncs.invert->_one_to_one_unop(np.invert, lax.bitwise_not)
A:jax._src.numpy.ufuncs.negative->_one_to_one_unop(np.negative, lax.neg)
A:jax._src.numpy.ufuncs.positive->_one_to_one_unop(np.positive, lambda x: x)
A:jax._src.numpy.ufuncs.floor->_one_to_one_unop(np.floor, lax.floor, True)
A:jax._src.numpy.ufuncs.ceil->_one_to_one_unop(np.ceil, lax.ceil, True)
A:jax._src.numpy.ufuncs.exp->_one_to_one_unop(np.exp, lax.exp, True)
A:jax._src.numpy.ufuncs.log->_one_to_one_unop(np.log, lax.log, True)
A:jax._src.numpy.ufuncs.expm1->_one_to_one_unop(np.expm1, lax.expm1, True)
A:jax._src.numpy.ufuncs.log1p->_one_to_one_unop(np.log1p, lax.log1p, True)
A:jax._src.numpy.ufuncs.sin->_one_to_one_unop(np.sin, lax.sin, True)
A:jax._src.numpy.ufuncs.cos->_one_to_one_unop(np.cos, lax.cos, True)
A:jax._src.numpy.ufuncs.tan->_one_to_one_unop(np.tan, lax.tan, True)
A:jax._src.numpy.ufuncs.arcsin->_one_to_one_unop(np.arcsin, lax.asin, True)
A:jax._src.numpy.ufuncs.arccos->_one_to_one_unop(np.arccos, lax.acos, True)
A:jax._src.numpy.ufuncs.arctan->_one_to_one_unop(np.arctan, lax.atan, True)
A:jax._src.numpy.ufuncs.sinh->_one_to_one_unop(np.sinh, lax.sinh, True)
A:jax._src.numpy.ufuncs.cosh->_one_to_one_unop(np.cosh, lax.cosh, True)
A:jax._src.numpy.ufuncs.arcsinh->_one_to_one_unop(np.arcsinh, lax.asinh, True)
A:jax._src.numpy.ufuncs.tanh->_one_to_one_unop(np.tanh, lax.tanh, True)
A:jax._src.numpy.ufuncs.arctanh->_one_to_one_unop(np.arctanh, lax.atanh, True)
A:jax._src.numpy.ufuncs.sqrt->_one_to_one_unop(np.sqrt, lax.sqrt, True)
A:jax._src.numpy.ufuncs.cbrt->_one_to_one_unop(np.cbrt, lax.cbrt, True)
A:jax._src.numpy.ufuncs.add->_maybe_bool_binop(np.add, lax.add, lax.bitwise_or)
A:jax._src.numpy.ufuncs.bitwise_and->_one_to_one_binop(np.bitwise_and, lax.bitwise_and)
A:jax._src.numpy.ufuncs.bitwise_or->_one_to_one_binop(np.bitwise_or, lax.bitwise_or)
A:jax._src.numpy.ufuncs.bitwise_xor->_one_to_one_binop(np.bitwise_xor, lax.bitwise_xor)
A:jax._src.numpy.ufuncs.left_shift->_one_to_one_binop(np.left_shift, lax.shift_left)
A:jax._src.numpy.ufuncs.equal->_one_to_one_binop(np.equal, lax.eq)
A:jax._src.numpy.ufuncs.multiply->_maybe_bool_binop(np.multiply, lax.mul, lax.bitwise_and)
A:jax._src.numpy.ufuncs.not_equal->_one_to_one_binop(np.not_equal, lax.ne)
A:jax._src.numpy.ufuncs.subtract->_one_to_one_binop(np.subtract, lax.sub)
A:jax._src.numpy.ufuncs.arctan2->_one_to_one_binop(np.arctan2, lax.atan2, True)
A:jax._src.numpy.ufuncs.minimum->_one_to_one_binop(np.minimum, lax.min)
A:jax._src.numpy.ufuncs.maximum->_one_to_one_binop(np.maximum, lax.max)
A:jax._src.numpy.ufuncs.float_power->_one_to_one_binop(np.float_power, lax.pow, True)
A:jax._src.numpy.ufuncs.nextafter->_one_to_one_binop(np.nextafter, lax.nextafter, True, True)
A:jax._src.numpy.ufuncs.greater_equal->_comparison_op(np.greater_equal, lax.ge)
A:jax._src.numpy.ufuncs.greater->_comparison_op(np.greater, lax.gt)
A:jax._src.numpy.ufuncs.less_equal->_comparison_op(np.less_equal, lax.le)
A:jax._src.numpy.ufuncs.less->_comparison_op(np.less, lax.lt)
A:jax._src.numpy.ufuncs.logical_and->_logical_op(np.logical_and, lax.bitwise_and)
A:jax._src.numpy.ufuncs.logical_not->_logical_op(np.logical_not, lax.bitwise_not)
A:jax._src.numpy.ufuncs.logical_or->_logical_op(np.logical_or, lax.bitwise_or)
A:jax._src.numpy.ufuncs.logical_xor->_logical_op(np.logical_xor, lax.bitwise_xor)
A:jax._src.numpy.ufuncs.out->jax.lax.add(amax, lax.div(lax.log1p(exp2(delta)), _constant_like(x1, np.log(2))))
A:jax._src.numpy.ufuncs.dt->jax._src.dtypes.dtype(x)
A:jax._src.numpy.ufuncs.abs->_wraps(np.abs)(absolute)
A:jax._src.numpy.ufuncs.dtype->jax._src.dtypes.dtype(x)
A:jax._src.numpy.ufuncs.re->jax.lax.real(x)
A:jax._src.numpy.ufuncs.quotient->jax.lax.div(x1, x2)
A:jax._src.numpy.ufuncs.select->logical_and(lax.sign(x1) != lax.sign(x2), lax.rem(x1, x2) != 0)
A:jax._src.numpy.ufuncs.x1r->jax.lax.real(x1)
A:jax._src.numpy.ufuncs.x1i->jax.lax.imag(x1)
A:jax._src.numpy.ufuncs.x2r->jax.lax.real(x2)
A:jax._src.numpy.ufuncs.x2i->jax.lax.imag(x2)
A:jax._src.numpy.ufuncs.which->jax.lax.ge(lax.abs(x2r), lax.abs(x2i))
A:jax._src.numpy.ufuncs.rat1->_where(which, lax.full_like(x2i, 1), lax.div(x2r, x2i))
A:jax._src.numpy.ufuncs.rat2->_where(which, lax.div(x2i, x2r), _lax_const(x2i, 1))
A:jax._src.numpy.ufuncs.mod->_wraps(np.mod)(remainder)
A:jax._src.numpy.ufuncs.div->jax.lax.select(ind, div - _constant_like(div, 1), div)
A:jax._src.numpy.ufuncs.ind->jax.lax.bitwise_and(mod != 0, lax.sign(x2) != lax.sign(mod))
A:jax._src.numpy.ufuncs.zero->_lax_const(x1, 0)
A:jax._src.numpy.ufuncs.one->_constant_like(x2, 1)
A:jax._src.numpy.ufuncs.acc->_where(lax.bitwise_and(x2, one), lax.mul(acc, x1), acc)
A:jax._src.numpy.ufuncs.x1->jax.lax.abs(x1)
A:jax._src.numpy.ufuncs.x2->jax.lax.abs(x2)
A:jax._src.numpy.ufuncs.amax->jax.lax.max(x1, x2)
A:jax._src.numpy.ufuncs.delta->jax.lax.sub(lax.add(x1, x2), lax.mul(amax, _constant_like(amax, 2)))
A:jax._src.numpy.ufuncs.a->_constant_like(x, _a)
A:jax._src.numpy.ufuncs.two_a->_constant_like(x, 2 * _a)
A:jax._src.numpy.ufuncs.rem->jax.lax.select(lax.lt(rem, zero), lax.add(rem, two_a), rem)
A:jax._src.numpy.ufuncs.(x1, x2, t1, t2)->_promote_args_inexact('logaddexp2_jvp', x1, x2, t1, t2)
A:jax._src.numpy.ufuncs.primal_out->logaddexp2(x1, x2)
A:jax._src.numpy.ufuncs.tangent_out->jax.lax.add(lax.mul(t1, exp2(lax.sub(_replace_inf(x1), _replace_inf(primal_out)))), lax.mul(t2, exp2(lax.sub(_replace_inf(x2), _replace_inf(primal_out)))))
A:jax._src.numpy.ufuncs.(x,)->_promote_dtypes_inexact(x)
A:jax._src.numpy.ufuncs.x->jax.lax.convert_element_type(x, np.float_)
A:jax._src.numpy.ufuncs.info->jax._src.dtypes.finfo(dtype)
A:jax._src.numpy.ufuncs.(x, e)->_normalize_float(x1)
A:jax._src.numpy.ufuncs.m->_where(cond, m / (1 << info.nmant), m)
A:jax._src.numpy.ufuncs.trunc_mod->jax.lax.rem(x1, x2)
A:jax._src.numpy.ufuncs.trunc_mod_not_zero->jax.lax.ne(trunc_mod, zero)
A:jax._src.numpy.ufuncs.do_plus->jax.lax.bitwise_and(lax.ne(lax.lt(trunc_mod, zero), lax.lt(x2, zero)), trunc_mod_not_zero)
A:jax._src.numpy.ufuncs.whole->_where(lax.ge(x, lax_internal._zero(x)), floor(x), ceil(x))
A:jax._src.numpy.ufuncs.im->jax.lax.imag(x)
A:jax._src.numpy.ufuncs.isposinf->_wraps(np.isposinf, skip_params=['out'])(lambda x, out=None: _isposneginf(np.inf, x, out))
A:jax._src.numpy.ufuncs.isneginf->_wraps(np.isneginf, skip_params=['out'])(lambda x, out=None: _isposneginf(-np.inf, x, out))
A:jax._src.numpy.ufuncs.eq_zero->jax.lax.eq(x, _lax_const(x, 0))
A:jax._src.numpy.ufuncs.pi_x->jax.lax.mul(_lax_const(x, np.pi), x)
A:jax._src.numpy.ufuncs.safe_pi_x->_where(eq_zero, _lax_const(x, 1), pi_x)
jax._src.numpy.ufuncs._comparison_op(numpy_fn,lax_fn)
jax._src.numpy.ufuncs._constant_like(x,const)
jax._src.numpy.ufuncs._float_divmod(x1,x2)
jax._src.numpy.ufuncs._isposneginf(infinity,x,out)
jax._src.numpy.ufuncs._logaddexp2_jvp(primals,tangents)
jax._src.numpy.ufuncs._logaddexp_jvp(primals,tangents)
jax._src.numpy.ufuncs._logical_op(np_op,bitwise_op)
jax._src.numpy.ufuncs._maybe_bool_binop(numpy_fn,lax_fn,bool_lax_fn,lax_doc=False)
jax._src.numpy.ufuncs._normalize_float(x)
jax._src.numpy.ufuncs._one_to_one_binop(numpy_fn,lax_fn,promote_to_inexact=False,lax_doc=False)
jax._src.numpy.ufuncs._one_to_one_unop(numpy_fn,lax_fn,promote_to_inexact=False,lax_doc=False)
jax._src.numpy.ufuncs._power(x1,x2)
jax._src.numpy.ufuncs._replace_inf(x)
jax._src.numpy.ufuncs._result_dtype(op,*args)
jax._src.numpy.ufuncs._sinc_maclaurin(k,x)
jax._src.numpy.ufuncs._sinc_maclaurin_jvp(k,primals,tangents)
jax._src.numpy.ufuncs._wrap_between(x,_a)
jax._src.numpy.ufuncs.absolute(x)
jax._src.numpy.ufuncs.arccosh(x)
jax._src.numpy.ufuncs.conjugate(x)
jax._src.numpy.ufuncs.copysign(x1,x2)
jax._src.numpy.ufuncs.deg2rad(x)
jax._src.numpy.ufuncs.divmod(x1,x2)
jax._src.numpy.ufuncs.exp2(x)
jax._src.numpy.ufuncs.floor_divide(x1,x2)
jax._src.numpy.ufuncs.fmod(x1,x2)
jax._src.numpy.ufuncs.frexp(x)
jax._src.numpy.ufuncs.heaviside(x1,x2)
jax._src.numpy.ufuncs.hypot(x1,x2)
jax._src.numpy.ufuncs.imag(val)
jax._src.numpy.ufuncs.isfinite(x)
jax._src.numpy.ufuncs.isinf(x)
jax._src.numpy.ufuncs.isnan(x)
jax._src.numpy.ufuncs.ldexp(x1,x2)
jax._src.numpy.ufuncs.log10(x)
jax._src.numpy.ufuncs.log2(x)
jax._src.numpy.ufuncs.logaddexp(x1,x2)
jax._src.numpy.ufuncs.logaddexp2(x1,x2)
jax._src.numpy.ufuncs.modf(x,out=None)
jax._src.numpy.ufuncs.power(x1,x2)
jax._src.numpy.ufuncs.rad2deg(x)
jax._src.numpy.ufuncs.real(val)
jax._src.numpy.ufuncs.reciprocal(x)
jax._src.numpy.ufuncs.remainder(x1,x2)
jax._src.numpy.ufuncs.right_shift(x1,x2)
jax._src.numpy.ufuncs.rint(x)
jax._src.numpy.ufuncs.sign(x)
jax._src.numpy.ufuncs.signbit(x)
jax._src.numpy.ufuncs.sinc(x)
jax._src.numpy.ufuncs.square(x)
jax._src.numpy.ufuncs.true_divide(x1,x2)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/linalg.py----------------------------------------
A:jax._src.numpy.linalg.(dtype, weak_type)->jax._src.dtypes._lattice_result_type(*args)
A:jax._src.numpy.linalg.dtype->jax.lax.dtype(a)
A:jax._src.numpy.linalg.a->_promote_arg_dtypes(jnp.asarray(a))
A:jax._src.numpy.linalg.(w, v)->jax._src.lax.linalg.eigh(a)
A:jax._src.numpy.linalg.s->jax._src.numpy.lax_numpy.where(s > cutoff, s, jnp.inf)
A:jax._src.numpy.linalg.sign->jax._src.numpy.lax_numpy.asarray(-2 * (parity % 2) + 1, dtype=dtype)
A:jax._src.numpy.linalg.idxs->jax.lax.rev(idxs, dimensions=[s.ndim - 1])
A:jax._src.numpy.linalg.(s, idxs, sign)->jax.lax.sort((s, idxs, sign), dimension=-1, num_keys=1)
A:jax._src.numpy.linalg.u->jax._src.numpy.lax_numpy.take_along_axis(w, idxs[..., None, :], axis=-1)
A:jax._src.numpy.linalg.vh->_H(u * sign[..., None, :])
A:jax._src.numpy.linalg.n->numpy.abs(n)
A:jax._src.numpy.linalg.(n, bit)->divmod(n, 2)
A:jax._src.numpy.linalg.M->_promote_arg_dtypes(jnp.asarray(M))
A:jax._src.numpy.linalg.S->svd(M, full_matrices=False, compute_uv=False)
A:jax._src.numpy.linalg.a_shape->jax._src.numpy.lax_numpy.shape(a)
A:jax._src.numpy.linalg.(lu, pivot, _)->jax._src.lax.linalg.lu(a)
A:jax._src.numpy.linalg.diag->jax._src.numpy.lax_numpy.diagonal(lu, axis1=-2, axis2=-1)
A:jax._src.numpy.linalg.is_zero->jax._src.numpy.lax_numpy.any(diag == jnp.array(0, dtype=dtype), axis=-1)
A:jax._src.numpy.linalg.iota->jax.lax.expand_dims(jnp.arange(a_shape[-1]), range(pivots.ndim - 1))
A:jax._src.numpy.linalg.parity->jax._src.numpy.lax_numpy.count_nonzero(pivots != iota, axis=-1)
A:jax._src.numpy.linalg.logdet->jax._src.numpy.lax_numpy.where(is_zero, jnp.array(-jnp.inf, dtype=dtype), jnp.sum(jnp.log(jnp.abs(diag)), axis=-1))
A:jax._src.numpy.linalg.(sign, ans)->slogdet(x)
A:jax._src.numpy.linalg.ans_dot->numpy.real(ans_dot)
A:jax._src.numpy.linalg.sign_dot->jax._src.numpy.lax_numpy.zeros_like(sign)
A:jax._src.numpy.linalg.b->_promote_arg_dtypes(jnp.asarray(b))
A:jax._src.numpy.linalg.b_shape->jax._src.numpy.lax_numpy.shape(b)
A:jax._src.numpy.linalg.a_ndims->len(a_shape)
A:jax._src.numpy.linalg.(lu, pivots, permutation)->jax._src.lax.linalg.lu(a)
A:jax._src.numpy.linalg.batch_dims->jax.lax.broadcast_shapes(lu.shape[:-2], b.shape[:-2])
A:jax._src.numpy.linalg.x->x.ravel().ravel()
A:jax._src.numpy.linalg.lu->lu.at[..., -1, -1].set(1.0 / partial_det[..., -2]).at[..., -1, -1].set(1.0 / partial_det[..., -2])
A:jax._src.numpy.linalg.permutation->jax._src.numpy.lax_numpy.broadcast_to(permutation, batch_dims + (a_shape[-1],))
A:jax._src.numpy.linalg.iotas->jax._src.numpy.lax_numpy.ix_(*(lax.iota(jnp.int32, b) for b in batch_dims + (1,)))
A:jax._src.numpy.linalg.d->jax._src.numpy.lax_numpy.tile(d[..., None, None], d.ndim * (1,) + x.shape[-2:])
A:jax._src.numpy.linalg.(sign, logdet)->slogdet(a)
A:jax._src.numpy.linalg.(y, z)->_cofactor_solve(x, g)
A:jax._src.numpy.linalg.msg->"UPLO must be one of None, 'L', or 'U', got {}".format(UPLO)
A:jax._src.numpy.linalg.(v, w)->jax._src.lax.linalg.eigh(a, lower=lower, symmetrize_input=symmetrize_input)
A:jax._src.numpy.linalg.(w, _)->eigh(a, UPLO)
A:jax._src.numpy.linalg.max_rows_cols->max(a.shape[-2:])
A:jax._src.numpy.linalg.rcond->jax._src.numpy.lax_numpy.where(rcond < 0, jnp.finfo(dtype).eps, rcond)
A:jax._src.numpy.linalg.(u, s, vh)->svd(a, full_matrices=False)
A:jax._src.numpy.linalg.res->jax._src.numpy.lax_numpy.matmul(_T(vh), jnp.divide(_T(u), s[..., jnp.newaxis]))
A:jax._src.numpy.linalg.p->pinv(a, rcond=rcond)
A:jax._src.numpy.linalg.I_n->jax.lax.expand_dims(jnp.eye(m, dtype=a.dtype), range(a.ndim - 2))
A:jax._src.numpy.linalg.I_m->jax.lax.expand_dims(jnp.eye(n, dtype=a.dtype), range(a.ndim - 2))
A:jax._src.numpy.linalg.x_shape->jax._src.numpy.lax_numpy.shape(x)
A:jax._src.numpy.linalg.ndim->len(x_shape)
A:jax._src.numpy.linalg.axis->tuple((canonicalize_axis(x, ndim) for x in axis))
A:jax._src.numpy.linalg.num_axes->len(axis)
A:jax._src.numpy.linalg.abs_x->jax._src.numpy.lax_numpy.abs(x)
A:jax._src.numpy.linalg.ord->jax._src.lax.lax._const(abs_x, ord)
A:jax._src.numpy.linalg.out->jax._src.numpy.lax_numpy.sum(abs_x ** ord, axis=axis, keepdims=keepdims)
A:jax._src.numpy.linalg.(row_axis, col_axis)->cast(Tuple[int, ...], axis)
A:jax._src.numpy.linalg.y->jax._src.numpy.lax_numpy.expand_dims(y, axis)
A:jax._src.numpy.linalg.(q, r)->jax._src.lax.linalg.qr(a, full_matrices)
A:jax._src.numpy.linalg.(a, b)->_promote_arg_dtypes(a, b)
A:jax._src.numpy.linalg.(u, s, vt)->svd(a, full_matrices=False)
A:jax._src.numpy.linalg.rank->mask.sum()
A:jax._src.numpy.linalg.safe_s->jax._src.numpy.lax_numpy.where(mask, s, 1)
A:jax._src.numpy.linalg.uTb->jax._src.numpy.lax_numpy.matmul(u.conj().T, b, precision=lax.Precision.HIGHEST)
A:jax._src.numpy.linalg.resid->jax._src.numpy.lax_numpy.asarray([])
A:jax._src.numpy.linalg.b_estimate->jax._src.numpy.lax_numpy.matmul(a, x, precision=lax.Precision.HIGHEST)
A:jax._src.numpy.linalg._jit_lstsq->jit(partial(_lstsq, numpy_resid=False))
jax._src.numpy.linalg._cofactor_solve(a,b)
jax._src.numpy.linalg._det_2x2(a)
jax._src.numpy.linalg._det_3x3(a)
jax._src.numpy.linalg._det_jvp(primals,tangents)
jax._src.numpy.linalg._lstsq(a,b,rcond,*,numpy_resid=False)
jax._src.numpy.linalg._pinv_jvp(rcond,primals,tangents)
jax._src.numpy.linalg._promote_arg_dtypes(*args)
jax._src.numpy.linalg._slogdet_jvp(primals,tangents)
jax._src.numpy.linalg.cholesky(a)
jax._src.numpy.linalg.det(a)
jax._src.numpy.linalg.eig(a)
jax._src.numpy.linalg.eigh(a,UPLO=None,symmetrize_input=True)
jax._src.numpy.linalg.eigvals(a)
jax._src.numpy.linalg.eigvalsh(a,UPLO='L')
jax._src.numpy.linalg.inv(a)
jax._src.numpy.linalg.lstsq(a,b,rcond=None,*,numpy_resid=False)
jax._src.numpy.linalg.matrix_power(a,n)
jax._src.numpy.linalg.matrix_rank(M,tol=None)
jax._src.numpy.linalg.norm(x,ord=None,axis:Union[None,Tuple[int,...],int]=None,keepdims=False)
jax._src.numpy.linalg.pinv(a,rcond=None)
jax._src.numpy.linalg.qr(a,mode='reduced')
jax._src.numpy.linalg.slogdet(a)
jax._src.numpy.linalg.solve(a,b)
jax._src.numpy.linalg.svd(a,full_matrices:bool=True,compute_uv:bool=True,hermitian:bool=False)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/util.py----------------------------------------
A:jax._src.numpy.util._parameter_break->re.compile('\n(?=[A-Za-z_])')
A:jax._src.numpy.util._section_break->re.compile('\\n(?=[^\\n]{3,15}\\n-{3,15})', re.MULTILINE)
A:jax._src.numpy.util._numpy_signature_re->re.compile('^([\\w., ]+=)?\\s*[\\w\\.]+\\([\\w\\W]*?\\)$', re.MULTILINE)
A:jax._src.numpy.util._versionadded->re.compile('^\\s+\\.\\.\\s+versionadded::', re.MULTILINE)
A:jax._src.numpy.util._docreference->re.compile(':doc:`(.*?)\\s*<.*?>`')
A:jax._src.numpy.util.docstr->getattr(fun, '__doc__', None)
A:jax._src.numpy.util.match->re.compile('^([\\w., ]+=)?\\s*[\\w\\.]+\\([\\w\\W]*?\\)$', re.MULTILINE).match(body)
A:jax._src.numpy.util.signature->re.compile('^([\\w., ]+=)?\\s*[\\w\\.]+\\([\\w\\W]*?\\)$', re.MULTILINE).match(body).group()
A:jax._src.numpy.util.(firstline, _, body)->textwrap.dedent(body.lstrip('\n')).partition('\n')
A:jax._src.numpy.util.body->textwrap.dedent(body.lstrip('\n'))
A:jax._src.numpy.util.(summary, _, body)->textwrap.dedent(body.lstrip('\n')).lstrip('\n').partition('\n')
A:jax._src.numpy.util.section_list->re.compile('\\n(?=[^\\n]{3,15}\\n-{3,15})', re.MULTILINE).split(body)
A:jax._src.numpy.util.(title, underline, content)->textwrap.dedent(body.lstrip('\n')).split('\n', 2)
A:jax._src.numpy.util.parameters->_parse_parameters(parsed.sections['Parameters'])
A:jax._src.numpy.util.name->getattr(fun, '__name__', getattr(op, '__name__', str(op)))
A:jax._src.numpy.util.parsed->_parse_numpydoc(docstr)
A:jax._src.numpy.util.code->getattr(getattr(op, '__wrapped__', op), '__code__', None)
A:jax._src.numpy.util.value->getattr(fun, attr)
A:jax._src.numpy.util._dtype->partial(dtypes.dtype, canonicalize=True)
A:jax._src.numpy.util.(dtype, weak_type)->jax._src.dtypes._lattice_result_type(arr)
A:jax._src.numpy.util.res_shape->jax._src.lax.lax.broadcast_shapes(*shapes)
A:jax._src.numpy.util.result_rank->len(lax.broadcast_shapes(*shapes))
A:jax._src.numpy.util.(to_dtype, weak_type)->jax._src.dtypes._lattice_result_type(*args)
A:jax._src.numpy.util.to_dtype->jax._src.dtypes.canonicalize_dtype(to_dtype)
A:jax._src.numpy.util.to_dtype_inexact->_to_inexact_dtype(to_dtype)
A:jax._src.numpy.util.(pos, arg)->next(((i, arg) for (i, arg) in enumerate(args) if not _arraylike(arg)))
A:jax._src.numpy.util.result_shape->jax._src.lax.lax.broadcast_shapes(*shapes)
A:jax._src.numpy.util.shape->jax.core.canonicalize_shape(shape)
A:jax._src.numpy.util.arr_shape->numpy.shape(arr)
A:jax._src.numpy.util.compatible->all((core.symbolic_equal_one_of_dim(arr_d, [1, shape_d]) for (arr_d, shape_d) in safe_zip(arr_shape, shape_tail)))
A:jax._src.numpy.util.(diff,)->numpy.where(tuple((not core.symbolic_equal_dim(arr_d, shape_d) for (arr_d, shape_d) in safe_zip(arr_shape, shape_tail))))
A:jax._src.numpy.util.kept_dims->tuple(np.delete(np.arange(len(shape)), new_dims))
A:jax._src.numpy.util.condition->jax._src.lax.lax.ne(condition, lax_internal._zero(condition))
A:jax._src.numpy.util.(x, y)->_promote_dtypes(x, y)
A:jax._src.numpy.util.(condition, x, y)->_broadcast_arrays(condition, x, y)
A:jax._src.numpy.util.is_always_empty->jax.core.is_empty_shape(np.shape(x))
jax._src.numpy.util.ParsedDoc(NamedTuple)
jax._src.numpy.util._arraylike(x)
jax._src.numpy.util._asarray(arr)
jax._src.numpy.util._broadcast_arrays(*args)
jax._src.numpy.util._broadcast_to(arr,shape)
jax._src.numpy.util._check_arraylike(fun_name,*args)
jax._src.numpy.util._check_no_float0s(fun_name,*args)
jax._src.numpy.util._complex_elem_type(dtype)
jax._src.numpy.util._parse_extra_params(extra_params:str)->Dict[str, str]
jax._src.numpy.util._parse_numpydoc(docstr:Optional[str])->ParsedDoc
jax._src.numpy.util._parse_parameters(body:str)->Dict[str, str]
jax._src.numpy.util._promote_args(fun_name,*args)
jax._src.numpy.util._promote_args_inexact(fun_name,*args)
jax._src.numpy.util._promote_dtypes(*args)
jax._src.numpy.util._promote_dtypes_inexact(*args)
jax._src.numpy.util._promote_shapes(fun_name,*args)
jax._src.numpy.util._rank_promotion_warning_or_error(fun_name,shapes)
jax._src.numpy.util._stackable(*args)
jax._src.numpy.util._to_inexact_dtype(dtype)
jax._src.numpy.util._where(condition,x=None,y=None)
jax._src.numpy.util._wraps(fun:Optional[Callable],update_doc:bool=True,lax_description:str='',sections:Sequence[str]=('Parameters','Returns','References'),skip_params:Sequence[str]=(),extra_params:Optional[str]=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/reductions.py----------------------------------------
A:jax._src.numpy.reductions.element->element.__jax_array__().__jax_array__()
A:jax._src.numpy.reductions.a->jax.lax.convert_element_type(a, dtype)
A:jax._src.numpy.reductions.source->_canonicalize_axis(source, np.ndim(a))
A:jax._src.numpy.reductions.destination->_canonicalize_axis(destination, np.ndim(a))
A:jax._src.numpy.reductions.axis->_canonicalize_axis(axis, num_dims)
A:jax._src.numpy.reductions.(pos_dims, dims)->_reduction_dims(a, axis)
A:jax._src.numpy.reductions.result_dtype->jax._src.dtypes.canonicalize_dtype(dtype or dtypes.dtype(np_fun(np.ones((), dtype=dtypes.dtype(a)))))
A:jax._src.numpy.reductions.computation_dtype->jax._src.dtypes.promote_types(result_dtype, np.float32)
A:jax._src.numpy.reductions.init_val->_reduction_init_val(a, init_val)
A:jax._src.numpy.reductions.result->_where(normalizer_mask, np.nan, result)
A:jax._src.numpy.reductions.canon_axis->tuple((_canonicalize_axis_allow_named(x, np.ndim(a)) for x in axis))
A:jax._src.numpy.reductions.canon_pos_axis->tuple((x for x in canon_axis if isinstance(x, int)))
A:jax._src.numpy.reductions.a_dtype->jax._src.dtypes.promote_types(a_dtype, np.float32)
A:jax._src.numpy.reductions.a_shape->list(np.shape(a))
A:jax._src.numpy.reductions.normalizer->sum(lax_internal.bitwise_not(lax_internal._isnan(a)), axis=axis, keepdims=keepdims, where=where)
A:jax._src.numpy.reductions.dtype->jax._src.dtypes.canonicalize_dtype(dtypes.int_)
A:jax._src.numpy.reductions.avg->mean(a, axis=axis)
A:jax._src.numpy.reductions.weights_sum->_broadcast_to(weights_sum, avg.shape)
A:jax._src.numpy.reductions.weights->_moveaxis(weights, -1, axis)
A:jax._src.numpy.reductions.out_dtype->jax._src.dtypes.canonicalize_dtype(out_dtype)
A:jax._src.numpy.reductions.a_ndim->len(a_shape)
A:jax._src.numpy.reductions.weights_shape->numpy.shape(weights)
A:jax._src.numpy.reductions.(a_dtype, dtype)->_var_promote_types(dtypes.dtype(a), dtype)
A:jax._src.numpy.reductions.a_mean->nanmean(a, axis, dtype=a_dtype, keepdims=True, where=where)
A:jax._src.numpy.reductions.centered->jax.lax.square(centered)
A:jax._src.numpy.reductions.out->jax.lax.div(result, lax.convert_element_type(divisor, result.dtype))
A:jax._src.numpy.reductions.dtypea_dtype->jax._src.dtypes.canonicalize_dtype(dtypes.float_)
A:jax._src.numpy.reductions.x->amax(a, axis=axis, keepdims=keepdims)
A:jax._src.numpy.reductions.y->amin(a, axis=axis, keepdims=keepdims)
A:jax._src.numpy.reductions.nansum.__doc__->nansum.__doc__.replace('\n\n\n', '\n\n')
A:jax._src.numpy.reductions.nan_mask->jax._src.lax.lax.bitwise_not(lax_internal._isnan(a))
A:jax._src.numpy.reductions.td->jax.lax.div(nansum(a, axis, dtype=dtype, keepdims=keepdims, where=where), normalizer)
A:jax._src.numpy.reductions.normalizer_mask->jax.lax.le(normalizer, 0)
A:jax._src.numpy.reductions.divisor->_where(normalizer_mask, 1, normalizer)
A:jax._src.numpy.reductions.num_dims->len(a_shape)
A:jax._src.numpy.reductions.cumsum->_make_cumulative_reduction(np.cumsum, lax.cumsum, fill_nan=False)
A:jax._src.numpy.reductions.cumprod->_make_cumulative_reduction(np.cumprod, lax.cumprod, fill_nan=False)
A:jax._src.numpy.reductions.nancumsum->_make_cumulative_reduction(np.nancumsum, lax.cumsum, fill_nan=True, fill_value=0)
A:jax._src.numpy.reductions.nancumprod->_make_cumulative_reduction(np.nancumprod, lax.cumprod, fill_nan=True, fill_value=1)
jax._src.numpy.reductions._asarray(a)
jax._src.numpy.reductions._average(a,axis:Optional[Union[int,Tuple[int,...]]]=None,weights=None,returned=False)
jax._src.numpy.reductions._axis_size(a,axis)
jax._src.numpy.reductions._canonicalize_axis_allow_named(x,rank)
jax._src.numpy.reductions._cast_to_bool(operand)
jax._src.numpy.reductions._ensure_optional_axes(x)
jax._src.numpy.reductions._isscalar(element)
jax._src.numpy.reductions._make_cumulative_reduction(np_reduction,reduction,fill_nan=False,fill_value=0)
jax._src.numpy.reductions._mean(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=False,*,where=None)
jax._src.numpy.reductions._moveaxis(a,source:int,destination:int)
jax._src.numpy.reductions._nan_reduction(a,name,jnp_reduction,init_val,nan_if_all_nan,axis=None,keepdims=None,**kwargs)
jax._src.numpy.reductions._ptp(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=False)
jax._src.numpy.reductions._reduce_all(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,*,where=None)
jax._src.numpy.reductions._reduce_any(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,*,where=None)
jax._src.numpy.reductions._reduce_max(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions._reduce_min(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions._reduce_prod(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions._reduce_sum(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions._reduction(a,name,np_fun,op,init_val,has_identity=True,preproc=None,bool_op=None,upcast_f16_for_computation=False,axis=None,dtype=None,out=None,keepdims=False,initial=None,where_=None,parallel_reduce=None)
jax._src.numpy.reductions._reduction_dims(a,axis)
jax._src.numpy.reductions._reduction_init_val(a,init_val)
jax._src.numpy.reductions._std(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,*,where=None)
jax._src.numpy.reductions._var(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,*,where=None)
jax._src.numpy.reductions._var_promote_types(a_dtype,dtype)
jax._src.numpy.reductions.all(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,*,where=None)
jax._src.numpy.reductions.any(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,*,where=None)
jax._src.numpy.reductions.average(a,axis:Optional[Union[int,Tuple[int,...]]]=None,weights=None,returned=False)
jax._src.numpy.reductions.count_nonzero(a,axis:Optional[Union[int,Tuple[int,...]]]=None,keepdims=False)
jax._src.numpy.reductions.max(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.mean(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=False,*,where=None)
jax._src.numpy.reductions.min(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.nanmax(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.nanmean(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=False,where=None)
jax._src.numpy.reductions.nanmin(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.nanprod(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.nanstd(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,where=None)
jax._src.numpy.reductions.nansum(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.nanvar(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,where=None)
jax._src.numpy.reductions.prod(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.ptp(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,keepdims=False)
jax._src.numpy.reductions.std(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,*,where=None)
jax._src.numpy.reductions.sum(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,keepdims=None,initial=None,where=None)
jax._src.numpy.reductions.var(a,axis:Optional[Union[int,Tuple[int,...]]]=None,dtype=None,out=None,ddof=0,keepdims=False,*,where=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/lax_numpy.py----------------------------------------
A:jax._src.numpy.lax_numpy._dtype->partial(dtypes.dtype, canonicalize=True)
A:jax._src.numpy.lax_numpy.meta->_ScalarMeta(np_scalar_type.__name__, (object,), {'dtype': np.dtype(np_scalar_type)})
A:jax._src.numpy.lax_numpy.bool_->_make_scalar_type(np.bool_)
A:jax._src.numpy.lax_numpy.uint8->_make_scalar_type(np.uint8)
A:jax._src.numpy.lax_numpy.uint16->_make_scalar_type(np.uint16)
A:jax._src.numpy.lax_numpy.uint32->_make_scalar_type(np.uint32)
A:jax._src.numpy.lax_numpy.uint64->_make_scalar_type(np.uint64)
A:jax._src.numpy.lax_numpy.int8->_make_scalar_type(np.int8)
A:jax._src.numpy.lax_numpy.int16->_make_scalar_type(np.int16)
A:jax._src.numpy.lax_numpy.int32->_make_scalar_type(np.int32)
A:jax._src.numpy.lax_numpy.int64->_make_scalar_type(np.int64)
A:jax._src.numpy.lax_numpy.bfloat16->_make_scalar_type(dtypes.bfloat16)
A:jax._src.numpy.lax_numpy.float16->_make_scalar_type(np.float16)
A:jax._src.numpy.lax_numpy.float32single->_make_scalar_type(np.float32)
A:jax._src.numpy.lax_numpy.float64double->_make_scalar_type(np.float64)
A:jax._src.numpy.lax_numpy.complex64csingle->_make_scalar_type(np.complex64)
A:jax._src.numpy.lax_numpy.complex128cdouble->_make_scalar_type(np.complex128)
A:jax._src.numpy.lax_numpy.dtype->jax._src.dtypes.canonicalize_dtype(float_)
A:jax._src.numpy.lax_numpy.val_dtype->jax._src.dtypes.canonicalize_dtype(val.dtype)
A:jax._src.numpy.lax_numpy.min_val->_lax_const(val, _max(iinfo(dtype).min, iinfo(val_dtype).min))
A:jax._src.numpy.lax_numpy.max_val->_lax_const(val, _min(iinfo(dtype).max, iinfo(val_dtype).max))
A:jax._src.numpy.lax_numpy.out->round(number, decimals=ndigits or 0)
A:jax._src.numpy.lax_numpy.element->element.__jax_array__().__jax_array__()
A:jax._src.numpy.lax_numpy.y->atleast_2d(y)
A:jax._src.numpy.lax_numpy.dx->list(varargs)
A:jax._src.numpy.lax_numpy.(x, y)->_promote_dtypes_inexact(x, y)
A:jax._src.numpy.lax_numpy.out_order->slice(None, None, -1)
A:jax._src.numpy.lax_numpy.result->reshape(result, keepdim)
A:jax._src.numpy.lax_numpy.a->jax.lax.sort(a, dimension=axis)
A:jax._src.numpy.lax_numpy.b->expand_dims(b, range(ndim(a) - ndim(b)))
A:jax._src.numpy.lax_numpy.range->asarray(range)
A:jax._src.numpy.lax_numpy.weights->numpy.array(1, dtype=int_)
A:jax._src.numpy.lax_numpy.bin_edges->histogram_bin_edges(sample[:, i], bins[i], range_i, weights)
A:jax._src.numpy.lax_numpy.bin_idx->where(sample[:, i] == bin_edges[-1], bin_idx - 1, bin_idx)
A:jax._src.numpy.lax_numpy.bin_widths->diff(bin_edges)
A:jax._src.numpy.lax_numpy.N->len(dimensions)
A:jax._src.numpy.lax_numpy.x_edgesy_edges->asarray(bins)
A:jax._src.numpy.lax_numpy.sample->transpose(asarray([x, y]))
A:jax._src.numpy.lax_numpy.(hist, edges)->histogramdd(sample, bins, range, weights, density)
A:jax._src.numpy.lax_numpy.(N, D)->shape(sample)
A:jax._src.numpy.lax_numpy.num_bins->len(bins)
A:jax._src.numpy.lax_numpy.nbins->numpy.empty(D, int)
A:jax._src.numpy.lax_numpy.dedges[i]->diff(bin_edges_by_dim[i])
A:jax._src.numpy.lax_numpy.xy->ravel_multi_index(bin_idx_by_dim, nbins, mode='clip')
A:jax._src.numpy.lax_numpy.hist->reshape(hist, nbins)
A:jax._src.numpy.lax_numpy.ax1->_canonicalize_axis(ax1, ndim(m))
A:jax._src.numpy.lax_numpy.ax2->_canonicalize_axis(ax2, ndim(m))
A:jax._src.numpy.lax_numpy.perm->tuple([names.index(name) for name in result_names])
A:jax._src.numpy.lax_numpy.axis->_canonicalize_axis(axis, ndim(a))
A:jax._src.numpy.lax_numpy.i->array(i)
A:jax._src.numpy.lax_numpy.re->jax.lax.convert_element_type(re, dtype)
A:jax._src.numpy.lax_numpy.im->jax.lax.convert_element_type(im, dtype)
A:jax._src.numpy.lax_numpy.n->jax.core.concrete_or_error(operator.index, n, "'n' argument of jnp.diag_indices()")
A:jax._src.numpy.lax_numpy.shape->jax.core.canonicalize_shape(shape, context='shape argument of jnp.fromfunction()')
A:jax._src.numpy.lax_numpy.prepend->broadcast_to(prepend, tuple(shape))
A:jax._src.numpy.lax_numpy.append->broadcast_to(append, tuple(shape))
A:jax._src.numpy.lax_numpy.slice1[axis]->slice(1, None)
A:jax._src.numpy.lax_numpy.slice2[axis]->slice(None, -1)
A:jax._src.numpy.lax_numpy.slice1_tuple->tuple(slice1)
A:jax._src.numpy.lax_numpy.slice2_tuple->tuple(slice2)
A:jax._src.numpy.lax_numpy.ary->asarray(ary)
A:jax._src.numpy.lax_numpy.sliced->jax.lax.squeeze(sliced, removed)
A:jax._src.numpy.lax_numpy.a_grad->concatenate((sliced(1, 2) - sliced(0, 1), (sliced(2, None) - sliced(None, -2)) * 0.5, sliced(-1, None) - sliced(-2, -1)), axis)
A:jax._src.numpy.lax_numpy.axis_tuple->tuple((_canonicalize_axis(i, a.ndim) for i in axis))
A:jax._src.numpy.lax_numpy.len_axes->len(axis_tuple)
A:jax._src.numpy.lax_numpy.newshape->_compute_newshape(a, args[0] if len(args) == 1 else args)
A:jax._src.numpy.lax_numpy.dims->list(range(ndim(a)))
A:jax._src.numpy.lax_numpy.strides->(np.cumprod(a.shape[::-1])[::-1] // a.shape).astype(int_)
A:jax._src.numpy.lax_numpy.sizes->append(array(shape), 1)
A:jax._src.numpy.lax_numpy.clipped_indices->expand_dims(clipped_indices, axis=0)
A:jax._src.numpy.lax_numpy.cumulative_sizes->expand_dims(cumulative_sizes, range(1, 1 + _ndim(indices)))
A:jax._src.numpy.lax_numpy.new_shape->_ensure_index_tuple(new_shape)
A:jax._src.numpy.lax_numpy.new_size->_prod(new_shape)
A:jax._src.numpy.lax_numpy.repeats->broadcast_to(repeats, [a.shape[axis]])
A:jax._src.numpy.lax_numpy.a_shape->shape(a)
A:jax._src.numpy.lax_numpy.source->tuple((_canonicalize_axis(i, ndim(a)) for i in source))
A:jax._src.numpy.lax_numpy.destination->tuple((_canonicalize_axis(i, ndim(a)) for i in destination))
A:jax._src.numpy.lax_numpy.(a, b)->_promote_dtypes(a, b)
A:jax._src.numpy.lax_numpy.rtol->jax.lax.convert_element_type(rtol, dtype)
A:jax._src.numpy.lax_numpy.atol->jax.lax.convert_element_type(atol, dtype)
A:jax._src.numpy.lax_numpy.a_inf->isinf(a)
A:jax._src.numpy.lax_numpy.b_inf->isinf(b)
A:jax._src.numpy.lax_numpy.any_inf->logical_or(a_inf, b_inf)
A:jax._src.numpy.lax_numpy.both_inf->logical_and(a_inf, b_inf)
A:jax._src.numpy.lax_numpy.same_value->jax.lax.eq(a, b)
A:jax._src.numpy.lax_numpy.same_inf->logical_and(both_inf, same_value)
A:jax._src.numpy.lax_numpy.a_nan->isnan(a)
A:jax._src.numpy.lax_numpy.b_nan->isnan(b)
A:jax._src.numpy.lax_numpy.any_nan->logical_or(a_nan, b_nan)
A:jax._src.numpy.lax_numpy.both_nan->logical_and(a_nan, b_nan)
A:jax._src.numpy.lax_numpy.(x, xp, fp)->_promote_dtypes_inexact(x, xp, fp)
A:jax._src.numpy.lax_numpy.period->abs(period)
A:jax._src.numpy.lax_numpy.(xp, fp)->jax.lax.sort_key_val(xp, fp)
A:jax._src.numpy.lax_numpy.xp->concatenate([xp[-1:] - period, xp, xp[:1] + period])
A:jax._src.numpy.lax_numpy.fp->concatenate([fp[-1:], fp, fp[:1]])
A:jax._src.numpy.lax_numpy.f->where(x > xp[-1], fp[-1] if right is None else right, f)
A:jax._src.numpy.lax_numpy.choices->_promote_dtypes(default, *choicelist)
A:jax._src.numpy.lax_numpy.output->where(cond, choice, output)
A:jax._src.numpy.lax_numpy.minlength->jax.core.concrete_or_error(operator.index, minlength, "The error occurred because of argument 'minlength' of jnp.bincount.")
A:jax._src.numpy.lax_numpy.x->remainder(x, a_shape[i] or 1)
A:jax._src.numpy.lax_numpy.length->jax.core.concrete_or_error(operator.index, length, "The error occurred because of argument 'length' of jnp.bincount.")
A:jax._src.numpy.lax_numpy.broadcast_arrays->_wraps(np.broadcast_arrays, lax_description='The JAX version does not necessarily return a view of the input.\n')(_broadcast_arrays)
A:jax._src.numpy.lax_numpy.broadcast_to->_wraps(np.broadcast_to, lax_description='The JAX version does not necessarily return a view of the input.\n')(_broadcast_to)
A:jax._src.numpy.lax_numpy.indices_or_sections->jax.core.concrete_or_error(np.int64, indices_or_sections, f'in jax.numpy.{op} argument 1')
A:jax._src.numpy.lax_numpy.split_indices->numpy.concatenate([np.arange(r + 1, dtype=np.int64) * (part_size + 1), np.arange(indices_or_sections - r, dtype=np.int64) * part_size + ((r + 1) * (part_size + 1) - 1)])
A:jax._src.numpy.lax_numpy.(part_size, r)->_divmod(size, indices_or_sections)
A:jax._src.numpy.lax_numpy.vsplit->_split_on_axis('vsplit', axis=0)
A:jax._src.numpy.lax_numpy.hsplit->_split_on_axis('hsplit', axis=1)
A:jax._src.numpy.lax_numpy.dsplit->_split_on_axis('dsplit', axis=2)
A:jax._src.numpy.lax_numpy.decimals->jax.core.concrete_or_error(operator.index, decimals, "'decimals' argument of jnp.round")
A:jax._src.numpy.lax_numpy.factor->_lax_const(x, 10 ** decimals)
A:jax._src.numpy.lax_numpy.zero->_lax_const(x, 0)
A:jax._src.numpy.lax_numpy.info->finfo(dtypes.canonicalize_dtype(dtype))
A:jax._src.numpy.lax_numpy.size->jax.core.concrete_or_error(int, size, 'The size argument of jnp.nonzero must be statically specified to use jnp.nonzero within JAX transformations.')
A:jax._src.numpy.lax_numpy.flat_indices->cumsum(bincount(cumsum(mask), length=size))
A:jax._src.numpy.lax_numpy.dd->diff(p, axis=axis)
A:jax._src.numpy.lax_numpy.ddmod->where((ddmod == -pi) & (dd > 0), pi, ddmod)
A:jax._src.numpy.lax_numpy.ph_correct->where(abs(dd) < discont, 0, ddmod - dd)
A:jax._src.numpy.lax_numpy.up->concatenate((lax.slice_in_dim(p, 0, 1, axis=axis), lax.slice_in_dim(p, 1, None, axis=axis) + cumsum(ph_correct, axis=axis)), axis=axis)
A:jax._src.numpy.lax_numpy.nd->ndim(a)
A:jax._src.numpy.lax_numpy.constant_values->kwargs.get('constant_values', 0)
A:jax._src.numpy.lax_numpy.array->asarray(array)
A:jax._src.numpy.lax_numpy.(repeats, (left_remainder, right_remainder))->_divmod(pad_width[i], size)
A:jax._src.numpy.lax_numpy.edge->jax.lax.slice_in_dim(x, -1, None, axis=i)
A:jax._src.numpy.lax_numpy.curr_pad->_min(padding, n - offset)
A:jax._src.numpy.lax_numpy.edge_before->jax.lax.slice_in_dim(array, 0, 1, axis=axis)
A:jax._src.numpy.lax_numpy.pad_before->empty_like(array, shape=shape_before)
A:jax._src.numpy.lax_numpy.edge_after->jax.lax.slice_in_dim(array, -1, None, axis=axis)
A:jax._src.numpy.lax_numpy.pad_after->empty_like(array, shape=shape_after)
A:jax._src.numpy.lax_numpy.ramp_before->jax._src.lax.lax._convert_element_type(ramp_before, weak_type=dtypes.is_weakly_typed(array))
A:jax._src.numpy.lax_numpy.ramp_after->flip(ramp_after, axis)
A:jax._src.numpy.lax_numpy.stat_before->jax._src.lax.lax._convert_element_type(stat_before, array.dtype, dtypes.is_weakly_typed(array))
A:jax._src.numpy.lax_numpy.length_before->_min(length_before, array_length)
A:jax._src.numpy.lax_numpy.length_after->_min(length_after, array_length)
A:jax._src.numpy.lax_numpy.slice_before->jax.lax.slice_in_dim(array, 0, length_before, axis=i)
A:jax._src.numpy.lax_numpy.slice_after->jax.lax.slice_in_dim(array, -length_after, None, axis=i)
A:jax._src.numpy.lax_numpy.stat_after->jax._src.lax.lax._convert_element_type(stat_after, array.dtype, dtypes.is_weakly_typed(array))
A:jax._src.numpy.lax_numpy.pad_width->_broadcast_to_pairs(pad_width, ndim(array), 'pad_width')
A:jax._src.numpy.lax_numpy.padded->apply_along_axis(func, axis, padded, pad_width[axis], axis, kwargs)
A:jax._src.numpy.lax_numpy.nvals->numpy.asarray(tree_map(lambda x: core.concrete_or_error(np.array, x, context=f'{name} argument of jnp.pad'), nvals))
A:jax._src.numpy.lax_numpy.end_values->kwargs.get('end_values', 0)
A:jax._src.numpy.lax_numpy.stat_length->kwargs.get('stat_length', None)
A:jax._src.numpy.lax_numpy.reflect_type->kwargs.get('reflect_type', 'even')
A:jax._src.numpy.lax_numpy.shape0->shape(arrays[0])
A:jax._src.numpy.lax_numpy.reps->tuple((operator.index(rep) if core.is_constant_dim(rep) else rep for rep in reps))
A:jax._src.numpy.lax_numpy.arr->arr.astype(uint8).astype(uint8)
A:jax._src.numpy.lax_numpy.arrays->_promote_dtypes(*arrays)
A:jax._src.numpy.lax_numpy.arrs->jax.vmap(atleast_3d)(tup)
A:jax._src.numpy.lax_numpy.(a, *choices)->broadcast_arrays(a, *choices)
A:jax._src.numpy.lax_numpy.m->ndim(x)
A:jax._src.numpy.lax_numpy.(xs, depths)->unzip2([_block(x) for x in xs])
A:jax._src.numpy.lax_numpy.rank->ndim(arr)
A:jax._src.numpy.lax_numpy.(out, _)->_block(arrays)
A:jax._src.numpy.lax_numpy._->jax._src.dtypes.coerce_to_array(object, dtype)
A:jax._src.numpy.lax_numpy.leaves->tree_leaves(object)
A:jax._src.numpy.lax_numpy.aval->ShapedArray(object.xla_shape().dimensions(), object.dtype, weak_type=bool(getattr(object, 'weak_type', False)))
A:jax._src.numpy.lax_numpy.object->jax._src.device_array.make_device_array(aval, object.device(), object)
A:jax._src.numpy.lax_numpy.view->memoryview(object)
A:jax._src.numpy.lax_numpy.eq->equal(a1, a2)
A:jax._src.numpy.lax_numpy.function->jax.vmap(function, in_axes=tuple(in_axes[::-1]))
A:jax._src.numpy.lax_numpy.k->operator.index(k)
A:jax._src.numpy.lax_numpy.require->partial(core.concrete_or_error, None)
A:jax._src.numpy.lax_numpy.start->jax.core.concrete_or_error(operator.index, start, "'start' argument of jnp.rollaxis()")
A:jax._src.numpy.lax_numpy.num->jax.core.concrete_or_error(operator.index, num, "'num' argument of jnp.geomspace")
A:jax._src.numpy.lax_numpy.computation_dtype->promote_types(dtype, dtypes.canonicalize_dtype(float_))
A:jax._src.numpy.lax_numpy.stop->asarray(stop, dtype=computation_dtype)
A:jax._src.numpy.lax_numpy.bounds_shape->list(lax.broadcast_shapes(shape(start), shape(stop)))
A:jax._src.numpy.lax_numpy.broadcast_start->broadcast_to(start, bounds_shape)
A:jax._src.numpy.lax_numpy.broadcast_stop->broadcast_to(stop, bounds_shape)
A:jax._src.numpy.lax_numpy.empty_shape->list(lax.broadcast_shapes(shape(start), shape(stop)))
A:jax._src.numpy.lax_numpy.lin->linspace(start, stop, num, endpoint=endpoint, retstep=False, dtype=None, axis=axis)
A:jax._src.numpy.lax_numpy.res->argmin(a, axis=axis, keepdims=keepdims)
A:jax._src.numpy.lax_numpy.(x,)->_promote_args_inexact('i0', x)
A:jax._src.numpy.lax_numpy.dimensions->list(range(nd))
A:jax._src.numpy.lax_numpy.idx->_canonicalize_tuple_index(len(x_shape), idx)
A:jax._src.numpy.lax_numpy.result_shape->list(a.shape)
A:jax._src.numpy.lax_numpy.total_repeat_length->numpy.sum(repeats)
A:jax._src.numpy.lax_numpy.exclusive_repeats->roll(repeats, shift=1).at[0].set(0)
A:jax._src.numpy.lax_numpy.scatter_indices->cumsum(exclusive_repeats)
A:jax._src.numpy.lax_numpy.block_split_indicators->block_split_indicators.at[scatter_indices].add(1).at[scatter_indices].add(1)
A:jax._src.numpy.lax_numpy.m_shape->shape(m)
A:jax._src.numpy.lax_numpy.mask->numpy.ones(arr.shape[axis], dtype=bool)
A:jax._src.numpy.lax_numpy.default_int->jax._src.dtypes.canonicalize_dtype(np.int_)
A:jax._src.numpy.lax_numpy.tril_indices->_wrap_indices_function(np.tril_indices)
A:jax._src.numpy.lax_numpy.triu_indices->_wrap_indices_function(np.triu_indices)
A:jax._src.numpy.lax_numpy.mask_indices->_wrap_indices_function(np.mask_indices)
A:jax._src.numpy.lax_numpy.ndim->len(shape)
A:jax._src.numpy.lax_numpy.offset->jax.core.concrete_or_error(operator.index, offset, "'offset' argument of jnp.diagonal()")
A:jax._src.numpy.lax_numpy.diag_size->_max(0, _min(a_shape[axis1] + _min(offset, 0), a_shape[axis2] - _max(offset, 0)))
A:jax._src.numpy.lax_numpy.j->arange(_abs(offset), _abs(offset) + diag_size)
A:jax._src.numpy.lax_numpy.v_shape->shape(v)
A:jax._src.numpy.lax_numpy.v->ravel(v)
A:jax._src.numpy.lax_numpy.v_length->len(v)
A:jax._src.numpy.lax_numpy.filt->jax.core.concrete_or_error(asarray, filt, 'Error arose in the `filt` argument of trim_zeros()')
A:jax._src.numpy.lax_numpy.obj->jax.core.concrete_or_error(np.asarray, obj, "'obj' array argument of jnp.delete()")
A:jax._src.numpy.lax_numpy.indices->argmax(cumsum(concatenate([zeros_like(condlist[:1]), condlist], 0), 0), 0)
A:jax._src.numpy.lax_numpy.values->moveaxis(values, 0, axis)
A:jax._src.numpy.lax_numpy.out_shape->jax.lax.broadcast_shapes(idx_shape, arr_shape)
A:jax._src.numpy.lax_numpy.values_ind->argmax(cumsum(concatenate([zeros_like(condlist[:1]), condlist], 0), 0), 0).at[argsort(indices)].add(arange(n_insert))
A:jax._src.numpy.lax_numpy.arr_mask->ones(n_input + n_insert, dtype=bool).at[values_ind].set(False)
A:jax._src.numpy.lax_numpy.num_dims->ndim(arr)
A:jax._src.numpy.lax_numpy.func->jax.vmap(func, in_axes=0, out_axes=0)
A:jax._src.numpy.lax_numpy.num_batch_dims->_max(len(a_batch_dims), len(b_batch_dims))
A:jax._src.numpy.lax_numpy.a_ndim->ndim(a)
A:jax._src.numpy.lax_numpy.b_ndim->ndim(b)
A:jax._src.numpy.lax_numpy.(operands, contractions)->einsum_contract_path_fn(*operands, einsum_call=True, use_blas=True, optimize=optimize)
A:jax._src.numpy.lax_numpy.contractions->tuple(((a, frozenset(b), c) for (a, b, c, *_) in contractions))
A:jax._src.numpy.lax_numpy.operands->list(_promote_dtypes(*operands))
A:jax._src.numpy.lax_numpy.operand->jax.lax.transpose(operand, perm)
A:jax._src.numpy.lax_numpy.names->names.replace(name, '', count - 1).replace(name, '', count - 1)
A:jax._src.numpy.lax_numpy.eye->jax._src.lax.lax._delta(operand.dtype, operand.shape, axes)
A:jax._src.numpy.lax_numpy.s->shape(operand)
A:jax._src.numpy.lax_numpy.other_i->other_names.find(d)
A:jax._src.numpy.lax_numpy.contracted_names->sorted(contracted_names_set)
A:jax._src.numpy.lax_numpy.(input_str, result_names)->einstr.split('->')
A:jax._src.numpy.lax_numpy.input_names->input_str.split(',')
A:jax._src.numpy.lax_numpy.counts->jax.lax.expand_dims(counts, tuple(range(q_ndim)))
A:jax._src.numpy.lax_numpy.(operand, names)->sum_repeats(operand, names, counts, result_names)
A:jax._src.numpy.lax_numpy.(lhs, rhs)->map(operands.pop, operand_indices)
A:jax._src.numpy.lax_numpy.(lhs, lhs_names)->sum_repeats(lhs, lhs_names, lhs_counts, result_names + rhs_names)
A:jax._src.numpy.lax_numpy.(rhs, rhs_names)->sum_repeats(rhs, rhs_names, rhs_counts, result_names + lhs_names)
A:jax._src.numpy.lax_numpy.lhs_counts->collections.Counter(lhs_names)
A:jax._src.numpy.lax_numpy.rhs_counts->collections.Counter(rhs_names)
A:jax._src.numpy.lax_numpy.(lhs_batch, rhs_batch)->unzip2(((lhs_names.find(n), rhs_names.find(n)) for n in batch_names))
A:jax._src.numpy.lax_numpy.batch_names_str->''.join(batch_names)
A:jax._src.numpy.lax_numpy.(lhs_cont, rhs_cont)->unzip2(((lhs_names.index(n), rhs_names.index(n)) for n in contracted_names))
A:jax._src.numpy.lax_numpy.remaining_lhs_names->_removechars(lhs_names, deleted_names)
A:jax._src.numpy.lax_numpy.remaining_rhs_names->_removechars(rhs_names, deleted_names)
A:jax._src.numpy.lax_numpy.c->jax.lax.complex(real_part, complex_part)
A:jax._src.numpy.lax_numpy.a_reshaped->expand_dims(a, range(1, 2 * ndim(a), 2))
A:jax._src.numpy.lax_numpy.b_reshaped->expand_dims(b, range(0, 2 * ndim(b), 2))
A:jax._src.numpy.lax_numpy.iota->jax.lax.broadcast_in_dim(iota, gather_index_shape, (j,))
A:jax._src.numpy.lax_numpy.nan_mask->isnan(a)
A:jax._src.numpy.lax_numpy.keys->tuple(keys)
A:jax._src.numpy.lax_numpy.axis_num->_canonicalize_axis(axis, ndim(a))
A:jax._src.numpy.lax_numpy.(_, perm)->jax.lax.sort_key_val(a, iota, dimension=axis_num)
A:jax._src.numpy.lax_numpy.shift->asarray(shift)
A:jax._src.numpy.lax_numpy.b_shape->jax.lax.broadcast_shapes(shift.shape, axis.shape, (1,))
A:jax._src.numpy.lax_numpy.bits->expand_dims(bits, tuple(range(a.ndim - 1)))
A:jax._src.numpy.lax_numpy.packed->(a << bits).sum(-1).astype('uint8')
A:jax._src.numpy.lax_numpy.unpacked->(a[..., None] & expand_dims(bits, tuple(range(a.ndim))) > 0).astype('uint8')
A:jax._src.numpy.lax_numpy.axis_idx->_canonicalize_axis(axis, ndim(a))
A:jax._src.numpy.lax_numpy.index_dims->len(shape(indices))
A:jax._src.numpy.lax_numpy.slice_sizes->list(a_shape)
A:jax._src.numpy.lax_numpy.dnums->jax.lax.GatherDimensionNumbers(offset_dims=tuple(range(q_ndim, len(a_shape) + q_ndim if keepdims else len(a_shape) + q_ndim - 1)), collapsed_slice_dims=() if keepdims else (axis,), start_index_map=(axis,))
A:jax._src.numpy.lax_numpy.axis_size_val->jax.lax.convert_element_type(core.dimension_as_value(axis_size), _dtype(index))
A:jax._src.numpy.lax_numpy.lst->list(tup)
A:jax._src.numpy.lax_numpy.use_64bit_index->_any([not core.is_constant_dim(d) or d >= 1 << 31 for d in x_shape])
A:jax._src.numpy.lax_numpy.bcast_shape->jax.lax.broadcast_shapes(replace(arr.shape, 1), replace(indices.shape, 1))
A:jax._src.numpy.lax_numpy.arr_shape->replace(arr.shape, 1)
A:jax._src.numpy.lax_numpy.gather_indices->jax.lax.concatenate(gather_indices, dimension=j)
A:jax._src.numpy.lax_numpy.(treedef, static_idx, dynamic_idx)->_split_index_for_jit(idx, arr.shape)
A:jax._src.numpy.lax_numpy.indexer->_index_to_gather(shape(arr), idx)
A:jax._src.numpy.lax_numpy.fill_value->fill_value.item().item()
A:jax._src.numpy.lax_numpy._Indexer->collections.namedtuple('_Indexer', ['slice_shape', 'gather_slice_shape', 'gather_indices', 'dnums', 'unique_indices', 'indices_are_sorted', 'reversed_y_dims', 'newaxis_dims'])
A:jax._src.numpy.lax_numpy.(leaves, treedef)->tree_flatten(idx)
A:jax._src.numpy.lax_numpy.(advanced_indexes, idx_advanced_axes, x_advanced_axes)->zip(*advanced_pairs)
A:jax._src.numpy.lax_numpy.advanced_axes_are_contiguous->numpy.all(np.diff(idx_advanced_axes) == 1)
A:jax._src.numpy.lax_numpy.advanced_indexes->broadcast_arrays(*advanced_indexes)
A:jax._src.numpy.lax_numpy.start_dim->len(gather_indices_shape)
A:jax._src.numpy.lax_numpy.abstract_i->jax.core.get_aval(i)
A:jax._src.numpy.lax_numpy.(start, limit, stride, needs_rev)->_static_idx(slice(start, stop, step), x_shape[x_axis])
A:jax._src.numpy.lax_numpy.gather_indices_array->jax.lax.concatenate([lax.broadcast_in_dim(g, gather_indices_shape, tuple(range(i, i + g.ndim))) for (g, i) in gather_indices], last_dim)
A:jax._src.numpy.lax_numpy.last_dim->len(gather_indices_shape)
A:jax._src.numpy.lax_numpy.total_dims->_sum((_ndim(e) if _is_boolean_index(e) else 1 for e in idx if e is not None and e is not Ellipsis))
A:jax._src.numpy.lax_numpy.num_ellipsis->_sum((e is Ellipsis for e in idx))
A:jax._src.numpy.lax_numpy.i_shape->_shape(i)
A:jax._src.numpy.lax_numpy.len_without_none->_sum((1 for e in idx if e is not None and e is not Ellipsis))
A:jax._src.numpy.lax_numpy.ellipsis_index->next(ellipses, None)
A:jax._src.numpy.lax_numpy.(start, stop, step)->_canonicalize_tuple_index(len(x_shape), idx).indices(size)
A:jax._src.numpy.lax_numpy.blackman->_wrap_numpy_nullary_function(np.blackman)
A:jax._src.numpy.lax_numpy.bartlett->_wrap_numpy_nullary_function(np.bartlett)
A:jax._src.numpy.lax_numpy.hamming->_wrap_numpy_nullary_function(np.hamming)
A:jax._src.numpy.lax_numpy.hanning->_wrap_numpy_nullary_function(np.hanning)
A:jax._src.numpy.lax_numpy.kaiser->_wrap_numpy_nullary_function(np.kaiser)
A:jax._src.numpy.lax_numpy.(x1, x2)->_promote_dtypes(x1, x2)
A:jax._src.numpy.lax_numpy.(gcd, _)->jax.lax.while_loop(_gcd_cond_fn, _gcd_body_fn, (abs(x1), abs(x2)))
A:jax._src.numpy.lax_numpy.d->diag(c)
A:jax._src.numpy.lax_numpy.condition->asarray(condition).astype(bool)
A:jax._src.numpy.lax_numpy.(m, y)->_promote_args_inexact('cov', m, y)
A:jax._src.numpy.lax_numpy.(m,)->_promote_args_inexact('cov', m)
A:jax._src.numpy.lax_numpy.X->concatenate((X, y), axis=0)
A:jax._src.numpy.lax_numpy.w->asarray(abs(fweights))
A:jax._src.numpy.lax_numpy.aweights->abs(aweights)
A:jax._src.numpy.lax_numpy.(avg, w_sum)->average(X, axis=1, weights=w, returned=True)
A:jax._src.numpy.lax_numpy.stddev->sqrt(real(d))
A:jax._src.numpy.lax_numpy.real_part->clip(real(c), -1, 1)
A:jax._src.numpy.lax_numpy.complex_part->clip(imag(c), -1, 1)
A:jax._src.numpy.lax_numpy.(a, q)->_promote_dtypes_inexact(a, q)
A:jax._src.numpy.lax_numpy.keepdim->tuple(keepdim)
A:jax._src.numpy.lax_numpy.do_not_touch_shape->tuple((x for (idx, x) in enumerate(shape(a)) if idx not in axis))
A:jax._src.numpy.lax_numpy.touch_shape->tuple((x for (idx, x) in enumerate(shape(a)) if idx in axis))
A:jax._src.numpy.lax_numpy.q_shape->shape(q)
A:jax._src.numpy.lax_numpy.q_ndim->ndim(q)
A:jax._src.numpy.lax_numpy.q->true_divide(q, float32(100.0))
A:jax._src.numpy.lax_numpy.low->jax.lax.convert_element_type(low, int64)
A:jax._src.numpy.lax_numpy.high->jax.lax.convert_element_type(high, int64)
A:jax._src.numpy.lax_numpy.high_weight->jax.lax.broadcast_in_dim(high_weight, high_value.shape, broadcast_dimensions=(0,))
A:jax._src.numpy.lax_numpy.low_weight->jax.lax.broadcast_in_dim(low_weight, low_value.shape, broadcast_dimensions=(0,))
A:jax._src.numpy.lax_numpy.low_value->jax.lax.gather(a, low[..., None], dimension_numbers=dnums, slice_sizes=slice_sizes)
A:jax._src.numpy.lax_numpy.high_value->jax.lax.gather(a, high[..., None], dimension_numbers=dnums, slice_sizes=slice_sizes)
A:jax._src.numpy.lax_numpy.pred->jax.lax.le(high_weight, _lax_const(high_weight, 0.5))
A:jax._src.numpy.lax_numpy.(a, v)->_promote_dtypes(a, v)
A:jax._src.numpy.lax_numpy.go_left->op(v, a[mid])
A:jax._src.numpy.lax_numpy.n_levels->int(np.ceil(np.log2(len(a) + 1)))
A:jax._src.numpy.lax_numpy.right->jax.core.concrete_or_error(bool, right, 'right argument of jnp.digitize()')
A:jax._src.numpy.lax_numpy.condlist->array(condlist, dtype=bool_)
A:jax._src.numpy.lax_numpy.funcs->dict(funcs)
A:jax._src.numpy.lax_numpy.arr_dtype->_dtype(arr)
A:jax._src.numpy.lax_numpy.arr_bytes->arr_bytes.reshape(arr_bytes.shape[:-2] + (-1,)).reshape(arr_bytes.shape[:-2] + (-1,))
A:jax._src.numpy.lax_numpy.shifts->jax.lax.expand_dims(arange(0, nbits_in, nbits_out, dtype=dt_in), tuple(range(arr_bytes.ndim)))
A:jax._src.numpy.lax_numpy.other->other.__jax_array__().__jax_array__()
A:jax._src.numpy.lax_numpy.argpartition->_not_implemented(np.argpartition)
A:jax._src.numpy.lax_numpy.(num_chunks, tail)->divmod(x.shape[0], size)
jax._src.numpy.lax_numpy._IndexUpdateHelper(self,array)
jax._src.numpy.lax_numpy._IndexUpdateHelper.__getitem__(self,index)
jax._src.numpy.lax_numpy._IndexUpdateHelper.__init__(self,array)
jax._src.numpy.lax_numpy._IndexUpdateHelper.__repr__(self)
jax._src.numpy.lax_numpy._IndexUpdateRef(self,array,index)
jax._src.numpy.lax_numpy._IndexUpdateRef.__init__(self,array,index)
jax._src.numpy.lax_numpy._IndexUpdateRef.__repr__(self)
jax._src.numpy.lax_numpy._IndexUpdateRef.add(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.apply(self,func,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.divide(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.get(self,indices_are_sorted=False,unique_indices=False,mode=None,fill_value=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.max(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.min(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.multiply(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.power(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._IndexUpdateRef.set(self,values,indices_are_sorted=False,unique_indices=False,mode=None)
jax._src.numpy.lax_numpy._ScalarMeta(self,x)
jax._src.numpy.lax_numpy._ScalarMeta.__call__(self,x)
jax._src.numpy.lax_numpy._ScalarMeta.__eq__(self,other)
jax._src.numpy.lax_numpy._ScalarMeta.__hash__(self)
jax._src.numpy.lax_numpy._ScalarMeta.__instancecheck__(self,instance)
jax._src.numpy.lax_numpy._ScalarMeta.__ne__(self,other)
jax._src.numpy.lax_numpy.__array_module__(self,types)
jax._src.numpy.lax_numpy._argmax(a,axis:Optional[int]=None,out=None,keepdims=False)
jax._src.numpy.lax_numpy._argmin(a,axis:Optional[int]=None,out=None,keepdims=False)
jax._src.numpy.lax_numpy._astype(arr,dtype)
jax._src.numpy.lax_numpy._atleast_nd(x,n)
jax._src.numpy.lax_numpy._block(xs)
jax._src.numpy.lax_numpy._broadcast_to_pairs(nvals,nd,name)
jax._src.numpy.lax_numpy._canonicalize_tuple_index(arr_ndim,idx,array_name='array')
jax._src.numpy.lax_numpy._check_no_padding(axis_padding,mode)
jax._src.numpy.lax_numpy._chunk_iter(x,size)
jax._src.numpy.lax_numpy._clip(number,min=None,max=None,out=None,*,a_min=None,a_max=None)
jax._src.numpy.lax_numpy._compress_method(a,condition,axis=None,out=None)
jax._src.numpy.lax_numpy._compute_newshape(a,newshape)
jax._src.numpy.lax_numpy._concatenate_array(arr,axis:int)
jax._src.numpy.lax_numpy._conv(x,y,mode,op,precision)
jax._src.numpy.lax_numpy._convert_and_clip_integer(val,dtype)
jax._src.numpy.lax_numpy._convert_to_array_if_dtype_fails(x)
jax._src.numpy.lax_numpy._defer_to_unrecognized_arg(binary_op)
jax._src.numpy.lax_numpy._diag(v,k)
jax._src.numpy.lax_numpy._einsum(operands:Sequence,contractions:Sequence[Tuple[Tuple[int,...],FrozenSet[str],str]],precision)
jax._src.numpy.lax_numpy._eliminate_deprecated_list_indexing(idx)
jax._src.numpy.lax_numpy._expand_bool_indices(idx,shape)
jax._src.numpy.lax_numpy._flip(m,axis:Optional[Union[int,Tuple[int,...]]]=None)
jax._src.numpy.lax_numpy._gather(arr,treedef,static_idx,dynamic_idx,indices_are_sorted,unique_indices,mode,fill_value)
jax._src.numpy.lax_numpy._gcd_body_fn(xs)
jax._src.numpy.lax_numpy._gcd_cond_fn(xs)
jax._src.numpy.lax_numpy._geomspace(start,stop,num=50,endpoint=True,dtype=None,axis:int=0)
jax._src.numpy.lax_numpy._index_to_gather(x_shape,idx,normalize_indices=True)
jax._src.numpy.lax_numpy._int(aval)
jax._src.numpy.lax_numpy._is_advanced_int_indexer(idx)
jax._src.numpy.lax_numpy._is_boolean_index(i)
jax._src.numpy.lax_numpy._is_int_arraylike(x)
jax._src.numpy.lax_numpy._is_scalar(x)
jax._src.numpy.lax_numpy._is_slice_element_none_or_constant(elt)
jax._src.numpy.lax_numpy._itemsize(arr)
jax._src.numpy.lax_numpy._jnp_dtype(obj,align=False,copy=False)
jax._src.numpy.lax_numpy._linspace(start,stop,num=50,endpoint=True,retstep=False,dtype=None,axis:int=0)
jax._src.numpy.lax_numpy._logspace(start,stop,num=50,endpoint=True,base=10.0,dtype=None,axis:int=0)
jax._src.numpy.lax_numpy._make_scalar_type(np_scalar_type)
jax._src.numpy.lax_numpy._merge_static_and_dynamic_indices(treedef,static_idx,dynamic_idx)
jax._src.numpy.lax_numpy._moveaxis(a,source:Tuple[int,...],destination:Tuple[int,...])
jax._src.numpy.lax_numpy._movechars(s,src,dst)
jax._src.numpy.lax_numpy._multi_slice(arr,start_indices:Tuple[Tuple[int,...]],limit_indices:Tuple[Tuple[int,...]],removed_dims:Tuple[Tuple[int,...]])
jax._src.numpy.lax_numpy._nanargmax(a,axis:Optional[int]=None,keepdims:bool=False)
jax._src.numpy.lax_numpy._nanargmin(a,axis:Optional[int]=None,keepdims:bool=False)
jax._src.numpy.lax_numpy._nbytes(arr)
jax._src.numpy.lax_numpy._normalize_index(index,axis_size)
jax._src.numpy.lax_numpy._not_implemented(fun)
jax._src.numpy.lax_numpy._operator_round(number,ndigits=None)
jax._src.numpy.lax_numpy._pad(array,pad_width,mode,constant_values,stat_length,end_values,reflect_type)
jax._src.numpy.lax_numpy._pad_constant(array,pad_width,constant_values)
jax._src.numpy.lax_numpy._pad_edge(array,pad_width)
jax._src.numpy.lax_numpy._pad_empty(array,pad_width)
jax._src.numpy.lax_numpy._pad_func(array,pad_width,func,**kwargs)
jax._src.numpy.lax_numpy._pad_linear_ramp(array,pad_width,end_values)
jax._src.numpy.lax_numpy._pad_stats(array,pad_width,stat_length,stat_func)
jax._src.numpy.lax_numpy._pad_symmetric_or_reflect(array,pad_width,mode,reflect_type)
jax._src.numpy.lax_numpy._pad_wrap(array,pad_width)
jax._src.numpy.lax_numpy._piecewise(x,condlist,consts,funcs,*args,**kw)
jax._src.numpy.lax_numpy._quantile(a,q,axis,interpolation,keepdims,squash_nans)
jax._src.numpy.lax_numpy._removechars(s,chars)
jax._src.numpy.lax_numpy._reshape(a,*args,order='C')
jax._src.numpy.lax_numpy._result_dtype(op,*args)
jax._src.numpy.lax_numpy._rewriting_take(arr,idx,indices_are_sorted=False,unique_indices=False,mode=None,fill_value=None)
jax._src.numpy.lax_numpy._roll(a,shift,axis)
jax._src.numpy.lax_numpy._searchsorted(a,v,side)
jax._src.numpy.lax_numpy._set_device_array_attributes(device_array)
jax._src.numpy.lax_numpy._set_device_array_base_attributes(device_array)
jax._src.numpy.lax_numpy._set_shaped_array_attributes(shaped_array)
jax._src.numpy.lax_numpy._should_unpack_list_index(x)
jax._src.numpy.lax_numpy._split(op,ary,indices_or_sections,axis=0)
jax._src.numpy.lax_numpy._split_index_for_jit(idx,shape)
jax._src.numpy.lax_numpy._split_on_axis(op,axis)
jax._src.numpy.lax_numpy._squeeze(a,axis)
jax._src.numpy.lax_numpy._static_idx(idx:slice,size:core.DimSize)
jax._src.numpy.lax_numpy._swap_args(f)
jax._src.numpy.lax_numpy._take(a,indices,axis:Optional[int]=None,out=None,mode=None)
jax._src.numpy.lax_numpy._transpose(a,*args)
jax._src.numpy.lax_numpy._unimplemented_setitem(self,i,x)
jax._src.numpy.lax_numpy._unstack(x)
jax._src.numpy.lax_numpy._view(arr,dtype=None,type=None)
jax._src.numpy.lax_numpy._wrap_indices_function(f)
jax._src.numpy.lax_numpy._wrap_numpy_nullary_function(f)
jax._src.numpy.lax_numpy.allclose(a,b,rtol=1e-05,atol=1e-08,equal_nan=False)
jax._src.numpy.lax_numpy.angle(z,deg=False)
jax._src.numpy.lax_numpy.append(arr,values,axis:Optional[int]=None)
jax._src.numpy.lax_numpy.apply_along_axis(func1d,axis:int,arr,*args,**kwargs)
jax._src.numpy.lax_numpy.apply_over_axes(func,a,axes)
jax._src.numpy.lax_numpy.arange(start:core.DimSize,stop:Optional[core.DimSize]=None,step:Optional[core.DimSize]=None,dtype=None)
jax._src.numpy.lax_numpy.argmax(a,axis:Optional[int]=None,out=None,keepdims=None)
jax._src.numpy.lax_numpy.argmin(a,axis:Optional[int]=None,out=None,keepdims=None)
jax._src.numpy.lax_numpy.argsort(a,axis:Optional[int]=-1,kind='stable',order=None)
jax._src.numpy.lax_numpy.argwhere(a,*,size=None,fill_value=None)
jax._src.numpy.lax_numpy.array(object,dtype=None,copy=True,order='K',ndmin=0)
jax._src.numpy.lax_numpy.array_equal(a1,a2,equal_nan=False)
jax._src.numpy.lax_numpy.array_equiv(a1,a2)
jax._src.numpy.lax_numpy.array_split(ary,indices_or_sections,axis:int=0)
jax._src.numpy.lax_numpy.asarray(a,dtype=None,order=None)
jax._src.numpy.lax_numpy.atleast_1d(*arys)
jax._src.numpy.lax_numpy.atleast_2d(*arys)
jax._src.numpy.lax_numpy.atleast_3d(*arys)
jax._src.numpy.lax_numpy.bincount(x,weights=None,minlength=0,*,length=None)
jax._src.numpy.lax_numpy.block(arrays)
jax._src.numpy.lax_numpy.broadcast_shapes(*shapes)
jax._src.numpy.lax_numpy.choose(a,choices,out=None,mode='raise')
jax._src.numpy.lax_numpy.clip(a,a_min=None,a_max=None,out=None)
jax._src.numpy.lax_numpy.column_stack(tup)
jax._src.numpy.lax_numpy.compress(condition,a,axis:Optional[int]=None,out=None)
jax._src.numpy.lax_numpy.concatenate(arrays,axis:int=0)
jax._src.numpy.lax_numpy.convolve(a,v,mode='full',*,precision=None)
jax._src.numpy.lax_numpy.copy(a,order=None)
jax._src.numpy.lax_numpy.corrcoef(x,y=None,rowvar=True)
jax._src.numpy.lax_numpy.correlate(a,v,mode='valid',*,precision=None)
jax._src.numpy.lax_numpy.cov(m,y=None,rowvar=True,bias=False,ddof=None,fweights=None,aweights=None)
jax._src.numpy.lax_numpy.cross(a,b,axisa:int=-1,axisb:int=-1,axisc:int=-1,axis:Optional[int]=None)
jax._src.numpy.lax_numpy.delete(arr,obj,axis=None)
jax._src.numpy.lax_numpy.diag(v,k=0)
jax._src.numpy.lax_numpy.diag_indices(n,ndim=2)
jax._src.numpy.lax_numpy.diag_indices_from(arr)
jax._src.numpy.lax_numpy.diagflat(v,k=0)
jax._src.numpy.lax_numpy.diagonal(a,offset=0,axis1:int=0,axis2:int=1)
jax._src.numpy.lax_numpy.diff(a,n=1,axis:int=-1,prepend=None,append=None)
jax._src.numpy.lax_numpy.digitize(x,bins,right=False)
jax._src.numpy.lax_numpy.dot(a,b,*,precision=None)
jax._src.numpy.lax_numpy.dstack(tup)
jax._src.numpy.lax_numpy.ediff1d(ary,to_end=None,to_begin=None)
jax._src.numpy.lax_numpy.einsum(*operands,out=None,optimize='optimal',precision=None,_use_xeinsum=False)
jax._src.numpy.lax_numpy.einsum_path(subscripts,*operands,optimize='greedy')
jax._src.numpy.lax_numpy.expand_dims(a,axis:Union[int,Sequence[int]])
jax._src.numpy.lax_numpy.extract(condition,arr)
jax._src.numpy.lax_numpy.eye(N,M=None,k=0,dtype=None)
jax._src.numpy.lax_numpy.fix(x,out=None)
jax._src.numpy.lax_numpy.flatnonzero(a,*,size=None,fill_value=None)
jax._src.numpy.lax_numpy.flip(m,axis:Optional[Union[int,Tuple[int,...]]]=None)
jax._src.numpy.lax_numpy.fliplr(m)
jax._src.numpy.lax_numpy.flipud(m)
jax._src.numpy.lax_numpy.fmax(x1,x2)
jax._src.numpy.lax_numpy.fmin(x1,x2)
jax._src.numpy.lax_numpy.frombuffer(buffer,dtype=float,count=-1,offset=0)
jax._src.numpy.lax_numpy.fromfile(*args,**kwargs)
jax._src.numpy.lax_numpy.fromfunction(function,shape,*,dtype=float,**kwargs)
jax._src.numpy.lax_numpy.fromiter(*args,**kwargs)
jax._src.numpy.lax_numpy.fromstring(string,dtype=float,count=-1,*,sep)
jax._src.numpy.lax_numpy.full(shape,fill_value,dtype=None)
jax._src.numpy.lax_numpy.full_like(a,fill_value,dtype=None,shape=None)
jax._src.numpy.lax_numpy.gcd(x1,x2)
jax._src.numpy.lax_numpy.geomspace(start,stop,num=50,endpoint=True,dtype=None,axis:int=0)
jax._src.numpy.lax_numpy.gradient(f,*varargs,axis:Optional[Union[int,Tuple[int,...]]]=None,edge_order=None)
jax._src.numpy.lax_numpy.histogram(a,bins=10,range=None,weights=None,density=None)
jax._src.numpy.lax_numpy.histogram2d(x,y,bins=10,range=None,weights=None,density=None)
jax._src.numpy.lax_numpy.histogram_bin_edges(a,bins=10,range=None,weights=None)
jax._src.numpy.lax_numpy.histogramdd(sample,bins=10,range=None,weights=None,density=None)
jax._src.numpy.lax_numpy.hstack(tup)
jax._src.numpy.lax_numpy.i0(x)
jax._src.numpy.lax_numpy.identity(n,dtype=None)
jax._src.numpy.lax_numpy.indices(dimensions,dtype=int32,sparse=False)
jax._src.numpy.lax_numpy.inner(a,b,*,precision=None)
jax._src.numpy.lax_numpy.insert(arr,obj,values,axis=None)
jax._src.numpy.lax_numpy.interp(x,xp,fp,left=None,right=None,period=None)
jax._src.numpy.lax_numpy.isclose(a,b,rtol=1e-05,atol=1e-08,equal_nan=False)
jax._src.numpy.lax_numpy.iscomplex(x)
jax._src.numpy.lax_numpy.isreal(x)
jax._src.numpy.lax_numpy.isrealobj(x)
jax._src.numpy.lax_numpy.isscalar(element)
jax._src.numpy.lax_numpy.issubdtype(arg1,arg2)
jax._src.numpy.lax_numpy.ix_(*args)
jax._src.numpy.lax_numpy.kron(a,b)
jax._src.numpy.lax_numpy.lcm(x1,x2)
jax._src.numpy.lax_numpy.lexsort(keys,axis=-1)
jax._src.numpy.lax_numpy.linspace(start,stop,num=50,endpoint=True,retstep=False,dtype=None,axis:int=0)
jax._src.numpy.lax_numpy.load(*args,**kwargs)
jax._src.numpy.lax_numpy.logspace(start,stop,num=50,endpoint=True,base=10.0,dtype=None,axis:int=0)
jax._src.numpy.lax_numpy.matmul(a,b,*,precision=None)
jax._src.numpy.lax_numpy.median(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,overwrite_input=False,keepdims=False)
jax._src.numpy.lax_numpy.meshgrid(*xi,copy=True,sparse=False,indexing='xy')
jax._src.numpy.lax_numpy.moveaxis(a,source:Union[int,Sequence[int]],destination:Union[int,Sequence[int]])
jax._src.numpy.lax_numpy.msort(a)
jax._src.numpy.lax_numpy.nan_to_num(x,copy=True,nan=0.0,posinf=None,neginf=None)
jax._src.numpy.lax_numpy.nanargmax(a,axis:Optional[int]=None,out:Any=None,keepdims:Optional[bool]=None)
jax._src.numpy.lax_numpy.nanargmin(a,axis:Optional[int]=None,out:Any=None,keepdims:Optional[bool]=None)
jax._src.numpy.lax_numpy.nanmedian(a,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,overwrite_input=False,keepdims=False)
jax._src.numpy.lax_numpy.nanpercentile(a,q,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,overwrite_input=False,method='linear',keepdims=False,interpolation=None)
jax._src.numpy.lax_numpy.nanquantile(a,q,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,overwrite_input=False,method='linear',keepdims=False,interpolation=None)
jax._src.numpy.lax_numpy.nonzero(a,*,size=None,fill_value=None)
jax._src.numpy.lax_numpy.ones(shape,dtype=None)
jax._src.numpy.lax_numpy.ones_like(a,dtype=None,shape=None)
jax._src.numpy.lax_numpy.outer(a,b,out=None)
jax._src.numpy.lax_numpy.packbits(a,axis:Optional[int]=None,bitorder='big')
jax._src.numpy.lax_numpy.pad(array,pad_width,mode='constant',**kwargs)
jax._src.numpy.lax_numpy.percentile(a,q,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,overwrite_input=False,method='linear',keepdims=False,interpolation=None)
jax._src.numpy.lax_numpy.piecewise(x,condlist,funclist,*args,**kw)
jax._src.numpy.lax_numpy.quantile(a,q,axis:Optional[Union[int,Tuple[int,...]]]=None,out=None,overwrite_input=False,method='linear',keepdims=False,interpolation=None)
jax._src.numpy.lax_numpy.ravel(a,order='C')
jax._src.numpy.lax_numpy.ravel_multi_index(multi_index,dims,mode='raise',order='C')
jax._src.numpy.lax_numpy.repeat(a,repeats,axis:Optional[int]=None,*,total_repeat_length=None)
jax._src.numpy.lax_numpy.reshape(a,newshape,order='C')
jax._src.numpy.lax_numpy.resize(a,new_shape)
jax._src.numpy.lax_numpy.result_type(*args)
jax._src.numpy.lax_numpy.roll(a,shift,axis:Optional[Union[int,Sequence[int]]]=None)
jax._src.numpy.lax_numpy.rollaxis(a,axis:int,start=0)
jax._src.numpy.lax_numpy.rot90(m,k=1,axes=(0,1))
jax._src.numpy.lax_numpy.round(a,decimals=0,out=None)
jax._src.numpy.lax_numpy.searchsorted(a,v,side='left',sorter=None)
jax._src.numpy.lax_numpy.select(condlist,choicelist,default=0)
jax._src.numpy.lax_numpy.sort(a,axis:Optional[int]=-1,kind='quicksort',order=None)
jax._src.numpy.lax_numpy.sort_complex(a)
jax._src.numpy.lax_numpy.split(ary,indices_or_sections,axis:int=0)
jax._src.numpy.lax_numpy.squeeze(a,axis:Optional[Union[int,Tuple[int,...]]]=None)
jax._src.numpy.lax_numpy.stack(arrays,axis:int=0,out=None)
jax._src.numpy.lax_numpy.swapaxes(a,axis1:int,axis2:int)
jax._src.numpy.lax_numpy.take(a,indices,axis:Optional[int]=None,out=None,mode=None)
jax._src.numpy.lax_numpy.take_along_axis(arr,indices,axis:Optional[int])
jax._src.numpy.lax_numpy.tensordot(a,b,axes=2,*,precision=None)
jax._src.numpy.lax_numpy.tile(A,reps)
jax._src.numpy.lax_numpy.trace(a,offset=0,axis1:int=0,axis2:int=1,dtype=None,out=None)
jax._src.numpy.lax_numpy.transpose(a,axes=None)
jax._src.numpy.lax_numpy.trapz(y,x=None,dx=1.0,axis:int=-1)
jax._src.numpy.lax_numpy.tri(N,M=None,k=0,dtype=None)
jax._src.numpy.lax_numpy.tril(m,k=0)
jax._src.numpy.lax_numpy.tril_indices_from(arr,k=0)
jax._src.numpy.lax_numpy.trim_zeros(filt,trim='fb')
jax._src.numpy.lax_numpy.triu(m,k=0)
jax._src.numpy.lax_numpy.triu_indices_from(arr,k=0)
jax._src.numpy.lax_numpy.trunc(x)
jax._src.numpy.lax_numpy.unpackbits(a,axis:Optional[int]=None,count=None,bitorder='big')
jax._src.numpy.lax_numpy.unravel_index(indices,shape)
jax._src.numpy.lax_numpy.unwrap(p,discont=pi,axis:int=-1)
jax._src.numpy.lax_numpy.vander(x,N=None,increasing=False)
jax._src.numpy.lax_numpy.vdot(a,b,*,precision=None)
jax._src.numpy.lax_numpy.vstack(tup)
jax._src.numpy.lax_numpy.where(condition,x=None,y=None,*,size=None,fill_value=None)
jax._src.numpy.lax_numpy.zeros(shape,dtype=None)
jax._src.numpy.lax_numpy.zeros_like(a,dtype=None,shape=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/vectorize.py----------------------------------------
A:jax._src.numpy.vectorize._CORE_DIMENSION_LIST->'(?:{0:}(?:,{0:})*)?'.format(_DIMENSION_NAME)
A:jax._src.numpy.vectorize._ARGUMENT->'\\({}\\)'.format(_CORE_DIMENSION_LIST)
A:jax._src.numpy.vectorize._ARGUMENT_LIST->'{0:}(?:,{0:})*'.format(_ARGUMENT)
A:jax._src.numpy.vectorize._SIGNATURE->'^{0:}->{0:}$'.format(_ARGUMENT_LIST)
A:jax._src.numpy.vectorize.num_core_dims->len(core_dims)
A:jax._src.numpy.vectorize.broadcast_shape->jax.lax.broadcast_shapes(*shapes)
A:jax._src.numpy.vectorize.out->func(*args)
A:jax._src.numpy.vectorize.out_shapes->map(jnp.shape, out if isinstance(out, tuple) else [out])
A:jax._src.numpy.vectorize.sizes->dict(dim_sizes)
A:jax._src.numpy.vectorize.args->tuple(map(jnp.asarray, args))
A:jax._src.numpy.vectorize.error_context->'on vectorized function with excluded={!r} and signature={!r}'.format(excluded, signature)
A:jax._src.numpy.vectorize.(excluded_func, args)->_apply_excluded(pyfunc, excluded, args)
A:jax._src.numpy.vectorize.(input_core_dims, output_core_dims)->_parse_gufunc_signature(signature)
A:jax._src.numpy.vectorize.(broadcast_shape, dim_sizes)->_parse_input_dimensions(args, input_core_dims, error_context)
A:jax._src.numpy.vectorize.checked_func->_check_output_dims(excluded_func, dim_sizes, output_core_dims, error_context)
A:jax._src.numpy.vectorize.core_shape->tuple((dim_sizes[dim] for dim in core_dims))
A:jax._src.numpy.vectorize.vec_arg->jax._src.numpy.lax_numpy.broadcast_to(arg, vec_shape)
A:jax._src.numpy.vectorize.in_axes->tuple((0 if c > 0 else None for c in vmap_counts))
A:jax._src.numpy.vectorize.vectorized_func->jax._src.api.vmap(vectorized_func, in_axes)
jax._src.numpy.vectorize._apply_excluded(func,excluded,args)
jax._src.numpy.vectorize._check_output_dims(func:Callable,dim_sizes:Dict[str,int],expected_output_core_dims:List[CoreDims],error_context:str='')->Callable
jax._src.numpy.vectorize._parse_gufunc_signature(signature:str)->Tuple[List[CoreDims], List[CoreDims]]
jax._src.numpy.vectorize._parse_input_dimensions(args:Tuple[NDArray,...],input_core_dims:List[CoreDims],error_context:str='')->Tuple[Tuple[int, ...], Dict[str, int]]
jax._src.numpy.vectorize._update_dim_sizes(dim_sizes:Dict[str,int],shape:Tuple[int,...],core_dims:CoreDims,error_context:str='',*,is_input:bool)
jax._src.numpy.vectorize.vectorize(pyfunc,*,excluded=frozenset(),signature=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/numpy/index_tricks.py----------------------------------------
A:jax._src.numpy.index_tricks.stop->jax.core.concrete_or_error(None, s.stop, f'slice stop of jnp.{op_name}')
A:jax._src.numpy.index_tricks.newobj->transpose(newobj, shape_obj)
A:jax._src.numpy.index_tricks.single_slice->isinstance(key, slice)
A:jax._src.numpy.index_tricks.output->meshgrid(*output, indexing='ij', sparse=self.sparse)
A:jax._src.numpy.index_tricks.mgrid->_Mgrid()
A:jax._src.numpy.index_tricks.ogrid->_Ogrid()
A:jax._src.numpy.index_tricks.vec->directive.split(',')
A:jax._src.numpy.index_tricks.k->len(vec)
A:jax._src.numpy.index_tricks.params->list(map(int, vec))
A:jax._src.numpy.index_tricks.shape_obj->tuple(shape_obj[num_lshifts:] + shape_obj[:num_lshifts])
A:jax._src.numpy.index_tricks.res->expand_dims(res, matrix)
A:jax._src.numpy.index_tricks.r_->RClass()
A:jax._src.numpy.index_tricks.c_->CClass()
jax._src.numpy.index_tricks.CClass(_AxisConcat)
jax._src.numpy.index_tricks.RClass(_AxisConcat)
jax._src.numpy.index_tricks._AxisConcat(abc.ABC)
jax._src.numpy.index_tricks._AxisConcat.__getitem__(self,key)
jax._src.numpy.index_tricks._AxisConcat.__len__(self)
jax._src.numpy.index_tricks._IndexGrid(abc.ABC)
jax._src.numpy.index_tricks._IndexGrid.__getitem__(self,key)
jax._src.numpy.index_tricks._Mgrid(_IndexGrid)
jax._src.numpy.index_tricks._Ogrid(_IndexGrid)
jax._src.numpy.index_tricks._make_1d_grid_from_slice(s:slice,op_name:str)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/third_party/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/third_party/scipy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/third_party/scipy/signal_helper.py----------------------------------------
A:jax._src.third_party.scipy.signal_helper.win->jax._src.numpy.lax_numpy.asarray(window)
A:jax._src.third_party.scipy.signal_helper.ii_2->jax._src.numpy.lax_numpy.arange(2.0, n, 2)
jax._src.third_party.scipy.signal_helper._median_bias(n)
jax._src.third_party.scipy.signal_helper._triage_segments(window,nperseg,input_length)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/third_party/scipy/interpolate.py----------------------------------------
A:jax._src.third_party.scipy.interpolate.p->broadcast_arrays(*points)
A:jax._src.third_party.scipy.interpolate.points->points.reshape(-1, ndim).reshape(-1, ndim)
A:jax._src.third_party.scipy.interpolate.(values,)->_promote_dtypes_inexact(values)
A:jax._src.third_party.scipy.interpolate.fill_value->asarray(fill_value)
A:jax._src.third_party.scipy.interpolate.self.grid->tuple((asarray(p) for p in points))
A:jax._src.third_party.scipy.interpolate.ndim->len(self.grid)
A:jax._src.third_party.scipy.interpolate.xi->xi.reshape(-1, xi_shape[-1]).reshape(-1, xi_shape[-1])
A:jax._src.third_party.scipy.interpolate.(indices, norm_distances, out_of_bounds)->self._find_indices(xi.T)
A:jax._src.third_party.scipy.interpolate.result->where(out_of_bounds.reshape(bc_shp), self.fill_value, result)
A:jax._src.third_party.scipy.interpolate.edges->product(*[[i, i + 1] for i in indices])
A:jax._src.third_party.scipy.interpolate.values->asarray(0.0)
A:jax._src.third_party.scipy.interpolate.weight->asarray(1.0)
A:jax._src.third_party.scipy.interpolate.out_of_bounds->zeros((xi.shape[1],), dtype=bool)
A:jax._src.third_party.scipy.interpolate.i->where(i > g.size - 2, g.size - 2, i)
jax._src.third_party.scipy.interpolate.RegularGridInterpolator(self,points,values,method='linear',bounds_error=False,fill_value=nan)
jax._src.third_party.scipy.interpolate.RegularGridInterpolator.__init__(self,points,values,method='linear',bounds_error=False,fill_value=nan)
jax._src.third_party.scipy.interpolate.RegularGridInterpolator._evaluate_linear(self,indices,norm_distances)
jax._src.third_party.scipy.interpolate.RegularGridInterpolator._evaluate_nearest(self,indices,norm_distances)
jax._src.third_party.scipy.interpolate.RegularGridInterpolator._find_indices(self,xi)
jax._src.third_party.scipy.interpolate._ndim_coords_from_arrays(points,ndim=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/third_party/numpy/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/third_party/numpy/linalg.py----------------------------------------
A:jax._src.third_party.numpy.linalg.s->numpy.empty((n, n), dtype=np.intp)
A:jax._src.third_party.numpy.linalg.invx->jax._src.numpy.linalg.inv(x)
A:jax._src.third_party.numpy.linalg.orig_nan_check->jax._src.numpy.lax_numpy.full_like(r, ~jnp.isnan(r).any())
A:jax._src.third_party.numpy.linalg.nan_mask->jax._src.numpy.lax_numpy.logical_and(jnp.isnan(r), ~jnp.isnan(x).any(axis=(-2, -1)))
A:jax._src.third_party.numpy.linalg.r->jax._src.numpy.lax_numpy.where(orig_nan_check, jnp.where(nan_mask, jnp.inf, r), r)
A:jax._src.third_party.numpy.linalg.a->a.reshape(-1, prod).reshape(-1, prod)
A:jax._src.third_party.numpy.linalg.ia->jax._src.numpy.linalg.inv(a)
A:jax._src.third_party.numpy.linalg.b->b.ravel().ravel()
A:jax._src.third_party.numpy.linalg.allaxes->list(range(0, an))
A:jax._src.third_party.numpy.linalg.res->res.reshape(Q).reshape(Q)
A:jax._src.third_party.numpy.linalg.n->len(arrays)
A:jax._src.third_party.numpy.linalg.arrays[0]->jax._src.numpy.lax_numpy.atleast_2d(arrays[0])
A:jax._src.third_party.numpy.linalg.result->_multi_dot(arrays, order, 0, n - 1, precision)
A:jax._src.third_party.numpy.linalg.order->_multi_dot_matrix_chain_order(arrays)
A:jax._src.third_party.numpy.linalg.m->numpy.zeros((n, n), dtype=np.double)
jax._src.third_party.numpy.linalg._assert2d(*arrays)
jax._src.third_party.numpy.linalg._assertNdSquareness(*arrays)
jax._src.third_party.numpy.linalg._assertNoEmpty2d(*arrays)
jax._src.third_party.numpy.linalg._assertRankAtLeast2(*arrays)
jax._src.third_party.numpy.linalg._isEmpty2d(arr)
jax._src.third_party.numpy.linalg._multi_dot(arrays,order,i,j,precision)
jax._src.third_party.numpy.linalg._multi_dot_matrix_chain_order(arrays,return_costs=False)
jax._src.third_party.numpy.linalg._multi_dot_three(A,B,C,precision)
jax._src.third_party.numpy.linalg.cond(x,p=None)
jax._src.third_party.numpy.linalg.multi_dot(arrays,*,precision=None)
jax._src.third_party.numpy.linalg.tensorinv(a,ind=2)
jax._src.third_party.numpy.linalg.tensorsolve(a,b,axes=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/nn/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/nn/functions.py----------------------------------------
A:jax._src.nn.functions.safe_x->jax.numpy.where(x > 0, 0.0, x)
A:jax._src.nn.functions.sqrt_2_over_pi->numpy.sqrt(2 / np.pi).astype(x.dtype)
A:jax._src.nn.functions.(x1, x2)->jax.numpy.split(x, 2, axis)
A:jax._src.nn.functions.x_max->jax.numpy.max(x, axis, where=where, initial=initial, keepdims=True)
A:jax._src.nn.functions.shifted_logsumexp->jax.numpy.log(jnp.sum(jnp.exp(shifted), axis, where=where, keepdims=True))
A:jax._src.nn.functions.unnormalized->jax.numpy.exp(x - lax.stop_gradient(x_max))
A:jax._src.nn.functions.mean->jax.numpy.mean(x, axis, keepdims=True, where=where)
A:jax._src.nn.functions.num_classes->jax.core.concrete_or_error(int, num_classes, 'The error arose in jax.nn.one_hot argument `num_classes`.')
A:jax._src.nn.functions.dtype->jax._src.dtypes.canonicalize_dtype(dtype)
A:jax._src.nn.functions.x->jax.numpy.asarray(x)
A:jax._src.nn.functions.output_pos_axis->jax._src.util.canonicalize_axis(axis, x.ndim + 1)
A:jax._src.nn.functions.axis_size->jax.lax.psum(1, axis)
A:jax._src.nn.functions.axis_idx->jax.lax.axis_index(axis)
A:jax._src.nn.functions.axis->operator.index(axis)
A:jax._src.nn.functions.lhs->jax.lax.expand_dims(x, (axis,))
A:jax._src.nn.functions.rhs->jax.lax.broadcast_in_dim(jnp.arange(num_classes, dtype=x.dtype), rhs_shape, (output_pos_axis,))
jax._src.nn.functions._one_hot(x:Array,num_classes:int,*,dtype:Any,axis:Union[int,AxisName])->Array
jax._src.nn.functions.celu(x:Array,alpha:Array=1.0)->Array
jax._src.nn.functions.elu(x:Array,alpha:Array=1.0)->Array
jax._src.nn.functions.gelu(x:Array,approximate:bool=True)->Array
jax._src.nn.functions.glu(x:Array,axis:int=-1)->Array
jax._src.nn.functions.hard_sigmoid(x:Array)->Array
jax._src.nn.functions.hard_silu(x:Array)->Array
jax._src.nn.functions.hard_tanh(x:Array)->Array
jax._src.nn.functions.leaky_relu(x:Array,negative_slope:Array=0.01)->Array
jax._src.nn.functions.log_sigmoid(x:Array)->Array
jax._src.nn.functions.log_softmax(x:Array,axis:Optional[Union[int,Tuple[int,...]]]=-1,where:Optional[Array]=None,initial:Optional[Array]=None)->Array
jax._src.nn.functions.normalize(x:Array,axis:Optional[Union[int,Tuple[int,...]]]=-1,mean:Optional[Array]=None,variance:Optional[Array]=None,epsilon:Array=1e-05,where:Optional[Array]=None)->Array
jax._src.nn.functions.one_hot(x:Array,num_classes:int,*,dtype:Any=jnp.float_,axis:Union[int,AxisName]=-1)->Array
jax._src.nn.functions.relu(x:Array)->Array
jax._src.nn.functions.relu6(x:Array)->Array
jax._src.nn.functions.selu(x:Array)->Array
jax._src.nn.functions.sigmoid(x:Array)->Array
jax._src.nn.functions.silu(x:Array)->Array
jax._src.nn.functions.soft_sign(x:Array)->Array
jax._src.nn.functions.softmax(x:Array,axis:Optional[Union[int,Tuple[int,...]]]=-1,where:Optional[Array]=None,initial:Optional[Array]=None)->Array
jax._src.nn.functions.softplus(x:Array)->Array
jax._src.nn.functions.standardize(x:Array,axis:Optional[Union[int,Tuple[int,...]]]=-1,mean:Optional[Array]=None,variance:Optional[Array]=None,epsilon:Array=1e-05,where:Optional[Array]=None)->Array


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/nn/initializers.py----------------------------------------
A:jax._src.nn.initializers.dtype->jax.dtypes.canonicalize_dtype(dtype)
A:jax._src.nn.initializers.in_size->int(np.prod([shape[i] for i in in_axis]))
A:jax._src.nn.initializers.out_size->int(np.prod([shape[i] for i in out_axis]))
A:jax._src.nn.initializers.batch_size->int(np.prod([shape[i] for i in batch_axis]))
A:jax._src.nn.initializers.(key_r, key_theta)->jax.random.split(key)
A:jax._src.nn.initializers.r->jax.numpy.sqrt(-jnp.log(1 - t))
A:jax._src.nn.initializers.shape->jax.core.as_named_shape(shape)
A:jax._src.nn.initializers.(fan_in, fan_out)->_compute_fans(shape, in_axis, out_axis, batch_axis)
A:jax._src.nn.initializers.variance->jax.numpy.array(scale / denominator, dtype=dtype)
A:jax._src.nn.initializers.A->jax.random.normal(key, matrix_shape, dtype)
A:jax._src.nn.initializers.(Q, R)->jax.numpy.linalg.qr(A)
A:jax._src.nn.initializers.diag_sign->jax.lax.broadcast_to_rank(jnp.sign(jnp.diag(R)), rank=Q.ndim)
A:jax._src.nn.initializers.Q->jax.numpy.moveaxis(Q, -1, column_axis)
A:jax._src.nn.initializers.ortho_init->orthogonal(scale=scale, column_axis=column_axis, dtype=dtype)
A:jax._src.nn.initializers.ortho_matrix->ortho_init(key, shape[-2:])
A:jax._src.nn.initializers.W->jax.numpy.zeros(shape, dtype=dtype)
jax._src.nn.initializers._complex_truncated_normal(key,upper,shape,dtype)
jax._src.nn.initializers._complex_uniform(key,shape,dtype)
jax._src.nn.initializers._compute_fans(shape:core.NamedShape,in_axis=-2,out_axis=-1,batch_axis=())
jax._src.nn.initializers.constant(value,dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.delta_orthogonal(scale=1.0,column_axis=-1,dtype:DType=jnp.float_)
jax._src.nn.initializers.glorot_normal(in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.glorot_uniform(in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.he_normal(in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.he_uniform(in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.lecun_normal(in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.lecun_uniform(in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.normal(stddev=0.01,dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.ones(key,shape,dtype:DType=jnp.float_)
jax._src.nn.initializers.orthogonal(scale=1.0,column_axis=-1,dtype:DType=jnp.float_)
jax._src.nn.initializers.uniform(scale=0.01,dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.variance_scaling(scale,mode:str,distribution:str,in_axis:Union[int,Sequence[int]]=-2,out_axis:Union[int,Sequence[int]]=-1,batch_axis:Sequence[int]=(),dtype:DType=jnp.float_)->Callable
jax._src.nn.initializers.zeros(key,shape,dtype:DType=jnp.float_)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/ops/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/ops/scatter.py----------------------------------------
A:jax._src.ops.scatter.x->jax._src.numpy.lax_numpy.asarray(x)
A:jax._src.ops.scatter.y->jax.lax.rev(y, indexer.reversed_y_dims)
A:jax._src.ops.scatter.(treedef, static_idx, dynamic_idx)->jax._src.numpy.lax_numpy._split_index_for_jit(idx, x.shape)
A:jax._src.ops.scatter.dtype->jax.lax.dtype(x)
A:jax._src.ops.scatter.weak_type->jax._src.dtypes.is_weakly_typed(x)
A:jax._src.ops.scatter.idx->jax._src.numpy.lax_numpy._merge_static_and_dynamic_indices(treedef, static_idx, dynamic_idx)
A:jax._src.ops.scatter.indexer->jax._src.numpy.lax_numpy._index_to_gather(jnp.shape(x), idx, normalize_indices=normalize_indices)
A:jax._src.ops.scatter.(x, y)->jax._src.numpy.lax_numpy._promote_dtypes(x, y)
A:jax._src.ops.scatter.dnums->jax.lax.ScatterDimensionNumbers(update_window_dims=indexer.dnums.offset_dims, inserted_window_dims=indexer.dnums.collapsed_slice_dims, scatter_dims_to_operand_dims=indexer.dnums.start_index_map)
A:jax._src.ops.scatter.out->_scatter_update(out, np.index_exp[lax.div(jnp.arange(segment_ids.shape[0]), bucket_size), segment_ids[None, :]], data, scatter_op, indices_are_sorted, unique_indices, normalize_indices=False, mode=mode)
A:jax._src.ops.scatter.data->jax._src.numpy.lax_numpy.asarray(data)
A:jax._src.ops.scatter.segment_ids->jax._src.numpy.lax_numpy.asarray(segment_ids)
A:jax._src.ops.scatter.num_segments->jax.core.concrete_or_error(int, num_segments, 'segment_sum() `num_segments` argument.')
jax._src.ops.scatter._get_identity(op,dtype)
jax._src.ops.scatter._scatter_impl(x,y,scatter_op,treedef,static_idx,dynamic_idx,indices_are_sorted,unique_indices,mode,normalize_indices)
jax._src.ops.scatter._scatter_update(x,idx,y,scatter_op,indices_are_sorted,unique_indices,mode=None,normalize_indices=True)
jax._src.ops.scatter._segment_update(name:str,data:Array,segment_ids:Array,scatter_op:Callable,num_segments:Optional[int]=None,indices_are_sorted:bool=False,unique_indices:bool=False,bucket_size:Optional[int]=None,reducer:Optional[Callable]=None,mode:Optional[lax.GatherScatterMode]=None)->Array
jax._src.ops.scatter.segment_max(data:Array,segment_ids:Array,num_segments:Optional[int]=None,indices_are_sorted:bool=False,unique_indices:bool=False,bucket_size:Optional[int]=None,mode:Optional[lax.GatherScatterMode]=None)->Array
jax._src.ops.scatter.segment_min(data:Array,segment_ids:Array,num_segments:Optional[int]=None,indices_are_sorted:bool=False,unique_indices:bool=False,bucket_size:Optional[int]=None,mode:Optional[lax.GatherScatterMode]=None)->Array
jax._src.ops.scatter.segment_prod(data:Array,segment_ids:Array,num_segments:Optional[int]=None,indices_are_sorted:bool=False,unique_indices:bool=False,bucket_size:Optional[int]=None,mode:Optional[lax.GatherScatterMode]=None)->Array
jax._src.ops.scatter.segment_sum(data:Array,segment_ids:Array,num_segments:Optional[int]=None,indices_are_sorted:bool=False,unique_indices:bool=False,bucket_size:Optional[int]=None,mode:Optional[lax.GatherScatterMode]=None)->Array


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/ann.py----------------------------------------
A:jax._src.lax.ann.dims->list(operand.shape)
A:jax._src.lax.ann.c->jax._src.lib.xla_client.XlaBuilder('top_k_{}_comparator'.format('gt' if is_max_k else 'lt'))
A:jax._src.lax.ann.p0->jax.interpreters.xla.parameter(c, 0, xc.Shape.scalar_shape(op_type))
A:jax._src.lax.ann.p1->jax.interpreters.xla.parameter(c, 1, xc.Shape.scalar_shape(op_type))
A:jax._src.lax.ann.cmp_result->jax._src.lib.xla_client.ops.Lt(p0, p1)
A:jax._src.lax.ann.op_shape->jax._src.lib.xla_client.XlaBuilder('top_k_{}_comparator'.format('gt' if is_max_k else 'lt')).get_shape(operand)
A:jax._src.lax.ann.op_dims->jax._src.lib.xla_client.XlaBuilder('top_k_{}_comparator'.format('gt' if is_max_k else 'lt')).get_shape(operand).dimensions()
A:jax._src.lax.ann.op_type->jax._src.lib.xla_client.XlaBuilder('top_k_{}_comparator'.format('gt' if is_max_k else 'lt')).get_shape(operand).element_type()
A:jax._src.lax.ann.comparator->_comparator_builder(op_type, is_max_k)
A:jax._src.lax.ann.init_val_literal->_get_init_val_literal(op_type, is_max_k)
A:jax._src.lax.ann.iota->jax._src.lib.xla_client.ops.Iota(c, xc.Shape.array_shape(np.dtype(np.int32), op_dims), reduction_dimension)
A:jax._src.lax.ann.init_val->jax._src.lib.xla_client.ops.Constant(c, init_val_literal)
A:jax._src.lax.ann.init_arg->jax._src.lib.xla_client.ops.Constant(c, np.int32(-1))
A:jax._src.lax.ann.out->jax._src.lib.xla_client.ops.ApproxTopKFallback(c, [operand, iota], [init_val, init_arg], k, reduction_dimension, comparator, recall_target, aggregate_to_topk, reduction_input_size_override)
A:jax._src.lax.ann.val_arg->jax._src.lib.xla_client.ops.Sort(c, [operand, iota], comparator, reduction_dimension)
A:jax._src.lax.ann.vals->jax._src.lib.xla_client.ops.GetTupleElement(val_arg, 0)
A:jax._src.lax.ann.args->jax._src.lib.xla_client.ops.GetTupleElement(val_arg, 1)
A:jax._src.lax.ann.sliced_vals->jax._src.lib.xla_client.ops.SliceInDim(vals, 0, avals_out[0].shape[reduction_dimension], 1, reduction_dimension)
A:jax._src.lax.ann.sliced_args->jax._src.lib.xla_client.ops.SliceInDim(args, 0, avals_out[0].shape[reduction_dimension], 1, reduction_dimension)
A:jax._src.lax.ann.(val_out, arg_out)->approx_min_k(operand, k, reduction_dimension, recall_target, reduction_input_size_override, aggregate_to_topk)
A:jax._src.lax.ann.tangent_out->jax._src.ad_util.Zero.from_value(val_out)
A:jax._src.lax.ann.rank->len(arg_shape)
A:jax._src.lax.ann.idx->tuple((arg_out if i == reduction_dimension else iotas[i] for i in range(rank)))
A:jax._src.lax.ann.approx_top_k_p->jax.core.Primitive('approx_top_k')
jax._src.lax.ann._approx_top_k_abstract_eval(operand,*,k,reduction_dimension,recall_target,is_max_k,reduction_input_size_override,aggregate_to_topk)
jax._src.lax.ann._approx_top_k_batch_rule(batch_operands,batch_axes,*,k,reduction_dimension,recall_target,is_max_k,reduction_input_size_override,aggregate_to_topk)
jax._src.lax.ann._approx_top_k_fallback_translation(ctx,avals_in,avals_out,operand,*,k,reduction_dimension,recall_target,is_max_k,reduction_input_size_override,aggregate_to_topk)
jax._src.lax.ann._approx_top_k_jvp(primals,tangents,*,k,reduction_dimension,recall_target,is_max_k,reduction_input_size_override,aggregate_to_topk)
jax._src.lax.ann._approx_top_k_tpu_translation(ctx,avals_in,avals_out,operand,*,k,reduction_dimension,recall_target,is_max_k,reduction_input_size_override,aggregate_to_topk)
jax._src.lax.ann._comparator_builder(op_type,is_max_k)
jax._src.lax.ann._get_init_val_literal(op_type,is_max_k)
jax._src.lax.ann.approx_max_k(operand:Array,k:int,reduction_dimension:int=-1,recall_target:float=0.95,reduction_input_size_override:int=-1,aggregate_to_topk:bool=True)->Tuple[Array, Array]
jax._src.lax.ann.approx_min_k(operand:Array,k:int,reduction_dimension:int=-1,recall_target:float=0.95,reduction_input_size_override:int=-1,aggregate_to_topk:bool=True)->Tuple[Array, Array]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/fft.py----------------------------------------
A:jax._src.lax.fft.dtype->_real_dtype(x.dtype)
A:jax._src.lax.fft.typ->_str_to_fft_type(fft_type)
A:jax._src.lax.fft.x->jax.interpreters.batching.moveaxis(x, bd, 0)
A:jax._src.lax.fft.fft_lengths->tuple(fft_lengths)
A:jax._src.lax.fft.y->fft(x, xla_client.FftType.FFT, fft_lengths)
A:jax._src.lax.fft.dummy_primal->ShapeDtypeStruct(dummy_shape, _real_dtype(t.dtype))
A:jax._src.lax.fft.transpose->linear_transpose(partial(_naive_rfft, fft_lengths=fft_lengths), dummy_primal)
A:jax._src.lax.fft.(result,)->transpose(t)
A:jax._src.lax.fft.full->partial(lax.full_like, t, dtype=t.dtype)
A:jax._src.lax.fft.mask->jax.lax.concatenate([full(1.0, shape=(1,)), full(2.0, shape=(n - 2 + is_odd,)), full(1.0, shape=(1 - is_odd,))], dimension=0)
A:jax._src.lax.fft.result->fft(t, fft_type, fft_lengths)
A:jax._src.lax.fft.fft_p->Primitive('fft')
jax._src.lax.fft._fft_translation_rule(ctx,avals_in,avals_out,x,*,fft_type,fft_lengths)
jax._src.lax.fft._fft_translation_rule_cpu(ctx,avals_in,avals_out,x,*,fft_type,fft_lengths)
jax._src.lax.fft._irfft_transpose(t,fft_lengths)
jax._src.lax.fft._naive_rfft(x,fft_lengths)
jax._src.lax.fft._promote_to_complex(arg)
jax._src.lax.fft._promote_to_real(arg)
jax._src.lax.fft._rfft_transpose(t,fft_lengths)
jax._src.lax.fft._str_to_fft_type(s:str)->xla_client.FftType
jax._src.lax.fft.fft(x,fft_type:Union[xla_client.FftType,str],fft_lengths:Sequence[int])
jax._src.lax.fft.fft_abstract_eval(x,fft_type,fft_lengths)
jax._src.lax.fft.fft_batching_rule(batched_args,batch_dims,fft_type,fft_lengths)
jax._src.lax.fft.fft_impl(x,fft_type,fft_lengths)
jax._src.lax.fft.fft_transpose_rule(t,operand,fft_type,fft_lengths)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/utils.py----------------------------------------
A:jax._src.lax.utils.prim->jax.core.Primitive(name)
A:jax._src.lax.utils.weak_type->weak_type_rule(*avals, **kwargs)
A:jax._src.lax.utils.least_specialized->_max(map(type, avals), key=operator.attrgetter('array_abstraction_level'))
A:jax._src.lax.utils.out->jax.core.Primitive(name).impl(*[x.val for x in avals], **kwargs)
A:jax._src.lax.utils.shape->shape_rule(*avals, **kwargs)
A:jax._src.lax.utils.weak_types->weak_type_rule(*avals, **kwargs)
A:jax._src.lax.utils.out_vals->jax.core.Primitive(name).impl(*[x.val for x in avals], **kwargs)
A:jax._src.lax.utils.out_shapes->shape_rule(*avals, **kwargs)
A:jax._src.lax.utils.out_dtypes->dtype_rule(*avals, **kwargs)
A:jax._src.lax.utils.out_named_shapes->named_shape_rule(*avals, **kwargs)
A:jax._src.lax.utils.xla_opname->''.join((term.capitalize() for term in name.split('_')))
jax._src.lax.utils._argnum_weak_type(*argnums)
jax._src.lax.utils._standard_translate(name,ctx,avals_in,avals_out,*args,**kwargs)
jax._src.lax.utils._standard_weak_type_rule(*avals,**kwargs)
jax._src.lax.utils.standard_abstract_eval(prim,shape_rule,dtype_rule,weak_type_rule,named_shape_rule,*avals,**kwargs)
jax._src.lax.utils.standard_multi_result_abstract_eval(prim,shape_rule,dtype_rule,weak_type_rule,named_shape_rule,*avals,**kwargs)
jax._src.lax.utils.standard_named_shape_rule(*avals,**kwargs)
jax._src.lax.utils.standard_primitive(shape_rule,dtype_rule,name,translation_rule=None,weak_type_rule=None,named_shape_rule=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/convolution.py----------------------------------------
A:jax._src.lax.convolution.dnums->jax._src.lib.mlir.dialects.mhlo.ConvDimensionNumbers.get(input_batch_dimension=lhs_spec[0], input_feature_dimension=lhs_spec[1], input_spatial_dimensions=list(lhs_spec[2:]), kernel_output_feature_dimension=rhs_spec[0], kernel_input_feature_dimension=rhs_spec[1], kernel_spatial_dimensions=list(rhs_spec[2:]), output_batch_dimension=out_spec[0], output_feature_dimension=out_spec[1], output_spatial_dimensions=list(out_spec[2:]))
A:jax._src.lax.convolution.padding->list(map(np.sum, padding))
A:jax._src.lax.convolution.pad_a->int(np.ceil(pad_len / 2))
A:jax._src.lax.convolution.x->numpy.flip(x, axis)
A:jax._src.lax.convolution.ndims->len(lhs.shape)
A:jax._src.lax.convolution.dn->conv_dimension_numbers(lhs.shape, rhs.shape, dimension_numbers)
A:jax._src.lax.convolution.k_shape->numpy.take(rhs.shape, dn.rhs_spec)
A:jax._src.lax.convolution.effective_k_size->map(lambda k, r: (k - 1) * r + 1, k_sdims, rhs_dilation)
A:jax._src.lax.convolution.rhs->_reshape_axis_into(rhs_spec[0], rhs_spec[1], rhs)
A:jax._src.lax.convolution.(quot, rem)->divmod(lhs_feature_count, feature_group_count)
A:jax._src.lax.convolution.lhs_trans->numpy.take(lhs_shape, lhs_perm)
A:jax._src.lax.convolution.rhs_trans->numpy.take(rhs_shape, rhs_perm)
A:jax._src.lax.convolution.out_trans->tuple((lhs_trans[0], rhs_trans[0]) + tuple(out_space))
A:jax._src.lax.convolution.input_dtype->jax._src.lax.lax.naryop_dtype_rule(lax._input_dtype, [lax._any, lax._any], 'conv_general_dilated', lhs, rhs)
A:jax._src.lax.convolution.(lhs_sdims, rhs_sdims, out_sdims)->map(_conv_sdims, dimension_numbers)
A:jax._src.lax.convolution.t_rhs_spec->_conv_spec_transpose(rhs_spec)
A:jax._src.lax.convolution.trans_dimension_numbers->ConvDimensionNumbers(lhs_trans, out_trans, rhs_trans)
A:jax._src.lax.convolution.revd_weights->jax._src.lax.lax.rev(rhs, rhs_sdims)
A:jax._src.lax.convolution.out->_reshape_axis_into(out_spec[1], out_spec[1] + 1, out)
A:jax._src.lax.convolution.(lhs_trans, rhs_trans, out_trans)->map(_conv_spec_transpose, dimension_numbers)
A:jax._src.lax.convolution.dimension_numbers->_conv_general_proto(dimension_numbers)
A:jax._src.lax.convolution.precision_config->jax._src.lax.lax._precision_config(precision)
A:jax._src.lax.convolution.preferred_element_type->_real_dtype(preferred_element_type)
A:jax._src.lax.convolution.k1->mul(lax.add(x_re, x_im), y_re)
A:jax._src.lax.convolution.k2->mul(x_re, lax.sub(y_im, y_re))
A:jax._src.lax.convolution.k3->mul(x_im, lax.add(y_re, y_im))
A:jax._src.lax.convolution.new_lhs->_reshape_axis_into(lhs_spec[0], lhs_spec[0], new_lhs)
A:jax._src.lax.convolution.new_rhs->_reshape_axis_into(rhs_spec[0], rhs_spec[0], new_rhs)
A:jax._src.lax.convolution.conv_general_dilated_p->jax._src.lax.lax.standard_primitive(_conv_general_dilated_shape_rule, _conv_general_dilated_dtype_rule, 'conv_general_dilated', partial(_conv_general_dilated_translation_rule, expand_complex_convolutions=False))
A:jax._src.lax.convolution.complex_conv->jax.interpreters.mlir.lower_fun(partial(_complex_mul, partial(conv_general_dilated, window_strides=window_strides, padding=padding, lhs_dilation=lhs_dilation, rhs_dilation=rhs_dilation, dimension_numbers=dimension_numbers, feature_group_count=feature_group_count, batch_group_count=batch_group_count, precision=precision, preferred_element_type=preferred_element_type)), multiple_results=False)
A:jax._src.lax.convolution.window_reversal->jax.interpreters.mlir.dense_bool_elements([False] * num_spatial_dims)
A:jax._src.lax.convolution.new_shape->list(np.delete(x.shape, src))
A:jax._src.lax.convolution.shape->list(x.shape)
A:jax._src.lax.convolution.(size2, ragged)->divmod(shape[src], size1)
A:jax._src.lax.convolution.pads->jax._src.lax.lax.padtype_to_pads(lhs_shape[2:], rhs_shape[2:], strides, pads)
A:jax._src.lax.convolution.lhs_padded->numpy.add(lhs_shape[2:], np.sum(np.array(pads).reshape(-1, 2), axis=1))
A:jax._src.lax.convolution.out_space->numpy.sum([unpad_out_space, padding], axis=0).tolist()
A:jax._src.lax.convolution.(lhs_perm, rhs_perm, out_perm)->map(getperm, dimension_numbers, charpairs)
A:jax._src.lax.convolution.iota->tuple(range(len(lhs_shape)))
A:jax._src.lax.convolution.(lhs_spec, rhs_spec, out_spec)->conv_general_permutations(dimension_numbers)
A:jax._src.lax.convolution.spatial->sorted(spatial, key=lambda i: rhs_spec.index(spec[i]))
A:jax._src.lax.convolution.proto->jax._src.lib.xla_client.ConvolutionDimensionNumbers()
A:jax._src.lax.convolution.lhs_dilated_shape->jax._src.lax.lax._dilate_shape(in_shape, lhs_dilation)
A:jax._src.lax.convolution.rhs_dilated_shape->jax._src.lax.lax._dilate_shape(window_dimensions, rhs_dilation)
A:jax._src.lax.convolution.out_dilated_shape->jax._src.lax.lax._dilate_shape(out_shape, window_strides)
A:jax._src.lax.convolution.(pads_lo, _)->zip(*padding)
A:jax._src.lax.convolution.pads_from_lhs->jax.core.diff_shape(out_dilated_shape, lhs_dilated_shape)
A:jax._src.lax.convolution.pads_from_rhs->jax.core.diff_shape(core.diff_shape(rhs_dilated_shape, pads_lo), (1,) * len(pads_lo))
A:jax._src.lax.convolution.pads_hi->jax.core.sum_shapes(pads_from_lhs, pads_from_rhs)
jax._src.lax.convolution.ConvDimensionNumbers(NamedTuple)
jax._src.lax.convolution._check_conv_shapes(name,lhs_shape,rhs_shape,window_strides)
jax._src.lax.convolution._complex_mul(mul,x,y)
jax._src.lax.convolution._conv_general_dilated_batch_rule(batched_args,batch_dims,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,batch_group_count,precision,preferred_element_type,**unused_kwargs)
jax._src.lax.convolution._conv_general_dilated_dtype_rule(lhs,rhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,preferred_element_type,**unused_kwargs)
jax._src.lax.convolution._conv_general_dilated_lower(ctx,lhs,rhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,batch_group_count,precision,preferred_element_type,expand_complex_convolutions=False,**unused_kwargs)
jax._src.lax.convolution._conv_general_dilated_masking_rule(padded_vals,logical_shapes,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,batch_group_count,lhs_shape,rhs_shape,precision,preferred_element_type)
jax._src.lax.convolution._conv_general_dilated_shape_rule(lhs:core.ShapedArray,rhs:core.ShapedArray,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,batch_group_count,**unused_kwargs)->Tuple[int, ...]
jax._src.lax.convolution._conv_general_dilated_translation_rule(ctx,avals_in,avals_out,lhs,rhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,batch_group_count,precision,expand_complex_convolutions,preferred_element_type,**unused_kwargs)
jax._src.lax.convolution._conv_general_dilated_transpose_lhs(g,rhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers,feature_group_count,batch_group_count,lhs_shape,rhs_shape,precision,preferred_element_type)
jax._src.lax.convolution._conv_general_dilated_transpose_rhs(g,lhs,*,window_strides,padding,lhs_dilation,rhs_dilation,dimension_numbers:ConvDimensionNumbers,feature_group_count:int,batch_group_count:int,lhs_shape,rhs_shape,precision,preferred_element_type)
jax._src.lax.convolution._conv_general_proto(dimension_numbers)
jax._src.lax.convolution._conv_general_vjp_lhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)->List[Tuple[int, int]]
jax._src.lax.convolution._conv_general_vjp_rhs_padding(in_shape,window_dimensions,window_strides,out_shape,padding,lhs_dilation,rhs_dilation)
jax._src.lax.convolution._conv_transpose_padding(k,s,padding)
jax._src.lax.convolution._flip_axes(x,axes)
jax._src.lax.convolution._reshape_axis_into(src,dst,x)
jax._src.lax.convolution._reshape_axis_out_of(src,size1,x)
jax._src.lax.convolution.conv(lhs:Array,rhs:Array,window_strides:Sequence[int],padding:str,precision:lax.PrecisionLike=None,preferred_element_type:Optional[DType]=None)->Array
jax._src.lax.convolution.conv_dimension_numbers(lhs_shape,rhs_shape,dimension_numbers)->ConvDimensionNumbers
jax._src.lax.convolution.conv_general_dilated(lhs:Array,rhs:Array,window_strides:Sequence[int],padding:Union[str,Sequence[Tuple[int,int]]],lhs_dilation:Optional[Sequence[int]]=None,rhs_dilation:Optional[Sequence[int]]=None,dimension_numbers:ConvGeneralDilatedDimensionNumbers=None,feature_group_count:int=1,batch_group_count:int=1,precision:lax.PrecisionLike=None,preferred_element_type:Optional[DType]=None)->Array
jax._src.lax.convolution.conv_general_permutations(dimension_numbers)
jax._src.lax.convolution.conv_general_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax._src.lax.convolution.conv_shape_tuple(lhs_shape,rhs_shape,strides,pads,batch_group_count=1)
jax._src.lax.convolution.conv_transpose(lhs:Array,rhs:Array,strides:Sequence[int],padding:Union[str,Sequence[Tuple[int,int]]],rhs_dilation:Optional[Sequence[int]]=None,dimension_numbers:ConvGeneralDilatedDimensionNumbers=None,transpose_kernel:bool=False,precision:lax.PrecisionLike=None,preferred_element_type:Optional[DType]=None)->Array
jax._src.lax.convolution.conv_transpose_shape_tuple(lhs_shape,rhs_shape,window_strides,padding,dimension_numbers)
jax._src.lax.convolution.conv_with_general_padding(lhs:Array,rhs:Array,window_strides:Sequence[int],padding:Union[str,Sequence[Tuple[int,int]]],lhs_dilation:Optional[Sequence[int]],rhs_dilation:Optional[Sequence[int]],precision:lax.PrecisionLike=None,preferred_element_type:Optional[DType]=None)->Array


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/polar.py----------------------------------------
A:jax._src.lax.polar.diag_indices->jax.numpy.diag_indices(X.shape[0])
A:jax._src.lax.polar.(unitary, info)->_polar_unitary(a, method, eps, maxiter)
A:jax._src.lax.polar.posdef->_dot(a, unitary.conj().T)
A:jax._src.lax.polar.(u_svd, _, vh_svd)->jax.numpy.linalg.svd(a, full_matrices=False)
A:jax._src.lax.polar.unitary->_dot(u_svd, vh_svd)
A:jax._src.lax.polar.(unitary, j_qr, j_chol, errs)->_qdwh(a, eps, maxiter)
A:jax._src.lax.polar.(matrix, q_factor, l0)->_initialize_qdwh(matrix)
A:jax._src.lax.polar.tol_delta->jax.numpy.cbrt(tol_lk)
A:jax._src.lax.polar.coefs->_qdwh_coefs(lk)
A:jax._src.lax.polar.errs->errs.at[j].set(err).at[j].set(err)
A:jax._src.lax.polar.(matrix, j_qr, coefs, errs)->_qdwh_qr(matrix, coefs, errs, tol_lk, tol_delta, maxiter)
A:jax._src.lax.polar.(matrix, j_chol, errs)->_qdwh_cholesky(matrix, coefs, errs, tol_lk, tol_delta, j_qr, maxiter)
A:jax._src.lax.polar.matrix->_dot(q_factor, matrix)
A:jax._src.lax.polar.(q_factor, r_factor)->jax.numpy.linalg.qr(matrix, mode='reduced')
A:jax._src.lax.polar.alpha->jax.numpy.linalg.norm(r_factor)
A:jax._src.lax.polar.eye->jax.numpy.eye(n_cols, dtype=matrix.dtype)
A:jax._src.lax.polar.r_inv->jax.scipy.linalg.solve_triangular(r_factor, eye, overwrite_b=True)
A:jax._src.lax.polar.one_norm_inv->jax.numpy.linalg.norm(r_inv, ord=1)
A:jax._src.lax.polar.l0->jax.numpy.where(l0 > 1.0, x=1.0, y=l0)
A:jax._src.lax.polar.lk->jax.numpy.where(lk > 1.0, x=1.0, y=lk)
A:jax._src.lax.polar.unconverged->_unconverged(lk, j, maxiter, err, tol_delta, tol_lk)
A:jax._src.lax.polar.csqrt->jax.numpy.sqrt(c)
A:jax._src.lax.polar.matrixI->jax.numpy.vstack((csqrt * matrix, eye))
A:jax._src.lax.polar.(Q, _)->jax.numpy.linalg.qr(matrixI, mode='reduced')
A:jax._src.lax.polar.err->jax.numpy.linalg.norm(new_matrix - matrix).astype(errs[0].dtype)
A:jax._src.lax.polar.j->jax.numpy.zeros(1, dtype=jnp.int32)
A:jax._src.lax.polar.(matrix, j, coefs, errs, _)->jax.lax.while_loop(_do_qr, _qr_work, (matrix, j, coefs, errs, err))
A:jax._src.lax.polar.Z->_add_to_diagonal(Z, 1.0)
A:jax._src.lax.polar.W->jax.scipy.linalg.cholesky(Z)
A:jax._src.lax.polar.B->jax.scipy.linalg.solve_triangular(W.T, matrix.T, lower=True).conj()
A:jax._src.lax.polar.(matrix, j_total, coefs, errs)->jax.lax.while_loop(_do_cholesky, _cholesky_work, carry)
jax._src.lax.polar._add_to_diagonal(X,val)
jax._src.lax.polar._dot(a,b)
jax._src.lax.polar._initialize_qdwh(matrix)
jax._src.lax.polar._polar(a,side,method,eps,maxiter)
jax._src.lax.polar._polar_unitary(a,method,eps,maxiter)
jax._src.lax.polar._qdwh(matrix,eps,maxiter)
jax._src.lax.polar._qdwh_cholesky(matrix,coefs,errs,tol_delta,tol_lk,j0,maxiter)
jax._src.lax.polar._qdwh_coefs(lk)
jax._src.lax.polar._qdwh_qr(matrix,coefs,errs,tol_lk,tol_delta,maxiter)
jax._src.lax.polar._unconverged(lk,j,maxiter,err,tol_delta,tol_lk)
jax._src.lax.polar.polar(a,side='right',method='qdwh',eps=None,maxiter=50)
jax._src.lax.polar.polar_unitary(a,method='qdwh',eps=None,maxiter=50)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/linalg.py----------------------------------------
A:jax._src.lax.linalg.x->jax._src.lib.mlir.dialects.mhlo.BroadcastInDimOp(ir.RankedTensorType.get(out_shape, x_type.element_type), x, bcast_dims(x_type.shape))
A:jax._src.lax.linalg.(v, w)->jax.interpreters.xla.apply_primitive(eigh_p, operand, lower=lower)
A:jax._src.lax.linalg.permutation->list(range(len(shape)))
A:jax._src.lax.linalg.(lu, pivots, permutation)->Primitive('lu').bind(a)
A:jax._src.lax.linalg.(q, r)->Primitive('qr').bind(x, full_matrices=False)
A:jax._src.lax.linalg.result->Primitive('svd').bind(x, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax._src.lax.linalg.b->min(r - k, block_size)
A:jax._src.lax.linalg.out->standard_primitive(triangular_solve_shape_rule, triangular_solve_dtype_rule, 'triangular_solve', translation_rule=_triangular_solve_translation_rule).bind(a, b, left_side=left_side, lower=lower, transpose_a=transpose_a, conjugate_a=conjugate_a, unit_diagonal=unit_diagonal)
A:jax._src.lax.linalg.out_shape->list(lax_internal.broadcast_shapes(tuple(which_type.shape), tuple(x_type.shape), tuple(y_type.shape)))
A:jax._src.lax.linalg.(lu_, _, permutation)->lu(lax.stop_gradient(a))
A:jax._src.lax.linalg.custom_solve->partial(lax.custom_linear_solve, lambda x: _matvec_multiply(a, x), solve=lambda _, x: lu_solve(lu_, permutation, x, trans=0), transpose_solve=lambda _, x: lu_solve(lu_, permutation, x, trans=1))
A:jax._src.lax.linalg.t->f(c, *args, **kwargs)
A:jax._src.lax.linalg.L->jax._src.numpy.lax_numpy.tril(cholesky_p.bind(x))
A:jax._src.lax.linalg.l->jax.lax.pad(jnp.tril(lu[..., :, :k], -1), zero, l_padding)
A:jax._src.lax.linalg.tmp->triangular_solve(L, sigma_dot, left_side=False, transpose_a=True, conjugate_a=True, lower=True)
A:jax._src.lax.linalg.L_dot->jax.lax.batch_matmul(L, phi(triangular_solve(L, tmp, left_side=True, transpose_a=False, lower=True)), precision=lax.Precision.HIGHEST)
A:jax._src.lax.linalg.cholesky_p->standard_unop(_float | _complex, 'cholesky')
A:jax._src.lax.linalg.(result, info)->potrf_impl(operand_aval.dtype, operand, lower=True)
A:jax._src.lax.linalg.ok->xops.Eq(info, xops.Constant(c, np.array(0, np.int32)))
A:jax._src.lax.linalg.dtype->c.get_shape(operand).element_type()
A:jax._src.lax.linalg.vlvr->raise_to_shaped(operand).update(shape=batch_dims + (n, n), dtype=dtype)
A:jax._src.lax.linalg.w->w_real.astype(a.dtype)
A:jax._src.lax.linalg.(w, vl, vr, info)->jax._src.lib.lapack.geev_mhlo(operand_aval.dtype, operand, jobvl=compute_left_eigenvectors, jobvr=compute_right_eigenvectors)
A:jax._src.lax.linalg.vl->_broadcasting_select_mhlo(mhlo.BroadcastInDimOp(ir.RankedTensorType.get(batch_dims + (1, 1), ir.IntegerType.get_signless(1)), ok, mlir.dense_int_elements(range(len(batch_dims)))).result, vl, _nan_like_mhlo(aval))
A:jax._src.lax.linalg.vr->_broadcasting_select_mhlo(mhlo.BroadcastInDimOp(ir.RankedTensorType.get(batch_dims + (1, 1), ir.IntegerType.get_signless(1)), ok, mlir.dense_int_elements(range(len(batch_dims)))).result, vr, _nan_like_mhlo(aval))
A:jax._src.lax.linalg.(l, v)->eig(a, compute_left_eigenvectors=False)
A:jax._src.lax.linalg.eig_p->Primitive('eig')
A:jax._src.lax.linalg.v->jax._src.numpy.lax_numpy.empty(batch_shape + (0, 0), dtype=a.dtype)
A:jax._src.lax.linalg.(v, w, info)->syevd_impl(operand_aval.dtype, operand, lower=lower)
A:jax._src.lax.linalg.zeros->jax.interpreters.mlir.full_like_aval(0, ShapedArray(batch_dims, np.dtype(np.int32)))
A:jax._src.lax.linalg.(v, w_real)->Primitive('eigh').bind(symmetrize(a), lower=lower)
A:jax._src.lax.linalg.eye_n->jax._src.numpy.lax_numpy.eye(a.shape[-1], dtype=a.dtype)
A:jax._src.lax.linalg.dot->partial(lax.dot if g_a.ndim == 2 else lax.batch_matmul, precision=lax.Precision.HIGHEST)
A:jax._src.lax.linalg.vdag_adot_v->dot(dot(_H(v), a_dot), v)
A:jax._src.lax.linalg.dv->dot(v, jnp.multiply(Fmat, vdag_adot_v))
A:jax._src.lax.linalg.dw->jax._src.numpy.lax_numpy.real(jnp.diagonal(vdag_adot_v, axis1=-2, axis2=-1))
A:jax._src.lax.linalg.eigh_p->Primitive('eigh')
A:jax._src.lax.linalg.triangular_solve_dtype_rule->partial(naryop_dtype_rule, _input_dtype, (_float | _complex, _float | _complex), 'triangular_solve')
A:jax._src.lax.linalg.g_a->jax.lax.neg(g_a)
A:jax._src.lax.linalg.cotangent_b->triangular_solve(a, cotangent, left_side, lower, not transpose_a, conjugate_a, unit_diagonal)
A:jax._src.lax.linalg.y->jax._src.lib.mlir.dialects.mhlo.BroadcastInDimOp(ir.RankedTensorType.get(out_shape, y_type.element_type), y, bcast_dims(y_type.shape))
A:jax._src.lax.linalg.y_flat->jax._src.lib.mlir.dialects.mhlo.BroadcastInDimOp(ir.RankedTensorType.get(out_shape, y_type.element_type), y, bcast_dims(y_type.shape)).reshape(y.shape[:-3] + (y.shape[-3] * y.shape[-2], y.shape[-1]))
A:jax._src.lax.linalg.out_flat->triangular_solve(x, y_flat, left_side=left_side, lower=lower, transpose_a=transpose_a, conjugate_a=conjugate_a, unit_diagonal=unit_diagonal)
A:jax._src.lax.linalg.size->max(m, n)
A:jax._src.lax.linalg.a->a.at[k + b:, k + b:].add(-lax.dot(a[k + b:, k:k + b], a[k:k + b, k + b:], precision=lax.Precision.HIGHEST)).at[k + b:, k + b:].add(-lax.dot(a[k + b:, k:k + b], a[k:k + b, k + b:], precision=lax.Precision.HIGHEST))
A:jax._src.lax.linalg.triangular_solve_p->standard_primitive(triangular_solve_shape_rule, triangular_solve_dtype_rule, 'triangular_solve', translation_rule=_triangular_solve_translation_rule)
A:jax._src.lax.linalg.alpha->jax.interpreters.mlir.ir_constant(np.array(1, dtype=a_aval.dtype))
A:jax._src.lax.linalg.batch->prod(a_aval.shape[:-2])
A:jax._src.lax.linalg.iotas->jax._src.numpy.lax_numpy.ix_(*(lax.iota(jnp.int32, b) for b in batch_dims + (1,)))
A:jax._src.lax.linalg.(result, _)->jax.lax.fori_loop(np.array(0, np.int32), np.array(k, np.int32), _lu_pivots_body_fn, (permutation, swaps))
A:jax._src.lax.linalg.pivots->raise_to_shaped(pivots)
A:jax._src.lax.linalg.permutations->raise_to_shaped(pivots).update(shape=batch_dims + (permutation_size,))
A:jax._src.lax.linalg.lu_pivots_to_permutation_p->Primitive('lu_pivots_to_permutation')
A:jax._src.lax.linalg.m_idx->jax._src.numpy.lax_numpy.arange(m)
A:jax._src.lax.linalg.n_idx->jax._src.numpy.lax_numpy.arange(n)
A:jax._src.lax.linalg.magnitude->jax._src.numpy.lax_numpy.abs(a[:, k])
A:jax._src.lax.linalg.i->jax._src.numpy.lax_numpy.argmax(jnp.where(m_idx >= k, magnitude, -jnp.inf))
A:jax._src.lax.linalg.pivot->xops.Sub(pivot, xops.Constant(c, np.array(1, np.int32)))
A:jax._src.lax.linalg.perm->jax.interpreters.xla.lower_fun(lambda x: lu_pivots_to_permutation(x, m), multiple_results=False, backend=ctx.platform)(c, pivot)
A:jax._src.lax.linalg.r->_broadcasting_select_mhlo(ok, r, _nan_like_mhlo(r_aval))
A:jax._src.lax.linalg.(block_pivot, block_perm, lu_block)->_lu_unblocked(a[k:, k:k + b])
A:jax._src.lax.linalg.batch_size->numpy.prod(batch_dims, dtype=np.int64)
A:jax._src.lax.linalg.(lu, pivot, perm)->jax.interpreters.xla.apply_primitive(lu_p, operand)
A:jax._src.lax.linalg.lu->_broadcasting_select_mhlo(mhlo.BroadcastInDimOp(ir.RankedTensorType.get(batch_dims + (1, 1), ir.IntegerType.get_signless(1)), ok, mlir.dense_int_elements(range(len(batch_dims)))).result, lu, _nan_like_mhlo(out_aval))
A:jax._src.lax.linalg.operand->raise_to_shaped(operand)
A:jax._src.lax.linalg.a_shape->jax._src.numpy.lax_numpy.shape(a)
A:jax._src.lax.linalg.k->min(m, n)
A:jax._src.lax.linalg.ndims->len(a_shape)
A:jax._src.lax.linalg.zero->jax._src.lax.lax._const(lu, 0)
A:jax._src.lax.linalg.u_eye->jax.lax.pad(jnp.eye(n - k, n - k, dtype=dtype), zero, ((k, 0, 0), (k, 0, 0)))
A:jax._src.lax.linalg.la->triangular_solve(l, x, left_side=True, transpose_a=False, lower=True, unit_diagonal=True)
A:jax._src.lax.linalg.lau->triangular_solve(u, la, left_side=False, transpose_a=False, lower=False)
A:jax._src.lax.linalg.l_dot->jax._src.numpy.lax_numpy.matmul(l, jnp.tril(lau, -1))
A:jax._src.lax.linalg.u_dot->jax._src.numpy.lax_numpy.matmul(jnp.triu(lau), u)
A:jax._src.lax.linalg.(lu, pivot, info)->getrf_impl(operand_aval.dtype, operand)
A:jax._src.lax.linalg.sub_ctx->jax.interpreters.mlir.LoweringRuleContext(module_context=ctx.module_context, primitive=None, avals_in=[r_aval], avals_out=[r_aval])
A:jax._src.lax.linalg.perm_fn->jax.interpreters.mlir.lower_fun(lambda x: lu_pivots_to_permutation(x, m), multiple_results=False)
A:jax._src.lax.linalg.(perm,)->perm_fn(sub_ctx, pivot)
A:jax._src.lax.linalg.lu_p->Primitive('lu')
A:jax._src.lax.linalg.q->_broadcasting_select_mhlo(ok, q, _nan_like_mhlo(q_aval))
A:jax._src.lax.linalg.dx_rinv->triangular_solve(r, dx)
A:jax._src.lax.linalg.qt_dx_rinv->jax._src.numpy.lax_numpy.matmul(_H(q), dx_rinv)
A:jax._src.lax.linalg.qt_dx_rinv_lower->jax._src.numpy.lax_numpy.tril(qt_dx_rinv, -1)
A:jax._src.lax.linalg.I->jax.lax.expand_dims(jnp.eye(n, dtype=A.dtype), range(V.ndim - 2))
A:jax._src.lax.linalg.dr->jax._src.numpy.lax_numpy.matmul(qt_dx_rinv - do, r)
A:jax._src.lax.linalg.(r, tau, info_geqrf)->geqrf_impl(operand_aval.dtype, operand)
A:jax._src.lax.linalg.(q, info_orgqr)->orgqr_impl(operand_aval.dtype, q, tau)
A:jax._src.lax.linalg.(r,)->jax.interpreters.mlir.lower_fun(jnp.triu, multiple_results=False)(sub_ctx, r)
A:jax._src.lax.linalg.qr_p->Primitive('qr')
A:jax._src.lax.linalg.(u, s, v)->xops.SVD(operand)
A:jax._src.lax.linalg.vt->_broadcasting_select_mhlo(mhlo.BroadcastInDimOp(ir.RankedTensorType.get(batch_dims + (1, 1), ir.IntegerType.get_signless(1)), ok, mlir.dense_int_elements(range(len(batch_dims)))).result, vt, _nan_like_mhlo(vt_aval))
A:jax._src.lax.linalg.u->_broadcasting_select_mhlo(mhlo.BroadcastInDimOp(ir.RankedTensorType.get(batch_dims + (1, 1), ir.IntegerType.get_signless(1)), ok, mlir.dense_int_elements(range(len(batch_dims)))).result, u, _nan_like_mhlo(u_aval))
A:jax._src.lax.linalg.s->_broadcasting_select_mhlo(mhlo.BroadcastInDimOp(ir.RankedTensorType.get(batch_dims + (1,), ir.IntegerType.get_signless(1)), ok, mlir.dense_int_elements(range(len(batch_dims)))).result, s, _nan_like_mhlo(s_aval))
A:jax._src.lax.linalg.(s, U, Vt)->Primitive('svd').bind(A, full_matrices=False, compute_uv=True)
A:jax._src.lax.linalg.dS->jax._src.numpy.lax_numpy.matmul(jnp.matmul(Ut, dA), V)
A:jax._src.lax.linalg.ds->jax._src.numpy.lax_numpy.real(jnp.diagonal(dS, 0, -2, -1))
A:jax._src.lax.linalg.s_diffs_zeros->jax.lax.expand_dims(s_diffs_zeros, range(s_diffs.ndim - 2))
A:jax._src.lax.linalg.s_inv_mat->jax._src.numpy.lax_numpy.vectorize(jnp.diag, signature='(k)->(k,k)')(s_inv)
A:jax._src.lax.linalg.dU->jax._src.numpy.lax_numpy.matmul(U, F * (dSS + _H(dSS)) + dUdV_diag)
A:jax._src.lax.linalg.dV->jax._src.numpy.lax_numpy.matmul(V, F * (SdS + _H(SdS)))
A:jax._src.lax.linalg.(s, u, vt, info)->gesvd_impl(operand_aval.dtype, operand, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax._src.lax.linalg.outs->Primitive('svd').bind(x, full_matrices=full_matrices, compute_uv=compute_uv)
A:jax._src.lax.linalg.svd_p->Primitive('svd')
A:jax._src.lax.linalg.tridiagonal_solve_p->Primitive('tridiagonal_solve')
A:jax._src.lax.linalg.(_, tu_)->jax.lax.scan(lambda tu_, x: double(fwd1, (tu_, x)), du[0] / d[0], (d, du, dl), unroll=32)
A:jax._src.lax.linalg.(_, b_)->jax.lax.scan(lambda b_, x: double(fwd2, (b_, x)), b[0] / d[0], (b, d, prepend_zero(tu_), dl), unroll=32)
A:jax._src.lax.linalg.(_, x_)->jax.lax.scan(lambda x_, x: double(bwd1, (x_, x)), b_[-1], (b_[::-1], tu_[::-1]), unroll=32)
A:jax._src.lax.linalg.T->_broadcasting_select(c, xops.Reshape(ok, batch_dims + (1, 1)), T, _nan_like(c, T))
A:jax._src.lax.linalg.vs->_broadcasting_select(c, xops.Reshape(ok, batch_dims + (1, 1)), vs, _nan_like(c, vs))
A:jax._src.lax.linalg.(T, vs, sdim, info)->_cpu_gees(c, operand, jobvs=compute_schur_vectors, sort=sort_eig_vals, select=select_callable)
A:jax._src.lax.linalg.(T, vs, info)->_cpu_gees(c, operand, jobvs=compute_schur_vectors, sort=sort_eig_vals, select=select_callable)
A:jax._src.lax.linalg.schur_p->Primitive('schur')
A:jax._src.lax.linalg.shape->c.get_shape(operand)
A:jax._src.lax.linalg.nan->xops.Constant(c, np.array(np.nan, dtype=dtype))
A:jax._src.lax.linalg.which->jax._src.lib.mlir.dialects.mhlo.BroadcastInDimOp(ir.RankedTensorType.get(out_shape, which_type.element_type), which, bcast_dims(which_type.shape))
jax._src.lax.linalg._H(x)
jax._src.lax.linalg._T(x)
jax._src.lax.linalg._broadcasting_select(c,which,x,y)
jax._src.lax.linalg._broadcasting_select_mhlo(which,x,y)
jax._src.lax.linalg._check_solve_shapes(a,b)
jax._src.lax.linalg._cholesky_cpu_gpu_lowering(potrf_impl,ctx,operand)
jax._src.lax.linalg._cholesky_cpu_gpu_translation_rule(potrf_impl,ctx,avals_in,avals_out,operand)
jax._src.lax.linalg._eig_cpu_lowering(ctx,operand,*,compute_left_eigenvectors,compute_right_eigenvectors)
jax._src.lax.linalg._eig_cpu_translation_rule(ctx,avals_in,avals_out,operand,*,compute_left_eigenvectors,compute_right_eigenvectors)
jax._src.lax.linalg._eigh_cpu_gpu_lowering(syevd_impl,ctx,operand,*,lower)
jax._src.lax.linalg._eigh_cpu_gpu_translation_rule(syevd_impl,ctx,avals_in,avals_out,operand,*,lower)
jax._src.lax.linalg._eigh_translation_rule(ctx,avals_in,avals_out,operand,*,lower)
jax._src.lax.linalg._empty_svd(a,*,full_matrices,compute_uv)
jax._src.lax.linalg._generic_lu_pivots_to_permutation(swaps,permutation_size)
jax._src.lax.linalg._lu_abstract_eval(operand)
jax._src.lax.linalg._lu_batching_rule(batched_args,batch_dims)
jax._src.lax.linalg._lu_blocked(a,block_size=128)
jax._src.lax.linalg._lu_cpu_gpu_lowering(getrf_impl,ctx,operand)
jax._src.lax.linalg._lu_cpu_gpu_translation_rule(getrf_impl,ctx,avals_in,avals_out,operand)
jax._src.lax.linalg._lu_impl(operand)
jax._src.lax.linalg._lu_jvp_rule(primals,tangents)
jax._src.lax.linalg._lu_pivots_body_fn(i,permutation_and_swaps)
jax._src.lax.linalg._lu_pivots_to_permutation_abstract_eval(pivots,*,permutation_size)
jax._src.lax.linalg._lu_pivots_to_permutation_batching_rule(batched_args,batch_dims,*,permutation_size)
jax._src.lax.linalg._lu_pivots_to_permutation_gpu(ctx,avals_in,avals_out,pivots,*,permutation_size)
jax._src.lax.linalg._lu_pivots_to_permutation_gpu_lowering(ctx,pivots,*,permutation_size)
jax._src.lax.linalg._lu_python(x)
jax._src.lax.linalg._lu_solve(lu,permutation,b,trans)
jax._src.lax.linalg._lu_solve_core(lu,permutation,b,trans)
jax._src.lax.linalg._lu_tpu_translation_rule(ctx,avals_in,avals_out,operand)
jax._src.lax.linalg._lu_unblocked(a)
jax._src.lax.linalg._matvec_multiply(a,b)
jax._src.lax.linalg._nan_like(c,operand)
jax._src.lax.linalg._nan_like_mhlo(aval)
jax._src.lax.linalg._qr_cpu_gpu_lowering(geqrf_impl,orgqr_impl,ctx,operand,*,full_matrices)
jax._src.lax.linalg._qr_cpu_gpu_translation_rule(geqrf_impl,orgqr_impl,ctx,avals_in,avals_out,operand,*,full_matrices)
jax._src.lax.linalg._qr_translation_rule(ctx,avals_in,avals_out,operand,*,full_matrices)
jax._src.lax.linalg._schur_abstract_eval(operand,*,compute_schur_vectors,sort_eig_vals,select_callable)
jax._src.lax.linalg._schur_batching_rule(batched_args,batch_dims,*,compute_schur_vectors,sort_eig_vals,select_callable)
jax._src.lax.linalg._schur_cpu_translation_rule(ctx,avals_in,avals_out,operand,*,compute_schur_vectors,sort_eig_vals,select_callable)
jax._src.lax.linalg._schur_impl(operand,*,compute_schur_vectors,sort_eig_vals,select_callable)
jax._src.lax.linalg._schur_jvp_rule(primals,tangents,*,compute_schur_vectors,sort_eig_vals)
jax._src.lax.linalg._schur_translation_rule(ctx,avals_in,avals_out,operand,*,compute_schur_vectors,sort_eig_vals)
jax._src.lax.linalg._solve(a,b)
jax._src.lax.linalg._svd_cpu_gpu_lowering(gesvd_impl,ctx,operand,*,full_matrices,compute_uv)
jax._src.lax.linalg._svd_cpu_gpu_translation_rule(gesvd_impl,ctx,avals_in,avals_out,operand,*,full_matrices,compute_uv)
jax._src.lax.linalg._svd_translation_rule(ctx,avals_in,avals_out,operand,*,full_matrices,compute_uv)
jax._src.lax.linalg._triangular_solve_cpu_lower(ctx,a,b,*,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg._triangular_solve_cpu_translation_rule(ctx,avals_in,avals_out,a,b,*,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg._triangular_solve_gpu_lower(trsm_impl,ctx,a,b,*,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg._triangular_solve_gpu_translation_rule(trsm_impl,ctx,avals_in,avals_out,a,b,*,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg._triangular_solve_translation_rule(ctx,avals_in,avals_out,a,b,*,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg._tridiagonal_solve_gpu_lowering(ctx,dl,d,du,b,*,m,n,ldb,t)
jax._src.lax.linalg._tridiagonal_solve_gpu_translation_rule(ctx,avals_in,avals_out,dl,d,du,b,*,m,n,ldb,t)
jax._src.lax.linalg._tridiagonal_solve_jax(dl,d,du,b,**kw)
jax._src.lax.linalg._unpack_tuple(f,n)
jax._src.lax.linalg.cholesky(x,symmetrize_input:bool=True)
jax._src.lax.linalg.cholesky_batching_rule(batched_args,batch_dims)
jax._src.lax.linalg.cholesky_jvp_rule(primals,tangents)
jax._src.lax.linalg.eig(x,compute_left_eigenvectors=True,compute_right_eigenvectors=True)
jax._src.lax.linalg.eig_abstract_eval(operand,*,compute_left_eigenvectors,compute_right_eigenvectors)
jax._src.lax.linalg.eig_batching_rule(batched_args,batch_dims,*,compute_left_eigenvectors,compute_right_eigenvectors)
jax._src.lax.linalg.eig_impl(operand,*,compute_left_eigenvectors,compute_right_eigenvectors)
jax._src.lax.linalg.eig_jvp_rule(primals,tangents,*,compute_left_eigenvectors,compute_right_eigenvectors)
jax._src.lax.linalg.eig_lower(*args,**kw)
jax._src.lax.linalg.eigh(x,lower:bool=True,symmetrize_input:bool=True)
jax._src.lax.linalg.eigh_abstract_eval(operand,lower)
jax._src.lax.linalg.eigh_batching_rule(batched_args,batch_dims,lower)
jax._src.lax.linalg.eigh_impl(operand,lower)
jax._src.lax.linalg.eigh_jvp_rule(primals,tangents,lower)
jax._src.lax.linalg.lu(x)
jax._src.lax.linalg.lu_pivots_to_permutation(pivots,permutation_size:int)
jax._src.lax.linalg.lu_solve(lu,permutation,b,trans=0)
jax._src.lax.linalg.qr(x,full_matrices:bool=True)
jax._src.lax.linalg.qr_abstract_eval(operand,full_matrices)
jax._src.lax.linalg.qr_batching_rule(batched_args,batch_dims,full_matrices)
jax._src.lax.linalg.qr_impl(operand,full_matrices)
jax._src.lax.linalg.qr_jvp_rule(primals,tangents,full_matrices)
jax._src.lax.linalg.schur(x,compute_schur_vectors=True,sort_eig_vals=False,select_callable=None)
jax._src.lax.linalg.svd(x,full_matrices=True,compute_uv=True)
jax._src.lax.linalg.svd_abstract_eval(operand,full_matrices,compute_uv)
jax._src.lax.linalg.svd_batching_rule(batched_args,batch_dims,full_matrices,compute_uv)
jax._src.lax.linalg.svd_impl(operand,full_matrices,compute_uv)
jax._src.lax.linalg.svd_jvp_rule(primals,tangents,full_matrices,compute_uv)
jax._src.lax.linalg.symmetrize(x)
jax._src.lax.linalg.triangular_solve(a,b,left_side:bool=False,lower:bool=False,transpose_a:bool=False,conjugate_a:bool=False,unit_diagonal:bool=False)
jax._src.lax.linalg.triangular_solve_batching_rule(batched_args,batch_dims,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg.triangular_solve_jvp_rule_a(g_a,ans,a,b,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg.triangular_solve_shape_rule(a,b,left_side=False,**unused_kwargs)
jax._src.lax.linalg.triangular_solve_transpose_rule(cotangent,a,b,left_side,lower,transpose_a,conjugate_a,unit_diagonal)
jax._src.lax.linalg.tridiagonal_solve(dl,d,du,b)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/parallel.py----------------------------------------
A:jax._src.lax.parallel.(leaves, treedef)->jax.tree_util.tree_flatten(x)
A:jax._src.lax.parallel.axis_index_groups->_canonicalize_axis_index_groups(axis_index_groups)
A:jax._src.lax.parallel.out_flat->jax.core.AxisPrimitive('pmin').bind(*leaves, axes=axis_name, axis_index_groups=axis_index_groups)
A:jax._src.lax.parallel.x->xops.Reshape(x, new_shape)
A:jax._src.lax.parallel.n->psum(1, axis_name=axis_name, axis_index_groups=axis_index_groups)
A:jax._src.lax.parallel.idx->jax._src.lax.lax.expand_dims(idx, (-1,))
A:jax._src.lax.parallel.validx->jax._src.numpy.lax_numpy.where(val == x, idx, dtypes.iinfo(dtypes.dtype(idx)).max)
A:jax._src.lax.parallel.axis_space->range(sum((len(group) for group in axis_index_groups)))
A:jax._src.lax.parallel.group_size->len(replica_groups[0])
A:jax._src.lax.parallel.result->jax.core.AxisPrimitive('pgather').bind(src_last_batched, idx, axes=axes)
A:jax._src.lax.parallel.pos_contract->unzip2(((lhs_subs.index(n), rhs_subs.index(n)) for n in subs_contract - (lhs_uniques | rhs_uniques)))
A:jax._src.lax.parallel.pos_batch->unzip2(((lhs_subs.index(n), rhs_subs.index(n)) for n in subs_batch))
A:jax._src.lax.parallel.(in_spec, out_spec)->spec.split('->')
A:jax._src.lax.parallel.((lhs_subs, lhs_named), (rhs_subs, rhs_named))->XeinsumSpecParser(in_spec).parse_args()
A:jax._src.lax.parallel.((out_subs, out_named),)->XeinsumSpecParser(out_spec).parse_args()
A:jax._src.lax.parallel.named_contract->list(all_named - set(out_named))
A:jax._src.lax.parallel.y->_foldaxis(all_gather_dimension, y)
A:jax._src.lax.parallel.end->self.spec.index(',', self.pos, end)
A:jax._src.lax.parallel.(subscript, cont)->self.parse_subscript()
A:jax._src.lax.parallel.axis_name->self.parse_axis_name()
A:jax._src.lax.parallel.(cont, result)->self.parse_arg()
A:jax._src.lax.parallel.result[pname]->sum(((name,) if isinstance(name, int) else subst(name) for name in axis_name), ())
A:jax._src.lax.parallel.(unmapped_axes, unmapped_vals_in)->transform_unmapped(0, unmapped_vals_in)
A:jax._src.lax.parallel.unmapped_vals_out->prim.bind(*unmapped_vals_in, axes=unmapped_axes, axis_index_groups=None)
A:jax._src.lax.parallel.(mapped_axes, mapped_vals_in)->transform_mapped(0, mapped_vals_in)
A:jax._src.lax.parallel.mapped_vals_out->prim.bind(*mapped_vals_in, axes=mapped_axes, axis_index_groups=None)
A:jax._src.lax.parallel.vals_out->_reduction_with_positional_batcher(prim, vals_in, dims_in, axis_index_groups, lambda d, d_vals_in: (tuple((axis for axis in axes if axis != frame_name)), [if_unmapped(v, axis_size) for v in d_vals_in]), lambda d, d_vals_in: (tuple((axis + (axis >= d) if isinstance(axis, int) else axis if axis != frame_name else d for axis in axes)), d_vals_in))
A:jax._src.lax.parallel.replica_groups->_replica_groups(ctx.module_context.axis_env, axis_name, axis_index_groups)
A:jax._src.lax.parallel.pos_axes->tuple((axis for axis in axes if isinstance(axis, int)))
A:jax._src.lax.parallel.named_axes->set((axis for axis in axes if not isinstance(axis, int)))
A:jax._src.lax.parallel.len_0->len(axis_index_groups[0])
A:jax._src.lax.parallel.reducer->jax.interpreters.mlir.lower_fun(pos_fn, multiple_results=False)
A:jax._src.lax.parallel.args->map(_positional_reduce, ctx.avals_in, args)
A:jax._src.lax.parallel.replica_groups_protos->jax._src.lib.xla_client.make_replica_groups(replica_groups)
A:jax._src.lax.parallel.scalar->ShapedArray((), c.get_shape(x).numpy_dtype())
A:jax._src.lax.parallel.computation->jax.interpreters.xla.primitive_subcomputation(ctx.platform, ctx.axis_env, prim, scalar, scalar)
A:jax._src.lax.parallel.aval_out->aval.update(shape=np.delete(np.array(aval.shape, dtype=np.int64), positional_axes))
A:jax._src.lax.parallel.reducer_ctx->jax.interpreters.mlir.LoweringRuleContext(module_context=ctx.module_context, primitive=None, avals_in=[scalar_aval] * 2, avals_out=[scalar_aval])
A:jax._src.lax.parallel.op->jax._src.lib.mlir.dialects.mhlo.ReduceScatterOp(mlir.aval_to_ir_type(x_aval.update(shape=scatter_out_shape)), x, scatter_dimension=mlir.i64_attr(scatter_dimension), replica_groups=_replica_groups_mhlo(replica_groups), channel_handle=None)
A:jax._src.lax.parallel.scalar_aval->jax.core.raise_to_shaped(x).update(shape=())
A:jax._src.lax.parallel.scalar_type->jax.interpreters.mlir.aval_to_ir_type(scalar_aval)
A:jax._src.lax.parallel.reducer_block->jax._src.lib.mlir.dialects.mhlo.ReduceScatterOp(mlir.aval_to_ir_type(x_aval.update(shape=scatter_out_shape)), x, scatter_dimension=mlir.i64_attr(scatter_dimension), replica_groups=_replica_groups_mhlo(replica_groups), channel_handle=None).regions[0].blocks.append(scalar_type, scalar_type)
A:jax._src.lax.parallel.lower_reducer->jax.interpreters.mlir.lower_fun(prim.bind, multiple_results=False)
A:jax._src.lax.parallel.out_nodes->lower_reducer(reducer_ctx, *([a] for a in reducer_block.arguments))
A:jax._src.lax.parallel.cts->map(broadcast_positional, cts, args)
A:jax._src.lax.parallel.(nonzero_out_cts, treedef)->jax.tree_util.tree_flatten(cts)
A:jax._src.lax.parallel.nonzero_in_cts->jax.core.AxisPrimitive('psum').bind(*nonzero_out_cts, axes=tuple(named_axes), axis_index_groups=axis_index_groups)
A:jax._src.lax.parallel.psum_p->jax.core.AxisPrimitive('psum')
A:jax._src.lax.parallel.batching.primitive_batchers[psum_p]->partial(_reduction_batcher, psum_p)
A:jax._src.lax.parallel.batching.axis_primitive_batchers[psum_p]->partial(_batched_reduction_collective, psum_p, lambda v, axis_size: axis_size * v)
A:jax._src.lax.parallel.core.axis_substitution_rules[psum_p]->partial(_subst_all_names_in_param, 'axes')
A:jax._src.lax.parallel.size->prod([core.axis_frame(name).size for name in named_axes])
A:jax._src.lax.parallel.pmax_p->jax.core.AxisPrimitive('pmax')
A:jax._src.lax.parallel.batching.primitive_batchers[pmax_p]->partial(_reduction_batcher, pmax_p)
A:jax._src.lax.parallel.batching.axis_primitive_batchers[pmax_p]->partial(_batched_reduction_collective, pmax_p, lambda v, axis_size: v)
A:jax._src.lax.parallel.core.axis_substitution_rules[pmax_p]->partial(_subst_all_names_in_param, 'axes')
A:jax._src.lax.parallel.pmin_p->jax.core.AxisPrimitive('pmin')
A:jax._src.lax.parallel.batching.primitive_batchers[pmin_p]->partial(_reduction_batcher, pmin_p)
A:jax._src.lax.parallel.batching.axis_primitive_batchers[pmin_p]->partial(_batched_reduction_collective, pmin_p, lambda v, axis_size: v)
A:jax._src.lax.parallel.core.axis_substitution_rules[pmin_p]->partial(_subst_all_names_in_param, 'axes')
A:jax._src.lax.parallel.(srcs, dsts)->unzip2(perm)
A:jax._src.lax.parallel.grp->list(sorted(grp))
A:jax._src.lax.parallel.full_perm->full_perm.reshape((-1, 2)).reshape((-1, 2))
A:jax._src.lax.parallel.inverse_perm->list(zip(dsts, srcs))
A:jax._src.lax.parallel.remaining_axes->tuple((axis for axis in axis_name if axis != frame_name))
A:jax._src.lax.parallel.perm_indices->numpy.zeros(axis_size, dtype=int)
A:jax._src.lax.parallel.ppermute_p->jax.core.AxisPrimitive('ppermute')
A:jax._src.lax.parallel.batching.primitive_batchers[ppermute_p]->partial(_collective_batcher, ppermute_p)
A:jax._src.lax.parallel.core.axis_substitution_rules[ppermute_p]->partial(_subst_all_names_in_param, 'axis_name')
A:jax._src.lax.parallel.new_shape->list(x_aval.shape)
A:jax._src.lax.parallel.cur_device_id->axis_index(axis_name)
A:jax._src.lax.parallel.flat_groups->numpy.array(axis_index_groups).flatten()
A:jax._src.lax.parallel.full->all_gather(x, axis_name, axis_index_groups=axis_index_groups)
A:jax._src.lax.parallel.sliced->jax._src.lax.slicing.dynamic_slice_in_dim(full, tile_base_idx, tile_size, split_axis + 1)
A:jax._src.lax.parallel.split_count->len(replica_groups[0])
A:jax._src.lax.parallel.lowering->jax.interpreters.mlir.lower_fun(_all_gather_via_psum, multiple_results=False)
A:jax._src.lax.parallel.pos->self.parse_axis_name().index(frame_name)
A:jax._src.lax.parallel.x_concat->_foldaxis(concat_axis, _moveaxis(d, concat_axis, x))
A:jax._src.lax.parallel.input_aval->raise_to_shaped(x)
A:jax._src.lax.parallel.shape->list(src.shape)
A:jax._src.lax.parallel.all_to_all_p->jax.core.AxisPrimitive('all_to_all')
A:jax._src.lax.parallel.core.axis_substitution_rules[all_to_all_p]->partial(_subst_all_names_in_param, 'axis_name')
A:jax._src.lax.parallel.axis_size->psum(1, axis_name, axis_index_groups=axis_index_groups)
A:jax._src.lax.parallel.bind->partial(reduce_scatter_p.bind, axis_name=axis_name, scatter_dimension=scatter_dimension, axis_index_groups=axis_index_groups, axis_size=axis_size, tiled=tiled)
A:jax._src.lax.parallel.out->jax.core.AxisPrimitive('pdot').bind(x, y, axis_name=axis_name, pos_contract=pos_contract, pos_batch=pos_batch, precision=precision)
A:jax._src.lax.parallel.index->_index_in_group(axis_name, axis_index_groups)
A:jax._src.lax.parallel.outs->jax._src.lax.lax.squeeze(outs, [scatter_dimension])
A:jax._src.lax.parallel.sums->psum(outs, axis_name, axis_index_groups=axis_index_groups)
A:jax._src.lax.parallel.x_aval->jax.core.raise_to_shaped(x)
A:jax._src.lax.parallel.out_shape->list(np.shape(x))
A:jax._src.lax.parallel.all_gather_p->jax.core.AxisPrimitive('all_gather')
A:jax._src.lax.parallel.core.axis_substitution_rules[all_gather_p]->partial(_subst_all_names_in_param, 'axis_name')
A:jax._src.lax.parallel.scatter_out_shape->list(x_aval.shape)
A:jax._src.lax.parallel.reduce_scatter_p->jax.core.AxisPrimitive('reduce_scatter')
A:jax._src.lax.parallel.axis_pos->list(axis_env.names).index(axis_name)
A:jax._src.lax.parallel.div->jax.interpreters.mlir.ir_constant(np.array(nreplicas * prod(axis_env.sizes[axis_pos + 1:]), dtype=np.uint32))
A:jax._src.lax.parallel.mod->jax.interpreters.mlir.ir_constant(np.array(axis_env.sizes[axis_pos], dtype=np.uint32))
A:jax._src.lax.parallel.unsigned_index->jax._src.lib.mlir.dialects.mhlo.RemOp(mhlo.DivOp(mhlo.ReplicaIdOp(), div), mod)
A:jax._src.lax.parallel.frame->jax.core.axis_frame(name)
A:jax._src.lax.parallel.axis_index_p->jax.core.Primitive('axis_index')
A:jax._src.lax.parallel.core.axis_substitution_rules[axis_index_p]->partial(_subst_all_names_in_param, 'axis_name')
A:jax._src.lax.parallel.trace->jax.core.axis_frame(name).main_trace.with_cur_sublevel()
A:jax._src.lax.parallel.pdot_p->jax.core.AxisPrimitive('pdot')
A:jax._src.lax.parallel.core.axis_substitution_rules[pdot_p]->partial(_subst_all_names_in_param, 'axis_name')
A:jax._src.lax.parallel.common_named_shape->jax.core.join_named_shapes(x.named_shape, y.named_shape)
A:jax._src.lax.parallel.remaining_axis_names->tuple((n for n in axis_name if n != frame_name))
A:jax._src.lax.parallel.((pos_contract, pos_batch), result_batch_dim)->jax._src.lax.lax._dot_general_batch_dim_nums((x.ndim, y.ndim), dims_in, [pos_contract, pos_batch])
A:jax._src.lax.parallel.local_out->jax._src.lax.lax.dot_general(x, y, dimension_numbers=(pos_contract, pos_batch), precision=precision, preferred_element_type=None)
A:jax._src.lax.parallel.src_axes_front->moveaxis(src, axes, range(len(axes)))
A:jax._src.lax.parallel.src_one_axis_front->moveaxis(src, axes, range(len(axes))).reshape((-1,) + non_axes_shape)
A:jax._src.lax.parallel.offset_dims->tuple(range(idx.ndim - 1, idx.ndim + src_one_axis_front.ndim - 2))
A:jax._src.lax.parallel.dnums->jax._src.lax.slicing.GatherDimensionNumbers(offset_dims=offset_dims, collapsed_slice_dims=(0,), start_index_map=(0,))
A:jax._src.lax.parallel.src_last_batched->moveaxis(src, dsrc, -1)
A:jax._src.lax.parallel.new_axes->tuple((dsrc if axis == frame_name else axis + (dsrc <= axis) if isinstance(axis, int) else axis for axis in axes))
A:jax._src.lax.parallel.pgather_p->jax.core.AxisPrimitive('pgather')
A:jax._src.lax.parallel.core.axis_substitution_rules[pgather_p]->partial(_subst_all_names_in_param, 'axes')
jax._src.lax.parallel.XeinsumSpecParser(self,spec:str)
jax._src.lax.parallel.XeinsumSpecParser.__init__(self,spec:str)
jax._src.lax.parallel.XeinsumSpecParser.cur(self)
jax._src.lax.parallel.XeinsumSpecParser.eof(self)
jax._src.lax.parallel.XeinsumSpecParser.maybe_take(self,char:str,on_eof:bool=False)
jax._src.lax.parallel.XeinsumSpecParser.parse_arg(self)
jax._src.lax.parallel.XeinsumSpecParser.parse_args(self)
jax._src.lax.parallel.XeinsumSpecParser.parse_axis_name(self)
jax._src.lax.parallel.XeinsumSpecParser.parse_subscript(self)
jax._src.lax.parallel._all_gather_abstract_eval(x,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_batched_collective(frame_size,frame_name,_,vals_in,dims_in,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_batcher(vals_in,dims_in,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_impl(x,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_lowering(ctx,x,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_translation_rule(ctx,avals_in,avals_out,x,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_transpose_rule(cts,x,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_gather_via_psum(x,*,all_gather_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._all_to_all_abstract_eval(x,axis_name,split_axis,concat_axis,axis_index_groups)
jax._src.lax.parallel._all_to_all_batched_collective(axis_size,frame_name,_,vals_in,dims_in,axis_name,split_axis,concat_axis,axis_index_groups)
jax._src.lax.parallel._all_to_all_batcher(vals_in,dims_in,*,axis_name,split_axis,concat_axis,axis_index_groups)
jax._src.lax.parallel._all_to_all_lowering(ctx,x,*,split_axis,concat_axis,axis_name,axis_index_groups)
jax._src.lax.parallel._all_to_all_translation_rule(ctx,avals_in,avals_out,x,*,split_axis,concat_axis,axis_name,axis_index_groups)
jax._src.lax.parallel._all_to_all_transpose_rule(cts,x,axis_name,split_axis,concat_axis,axis_index_groups)
jax._src.lax.parallel._all_to_all_via_all_gather(x,*,axis_name,split_axis,concat_axis,axis_index_groups)
jax._src.lax.parallel._allreduce_abstract_eval(*args,axes,axis_index_groups)
jax._src.lax.parallel._allreduce_impl(pos_reducer,*args,axes,axis_index_groups)
jax._src.lax.parallel._allreduce_lowering(prim,pos_fn,ctx,*args,axes,axis_index_groups)
jax._src.lax.parallel._allreduce_translation_rule(prim,pos_fn,ctx,avals_in,avals_out,*args,axes,axis_index_groups)
jax._src.lax.parallel._axis_index_abstract_eval(*,axis_name)
jax._src.lax.parallel._axis_index_bind(*,axis_name)
jax._src.lax.parallel._axis_index_lowering(ctx,*,axis_name)
jax._src.lax.parallel._axis_index_of_val(x,val,axis_name)
jax._src.lax.parallel._axis_index_translation_rule(ctx,avals_in,avals_out,*,axis_name)
jax._src.lax.parallel._batched_reduction_collective(prim,if_unmapped,axis_size,frame_name,_,vals_in,dims_in,axes,axis_index_groups)
jax._src.lax.parallel._build_axis_index_lowering(c,axis_name,axis_env)
jax._src.lax.parallel._build_axis_index_lowering_mhlo(axis_name,axis_env)
jax._src.lax.parallel._canonicalize_axis_index_groups(axis_index_groups)
jax._src.lax.parallel._collective_batcher(prim,args,dims,**params)
jax._src.lax.parallel._expand(dim,size,index,tiled,x)
jax._src.lax.parallel._foldaxis(axis,x)
jax._src.lax.parallel._index_in_group(axis_name,axis_index_groups)
jax._src.lax.parallel._moveaxis(src,dst,x)
jax._src.lax.parallel._pdot_abstract_eval(x,y,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pdot_impl(x,y,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pdot_lowering(x,y,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pdot_transpose_lhs(g,y,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pdot_transpose_rhs(g,x,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pdot_vmap_batching_rule(vals_in,dims_in,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pdot_vmap_collective_rule(axis_size,frame_name,_,vals_in,dims_in,*,axis_name,pos_contract,pos_batch,precision)
jax._src.lax.parallel._pgather_abstract_eval(src,idx,*,axes)
jax._src.lax.parallel._pgather_batcher(vals_in,dims_in,*,axes)
jax._src.lax.parallel._pgather_collective_batcher(axis_size,frame_name,_,vals_in,dims_in,*,axes)
jax._src.lax.parallel._pgather_impl(src,idx,*,axes)
jax._src.lax.parallel._pgather_parallel_lowering(ctx,src,idx,*,axes)
jax._src.lax.parallel._pgather_parallel_translation(ctx,avals_in,avals_out,src,idx,*,axes)
jax._src.lax.parallel._ppermute_batcher(axis_size,frame_name,_,vals_in,dims_in,axis_name,perm)
jax._src.lax.parallel._ppermute_lowering(ctx,x,*,axis_name,perm)
jax._src.lax.parallel._ppermute_translation_rule(ctx,avals_in,avals_out,x,*,axis_name,perm)
jax._src.lax.parallel._ppermute_transpose_rule(t,x,perm,axis_name)
jax._src.lax.parallel._psum_transpose_rule(cts,*args,axes,axis_index_groups)
jax._src.lax.parallel._reduce_scatter_abstract_eval(x,*,axis_name,scatter_dimension,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._reduce_scatter_lowering(prim,reducer,ctx,x,*,scatter_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._reduce_scatter_translation_rule(prim,reducer,ctx,avals_in,avals_out,x,*,scatter_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._reduce_scatter_via_reducer(x,*,reducer,scatter_dimension,axis_name,axis_index_groups,axis_size,tiled)
jax._src.lax.parallel._reduction_batcher(prim,vals_in,dims_in,*,axes,axis_index_groups)
jax._src.lax.parallel._reduction_with_positional_batcher(prim,vals_in,dims_in,axis_index_groups,transform_unmapped,transform_mapped)
jax._src.lax.parallel._replica_groups(axis_env,axis_name,axis_index_groups)
jax._src.lax.parallel._replica_groups_mhlo(replica_groups:Sequence[Sequence[int]])->ir.DenseIntElementsAttr
jax._src.lax.parallel._splitaxis(axis,factor,x)
jax._src.lax.parallel._subst_all_names_in_param(pname:str,params:core.ParamDict,subst:core.AxisSubst,traverse:bool)->core.ParamDict
jax._src.lax.parallel._validate_reduce_axis_index_groups(axis_index_groups)
jax._src.lax.parallel._vmap_process_axis_index(self,frame)
jax._src.lax.parallel.all_gather(x,axis_name,*,axis_index_groups=None,axis=0,tiled=False)
jax._src.lax.parallel.all_to_all(x,axis_name,split_axis,concat_axis,*,axis_index_groups=None,tiled=False)
jax._src.lax.parallel.axis_index(axis_name)
jax._src.lax.parallel.pargmax(x,axis_name)
jax._src.lax.parallel.pargmin(x,axis_name)
jax._src.lax.parallel.pdot(x,y,axis_name,pos_contract=((),()),pos_batch=((),()),precision=None)
jax._src.lax.parallel.pgather(src,idx,axes:Union[int,AxisName])
jax._src.lax.parallel.pmax(x,axis_name,*,axis_index_groups=None)
jax._src.lax.parallel.pmean(x,axis_name,*,axis_index_groups=None)
jax._src.lax.parallel.pmin(x,axis_name,*,axis_index_groups=None)
jax._src.lax.parallel.ppermute(x,axis_name,perm)
jax._src.lax.parallel.pshuffle(x,axis_name,perm)
jax._src.lax.parallel.psum(x,axis_name,*,axis_index_groups=None)
jax._src.lax.parallel.psum_bind(*args,axes,axis_index_groups)
jax._src.lax.parallel.psum_scatter(x,axis_name,*,scatter_dimension=0,axis_index_groups=None,tiled=False)
jax._src.lax.parallel.pswapaxes(x,axis_name,axis,*,axis_index_groups=None)
jax._src.lax.parallel.xeinsum(spec:str,x,y)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/windowed_reductions.py----------------------------------------
A:jax._src.lax.windowed_reductions.(flat_operands, operand_tree)->jax.tree_util.tree_flatten(operand)
A:jax._src.lax.windowed_reductions.(flat_init_values, init_value_tree)->jax.tree_util.tree_flatten(init_value)
A:jax._src.lax.windowed_reductions.padding->tuple(padding)
A:jax._src.lax.windowed_reductions.monoid_reducer->_get_monoid_window_reducer(computation, flat_init_values)
A:jax._src.lax.windowed_reductions.flat_init_avals->map(lax._abstractify, flat_init_values)
A:jax._src.lax.windowed_reductions.(jaxpr, consts, out_tree)->jax._src.lax.lax._variadic_reduction_jaxpr(computation, tuple(flat_init_avals), init_value_tree)
A:jax._src.lax.windowed_reductions.out_flat->jax.core.Primitive('reduce_window').bind(*flat_operands + flat_init_values, jaxpr=jaxpr, consts=consts, window_dimensions=tuple(window_dimensions), window_strides=tuple(window_strides), padding=padding, base_dilation=tuple(base_dilation), window_dilation=tuple(window_dilation))
A:jax._src.lax.windowed_reductions.aval->jax.core.get_aval(x)
A:jax._src.lax.windowed_reductions.init_value->jax._src.lax.lax._const(operand, 1)
A:jax._src.lax.windowed_reductions.(jaxpr, consts)->jax._src.lax.lax._reduction_jaxpr(lax.mul, lax._abstractify(init_value))
A:jax._src.lax.windowed_reductions.(out,)->jax.core.Primitive('reduce_window').bind(operand, init_value, jaxpr=jaxpr, consts=consts, window_dimensions=tuple(window_dimensions), window_strides=tuple(window_strides), padding=tuple(padding), base_dilation=tuple(base_dilation), window_dilation=tuple(window_dilation))
A:jax._src.lax.windowed_reductions.(select_jaxpr, select_consts)->jax._src.lax.lax._reduction_jaxpr(select, lax._abstractify(init_value))
A:jax._src.lax.windowed_reductions.(scatter_jaxpr, scatter_consts)->jax._src.lax.lax._reduction_jaxpr(scatter, lax._abstractify(init_value))
A:jax._src.lax.windowed_reductions.(operand_avals, init_val_avals)->jax._src.util.split_list(avals, [len(avals) // 2])
A:jax._src.lax.windowed_reductions.out_shape->_common_reduce_window_shape_rule(operand_avals[0], window_dimensions, window_strides, padding, base_dilation, window_dilation)
A:jax._src.lax.windowed_reductions.(operands, init_values)->jax._src.util.split_list(args, [len(args) // 2])
A:jax._src.lax.windowed_reductions.xla_computation->jax._src.lax.lax._reduction_computation(ctx, jaxpr, consts, init_values, singleton=False)
A:jax._src.lax.windowed_reductions.(operand_bdims, init_value_bdims)->jax._src.util.split_list(batch_dims, [num_operands])
A:jax._src.lax.windowed_reductions.size->next((a.shape[bdim] for (a, bdim) in zip(batched_args, batch_dims) if bdim is not None))
A:jax._src.lax.windowed_reductions.outs->jax.core.Primitive('reduce_window').bind(*operands + init_values, jaxpr=jaxpr, consts=consts, window_dimensions=window_dimensions, window_strides=window_strides, padding=padding, base_dilation=base_dilation, window_dilation=window_dilation)
A:jax._src.lax.windowed_reductions.reduce_window_p->jax.core.Primitive('reduce_window')
A:jax._src.lax.windowed_reductions.(_, init_value_avals)->jax._src.util.split_list(ctx.avals_in, [len(operands)])
A:jax._src.lax.windowed_reductions.rw->jax._src.lib.mlir.dialects.mhlo.ReduceWindowOp(mlir.aval_to_ir_types(aval_out), [operand], [mlir.full_like_aval(init_value(scalar_aval.dtype), scalar_aval)], mlir.dense_int_elements(window_dimensions), mlir.dense_int_elements(window_strides), mlir.dense_int_elements(base_dilation), mlir.dense_int_elements(window_dilation), ir.DenseIntElementsAttr.get(np.asarray(padding, np.int64)))
A:jax._src.lax.windowed_reductions.reducer->jax._src.lib.mlir.dialects.mhlo.ReduceWindowOp(mlir.aval_to_ir_types(aval_out), [operand], [mlir.full_like_aval(init_value(scalar_aval.dtype), scalar_aval)], mlir.dense_int_elements(window_dimensions), mlir.dense_int_elements(window_strides), mlir.dense_int_elements(base_dilation), mlir.dense_int_elements(window_dilation), ir.DenseIntElementsAttr.get(np.asarray(padding, np.int64))).regions[0].blocks.append(scalar_type, scalar_type)
A:jax._src.lax.windowed_reductions.out_nodes->jax.interpreters.mlir.jaxpr_subcomp(ctx.module_context, scatter_jaxpr, scatter_consts, *([a] for a in scatter.arguments))
A:jax._src.lax.windowed_reductions.scalar->ShapedArray((), dtype)
A:jax._src.lax.windowed_reductions.pads->jax._src.lax.convolution._conv_general_vjp_lhs_padding(input_shape, window_dimensions, window_strides, cotangent.shape, padding, base_dilation, window_dilation)
A:jax._src.lax.windowed_reductions.pad_cotangent->jax._src.lax.lax.pad(cotangent, lax._zero(cotangent), padding_config)
A:jax._src.lax.windowed_reductions.result->jax._src.lax.slicing.slice(result, (0,) * len(result.shape), result.shape, base_dilation)
A:jax._src.lax.windowed_reductions.operand->jax._src.lax.lax.pad(operand, select_identity(operand.dtype), tuple(((0, 0, d - 1) for d in base_dilation)))
A:jax._src.lax.windowed_reductions.reduce_window_sum_p->jax._src.lax.lax.standard_primitive(_reduce_window_sum_shape_rule, lax._input_dtype, 'reduce_window_sum', _reduce_window_sum_translation_rule)
A:jax._src.lax.windowed_reductions.batching.primitive_batchers[reduce_window_sum_p]->partial(_reduce_window_batch_rule, _reduce_window_sum)
A:jax._src.lax.windowed_reductions.operand_shape->jax._src.lax.lax._dilate_shape(operand_shape, base_dilation)
A:jax._src.lax.windowed_reductions.window_dimensions->jax._src.lax.lax._dilate_shape(window_dimensions, window_dilation)
A:jax._src.lax.windowed_reductions.(pads_lo, pads_hi)->zip(*padding)
A:jax._src.lax.windowed_reductions.operand_padded->jax.core.sum_shapes(operand_shape, pads_lo, pads_hi)
A:jax._src.lax.windowed_reductions._reduce_window_max_translation_rule->partial(_reduce_window_chooser_translation_rule, lax.max_p, lax._get_max_identity)
A:jax._src.lax.windowed_reductions.reduce_window_max_p->jax._src.lax.lax.standard_primitive(_common_reduce_window_shape_rule, lax._input_dtype, 'reduce_window_max', _reduce_window_max_translation_rule)
A:jax._src.lax.windowed_reductions.batching.primitive_batchers[reduce_window_max_p]->partial(_reduce_window_batch_rule, _reduce_window_max)
A:jax._src.lax.windowed_reductions._reduce_window_min_translation_rule->partial(_reduce_window_chooser_translation_rule, lax.min_p, lax._get_min_identity)
A:jax._src.lax.windowed_reductions.reduce_window_min_p->jax._src.lax.lax.standard_primitive(_common_reduce_window_shape_rule, lax._input_dtype, 'reduce_window_min', _reduce_window_min_translation_rule)
A:jax._src.lax.windowed_reductions._reduce_window_min_batch_rule->partial(_reduce_window_batch_rule, _reduce_window_min)
A:jax._src.lax.windowed_reductions.batching.primitive_batchers[reduce_window_min_p]->partial(_reduce_window_batch_rule, _reduce_window_min)
A:jax._src.lax.windowed_reductions.scalar_aval->operand_aval.update(shape=())
A:jax._src.lax.windowed_reductions.scalar_type->jax.interpreters.mlir.aval_to_ir_type(scalar_aval)
A:jax._src.lax.windowed_reductions.select->jax.interpreters.xla.primitive_subcomputation(ctx.platform, ctx.axis_env, select_prim, scalar, scalar)
A:jax._src.lax.windowed_reductions.scatter->jax.interpreters.xla.primitive_subcomputation(ctx.platform, ctx.axis_env, lax.or_p if dtype == np.bool_ else lax.add_p, scalar, scalar)
A:jax._src.lax.windowed_reductions.select_and_scatter_p->jax._src.lax.lax.standard_primitive(_select_and_scatter_shape_rule, lax._input_dtype, 'select_and_scatter', _select_and_scatter_translation)
A:jax._src.lax.windowed_reductions.op->jax._src.lib.mlir.dialects.mhlo.SelectAndScatterOp(mlir.aval_to_ir_type(aval_out), operand, source, init_value, mlir.dense_int_elements(window_dimensions), mlir.dense_int_elements(window_strides), ir.DenseIntElementsAttr.get(np.asarray(padding, np.int64)))
A:jax._src.lax.windowed_reductions.zero->jax.interpreters.xla.pyval_to_ir_constant(c, np.array(0, dtype))
A:jax._src.lax.windowed_reductions.output->xops.Slice(output, start_indices, stop_indices, [1] * len(start_indices))
A:jax._src.lax.windowed_reductions.val_out->_select_and_gather_add(source, operand, select_prim, window_dimensions, window_strides, padding, base_dilation, window_dilation)
A:jax._src.lax.windowed_reductions.tangent_out->_select_and_gather_add(g_source, operand, select_prim, window_dimensions, window_strides, padding, base_dilation, window_dilation)
A:jax._src.lax.windowed_reductions.source_t->_select_and_gather_add(t, operand, select_prim, window_dimensions, window_strides, padding, ones, ones)
A:jax._src.lax.windowed_reductions.source->jax.interpreters.batching.bdim_at_front(source, s_bdim, size)
A:jax._src.lax.windowed_reductions.out->_select_and_gather_add(t, x, select_prim, window_dimensions, window_strides, padding, base_dilation, window_dilation)
A:jax._src.lax.windowed_reductions.select_and_scatter_add_p->jax._src.lax.lax.standard_primitive(_select_and_scatter_add_shape_rule, lax._input_dtype, 'select_and_scatter_add', partial(_select_and_scatter_add_translation, expand_padding=False))
A:jax._src.lax.windowed_reductions.etype->jax.interpreters.xla.dtype_to_primitive_type(dtype)
A:jax._src.lax.windowed_reductions.word_type->jax.interpreters.xla.dtype_to_primitive_type(word_dtype)
A:jax._src.lax.windowed_reductions.double_word_type->jax.interpreters.xla.dtype_to_primitive_type(double_word_dtype)
A:jax._src.lax.windowed_reductions.a->xops.BitcastConvertType(a, word_type)
A:jax._src.lax.windowed_reductions.b->xops.ShiftRightLogical(b, const(c, word_dtype, r_nbits))
A:jax._src.lax.windowed_reductions.st->xops.And(t, const(c, word_dtype, (1 << r_nbits) - 1 << r_nbits))
A:jax._src.lax.windowed_reductions.c->xc.XlaBuilder('select_and_gather_pair_reducer')
A:jax._src.lax.windowed_reductions.x->jax.interpreters.batching.bdim_at_front(x, x_bdim, size)
A:jax._src.lax.windowed_reductions.y->jax.interpreters.xla.parameter(c, 1, xla_client.Shape.array_shape(np.dtype(double_word_dtype), ()))
A:jax._src.lax.windowed_reductions.which->select_prim.bind(kx, ky)
A:jax._src.lax.windowed_reductions.(_, out)->reduce_window((operand, tangents), (np.array(init, dtype=operand.dtype), np.array(0, dtype=operand.dtype)), reducer, window_dimensions, window_strides, padding, base_dilation, window_dilation)
A:jax._src.lax.windowed_reductions.has_base_dilation->any((d != 1 for d in base_dilation))
A:jax._src.lax.windowed_reductions.t->jax.interpreters.batching.bdim_at_front(t, t_bdim, size)
A:jax._src.lax.windowed_reductions.select_and_gather_add_p->jax._src.lax.lax.standard_primitive(_select_and_gather_add_shape_rule, lax._input_dtype, 'select_and_gather_add', xla.lower_fun(_select_and_gather_add_using_variadic_reducewindow, new_style=True, multiple_results=False))
jax._src.lax.windowed_reductions._common_reduce_window_shape_rule(operand,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._generic_reduce_window_batch_rule(batched_args,batch_dims,*,jaxpr,consts,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._generic_reduce_window_lower(ctx,*args,jaxpr,consts,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._get_monoid_window_reducer(monoid_op:Callable,xs:Sequence[Array])->Optional[Callable]
jax._src.lax.windowed_reductions._reduce_window_abstract_eval_rule(*avals,jaxpr,consts,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_batch_rule(reduce_window,batched_args,bdims,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_chooser_jvp_rule(prim,g,operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_chooser_translation_rule(prim,identity,ctx,avals_in,avals_out,operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_lower(reduce_op,init_value,ctx,operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_max(operand:Array,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]],base_dilation:Optional[Sequence[int]]=None,window_dilation:Optional[Sequence[int]]=None)->Array
jax._src.lax.windowed_reductions._reduce_window_min(operand:Array,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]],base_dilation:Optional[Sequence[int]]=None,window_dilation:Optional[Sequence[int]]=None)->Array
jax._src.lax.windowed_reductions._reduce_window_prod(operand:Array,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]],base_dilation:Optional[Sequence[int]]=None,window_dilation:Optional[Sequence[int]]=None)->Array
jax._src.lax.windowed_reductions._reduce_window_sum(operand:Array,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]],base_dilation:Optional[Sequence[int]]=None,window_dilation:Optional[Sequence[int]]=None)->Array
jax._src.lax.windowed_reductions._reduce_window_sum_shape_rule(operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_sum_translation_rule(ctx,avals_in,avals_out,operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_sum_transpose_rule(cotangent,operand,*,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._reduce_window_translation_rule(ctx,avals_in,avals_out,*args,jaxpr,consts,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._select_and_gather_add(tangents:Array,operand:Array,select_prim:core.Primitive,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]],base_dilation:Sequence[int],window_dilation:Sequence[int])->Array
jax._src.lax.windowed_reductions._select_and_gather_add_batching_rule(batched_args,batch_dims,*,select_prim,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._select_and_gather_add_jvp(primals,tangents,*,select_prim,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._select_and_gather_add_shape_rule(tangents,operand,*,select_prim,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._select_and_gather_add_translation(ctx,avals_in,avals_out,tangents,operand,*,select_prim,window_dimensions,window_strides,padding,base_dilation,window_dilation,max_bits=64)
jax._src.lax.windowed_reductions._select_and_gather_add_transpose(t,tangents,operand,*,select_prim,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._select_and_gather_add_using_variadic_reducewindow(tangents,operand,*,select_prim,window_dimensions,window_strides,padding,base_dilation,window_dilation)
jax._src.lax.windowed_reductions._select_and_scatter(operand:Array,select:Callable,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]],source:Array,init_value:Array,scatter:Callable)->Array
jax._src.lax.windowed_reductions._select_and_scatter_add(source:Array,operand:Array,select_prim:core.Primitive,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Sequence[Tuple[int,int]])->Array
jax._src.lax.windowed_reductions._select_and_scatter_add_batch_rule(batched_args,batch_dims,*,select_prim,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions._select_and_scatter_add_impl(source,operand,*,select_prim,window_dimensions,window_strides,padding,expand_padding)
jax._src.lax.windowed_reductions._select_and_scatter_add_jvp(primals,tangents,*,select_prim,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions._select_and_scatter_add_shape_rule(source,operand,*,select_prim,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions._select_and_scatter_add_translation(ctx,avals_in,avals_out,source,operand,*,select_prim,window_dimensions,window_strides,padding,expand_padding)
jax._src.lax.windowed_reductions._select_and_scatter_add_transpose(t,source,operand,*,select_prim,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions._select_and_scatter_lower(ctx,operand,source,init_value,*,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions._select_and_scatter_shape_rule(operand,source,init_value,*,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions._select_and_scatter_translation(ctx,avals_in,avals_out,operand,source,init_value,*,select_jaxpr,select_consts,scatter_jaxpr,scatter_consts,window_dimensions,window_strides,padding)
jax._src.lax.windowed_reductions.reduce_window(operand,init_value,computation:Callable,window_dimensions:core.Shape,window_strides:Sequence[int],padding:Union[str,Sequence[Tuple[int,int]]],base_dilation:Optional[Sequence[int]]=None,window_dilation:Optional[Sequence[int]]=None)->Array
jax._src.lax.windowed_reductions.reduce_window_shape_tuple(operand_shape,window_dimensions,window_strides,padding,base_dilation=None,window_dilation=None)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/slicing.py----------------------------------------
A:jax._src.lax.slicing.start_indices->_dynamic_slice_indices(operand, start_indices)
A:jax._src.lax.slicing.CLIP->enum.auto()
A:jax._src.lax.slicing.FILL_OR_DROP->enum.auto()
A:jax._src.lax.slicing.PROMISE_IN_BOUNDS->enum.auto()
A:jax._src.lax.slicing.parsed_mode->GatherScatterMode.from_any(mode)
A:jax._src.lax.slicing.dtype->jax._src.lax.lax._dtype(operand)
A:jax._src.lax.slicing.(jaxpr, consts)->jax._src.lax.lax._reduction_jaxpr(_scatter_reduction_computation, lax._abstractify(lax._const(operand, 0)))
A:jax._src.lax.slicing.unused->jax._src.lax.lax.full(scatter_indices.shape[:1], 0, operand.dtype)
A:jax._src.lax.slicing._apply->_scatter_apply_cache.setdefault(func, _apply)
A:jax._src.lax.slicing.indices->jax._src.lax.lax.concatenate([counts, indices], len(count_shape) - 1)
A:jax._src.lax.slicing.slice_sizes->iter(np.delete(slice_sizes, collapsed_slice_dims))
A:jax._src.lax.slicing.offset_dims->tuple(np.add(1, dimension_numbers.offset_dims))
A:jax._src.lax.slicing.dnums->ScatterDimensionNumbers(update_window_dims=update_window_dims, inserted_window_dims=inserted_window_dims, scatter_dims_to_operand_dims=scatter_dims_to_operand_dims)
A:jax._src.lax.slicing.limit_indices->list(operand.shape)
A:jax._src.lax.slicing.axis->int(axis)
A:jax._src.lax.slicing.strides[axis]->int(stride)
A:jax._src.lax.slicing.result->jax._src.lax.lax.pad(t, lax._const(t, 0), pads)
A:jax._src.lax.slicing.slice_sizes[axis]->jax.core._canonicalize_dimension(slice_size)
A:jax._src.lax.slicing.update->jax._src.lib.mlir.dialects.mhlo.ScatterOp(mlir.aval_to_ir_type(aval_out), operand, indices, updates, scatter_dnums, ir.BoolAttr.get(indices_are_sorted), ir.BoolAttr.get(unique_indices)).update_computation.blocks.append(scalar_type, scalar_type)
A:jax._src.lax.slicing.strides->numpy.ones(operand.ndim, np.int32)
A:jax._src.lax.slicing.diff->jax.core.diff_shape(limit_indices, start_indices)
A:jax._src.lax.slicing.pads->safe_zip(start_indices, np.subtract(operand_shape, real_limits), np.subtract(strides, 1))
A:jax._src.lax.slicing.real_limits->numpy.add(start_indices, np.where(np.array(t.shape) == 0, 0, np.add(1, np.multiply(np.subtract(t.shape, 1), strides))))
A:jax._src.lax.slicing.new_start_indices->list(start_indices)
A:jax._src.lax.slicing.new_limit_indices->list(limit_indices)
A:jax._src.lax.slicing.new_strides->list(strides)
A:jax._src.lax.slicing.out->xops.Add(args[0], args[1])
A:jax._src.lax.slicing.slice_p->standard_primitive(_slice_shape_rule, _input_dtype, 'slice', _slice_translation_rule)
A:jax._src.lax.slicing.tangent_out->scatter_add(masked_g_operand, indices, masked_g_updates, dimension_numbers=dnums, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)
A:jax._src.lax.slicing.zeros->jax._src.lax.lax.full(operand_shape, lax._zero(t))
A:jax._src.lax.slicing.empty_marker->object()
A:jax._src.lax.slicing.size->jax._src.lax.lax.make_bint(lax.clamp(0, hi - lo, x.shape[0]), x.shape[0])
A:jax._src.lax.slicing.dims->tuple(range(len(update_shape)))
A:jax._src.lax.slicing.(index, index_bdim)->_batch_dynamic_slice_indices(start_idx, start_idx_bd)
A:jax._src.lax.slicing.dynamic_slice_p->standard_primitive(_dynamic_slice_shape_rule, _dynamic_slice_dtype_rule, 'dynamic_slice', _dynamic_slice_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.val_out->scatter_add(masked_operand, indices, masked_updates, dimension_numbers=dnums, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)
A:jax._src.lax.slicing.g_operand->jax.interpreters.ad.instantiate_zeros(g_operand)
A:jax._src.lax.slicing.g_update->jax.interpreters.ad.instantiate_zeros(g_update)
A:jax._src.lax.slicing.dynamic_update_slice_p->standard_primitive(_dynamic_update_slice_shape_rule, _dynamic_update_slice_dtype_rule, 'dynamic_update_slice', _dynamic_update_slice_translation_rule)
A:jax._src.lax.slicing.proto->jax._src.lib.xla_client.ScatterDimensionNumbers()
A:jax._src.lax.slicing.expanded_indices_shape->list(indices.shape)
A:jax._src.lax.slicing.output_offset_dim_count->len(offset_dims)
A:jax._src.lax.slicing.indices_shape->iter(expanded_indices_shape)
A:jax._src.lax.slicing.intarray->partial(np.array, dtype=np.int64)
A:jax._src.lax.slicing.operand_dims->jax._src.lax.lax._shape_as_value(operand.shape)
A:jax._src.lax.slicing.mask->scatter(lax._ones(t, dtype=np.bool_), indices, lax.full(updates_shape, False), dimension_numbers=dimension_numbers, indices_are_sorted=indices_are_sorted, unique_indices=True, mode=mode)
A:jax._src.lax.slicing.batch_dims_in_output->numpy.delete(np.arange(output_ndims), dnums.offset_dims)
A:jax._src.lax.slicing.gather_out->gather(operand, indices, dnums, slice_sizes, indices_are_sorted=indices_are_sorted, mode=GatherScatterMode.PROMISE_IN_BOUNDS)
A:jax._src.lax.slicing.gather_fill_fn->jax.interpreters.mlir.lower_fun(_gather_fill, multiple_results=False)
A:jax._src.lax.slicing.dimensions->_gather_dimensions_proto(indices_aval.shape, dimension_numbers)
A:jax._src.lax.slicing.scatter_dnums->jax._src.lib.mlir.dialects.mhlo.ScatterDimensionNumbers.get(update_window_dims=list(dnums.update_window_dims), inserted_window_dims=list(dnums.inserted_window_dims), scattered_dims_to_operand_dims=list(dnums.scatter_dims_to_operand_dims), index_vector_dim=len(ctx.avals_in[1].shape) - 1)
A:jax._src.lax.slicing.operand->jax.interpreters.batching.bdim_at_front(operand, operand_bdim, size)
A:jax._src.lax.slicing.collapsed_slice_dims->tuple(np.add(1, dimension_numbers.collapsed_slice_dims))
A:jax._src.lax.slicing.start_index_map->tuple(np.add(1, dimension_numbers.start_index_map))
A:jax._src.lax.slicing.output_shape->_gather_shape_rule(core.ShapedArray(operand.shape[1:], operand.dtype), core.ShapedArray(indices.shape[1:], dtypes.canonicalize_dtype(indices.dtype)), dimension_numbers=dimension_numbers, slice_sizes=slice_sizes, unique_indices=unique_indices, indices_are_sorted=indices_are_sorted, mode=mode, fill_value=fill_value)
A:jax._src.lax.slicing.count_shape->list(indices.shape)
A:jax._src.lax.slicing.counts->jax._src.lax.lax.broadcasted_iota(indices.dtype, tuple(count_shape), 0)
A:jax._src.lax.slicing.gather_p->standard_primitive(_gather_shape_rule, _gather_dtype_rule, 'gather', _gather_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.upper_bound->jax._src.lax.lax.broadcast_in_dim(upper_bound, indices.shape, (len(indices.shape) - 1,))
A:jax._src.lax.slicing.clip_fn->jax.interpreters.mlir.lower_fun(_clamp_scatter_indices, multiple_results=False)
A:jax._src.lax.slicing.(indices,)->clip_fn(ctx, avals_in, None, operand, indices, updates, dnums=dimension_numbers)
A:jax._src.lax.slicing.init_value->jax.interpreters.xla.pyval_to_ir_constant(c, np.array(0, operand_aval.dtype))
A:jax._src.lax.slicing.update_computation->_make_reducer(dtype)
A:jax._src.lax.slicing.scatter_dims->_scatter_dimensions_proto(indices_aval.shape, dimension_numbers)
A:jax._src.lax.slicing.subc->xc.XlaBuilder('scatter_add_reducer')
A:jax._src.lax.slicing.shape->xc.Shape.array_shape(np.dtype(dtype), ())
A:jax._src.lax.slicing.re->xops.Scatter(xops.Real(operand), indices, xops.Real(updates), update_computation, scatter_dims, indices_are_sorted, unique_indices)
A:jax._src.lax.slicing.im->xops.Scatter(xops.Imag(operand), indices, xops.Imag(updates), update_computation, scatter_dims, indices_are_sorted, unique_indices)
A:jax._src.lax.slicing.g_updates->jax.interpreters.ad.instantiate_zeros(g_updates)
A:jax._src.lax.slicing.gather_dnums->GatherDimensionNumbers(offset_dims=dimension_numbers.update_window_dims, collapsed_slice_dims=dimension_numbers.inserted_window_dims, start_index_map=dimension_numbers.scatter_dims_to_operand_dims)
A:jax._src.lax.slicing.update_t->gather(t, indices, dimension_numbers=gather_dnums, slice_sizes=slice_sizes, mode=mode, fill_value=0)
A:jax._src.lax.slicing.operand_t->jax._src.lax.lax.select(mask, t, lax._zeros(t))
A:jax._src.lax.slicing.updates->jax.interpreters.batching.bdim_at_front(updates, updates_bdim, size)
A:jax._src.lax.slicing.inserted_window_dims->tuple(np.add(1, dimension_numbers.inserted_window_dims))
A:jax._src.lax.slicing.scatter_dims_to_operand_dims->tuple(np.add(1, dimension_numbers.scatter_dims_to_operand_dims))
A:jax._src.lax.slicing.update_window_dims->tuple(np.add(1, dimension_numbers.update_window_dims))
A:jax._src.lax.slicing.scatter_add_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-add', _scatter_add_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.batching.primitive_batchers[scatter_add_p]->partial(_scatter_batching_rule, scatter_add)
A:jax._src.lax.slicing.scatter_mul_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-mul', _scatter_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.batching.primitive_batchers[scatter_mul_p]->partial(_scatter_batching_rule, scatter_mul)
A:jax._src.lax.slicing.initial_vals->gather(operand, indices, gather_dnums, np.array(slice_sizes))
A:jax._src.lax.slicing.target_vals->gather(val_out, indices, gather_dnums, np.array(slice_sizes))
A:jax._src.lax.slicing.num_updates->gather(scatter_add(lax._zeros(operand), indices, lax.select(successful_updates, lax._ones(updates), lax._zeros(updates)), scatter_dnums), indices, gather_dnums, np.array(slice_sizes))
A:jax._src.lax.slicing.num_refs->gather(scatter_add(lax._zeros(operand), indices, lax._ones(updates), scatter_dnums), indices, gather_dnums, np.array(slice_sizes))
A:jax._src.lax.slicing.updates_normalizer->jax._src.lax.lax.select(retained_values, 1.0 / (num_updates + 1), 1.0 / num_updates)
A:jax._src.lax.slicing.updates_coef->jax._src.lax.lax.select(successful_updates, updates_normalizer, lax._zeros(updates))
A:jax._src.lax.slicing.operand_normalizer->jax._src.lax.lax.select(retained_values, 1.0 / (num_updates + 1), lax._zeros(num_updates))
A:jax._src.lax.slicing.target_tangents->gather(g_operand, indices, gather_dnums, np.array(slice_sizes))
A:jax._src.lax.slicing.scatter_min_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-min', _scatter_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.batching.primitive_batchers[scatter_min_p]->partial(_scatter_batching_rule, scatter_min)
A:jax._src.lax.slicing.ad.primitive_jvps[scatter_min_p]->partial(_scatter_extremal_jvp, scatter_min_p)
A:jax._src.lax.slicing.scatter_max_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter-max', _scatter_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.batching.primitive_batchers[scatter_max_p]->partial(_scatter_batching_rule, scatter_max)
A:jax._src.lax.slicing.ad.primitive_jvps[scatter_max_p]->partial(_scatter_extremal_jvp, scatter_max_p)
A:jax._src.lax.slicing.ids_shape->numpy.array(updates.shape, dtype=np.int64)
A:jax._src.lax.slicing.num_ids->numpy.prod(ids_shape)
A:jax._src.lax.slicing.update_ids->jax._src.lax.lax.add(lax.reshape(lax.iota(id_dtype, num_ids), ids_shape), lax._ones(updates, dtype=id_dtype))
A:jax._src.lax.slicing.scattered_ids->scatter(lax.full(operand.shape, 0, id_dtype), indices, update_ids, dnums, indices_are_sorted=indices_are_sorted, unique_indices=unique_indices, mode=mode)
A:jax._src.lax.slicing.gathered_update_ids->gather(scattered_ids, indices, dimension_numbers=gather_dnums, slice_sizes=slice_sizes)
A:jax._src.lax.slicing.masked_operand->jax._src.lax.lax.select(lax.eq(scattered_ids, lax._zeros(scattered_ids)), operand, lax._zeros(operand))
A:jax._src.lax.slicing.masked_updates->jax._src.lax.lax.select(lax.eq(update_ids, gathered_update_ids), updates, lax._zeros(updates))
A:jax._src.lax.slicing.masked_g_operand->jax._src.lax.lax.select(lax.eq(scattered_ids, lax._zeros(scattered_ids)), g_operand, lax._zeros(g_operand))
A:jax._src.lax.slicing.masked_g_updates->jax._src.lax.lax.select(lax.eq(update_ids, gathered_update_ids), g_updates, lax._zeros(g_updates))
A:jax._src.lax.slicing.scatter_p->standard_primitive(_scatter_shape_rule, _scatter_dtype_rule, 'scatter', _scatter_translation_rule, weak_type_rule=_argnum_weak_type(0))
A:jax._src.lax.slicing.batching.primitive_batchers[scatter_p]->partial(_scatter_batching_rule, scatter)
A:jax._src.lax.slicing.((indices,),)->clip_fn(ctx, ctx.avals_in, None, operand, indices, updates, dnums=dimension_numbers)
A:jax._src.lax.slicing.op->jax._src.lib.mlir.dialects.mhlo.ScatterOp(mlir.aval_to_ir_type(aval_out), operand, indices, updates, scatter_dnums, ir.BoolAttr.get(indices_are_sorted), ir.BoolAttr.get(unique_indices))
A:jax._src.lax.slicing.scalar_type->jax.interpreters.mlir.aval_to_ir_type(core.ShapedArray((), real_dtype))
A:jax._src.lax.slicing.update_ctx->ctx.module_context.replace(name_stack='')
A:jax._src.lax.slicing.out_nodes->jax.interpreters.mlir.jaxpr_subcomp(update_ctx, update_jaxpr, update_consts, (update.arguments[0],), (update.arguments[1],))
A:jax._src.lax.slicing.real_dtype->_real_dtype(aval_out.dtype)
A:jax._src.lax.slicing.operand_type_part->jax.interpreters.mlir.aval_to_ir_type(core.ShapedArray(aval_out.shape, real_dtype))
A:jax._src.lax.slicing.scatter->jax._src.lib.mlir.dialects.mhlo.ScatterOp(operand_type_part, operand_part, indices, updates_part, scatter_dnums, ir.BoolAttr.get(indices_are_sorted), ir.BoolAttr.get(unique_indices))
A:jax._src.lax.slicing.reducer->jax._src.lib.mlir.dialects.mhlo.ScatterOp(operand_type_part, operand_part, indices, updates_part, scatter_dnums, ir.BoolAttr.get(indices_are_sorted), ir.BoolAttr.get(unique_indices)).regions[0].blocks.append(scalar_type, scalar_type)
A:jax._src.lax.slicing.real->_scatter(mhlo.RealOp(operand).result, mhlo.RealOp(updates).result)
A:jax._src.lax.slicing.imag->_scatter(mhlo.ImagOp(operand).result, mhlo.ImagOp(updates).result)
A:jax._src.lax.slicing.getslice_p->jax.core.Primitive('getslice')
A:jax._src.lax.slicing.aval->jax.core.DShapedArray((size,), x.dtype, x.weak_type)
A:jax._src.lax.slicing.source_info->jax._src.source_info_util.current()
A:jax._src.lax.slicing.out_tracer->jax.interpreters.partial_eval.DynamicJaxprTracer(trace, aval, source_info)
A:jax._src.lax.slicing.invars->map(trace.getvar, [x, lo, hi])
A:jax._src.lax.slicing.eqn->jax.interpreters.partial_eval.new_jaxpr_eqn(invars, [trace.makevar(out_tracer)], getslice_p, {}, source_info)
A:jax._src.lax.slicing.xx->jax._src.lax.lax.concatenate([x, x], 0)
jax._src.lax.slicing.GatherDimensionNumbers(NamedTuple)
jax._src.lax.slicing.GatherScatterMode(enum.Enum)
jax._src.lax.slicing.GatherScatterMode.from_any(s:Optional[Union[str,'GatherScatterMode']])
jax._src.lax.slicing.ScatterDimensionNumbers(NamedTuple)
jax._src.lax.slicing._batch_dynamic_slice_indices(indices,bdims)
jax._src.lax.slicing._clamp_scatter_indices(operand,indices,updates,*,dnums)
jax._src.lax.slicing._dynamic_slice_batching_rule(batched_args,batch_dims,*,slice_sizes)
jax._src.lax.slicing._dynamic_slice_dtype_rule(operand,*start_indices,slice_sizes)
jax._src.lax.slicing._dynamic_slice_indices(operand,start_indices:Any)
jax._src.lax.slicing._dynamic_slice_jvp(primals,tangents,*,slice_sizes)
jax._src.lax.slicing._dynamic_slice_lower(ctx,x,*start_indices,slice_sizes)
jax._src.lax.slicing._dynamic_slice_shape_rule(operand,*start_indices,slice_sizes)
jax._src.lax.slicing._dynamic_slice_translation_rule(ctx,avals_in,avals_out,operand,*start_indices,slice_sizes)
jax._src.lax.slicing._dynamic_slice_transpose_rule(t,operand,*start_indices,slice_sizes)
jax._src.lax.slicing._dynamic_update_slice_batching_rule(batched_args,batch_dims)
jax._src.lax.slicing._dynamic_update_slice_dtype_rule(operand,update,*start_indices)
jax._src.lax.slicing._dynamic_update_slice_jvp(primals,tangents)
jax._src.lax.slicing._dynamic_update_slice_lower(ctx,x,update,*start_indices)
jax._src.lax.slicing._dynamic_update_slice_shape_rule(operand,update,*start_indices)
jax._src.lax.slicing._dynamic_update_slice_translation_rule(ctx,avals_in,avals_out,operand,update,*start_indices)
jax._src.lax.slicing._dynamic_update_slice_transpose_rule(t,operand,update,*start_indices)
jax._src.lax.slicing._gather_batching_rule(batched_args,batch_dims,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax._src.lax.slicing._gather_dimensions_proto(indices_shape:Sequence[int],dimension_numbers:GatherDimensionNumbers)->xla_client.GatherDimensionNumbers
jax._src.lax.slicing._gather_dtype_rule(operand,indices,*,fill_value,**kwargs)
jax._src.lax.slicing._gather_fill(operand,indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,fill_value,output_shape)
jax._src.lax.slicing._gather_jvp_rule(g,operand,indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax._src.lax.slicing._gather_lower(ctx,operand,indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax._src.lax.slicing._gather_shape_rule(operand,indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax._src.lax.slicing._gather_translation_rule(ctx,avals_in,avals_out,operand,indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax._src.lax.slicing._gather_transpose_rule(t,operand,indices,*,dimension_numbers,slice_sizes,unique_indices,indices_are_sorted,mode,fill_value)
jax._src.lax.slicing._getslice(x,lo,hi)
jax._src.lax.slicing._getslice_padding_rule(in_avals,out_avals,x,lo,hi)
jax._src.lax.slicing._getslice_staging_rule(trace,x,lo,hi)
jax._src.lax.slicing._is_sorted(dims,op_name,name)
jax._src.lax.slicing._no_duplicate_dims(dims,op_name,name)
jax._src.lax.slicing._real_dtype(dtype)
jax._src.lax.slicing._scatter_add_jvp(primals,tangents,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_add_lower_gpu(ctx,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_add_translation_rule(ctx,avals_in,avals_out,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode,expand_complex128=False)
jax._src.lax.slicing._scatter_add_transpose_rule(t,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_batching_rule(scatter_op,batched_args,batch_dims,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_dimensions_proto(indices_shape:Sequence[int],dimension_numbers:ScatterDimensionNumbers)->xla_client.ScatterDimensionNumbers
jax._src.lax.slicing._scatter_dtype_rule(operand,indices,updates,**kwargs)
jax._src.lax.slicing._scatter_extremal_jvp(scatter_op,primals,tangents,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_jvp(primals,tangents,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_lower(ctx,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_mul_jvp_rhs(g,x,i,y,*,dimension_numbers,indices_are_sorted,unique_indices,mode,**kw)
jax._src.lax.slicing._scatter_mul_transpose_rule(t,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_shape_rule(operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_translation_rule(ctx,avals_in,avals_out,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._scatter_transpose_rule(t,operand,indices,updates,*,update_jaxpr,update_consts,dimension_numbers,indices_are_sorted,unique_indices,mode)
jax._src.lax.slicing._slice_batching_rule(batched_args,batch_dims,*,start_indices,limit_indices,strides)
jax._src.lax.slicing._slice_lower(ctx,x,*,start_indices,limit_indices,strides)
jax._src.lax.slicing._slice_masking_rule(padded_vals,logical_shapes,start_indices,limit_indices,strides)
jax._src.lax.slicing._slice_shape_rule(operand,*,start_indices,limit_indices,strides)
jax._src.lax.slicing._slice_translation_rule(ctx,avals_in,avals_out,operand,*,start_indices,limit_indices,strides)
jax._src.lax.slicing._slice_transpose_rule(t,operand,*,start_indices,limit_indices,strides)
jax._src.lax.slicing._sorted_dims_in_range(dims,rank,op_name,name)
jax._src.lax.slicing.dynamic_index_in_dim(operand:Array,index:Array,axis:int=0,keepdims:bool=True)->Array
jax._src.lax.slicing.dynamic_slice(operand:Array,start_indices:Sequence[Array],slice_sizes:Shape)->Array
jax._src.lax.slicing.dynamic_slice_in_dim(operand:Array,start_index:Array,slice_size:int,axis:int=0)->Array
jax._src.lax.slicing.dynamic_update_index_in_dim(operand:Array,update:Array,index:Array,axis:int)->Array
jax._src.lax.slicing.dynamic_update_slice(operand:Array,update:Array,start_indices:Array)->Array
jax._src.lax.slicing.dynamic_update_slice_in_dim(operand:Array,update:Array,start_index:Array,axis:int)->Array
jax._src.lax.slicing.gather(operand:Array,start_indices:Array,dimension_numbers:GatherDimensionNumbers,slice_sizes:Shape,*,unique_indices:bool=False,indices_are_sorted:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None,fill_value=None)->Array
jax._src.lax.slicing.getslice_impl(x,lo,hi)
jax._src.lax.slicing.index_in_dim(operand:Array,index:int,axis:int=0,keepdims:bool=True)->Array
jax._src.lax.slicing.index_take(src:Array,idxs:Array,axes:Sequence[int])->Array
jax._src.lax.slicing.scatter(operand:Array,scatter_indices:Array,updates:Array,dimension_numbers:ScatterDimensionNumbers,*,indices_are_sorted:bool=False,unique_indices:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None)->Array
jax._src.lax.slicing.scatter_add(operand:Array,scatter_indices:Array,updates:Array,dimension_numbers:ScatterDimensionNumbers,*,indices_are_sorted:bool=False,unique_indices:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None)->Array
jax._src.lax.slicing.scatter_apply(operand:Array,scatter_indices:Array,func:Callable[[Array],Array],dimension_numbers:ScatterDimensionNumbers,*,indices_are_sorted:bool=False,unique_indices:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None)->Array
jax._src.lax.slicing.scatter_max(operand:Array,scatter_indices:Array,updates:Array,dimension_numbers:ScatterDimensionNumbers,*,indices_are_sorted:bool=False,unique_indices:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None)->Array
jax._src.lax.slicing.scatter_min(operand:Array,scatter_indices:Array,updates:Array,dimension_numbers:ScatterDimensionNumbers,*,indices_are_sorted:bool=False,unique_indices:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None)->Array
jax._src.lax.slicing.scatter_mul(operand:Array,scatter_indices:Array,updates:Array,dimension_numbers:ScatterDimensionNumbers,*,indices_are_sorted:bool=False,unique_indices:bool=False,mode:Optional[Union[str,GatherScatterMode]]=None)->Array
jax._src.lax.slicing.slice(operand:Array,start_indices:Sequence[int],limit_indices:Sequence[int],strides:Optional[Sequence[int]]=None)->Array
jax._src.lax.slicing.slice_in_dim(operand:Array,start_index:Optional[int],limit_index:Optional[int],stride:int=1,axis:int=0)->Array


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/qdwh.py----------------------------------------
A:jax._src.lax.qdwh.y->jax._src.lax.linalg.cholesky(x, symmetrize_input=False)
A:jax._src.lax.qdwh.(q, _)->jax._src.lax.linalg.qr(y, full_matrices=False)
A:jax._src.lax.qdwh.q2->q[m:, :].T.conj()
A:jax._src.lax.qdwh.z->jax._src.lax.linalg.triangular_solve(y, z, left_side=True, lower=True, transpose_a=True, conjugate_a=True).T.conj()
A:jax._src.lax.qdwh.alpha->jax.numpy.sqrt(jnp.linalg.norm(x, ord=1) * jnp.linalg.norm(x, ord=jnp.inf))
A:jax._src.lax.qdwh.tol_norm->jax.numpy.cbrt(tol_l)
A:jax._src.lax.qdwh.dd->jax.numpy.cbrt(4.0 * (1.0 / l2 - 1.0) / l2)
A:jax._src.lax.qdwh.sqd->jax.numpy.sqrt(1.0 + dd)
A:jax._src.lax.qdwh.a->jax.numpy.real(a)
A:jax._src.lax.qdwh.u->jax.lax.cond(c > 100, true_fn, false_fn, operand=u)
A:jax._src.lax.qdwh.is_unconverged->jax.numpy.logical_or(iterating_l, iterating_u)
A:jax._src.lax.qdwh.(u, _, num_iters, is_unconverged, _)->jax.lax.while_loop(cond_fun=cond_fun, body_fun=body_fun, init_val=(u, l, iter_idx, is_unconverged, is_not_max_iteration))
A:jax._src.lax.qdwh.is_converged->jax.numpy.logical_not(is_unconverged)
A:jax._src.lax.qdwh.max_iterations->jax.core.concrete_or_error(int, max_iterations, 'The `max_iterations` argument must be statically specified to use `qdwh` within JAX transformations.')
A:jax._src.lax.qdwh.is_symmetric->jax.core.concrete_or_error(bool, is_symmetric, 'The `is_symmetric` argument must be statically specified to use `qdwh` within JAX transformations.')
A:jax._src.lax.qdwh.(u, h, num_iters, is_converged)->_qdwh(x, is_symmetric, max_iterations)
jax._src.lax.qdwh._qdwh(x,is_symmetric,max_iterations)
jax._src.lax.qdwh._use_cholesky(u,params)
jax._src.lax.qdwh._use_qr(u,params)
jax._src.lax.qdwh.qdwh(x,is_symmetric,max_iterations=10)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/svd.py----------------------------------------
A:jax._src.lax.svd.(u, h, _, _)->jax.lax.linalg.qdwh(a, is_hermitian, max_iterations)
A:jax._src.lax.svd.(v, s)->jax.lax.linalg.eigh(h)
A:jax._src.lax.svd.s_out->jax.numpy.flip(s)
A:jax._src.lax.svd.v_out->jax.numpy.fliplr(v)
A:jax._src.lax.svd.(u_out, r)->jax.lax.linalg.qr(u_out, full_matrices=False)
A:jax._src.lax.svd.u_out->jax.lax.cond(s[0] < a.shape[1] * eps * s_out[0], correct_rank_deficiency, lambda u_out: u_out, operand=u_out)
A:jax._src.lax.svd.is_hermitian->jax.core.concrete_or_error(bool, is_hermitian, 'The `is_hermitian` argument must be statically specified to use `qdwh` within JAX transformations.')
A:jax._src.lax.svd.max_iterations->jax.core.concrete_or_error(int, max_iterations, 'The `max_iterations` argument must be statically specified to use `qdwh` within JAX transformations.')
A:jax._src.lax.svd.a->a.T.conj().T.conj()
A:jax._src.lax.svd.(q, a)->jax.lax.linalg.qr(a, full_matrices=False)
A:jax._src.lax.svd.(u_out, s_out, v_out)->_svd(a, is_hermitian, max_iterations)
jax._src.lax.svd._svd(a:jnp.ndarray,is_hermitian:bool,max_iterations:int)->Sequence[jnp.ndarray]
jax._src.lax.svd.svd(a:jnp.ndarray,is_hermitian:bool=False,max_iterations:int=10)->Sequence[jnp.ndarray]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/other.py----------------------------------------
A:jax._src.lax.other.filter_shape->tuple(filter_shape)
A:jax._src.lax.other.dimension_numbers->jax._src.lax.convolution.conv_dimension_numbers(lhs.shape, (1, 1) + filter_shape, dimension_numbers)
A:jax._src.lax.other.spatial_size->prod(filter_shape)
A:jax._src.lax.other.rhs->jax._src.numpy.lax_numpy.moveaxis(rhs, (0, 1), (rhs_spec[0], rhs_spec[1]))
A:jax._src.lax.other.out->jax._src.numpy.lax_numpy.moveaxis(out, (-2, -1), (out_spec[0], out_spec[1]))
A:jax._src.lax.other.c_precision->jax._src.lax.lax.canonicalize_precision(precision)
A:jax._src.lax.other.lhs_precision->type_cast(Optional[lax.PrecisionType], c_precision[0] if isinstance(c_precision, tuple) and len(c_precision) == 2 else c_precision)
A:jax._src.lax.other.patches->conv_general_dilated_patches(lhs=lhs, filter_shape=filter_shape, window_strides=window_strides, padding=padding, lhs_dilation=lhs_dilation, rhs_dilation=rhs_dilation, dimension_numbers=dimension_numbers, precision=lhs_precision)
A:jax._src.lax.other.(lhs_spec, rhs_spec, out_spec)->jax._src.lax.convolution.conv_dimension_numbers(lhs.shape, (1, 1) + tuple(filter_shape), dimension_numbers)
A:jax._src.lax.other.lhs_b_dims->sorted(lhs_b_dims)
jax._src.lax.other.conv_general_dilated_local(lhs:jnp.ndarray,rhs:jnp.ndarray,window_strides:Sequence[int],padding:Union[str,Sequence[Tuple[int,int]]],filter_shape:Sequence[int],lhs_dilation:Optional[Sequence[int]]=None,rhs_dilation:Optional[Sequence[int]]=None,dimension_numbers:Optional[convolution.ConvGeneralDilatedDimensionNumbers]=None,precision:lax.PrecisionLike=None)->jnp.ndarray
jax._src.lax.other.conv_general_dilated_patches(lhs:lax.Array,filter_shape:Sequence[int],window_strides:Sequence[int],padding:Union[str,Sequence[Tuple[int,int]]],lhs_dilation:Optional[Sequence[int]]=None,rhs_dilation:Optional[Sequence[int]]=None,dimension_numbers:Optional[convolution.ConvGeneralDilatedDimensionNumbers]=None,precision:Optional[lax.PrecisionType]=None,preferred_element_type:Optional[DType]=None)->lax.Array


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/lax.py----------------------------------------
A:jax._src.lax.lax.T->TypeVar('T')
A:jax._src.lax.lax.checked->canonicalize_shape(shape)
A:jax._src.lax.lax._->tuple(map(_check_static_shape, shapes))
A:jax._src.lax.lax.result_shape[i]->next(iter(non_1s), 1)
A:jax._src.lax.lax.ndim->numpy.ndim(array)
A:jax._src.lax.lax.result_shape->broadcast_shapes(np.shape(x), np.shape(y))
A:jax._src.lax.lax.rounding_method->RoundingMethod(rounding_method)
A:jax._src.lax.lax.operand->jax.interpreters.batching.moveaxis(operand, bdim, 0)
A:jax._src.lax.lax.old_dtype->jax._src.dtypes.canonicalize_dtype(operand.dtype)
A:jax._src.lax.lax.old_weak_type->jax._src.dtypes.is_weakly_typed(operand)
A:jax._src.lax.lax.new_dtype->jax._src.dtypes.canonicalize_dtype(new_dtype)
A:jax._src.lax.lax.new_weak_type->bool(weak_type)
A:jax._src.lax.lax.DEFAULT->_enum_descriptor('default')
A:jax._src.lax.lax.HIGH->_enum_descriptor('high')
A:jax._src.lax.lax.HIGHEST->_enum_descriptor('highest')
A:jax._src.lax.lax.arg0->self._strings.get(arg0, arg0)
A:jax._src.lax.lax.dims->numpy.delete(np.arange(prototype_arg.ndim), new_bdim)
A:jax._src.lax.lax.shape->jax.core.canonicalize_shape(shape)
A:jax._src.lax.lax.new_sizes->tuple(new_sizes)
A:jax._src.lax.lax.same_shape->jax.core.symbolic_equal_shape(np.shape(operand), new_sizes)
A:jax._src.lax.lax.permutation->tuple((operator.index(d) for d in permutation))
A:jax._src.lax.lax.(flat_operands, operand_tree)->jax.tree_util.tree_flatten(operands)
A:jax._src.lax.lax.(flat_init_values, init_value_tree)->jax.tree_util.tree_flatten(init_values)
A:jax._src.lax.lax.monoid_reducer->_get_monoid_reducer(computation, flat_init_values)
A:jax._src.lax.lax.flat_init_avals->safe_map(_abstractify, flat_init_values)
A:jax._src.lax.lax.(jaxpr, consts, out_tree)->_variadic_reduction_jaxpr(computation, tuple(flat_init_avals), init_value_tree)
A:jax._src.lax.lax.out->lower_comparator(sub_ctx, *[[a] for a in comparator.arguments], num_keys=num_keys)
A:jax._src.lax.lax.pval->jax.interpreters.partial_eval.PartialVal.unknown(aval)
A:jax._src.lax.lax.result->jax.interpreters.xla.lower_fun(partial(_sort_lt_comparator, num_keys=num_keys), backend=ctx.platform, multiple_results=False)(subc, *params)
A:jax._src.lax.lax.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(flat_comp, tuple(flat_in_avals))
A:jax._src.lax.lax.avals->jax.tree_util.tree_unflatten(aval_tree, flat_avals)
A:jax._src.lax.lax.(flat_in_avals, in_tree)->jax.tree_util.tree_flatten((avals, avals))
A:jax._src.lax.lax.comp->jax.linear_util.wrap_init(computation)
A:jax._src.lax.lax.(flat_comp, out_tree)->jax._src.api_util.flatten_fun_nokwargs(comp, in_tree)
A:jax._src.lax.lax.aval->jax.core.DShapedArray(tuple(out_shape_for_tracer), x.dtype, x.weak_type)
A:jax._src.lax.lax.dtype->_dtype(example)
A:jax._src.lax.lax.dimension->kwargs.pop('dimension')
A:jax._src.lax.lax.(k, v)->Primitive('sort').bind(keys, values, dimension=dimension, is_stable=is_stable, num_keys=1)
A:jax._src.lax.lax.k->int(k)
A:jax._src.lax.lax.fill_value->_convert_element_type(fill_value, dtype, weak_type)
A:jax._src.lax.lax.scalar_zero->_convert_element_type(0, aval.dtype, aval.weak_type)
A:jax._src.lax.lax.(size,)->canonicalize_shape((size,))
A:jax._src.lax.lax.offset->int(offset)
A:jax._src.lax.lax.bool_eye->eq(add(broadcasted_iota(np.int32, shape, 0), np.int32(offset)), broadcasted_iota(np.int32, shape, 1))
A:jax._src.lax.lax.axes->frozenset(axes)
A:jax._src.lax.lax.base_shape->tuple(np.take(shape, axes))
A:jax._src.lax.lax.bool_tri->ge(add(broadcasted_iota(np.int32, shape, 0), np.int32(offset)), broadcasted_iota(np.int32, shape, 1))
A:jax._src.lax.lax.exponent_bits->operator.index(exponent_bits)
A:jax._src.lax.lax.mantissa_bits->operator.index(mantissa_bits)
A:jax._src.lax.lax.dimensions->tuple(np.add(1, dimensions))
A:jax._src.lax.lax.dims_set->set(dimensions)
A:jax._src.lax.lax.size->next((x.shape[ax] for (x, ax) in zip(batched_args, batch_dims) if ax is not None))
A:jax._src.lax.lax.batch->tuple(range(lhs.ndim - 2))
A:jax._src.lax.lax.ShapedArray.broadcast->jax.core.aval_method(broadcast)
A:jax._src.lax.lax.ShapedArray.transpose->jax.core.aval_method(transpose)
A:jax._src.lax.lax.ShapedArray.reshape->jax.core.aval_method(reshape)
A:jax._src.lax.lax.n->numpy.prod(input_shape[list(axes)])
A:jax._src.lax.lax.ShapedArray._iter->staticmethod(_iter)
A:jax._src.lax.lax.typename->str(np.dtype(dtype).name)
A:jax._src.lax.lax.dtype_rule->partial(naryop_dtype_rule, result_dtype, accepted_dtypes, name)
A:jax._src.lax.lax.weak_type_rule->partial(_naryop_weak_type_rule, name)
A:jax._src.lax.lax.prim->standard_primitive(shape_rule, dtype_rule, name, translation_rule=translation_rule, weak_type_rule=weak_type_rule)
A:jax._src.lax.lax.standard_unop->partial(unop, _identity)
A:jax._src.lax.lax.typenames->', '.join((t.__name__ for t in types))
A:jax._src.lax.lax.pos->next((i for (i, aval) in enumerate(avals) if aval.dtype is dtypes.float0))
A:jax._src.lax.lax.shape_rule->partial(_broadcasting_shape_rule, name)
A:jax._src.lax.lax.standard_naryop->partial(naryop, _input_dtype)
A:jax._src.lax.lax.bcast_dims->tuple(range(len(aval_out.shape) - len(aval_in.shape), len(aval_out.shape)))
A:jax._src.lax.lax.arg->xops.BroadcastInDim(arg, aval_out.shape, bcast_dims)
A:jax._src.lax.lax.x_shape->numpy.shape(x)
A:jax._src.lax.lax.broadcasted_args->broadcast_mhlo(aval_out, ctx.avals_in, args)
A:jax._src.lax.lax.neg_p->standard_unop(_num, 'neg')
A:jax._src.lax.lax.zero->xops.Constant(c, np.array(0, dtype=dtype))
A:jax._src.lax.lax.sign_p->standard_unop(_num, 'sign', translation_rule=_sign_translation_rule)
A:jax._src.lax.lax._nextafter_translation_rule->partial(_broadcast_translate, xops.NextAfter)
A:jax._src.lax.lax.nextafter_p->standard_naryop([_float, _float], 'nextafter', translation_rule=_nextafter_translation_rule)
A:jax._src.lax.lax.floor_p->standard_unop(_float, 'floor')
A:jax._src.lax.lax.ceil_p->standard_unop(_float, 'ceil')
A:jax._src.lax.lax.half->_const(x, 0.5)
A:jax._src.lax.lax.one->jax.interpreters.xla.pyval_to_ir_constant(ctx.builder, np.array(1, dtype=x_aval.dtype))
A:jax._src.lax.lax.round_val->floor(x)
A:jax._src.lax.lax.nearest_even_int->sub(round_val, mul(_const(x, 2), floor(mul(half, x))))
A:jax._src.lax.lax.is_odd->eq(nearest_even_int, one)
A:jax._src.lax.lax.rounding_fun->jax.interpreters.xla.lower_fun(_round_to_nearest_even, multiple_results=False, new_style=True)
A:jax._src.lax.lax.round_p->standard_unop(_float, 'round')
A:jax._src.lax.lax.round_nearest->jax.interpreters.mlir.cache_lowering(mlir.lower_fun(_round_to_nearest_even, multiple_results=False))
A:jax._src.lax.lax.is_finite_p->unop(_fixed_dtype(np.bool_), _float, 'is_finite')
A:jax._src.lax.lax.exp_p->standard_unop(_float | _complex, 'exp')
A:jax._src.lax.lax.log_p->standard_unop(_float | _complex, 'log')
A:jax._src.lax.lax.expm1_p->standard_unop(_float | _complex, 'expm1')
A:jax._src.lax.lax.log1p_p->standard_unop(_float | _complex, 'log1p')
A:jax._src.lax.lax.tanh_p->standard_unop(_float | _complex, 'tanh')
A:jax._src.lax.lax.sin_p->standard_unop(_float | _complex, 'sin')
A:jax._src.lax.lax.cos_p->standard_unop(_float | _complex, 'cos')
A:jax._src.lax.lax.tan_p->standard_unop(_float | _complex, 'tan', translation_rule=xla.lower_fun(_tan_impl, multiple_results=False, new_style=True))
A:jax._src.lax.lax.asin_p->standard_unop(_float | _complex, 'asin', translation_rule=xla.lower_fun(asin_impl, multiple_results=False, new_style=True))
A:jax._src.lax.lax.rpart->real(result)
A:jax._src.lax.lax.acos_p->standard_unop(_float | _complex, 'acos', translation_rule=xla.lower_fun(acos_impl, multiple_results=False, new_style=True))
A:jax._src.lax.lax.atan_p->standard_unop(_float | _complex, 'atan', translation_rule=xla.lower_fun(atan_impl, multiple_results=False, new_style=True))
A:jax._src.lax.lax.atan2_p->standard_naryop([_float | _complex, _float | _complex], 'atan2')
A:jax._src.lax.lax.sinh_p->standard_unop(_float | _complex, 'sinh')
A:jax._src.lax.lax.cosh_p->standard_unop(_float | _complex, 'cosh')
A:jax._src.lax.lax.asinh_p->standard_unop(_float | _complex, 'asinh')
A:jax._src.lax.lax.acosh_p->standard_unop(_float | _complex, 'acosh')
A:jax._src.lax.lax.atanh_p->standard_unop(_float | _complex, 'atanh')
A:jax._src.lax.lax.regularized_incomplete_beta_p->standard_naryop([_float, _float, _float], 'regularized_incomplete_beta', translation_rule=partial(_broadcast_translate, xops.RegularizedIncompleteBeta))
A:jax._src.lax.lax.partial_x->exp((b - 1) * log1p(-x) + (a - 1) * log(x) - lbeta)
A:jax._src.lax.lax.lgamma_p->standard_unop(_float, 'lgamma')
A:jax._src.lax.lax.digamma_p->standard_unop(_float, 'digamma')
A:jax._src.lax.lax.igamma_p->standard_naryop([_float, _float], 'igamma', translation_rule=partial(_broadcast_translate, xops.Igamma))
A:jax._src.lax.lax.igamma_grad_a_p->standard_naryop([_float, _float], 'igamma_grad_a', translation_rule=partial(_broadcast_translate, xops.IgammaGradA))
A:jax._src.lax.lax.igammac_p->standard_naryop([_float, _float], 'igammac', translation_rule=partial(_broadcast_translate, xops.Igammac))
A:jax._src.lax.lax.random_gamma_grad_p->standard_naryop([_float, _float], 'random_gamma_grad', translation_rule=partial(_broadcast_translate, xops.RandomGammaGrad))
A:jax._src.lax.lax.bessel_i0e_p->standard_unop(_float, 'bessel_i0e')
A:jax._src.lax.lax.bessel_i1e_p->standard_unop(_float, 'bessel_i1e')
A:jax._src.lax.lax.safe_x->select(x_is_not_tiny, x, full_like(x, eps))
A:jax._src.lax.lax.dy_dx->select(x_is_not_tiny, dy_dx, full_like(x, 0.5))
A:jax._src.lax.lax.erf_p->standard_unop(_float, 'erf')
A:jax._src.lax.lax.erfc_p->standard_unop(_float, 'erfc')
A:jax._src.lax.lax.erf_inv_p->standard_unop(_float, 'erf_inv')
A:jax._src.lax.lax.real_p->unop(_complex_basetype, _complex, 'real')
A:jax._src.lax.lax.imag_p->unop(_complex_basetype, _complex, 'imag')
A:jax._src.lax.lax.complex_p->naryop(_complex_dtype, [_complex_elem_types, _complex_elem_types], 'complex')
A:jax._src.lax.lax.conj_p->unop(_complex_dtype, _complex_elem_types | _complex, 'conj')
A:jax._src.lax.lax.ad.primitive_jvps[conj_p]->partial(ad.linear_jvp, conj_p)
A:jax._src.lax.lax.abs_p->unop(_complex_basetype, _num, 'abs')
A:jax._src.lax.lax.sqrt_p->standard_unop(_float | _complex, 'sqrt')
A:jax._src.lax.lax.rsqrt_p->standard_unop(_float | _complex, 'rsqrt')
A:jax._src.lax.lax.cbrt_p->standard_unop(_float, 'cbrt')
A:jax._src.lax.lax.pow_p->standard_naryop([_float | _complex, _float | _complex], 'pow')
A:jax._src.lax.lax.jac->mul(y, pow(x, select(eq(y, _zeros(y)), _ones(y), sub(y, _ones(y)))))
A:jax._src.lax.lax.x->convert_element_type(x, np.float32)
A:jax._src.lax.lax.integer_pow_p->standard_primitive(_attrgetter('shape'), _integer_pow_dtype_rule, 'integer_pow', translation_rule=_integer_pow_translation_rule)
A:jax._src.lax.lax.lowering->jax.interpreters.mlir.cache_lowering(lowering)
A:jax._src.lax.lax.not_p->standard_unop(_bool_or_int, 'not')
A:jax._src.lax.lax.and_p->standard_naryop([_bool_or_int, _bool_or_int], 'and')
A:jax._src.lax.lax.or_p->standard_naryop([_bool_or_int, _bool_or_int], 'or')
A:jax._src.lax.lax.xor_p->standard_naryop([_bool_or_int, _bool_or_int], 'xor')
A:jax._src.lax.lax.population_count_p->standard_unop(_int, 'population_count')
A:jax._src.lax.lax.clz_p->standard_unop(_int, 'clz')
A:jax._src.lax.lax.primal_out->sub(x, y)
A:jax._src.lax.lax.sub_p->standard_naryop([_num, _num], 'sub')
A:jax._src.lax.lax.mul_p->standard_naryop([_num, _num], 'mul')
A:jax._src.lax.lax.div_p->standard_naryop([_num, _num], 'div')
A:jax._src.lax.lax.rem_p->standard_naryop([_num, _num], 'rem')
A:jax._src.lax.lax.y->_maybe_broadcast(result_shape, y)
A:jax._src.lax.lax.rx->real(x)
A:jax._src.lax.lax.ry->real(y)
A:jax._src.lax.lax.pick_x->select(eq(rx, ry), lax_cmp_pick_x(imag(x), imag(y)), lax_cmp_pick_x(rx, ry))
A:jax._src.lax.lax.shift_left_p->standard_naryop([_int, _int], 'shift_left')
A:jax._src.lax.lax.shift_right_arithmetic_p->standard_naryop([_int, _int], 'shift_right_arithmetic')
A:jax._src.lax.lax.shift_right_logical_p->standard_naryop([_int, _int], 'shift_right_logical')
A:jax._src.lax.lax.(x, y)->broadcast_mhlo(aval_out.update(dtype=x_aval.dtype), ctx.avals_in, (x, y))
A:jax._src.lax.lax.eq_p->naryop(_fixed_dtype(np.bool_), [_any, _any], 'eq')
A:jax._src.lax.lax.ne_p->naryop(_fixed_dtype(np.bool_), [_any, _any], 'ne')
A:jax._src.lax.lax.ge_p->naryop(_fixed_dtype(np.bool_), [_any, _any], 'ge')
A:jax._src.lax.lax.gt_p->naryop(_fixed_dtype(np.bool_), [_any, _any], 'gt')
A:jax._src.lax.lax.le_p->naryop(_fixed_dtype(np.bool_), [_any, _any], 'le')
A:jax._src.lax.lax.lt_p->naryop(_fixed_dtype(np.bool_), [_any, _any], 'lt')
A:jax._src.lax.lax.new_etype->jax.interpreters.xla.dtype_to_primitive_type(new_dtype)
A:jax._src.lax.lax.convert_element_type_p->Primitive('convert_element_type')
A:jax._src.lax.lax.aval_in->aval_in.update(dtype=_real_dtype(aval_in.dtype)).update(dtype=_real_dtype(aval_in.dtype))
A:jax._src.lax.lax.bitcast_convert_type_p->standard_primitive(_bitcast_convert_type_shape_rule, _bitcast_convert_type_dtype_rule, 'bitcast_convert_type', _bitcast_convert_type_translation_rule, weak_type_rule=_strip_weak_type)
A:jax._src.lax.lax.config->jax._src.lib.xla_client.PrecisionConfig()
A:jax._src.lax.lax.lhs_batch_shape->tuple((lhs.shape[i] for i in lhs_batch))
A:jax._src.lax.lax.rhs_batch_shape->tuple((rhs.shape[i] for i in rhs_batch))
A:jax._src.lax.lax.lhs_contracting_shape->tuple((lhs.shape[i] for i in lhs_contracting))
A:jax._src.lax.lax.rhs_contracting_shape->tuple((rhs.shape[i] for i in rhs_contracting))
A:jax._src.lax.lax.batch_shape->tuple((lhs_shape[i] for i in lhs_batch))
A:jax._src.lax.lax.lhs_contract_or_batch->tuple(sorted(tuple(lhs_contracting) + tuple(lhs_batch)))
A:jax._src.lax.lax.lhs_tensored_shape->tuple_delete(lhs_shape, lhs_contract_or_batch)
A:jax._src.lax.lax.rhs_contract_or_batch->tuple(sorted(tuple(rhs_contracting) + tuple(rhs_batch)))
A:jax._src.lax.lax.rhs_tensored_shape->tuple_delete(rhs_shape, rhs_contract_or_batch)
A:jax._src.lax.lax.idx_->set(idx)
A:jax._src.lax.lax.input_dtype->naryop_dtype_rule(_input_dtype, [_any, _any], 'dot_general', lhs, rhs)
A:jax._src.lax.lax.x_kept->remaining(range(x_ndim), x_contract, x_batch)
A:jax._src.lax.lax.y_kept->remaining(range(y.ndim), y_contract, y_batch)
A:jax._src.lax.lax.(ans_batch, ans_y, _)->ranges_like(x_batch, y_kept, x_kept)
A:jax._src.lax.lax.(ans_batch, _, ans_y)->ranges_like(x_batch, x_kept, y_kept)
A:jax._src.lax.lax.x_contract_sorted_by_y->list(np.take(x_contract, np.argsort(y_contract)))
A:jax._src.lax.lax.out_axes->numpy.argsort(list(x_batch) + x_kept + x_contract_sorted_by_y)
A:jax._src.lax.lax.(new_dimension_numbers, result_batch_dim)->_dot_general_batch_dim_nums((lhs.ndim, rhs.ndim), batch_dims, dimension_numbers)
A:jax._src.lax.lax.batched_out->dot_general(lhs, rhs, new_dimension_numbers, precision=precision, preferred_element_type=preferred_element_type)
A:jax._src.lax.lax.lhs_contract->bump_dims(lhs_contract, lbd)
A:jax._src.lax.lax.rhs_contract->bump_dims(rhs_contract, rbd)
A:jax._src.lax.lax.other->tuple((d for d in range(rhs_ndim) if d not in rhs_batch and d not in rhs_contract))
A:jax._src.lax.lax.lhs_batch->bump_dims(lhs_batch, lbd)
A:jax._src.lax.lax.rhs_batch->bump_dims(rhs_batch, rbd)
A:jax._src.lax.lax.preferred_element_type->jax.interpreters.xla.dtype_to_primitive_type(preferred_element_type)
A:jax._src.lax.lax.lhs->xops.ConvertElementType(lhs, xla.dtype_to_primitive_type(np.dtype(np.float32)))
A:jax._src.lax.lax.rhs->xops.ConvertElementType(rhs, xla.dtype_to_primitive_type(np.dtype(np.float32)))
A:jax._src.lax.lax.lhs_->_replace_masked_values(lhs, 0, padded_axes)
A:jax._src.lax.lax.dot_general_p->standard_primitive(_dot_general_shape_rule, _dot_general_dtype_rule, 'dot_general', _dot_general_translation_rule)
A:jax._src.lax.lax.f32->jax.interpreters.mlir.dtype_to_ir_type(np.dtype(np.float32))
A:jax._src.lax.lax.dot_dnums->jax._src.lib.mlir.dialects.mhlo.DotDimensionNumbers.get(lhs_batching_dimensions=list(lhs_batch), rhs_batching_dimensions=list(rhs_batch), lhs_contracting_dimensions=list(lhs_contracting), rhs_contracting_dimensions=list(rhs_contracting))
A:jax._src.lax.lax.operand_ndim->numpy.ndim(operand)
A:jax._src.lax.lax.unit_dimensions->tuple((i for (i, s) in enumerate(shape_in) if core.symbolic_equal_dim(s, 1)))
A:jax._src.lax.lax.bdims->tuple(np.delete(broadcast_dimensions, unit_dimensions))
A:jax._src.lax.lax.new_operand->jax.interpreters.batching.moveaxis(operand, bdim, 0)
A:jax._src.lax.lax.params->dict(shape=shape, broadcast_dimensions=broadcast_dimensions)
A:jax._src.lax.lax.source_info->jax._src.source_info_util.current()
A:jax._src.lax.lax.ds->iter(dyn_shape)
A:jax._src.lax.lax.out_tracer->jax.interpreters.partial_eval.DynamicJaxprTracer(trace, aval, source_info)
A:jax._src.lax.lax.eqn->jax.interpreters.partial_eval.new_jaxpr_eqn(invars, [trace.makevar(out_tracer)], broadcast_in_dim_p, params, core.no_effects, source_info)
A:jax._src.lax.lax.broadcast_in_dim_p->standard_primitive(_broadcast_in_dim_shape_rule, _input_dtype, 'broadcast_in_dim')
A:jax._src.lax.lax._clamp_dtype_rule->partial(naryop_dtype_rule, _input_dtype, [_any, _any, _any], 'clamp')
A:jax._src.lax.lax.min->broadcast_in_dim(min, x.shape, [0])
A:jax._src.lax.lax.max->broadcast_in_dim(max, x.shape, [0])
A:jax._src.lax.lax.clamp_p->standard_primitive(_clamp_shape_rule, _clamp_dtype_rule, 'clamp')
A:jax._src.lax.lax.op->jax._src.lib.mlir.dialects.mhlo.ReduceOp([mlir.aval_to_ir_type(aval_out)], [x], mlir.ir_constants(unit_factory(aval_out.dtype)), mlir.dense_int_elements(axes))
A:jax._src.lax.lax.limit_points->numpy.cumsum([shape[dimension] for shape in operand_shapes]).tolist()
A:jax._src.lax.lax.starts->numpy.zeros((len(operands), t.ndim), dtype=int).tolist()
A:jax._src.lax.lax.limits->numpy.tile(t.shape, (len(operands), 1)).tolist()
A:jax._src.lax.lax.concatenate_p->standard_primitive(_concatenate_shape_rule, _concatenate_dtype_rule, 'concatenate', _concatenate_translation_rule)
A:jax._src.lax.lax.op_shape->numpy.shape(operand)
A:jax._src.lax.lax.(lo, hi, interior)->zip(*padding_config)
A:jax._src.lax.lax.unpad_config->safe_zip(np.negative(lo), np.negative(hi), np.zeros_like(interior))
A:jax._src.lax.lax.unpadded->pad(t, np.array(0.0, t.dtype), unpad_config)
A:jax._src.lax.lax.padding_config->list(padding_config)
A:jax._src.lax.lax.mask->_reduce(operator.and_, masks)
A:jax._src.lax.lax.broadcasted_padding->broadcast_in_dim(padding_value, x.shape, (operand_bdim,))
A:jax._src.lax.lax.pad_p->standard_primitive(_pad_shape_rule, _pad_dtype_rule, 'pad', translation_rule=_pad_translation_rule)
A:jax._src.lax.lax.(low, high, interior)->jax._src.util.unzip3(padding_config)
A:jax._src.lax.lax.squeeze_p->standard_primitive(_squeeze_shape_rule, _squeeze_dtype_rule, 'squeeze', _squeeze_translation_rule)
A:jax._src.lax.lax.d2->next(new, None)
A:jax._src.lax.lax.reshape_p->standard_primitive(_reshape_shape_rule, _reshape_dtype_rule, 'reshape', _reshape_translation_rule)
A:jax._src.lax.lax.rev_p->standard_primitive(_rev_shape_rule, _input_dtype, 'rev')
A:jax._src.lax.lax.transpose_p->standard_primitive(_transpose_shape_rule, _input_dtype, 'transpose')
A:jax._src.lax.lax.zeros->full_like(t, 0)
A:jax._src.lax.lax.which->broadcast_in_dim(which, cases[0].shape, [0])
A:jax._src.lax.lax.out_dot->select_n(which, *case_tangents)
A:jax._src.lax.lax.z->_zeros(next((t for t in case_tangents if type(t) is not ad_util.Zero)))
A:jax._src.lax.lax.cutoff->jax.interpreters.xla.pyval_to_ir_constant(ctx.builder, np.array(offset + mid, dtype=which_aval.dtype))
A:jax._src.lax.lax.pred->jax.interpreters.mlir.compare_mhlo(which, mlir.full_like_aval(offset + mid, which_aval), lt, compare_type)
A:jax._src.lax.lax.select_n_p->standard_primitive(_select_shape_rule, _select_dtype_rule, 'select_n', weak_type_rule=_select_weak_type_rule, translation_rule=_select_xla_translation)
A:jax._src.lax.lax.(operand_avals, init_val_avals)->split_list(avals, [len(avals) // 2])
A:jax._src.lax.lax.(operands, init_values)->jax._src.util.split_list(values, [len(values) // 2])
A:jax._src.lax.lax.xla_computation->_reduction_computation(ctx, jaxpr, consts, init_values, singleton=False)
A:jax._src.lax.lax.(operand_bdims, init_value_bdims)->split_list(batch_dims, [num_operands])
A:jax._src.lax.lax.shapes->' '.join((str(a.shape) for a in args))
A:jax._src.lax.lax.axis_env->jax.interpreters.xla.AxisEnv(1, (), ())
A:jax._src.lax.lax.subc->xc.XlaBuilder('sort_lt_comparator')
A:jax._src.lax.lax.ctx->jax.interpreters.xla.TranslationContext(subc, platform, axis_env, new_name_stack())
A:jax._src.lax.lax.out_nodes->jax.interpreters.mlir.jaxpr_subcomp(reducer_ctx, jaxpr, consts, *([a] for a in reducer.arguments))
A:jax._src.lax.lax.input_shape->numpy.array(primals[0].shape, dtype=np.int_)
A:jax._src.lax.lax.non_axes->numpy.delete(np.arange(len(input_shape)), axes)
A:jax._src.lax.lax.primals->Primitive('sort').bind(*primals + (iotas[dimension],), dimension=dimension, is_stable=is_stable, num_keys=num_keys)
A:jax._src.lax.lax.tangents->tuple((reshape(t, new_shape, permutation) for t in tangents))
A:jax._src.lax.lax.reducer->jax._src.lib.mlir.dialects.mhlo.ReduceOp([mlir.aval_to_ir_type(aval_out)], [x], mlir.ir_constants(unit_factory(aval_out.dtype)), mlir.dense_int_elements(axes)).regions[0].blocks.append(*ir_types + ir_types)
A:jax._src.lax.lax.xs->xops.GetTupleElement(xs_and_token, 0)
A:jax._src.lax.lax.(primal_xs, init_values)->split_list(primals, [len(primals) // 2])
A:jax._src.lax.lax.(tangent_xs, tangent_init)->split_list(tangents, [len(tangents) // 2])
A:jax._src.lax.lax.masking.masking_rules[prim]->partial(_reducer_masking_rule, prim, identity)
A:jax._src.lax.lax.padded_shape->jax.interpreters.masking.padded_shape_as_value(padded_val.shape)
A:jax._src.lax.lax.masked_val->select(mask, padded_val, identity(padded_shape, padded_val.dtype))
A:jax._src.lax.lax.prim_bind->partial(prim.bind, **reduce_kwargs)
A:jax._src.lax.lax.(operand_avals, init_avals)->split_list(avals, [num_operands])
A:jax._src.lax.lax.join->jax.core.join_named_shapes(*(a.named_shape for a in operand_avals))
A:jax._src.lax.lax.reduce_p->jax.core.Primitive('reduce')
A:jax._src.lax.lax.reducer_ctx->jax.interpreters.xla.TranslationContext(subc, platform, axis_env, new_name_stack()).module_context.replace(name_stack='')
A:jax._src.lax.lax.scalar->ShapedArray((), np.bool_)
A:jax._src.lax.lax.broadcast_dimensions->tuple(np.delete(np.arange(len(input_shape)), axes))
A:jax._src.lax.lax.masked_operand->_replace_masked_values(operand, 0, padded_axes)
A:jax._src.lax.lax.reduce_sum_p->standard_primitive(_reduce_sum_shape_rule, partial(_reduce_number_dtype_rule, 'reduce_sum'), 'reduce_sum', _reduce_sum_translation_rule)
A:jax._src.lax.lax.(primals_out, tangents_out)->_reduce_jvp(reducer, [_const(primals[0], 1)], primals, tangents, axes)
A:jax._src.lax.lax.reduce_prod_p->standard_primitive(_reduce_op_shape_rule, partial(_reduce_number_dtype_rule, 'reduce_prod'), 'reduce_prod', _reduce_prod_translation_rule)
A:jax._src.lax.lax.location_indicators->convert_element_type(_eq_meet(operand, reshape(ans, shape)), g.dtype)
A:jax._src.lax.lax.counts->_reduce_sum(location_indicators, axes)
A:jax._src.lax.lax._reduce_max_translation_rule->partial(_reduce_chooser_translation_rule, max_p, _get_max_identity)
A:jax._src.lax.lax.reduce_max_p->standard_primitive(_reduce_op_shape_rule, _input_dtype, 'reduce_max', _reduce_max_translation_rule)
A:jax._src.lax.lax._reduce_min_translation_rule->partial(_reduce_chooser_translation_rule, min_p, _get_min_identity)
A:jax._src.lax.lax.reduce_min_p->standard_primitive(_reduce_op_shape_rule, _input_dtype, 'reduce_min', _reduce_min_translation_rule)
A:jax._src.lax.lax.indices->broadcasted_iota(index_dtype, np.shape(operand), axis)
A:jax._src.lax.lax.pick_op_val->bitwise_or(value_comparator(op_val, acc_val), ne(op_val, op_val))
A:jax._src.lax.lax.pick_op_index->bitwise_or(pick_op_val, bitwise_and(eq(op_val, acc_val), lt(op_index, acc_index)))
A:jax._src.lax.lax.res->reduce([operand, indices], [get_identity(operand.dtype), np.array(0, index_dtype)], reducer_fn, axes)
A:jax._src.lax.lax._argmin_translation_rule->jax.interpreters.xla.lower_fun(partial(_compute_argminmax, lt, _get_min_identity), multiple_results=False, new_style=True)
A:jax._src.lax.lax._argmax_translation_rule->jax.interpreters.xla.lower_fun(partial(_compute_argminmax, gt, _get_max_identity), multiple_results=False, new_style=True)
A:jax._src.lax.lax.argmin_p->standard_primitive(_argminmax_shape_rule, _argminmax_dtype_rule, 'argmin', _argmin_translation_rule, weak_type_rule=_strip_weak_type)
A:jax._src.lax.lax.argmax_p->standard_primitive(_argminmax_shape_rule, _argminmax_dtype_rule, 'argmax', _argmax_translation_rule, weak_type_rule=_strip_weak_type)
A:jax._src.lax.lax._reduce_or_translation_rule->partial(_reduce_logical_translation_rule, or_p, _get_max_identity)
A:jax._src.lax.lax.reduce_or_p->standard_primitive(_reduce_logical_shape_rule, _fixed_dtype(np.bool_), 'reduce_or', _reduce_or_translation_rule, weak_type_rule=_strip_weak_type)
A:jax._src.lax.lax._reduce_and_translation_rule->partial(_reduce_logical_translation_rule, and_p, _get_min_identity)
A:jax._src.lax.lax.reduce_and_p->standard_primitive(_reduce_logical_shape_rule, _fixed_dtype(np.bool_), 'reduce_and', _reduce_and_translation_rule, weak_type_rule=_strip_weak_type)
A:jax._src.lax.lax.scalar_type->jax.interpreters.mlir.aval_to_ir_type(core.ShapedArray((), dtype))
A:jax._src.lax.lax.reducer_region->jax._src.lib.mlir.dialects.mhlo.ReduceOp([mlir.aval_to_ir_type(aval_out)], [x], mlir.ir_constants(unit_factory(aval_out.dtype)), mlir.dense_int_elements(axes)).regions[0].blocks.append(scalar_type, scalar_type)
A:jax._src.lax.lax.add->reducer(*reducer_region.arguments)
A:jax._src.lax.lax.reduce_precision_p->standard_primitive(_reduce_precision_shape_rule, partial(unop_dtype_rule, _identity, _float, 'reduce_precision'), name='reduce_precision')
A:jax._src.lax.lax.args->tuple((raise_to_shaped(arg) for arg in args))
A:jax._src.lax.lax.signed->select(_isnan(x), full_like(signed, signed_nan), signed)
A:jax._src.lax.lax.unsigned->bitcast_convert_type(x, unsigned_dtype)
A:jax._src.lax.lax.signed_nan->convert_element_type(x, np.float32).dtype.type(np.nan).view(signed_dtype)
A:jax._src.lax.lax.flipped->bitcast_convert_type(sub(unsigned_dtype.type(np.iinfo(signed_dtype).max), unsigned), signed_dtype)
A:jax._src.lax.lax.(x_keys, y_keys)->_operands_to_keys(*operands, num_keys=num_keys)
A:jax._src.lax.lax.comparator->jax._src.lib.mlir.dialects.mhlo.SortOp([mlir.aval_to_ir_type(aval) for aval in ctx.avals_out], mlir.flatten_lowering_ir_args(operands), mlir.i64_attr(dimension), ir.BoolAttr.get(is_stable)).comparator.blocks.append(*util.flatten(zip(scalar_types, scalar_types)))
A:jax._src.lax.lax.idx->tuple((primals[-1] if i == dimension else iotas[i] for i in range(len(shape))))
A:jax._src.lax.lax.tangents_out->tuple((t if type(t) is ad_util.Zero else t[idx] for t in tangents))
A:jax._src.lax.lax.(prototype_arg, new_bdim)->next(((a, b) for (a, b) in zip(batched_args, batch_dims) if b is not None))
A:jax._src.lax.lax.sort_p->Primitive('sort')
A:jax._src.lax.lax.sort->jax._src.lib.mlir.dialects.mhlo.SortOp([mlir.aval_to_ir_type(aval) for aval in ctx.avals_out], mlir.flatten_lowering_ir_args(operands), mlir.i64_attr(dimension), ir.BoolAttr.get(is_stable))
A:jax._src.lax.lax.scalar_types->safe_map(mlir.aval_to_ir_type, scalar_avals)
A:jax._src.lax.lax.lower_comparator->jax.interpreters.mlir.lower_fun(partial(_sort_lt_comparator), multiple_results=False)
A:jax._src.lax.lax.sub_ctx->jax.interpreters.mlir.LoweringRuleContext(module_context=ctx.module_context, primitive=None, avals_in=util.flatten(zip(scalar_avals, scalar_avals)), avals_out=[core.ShapedArray((), np.bool_)])
A:jax._src.lax.lax.primals_out->top_k(operand, k)
A:jax._src.lax.lax.tangent_out->jax._src.lax.slicing.gather(tangent, gather_indices, dnums, slice_sizes)
A:jax._src.lax.lax.rank->len(idx_shape)
A:jax._src.lax.lax._iota->broadcast_in_dim(_iota, gather_index_shape, (i,))
A:jax._src.lax.lax.gather_indices->concatenate(gather_indices, dimension=rank)
A:jax._src.lax.lax.dnums->jax._src.lax.slicing.GatherDimensionNumbers(offset_dims=(), collapsed_slice_dims=tuple(range(rank)), start_index_map=tuple(range(rank)))
A:jax._src.lax.lax.perm->numpy.arange(operand.ndim)
A:jax._src.lax.lax.(top_k_v, top_k_i)->top_k(transpose(operand, perm), k=k)
A:jax._src.lax.lax.top_k_p->Primitive('top_k')
A:jax._src.lax.lax.create_token_p->Primitive('create_token')
A:jax._src.lax.lax.after_all_p->Primitive('after_all')
A:jax._src.lax.lax.(flat_shapes, treedef)->jax._src.lib.pytree.flatten(shape)
A:jax._src.lax.lax.xs_and_token->build_infeed()
A:jax._src.lax.lax.build_infeed->partial(xops.InfeedWithToken, token, xla_client.Shape.tuple_shape(shape))
A:jax._src.lax.lax.token->xops.GetTupleElement(xs_and_token, 1)
A:jax._src.lax.lax.infeed_p->Primitive('infeed')
A:jax._src.lax.lax.output_types->safe_map(mlir.aval_to_ir_types, ctx.avals_out[:-1])
A:jax._src.lax.lax.flat_output_types->jax._src.util.flatten(output_types)
A:jax._src.lax.lax.layouts->jax._src.lib.mlir.ir.ArrayAttr.get([ir.ArrayAttr.get([mlir.i64_attr(i) for i in range(len(aval.shape) - 1, -1, -1)]) for aval in shapes])
A:jax._src.lax.lax.infeed->jax._src.lib.mlir.dialects.mhlo.InfeedOp(flat_output_types + [mhlo.TokenType.get()], token, ir.StringAttr.get(''), layouts)
A:jax._src.lax.lax.(flat_xs, _)->jax._src.lib.pytree.flatten(xs)
A:jax._src.lax.lax.t->xops.Tuple(c, xs)
A:jax._src.lax.lax.outfeed_p->Primitive('outfeed')
A:jax._src.lax.lax.outfeed->jax._src.lib.mlir.dialects.mhlo.OutfeedOp(mlir.aval_to_ir_type(token_aval), mlir.flatten_lowering_ir_args(xs), token, ir.StringAttr.get(''))
A:jax._src.lax.lax.xla_shape->xc.Shape.array_shape(etype, shape)
A:jax._src.lax.lax.rng_uniform_p->Primitive('rng_uniform')
A:jax._src.lax.lax.(shape,)->jax.interpreters.mlir.ir_constants(np.array(aval_out.shape, np.int64), canonicalize_types=False)
A:jax._src.lax.lax.rbg_dtype->numpy.dtype('uint32')
A:jax._src.lax.lax.u64_etype->jax.interpreters.xla.dtype_to_primitive_type(np.dtype('uint64'))
A:jax._src.lax.lax.key->xops.BitcastConvertType(xops.Reshape(key, (2, 2)), u64_etype)
A:jax._src.lax.lax.(out_key, out_vals)->jax.interpreters.xla.xla_destructure(c, xops.RngBitGenerator(algorithm, key, xla_shape))
A:jax._src.lax.lax.u32_etype->jax.interpreters.xla.dtype_to_primitive_type(np.dtype('uint32'))
A:jax._src.lax.lax.out_key->xops.Reshape(xops.BitcastConvertType(out_key, u32_etype), (4,))
A:jax._src.lax.lax.out_vals->xops.ConvertElementType(out_vals, xla.dtype_to_primitive_type(dtype))
A:jax._src.lax.lax.rng_bit_generator_p->Primitive('rng_bit_generator')
A:jax._src.lax.lax.copy_p->jax.core.Primitive('copy')
A:jax._src.lax.lax.etype->jax.interpreters.xla.dtype_to_primitive_type(dtype)
A:jax._src.lax.lax.iota_p->Primitive('iota')
A:jax._src.lax.lax.bint_p->jax.core.Primitive('bint')
A:jax._src.lax.lax.out_shape->_ceil_divide(in_shape, window_strides)
A:jax._src.lax.lax.pad_sizes->numpy.maximum(0, (out_shape - 1) * window_strides + window_shape - in_shape)
A:jax._src.lax.lax.types->list(map(np.dtype, ttypes))
A:jax._src.lax.lax.obj_arr->numpy.array(obj)
A:jax._src.lax.lax.val->jax._src.dtypes.scalar_type_of(example)(val)
A:jax._src.lax.lax.x_len->len(x)
A:jax._src.lax.lax.removed->set(itertools.chain(*removed_lists))
A:jax._src.lax.lax.higher_dtype->jax._src.dtypes.promote_types(a_dtype, b_dtype)
A:jax._src.lax.lax.a->convert_element_type(a, b_dtype)
A:jax._src.lax.lax.b->convert_element_type(b, a_dtype)
A:jax._src.lax.lax.np_dtype->numpy.dtype(dtype)
jax._src.lax.lax.Precision(self,arg0)
jax._src.lax.lax.Precision.__init__(self,arg0)
jax._src.lax.lax.Precision.__str__(self)->str
jax._src.lax.lax.RoundingMethod(enum.IntEnum)
jax._src.lax.lax._abs_jvp_rule(g,ans,x)
jax._src.lax.lax._abstractify(x)
jax._src.lax.lax._add_inverse(r,x,y)
jax._src.lax.lax._add_jvp(primals,tangents)
jax._src.lax.lax._add_transpose(t,x,y)
jax._src.lax.lax._after_all_abstract_eval(*operands)
jax._src.lax.lax._after_all_lowering(ctx,*operands)
jax._src.lax.lax._after_all_translation_rule(ctx,avals_in,avals_out,*operands)
jax._src.lax.lax._argminmax_dtype_rule(operand,*,axes,index_dtype)
jax._src.lax.lax._argminmax_shape_rule(operand,*,axes,index_dtype)
jax._src.lax.lax._array_copy(arr)
jax._src.lax.lax._balanced_eq(x,z,y)
jax._src.lax.lax._bessel_i1e_jvp(g,y,x)
jax._src.lax.lax._bitcast_convert_type_dtype_rule(operand,*,new_dtype)
jax._src.lax.lax._bitcast_convert_type_lower(ctx,operand,*,new_dtype)
jax._src.lax.lax._bitcast_convert_type_shape_rule(operand,*,new_dtype)
jax._src.lax.lax._bitcast_convert_type_translation_rule(ctx,avals_in,avals_out,operand,*,new_dtype)
jax._src.lax.lax._broadcast_in_dim_batch_rule(batched_args,batch_dims,*,shape,broadcast_dimensions)
jax._src.lax.lax._broadcast_in_dim_fwd_rule(eqn)
jax._src.lax.lax._broadcast_in_dim_lower(ctx,x,*,shape,broadcast_dimensions)
jax._src.lax.lax._broadcast_in_dim_padding_rule(in_avals,out_avals,x,*dyn_shape,shape,broadcast_dimensions)
jax._src.lax.lax._broadcast_in_dim_shape_rule(operand,*,shape,broadcast_dimensions)
jax._src.lax.lax._broadcast_in_dim_staging_rule(trace,x,*dyn_shape,shape,broadcast_dimensions)
jax._src.lax.lax._broadcast_in_dim_transpose_rule(ct,operand,*,shape,broadcast_dimensions)
jax._src.lax.lax._broadcast_ranks(s1,s2)
jax._src.lax.lax._broadcast_shapes_cached(*shapes:Tuple[int,...])->Tuple[int, ...]
jax._src.lax.lax._broadcast_shapes_uncached(*shapes)
jax._src.lax.lax._broadcast_translate(op,ctx,avals_in,avals_out,*args)
jax._src.lax.lax._broadcasting_shape_rule(name,*avals)
jax._src.lax.lax._ceil_divide(x1,x2)
jax._src.lax.lax._check_same_dtypes(name,ignore_fp_precision,*ttypes)
jax._src.lax.lax._check_shapelike(fun_name,arg_name,obj,non_zero_shape=False)
jax._src.lax.lax._check_user_dtype_supported(dtype,fun_name=None)
jax._src.lax.lax._clamp_batch_rule(batched_args,batch_dims,**params)
jax._src.lax.lax._clamp_shape_rule(min,operand,max)
jax._src.lax.lax._compare_lower_mhlo(direction:str,ctx,x,y)
jax._src.lax.lax._complex_transpose_rule(t,x,y)
jax._src.lax.lax._compute_argminmax(value_comparator,get_identity,operand,*,index_dtype,axes)
jax._src.lax.lax._compute_squeeze_shape(shape,dimensions)
jax._src.lax.lax._concatenate_batch_rule(batched_args,batch_dims,*,dimension)
jax._src.lax.lax._concatenate_dtype_rule(*operands,**kwargs)
jax._src.lax.lax._concatenate_lower(ctx,*xs,dimension)
jax._src.lax.lax._concatenate_shape_rule(*operands,**kwargs)
jax._src.lax.lax._concatenate_translation_rule(ctx,avals_in,avals_out,*operands,dimension,**kw)
jax._src.lax.lax._concatenate_transpose_rule(t,*operands,dimension)
jax._src.lax.lax._conj_impl(x,**kw)
jax._src.lax.lax._conj_transpose_rule(t,x,*,input_dtype)
jax._src.lax.lax._const(example,val)
jax._src.lax.lax._convert_element_type(operand:Array,new_dtype:Optional[DType]=None,weak_type:bool=False)
jax._src.lax.lax._convert_element_type_dtype_rule(operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_element_type_jvp_rule(tangent,operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_element_type_lower(ctx,operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_element_type_shape_rule(operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_element_type_translation_rule(ctx,avals_in,avals_out,operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_element_type_transpose_rule(ct,operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_element_type_weak_type_rule(operand,*,new_dtype,weak_type)
jax._src.lax.lax._convert_elt_type_folding_rule(consts,eqn)
jax._src.lax.lax._convert_elt_type_fwd_rule(eqn)
jax._src.lax.lax._convert_elt_type_pp_rule(eqn,context,settings)
jax._src.lax.lax._create_token_lowering(ctx,*operands)
jax._src.lax.lax._delta(dtype:DType,shape:Shape,axes:Sequence[int])->Array
jax._src.lax.lax._device_put_raw(x,weak_type=None)
jax._src.lax.lax._dilate_shape(shape,dilation)
jax._src.lax.lax._div_transpose_rule(cotangent,x,y)
jax._src.lax.lax._dot_general_batch_dim_nums(ndims,batch_dims,dimension_numbers)
jax._src.lax.lax._dot_general_batch_rule(batched_args,batch_dims,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._dot_general_cpu_translation_rule(ctx,avals_in,avals_out,lhs,rhs,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._dot_general_dtype_rule(lhs,rhs,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._dot_general_lower(ctx,lhs,rhs,*,dimension_numbers,precision,preferred_element_type:Optional[np.dtype])
jax._src.lax.lax._dot_general_masking_rule(padded_vals,logical_shapes,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._dot_general_padding_rule(in_avals,out_avals,lhs,rhs,*,dimension_numbers,**params)
jax._src.lax.lax._dot_general_pp_rule(eqn,context,settings)
jax._src.lax.lax._dot_general_shape_computation(lhs_shape,rhs_shape,dimension_numbers)
jax._src.lax.lax._dot_general_shape_rule(lhs,rhs,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._dot_general_translation_rule(ctx,avals_in,avals_out,lhs,rhs,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._dot_general_transpose_lhs(g,y,*,dimension_numbers,precision,preferred_element_type:Optional[DType],swap_ans=False)
jax._src.lax.lax._dot_general_transpose_rhs(g,x,*,dimension_numbers,precision,preferred_element_type:Optional[DType])
jax._src.lax.lax._enum_descriptor(self,val)
jax._src.lax.lax._enum_descriptor.__get__(self,_,owner)
jax._src.lax.lax._enum_descriptor.__init__(self,val)
jax._src.lax.lax._eq_meet(a,b)
jax._src.lax.lax._eye(dtype:DType,shape:Shape,offset:int)->Array
jax._src.lax.lax._float_to_int_for_sort(x)
jax._src.lax.lax._get_max_identity(dtype:DType)->Array
jax._src.lax.lax._get_min_identity(dtype:DType)->Array
jax._src.lax.lax._get_monoid_reducer(monoid_op:Callable,xs:Sequence[Array])->Optional[Callable]
jax._src.lax.lax._identity(x)
jax._src.lax.lax._infeed_abstract_eval(token,*,shapes,partitions)
jax._src.lax.lax._infeed_lowering(ctx,token,*,shapes,partitions)
jax._src.lax.lax._infeed_translation_rule(ctx,avals_in,avals_out,token,*,shapes,partitions)
jax._src.lax.lax._integer_pow(x,*,y)
jax._src.lax.lax._integer_pow_dtype_rule(x,*,y)
jax._src.lax.lax._integer_pow_jvp(g,x,*,y)
jax._src.lax.lax._integer_pow_lowering(ctx,x,*,y)
jax._src.lax.lax._integer_pow_translation_rule(ctx,avals_in,avals_out,x,*,y)
jax._src.lax.lax._iota_abstract_eval(*,dtype,shape,dimension)
jax._src.lax.lax._iota_lower(ctx,*,dtype,shape,dimension)
jax._src.lax.lax._iota_translation_rule(ctx,avals_in,avals_out,*,dtype,shape,dimension)
jax._src.lax.lax._is_singleton_reshape(old,new)
jax._src.lax.lax._iscomplex(x)->bool
jax._src.lax.lax._isnan(x)->bool
jax._src.lax.lax._iter(tracer)
jax._src.lax.lax._masked(padded_value,logical_shape,dimensions,value=0)
jax._src.lax.lax._masking_defreducer(prim,identity)
jax._src.lax.lax._maybe_broadcast(target_shape,x)
jax._src.lax.lax._minmax_complex_lowering(x,y,*,lax_cmp_pick_x)
jax._src.lax.lax._minmax_translation_rule(ctx,avals_in,avals_out,x,y,*,op_minmax=None,lax_cmp_pick_x=None)
jax._src.lax.lax._mul_inverse(r,x,y)
jax._src.lax.lax._mul_transpose(ct,x,y)
jax._src.lax.lax._nary_lower_mhlo(op:Callable,ctx,*args:Union[ir.Value,Sequence[ir.Value]],explicit_type=False,**params)
jax._src.lax.lax._naryop_weak_type_rule(name,*avals,**kwargs)
jax._src.lax.lax._operands_to_keys(*operands,num_keys=1)
jax._src.lax.lax._outfeed_abstract_eval(token,*xs,partitions)
jax._src.lax.lax._outfeed_lowering(ctx,token,*xs,partitions)
jax._src.lax.lax._outfeed_translation_rule(ctx,avals_in,avals_out,token,*xs,partitions)
jax._src.lax.lax._pad_batch_rule(batched_args,batch_dims,*,padding_config)
jax._src.lax.lax._pad_dtype_rule(operand,padding_value,*,padding_config)
jax._src.lax.lax._pad_lower(ctx,x,padding_value,*,padding_config)
jax._src.lax.lax._pad_masking_rule(padded_vals,logical_shapes,padding_config)
jax._src.lax.lax._pad_shape_rule(operand,padding_value,*,padding_config)
jax._src.lax.lax._pad_translation_rule(ctx,avals_in,avals_out,operand,padding_value,*,padding_config)
jax._src.lax.lax._pad_transpose(t,operand,padding_value,*,padding_config)
jax._src.lax.lax._pow_jvp_lhs(g,ans,x,y)
jax._src.lax.lax._pow_jvp_rhs(g,ans,x,y)
jax._src.lax.lax._precision_config(precision)
jax._src.lax.lax._real_dtype(dtype)
jax._src.lax.lax._reduce_and(operand:Array,axes:Sequence[int])->Array
jax._src.lax.lax._reduce_batch_rule(batched_args,batch_dims,*,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_chooser_jvp_rule(g,ans,operand,*,axes)
jax._src.lax.lax._reduce_chooser_shape_rule(operand,*,axes)
jax._src.lax.lax._reduce_chooser_translation_rule(prim,identity,ctx,avals_in,avals_out,operand,*,axes)
jax._src.lax.lax._reduce_dtype_rule(*avals,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_jvp(reducer,init_values,primals,tangents,axes)
jax._src.lax.lax._reduce_jvp_rule(primals,tangents,*,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_logical_shape_rule(operand,*,axes)
jax._src.lax.lax._reduce_logical_translation_rule(prim,identity,ctx,avals_in,avals_out,operand,*,axes)
jax._src.lax.lax._reduce_lower(ctx,*values,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_max(operand:Array,axes:Sequence[int])->Array
jax._src.lax.lax._reduce_min(operand:Array,axes:Sequence[int])->Array
jax._src.lax.lax._reduce_named_shape_rule(*avals,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_number_dtype_rule(name,operand,*args,**kw)
jax._src.lax.lax._reduce_op_shape_rule(operand,*,axes,input_shape=None)
jax._src.lax.lax._reduce_or(operand:Array,axes:Sequence[int])->Array
jax._src.lax.lax._reduce_precision_lower(ctx,operand,*,exponent_bits,mantissa_bits)
jax._src.lax.lax._reduce_precision_shape_rule(operand,*,exponent_bits,mantissa_bits)
jax._src.lax.lax._reduce_prod(operand:Array,axes:Sequence[int])->Array
jax._src.lax.lax._reduce_prod_jvp_rule(primals,tangents,*,axes)
jax._src.lax.lax._reduce_prod_translation_rule(ctx,avals_in,avals_out,operand,*,axes)
jax._src.lax.lax._reduce_shape_rule(*avals,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_sum(operand:Array,axes:Sequence[int])->Array
jax._src.lax.lax._reduce_sum_padding_rule(in_avals,out_avals,operand,*,axes)
jax._src.lax.lax._reduce_sum_shape_rule(operand,*,axes)
jax._src.lax.lax._reduce_sum_translation_rule(ctx,avals_in,avals_out,operand,*,axes)
jax._src.lax.lax._reduce_sum_transpose_rule(cotangent,operand,*,axes)
jax._src.lax.lax._reduce_translation_rule(ctx,avals_in,avals_out,*values,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reduce_weak_type_rule(*avals,computation,jaxpr,consts,dimensions)
jax._src.lax.lax._reducer_masking_rule(prim,identity,padded_vals,logical_shapes,axes,input_shape=None,**reduce_kwargs)
jax._src.lax.lax._reduction_computation(ctx,jaxpr,consts,init_values,singleton=True)
jax._src.lax.lax._reduction_jaxpr(computation,aval)
jax._src.lax.lax._replace_masked_values(x,val,padded_axes)
jax._src.lax.lax._reshape_batch_rule(batched_args,batch_dims,*,new_sizes,dimensions)
jax._src.lax.lax._reshape_dtype_rule(operand,*,new_sizes,dimensions)
jax._src.lax.lax._reshape_lower(ctx,x,*,new_sizes,dimensions)
jax._src.lax.lax._reshape_masking_rule(padded_args,logical_shapes,polymorphic_shapes,new_sizes,dimensions)
jax._src.lax.lax._reshape_shape_rule(operand,*,new_sizes,dimensions)
jax._src.lax.lax._reshape_translation_rule(ctx,avals_in,avals_out,operand,*,new_sizes,dimensions)
jax._src.lax.lax._reshape_transpose_rule(t,operand,*,new_sizes,dimensions)
jax._src.lax.lax._rev_batch_rule(batched_args,batch_dims,*,dimensions)
jax._src.lax.lax._rev_lower(ctx,x,*,dimensions)
jax._src.lax.lax._rev_shape_rule(operand,*,dimensions)
jax._src.lax.lax._rng_bit_generator_dtype_rule(key,*,shape,dtype,algorithm)
jax._src.lax.lax._rng_bit_generator_named_shape_rule(key,*,shape,dtype,algorithm)
jax._src.lax.lax._rng_bit_generator_shape_rule(key,*,shape,dtype,algorithm)
jax._src.lax.lax._rng_bit_generator_translation_rule(ctx,avals_in,avals_out,key,*,shape,dtype,algorithm)
jax._src.lax.lax._rng_bit_generator_weak_type_rule(key,*,shape,dtype,algorithm)
jax._src.lax.lax._rng_uniform_abstract_eval(a,b,*,shape)
jax._src.lax.lax._rng_uniform_lowering(ctx,a,b,*,shape)
jax._src.lax.lax._rng_uniform_translation_rule(ctx,avals_in,avals_out,a,b,*,shape)
jax._src.lax.lax._round_lower(ctx,x,*,rounding_method)
jax._src.lax.lax._round_to_nearest_even(x)
jax._src.lax.lax._round_translation_rule(ctx,avals_in,avals_out,x,*,rounding_method)
jax._src.lax.lax._select_batch_rule(batched_args,batch_dims,**unused_kwargs)
jax._src.lax.lax._select_dtype_rule(which,*cases)
jax._src.lax.lax._select_jvp(primals,tangents)
jax._src.lax.lax._select_masking_rule(padded_vals,logical_shapes)
jax._src.lax.lax._select_mhlo_lowering(ctx,which,*cases)
jax._src.lax.lax._select_shape_rule(which,*cases)
jax._src.lax.lax._select_transpose_rule(t,which,*cases)
jax._src.lax.lax._select_weak_type_rule(which,*cases)
jax._src.lax.lax._select_xla_translation(ctx,avals_in,avals_out,which,*cases)
jax._src.lax.lax._shape_as_value(shape:core.Shape)
jax._src.lax.lax._sign_lower_mhlo(ctx,x)
jax._src.lax.lax._sign_translation_rule(ctx,avals_in,avals_out,x)
jax._src.lax.lax._sort_abstract_eval(*args,**kwargs)
jax._src.lax.lax._sort_batch_rule(batched_args,batch_dims,*,dimension,is_stable,num_keys)
jax._src.lax.lax._sort_jvp(primals,tangents,*,dimension,is_stable,num_keys)
jax._src.lax.lax._sort_le_comparator(*operands,num_keys=1)
jax._src.lax.lax._sort_lower(ctx,*operands,dimension,is_stable,num_keys)
jax._src.lax.lax._sort_lt_comparator(*operands,num_keys=1)
jax._src.lax.lax._sort_translation_rule(ctx,avals_in,avals_out,*operands,dimension,is_stable,num_keys)
jax._src.lax.lax._squeeze_batch_rule(batched_args,batch_dims,*,dimensions)
jax._src.lax.lax._squeeze_dtype_rule(operand,*,dimensions)
jax._src.lax.lax._squeeze_lower(ctx,operand,*,dimensions)
jax._src.lax.lax._squeeze_shape_rule(operand,*,dimensions)
jax._src.lax.lax._squeeze_translation_rule(ctx,avals_in,avals_out,arg,*,dimensions)
jax._src.lax.lax._squeeze_transpose_rule(t,operand,*,dimensions)
jax._src.lax.lax._stop_gradient_batch_rule(batched_args,batch_dims)
jax._src.lax.lax._stop_gradient_jvp_rule(primals,tangents)
jax._src.lax.lax._sub_jvp(primals,tangents)
jax._src.lax.lax._sub_transpose(t,x,y)
jax._src.lax.lax._tan_impl(x)
jax._src.lax.lax._top_k_abstract_eval(operand,*,k)
jax._src.lax.lax._top_k_batch_rule(batched_args,batch_dims,*,k)
jax._src.lax.lax._top_k_jvp(primals,tangents,*,k)
jax._src.lax.lax._top_k_translation_rule(ctx,avals_in,avals_out,x,*,k)
jax._src.lax.lax._transpose_batch_rule(batched_args,batch_dims,*,permutation)
jax._src.lax.lax._transpose_lower(ctx,x,*,permutation)
jax._src.lax.lax._transpose_masking_rule(padded_vals,logical_shapes,permutation)
jax._src.lax.lax._transpose_shape_rule(operand,*,permutation)
jax._src.lax.lax._tri(dtype:DType,shape:Shape,offset:int)->Array
jax._src.lax.lax._try_broadcast_shapes(shapes:Sequence[Tuple[int,...]])->Optional[Tuple[int, ...]]
jax._src.lax.lax._unary_reduce_lower(reducer,unit_factory,ctx,x,*,axes)
jax._src.lax.lax._unbroadcast(aval,x)
jax._src.lax.lax._upcast_fp16_for_computation(f)
jax._src.lax.lax._validate_preferred_element_type(input_dtype,preferred_element_type)
jax._src.lax.lax._validate_shapes(shapes:Sequence[Shape])
jax._src.lax.lax._variadic_reduction_jaxpr(computation,flat_avals,aval_tree)
jax._src.lax.lax.abs(x:Array)->Array
jax._src.lax.lax.acos(x:Array)->Array
jax._src.lax.lax.acos_impl(x)
jax._src.lax.lax.acosh(x:Array)->Array
jax._src.lax.lax.add(x:Array,y:Array)->Array
jax._src.lax.lax.after_all(*operands)
jax._src.lax.lax.argmax(operand:Array,axis:int,index_dtype:DType)->Tuple[Array, Array]
jax._src.lax.lax.argmin(operand:Array,axis:int,index_dtype:DType)->Tuple[Array, Array]
jax._src.lax.lax.asin(x:Array)->Array
jax._src.lax.lax.asin_impl(x)
jax._src.lax.lax.asinh(x:Array)->Array
jax._src.lax.lax.atan(x:Array)->Array
jax._src.lax.lax.atan2(x:Array,y:Array)->Array
jax._src.lax.lax.atan_impl(x)
jax._src.lax.lax.atanh(x:Array)->Array
jax._src.lax.lax.batch_matmul(lhs:Array,rhs:Array,precision:PrecisionLike=None)->Array
jax._src.lax.lax.bessel_i0e(x:Array)->Array
jax._src.lax.lax.bessel_i1e(x:Array)->Array
jax._src.lax.lax.betainc(a:Array,b:Array,x:Array)->Array
jax._src.lax.lax.betainc_grad_not_implemented(g,a,b,x)
jax._src.lax.lax.betainc_gradx(g,a,b,x)
jax._src.lax.lax.bint_abstract_eval(_,*,bd:int)
jax._src.lax.lax.bitcast_convert_type(operand:Array,new_dtype:DType)->Array
jax._src.lax.lax.bitwise_and(x:Array,y:Array)->Array
jax._src.lax.lax.bitwise_not(x:Array)->Array
jax._src.lax.lax.bitwise_or(x:Array,y:Array)->Array
jax._src.lax.lax.bitwise_xor(x:Array,y:Array)->Array
jax._src.lax.lax.broadcast(operand:Array,sizes:Sequence[int])->Array
jax._src.lax.lax.broadcast_in_dim(operand:Array,shape:Shape,broadcast_dimensions:Sequence[int])->Array
jax._src.lax.lax.broadcast_mhlo(aval_out:core.ShapedArray,avals:Sequence[core.ShapedArray],args:Sequence[ir.Value])->Sequence[ir.Value]
jax._src.lax.lax.broadcast_shapes(*shapes:Tuple[Union[int,core.Tracer],...])->Tuple[Union[int, core.Tracer], ...]
jax._src.lax.lax.broadcast_to_rank(x:Array,rank:int)->Array
jax._src.lax.lax.broadcasted_iota(dtype:DType,shape:Shape,dimension:int)->Array
jax._src.lax.lax.canonicalize_precision(precision:PrecisionLike)->Optional[Tuple[PrecisionType, PrecisionType]]
jax._src.lax.lax.cbrt(x:Array)->Array
jax._src.lax.lax.ceil(x:Array)->Array
jax._src.lax.lax.clamp(min:Array,x:Array,max:Array)->Array
jax._src.lax.lax.clz(x:Array)->Array
jax._src.lax.lax.collapse(operand:Array,start_dimension:int,stop_dimension:int)->Array
jax._src.lax.lax.complex(x:Array,y:Array)->Array
jax._src.lax.lax.concatenate(operands:Sequence[Array],dimension:int)->Array
jax._src.lax.lax.conj(x:Array)->Array
jax._src.lax.lax.convert_element_type(operand:Array,new_dtype:DType)->Array
jax._src.lax.lax.cos(x:Array)->Array
jax._src.lax.lax.cosh(x:Array)->Array
jax._src.lax.lax.create_token(_=None)
jax._src.lax.lax.digamma(x:Array)->Array
jax._src.lax.lax.div(x:Array,y:Array)->Array
jax._src.lax.lax.dot(lhs:Array,rhs:Array,precision:PrecisionLike=None,preferred_element_type:Optional[DType]=None)->Array
jax._src.lax.lax.dot_general(lhs:Array,rhs:Array,dimension_numbers:DotDimensionNumbers,precision:PrecisionLike=None,preferred_element_type:Optional[DType]=None)->Array
jax._src.lax.lax.eq(x:Array,y:Array)->Array
jax._src.lax.lax.erf(x:Array)->Array
jax._src.lax.lax.erf_inv(x:Array)->Array
jax._src.lax.lax.erfc(x:Array)->Array
jax._src.lax.lax.exp(x:Array)->Array
jax._src.lax.lax.expand_dims(array:Array,dimensions:Sequence[int])->Array
jax._src.lax.lax.expm1(x:Array)->Array
jax._src.lax.lax.floor(x:Array)->Array
jax._src.lax.lax.full(shape:Shape,fill_value:Array,dtype:Optional[DType]=None)->Array
jax._src.lax.lax.full_like(x:Array,fill_value:Array,dtype:Optional[DType]=None,shape:Optional[Shape]=None)->Array
jax._src.lax.lax.ge(x:Array,y:Array)->Array
jax._src.lax.lax.gt(x:Array,y:Array)->Array
jax._src.lax.lax.igamma(a:Array,x:Array)->Array
jax._src.lax.lax.igamma_grad_a(a:Array,x:Array)->Array
jax._src.lax.lax.igamma_grada(g,a,x)
jax._src.lax.lax.igamma_gradx(g,a,x)
jax._src.lax.lax.igammac(a:Array,x:Array)->Array
jax._src.lax.lax.igammac_grada(g,a,x)
jax._src.lax.lax.igammac_gradx(g,a,x)
jax._src.lax.lax.imag(x:Array)->Array
jax._src.lax.lax.infeed(token,shape=None,partitions=None)
jax._src.lax.lax.integer_pow(x:Array,y:int)->Array
jax._src.lax.lax.iota(dtype:DType,size:int)->Array
jax._src.lax.lax.is_finite(x:Array)->Array
jax._src.lax.lax.le(x:Array,y:Array)->Array
jax._src.lax.lax.lgamma(x:Array)->Array
jax._src.lax.lax.log(x:Array)->Array
jax._src.lax.lax.log1p(x:Array)->Array
jax._src.lax.lax.lt(x:Array,y:Array)->Array
jax._src.lax.lax.make_bint(i,bd:int)
jax._src.lax.lax.max(x:Array,y:Array)->Array
jax._src.lax.lax.min(x:Array,y:Array)->Array
jax._src.lax.lax.mul(x:Array,y:Array)->Array
jax._src.lax.lax.naryop(result_dtype,accepted_dtypes,name,translation_rule=None)
jax._src.lax.lax.naryop_dtype_rule(result_dtype,accepted_dtypes,name,*avals,**kwargs)
jax._src.lax.lax.ne(x:Array,y:Array)->Array
jax._src.lax.lax.neg(x:Array)->Array
jax._src.lax.lax.nextafter(x1:Array,x2:Array)->Array
jax._src.lax.lax.outfeed(token,xs,partitions=None)
jax._src.lax.lax.pad(operand:Array,padding_value:Array,padding_config:Sequence[Tuple[int,int,int]])->Array
jax._src.lax.lax.padtype_to_pads(in_shape,window_shape,window_strides,padding)
jax._src.lax.lax.population_count(x:Array)->Array
jax._src.lax.lax.pow(x:Array,y:Array)->Array
jax._src.lax.lax.precision_attr(precision:PrecisionType)->ir.ArrayAttr
jax._src.lax.lax.random_gamma_grad(a:Array,x:Array)->Array
jax._src.lax.lax.ranges_like(*xs)
jax._src.lax.lax.real(x:Array)->Array
jax._src.lax.lax.reciprocal(x:Array)->Array
jax._src.lax.lax.reduce(operands:Any,init_values:Any,computation:Callable[[Any,Any],Any],dimensions:Sequence[int])->Any
jax._src.lax.lax.reduce_precision(operand:Union[float,Array],exponent_bits:int,mantissa_bits:int)->Array
jax._src.lax.lax.rem(x:Array,y:Array)->Array
jax._src.lax.lax.remaining(original,*removed_lists)
jax._src.lax.lax.reshape(operand:Array,new_sizes:Shape,dimensions:Optional[Sequence[int]]=None)->Array
jax._src.lax.lax.rev(operand:Array,dimensions:Sequence[int])->Array
jax._src.lax.lax.rng_bit_generator(key,shape,dtype=np.uint32,algorithm=RandomAlgorithm.RNG_DEFAULT)
jax._src.lax.lax.rng_uniform(a,b,shape)
jax._src.lax.lax.round(x:Array,rounding_method:RoundingMethod=RoundingMethod.AWAY_FROM_ZERO)->Array
jax._src.lax.lax.rsqrt(x:Array)->Array
jax._src.lax.lax.select(pred:Array,on_true:Array,on_false:Array)->Array
jax._src.lax.lax.select_n(which:Array,*cases:Array)->Array
jax._src.lax.lax.shift_left(x:Array,y:Array)->Array
jax._src.lax.lax.shift_right_arithmetic(x:Array,y:Array)->Array
jax._src.lax.lax.shift_right_logical(x:Array,y:Array)->Array
jax._src.lax.lax.sign(x:Array)->Array
jax._src.lax.lax.sin(x:Array)->Array
jax._src.lax.lax.sinh(x:Array)->Array
jax._src.lax.lax.sort(operand:Union[Array,Sequence[Array]],dimension:int=-1,is_stable:bool=True,num_keys:int=1)->Union[Array, Tuple[Array, ...]]
jax._src.lax.lax.sort_key_val(keys:Array,values:Array,dimension:int=-1,is_stable:bool=True)->Tuple[Array, Array]
jax._src.lax.lax.sqrt(x:Array)->Array
jax._src.lax.lax.square(x:Array)->Array
jax._src.lax.lax.squeeze(array:Array,dimensions:Sequence[int])->Array
jax._src.lax.lax.stop_gradient(x:T)->T
jax._src.lax.lax.sub(x:Array,y:Array)->Array
jax._src.lax.lax.tan(x:Array)->Array
jax._src.lax.lax.tanh(x:Array)->Array
jax._src.lax.lax.tie_in(x:Array,y:Array)->Array
jax._src.lax.lax.top_k(operand:Array,k:int)->Tuple[Array, Array]
jax._src.lax.lax.transpose(operand:Array,permutation:Sequence[int])->Array
jax._src.lax.lax.tuple_delete(tup,idx)
jax._src.lax.lax.unop(result_dtype,accepted_dtypes,name,translation_rule=None)
jax._src.lax.lax.unop_dtype_rule(result_dtype,accepted_dtypes,name,aval,**kwargs)
jax._src.lax.lax.zeros_like_array(x:Array)->Array
jax._src.lax.lax.zeros_like_shaped_array(aval:Array)->Array


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/_src/lax/control_flow.py----------------------------------------
A:jax._src.lax.control_flow.T->TypeVar('T')
A:jax._src.lax.control_flow.(wrapped_fun, out_tree)->flatten_fun_nokwargs(lu.wrap_init(fun), in_tree)
A:jax._src.lax.control_flow.debug->jax.interpreters.partial_eval.debug_info(fun, in_tree, False, primitive_name or '<unknown>')
A:jax._src.lax.control_flow.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(traceable, in_avals)
A:jax._src.lax.control_flow.(jaxpr, consts, out_tree)->_initial_style_jaxpr(f, in_tree, carry_avals + x_avals, 'scan')
A:jax._src.lax.control_flow.closed_jaxpr->jax.core.ClosedJaxpr(pe.convert_constvars_jaxpr(jaxpr), ())
A:jax._src.lax.control_flow.(jaxprs, all_consts, all_out_trees)->unzip3((_initial_style_open_jaxpr(fun, in_tree, in_avals, primitive_name) for fun in funs))
A:jax._src.lax.control_flow.newvar->jax.core.gensym([j.jaxpr for j in jaxprs], suffix='_')
A:jax._src.lax.control_flow.prefix->jax._src.util.concatenate(unused_const_vars[:i])
A:jax._src.lax.control_flow.suffix->jax._src.util.concatenate(unused_const_vars[i + 1:])
A:jax._src.lax.control_flow.consts->jax._src.util.concatenate(all_consts)
A:jax._src.lax.control_flow.param_str->str(param)
A:jax._src.lax.control_flow.msg->sep.join([msg, param_str])
A:jax._src.lax.control_flow.lower_dtype->jax._src.dtypes.canonicalize_dtype(lax.dtype(lower))
A:jax._src.lax.control_flow.upper_dtype->jax._src.dtypes.canonicalize_dtype(lax.dtype(upper))
A:jax._src.lax.control_flow.lower_->int(lower)
A:jax._src.lax.control_flow.upper_->int(upper)
A:jax._src.lax.control_flow.((_, result), _)->scan(_fori_scan_body_fun(body_fun), (lower_, init_val), None, length=upper_ - lower_)
A:jax._src.lax.control_flow.(_, _, result)->while_loop(_fori_cond_fun, _fori_body_fun(body_fun), (lower, upper, init_val))
A:jax._src.lax.control_flow.val->body_fun(val)
A:jax._src.lax.control_flow.(init_vals, in_tree)->tree_flatten((init_val,))
A:jax._src.lax.control_flow.init_avals->tuple(_map(_abstractify, init_vals))
A:jax._src.lax.control_flow.(cond_jaxpr, cond_consts, cond_tree)->_initial_style_jaxpr(cond_fun, in_tree, init_avals, 'while_cond')
A:jax._src.lax.control_flow.(body_jaxpr, body_consts, body_tree)->_initial_style_jaxpr(body_fun, in_tree, init_avals, 'while_loop')
A:jax._src.lax.control_flow.(init_vals, init_avals, body_jaxpr, in_tree, *rest)->_create_jaxpr(new_init_val)
A:jax._src.lax.control_flow.(new_init_vals, changed)->_promote_weak_typed_inputs(init_vals, init_avals, body_jaxpr.out_avals)
A:jax._src.lax.control_flow.(new_init_val,)->tree_unflatten(in_tree, new_init_vals)
A:jax._src.lax.control_flow.joined_effects->jax.core.join_effects(*(jaxpr.effects for jaxpr in jaxprs))
A:jax._src.lax.control_flow.in_tree_children->in_tree.children()
A:jax._src.lax.control_flow.outs->jax.core.AxisPrimitive('custom_linear_solve').bind(*new_params + new_b, const_lengths=const_lengths, jaxprs=batched_jaxprs)
A:jax._src.lax.control_flow.(cond_consts, body_consts, init_vals)->split_list(args, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.batched->bool(pred_aval.shape)
A:jax._src.lax.control_flow.init_carry->xops.Tuple(c, cond_consts + body_consts + init_vals)
A:jax._src.lax.control_flow.cond_c->jax._src.lib.xla_client.XlaBuilder('cond_computation')
A:jax._src.lax.control_flow.cond_carry->jax.interpreters.xla.parameter(cond_c, 0, c.get_shape(init_carry))
A:jax._src.lax.control_flow.(x, _, z)->jax._src.util.split_list(cond_args, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.name_stack->extend_name_stack(ctx.name_stack, 'cond')
A:jax._src.lax.control_flow.cond_ctx->ctx.module_context.replace(name_stack=xla.extend_name_stack(ctx.module_context.name_stack, 'cond'))
A:jax._src.lax.control_flow.(pred,)->jax._src.lax.lax._unary_reduce_lower(mhlo.OrOp, lambda dtype: np.array(False, dtype), pred_ctx, pred, axes=tuple(range(len(pred_aval.shape))))
A:jax._src.lax.control_flow.scalar->ShapedArray((), np.bool_)
A:jax._src.lax.control_flow.or_->jax.interpreters.xla.primitive_subcomputation(ctx.platform, ctx.axis_env, lax.or_p, scalar, scalar)
A:jax._src.lax.control_flow.pred->jax._src.lax.lax.broadcast_in_dim(pred, np.shape(cases[0]), idx)
A:jax._src.lax.control_flow.body_c->jax._src.lib.xla_client.XlaBuilder('body_computation')
A:jax._src.lax.control_flow.body_carry->jax.interpreters.xla.parameter(body_c, 0, c.get_shape(init_carry))
A:jax._src.lax.control_flow.(x, y, z)->jax._src.util.split_list(body_args, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.body_ctx->ctx.module_context.replace(name_stack=xla.extend_name_stack(ctx.module_context.name_stack, 'body'))
A:jax._src.lax.control_flow.new_z->_map(partial(_pred_bcast_select_mhlo, pred_aval, body_pred), new_z, z, body_jaxpr.out_avals)
A:jax._src.lax.control_flow.body_pred_ctx->ctx.module_context.replace(name_stack=xla.extend_name_stack(ctx.module_context.name_stack, 'body_pred'))
A:jax._src.lax.control_flow.(body_pred,)->jax.interpreters.xla.jaxpr_subcomp(body_pred_ctx, cond_jaxpr.jaxpr, _map(partial(xla.pyval_to_ir_constant, body_c), cond_jaxpr.consts), *x + z)
A:jax._src.lax.control_flow.new_carry->xops.Tuple(body_c, [*x, *y, *new_z])
A:jax._src.lax.control_flow.ans->xops.While(cond_c.build(pred), body_c.build(new_carry), init_carry)
A:jax._src.lax.control_flow.(_, _, z)->jax._src.util.split_list(outputs, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.pred_shape->fn(a, b).get_shape(pred).dimensions()
A:jax._src.lax.control_flow.x_shape->fn(a, b).get_shape(x).dimensions()
A:jax._src.lax.control_flow.y_shape->fn(a, b).get_shape(y).dimensions()
A:jax._src.lax.control_flow.bcast_pred->xops.BroadcastInDim(pred, x_shape, list(range(len(pred_shape))))
A:jax._src.lax.control_flow.(cconst_bat, bconst_bat, init_bat)->split_list(orig_batched, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.(cconsts, bconsts, init)->split_list(args, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.(cconst_dims, bconst_dims, init_dims)->split_list(dims, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.(_, carry_bat_out)->jax.interpreters.batching.batch_jaxpr(body_jaxpr, axis_size, bconst_bat + carry_bat, instantiate=carry_bat, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.carry_bat->safe_map(operator.or_, carry_bat, carry_bat_out)
A:jax._src.lax.control_flow.(_, (pred_bat,))->jax.interpreters.batching.batch_jaxpr(cond_jaxpr, axis_size, cconst_bat + carry_bat, instantiate=False, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.(body_jaxpr_batched, _)->jax.interpreters.batching.batch_jaxpr_axes(body_jaxpr, axis_size, bconst_dims + carry_dims, carry_dims, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.(cond_jaxpr_batched, _)->jax.interpreters.batching.batch_jaxpr_axes(cond_jaxpr, axis_size, cconst_dims + carry_dims, (None,), axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.cond_rank->len(cond_jaxpr.out_avals[0].shape)
A:jax._src.lax.control_flow.(cconst_nz, bconst_nz, init_nz)->split_list(nonzeros, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.(body_jvp, nonzeros_out)->jax.interpreters.ad.jvp_jaxpr(body_jaxpr, body_nonzeros, instantiate=carry_nz)
A:jax._src.lax.control_flow.carry_nz->_map(operator.or_, carry_nz, carry_nz_out)
A:jax._src.lax.control_flow.(cconst, bconst, init)->split_list(primals, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.(_, bconst_dot, init_dot)->split_list(tangents, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.bconst_dot->_prune_zeros(bconst_dot)
A:jax._src.lax.control_flow.init_dot->_prune_zeros(init_dot)
A:jax._src.lax.control_flow.body_jvp_rearranged->jax.interpreters.ad.rearrange_binders(body_jvp, [body_nconsts, num_carry], [len(bconst_dot), len(init_dot)], [num_carry], [len(init_dot)])
A:jax._src.lax.control_flow.cond_jaxpr_augmented->jax.core.ClosedJaxpr(cond_jaxpr_augmented, cond_jaxpr.consts)
A:jax._src.lax.control_flow.out->xops.OptimizationBarrier(xops.Tuple(ctx.builder, args))
A:jax._src.lax.control_flow.(out_carry, out_carry_dot)->split_list(out, [num_carry])
A:jax._src.lax.control_flow.out_tangents_iter->iter(out_tangents)
A:jax._src.lax.control_flow.params->dict(branches=branches_2, linear=linear_2)
A:jax._src.lax.control_flow.(cond_consts_uk, body_consts_uk, carry_init_uk)->split_list(unknowns, [cond_nconsts, body_nconsts])
A:jax._src.lax.control_flow.(body_jaxpr_known, _, carry_out_uk)->jax.interpreters.partial_eval.partial_eval_jaxpr(body_jaxpr, body_consts_uk + carry_uk, instantiate=carry_uk)
A:jax._src.lax.control_flow.carry_uk->_map(operator.or_, carry_uk, carry_uk_out)
A:jax._src.lax.control_flow.(cond_jaxpr_known, _, cond_uk)->jax.interpreters.partial_eval.partial_eval_jaxpr(cond_jaxpr, cond_consts_uk + carry_uk, instantiate=False)
A:jax._src.lax.control_flow.out_known->jax.core.AxisPrimitive('while').bind(*in_consts, cond_nconsts=cond_nconsts, cond_jaxpr=cond_jaxpr_known, body_nconsts=body_nconsts, body_jaxpr=body_jaxpr_known)
A:jax._src.lax.control_flow.while_p->jax.core.AxisPrimitive('while')
A:jax._src.lax.control_flow.pe.partial_eval_jaxpr_custom_rules[while_p]->partial(pe.partial_eval_jaxpr_custom_rule_not_implemented, 'while_loop')
A:jax._src.lax.control_flow.loop_carry_types->_map(mlir.aval_to_ir_types, ctx.avals_in)
A:jax._src.lax.control_flow.flat_loop_carry_types->jax._src.util.flatten(loop_carry_types)
A:jax._src.lax.control_flow.flat_args->jax.interpreters.mlir.flatten_lowering_ir_args(args)
A:jax._src.lax.control_flow.while_op->jax._src.lib.mlir.dialects.mhlo.WhileOp(flat_loop_carry_types, flat_args)
A:jax._src.lax.control_flow.cond_block->jax._src.lib.mlir.dialects.mhlo.WhileOp(flat_loop_carry_types, flat_args).regions[0].blocks.append(*flat_loop_carry_types)
A:jax._src.lax.control_flow.cond_args->jax._src.util.unflatten(flat_cond_args, _map(len, loop_carry_types))
A:jax._src.lax.control_flow.((pred,),)->jax.interpreters.mlir.jaxpr_subcomp(cond_ctx, cond_jaxpr.jaxpr, _map(mlir.ir_constants, cond_jaxpr.consts), *x + z)
A:jax._src.lax.control_flow.pred_ctx->jax.interpreters.mlir.LoweringRuleContext(module_context=ctx.module_context, primitive=None, avals_in=[pred_aval], avals_out=[pred_aval.update(shape=())])
A:jax._src.lax.control_flow.body_block->jax._src.lib.mlir.dialects.mhlo.WhileOp(flat_loop_carry_types, flat_args).regions[1].blocks.append(*flat_loop_carry_types)
A:jax._src.lax.control_flow.body_args->jax._src.util.unflatten(flat_body_args, _map(len, loop_carry_types))
A:jax._src.lax.control_flow.((body_pred,),)->jax.interpreters.mlir.jaxpr_subcomp(body_pred_ctx, cond_jaxpr.jaxpr, _map(mlir.ir_constants, cond_jaxpr.consts), *x + z)
A:jax._src.lax.control_flow.outputs->jax._src.util.unflatten(while_op.results, _map(len, loop_carry_types))
A:jax._src.lax.control_flow._no_operand_sentinel->object()
A:jax._src.lax.control_flow.index_dtype->jax._src.dtypes.result_type(index)
A:jax._src.lax.control_flow.branches->tuple(branches)
A:jax._src.lax.control_flow.index->jax._src.lax.lax.convert_element_type(pred, np.int32)
A:jax._src.lax.control_flow.lo->numpy.array(0, np.int32)
A:jax._src.lax.control_flow.hi->numpy.array(len(branches) - 1, np.int32)
A:jax._src.lax.control_flow.(ops, ops_tree)->tree_flatten(operands)
A:jax._src.lax.control_flow.ops_avals->tuple(_map(_abstractify, ops))
A:jax._src.lax.control_flow.(jaxprs, consts, out_trees)->_initial_style_jaxprs_with_common_consts((true_fun, false_fun), ops_tree, ops_avals, 'cond')
A:jax._src.lax.control_flow.pred_dtype->jax._src.dtypes.result_type(pred)
A:jax._src.lax.control_flow.(linear_ops, ops_tree2)->tree_flatten(linear)
A:jax._src.lax.control_flow.ba->inspect.signature(_cond_with_per_branch_args).bind(*args, **kwargs)
A:jax._src.lax.control_flow.c->fn(a, b)
A:jax._src.lax.control_flow.op->xops.Tuple(c, args)
A:jax._src.lax.control_flow.subctx->ctx.replace(builder=c, name_stack=extend_name_stack(name_stack, name + '_fun'))
A:jax._src.lax.control_flow.op_shape->fn(a, b).get_shape(op)
A:jax._src.lax.control_flow.idx->list(range(np.ndim(pred)))
A:jax._src.lax.control_flow.predicate->jax._src.lax.lax.eq(index, lax._const(index, i))
A:jax._src.lax.control_flow.branches_batched->tuple((batching.batch_jaxpr(jaxpr, axis_size, ops_bat, out_bat, axis_name, main_type)[0] for jaxpr in branches))
A:jax._src.lax.control_flow.branches_jvp->tuple((ad.jvp_jaxpr(jaxpr, ops_nz, instantiate=out_nz)[0] for jaxpr in branches))
A:jax._src.lax.control_flow.ops_dot->_prune_zeros(ops_dot)
A:jax._src.lax.control_flow.ops_lin->tuple(linear)
A:jax._src.lax.control_flow.(out_primals, out_tangents)->split_list(out, [len(out_nz)])
A:jax._src.lax.control_flow.(_, _, out_uks)->jax.interpreters.partial_eval.partial_eval_jaxpr(branch_jaxpr, ops_uk, instantiate=False)
A:jax._src.lax.control_flow.(branch_jaxpr_1, branch_jaxpr_2, _)->jax.interpreters.partial_eval.partial_eval_jaxpr(branch_jaxpr, ops_uk, instantiate=out_uks)
A:jax._src.lax.control_flow.branch_jaxpr_2->jax.interpreters.partial_eval.move_binders_to_front(branch_jaxpr_2, move)
A:jax._src.lax.control_flow.res_avals->_map(raise_to_shaped, branch_jaxpr_2.in_avals[:branch_num_res])
A:jax._src.lax.control_flow.branches_1->_join_cond_outputs(branches_1, all_res_avals, res_avals_per_branch, num_outs)
A:jax._src.lax.control_flow.branches_2->_join_cond_pe_staged_jaxpr_inputs(branches_2, all_res_avals, res_avals_per_branch)
A:jax._src.lax.control_flow.num_outs->len(branches_2[0].out_avals)
A:jax._src.lax.control_flow.(all_res_avals, res_avals_per_branch)->_merge_branch_residuals(branch_res_avals)
A:jax._src.lax.control_flow.num_res->len(res_indices)
A:jax._src.lax.control_flow.(_, in_consts)->unzip2([t.pval for t in tracers])
A:jax._src.lax.control_flow.out_consts_res->jax.core.AxisPrimitive('cond').bind(*in_consts, branches=branches_1, linear=linear)
A:jax._src.lax.control_flow.(out_consts, res)->split_list(out_consts_res, [len(out_consts_res) - num_res])
A:jax._src.lax.control_flow.out_avals->_map(raise_to_shaped, branches_2[0].out_avals)
A:jax._src.lax.control_flow.index_tracer->trace.instantiate_const(tracers[0])
A:jax._src.lax.control_flow.res_tracers->_map(trace.new_instantiated_const, res)
A:jax._src.lax.control_flow.source->jax._src.source_info_util.current().replace(name_stack=name_stack)
A:jax._src.lax.control_flow.eqn->jax.interpreters.partial_eval.new_eqn_recipe(int_res_tracers + new_tracers + ext_res_tracers, out_tracers, scan_p, dict(reverse=reverse, length=length, jaxpr=jaxpr_2_opt, num_consts=num_consts_2, num_carry=num_carry, linear=tuple(linear_2), unroll=unroll), jaxpr_2_opt.effects, source)
A:jax._src.lax.control_flow.branch_res_tagged_avals->_map(enumerate_equal, branch_res_avals)
A:jax._src.lax.control_flow.all_tagged_avals->_ordered_unique(util.concatenate(branch_res_tagged_avals))
A:jax._src.lax.control_flow.outs_and_residuals->jax.core.jaxpr_as_fun(jaxpr)(*args)
A:jax._src.lax.control_flow.(outs, residuals)->split_list(outs_and_residuals, [num_non_res_outputs])
A:jax._src.lax.control_flow.aug_residuals->jax._src.util.subvals(aug_residuals, zip(res_indices, residuals))
A:jax._src.lax.control_flow.all_res_vars->_map(newvar, all_res_avals)
A:jax._src.lax.control_flow.aug_res_vars->list(util.subvals(all_res_vars, zip(res_indices, res_vars)))
A:jax._src.lax.control_flow.jaxpr_aug->jax.core.ClosedJaxpr(jaxpr_aug, jaxpr.consts)
A:jax._src.lax.control_flow.d->collections.OrderedDict(((x, None) for x in xs))
A:jax._src.lax.control_flow.(res_avals, primal_avals)->split_list(jaxpr.in_avals, [num_res])
A:jax._src.lax.control_flow.primal_avals->_map(raise_to_shaped, primal_avals)
A:jax._src.lax.control_flow.(res, cts_out)->split_list(args, [num_res])
A:jax._src.lax.control_flow.cts_in->jax.interpreters.ad.backward_pass(jaxpr.jaxpr, reduce_axes, False, jaxpr.consts, primals, cts_out)
A:jax._src.lax.control_flow.(_, cts_in)->split_list(cts_in, [num_res])
A:jax._src.lax.control_flow.in_avals->_map(raise_to_shaped, branches[0].in_avals)
A:jax._src.lax.control_flow.branches_trans->tuple((_transpose_cond_jaxpr(jaxpr, num_res, reduce_axes) for jaxpr in branches))
A:jax._src.lax.control_flow.cts->_map(ad.instantiate_zeros_aval, branches[0].out_avals, cts)
A:jax._src.lax.control_flow.out_iter->iter(out)
A:jax._src.lax.control_flow.tc->partial(_typecheck_param, 'scan')
A:jax._src.lax.control_flow.jaxpr0_in_avals_str->_avals_short(jaxpr0.in_avals)
A:jax._src.lax.control_flow.jaxpr0_out_avals_str->_avals_short(jaxpr0.out_avals)
A:jax._src.lax.control_flow.avals->_map(core.get_aval, args)
A:jax._src.lax.control_flow.cond_p->jax.core.AxisPrimitive('cond')
A:jax._src.lax.control_flow.pe.partial_eval_jaxpr_custom_rules[cond_p]->partial(pe.partial_eval_jaxpr_custom_rule_not_implemented, 'cond')
A:jax._src.lax.control_flow.output_types->_map(mlir.aval_to_ir_types, ctx.avals_out)
A:jax._src.lax.control_flow.flat_output_types->jax._src.util.flatten(output_types)
A:jax._src.lax.control_flow.case_op->jax._src.lib.mlir.dialects.mhlo.CaseOp.build_generic(flat_output_types, [index], regions=len(branches))
A:jax._src.lax.control_flow.branch->jax._src.lib.mlir.dialects.mhlo.CaseOp.build_generic(flat_output_types, [index], regions=len(branches)).regions[i].blocks.append()
A:jax._src.lax.control_flow.out_vals->jax.core.AxisPrimitive('scan').bind(dynamic_length, *consts, dtypes.int_(0), *init, *xs, reverse=reverse, length=max_length, jaxpr=masked_jaxpr, num_consts=1 + num_consts, num_carry=1 + num_carry, linear=tuple([False] + const_linear + [False] + init_linear + xs_linear), unroll=unroll)
A:jax._src.lax.control_flow.Carry->TypeVar('Carry')
A:jax._src.lax.control_flow.X->TypeVar('X')
A:jax._src.lax.control_flow.Y->TypeVar('Y')
A:jax._src.lax.control_flow.(xs_flat, xs_tree)->tree_flatten(xs)
A:jax._src.lax.control_flow.length->int(length)
A:jax._src.lax.control_flow.unique_lengths->set(lengths)
A:jax._src.lax.control_flow.(carry, y)->split_list(out, [num_carry])
A:jax._src.lax.control_flow.stacked_y->tree_map(stack, *maybe_reversed(ys))
A:jax._src.lax.control_flow.x_avals->tuple(_map(ShapedArray, x_shapes, x_dtypes))
A:jax._src.lax.control_flow.(init_flat, init_tree)->tree_flatten(init)
A:jax._src.lax.control_flow.(in_flat, in_tree)->tree_flatten((init, xs))
A:jax._src.lax.control_flow.carry_avals->tuple(_map(_abstractify, init_flat))
A:jax._src.lax.control_flow.out_tree_children->out_tree.children()
A:jax._src.lax.control_flow.(init_flat, carry_avals, carry_avals_out, init_tree, *rest)->_create_jaxpr(new_init)
A:jax._src.lax.control_flow.(new_init_flat, changed)->_promote_weak_typed_inputs(init_flat, carry_avals, carry_avals_out)
A:jax._src.lax.control_flow.new_init->tree_unflatten(init_tree, new_init_flat)
A:jax._src.lax.control_flow.(consts, init, xs)->split_list(padded_vals, [num_consts, num_carry])
A:jax._src.lax.control_flow.x->jax.core.AxisPrimitive('custom_linear_solve').bind(*primals, **kwargs)
A:jax._src.lax.control_flow.ys->_map(_concatenate, y_avals, ys, ys_rem)
A:jax._src.lax.control_flow.([i], carry, ys)->split_list(vals, [1, num_carry])
A:jax._src.lax.control_flow.out_flat->jax.core.AxisPrimitive('custom_linear_solve').bind(*_flatten(all_consts) + b_flat, const_lengths=const_lengths, jaxprs=jaxprs)
A:jax._src.lax.control_flow.(carry_out, y_updates)->split_list(out_flat, [num_carry])
A:jax._src.lax.control_flow.ys_out->_map(partial(_update_array, i_), y_avals, ys, y_updates)
A:jax._src.lax.control_flow.ys_init->_map(partial(_empty_array, length), y_avals)
A:jax._src.lax.control_flow.(_, *outs)->while_loop(cond_fun, body_fun, init_val)
A:jax._src.lax.control_flow.(num_blocks, rem)->divmod(length, unroll)
A:jax._src.lax.control_flow.partition->partial(_partition_leading, num_blocks, block_length)
A:jax._src.lax.control_flow.xs_block->_map(partition, x_avals, xs)
A:jax._src.lax.control_flow.prepend_aval->partial(_prepend_dim_to_aval, block_length)
A:jax._src.lax.control_flow.x_block_avals->_map(prepend_aval, x_avals)
A:jax._src.lax.control_flow.y_block_avals->_map(prepend_aval, y_avals)
A:jax._src.lax.control_flow.f_impl_block->partial(_scan_impl_unrolled, reverse=reverse, length=block_length, num_consts=num_consts, num_carry=num_carry, linear=linear, f_impl=f_impl, x_avals=x_avals, y_avals=y_avals)
A:jax._src.lax.control_flow.(carry, ys_blocks)->split_list(outs, [num_carry])
A:jax._src.lax.control_flow.combine->partial(_combine_leading, num_blocks, block_length)
A:jax._src.lax.control_flow.(_, _, x_avals)->split_list(jaxpr.in_avals, [num_consts, num_carry])
A:jax._src.lax.control_flow.(_, y_avals)->split_list(jaxpr.out_avals, [num_carry])
A:jax._src.lax.control_flow.f_impl->jax.core.jaxpr_as_fun(jaxpr)
A:jax._src.lax.control_flow.split->partial(_split_leading_dim, length_div)
A:jax._src.lax.control_flow.(xs_rem, xs)->unzip2(_map(split, x_avals, xs))
A:jax._src.lax.control_flow.(xs, xs_rem)->unzip2(_map(split, x_avals, xs))
A:jax._src.lax.control_flow.(carry, ys)->split_list(outs, [num_carry])
A:jax._src.lax.control_flow.(carry, ys_rem)->split_list(outs, [num_carry])
A:jax._src.lax.control_flow.(carry_avals, y_avals)->split_list(jaxpr.out_avals, [num_carry])
A:jax._src.lax.control_flow.ys_avals->_map(partial(_prepend_dim_to_aval, length), y_avals)
A:jax._src.lax.control_flow.(const_nz, init_nz, xs_nz)->split_list(nonzeros, [num_consts, num_carry])
A:jax._src.lax.control_flow.(jaxpr_jvp, nonzeros_out)->jax.interpreters.ad.jvp_jaxpr(jaxpr, nonzeros, instantiate=carry_nz + [False] * num_ys)
A:jax._src.lax.control_flow.all_tangents->split_list(tangents, [num_consts, num_carry])
A:jax._src.lax.control_flow.(consts_dot, init_dot, xs_dot)->_map(_prune_zeros, all_tangents)
A:jax._src.lax.control_flow.jaxpr_jvp_rearranged->jax.interpreters.ad.rearrange_binders(jaxpr_jvp, [num_consts, num_carry, num_xs], [len(consts_dot), len(init_dot), len(xs_dot)], [num_carry, num_ys], [len(init_dot), sum(nonzeros_out) - len(init_dot)])
A:jax._src.lax.control_flow.(consts_linear, init_linear, xs_linear)->split_list(linear, [num_consts, num_carry])
A:jax._src.lax.control_flow.jaxpr_jvp_linear->tuple(consts_linear + [True] * len(consts_dot) + init_linear + [True] * len(init_dot) + xs_linear + [True] * len(xs_dot))
A:jax._src.lax.control_flow.(carry, carry_dot, ys, ys_dot)->split_list(out_flat, [num_carry, len(init_dot), num_ys])
A:jax._src.lax.control_flow.tangents_out_iter->iter(carry_dot + ys_dot)
A:jax._src.lax.control_flow.(const_uk, init_uk, xs_uk)->split_list(unknowns, [num_consts, num_carry])
A:jax._src.lax.control_flow.(jaxpr_1, jaxpr_2, out_uk)->jax.interpreters.partial_eval.partial_eval_jaxpr(jaxpr, unknowns, instantiate=carry_uk + [False] * num_ys)
A:jax._src.lax.control_flow.(jaxpr_1_opt, out_pvals_1, consts_1)->jax.interpreters.partial_eval.trace_to_jaxpr(lu.wrap_init(core.jaxpr_as_fun(jaxpr_1)), in_pvals_1, instantiate=[True] * (num_carry + num_ys) + [False] * num_res)
A:jax._src.lax.control_flow.jaxpr_1_opt->jax.interpreters.partial_eval.ClosedJaxpr(pe.convert_constvars_jaxpr(jaxpr_1_opt), ())
A:jax._src.lax.control_flow.(_, _, res_pvals)->split_list(out_pvals_1, [num_carry, num_ys])
A:jax._src.lax.control_flow.jaxpr_2_opt->jax.interpreters.partial_eval.move_binders_to_front(jaxpr_2, move)
A:jax._src.lax.control_flow.(out_carry, out_extensive)->split_list(out_flat, [num_carry])
A:jax._src.lax.control_flow.out_extensive_iter->iter(out_extensive)
A:jax._src.lax.control_flow.(out_carry, ys, res_and_units)->split_list(out_flat, [num_carry, num_ys])
A:jax._src.lax.control_flow.int_res_tracers->_map(trace.new_instantiated_const, intensive_residuals)
A:jax._src.lax.control_flow.ext_res_tracers->_map(trace.new_instantiated_const, extensive_residuals)
A:jax._src.lax.control_flow.(consts_lin, init_lin, xs_lin)->split_list(linear, [num_consts, num_carry])
A:jax._src.lax.control_flow.(consts, _, xs)->split_list(args, [num_consts, num_carry])
A:jax._src.lax.control_flow.(ires, _)->split_list(consts, [num_ires])
A:jax._src.lax.control_flow.(_, eres)->split_list(xs, [sum(xs_lin)])
A:jax._src.lax.control_flow.(ct_carry, ct_ys)->split_list(cts, [num_carry])
A:jax._src.lax.control_flow.ct_carry->_map(ad.instantiate_zeros_aval, carry_avals, ct_carry)
A:jax._src.lax.control_flow.ct_ys->_map(ad.instantiate_zeros_aval, ys_avals, ct_ys)
A:jax._src.lax.control_flow.ct_consts->_map(ad_util.zeros_like_aval, jaxpr.in_avals[num_ires:num_consts])
A:jax._src.lax.control_flow.jaxpr_trans->_transpose_scan_jaxpr(num_ires, num_consts - num_ires, num_eres, jaxpr, reduce_axes)
A:jax._src.lax.control_flow.(ct_consts, ct_init, ct_xs)->split_list(outs, [num_consts - num_ires, num_carry])
A:jax._src.lax.control_flow.(res1_avals, c_avals, a_avals, res2_avals)->split_list(jaxpr.in_avals, [num_res1, num_c, num_a])
A:jax._src.lax.control_flow.num_b->len(jaxpr.out_avals)
A:jax._src.lax.control_flow.b_avals->tuple(_map(_abstractify, b_flat))
A:jax._src.lax.control_flow.(res1, c_bar, b_bar, res2)->split_list(res1_cbar_bbar_res2, [num_res1, num_c, num_b])
A:jax._src.lax.control_flow.cbar_abar->jax.interpreters.ad.backward_pass(jaxpr.jaxpr, reduce_axes, False, jaxpr.consts, primals, b_bar)
A:jax._src.lax.control_flow.(_, new_c_bar, a_bar, _)->split_list(cbar_abar, [num_res1, num_c, num_a])
A:jax._src.lax.control_flow.a_bar->_map(ad.instantiate_zeros_aval, a_avals, a_bar)
A:jax._src.lax.control_flow.c_bar->_map(ad.instantiate_zeros_aval, c_avals, _map(ad.add_tangents, c_bar, new_c_bar))
A:jax._src.lax.control_flow.(const_batched, init_batched, xs_batched)->split_list(orig_batched, [num_consts, num_carry])
A:jax._src.lax.control_flow.(jaxpr_batched, batched_out)->jax.interpreters.batching.batch_jaxpr(jaxpr, axis_size, batched, instantiate=carry_batched + [False] * num_ys, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.carry_batched->_map(operator.or_, carry_batched, carry_batched_out)
A:jax._src.lax.control_flow.(consts_bdims, init_bdims, xs_bdims)->split_list(dims, [num_consts, num_carry])
A:jax._src.lax.control_flow.(dynamic_length,)->jax.interpreters.masking.shape_as_value((length,))
A:jax._src.lax.control_flow.masked_jaxpr->_masked_scan_jaxpr(jaxpr, num_consts, num_carry)
A:jax._src.lax.control_flow.(const_linear, init_linear, xs_linear)->split_list(linear, [num_consts, num_carry])
A:jax._src.lax.control_flow.dynamic_length->jax._src.lax.lax.convert_element_type(dynamic_length, dtypes.int_)
A:jax._src.lax.control_flow.fun->jax.core.jaxpr_as_fun(jaxpr)
A:jax._src.lax.control_flow.([dynamic_length], consts, [i], carry, xs)->split_list(args, [1, num_consts, 1, num_carry])
A:jax._src.lax.control_flow.(new_carry, ys)->split_list(out, [num_carry])
A:jax._src.lax.control_flow.aval->ShapedArray((), dtypes.canonicalize_dtype(dtypes.int_))
A:jax._src.lax.control_flow.(const_avals, carry_avals, x_avals)->split_list(jaxpr.in_avals, [num_consts, num_carry])
A:jax._src.lax.control_flow.padded_jaxpr->jax.core.ClosedJaxpr(*pe.pad_jaxpr(jaxpr.jaxpr, jaxpr.consts))
A:jax._src.lax.control_flow.(const_avals, init_avals, x_avals)->split_list(avals, [num_consts, num_carry])
A:jax._src.lax.control_flow.(const_avals_jaxpr, init_avals_jaxpr, x_avals_jaxpr)->split_list(jaxpr.in_avals, [num_consts, num_carry])
A:jax._src.lax.control_flow.(carry_avals_jaxpr, _)->split_list(jaxpr.out_avals, [num_carry])
A:jax._src.lax.control_flow.x_avals_mapped->_map(partial(core.mapped_aval, length, 0), x_avals)
A:jax._src.lax.control_flow.scan_p->jax.core.AxisPrimitive('scan')
A:jax._src.lax.control_flow.core.custom_typechecks[scan_p]->partial(_scan_typecheck, False)
A:jax._src.lax.control_flow.pe.partial_eval_jaxpr_custom_rules[scan_p]->partial(pe.partial_eval_jaxpr_custom_rule_not_implemented, 'scan')
A:jax._src.lax.control_flow.(_, ys)->scan(g, (), xs)
A:jax._src.lax.control_flow.result->_memcpy(dimension, logical_shape[dimension], padded_val, result, offset)
A:jax._src.lax.control_flow.update->jax._src.lax.slicing.dynamic_index_in_dim(src, i, axis)
A:jax._src.lax.control_flow.key->jax.interpreters.batching.moveaxis(key, bd, 0)
A:jax._src.lax.control_flow.(stacked_keys, stacked_bits)->map(map_body, key)
A:jax._src.lax.control_flow.diff->tree_map(_show_diff, tree_unflatten(tree1, avals1), tree_unflatten(tree2, avals2))
A:jax._src.lax.control_flow.actual_tree_children->tree_structure(actual_tree_children[0]).children()
A:jax._src.lax.control_flow.actual_tree->tree_structure(actual_tree_children[0])
A:jax._src.lax.control_flow.new_dtype->jax._src.dtypes.result_type(in_vals[i], out_avals[i])
A:jax._src.lax.control_flow.in_vals[i]->jax._src.lax.lax.convert_element_type(in_vals[i], new_dtype)
A:jax._src.lax.control_flow._RootTuple->collections.namedtuple('_RootTuple', 'f, solve, l_and_s')
A:jax._src.lax.control_flow.params_list->split_list(args, list(const_lengths))
A:jax._src.lax.control_flow.(guess_flat, in_args_tree)->tree_flatten((initial_guess,))
A:jax._src.lax.control_flow.guess_avals->tuple(_map(_abstractify, guess_flat))
A:jax._src.lax.control_flow.(f_jaxpr, f_consts, out_tree)->_initial_style_jaxpr(f, in_args_tree, guess_avals)
A:jax._src.lax.control_flow.(in_tree,)->treedef_children(in_args_tree)
A:jax._src.lax.control_flow.(solve_jaxpr, solve_consts, solution_tree)->_initial_style_jaxpr(partial(solve, f), in_args_tree, guess_avals)
A:jax._src.lax.control_flow.(unchecked_zeros, f_jvp)->jax.linearize(f, x)
A:jax._src.lax.control_flow.(l_and_s_jaxpr, l_and_s_consts, out_tree)->_initial_style_jaxpr(linearize_and_solve, treedef_tuple((in_tree,) * 2), guess_avals * 2)
A:jax._src.lax.control_flow.const_lengths->_LinearSolveTuple(*_map(len, all_consts))
A:jax._src.lax.control_flow.jaxprs->_LinearSolveTuple(matvec_jaxpr, vecmat_jaxpr, solve_jaxpr, tr_solve_jaxpr)
A:jax._src.lax.control_flow.solution_flat->_custom_root(const_lengths, jaxprs, *_flatten(all_consts) + guess_flat)
A:jax._src.lax.control_flow.(params, initial_guess)->_split_root_args(args, const_lengths)
A:jax._src.lax.control_flow.solution->jax.core.jaxpr_as_fun(jaxprs.solve)(*params.solve + initial_guess)
A:jax._src.lax.control_flow.(params, _)->_split_linear_solve_args(primals, const_lengths)
A:jax._src.lax.control_flow.sol->_custom_root(const_lengths, jaxprs, *primals)
A:jax._src.lax.control_flow.f_out_vals->len(jaxprs.f.out_avals)
A:jax._src.lax.control_flow.(solution, aux)->split_list(sol, [f_out_vals])
A:jax._src.lax.control_flow.(params_dot, _)->_split_root_args(tangents, const_lengths)
A:jax._src.lax.control_flow.f->jax.core.jaxpr_as_fun(jaxprs.f)
A:jax._src.lax.control_flow.linearize_and_solve->partial(core.jaxpr_as_fun(jaxprs.l_and_s), *params.l_and_s)
A:jax._src.lax.control_flow.(_, rhs)->jax.interpreters.ad.jvp(lu.wrap_init(f_at_solution)).call_wrapped(params.f, params_dot.f)
A:jax._src.lax.control_flow.solution_dot->_map(operator.neg, linearize_and_solve(*solution, *rhs))
A:jax._src.lax.control_flow.transpose_fun->jax.linear_transpose(linear_fun, primals)
A:jax._src.lax.control_flow.(y,)->transpose_fun(x)
A:jax._src.lax.control_flow.actual_shapes->_map(np.shape, tree_leaves(actual))
A:jax._src.lax.control_flow.expected_shapes->_map(np.shape, tree_leaves(expected))
A:jax._src.lax.control_flow.(b_flat, in_args_tree)->tree_flatten((b,))
A:jax._src.lax.control_flow.(tree,)->treedef_children(in_args_tree)
A:jax._src.lax.control_flow.y->fun(x)
A:jax._src.lax.control_flow.(y, aux)->fun(x)
A:jax._src.lax.control_flow.(matvec_jaxpr, matvec_consts, out_tree)->_initial_style_jaxpr(_shape_checked(matvec, 'matvec', False), in_args_tree, b_avals, 'custom_linear_solve')
A:jax._src.lax.control_flow.(solve_jaxpr, solve_consts, out_tree)->_initial_style_jaxpr(_shape_checked(partial(solve, matvec), 'solve', has_aux), in_args_tree, b_avals, 'custom_linear_solve')
A:jax._src.lax.control_flow.vecmat->_transpose_one_output(matvec, b)
A:jax._src.lax.control_flow.(vecmat_jaxpr, vecmat_consts, out_tree)->_initial_style_jaxpr(vecmat, in_args_tree, b_avals, 'custom_linear_solve')
A:jax._src.lax.control_flow.(tr_solve_jaxpr, tr_solve_consts, out_tree)->_initial_style_jaxpr(_shape_checked(partial(transpose_solve, vecmat), 'transpose_solve', has_aux), in_args_tree, b_avals, 'custom_linear_solve')
A:jax._src.lax.control_flow.(params, b)->_split_linear_solve_args(args, const_lengths)
A:jax._src.lax.control_flow.zeros->_map(ad_util.Zero.from_value, x)
A:jax._src.lax.control_flow.(_, out_tangent)->jax.interpreters.ad.jvp(lu.wrap_init(func)).call_wrapped(params + list(x), params_dot + zeros)
A:jax._src.lax.control_flow.kwargs->dict(const_lengths=const_lengths, jaxprs=jaxprs)
A:jax._src.lax.control_flow.(params_dot, b_dot)->_split_linear_solve_args(tangents, const_lengths)
A:jax._src.lax.control_flow.num_x_leaves->len(b_dot)
A:jax._src.lax.control_flow.(x_leaves, _)->split_list(x, [num_x_leaves])
A:jax._src.lax.control_flow.matvec_tangents->_tangent_linear_map(core.jaxpr_as_fun(jaxprs.matvec), params.matvec, params_dot.matvec, *x_leaves)
A:jax._src.lax.control_flow.rhs->_map(ad.add_tangents, b_dot, _map(operator.neg, matvec_tangents))
A:jax._src.lax.control_flow.x_dot->jax.core.AxisPrimitive('custom_linear_solve').bind(*_flatten(params) + rhs, **kwargs)
A:jax._src.lax.control_flow.(dx_leaves, daux_leaves)->split_list(x_dot, [num_x_leaves])
A:jax._src.lax.control_flow.daux_leaves->_map(ad_util.Zero.from_value, daux_leaves)
A:jax._src.lax.control_flow.(x_cotangent, _)->split_list(cotangent, [len(b)])
A:jax._src.lax.control_flow.cotangent_b_full->jax.core.AxisPrimitive('custom_linear_solve').bind(*_flatten(params.transpose()) + x_cotangent, const_lengths=const_lengths.transpose(), jaxprs=jaxprs.transpose())
A:jax._src.lax.control_flow.(cotangent_b, _)->split_list(cotangent_b_full, [len(b)])
A:jax._src.lax.control_flow.(params_dims, b_dims)->_split_linear_solve_args(dims, const_lengths)
A:jax._src.lax.control_flow.(params_bat, orig_b_bat)->_split_linear_solve_args(orig_bat, const_lengths)
A:jax._src.lax.control_flow.(solve_jaxpr_batched, solve_x_bat)->jax.interpreters.batching.batch_jaxpr(solve, axis_size, solve_bat + b_bat, instantiate=x_bat, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.(vecmat_jaxpr_batched, vecmat_x_bat)->jax.interpreters.batching.batch_jaxpr(vecmat, axis_size, vecmat_bat + b_bat, instantiate=x_bat, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.x_bat_out->_map(operator.or_, vecmat_x_bat + [True] * num_aux, solve_x_bat)
A:jax._src.lax.control_flow.(matvec_jaxpr_batched, matvec_b_bat)->jax.interpreters.batching.batch_jaxpr(matvec, axis_size, matvec_bat + x_bat_out, instantiate=b_bat, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.b_bat_out->_map(lambda m, s, o: m or s or o, matvec_b_bat, solve_t_b_bat, orig_b_bat)
A:jax._src.lax.control_flow.(solve_t_jaxpr_batched, solve_t_b_aux_bat)->jax.interpreters.batching.batch_jaxpr(solve_t, axis_size, solve_t_bat + x_bat_out, instantiate=b_bat, axis_name=axis_name, main_type=main_type)
A:jax._src.lax.control_flow.(solve_t_b_bat, _)->split_list(solve_t_b_aux_bat, [len(orig_b_bat)])
A:jax._src.lax.control_flow.batched_jaxprs->_LinearSolveTuple(matvec_jaxpr_batched, vecmat_jaxpr_batched, solve_jaxpr_batched, solve_t_jaxpr_batched)
A:jax._src.lax.control_flow.linear_solve_p->jax.core.AxisPrimitive('custom_linear_solve')
A:jax._src.lax.control_flow.pe.partial_eval_jaxpr_custom_rules[linear_solve_p]->partial(pe.partial_eval_jaxpr_custom_rule_not_implemented, 'linear_solve')
A:jax._src.lax.control_flow.(elems_flat, tree)->tree_flatten(elems)
A:jax._src.lax.control_flow.a->tree_unflatten(tree, a_flat)
A:jax._src.lax.control_flow.b->tree_unflatten(tree, b_flat)
A:jax._src.lax.control_flow.(c_flat, _)->tree_flatten(c)
A:jax._src.lax.control_flow.axis->jax._src.util.canonicalize_axis(axis, elems_flat[0].ndim)
A:jax._src.lax.control_flow.num_elems->int(elems_flat[0].shape[axis])
A:jax._src.lax.control_flow.reduced_elems->combine([slicing.slice_in_dim(elem, 0, -1, stride=2, axis=axis) for elem in elems], [slicing.slice_in_dim(elem, 1, None, stride=2, axis=axis) for elem in elems])
A:jax._src.lax.control_flow.odd_elems->_scan(reduced_elems)
A:jax._src.lax.control_flow.even_elems->combine(odd_elems, [slicing.slice_in_dim(e, 2, None, stride=2, axis=axis) for e in elems])
A:jax._src.lax.control_flow.scans->_scan(elems_flat)
A:jax._src.lax.control_flow.reducer_p->jax._src.lax.lax.standard_primitive(_cumred_shape_rule, partial(_cumred_dtype_rule, name), name, translation_rule=xla.lower_fun(partial(associative_scan, reduce_fn), multiple_results=False, new_style=True))
A:jax._src.lax.control_flow.batching.primitive_batchers[reducer_p]->partial(_cumred_batch_rule, reducer_p)
A:jax._src.lax.control_flow.cumsum_p->_cumulative_reduction_primitive('cumsum', lax.add, windowed_reductions._reduce_window_sum)
A:jax._src.lax.control_flow.cumprod_p->_cumulative_reduction_primitive('cumprod', lax.mul, windowed_reductions._reduce_window_prod)
A:jax._src.lax.control_flow.cummax_p->_cumulative_reduction_primitive('cummax', lax.max, windowed_reductions._reduce_window_max)
A:jax._src.lax.control_flow.cummin_p->_cumulative_reduction_primitive('cummin', lax.min, windowed_reductions._reduce_window_min)
A:jax._src.lax.control_flow.ad.primitive_jvps[cumprod_p]->partial(_cumulative_jvp_rule, combine_fn=lax.mul)
A:jax._src.lax.control_flow.ad.primitive_jvps[cummin_p]->partial(_cumulative_jvp_rule, combine_fn=lax.min)
A:jax._src.lax.control_flow.ad.primitive_jvps[cummax_p]->partial(_cumulative_jvp_rule, combine_fn=lax.max)
A:jax._src.lax.control_flow.avals_out->tuple((ov.aval for ov in jaxpr.outvars))
A:jax._src.lax.control_flow.dummies_like_result->tuple(_map(_dummy_remat_result, avals_out))
A:jax._src.lax.control_flow.results->jax.core.eval_jaxpr(jaxpr, (), *args)
A:jax._src.lax.control_flow.carry_res->while_loop(cond, body, carry_init)
A:jax._src.lax.control_flow.args->_optimization_barrier(args)
A:jax._src.lax.control_flow.barrier_types->_map(mlir.aval_to_ir_types, ctx.avals_in)
A:jax._src.lax.control_flow.flat_barrier_types->jax._src.util.flatten(barrier_types)
A:jax._src.lax.control_flow.barrier_op->jax._src.lib.mlir.dialects.mhlo.OptimizationBarrierOp(flat_barrier_types, flat_args)
A:jax._src.lax.control_flow.(flat_args, treedef)->tree_flatten(arg)
A:jax._src.lax.control_flow.optimization_barrier_p->jax.core.Primitive('optimization_barrier')
jax._src.lax.control_flow._LinearSolveTuple(collections.namedtuple('_LinearSolveTuple','matvec,vecmat,solve,transpose_solve'))
jax._src.lax.control_flow._LinearSolveTuple.transpose(self)
jax._src.lax.control_flow._abstractify(x)
jax._src.lax.control_flow._avals_short(avals)
jax._src.lax.control_flow._bcast_select(pred,on_true,on_false)
jax._src.lax.control_flow._bcast_select_n(pred,*cases)
jax._src.lax.control_flow._check_shapes(func_name,expected_name,actual,expected)
jax._src.lax.control_flow._check_tree(func_name,expected_name,actual_tree,expected_tree,has_aux=False)
jax._src.lax.control_flow._check_tree_and_avals(what,tree1,avals1,tree2,avals2)
jax._src.lax.control_flow._combine_leading(sz0,sz1,aval,x)
jax._src.lax.control_flow._concat_masking_rule(padded_vals,logical_shapes,dimension)
jax._src.lax.control_flow._concatenate(aval,x1,x2)
jax._src.lax.control_flow._cond(pred,true_fun:Callable,false_fun:Callable,*operands,operand=_no_operand_sentinel,linear=None)
jax._src.lax.control_flow._cond_abstract_eval(*args,branches,**kwargs)
jax._src.lax.control_flow._cond_batching_rule(axis_size,axis_name,main_type,args,dims,branches,linear)
jax._src.lax.control_flow._cond_jvp(primals,tangents,branches,linear)
jax._src.lax.control_flow._cond_lowering(ctx,index,*args,branches,linear)
jax._src.lax.control_flow._cond_partial_eval(trace,*tracers,branches,linear)
jax._src.lax.control_flow._cond_translation_rule(ctx,avals_in,avals_out,index,*args,branches,linear)
jax._src.lax.control_flow._cond_transpose(reduce_axes,cts,*args,branches,linear)
jax._src.lax.control_flow._cond_typecheck(*avals,branches,linear)
jax._src.lax.control_flow._cond_with_per_branch_args(pred,true_operand,true_fun:Callable,false_operand,false_fun:Callable)
jax._src.lax.control_flow._cumred_batch_rule(prim,batched_args,batch_dims,*,axis:int,reverse:bool)
jax._src.lax.control_flow._cumred_dtype_rule(name,operand,*args,**kw)
jax._src.lax.control_flow._cumred_shape_rule(x,*,axis:int,reverse:bool)
jax._src.lax.control_flow._cumred_tpu_translation_rule(window_reduce:Callable,x,*,axis:int,reverse:bool)
jax._src.lax.control_flow._cumsum_transpose_rule(t,operand,*,axis:int,reverse:bool)
jax._src.lax.control_flow._cumulative_jvp_rule(primals,tangents,*,axis:int,reverse:bool,combine_fn:Callable)
jax._src.lax.control_flow._cumulative_reduction_primitive(name,reduce_fn,tpu_reduce_window_fn)
jax._src.lax.control_flow._custom_linear_solve_impl(*args,const_lengths,jaxprs)
jax._src.lax.control_flow._custom_linear_solve_jvp(primals,tangents,const_lengths,jaxprs)
jax._src.lax.control_flow._custom_root(const_lengths,jaxprs,*args)
jax._src.lax.control_flow._dummy_remat_result(aval:core.AbstractValue)
jax._src.lax.control_flow._dynamic_index_array(i,aval,x)
jax._src.lax.control_flow._empty_array(sz,aval)
jax._src.lax.control_flow._flatten(args)
jax._src.lax.control_flow._fori_body_fun(body_fun)
jax._src.lax.control_flow._fori_cond_fun(loop_carry)
jax._src.lax.control_flow._fori_scan_body_fun(body_fun)
jax._src.lax.control_flow._index_array(i,aval,x)
jax._src.lax.control_flow._initial_style_jaxpr(fun:Callable,in_tree,in_avals,primitive_name:Optional[str]=None)
jax._src.lax.control_flow._initial_style_jaxprs_with_common_consts(funs:Sequence[Callable],in_tree,in_avals,primitive_name:str)
jax._src.lax.control_flow._initial_style_open_jaxpr(fun:Callable,in_tree,in_avals,primitive_name:Optional[str]=None)
jax._src.lax.control_flow._interleave(a,b,axis)
jax._src.lax.control_flow._join_cond_outputs(jaxprs,all_res_avals,res_aval_indices_per_jaxpr,num_non_res_outputs)
jax._src.lax.control_flow._join_cond_pe_staged_jaxpr_inputs(jaxprs,all_res_avals,res_aval_indices_per_jaxpr)
jax._src.lax.control_flow._linear_solve_abstract_eval(*args,const_lengths,jaxprs)
jax._src.lax.control_flow._linear_solve_batching_rule(axis_size,axis_name,main_type,args,dims,const_lengths,jaxprs)
jax._src.lax.control_flow._linear_solve_transpose_rule(cotangent,*primals,const_lengths,jaxprs)
jax._src.lax.control_flow._make_closed_jaxpr(traceable:lu.WrappedFun,in_avals:Sequence[core.AbstractValue])
jax._src.lax.control_flow._masked_scan_jaxpr(jaxpr,num_consts,num_carry)
jax._src.lax.control_flow._maybe_device_put(x)
jax._src.lax.control_flow._memcpy(axis,num,src,dst,offset)
jax._src.lax.control_flow._merge_branch_residuals(branch_res_avals)
jax._src.lax.control_flow._optimization_barrier(arg)
jax._src.lax.control_flow._optimization_barrier_abstract_eval(*args)
jax._src.lax.control_flow._optimization_barrier_lowering_rule(ctx,*args)
jax._src.lax.control_flow._optimization_barrier_translation_rule(ctx,avals_in,avals_out,*args)
jax._src.lax.control_flow._ordered_unique(xs)
jax._src.lax.control_flow._partition_leading(sz0,sz1,aval,x)
jax._src.lax.control_flow._pred_bcast_select(c,pred,x,y,x_y_aval:core.AbstractValue)
jax._src.lax.control_flow._pred_bcast_select_mhlo(pred_aval:core.ShapedArray,pred:ir.Value,xs:Sequence[ir.Value],ys:Sequence[ir.Value],x_y_aval:core.AbstractValue)->Sequence[ir.Value]
jax._src.lax.control_flow._prepend_dim_to_aval(sz,aval)
jax._src.lax.control_flow._promote_weak_typed_inputs(in_vals,in_avals,out_avals)
jax._src.lax.control_flow._prune_zeros(ts)
jax._src.lax.control_flow._remat_translation_rule(*args,call_jaxpr:Optional[core.Jaxpr]=None,jaxpr:Optional[core.Jaxpr]=None,platform:str,prevent_cse:bool,differentiated:bool,policy,concrete:bool=False,name:str='checkpoint')
jax._src.lax.control_flow._remat_translation_using_cond(*args,jaxpr:core.Jaxpr)
jax._src.lax.control_flow._remat_translation_using_opt_barrier(*args,jaxpr:core.Jaxpr)
jax._src.lax.control_flow._remat_translation_using_while(*args,jaxpr:core.Jaxpr)
jax._src.lax.control_flow._rng_bit_generator_batching_rule(batched_args,batch_dims,*,shape,dtype,algorithm)
jax._src.lax.control_flow._root_jvp(const_lengths,jaxprs,primals,tangents)
jax._src.lax.control_flow._scan_abstract_eval(*args,reverse,length,num_consts,num_carry,jaxpr,linear,unroll)
jax._src.lax.control_flow._scan_batching_rule(axis_size,axis_name,main_type,args,dims,reverse,length,jaxpr,num_consts,num_carry,linear,unroll)
jax._src.lax.control_flow._scan_impl(*args,reverse,length,num_consts,num_carry,jaxpr,linear,unroll)
jax._src.lax.control_flow._scan_impl_block_unrolled(*args,reverse,length,num_consts,num_carry,linear,block_length,f_impl,x_avals,y_avals)
jax._src.lax.control_flow._scan_impl_loop(*args,reverse,length,num_consts,num_carry,linear,f_impl,x_avals,y_avals)
jax._src.lax.control_flow._scan_impl_unrolled(*args,reverse,length,num_consts,num_carry,linear,f_impl,x_avals,y_avals)
jax._src.lax.control_flow._scan_jvp(primals,tangents,reverse,length,jaxpr,num_consts,num_carry,linear,unroll)
jax._src.lax.control_flow._scan_masking_rule(padded_vals,logical_shapes,reverse,length,jaxpr,num_consts,num_carry,linear,unroll)
jax._src.lax.control_flow._scan_padding_rule(in_avals,out_avals,*args,jaxpr,**params)
jax._src.lax.control_flow._scan_partial_eval(trace,*tracers,reverse,length,num_consts,num_carry,jaxpr,linear,unroll)
jax._src.lax.control_flow._scan_transpose(reduce_axes,cts,*args,reverse,length,num_consts,num_carry,jaxpr,linear,unroll)
jax._src.lax.control_flow._scan_typecheck(bind_time,*avals,reverse,length,num_consts,num_carry,jaxpr,linear,unroll)
jax._src.lax.control_flow._show_diff(array1,array2)
jax._src.lax.control_flow._split_leading_dim(i,aval,x)
jax._src.lax.control_flow._split_linear_solve_args(args,const_lengths)
jax._src.lax.control_flow._split_root_args(args,const_lengths)
jax._src.lax.control_flow._stack(aval,vals)
jax._src.lax.control_flow._tangent_linear_map(func,params,params_dot,*x)
jax._src.lax.control_flow._transpose_cond_jaxpr(jaxpr,num_res,reduce_axes)
jax._src.lax.control_flow._transpose_one_output(linear_fun,primals)
jax._src.lax.control_flow._transpose_scan_jaxpr(num_res1,num_c,num_res2,jaxpr,reduce_axes)
jax._src.lax.control_flow._typecheck_param(prim,param,name,msg_required,pred)
jax._src.lax.control_flow._update_array(i,aval,xs,x)
jax._src.lax.control_flow._while_loop_abstract_eval(*args,body_jaxpr,**kwargs)
jax._src.lax.control_flow._while_loop_batching_rule(axis_size,axis_name,main_type,args,dims,cond_nconsts,cond_jaxpr,body_nconsts,body_jaxpr)
jax._src.lax.control_flow._while_loop_jvp(primals,tangents,cond_nconsts,cond_jaxpr,body_nconsts,body_jaxpr)
jax._src.lax.control_flow._while_loop_translation_rule(ctx,avals_in,avals_out,*args,cond_jaxpr,body_jaxpr,cond_nconsts,body_nconsts)
jax._src.lax.control_flow._while_lowering(ctx,*args,cond_jaxpr,body_jaxpr,cond_nconsts,body_nconsts)
jax._src.lax.control_flow._while_partial_eval(trace:pe.JaxprTrace,*tracers:pe.Tracer,cond_nconsts:int,cond_jaxpr:pe.ClosedJaxpr,body_nconsts:int,body_jaxpr:pe.ClosedJaxpr)->Sequence[pe.Tracer]
jax._src.lax.control_flow._while_transpose_error(*_,**kwargs)
jax._src.lax.control_flow.associative_scan(fn:Callable,elems,reverse:bool=False,axis:int=0)
jax._src.lax.control_flow.cond(*args,**kwargs)
jax._src.lax.control_flow.cond_bind(*args,branches,linear)
jax._src.lax.control_flow.cummax(operand:Array,axis:int=0,reverse:bool=False)->Array
jax._src.lax.control_flow.cummin(operand:Array,axis:int=0,reverse:bool=False)->Array
jax._src.lax.control_flow.cumprod(operand:Array,axis:int=0,reverse:bool=False)->Array
jax._src.lax.control_flow.cumsum(operand:Array,axis:int=0,reverse:bool=False)->Array
jax._src.lax.control_flow.custom_linear_solve(matvec,b,solve,transpose_solve=None,symmetric=False,has_aux=False)
jax._src.lax.control_flow.custom_root(f,initial_guess,solve,tangent_solve,has_aux=False)
jax._src.lax.control_flow.fori_loop(lower,upper,body_fun,init_val)
jax._src.lax.control_flow.map(f,xs)
jax._src.lax.control_flow.scan(f:Callable[[Carry,X],Tuple[Carry,Y]],init:Carry,xs:X,length:Optional[int]=None,reverse:bool=False,unroll:int=1)->Tuple[Carry, Y]
jax._src.lax.control_flow.scan_bind(*args,**params)
jax._src.lax.control_flow.switch(index,branches:Sequence[Callable],*operands,operand=_no_operand_sentinel)
jax._src.lax.control_flow.while_loop(cond_fun:Callable[[T],BooleanNumeric],body_fun:Callable[[T],T],init_val:T)->T


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/ops/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/ad.py----------------------------------------
A:jax.interpreters.ad.(fun, aux)->jvp_subtrace_aux(fun)
A:jax.interpreters.ad.trace->JVPTrace(main, core.cur_sublevel())
A:jax.interpreters.ad.out_tracers->map(trace.full_raise, ans)
A:jax.interpreters.ad.ans_tracers->map(trace.full_raise, ans)
A:jax.interpreters.ad.(out_primals, out_tangents)->unzip2(((t.primal, t.tangent) for t in ans_tracers))
A:jax.interpreters.ad.has_aux->kwargs.pop('has_aux', False)
A:jax.interpreters.ad.jvpfun->jvp(traceable)
A:jax.interpreters.ad.(jvpfun, aux)->jvp(traceable, has_aux=True)
A:jax.interpreters.ad.(_, in_tree)->tree_flatten(((primals, primals), {}))
A:jax.interpreters.ad.(jvpfun_flat, out_tree)->flatten_fun(jvpfun, in_tree)
A:jax.interpreters.ad.(jaxpr, out_pvals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr(jvpfun_flat, in_pvals)
A:jax.interpreters.ad.(out_primals_pvals, out_tangents_pvals)->tree_unflatten(out_tree(), out_pvals)
A:jax.interpreters.ad.(_, out_primals_consts)->unzip2(out_primals_pvals)
A:jax.interpreters.ad.(out_primals, pvals, jaxpr, consts)->linearize(traceable, *primals)
A:jax.interpreters.ad.(out_primals, pvals, jaxpr, consts, aux)->linearize(traceable, *primals, has_aux=True)
A:jax.interpreters.ad.cts->tuple(map(ignore_consts, cts, pvals))
A:jax.interpreters.ad.arg_cts->tree_unflatten(out_tree(), out_flat)
A:jax.interpreters.ad.vjp_->Partial(partial(unbound_vjp, pvals, jaxpr), consts)
A:jax.interpreters.ad.axes_to_reduce->tuple((axis_name for axis_name in reduce_axes if axis_name in core.get_aval(ct).named_shape and axis_name not in v.aval.named_shape))
A:jax.interpreters.ad.ct->jax.lax.psum(ct, axis_name=axes_to_reduce)
A:jax.interpreters.ad.ct_aval->jax.core.get_aval(ct_env[v])
A:jax.interpreters.ad.joined_aval->jax.core.lattice_join(v.aval, ct_aval).strip_weak_type().strip_named_shape()
A:jax.interpreters.ad.invals->map(read_primal, eqn.invars)
A:jax.interpreters.ad.cts_in->bwd.call_wrapped(*res, *cts_out)
A:jax.interpreters.ad.(cts_in,)->map(read_cotangent, eqn.outvars)
A:jax.interpreters.ad.params->update_params(params, map(is_undefined_primal, args), [type(x) is not Zero for x in ct])
A:jax.interpreters.ad.call_jaxpr->_close_jaxpr(call_jaxpr)
A:jax.interpreters.ad.cts_out->map(instantiate_zeros_aval, out_avals, cts_out)
A:jax.interpreters.ad.cotangents_out->backward_pass(tangent_jaxpr.jaxpr, reduce_axes, False, (), (*primals_in, *res), cotangents_in)
A:jax.interpreters.ad.tangent_zero->Zero(get_aval(val).at_least_vspace())
A:jax.interpreters.ad.(primals_in, tangents_in)->unzip2(((t.primal, t.tangent) for t in tracers))
A:jax.interpreters.ad.jvp->primitive_jvps.get(primitive)
A:jax.interpreters.ad.(primal_out, tangent_out)->tree_unflatten(out_tree_def(), result)
A:jax.interpreters.ad.(primals, tangents)->tree_unflatten(treedef, x)
A:jax.interpreters.ad.(nonzero_tangents, tangent_tree_def)->tree_flatten(tangents)
A:jax.interpreters.ad.f_jvp->_update_annotation(f_jvp, f.in_type, nz_tangents)
A:jax.interpreters.ad.(f_jvp, nz_tangents_out)->nonzero_tangent_outputs(f_jvp)
A:jax.interpreters.ad.out_axes->out_axes_thunk()
A:jax.interpreters.ad.(f_jvp, out_tree_def)->traceable(f_jvp, len(primals), tangent_tree_def)
A:jax.interpreters.ad.update_params->call_transpose_param_updaters.get(primitive)
A:jax.interpreters.ad.result->call_primitive.bind(f_jvp, *primals, *nonzero_tangents, **new_params)
A:jax.interpreters.ad.(out, treedef)->tree_flatten((primals, tangents))
A:jax.interpreters.ad.primals_in->map(core.full_lower, primals_in)
A:jax.interpreters.ad.tangents_in->map(instantiate_zeros, tangents_in)
A:jax.interpreters.ad.outs->_update_annotation(f_jvp, f.in_type, nz_tangents).call_wrapped(*it.chain(primals_in, tangents_in))
A:jax.interpreters.ad.(primals_out, tangents_out)->split_list(outs, [len(outs) // 2])
A:jax.interpreters.ad.tangents_out->list(tangents_out)
A:jax.interpreters.ad.res_and_primals_out->fwd.call_wrapped(*map(core.full_lower, primals_in))
A:jax.interpreters.ad.(out_tree, res_tree)->out_trees()
A:jax.interpreters.ad.(res, primals_out)->split_list(res_and_primals_out, [res_tree.num_leaves])
A:jax.interpreters.ad.(ps_in, ts_in)->unzip2(((t.primal, t.tangent) for t in tracers))
A:jax.interpreters.ad.(res_ps_in, lin_ps_in)->split_list(ps_in, [params['res_tree'].num_leaves])
A:jax.interpreters.ad.(res_ts_in, lin_ts_in)->split_list(ts_in, [params['res_tree'].num_leaves])
A:jax.interpreters.ad.ps_out->prim.bind(call, *ps_in, **params)
A:jax.interpreters.ad.lin_ts_in->map(instantiate_zeros, lin_ts_in)
A:jax.interpreters.ad.ts_out->prim.bind(call, *res_ps_in, *lin_ts_in, **params)
A:jax.interpreters.ad.primal_aval->raise_to_shaped(get_aval(primal), weak_type=False)
A:jax.interpreters.ad.tangent_aval->raise_to_shaped(get_aval(tangent), weak_type=False)
A:jax.interpreters.ad.expected_tangent_dtype->jax.core.primal_dtype_to_tangent_dtype(primal_aval.dtype)
A:jax.interpreters.ad.primitive_jvps[primitive]->partial(zero_jvp, primitive)
A:jax.interpreters.ad.primitive_transposes[primitive]->partial(linear_transpose2, transpose_rule)
A:jax.interpreters.ad.val_out->primitive.bind(*primals, **params)
A:jax.interpreters.ad.tangents->map(instantiate_zeros, tangents)
A:jax.interpreters.ad.primitive_transposes[prim]->partial(bilinear_transpose, lhs_rule, rhs_rule)
A:jax.interpreters.ad.out->rhs_rule(cotangent, x, **kwargs)
A:jax.interpreters.ad.r->primitive.bind(*primals, **params)
A:jax.interpreters.ad.new_tangents->tree_unflatten(in_tree_def, new_tangents)
A:jax.interpreters.ad.(out_flat, tree_def)->tree_flatten((primal_out, tangent_out))
A:jax.interpreters.ad.(all_args, in_tree_def)->tree_flatten(((), args, ct))
A:jax.interpreters.ad.fun->jax.linear_util.hashable_partial(lu.wrap_init(backward_pass), call_jaxpr, reduce_axes, False)
A:jax.interpreters.ad.(fun, out_tree)->flatten_fun_nokwargs(fun, in_tree_def)
A:jax.interpreters.ad.out_flat->primitive.bind(fun, *all_args, **new_params)
A:jax.interpreters.ad.primitive_transposes[core.call_p]->partial(call_transpose, call_p)
A:jax.interpreters.ad.unknowns->map(is_undefined_primal, primals_in)
A:jax.interpreters.ad.(primal_jaxpr, tangent_jaxpr, _)->jax.interpreters.partial_eval.partial_eval_jaxpr(call_jaxpr, unknowns=unknowns, instantiate=True)
A:jax.interpreters.ad.(args, in_tree_def)->tree_flatten((primals_in, cotangents_in))
A:jax.interpreters.ad.transpose->jax.linear_util.hashable_partial(lu.wrap_init(_remat_transpose), primal_jaxpr, tangent_jaxpr, reduce_axes)
A:jax.interpreters.ad.(flat_transpose, out_tree)->flatten_fun_nokwargs(transpose, in_tree_def)
A:jax.interpreters.ad.flat_cotangents_out->jax.interpreters.partial_eval.remat_call_p.bind(flat_transpose, *args, **params)
A:jax.interpreters.ad.(fun, nz_arg_cts)->nonzero_outputs(fun)
A:jax.interpreters.ad.new_params->update_params(new_params, map(is_undefined_primal, args), [type(x) is not Zero for x in ct])
A:jax.interpreters.ad.f->jax.linear_util.wrap_init(core.jaxpr_as_fun(jaxpr))
A:jax.interpreters.ad.(f_jvp, out_nonzeros)->f_jvp_traceable(jvp(f, instantiate=instantiate, transform_stack=False), nonzeros)
A:jax.interpreters.ad.avals_in->list(it.chain(jaxpr.in_avals, tangent_avals))
A:jax.interpreters.ad.(jaxpr_out, avals_out, literals_out)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(f_jvp, avals_in)
A:jax.interpreters.ad.num_primals->len(nonzeros)
A:jax.interpreters.ad.primals->list(primals_and_nztangents[:num_primals])
A:jax.interpreters.ad.nonzero_tangents->iter(primals_and_nztangents[num_primals:])
A:jax.interpreters.ad.new_invars->_perm(primals_in, tangents_in, jaxpr.jaxpr.invars)
A:jax.interpreters.ad.new_outvars->_perm(primals_out, tangents_out, jaxpr.jaxpr.outvars)
A:jax.interpreters.ad.new_jaxpr->jax.core.Jaxpr(jaxpr.jaxpr.constvars, new_invars, new_outvars, jaxpr.jaxpr.eqns, jaxpr.jaxpr.effects)
A:jax.interpreters.ad.n->sum(primal_counts)
A:jax.interpreters.ad.primal_groups->split_list(primals, primal_counts[:-1])
A:jax.interpreters.ad.tangent_groups->split_list(tangents, tangent_counts[:-1])
A:jax.interpreters.ad.(res, _)->split_list(invals, [num_res])
jax.interpreters.ad.CustomJVPException(self)
jax.interpreters.ad.CustomJVPException.__init__(self)
jax.interpreters.ad.CustomVJPException(self)
jax.interpreters.ad.CustomVJPException.__init__(self)
jax.interpreters.ad.JVPTrace(Trace)
jax.interpreters.ad.JVPTrace.join(self,xt,yt)
jax.interpreters.ad.JVPTrace.lift(self,val)
jax.interpreters.ad.JVPTrace.post_process_call(self,call_primitive,out_tracers,params)
jax.interpreters.ad.JVPTrace.post_process_custom_jvp_call(self,out_tracers,_)
jax.interpreters.ad.JVPTrace.post_process_custom_vjp_call(self,out_tracers,_)
jax.interpreters.ad.JVPTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.ad.JVPTrace.process_custom_jvp_call(self,_,__,f_jvp,tracers)
jax.interpreters.ad.JVPTrace.process_custom_transpose(self,prim,call,tracers,**params)
jax.interpreters.ad.JVPTrace.process_custom_vjp_call(self,_,__,fwd,bwd,tracers,*,out_trees)
jax.interpreters.ad.JVPTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.ad.JVPTrace.pure(self,val)
jax.interpreters.ad.JVPTrace.sublift(self,val)
jax.interpreters.ad.JVPTracer(self,trace,primal,tangent)
jax.interpreters.ad.JVPTracer.__init__(self,trace,primal,tangent)
jax.interpreters.ad.JVPTracer.aval(self)
jax.interpreters.ad.JVPTracer.full_lower(self)
jax.interpreters.ad.UndefinedPrimal(self,aval)
jax.interpreters.ad.UndefinedPrimal.__init__(self,aval)
jax.interpreters.ad.UndefinedPrimal.__repr__(self)
jax.interpreters.ad._close_jaxpr(jaxpr:core.Jaxpr)->core.ClosedJaxpr
jax.interpreters.ad._custom_lin_transpose(cts_out,*invals,num_res,bwd,out_avals)
jax.interpreters.ad._interleave(xs,ys)
jax.interpreters.ad._jvp_jaxpr(jaxpr,nonzeros,instantiate)
jax.interpreters.ad._perm(primal_counts,tangent_counts,lst)
jax.interpreters.ad._primal_tangent_shapes_match(primal,tangent)
jax.interpreters.ad._raise_custom_vjp_error_on_jvp(*_,**__)
jax.interpreters.ad._remat_transpose(primal_jaxpr,tangent_jaxpr,reduce_axes,primals_in,cotangents_in)
jax.interpreters.ad._update_annotation(f:lu.WrappedFun,orig_type:Optional[Tuple[Tuple[core.AbstractValue,bool],...]],nonzeros:List[bool])->lu.WrappedFun
jax.interpreters.ad.add_tangents(x,y)
jax.interpreters.ad.backward_pass(jaxpr:core.Jaxpr,reduce_axes,transform_stack,consts,primals_in,cotangents_in)
jax.interpreters.ad.bilinear_transpose(lhs_rule,rhs_rule,cotangent,x,y,**kwargs)
jax.interpreters.ad.call_transpose(primitive,params,call_jaxpr,args,ct,_,reduce_axes)
jax.interpreters.ad.closed_backward_pass(jaxpr:core.ClosedJaxpr,reduce_axes,transform_stack,primals_in,cotangents_in)
jax.interpreters.ad.defbilinear(prim,lhs_rule,rhs_rule)
jax.interpreters.ad.defjvp(primitive,*jvprules)
jax.interpreters.ad.defjvp2(primitive,*jvprules)
jax.interpreters.ad.defjvp_zero(primitive)
jax.interpreters.ad.deflinear(primitive,transpose_rule)
jax.interpreters.ad.deflinear2(primitive,transpose_rule)
jax.interpreters.ad.f_jvp_traceable(nonzeros,*primals_and_nztangents)
jax.interpreters.ad.get_primitive_transpose(p)
jax.interpreters.ad.identity(x)
jax.interpreters.ad.ignore_consts(ct,pval)
jax.interpreters.ad.instantiate_zeros(tangent)
jax.interpreters.ad.instantiate_zeros_aval(aval,tangent)
jax.interpreters.ad.is_undefined_primal(x)
jax.interpreters.ad.jvp(fun:lu.WrappedFun,has_aux=False,instantiate=True,transform_stack=True)->Any
jax.interpreters.ad.jvp_jaxpr(jaxpr,nonzeros,instantiate)
jax.interpreters.ad.jvp_subtrace(main,primals,tangents)
jax.interpreters.ad.jvp_subtrace_aux(main,primals,tangents)
jax.interpreters.ad.jvpfun(instantiate,transform_stack,primals,tangents)
jax.interpreters.ad.linear_jvp(primitive,primals,tangents,**params)
jax.interpreters.ad.linear_transpose(transpose_rule,cotangent,*args,**kwargs)
jax.interpreters.ad.linear_transpose2(transpose_rule,cotangent,*args,**kwargs)
jax.interpreters.ad.linearize(traceable,*primals,**kwargs)
jax.interpreters.ad.map_transpose(primitive,params,call_jaxpr,args,ct,_,reduce_axes)
jax.interpreters.ad.nonzero_outputs(*args,**kwargs)
jax.interpreters.ad.nonzero_tangent_outputs(*args,**kwargs)
jax.interpreters.ad.rearrange_binders(jaxpr:core.ClosedJaxpr,primals_in,tangents_in,primals_out,tangents_out)
jax.interpreters.ad.recast_to_float0(primal,tangent)
jax.interpreters.ad.remat_transpose(params,call_jaxpr,primals_in,cotangents_in,cotangent_in_avals,reduce_axes)
jax.interpreters.ad.replace_float0s(primal,tangent)
jax.interpreters.ad.standard_jvp(jvprules,primitive,primals,tangents,**params)
jax.interpreters.ad.standard_jvp2(jvprules,primitive,primals,tangents,**params)
jax.interpreters.ad.traceable(num_primals,in_tree_def,*primals_and_tangents)
jax.interpreters.ad.unpair_pval(pval)
jax.interpreters.ad.vjp(traceable,primals,has_aux=False,reduce_axes=())
jax.interpreters.ad.zero_jvp(primitive,primals,tangents,**params)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/batching.py----------------------------------------
A:jax.interpreters.batching.handler->make_iota_handlers.get(type(axis_size))
A:jax.interpreters.batching.x_->main.with_cur_sublevel().full_raise(x)
A:jax.interpreters.batching.(spec_type, axis_size_type)->vmappables.pop(data_type)
A:jax.interpreters.batching.(py_args, py_kwargs)->tree_unflatten(in_tree, args_flat)
A:jax.interpreters.batching.NotMapped->type(None)
A:jax.interpreters.batching.aval->jax.core.get_aval(x)
A:jax.interpreters.batching.(vals_in, dims_in)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.used_names->jax.core.used_axis_names(primitive, params)
A:jax.interpreters.batching.frame->self.get_frame(vals_in, dims_in)
A:jax.interpreters.batching.batcher_primitive->self.get_axis_primitive_batcher(primitive, frame)
A:jax.interpreters.batching.(val_out, dim_out)->batched_primitive(vals_in, dims_in, **params)
A:jax.interpreters.batching.batched_primitive->self.get_primitive_batcher(primitive, frame)
A:jax.interpreters.batching.src->jax._src.source_info_util.current()
A:jax.interpreters.batching.params->dict(params, input_shape=operand.shape)
A:jax.interpreters.batching.(vals, dims)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.(f_, dims_out)->batch_subtrace(f, self.main, dims)
A:jax.interpreters.batching.f_->_update_annotation(f_, f.in_type, ax_size, self.axis_name, dims)
A:jax.interpreters.batching.vals_out->map_primitive.bind(f, *vals, **new_params)
A:jax.interpreters.batching.(vals, dims, srcs)->unzip3(((t.val, t.batch_dim, t.source_info) for t in out_tracers))
A:jax.interpreters.batching.trace->main.with_cur_sublevel()
A:jax.interpreters.batching.new_in_axes->tuple((in_axis + 1 if both_mapped(in_axis, d) and d <= in_axis else in_axis for (d, in_axis) in zip(dims, params['in_axes'])))
A:jax.interpreters.batching.new_dims->tuple((d - 1 if both_mapped(in_axis, d) and in_axis < d else d for (d, in_axis) in zip(dims, params['in_axes'])))
A:jax.interpreters.batching.(f, dims_out)->batch_subtrace(f, self.main, new_dims)
A:jax.interpreters.batching.new_params->dict(params, in_axes=new_in_axes, out_axes_thunk=new_out_axes_thunk)
A:jax.interpreters.batching.(in_vals, in_dims)->unzip2(((t.val, t.batch_dim) for t in tracers))
A:jax.interpreters.batching.(fun, out_dims1)->batch_subtrace(fun, self.main, in_dims)
A:jax.interpreters.batching.(jvp, out_dims2)->batch_custom_jvp_subtrace(jvp, self.main, in_dims)
A:jax.interpreters.batching.out_vals->map(partial(matchaxis, trace.axis_name, axis_size), out_axes, out_axes_dest, out_vals)
A:jax.interpreters.batching.(fst, out_dims)->jax.linear_util.merge_linear_aux(out_dims1, out_dims2)
A:jax.interpreters.batching.(fwd, out_dims2)->batch_subtrace(fwd, self.main, in_dims)
A:jax.interpreters.batching.bwd->batch_custom_vjp_bwd(bwd, self.axis_name, axis_size, out_dims2, in_dims, self.main.trace_type)
A:jax.interpreters.batching.(_, res_tree)->out_trees()
A:jax.interpreters.batching.(res_dims, primal_dims)->split_list(dims, [num_res])
A:jax.interpreters.batching.(_, primal_srcs)->split_list(srcs, [num_res])
A:jax.interpreters.batching.f->_batch_jaxpr_outer(f, axis_name, axis_size, in_axes, main_type)
A:jax.interpreters.batching.idx->memoize(lambda : BatchTracer(trace, make_iota(axis_size), 0, source_info_util.current()))
A:jax.interpreters.batching.in_tracers->map(partial(to_elt, trace, idx), in_vals, in_dims)
A:jax.interpreters.batching.shape->list(np.shape(x))
A:jax.interpreters.batching.out_tracers->map(trace.full_raise, outs)
A:jax.interpreters.batching.(out_vals, out_dims)->unzip2(((t.val, t.batch_dim) for t in out_tracers))
A:jax.interpreters.batching.(f, out_batched)->_batch_jaxpr_inner(f, axis_size, out_axes_dest)
A:jax.interpreters.batching.(jaxpr_out, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(f, avals_in)
A:jax.interpreters.batching.(out_vals, out_axes)->unzip2(((t.val, t.batch_dim) for t in out_tracers))
A:jax.interpreters.batching.zero_if_mapped->object()
A:jax.interpreters.batching.(out_primals, out_tangents)->split_list(out_vals, [len(out_vals) // 2])
A:jax.interpreters.batching.(out_primal_bds, out_tangent_bds)->split_list(out_dims, [len(out_vals) // 2])
A:jax.interpreters.batching.out_dims->map(_merge_bdims, out_primal_bds, out_tangent_bds)
A:jax.interpreters.batching.out_primals->map(partial(matchaxis, trace.axis_name, size), out_primal_bds, out_dims, out_primals)
A:jax.interpreters.batching.out_tangents->map(partial(matchaxis, trace.axis_name, size), out_tangent_bds, out_dims, out_tangents)
A:jax.interpreters.batching.(bwd, out_dims_thunk)->batch_subtrace(bwd)
A:jax.interpreters.batching.bwd_->_batch_outer(bwd, axis_name, axis_size, in_dims, main_type)
A:jax.interpreters.batching.primitive_batchers[prim]->partial(reducer_batcher, prim)
A:jax.interpreters.batching.d->next((d for d in dims if d is not not_mapped))
A:jax.interpreters.batching.out->prim.bind(*args, **params)
A:jax.interpreters.batching.ndim->max((np.ndim(x) for x in args))
A:jax.interpreters.batching.axes->tuple(np.where(np.less(axes, bdim), axes, np.add(axes, 1)))
A:jax.interpreters.batching.bdim_out->int(list(np.delete(np.arange(operand.ndim), axes)).index(bdim))
A:jax.interpreters.batching.broadcast_dims->tuple(np.delete(np.arange(len(shape)), axis))
A:jax.interpreters.batching.x->moveaxis(x, bdx, bdy)
A:jax.interpreters.batching.y->broadcast(y, x.shape[bdx], bdx)
jax.interpreters.batching.BatchTrace(self,*args,axis_name)
jax.interpreters.batching.BatchTrace.__init__(self,*args,axis_name)
jax.interpreters.batching.BatchTrace.get_axis_primitive_batcher(self,primitive,frame)
jax.interpreters.batching.BatchTrace.get_frame(self,vals,dims)->core.AxisEnvFrame
jax.interpreters.batching.BatchTrace.get_primitive_batcher(self,primitive,frame)
jax.interpreters.batching.BatchTrace.lift(self,val)
jax.interpreters.batching.BatchTrace.post_process_call(self,call_primitive,out_tracers,params)
jax.interpreters.batching.BatchTrace.post_process_custom_jvp_call(self,out_tracers,jvp_was_run)
jax.interpreters.batching.BatchTrace.post_process_custom_vjp_call(self,out_tracers,_)
jax.interpreters.batching.BatchTrace.post_process_custom_vjp_call_fwd(self,out_tracers,out_trees)
jax.interpreters.batching.BatchTrace.post_process_map(self,call_primitive,out_tracers,params)
jax.interpreters.batching.BatchTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.batching.BatchTrace.process_custom_jvp_call(self,prim,fun,jvp,tracers)
jax.interpreters.batching.BatchTrace.process_custom_vjp_call(self,prim,fun,fwd,bwd,tracers,*,out_trees)
jax.interpreters.batching.BatchTrace.process_map(self,map_primitive,f:lu.WrappedFun,tracers,params)
jax.interpreters.batching.BatchTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.batching.BatchTrace.pure(self,val)
jax.interpreters.batching.BatchTrace.sublift(self,val)
jax.interpreters.batching.BatchTracer(self,trace,val,batch_dim:Optional[int],source_info:Optional[source_info_util.SourceInfo]=None)
jax.interpreters.batching.BatchTracer.__init__(self,trace,val,batch_dim:Optional[int],source_info:Optional[source_info_util.SourceInfo]=None)
jax.interpreters.batching.BatchTracer._contents(self)
jax.interpreters.batching.BatchTracer._origin_msg(self)
jax.interpreters.batching.BatchTracer.aval(self)
jax.interpreters.batching.BatchTracer.full_lower(self)
jax.interpreters.batching._batch_inner(axis_size,out_dim_dests,main,in_dims,*in_vals)
jax.interpreters.batching._batch_jaxpr(closed_jaxpr,axis_size,in_batched,instantiate,axis_name,main_type)
jax.interpreters.batching._batch_jaxpr_axes(closed_jaxpr,axis_size,in_axes,out_axes_dest,axis_name,main_type)
jax.interpreters.batching._batch_jaxpr_inner(axis_size,out_axes_dest,main,in_axes,*in_vals)
jax.interpreters.batching._batch_jaxpr_outer(axis_name,axis_size,in_dims,main_type,*in_vals)
jax.interpreters.batching._batch_outer(axis_name,axis_size,in_dims,main_type,*in_vals)
jax.interpreters.batching._handle_scalar_broadcasting(nd,x,d)
jax.interpreters.batching._main_trace_for_axis_names(main_trace:core.MainTrace,axis_name:Iterable[core.AxisName])->bool
jax.interpreters.batching._match_axes_and_sum(axis_size,axis_name,out_dims_thunk,out_dim_dests,*in_vals)
jax.interpreters.batching._matchaxis_symbolic_zeros(axis_name,sz,name,src,dst,x,sum_match=False)
jax.interpreters.batching._merge_bdims(x,y)
jax.interpreters.batching._update_annotation(f:lu.WrappedFun,orig_type:Optional[Tuple[Tuple[core.AbstractValue,bool],...]],axis_size:int,axis_name:core.AxisName,in_dims:Sequence[Optional[int]])->lu.WrappedFun
jax.interpreters.batching.add_batched(batched_args,batch_dims)
jax.interpreters.batching.batch(fun:lu.WrappedFun,axis_name:core.AxisName,axis_size,in_dims,out_dim_dests,main_type:Type[BatchTrace]=BatchTrace)->lu.WrappedFun
jax.interpreters.batching.batch_custom_jvp_subtrace(main,in_dims,*in_vals)
jax.interpreters.batching.batch_custom_vjp_bwd(bwd,axis_name,axis_size,in_dims,out_dim_dests,main_type)
jax.interpreters.batching.batch_jaxpr(closed_jaxpr,axis_size,in_batched,instantiate,axis_name,main_type)
jax.interpreters.batching.batch_jaxpr_axes(closed_jaxpr,axis_size,in_axes,out_axes_dest,axis_name,main_type)
jax.interpreters.batching.batch_subtrace(main,in_dims,*in_vals)
jax.interpreters.batching.bdim_at_front(x,bdim,size)
jax.interpreters.batching.broadcast(x,sz,axis)
jax.interpreters.batching.broadcast_batcher(prim,args,dims,**params)
jax.interpreters.batching.defbroadcasting(prim)
jax.interpreters.batching.defreducer(prim)
jax.interpreters.batching.defvectorized(prim)
jax.interpreters.batching.flatten_fun_for_vmap(in_tree,*args_flat)
jax.interpreters.batching.from_elt(trace:'BatchTrace',axis_size:AxisSize,x:Elt,spec:MapSpec)->Vmappable
jax.interpreters.batching.is_vmappable(x:Any)->bool
jax.interpreters.batching.make_iota(axis_size:AxisSize)->Array
jax.interpreters.batching.matchaxis(axis_name,sz,src,dst,x,sum_match=False)
jax.interpreters.batching.reducer_batcher(prim,batched_args,batch_dims,axes,**params)
jax.interpreters.batching.register_vmappable(data_type:Type,spec_type:Type,axis_size_type:Type,to_elt:Callable,from_elt:Callable,make_iota:Optional[Callable])
jax.interpreters.batching.to_elt(trace:Trace,get_idx:GetIdx,x:Vmappable,spec:MapSpec)->Elt
jax.interpreters.batching.unregister_vmappable(data_type:Type)->None
jax.interpreters.batching.vectorized_batcher(prim,batched_args,batch_dims,**params)
jax.interpreters.batching.vtile(f_flat:lu.WrappedFun,in_axes_flat:Tuple[Optional[int],...],out_axes_flat:Tuple[Optional[int],...],tile_size:Optional[int],axis_name:core.AxisName,main_type:Type[BatchTrace]=BatchTrace)
jax.interpreters.batching.zeros_like_batched(batched_args,batch_dims)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/xla.py----------------------------------------
A:jax.interpreters.xla._scalar_types->jax._src.dtypes.python_scalar_dtypes.keys()
A:jax.interpreters.xla.source_file->re.sub(config.jax_hlo_source_file_canonicalization_regex, '', source_file)
A:jax.interpreters.xla.frame->jax._src.source_info_util.user_frame(source_info)
A:jax.interpreters.xla.proto->jax._src.lib.xla_client.OpSharding()
A:jax.interpreters.xla.proto.tile_assignment_dimensions->list(sharding)
A:jax.interpreters.xla.proto.tile_assignment_devices->list(range(np.product(sharding)))
A:jax.interpreters.xla.opaque->bytes(opaque, 'utf-8')
A:jax.interpreters.xla.handler->canonicalize_dtype_handlers.get(typ)
A:jax.interpreters.xla.const->pyval_to_ir_constants(builder, py_val, canonicalize_types=canonicalize_types)
A:jax.interpreters.xla.value->_normalize_to_xla_dtypes(value)
A:jax.interpreters.xla.(zero_stride_axes,)->numpy.where(np.equal(0, val.strides))
A:jax.interpreters.xla.(other_axes,)->numpy.where(np.not_equal(0, val.strides))
A:jax.interpreters.xla.xla_val->xops.Broadcast(_numpy_array_constant(c, collapsed_val, canonicalize_types)[0], np.take(val.shape, zero_stride_axes))
A:jax.interpreters.xla.permutation->numpy.argsort(tuple(zero_stride_axes) + tuple(other_axes))
A:jax.interpreters.xla.typ->type(x)
A:jax.interpreters.xla.aval_fn->pytype_aval_mappings.get(typ)
A:jax.interpreters.xla.pytype_aval_mappings[t]->operator.attrgetter('aval')
A:jax.interpreters.xla.c->jax._src.lib.xla_client.XlaBuilder(f'primitive_computation_{prim.name}')
A:jax.interpreters.xla.f->lower_fun(prim.bind, multiple_results=prim.multiple_results, new_style=True)
A:jax.interpreters.xla.(xla_args, _)->_xla_callable_args(c, avals, tuple_args=False, filter_tokens=False)
A:jax.interpreters.xla.ctx->TranslationContext(c, backend, axis_env, new_name_stack())
A:jax.interpreters.xla.ans->f(ctx.builder, ctx.axis_env, args, ctx.name_stack, backend=ctx.platform, **kw)
A:jax.interpreters.xla._replicated_param->object()
A:jax.interpreters.xla.counts->itertools.count()
A:jax.interpreters.xla.tuple_parts->tuple(partitions)
A:jax.interpreters.xla.tuple_shape->jax._src.lib.xla_client.Shape.tuple_shape([shape if not (filter_tokens and a is abstract_token) else _token_param_shape() for a in avals for shape in aval_to_xla_shapes(a)])
A:jax.interpreters.xla.tuple_param->_xla_param(c, 0, tuple_shape, replicated, tuple_parts, partitions_proto, filter_tokens)
A:jax.interpreters.xla.is_token->_token_param_shape().is_token()
A:jax.interpreters.xla.xla_shape->_token_param_shape()
A:jax.interpreters.xla.make_param->partial(parameter, builder, param_num, xla_shape, replicated=replicated)
A:jax.interpreters.xla.out->xops.CreateToken(builder)
A:jax.interpreters.xla.source_info->eqn.source_info.replace(name_stack=ctx.name_stack + eqn.source_info.name_stack)
A:jax.interpreters.xla.op_metadata->make_op_metadata(eqn.primitive, eqn.params, name_stack=ctx.name_stack, source_info=source_info)
A:jax.interpreters.xla.in_nodes->_flatmap(read, eqn.invars)
A:jax.interpreters.xla.num_elements->len(c.get_shape(ans).tuple_shapes())
A:jax.interpreters.xla.mesh_axes->tuple(unsafe_map(partial(axis_read, axis_env), name))
A:jax.interpreters.xla.(trailing_size, ragged)->divmod(axis_env.nreps, prod(axis_env.sizes))
A:jax.interpreters.xla.iota->numpy.arange(prod(mesh_spec)).reshape(mesh_spec)
A:jax.interpreters.xla.groups->numpy.reshape(np.moveaxis(iota, mesh_axes, np.arange(len(mesh_axes))), (prod(np.take(mesh_spec, mesh_axes)), -1))
A:jax.interpreters.xla.donations->defaultdict(deque)
A:jax.interpreters.xla.out_donated_args->list(donated_args)
A:jax.interpreters.xla.(param_number, param_index, arg_index)->donations[key].popleft()
A:jax.interpreters.xla.subc->subc.Build(xops.Tuple(subc, out_nodes)).Build(xops.Tuple(subc, out_nodes))
A:jax.interpreters.xla.sub_ctx->TranslationContext(c, backend, axis_env, new_name_stack()).replace(builder=subc, name_stack=extend_name_stack(ctx.name_stack, name))
A:jax.interpreters.xla.out_nodes->jaxpr_subcomp(sub_ctx, call_jaxpr, (), *args)
A:jax.interpreters.xla.ad.primitive_transposes[xla_call_p]->partial(ad.call_transpose, xla_call_p)
A:jax.interpreters.xla.(donated_invars_known, _)->partition_list(unks_in, params_known['donated_invars'])
A:jax.interpreters.xla.new_params_known->dict(params_known, donated_invars=tuple(donated_invars_known))
A:jax.interpreters.xla.new_params_staged->dict(params_staged, donated_invars=tuple(donated_invars_staged))
A:jax.interpreters.xla.pe.partial_eval_jaxpr_custom_rules[xla_call_p]->partial(pe.call_partial_eval_custom_rule, 'call_jaxpr', _xla_call_partial_eval_custom_params_updater)
A:jax.interpreters.xla.pe.padding_rules[xla_call_p]->partial(pe.call_padding_rule, xla_call_p)
A:jax.interpreters.xla._backend_specific_translations->defaultdict(dict)
A:jax.interpreters.xla.self._translations[key]->self._wrap_fn(key, value)
A:jax.interpreters.xla.platform->kw.pop('backend', None)
A:jax.interpreters.xla.translations->_TranslationRuleAdapter(_translations, _wrap_old_translation)
A:jax.interpreters.xla.retself[key]->_TranslationRuleAdapter(_backend_specific_translations[key], _wrap_old_translation)
A:jax.interpreters.xla.backend_specific_translations->_BackendSpecificTranslationsAdapter()
A:jax.interpreters.xla.call_translations->_TranslationRuleAdapter(_translations, _wrap_old_call_translation)
A:jax.interpreters.xla.shape->jax._src.lib.xla_client.XlaBuilder(f'primitive_computation_{prim.name}').get_shape(x)
A:jax.interpreters.xla.zero->xops.Constant(c, np.array(0, shape.element_type()))
A:jax.interpreters.xla.wrapped_fun->_tuple_output(wrapped_fun)
A:jax.interpreters.xla.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(wrapped_fun, avals)
A:jax.interpreters.xla.axis_env->AxisEnv(1, (), ())
A:jax.interpreters.xla.outs->jaxpr_subcomp(ctx, jaxpr, _xla_consts(c, consts), *xla_args)
A:jax.interpreters.xla.ad.primitive_transposes[core.named_call_p]->partial(ad.call_transpose, core.named_call_p)
jax.interpreters.xla.AxisEnv(NamedTuple)
jax.interpreters.xla.TranslationContext
jax.interpreters.xla.TranslationContext.replace(self,**kw)
jax.interpreters.xla._BackendSpecificTranslationsAdapter(defaultdict)
jax.interpreters.xla._BackendSpecificTranslationsAdapter.__missing__(self,key)
jax.interpreters.xla._TranslationRuleAdapter(self,translations,wrap_fn:Callable[[core.Primitive,Callable],TranslationRule])
jax.interpreters.xla._TranslationRuleAdapter.__init__(self,translations,wrap_fn:Callable[[core.Primitive,Callable],TranslationRule])
jax.interpreters.xla._TranslationRuleAdapter.__setitem__(self,key:core.Primitive,value:Callable)
jax.interpreters.xla._array_aval_from_xla_shape(xla_shape)
jax.interpreters.xla._axis_groups(mesh_spec,mesh_axes)
jax.interpreters.xla._call_translation_rule(ctx,avals_in,avals_out,*in_nodes,backend=None,call_jaxpr)
jax.interpreters.xla._canonicalize_ndarray_dtype(x)
jax.interpreters.xla._canonicalize_python_scalar_dtype(typ,x)
jax.interpreters.xla._device_array_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.xla._flatmap(func:Callable,vars:Sequence)
jax.interpreters.xla._flatten_shape(s:XlaShape,index:Tuple[int,...],results:List[Tuple[Tuple[int,...],XlaShape]])->None
jax.interpreters.xla._get_canonical_source_file(frame:source_info_util.Frame)
jax.interpreters.xla._make_abstract_python_scalar(typ,val)
jax.interpreters.xla._make_array_shape(a:ShapedArray)->Sequence[XlaShape]
jax.interpreters.xla._make_token_return_value(c)
jax.interpreters.xla._make_unit_constant(c)
jax.interpreters.xla._make_unit_shape(_)
jax.interpreters.xla._named_call_translation_rule(ctx,avals_in,avals_out,*in_nodes,name='core_call',backend=None,call_jaxpr)
jax.interpreters.xla._ndarray_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.xla._normalize_to_xla_dtypes(val)
jax.interpreters.xla._numpy_array_constant(builder,value,canonicalize_types=True)
jax.interpreters.xla._partitionmap(func:Callable,vars:Sequence,nodes:Sequence)
jax.interpreters.xla._pp_xla_call(eqn:core.JaxprEqn,context:core.JaxprPpContext,settings:core.JaxprPpSettings)->List[pp.Doc]
jax.interpreters.xla._python_scalar_handler(dtype,c,val,canonicalize_dtypes=True)
jax.interpreters.xla._scalar_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.xla._token_param_shape()
jax.interpreters.xla._tuple_output(*args,**kwargs)
jax.interpreters.xla._wrap_old_call_translation(prim:core.Primitive,f:Callable)->TranslationRule
jax.interpreters.xla._wrap_old_translation(prim:core.Primitive,f:Callable)->TranslationRule
jax.interpreters.xla._xla_call_jvp_update_params(params,nz_tangents)
jax.interpreters.xla._xla_call_partial_eval_custom_params_updater(unks_in:Sequence[bool],kept_outs_known:Sequence[bool],kept_outs_staged:Sequence[bool],num_res:int,params_known:dict,params_staged:dict)->Tuple[dict, dict]
jax.interpreters.xla._xla_call_partial_eval_update_params(params,kept_inputs,num_new_inputs)
jax.interpreters.xla._xla_call_translation_rule(ctx,avals_in,avals_out,*in_nodes,name,backend=None,call_jaxpr,donated_invars,inline=None,device=None)
jax.interpreters.xla._xla_call_transpose_update_params(params,undef_primals,nonzero_cts)
jax.interpreters.xla._xla_callable_args(c,avals,tuple_args,*,replicated=None,partitions=None,partitions_proto:bool=False,donated_invars=None,filter_tokens=True)
jax.interpreters.xla._xla_consts(c,consts)
jax.interpreters.xla._xla_param(builder,param_num,xla_shape,replicated,partitions,parts_proto,filter_tokens)
jax.interpreters.xla.abstractify(x)->core.AbstractValue
jax.interpreters.xla.add_jaxvals_translation_rule(c,x,y)
jax.interpreters.xla.aval_to_xla_shapes(aval:core.AbstractValue)->Sequence[XlaShape]
jax.interpreters.xla.axis_groups(axis_env:AxisEnv,name)->Tuple[Tuple[int, ...]]
jax.interpreters.xla.axis_read(axis_env,axis_name)
jax.interpreters.xla.canonicalize_dtype(x)
jax.interpreters.xla.check_backend_matches(inner_backend,outer_backend)
jax.interpreters.xla.dtype_to_primitive_type(dtype:np.dtype)->xc.PrimitiveType
jax.interpreters.xla.extend_axis_env(env:AxisEnv,name,size:int)
jax.interpreters.xla.flatten_shape(s:XlaShape)->Sequence[Tuple[Sequence[int], XlaShape]]
jax.interpreters.xla.identity(x)
jax.interpreters.xla.jaxpr_collectives(jaxpr)
jax.interpreters.xla.jaxpr_subcomp(ctx:TranslationContext,jaxpr:core.Jaxpr,consts:Sequence[XlaOp],*args:XlaOp)->Sequence[XlaOp]
jax.interpreters.xla.lower_fun(fun:Callable,*,multiple_results:bool,backend=None,new_style:bool=False)->Callable
jax.interpreters.xla.make_op_metadata(primitive:core.Primitive,params:Dict,*,source_info:source_info_util.SourceInfo,name_stack:Union[str,source_info_util.NameStack]='')->xc.OpMetadata
jax.interpreters.xla.parameter(builder,num,shape,name=None,replicated=None)
jax.interpreters.xla.primitive_subcomputation(platform:str,axis_env:'AxisEnv',prim:core.Primitive,*avals:core.AbstractValue,**params)
jax.interpreters.xla.pyval_to_ir_constant(builder,py_val,canonicalize_types=True)
jax.interpreters.xla.pyval_to_ir_constants(builder,py_val,canonicalize_types=True)
jax.interpreters.xla.register_constant_handler(type_,handler_fun)
jax.interpreters.xla.register_translation(prim:core.Primitive,rule:TranslationRule,*,platform:Optional[str]=None,is_collective:bool=False,initial_style:bool=False)->None
jax.interpreters.xla.set_sharding(builder,op,sharding:SpatialSharding,unspecified_dims=None)
jax.interpreters.xla.set_sharding_proto(builder,op,sharding_proto,unspecified_dims=None)
jax.interpreters.xla.set_up_aliases(c,xla_args,out_shape:XlaShape,donated_args,tuple_args)
jax.interpreters.xla.sharding_to_proto(sharding:SpatialSharding)
jax.interpreters.xla.tuple_sharding_proto(elems)
jax.interpreters.xla.with_sharding(builder,sharding:SpatialSharding,op_fn,*args,**kwargs)
jax.interpreters.xla.with_sharding_proto(builder,sharding_proto,op_fn,*args,**kwargs)
jax.interpreters.xla.xla_destructure(c,ans)
jax.interpreters.xla.zeros_like_translation_rule(c,x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/pxla.py----------------------------------------
A:jax.interpreters.pxla._UNSHARDED_INSTANCE->NoSharding()
A:jax.interpreters.pxla.mesh_shape->list(named_mesh_shape.values())
A:jax.interpreters.pxla.mesh->numpy.arange(np.prod(mesh_shape)).reshape(mesh_shape)
A:jax.interpreters.pxla.proto->jax._src.lib.xla_client.OpSharding()
A:jax.interpreters.pxla.ty->special_axes.get(axis, xc.OpSharding.Type.REPLICATED)
A:jax.interpreters.pxla.proto_mesh->numpy.arange(np.prod(mesh_shape)).reshape(mesh_shape).transpose(mesh_permutation).reshape(new_mesh_shape)
A:jax.interpreters.pxla.proto.tile_assignment_dimensions->list(proto_mesh.shape)
A:jax.interpreters.pxla.proto.tile_assignment_devices->list(raw_mesh.transpose(tad_perm).reshape(tad_shape).flat)
A:jax.interpreters.pxla.total_chunks->int(np.prod(sharding.chunks))
A:jax.interpreters.pxla.(shard_size, ragged)->divmod(axis_size, total_chunks)
A:jax.interpreters.pxla.shard_indices->shard_indices.reshape(shard_indices_shape).reshape(shard_indices_shape)
A:jax.interpreters.pxla.num_sharded_dim->len(shard_indices_shape)
A:jax.interpreters.pxla.replica_sizes->tuple((a.replicas for a in self.mesh_mapping if isinstance(a, Replicated)))
A:jax.interpreters.pxla.ShardingSpec.mesh_shape->property(sharding_spec_mesh_shape)
A:jax.interpreters.pxla.arg->jax.interpreters.xla.canonicalize_dtype(arg)
A:jax.interpreters.pxla.(start_indices, limit_indices, removed_dims)->unzip3((_as_slice_indices(x, idx) for idx in indices))
A:jax.interpreters.pxla.shards->ShardInfo(sharded_avals, out_sharded_avals, global_sharded_avals, num_local_shards, num_global_shards)
A:jax.interpreters.pxla.limit_indices->list(arr.shape)
A:jax.interpreters.pxla.AUTO->_AUTOAxisResource()
A:jax.interpreters.pxla.reverse_map->defaultdict(list)
A:jax.interpreters.pxla.partitions->tuple((tuple(reverse_map[i]) if reverse_map[i] else None for i in range(max_index + 1)))
A:jax.interpreters.pxla.sharded_aval->global_mesh._global_to_local(axis, gaval).update(shape=aval.shape[1:])
A:jax.interpreters.pxla.sharding_spec->_pmap_sharding_spec(nrep, axis_size, 1, None, aval, in_axis)
A:jax.interpreters.pxla.indices->spec_to_indices(aval.shape, sharding_spec)
A:jax.interpreters.pxla.seen_index_hashes->set()
A:jax.interpreters.pxla.hashed_index->_hashable_index(index)
A:jax.interpreters.pxla.npy_value->numpy.empty(self.aval.shape, self.aval.dtype)
A:jax.interpreters.pxla.npy_value[self.indices[i]]->self.device_buffers[i].to_py()
A:jax.interpreters.pxla.buf_idx->self.indices.index(cidx)
A:jax.interpreters.pxla.aval->global_mesh._global_to_local(axis, gaval)
A:jax.interpreters.pxla.candidates->defaultdict(list)
A:jax.interpreters.pxla.xla.pytype_aval_mappings[sda]->operator.attrgetter('aval')
A:jax.interpreters.pxla.abstract_args->unsafe_map(xla.abstractify, args)
A:jax.interpreters.pxla.(compiled_fun, fingerprint)->parallel_callable(fun, backend, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, global_arg_shapes, *abstract_args)
A:jax.interpreters.pxla.pmap_computation->lower_parallel_callable(fun, backend_name, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, global_arg_shapes, avals)
A:jax.interpreters.pxla.pmap_executable->lower_parallel_callable(fun, backend_name, axis_name, axis_size, global_axis_size, devices, name, in_axes, out_axes_thunk, donated_invars, global_arg_shapes, avals).compile()
A:jax.interpreters.pxla.jaxpr_replicas->jax._src.dispatch.jaxpr_replicas(jaxpr)
A:jax.interpreters.pxla.sharded_avals->tuple((shard_aval(pci.axis_size, axis, aval) if axis is not None else aval for (axis, aval) in safe_zip(pci.in_axes, pci.avals)))
A:jax.interpreters.pxla.(jaxpr, out_sharded_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_final(fun, global_sharded_avals, pe.debug_info_final(fun, 'pmap'))
A:jax.interpreters.pxla.jaxpr->jax._src.dispatch.apply_outfeed_rewriter(jaxpr)
A:jax.interpreters.pxla.replicas->find_replicas(jaxpr, pci.axis_size, pci.global_axis_size)
A:jax.interpreters.pxla.parts->find_partitions(jaxpr)
A:jax.interpreters.pxla.backend->jax._src.lib.xla_bridge.get_device_backend(mesh.devices.flat[0])
A:jax.interpreters.pxla.global_axis_size->len(devices)
A:jax.interpreters.pxla.pci->ParallelCallableInfo(name, backend, axis_name, axis_size, global_axis_size, devices, in_axes, out_axes_thunk, avals)
A:jax.interpreters.pxla.(jaxpr, consts, replicas, parts, shards)->stage_parallel_callable(pci, fun, global_arg_shapes)
A:jax.interpreters.pxla.axis_env->jax.interpreters.xla.AxisEnv(nreps=mesh.size, names=tuple(global_axis_sizes.keys()), sizes=tuple(global_axis_sizes.values()))
A:jax.interpreters.pxla.name_stack->new_name_stack(wrap_name(fun_name, api_name))
A:jax.interpreters.pxla.closed_jaxpr->jax.core.ClosedJaxpr(jaxpr, consts)
A:jax.interpreters.pxla.tuple_args->should_tuple_args(shards)
A:jax.interpreters.pxla.module->jax.interpreters.mlir.lower_jaxpr_to_module(module_name, closed_jaxpr, backend.platform, axis_ctx, name_stack, donated_invars, replicated_args=replicated_args, arg_shardings=in_partitions, result_shardings=out_partitions)
A:jax.interpreters.pxla.module_str->xe.mlir.xla_computation_to_mlir_module(self._hlo)
A:jax.interpreters.pxla.self._executable->MeshExecutable.from_hlo(self._name, self._hlo, **self.compile_args, _allow_propagation_to_outputs=_allow_propagation_to_outputs, _allow_compile_replicated=_allow_compile_replicated)
A:jax.interpreters.pxla.devices->jax._src.lib.xla_bridge.get_backend(backend).get_default_device_assignment(nrep)
A:jax.interpreters.pxla.local_devices_str->', '.join(map(str, pci.local_devices))
A:jax.interpreters.pxla.device_assignment->numpy.arange(np.prod(mesh_shape)).reshape(mesh_shape).devices.reshape((num_replicas, num_partitions))
A:jax.interpreters.pxla.compile_options->jax._src.lib.xla_bridge.get_compile_options(num_replicas=num_replicas, num_partitions=num_partitions, device_assignment=device_assignment, use_spmd_partitioning=spmd_lowering, use_auto_spmd_partitioning=auto_spmd_lowering, auto_spmd_partitioning_mesh_shape=list(mesh.shape.values()), auto_spmd_partitioning_mesh_ids=mesh.device_ids.reshape(-1))
A:jax.interpreters.pxla.nouts->len(shards.out_sharded_avals)
A:jax.interpreters.pxla.handle_outs->global_avals_to_results_handler(global_out_avals, out_axes, mesh)
A:jax.interpreters.pxla.execute_fun->ExecuteReplicated(compiled, pci.backend, handle_args, handle_outs)
A:jax.interpreters.pxla.compiled->jax._src.dispatch.compile_or_get_cached(pci.backend, xla_computation, compile_options)
A:jax.interpreters.pxla.handle_args->InputsHandler(xla_executable.local_devices(), input_specs, input_indices)
A:jax.interpreters.pxla.fingerprint->getattr(compiled, 'fingerprint', None)
A:jax.interpreters.pxla.arg_avals->map(xla.abstractify, args)
A:jax.interpreters.pxla.used_collectives->set(xla.jaxpr_collectives(jaxpr))
A:jax.interpreters.pxla.num_partitions->reconcile_num_partitions(eqn.params['call_jaxpr'], eqn.params['nparts'])
A:jax.interpreters.pxla.(arg_parts, out_parts, num_partitions, local_arg_parts, local_out_parts, local_num_partitions)->_find_partitions(jaxpr)
A:jax.interpreters.pxla.inner_num_parts->_inner_partitions(jaxpr, outer_num_parts)
A:jax.interpreters.pxla.nparts->get_num_partitions(parts)
A:jax.interpreters.pxla.expected_num_parts->_inner_partitions(subjaxpr, expected_num_parts)
A:jax.interpreters.pxla.(result, ragged)->divmod(x, y)
A:jax.interpreters.pxla.self.handler->partial(shard_args, local_devices, input_indices)
A:jax.interpreters.pxla.global_sharding_spec->mesh_sharding_specs(global_axis_sizes, mesh.axis_names)
A:jax.interpreters.pxla.local_sharding_spec->mesh_sharding_specs(global_mesh.local_mesh.shape, global_mesh.axis_names)
A:jax.interpreters.pxla.replicated_aval->global_mesh._global_to_local(axis, gaval).update(shape=(axis_size,) + aval.shape)
A:jax.interpreters.pxla.device_buffers->device_put(val, devices, replicate=True)
A:jax.interpreters.pxla.(replication_factor, ragged)->divmod(nrep, axis_size)
A:jax.interpreters.pxla.pspec->partitioned_sharding_spec(npart, parts, sharded_aval)
A:jax.interpreters.pxla.sharded_in_axis->sum((not isinstance(s, NoSharding) for s in pspec.sharding[:map_axis]))
A:jax.interpreters.pxla.input_bufs->self.in_handler(args)
A:jax.interpreters.pxla.out_bufs->self.xla_executable.execute_sharded_on_local_devices(input_bufs)
A:jax.interpreters.pxla.xla_pmap_p->jax.core.MapPrimitive('xla_pmap')
A:jax.interpreters.pxla.pe.partial_eval_jaxpr_custom_rules[xla_pmap_p]->partial(pe.partial_eval_jaxpr_custom_rule_not_implemented, 'pmap')
A:jax.interpreters.pxla.new_env->_ThreadLocalOldEnv().stack[-1].with_mesh(self)
A:jax.interpreters.pxla.sub_ctx->ctx.module_context.replace(axis_context=mlir.ReplicaAxisContext(new_env), name_stack=xla.extend_name_stack(ctx.module_context.name_stack, util.wrap_name(name, 'pmap')))
A:jax.interpreters.pxla.sharded_outs->jax.interpreters.mlir.jaxpr_subcomp(sub_ctx, call_jaxpr, (), *in_nodes_sharded)
A:jax.interpreters.pxla.ad.primitive_transposes[xla_pmap_p]->partial(ad.map_transpose, xla_pmap_p)
A:jax.interpreters.pxla.dims->list(aval.shape)
A:jax.interpreters.pxla.zero->jax.interpreters.mlir.ir_constant(np.zeros((), dtype=np.uint32))
A:jax.interpreters.pxla.dims_unsqueezed->list(aval.shape).copy()
A:jax.interpreters.pxla.dims_squeezed->list(aval.shape).copy()
A:jax.interpreters.pxla.x->xops.ConvertElementType(x, xla.dtype_to_primitive_type(np.dtype(np.float32)))
A:jax.interpreters.pxla.xla_shape->c.get_shape(x)
A:jax.interpreters.pxla.padded->jax.interpreters.mlir.full_like_aval(0, padded_aval)
A:jax.interpreters.pxla.replica_groups_protos->jax._src.lib.xla_client.make_replica_groups(xla.axis_groups(axis_env, axis_env.names[-1]))
A:jax.interpreters.pxla.out->xops.ConvertElementType(nonzero, xla.dtype_to_primitive_type(np.dtype(np.bool_)))
A:jax.interpreters.pxla.perm->list(range(1, len(dims)))
A:jax.interpreters.pxla.nonzero->xops.Ne(out, xops.Constant(c, np.array(0, dtype=np.float32)))
A:jax.interpreters.pxla.div->jax.interpreters.mlir.ir_constant(np.array(axis_env.nreps // util.prod(axis_env.sizes), np.uint32))
A:jax.interpreters.pxla.mod->jax.interpreters.mlir.ir_constant(np.array(axis_env.sizes[-1], np.uint32))
A:jax.interpreters.pxla.tensor_type->jax._src.lib.mlir.ir.RankedTensorType(x.type)
A:jax.interpreters.pxla.bool_shape->jax._src.lib.mlir.ir.RankedTensorType.get(dims, ir.IntegerType.get_signless(1))
A:jax.interpreters.pxla.padded_aval->global_mesh._global_to_local(axis, gaval).update(shape=[axis_env.sizes[-1]] + dims)
A:jax.interpreters.pxla.replica_groups->jax.interpreters.mlir.dense_int_elements(xla.axis_groups(axis_env, axis_env.names[-1]))
A:jax.interpreters.pxla.transposed_dims->list(dims)
A:jax.interpreters.pxla.float_zero->jax.interpreters.mlir.full_like_aval(0, padded_aval)
A:jax.interpreters.pxla.self.devices->jax._src.lib.xla_bridge.get_backend(backend).get_default_device_assignment(nrep).copy()
A:jax.interpreters.pxla.self.axis_names->tuple(axis_names)
A:jax.interpreters.pxla.self._hash->hash((self.axis_names, tuple(self.devices.flat), self.devices.shape))
A:jax.interpreters.pxla.is_local_device->numpy.vectorize(lambda d: d.process_index == process_index, otypes=[bool])(self.devices)
A:jax.interpreters.pxla.other_axes->tuple_delete(tuple(range(self.devices.ndim)), axis)
A:jax.interpreters.pxla.local_slices->numpy.vectorize(lambda d: d.process_index == process_index, otypes=[bool])(self.devices).any(other_axes, keepdims=False)
A:jax.interpreters.pxla.nonzero_indices->numpy.flatnonzero(local_slices)
A:jax.interpreters.pxla.subcube_indices->tuple(subcube_indices)
A:jax.interpreters.pxla.process_index->jax._src.lib.xla_bridge.process_index()
A:jax.interpreters.pxla.EMPTY_ENV->ResourceEnv(Mesh(np.empty((), dtype=object), ()), ())
A:jax.interpreters.pxla.thread_resources->_ThreadResourcesLocalState()
A:jax.interpreters.pxla._old_env->_ThreadLocalOldEnv()
A:jax.interpreters.pxla.shape->list(aval.shape)
A:jax.interpreters.pxla.named_shape->dict(aval.named_shape)
A:jax.interpreters.pxla.fun->tiling_transform(fun, mesh, in_axes, out_axes)
A:jax.interpreters.pxla.full_to_shard_p->jax.core.Primitive('full_to_shard')
A:jax.interpreters.pxla.manual_axes->list(sorted(manual_axes_set, key=str))
A:jax.interpreters.pxla.replicated_axes->list((axis for axis in mesh.axis_names if axis not in manual_axes_set))
A:jax.interpreters.pxla.raw_mesh->numpy.arange(np.prod(mesh_shape)).reshape(mesh_shape)
A:jax.interpreters.pxla.sharding_proto->mesh_sharding_specs(mesh.shape, mesh.axis_names)(aval_out, axes).sharding_proto()
A:jax.interpreters.pxla.sx->jax.interpreters.mlir.wrap_with_sharding_op(x, manual_proto, unspecified_dims=unspecified_dims)
A:jax.interpreters.pxla.manual_proto->_manual_proto(aval_in, manual_axes, mesh)
A:jax.interpreters.pxla.(result_type,)->jax.interpreters.mlir.aval_to_ir_types(aval_out)
A:jax.interpreters.pxla.shard_to_full_p->jax.core.Primitive('shard_to_full')
A:jax.interpreters.pxla.should_auto->_is_auto(axis_resources[0])
A:jax.interpreters.pxla._UNCONSTRAINED_PARTITION->_UnconstrainedPartitionSingleton()
A:jax.interpreters.pxla.auto_spmd_lowering->_check_if_all_or_none_auto(in_axes + out_axes, 'in_axes and out_axes')
A:jax.interpreters.pxla.(jaxpr, out_jaxpr_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_final(fun, in_jaxpr_avals)
A:jax.interpreters.pxla.axis_ctx->jax.interpreters.mlir.ReplicaAxisContext(axis_env)
A:jax.interpreters.pxla.num_local_devices->len(global_mesh.local_devices)
A:jax.interpreters.pxla.index->tuple(((slice(None),) * aval.ndim for _ in range(num_local_devices)))
A:jax.interpreters.pxla.(in_pspec, out_pspec)->jax.experimental.pjit._get_sharding_from_executable(xla_executable, mesh)
A:jax.interpreters.pxla.(input_specs, input_indices, input_avals)->_get_input_metadata(global_in_avals, mesh, in_axes, in_is_global)
A:jax.interpreters.pxla.unsafe_call->ExecuteReplicated(xla_executable, backend, handle_args, handle_outs)
A:jax.interpreters.pxla.xla_executable->jax._src.dispatch.compile_or_get_cached(backend, computation, compile_options)
A:jax.interpreters.pxla.(in_axes, out_axes)->_get_array_mapping_from_executable(xla_executable, mesh)
A:jax.interpreters.pxla.gda_array_mapping->_get_array_mapping(arg.mesh_axes)
A:jax.interpreters.pxla.(axis, other_axis)->sorted([str(axis), str(other_axis)])
A:jax.interpreters.pxla.typing_rule->custom_resource_typing_rules.get(eqn.primitive, None)
A:jax.interpreters.pxla.aval_shape->list(aval.shape)
A:jax.interpreters.pxla.chunked->Chunked([])
A:jax.interpreters.pxla.sharding[axis]->Chunked(list(chunked.chunks) + [axis_sizes[name]])
A:jax.interpreters.pxla.mesh_mapping[mesh_axis_pos[name]]->ShardedAxis(next_sharded_axis)
A:jax.interpreters.pxla.self.dynamic_axis_env->DynamicAxisEnv()
A:jax.interpreters.pxla._thread_local_state->_ThreadLocalState()
jax.interpreters.pxla.DynamicAxisEnv(list)
jax.interpreters.pxla.DynamicAxisEnv.__contains__(self,axis_name)
jax.interpreters.pxla.DynamicAxisEnv.__getitem__(self,axis_name)
jax.interpreters.pxla.DynamicAxisEnv.nreps(self)
jax.interpreters.pxla.DynamicAxisEnv.sizes(self)
jax.interpreters.pxla.DynamicAxisEnvFrame(self,name,pmap_trace,hard_size)
jax.interpreters.pxla.DynamicAxisEnvFrame.__init__(self,name,pmap_trace,hard_size)
jax.interpreters.pxla.ExecuteReplicated(self,xla_executable,backend,in_handler:InputsHandler,out_handler:ResultsHandler)
jax.interpreters.pxla.ExecuteReplicated.__init__(self,xla_executable,backend,in_handler:InputsHandler,out_handler:ResultsHandler)
jax.interpreters.pxla.InputsHandler(self,local_devices,sharding_specs,input_indices)
jax.interpreters.pxla.InputsHandler.__init__(self,local_devices,sharding_specs,input_indices)
jax.interpreters.pxla.InputsHandler.__str__(self)
jax.interpreters.pxla.Mesh(self,devices:np.ndarray,axis_names:Sequence[MeshAxisName])
jax.interpreters.pxla.Mesh.__enter__(self)
jax.interpreters.pxla.Mesh.__eq__(self,other)
jax.interpreters.pxla.Mesh.__exit__(self,exc_type,exc_value,traceback)
jax.interpreters.pxla.Mesh.__hash__(self)
jax.interpreters.pxla.Mesh.__init__(self,devices:np.ndarray,axis_names:Sequence[MeshAxisName])
jax.interpreters.pxla.Mesh.__repr__(self)
jax.interpreters.pxla.Mesh.__setattr__(self,name,value)
jax.interpreters.pxla.Mesh._global_to_local(self,axes:ArrayMapping,aval)
jax.interpreters.pxla.Mesh._local_mesh(self,process_index)
jax.interpreters.pxla.Mesh._local_to_global(self,axes:ArrayMapping,aval)
jax.interpreters.pxla.Mesh.device_ids(self)
jax.interpreters.pxla.Mesh.empty(self)
jax.interpreters.pxla.Mesh.is_multi_process(self)
jax.interpreters.pxla.Mesh.local_devices(self)
jax.interpreters.pxla.Mesh.local_mesh(self)
jax.interpreters.pxla.Mesh.shape(self)
jax.interpreters.pxla.Mesh.size(self)
jax.interpreters.pxla.MeshComputation(self,name:str,hlo:Union[ir.Module,xc.XlaComputation],donated_invars:Sequence[bool],**compile_args)
jax.interpreters.pxla.MeshComputation.__init__(self,name:str,hlo:Union[ir.Module,xc.XlaComputation],donated_invars:Sequence[bool],**compile_args)
jax.interpreters.pxla.MeshComputation.compile(self,_allow_propagation_to_outputs:bool=False,_allow_compile_replicated:bool=True)->'MeshExecutable'
jax.interpreters.pxla.MeshComputation.hlo(self)
jax.interpreters.pxla.MeshComputation.mhlo(self)->ir.Module
jax.interpreters.pxla.MeshExecutable(self,xla_executable,unsafe_call,input_avals,in_axes,out_axes,auto_spmd_lowering)
jax.interpreters.pxla.MeshExecutable.__init__(self,xla_executable,unsafe_call,input_avals,in_axes,out_axes,auto_spmd_lowering)
jax.interpreters.pxla.MeshExecutable.call(self,*args)
jax.interpreters.pxla.MeshExecutable.from_hlo(name:str,computation:Union[ir.Module,xc.XlaComputation],mesh:Mesh,global_in_avals:Sequence[ShapedArray],global_out_avals:Sequence[ShapedArray],in_axes:Sequence[ArrayMappingOrAuto],out_axes:Sequence[ArrayMappingOrAuto],spmd_lowering:bool,tuple_args:bool,in_is_global:Sequence[bool],auto_spmd_lowering:bool,_allow_propagation_to_outputs:bool,_allow_compile_replicated:bool)->'MeshExecutable'
jax.interpreters.pxla.MeshExecutable.hlo_modules(self)
jax.interpreters.pxla.MeshExecutable.runtime_executable(self)
jax.interpreters.pxla.ParallelCallableInfo
jax.interpreters.pxla.ParallelCallableInfo.local_devices(self)
jax.interpreters.pxla.ParallelCallableInfo.out_axes(self)
jax.interpreters.pxla.PartitionInfo(NamedTuple)
jax.interpreters.pxla.PartitionSpec(self,*partitions)
jax.interpreters.pxla.PartitionSpec.__init__(self,*partitions)
jax.interpreters.pxla.PartitionSpec.__repr__(self)
jax.interpreters.pxla.PmapComputation(self,hlo:Union[ir.Module,xc.XlaComputation],**compile_args)
jax.interpreters.pxla.PmapComputation.__init__(self,hlo:Union[ir.Module,xc.XlaComputation],**compile_args)
jax.interpreters.pxla.PmapComputation.compile(self)->'PmapExecutable'
jax.interpreters.pxla.PmapComputation.hlo(self)
jax.interpreters.pxla.PmapComputation.mhlo(self)->ir.Module
jax.interpreters.pxla.PmapExecutable(self,xla_executable,unsafe_call,fingerprint,in_avals)
jax.interpreters.pxla.PmapExecutable.__init__(self,xla_executable,unsafe_call,fingerprint,in_avals)
jax.interpreters.pxla.PmapExecutable.call(self,*args)
jax.interpreters.pxla.PmapExecutable.from_hlo(xla_computation,pci:ParallelCallableInfo,replicas:ReplicaInfo,parts:'PartitionInfo',shards:ShardInfo,tuple_args:bool)
jax.interpreters.pxla.PmapExecutable.hlo_modules(self)
jax.interpreters.pxla.PmapExecutable.runtime_executable(self)
jax.interpreters.pxla.ReplicaInfo(NamedTuple)
jax.interpreters.pxla.ResourceEnv(NamedTuple)
jax.interpreters.pxla.ResourceEnv.__repr__(self)
jax.interpreters.pxla.ResourceEnv.local_shape(self)
jax.interpreters.pxla.ResourceEnv.loop_resource_axes(self)->Set[ResourceAxisName]
jax.interpreters.pxla.ResourceEnv.physical_resource_axes(self)->Set[ResourceAxisName]
jax.interpreters.pxla.ResourceEnv.resource_axes(self)->Set[ResourceAxisName]
jax.interpreters.pxla.ResourceEnv.shape(self)
jax.interpreters.pxla.ResourceEnv.with_extra_loop(self,loop:_Loop)
jax.interpreters.pxla.ResourceEnv.with_mesh(self,mesh:Mesh)
jax.interpreters.pxla.ResultsHandler(self,handlers,out_specs,out_indices,out_avals)
jax.interpreters.pxla.ResultsHandler.__init__(self,handlers,out_specs,out_indices,out_avals)
jax.interpreters.pxla.SPMDBatchTrace(batching.BatchTrace)
jax.interpreters.pxla.SPMDBatchTrace.get_axis_primitive_batcher(self,primitive,frame)
jax.interpreters.pxla.ShardInfo(NamedTuple)
jax.interpreters.pxla.TileManual
jax.interpreters.pxla.TileVectorize
jax.interpreters.pxla.WeakRefList(list)
jax.interpreters.pxla._AUTOAxisResource
jax.interpreters.pxla._Loop(NamedTuple)
jax.interpreters.pxla._ShardedDeviceArray(self,aval:ShapedArray,sharding_spec:ShardingSpec,device_buffers:List[xb.xla_client.Buffer],indices:Optional[Tuple[Index,...]]=None)
jax.interpreters.pxla._ShardedDeviceArray.__init__(self,aval:ShapedArray,sharding_spec:ShardingSpec,device_buffers:List[xb.xla_client.Buffer],indices:Optional[Tuple[Index,...]]=None)
jax.interpreters.pxla._ShardedDeviceArray.delete(self)
jax.interpreters.pxla._ShardedDeviceArray.dtype(self)
jax.interpreters.pxla._ShardedDeviceArray.ndim(self)
jax.interpreters.pxla._ShardedDeviceArray.shape(self)
jax.interpreters.pxla._ShardedDeviceArray.size(self)
jax.interpreters.pxla._ThreadLocalOldEnv(self)
jax.interpreters.pxla._ThreadLocalOldEnv.__init__(self)
jax.interpreters.pxla._ThreadLocalState(self)
jax.interpreters.pxla._ThreadLocalState.__init__(self)
jax.interpreters.pxla._ThreadResourcesLocalState(self)
jax.interpreters.pxla._ThreadResourcesLocalState.__init__(self)
jax.interpreters.pxla._UnconstrainedPartitionSingleton
jax.interpreters.pxla._UnconstrainedPartitionSingleton.__str__(self)
jax.interpreters.pxla._as_slice_indices(arr:device_array.DeviceArrayProtocol,idx:Index)->Tuple[Tuple[int, ...], Tuple[int, ...], Tuple[int, ...]]
jax.interpreters.pxla._check_gda_xla_sharding_match(args,in_array_mappings)
jax.interpreters.pxla._check_if_all_or_none_auto(axis_resources,name)
jax.interpreters.pxla._compare_mhlo(x,y,direction,type)
jax.interpreters.pxla._find_partitions(jaxpr)
jax.interpreters.pxla._full_to_shard_abstract_eval(x,axes,mesh,**_)
jax.interpreters.pxla._full_to_shard_lowering(ctx,x,*,axes:ArrayMapping,mesh:Mesh,manual_axes:FrozenSet[MeshAxisName])
jax.interpreters.pxla._get_array_mapping_from_executable(xla_executable,mesh)->Tuple[Sequence[ArrayMapping], Sequence[ArrayMapping]]
jax.interpreters.pxla._get_input_metadata(global_in_avals,global_mesh,in_axes,in_is_global)
jax.interpreters.pxla._hashable_index(idx)
jax.interpreters.pxla._inner_partitions(jaxpr,expected_num_parts:Optional[int])
jax.interpreters.pxla._is_auto(x)
jax.interpreters.pxla._manual_proto(aval:core.ShapedArray,manual_axes_set:FrozenSet[MeshAxisName],mesh:Mesh)
jax.interpreters.pxla._mhlo_shard(aval,axis_env,xs,in_axis)
jax.interpreters.pxla._mhlo_unshard(aval,axis_env,out_axis,xs,platform)
jax.interpreters.pxla._pmap_lowering(ctx,*in_nodes,axis_name,axis_size,global_axis_size,devices,name,call_jaxpr,backend=None,in_axes,out_axes,donated_invars,global_arg_shapes)
jax.interpreters.pxla._pmap_sharding_spec(nrep,axis_size,npart,parts,sharded_aval,map_axis:Optional[int])->ShardingSpec
jax.interpreters.pxla._pmap_translation_rule(ctx,avals_in,avals_out,*in_nodes,axis_name,axis_size,global_axis_size,devices,name,call_jaxpr,backend=None,in_axes,out_axes,donated_invars,global_arg_shapes)
jax.interpreters.pxla._register_handlers_for_sharded_device_array(sda)
jax.interpreters.pxla._safe_div(x,y)
jax.interpreters.pxla._sanitize_mesh_jaxpr(jaxpr)
jax.interpreters.pxla._sda__getitem__(self,idx)
jax.interpreters.pxla._sda__iter__(self)
jax.interpreters.pxla._sda__reversed__(self)
jax.interpreters.pxla._sda_block_until_ready(self)
jax.interpreters.pxla._sda_check_if_deleted(self)
jax.interpreters.pxla._sda_copy_to_host_async(self)
jax.interpreters.pxla._sda_one_replica_buffer_indices(self)
jax.interpreters.pxla._sda_value(self)
jax.interpreters.pxla._shard_abstract_array(size,axis:int,x)
jax.interpreters.pxla._shard_arg(arg,devices,arg_indices)
jax.interpreters.pxla._shard_array(x,devices,indices)
jax.interpreters.pxla._shard_device_array(x,devices,indices)
jax.interpreters.pxla._shard_sharded_device_array_slow_path(x,devices,indices)
jax.interpreters.pxla._shard_to_full_abstract_eval(x,axes,mesh,**_)
jax.interpreters.pxla._shard_to_full_lowering(ctx,x,*,axes:ArrayMapping,mesh:Mesh,manual_axes:FrozenSet[MeshAxisName])
jax.interpreters.pxla._sharded_device_array_constant_handler(c,val,canonicalize_types=True)
jax.interpreters.pxla._sharded_device_array_mlir_constant_handler(val,canonicalize_types=True)
jax.interpreters.pxla._shardings_to_mlir_shardings(shardings:Optional[Sequence['PartitionsOrReplicated']])->Optional[Sequence[Optional[xc.OpSharding]]]
jax.interpreters.pxla._unravel_index(c,axis_env)
jax.interpreters.pxla._unravel_index_mhlo(axis_env)
jax.interpreters.pxla._xla_shard(c,aval,axis_env,x,in_axis)
jax.interpreters.pxla._xla_unshard(c,aval,axis_env,out_axis,x,backend)
jax.interpreters.pxla.array_mapping_to_axis_resources(array_mapping:ArrayMapping)
jax.interpreters.pxla.check_multihost_collective_allowlist(jaxpr)
jax.interpreters.pxla.device_put(x,devices:Sequence[xb.xla_client.Device],replicate:bool=False)->List[xb.xla_client.Buffer]
jax.interpreters.pxla.find_partitions(jaxpr)->PartitionInfo
jax.interpreters.pxla.find_replicas(jaxpr,axis_size,global_axis_size)
jax.interpreters.pxla.get_global_aval(local_aval,global_parts:PartitionsOrReplicated,local_parts:PartitionsOrReplicated)
jax.interpreters.pxla.get_local_aval(global_aval,global_parts:PartitionsOrReplicated,local_parts:PartitionsOrReplicated)
jax.interpreters.pxla.get_num_partitions(*partitions)
jax.interpreters.pxla.global_aval_to_result_handler(aval:core.AbstractValue,out_axis_resources,global_mesh)->Callable[[List[xb.xla_client.Buffer]], Any]
jax.interpreters.pxla.global_avals_to_results_handler(global_out_avals:Sequence[ShapedArray],out_axes:Sequence[ArrayMapping],global_mesh)
jax.interpreters.pxla.identity(x)
jax.interpreters.pxla.local_aval_to_result_handler(aval:core.AbstractValue,sharding_spec:Optional[ShardingSpec],indices:Optional[Tuple[Index]])->Callable[[List[xb.xla_client.Buffer]], Any]
jax.interpreters.pxla.local_avals_to_results_handler(local_out_specs:Sequence[Optional[ShardingSpec]],unmapped_local_out_avals:Sequence[Optional[ShapedArray]])
jax.interpreters.pxla.lower_mesh_computation(fun:lu.WrappedFun,api_name:str,fun_name:str,mesh:Mesh,in_axes:Sequence[ArrayMappingOrAuto],out_axes:Sequence[ArrayMappingOrAuto],donated_invars:Sequence[bool],spmd_lowering:bool,global_in_avals:Sequence[core.ShapedArray],tiling_method:Optional[TilingMethod],in_is_global:Sequence[bool])
jax.interpreters.pxla.lower_parallel_callable(fun:lu.WrappedFun,backend_name:Optional[str],axis_name:core.AxisName,axis_size:int,global_axis_size:Optional[int],devices:Optional[Sequence[xla.Device]],name:str,in_axes:Iterable[Optional[int]],out_axes_thunk:Callable[[],Sequence[Optional[int]]],donated_invars:Sequence[bool],global_arg_shapes:Sequence[Optional[Tuple[int,...]]],avals:Sequence[core.AbstractValue])
jax.interpreters.pxla.make_sharded_device_array(aval:ShapedArray,sharding_spec:Optional[ShardingSpec],device_buffers:List[Union[Any,xb.xla_client.Buffer]],indices:Optional[Tuple[Index,...]]=None)
jax.interpreters.pxla.maybe_extend_axis_env(*args,**kwargs)
jax.interpreters.pxla.mesh_sharding_specs(axis_sizes,axis_names,allow_uneven_axes=False)
jax.interpreters.pxla.parallel_callable(fun:lu.WrappedFun,backend_name:Optional[str],axis_name:core.AxisName,axis_size:int,global_axis_size:Optional[int],devices:Optional[Sequence[Any]],name:str,in_axes:Sequence[Optional[int]],out_axes_thunk:Callable[[],Sequence[Optional[int]]],donated_invars:Sequence[bool],global_arg_shapes:Sequence[Optional[Tuple[int,...]]],*avals)
jax.interpreters.pxla.partitioned_sharding_spec(num_partitions:int,partitions:Optional[Sequence[int]],aval)->ShardingSpec
jax.interpreters.pxla.reconcile_num_partitions(jaxpr,outer_num_parts:Optional[int])
jax.interpreters.pxla.replicate(val,axis_size,nrep,devices=None,backend=None,in_axis=0)
jax.interpreters.pxla.resource_typecheck(jaxpr,resource_env,axis_resources,what_jaxpr_thunk)
jax.interpreters.pxla.sda_array_result_handler(aval:ShapedArray,sharding_spec,indices)
jax.interpreters.pxla.shard_args(devices:Sequence[xb.xla_client.Device],indices:Sequence[Sequence[Index]],args)->Sequence[Sequence[xb.xla_client.Buffer]]
jax.interpreters.pxla.shard_aval(size,axis:int,aval)
jax.interpreters.pxla.sharding_spec_indices(self,shape:Tuple[int,...])->np.ndarray
jax.interpreters.pxla.sharding_spec_mesh_shape(self)
jax.interpreters.pxla.sharding_spec_repr(self)
jax.interpreters.pxla.sharding_spec_sharding_proto(self,special_axes:Mapping[int,OpShardingType]={})
jax.interpreters.pxla.should_tuple_args(shards:ShardInfo)
jax.interpreters.pxla.show_axes(axes)
jax.interpreters.pxla.spec_to_indices(shape:Tuple[int,...],spec:ShardingSpec)->Tuple[Index, ...]
jax.interpreters.pxla.stage_parallel_callable(pci:ParallelCallableInfo,fun:lu.WrappedFun,global_arg_shapes:Sequence[Optional[Tuple[int,...]]])
jax.interpreters.pxla.tile_aval_nd(axis_sizes,in_axes:ArrayMapping,aval)
jax.interpreters.pxla.untile_aval_nd(axis_sizes,out_axes:ArrayMapping,aval)
jax.interpreters.pxla.vtile_by_mesh(fun:lu.WrappedFun,mesh:Mesh,in_axes:Sequence[ArrayMapping],out_axes:Sequence[ArrayMapping])
jax.interpreters.pxla.vtile_manual(manual_axes:FrozenSet[MeshAxisName],mesh:Mesh,in_axes:Sequence[ArrayMapping],out_axes:Sequence[ArrayMapping],*args)
jax.interpreters.pxla.xla_pmap_impl(fun:lu.WrappedFun,*args,backend:Optional[str],axis_name:core.AxisName,axis_size:int,global_axis_size:Optional[int],devices:Optional[Sequence[Any]],name:str,in_axes:Sequence[Optional[int]],out_axes_thunk:Callable[[],Sequence[Optional[int]]],donated_invars:Sequence[bool],global_arg_shapes:Sequence[Optional[Tuple[int,...]]])


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/masking.py----------------------------------------
A:jax.interpreters.masking.masking_rules[prim]->partial(naryop_masking_rule, prim)
A:jax.interpreters.masking.ShapeEnvs->namedtuple('ShapeEnvs', ['logical', 'padded'])
A:jax.interpreters.masking.shape_envs->ShapeEnvs({}, {})
A:jax.interpreters.masking.new_logical->dict(chain(shape_envs.logical.items(), logical_env.items()))
A:jax.interpreters.masking.new_padded->dict(chain(shape_envs.padded.items(), padded_env.items()))
A:jax.interpreters.masking.(env_keys, padded_env_vals)->unzip2(sorted(padded_env.items()))
A:jax.interpreters.masking.(fun, out_shapes)->mask_subtrace(fun, main, polymorphic_shapes, padded_env)
A:jax.interpreters.masking.out_vals->fun.call_wrapped(*logical_env_vals + in_vals)
A:jax.interpreters.masking.logical_env->dict(zip(env_keys, logical_env_vals))
A:jax.interpreters.masking.padded_env->dict(zip(*padded_env))
A:jax.interpreters.masking.trace->MaskTrace(main, core.cur_sublevel())
A:jax.interpreters.masking.out_tracers->map(trace.full_raise, outs)
A:jax.interpreters.masking.(out_vals, out_shapes)->unzip2(((t.val, t.polymorphic_shape) for t in out_tracers))
A:jax.interpreters.masking.coeffs->self.copy()
A:jax.interpreters.masking.other->_ensure_poly(other)
A:jax.interpreters.masking.(q, _)->divmod(self, divisor)
A:jax.interpreters.masking.(_, r)->divmod(self, divisor)
A:jax.interpreters.masking.divisor->_ensure_poly(divisor)
A:jax.interpreters.masking.(qcount, rcount)->divmod(count, dcount)
A:jax.interpreters.masking.r->Poly({mon: rcount})
A:jax.interpreters.masking.q->Poly({qmon: qcount})
A:jax.interpreters.masking.(lb, ub)->(self - other).bounds()
A:jax.interpreters.masking.lbub->self.get(Mon(), 0)
A:jax.interpreters.masking.deg->int(deg)
A:jax.interpreters.masking.coeff->int(coeff)
A:jax.interpreters.masking.core._SPECIAL_DIMENSION_HANDLERS[Poly]->DimensionHandlerPoly()
A:jax.interpreters.masking.d->Counter(self)
A:jax.interpreters.masking.dims->map(_parse_dim, spec.replace(' ', '').strip(',').split(','))
A:jax.interpreters.masking._identifiers->frozenset(string.ascii_lowercase)
A:jax.interpreters.masking._monomorphic_dim->MonomorphicDim()
A:jax.interpreters.masking.s_->S_()
A:jax.interpreters.masking.masking_rule->masking_rules.get(primitive)
A:jax.interpreters.masking.(out_aval, _)->primitive.abstract_eval(*(t.aval for t in tracers), **params)
A:jax.interpreters.masking.(vals, polymorphic_shapes)->unzip2(((t.val, t.polymorphic_shape) for t in tracers))
A:jax.interpreters.masking.logical_shapes->map(shape_as_value, polymorphic_shapes)
A:jax.interpreters.masking.out->masking_rule(vals, logical_shapes, **params)
A:jax.interpreters.masking.out_shapes->map(_polys_to_ints, [o.shape for o in out_aval])
A:jax.interpreters.masking.params->dict(params, donated_invars=(False,) * len(logical_env_vals) + params['donated_invars'])
A:jax.interpreters.masking.(vals, shapes)->unzip2(((t.val, t.polymorphic_shape) for t in out_tracers))
A:jax.interpreters.masking.logical_env_vals->tuple((logical_env[k] for k in env_keys))
A:jax.interpreters.masking.(f, shapes_out)->mask_subtrace(f, self.main, shapes, padded_env)
A:jax.interpreters.masking.vals_out->call_primitive.bind(f, *logical_env_vals + vals, **params)
A:jax.interpreters.masking.unique_id->UniqueId(key)
A:jax.interpreters.masking.poly->poly.copy().copy()
A:jax.interpreters.masking.const_coeff->poly.copy().copy().pop(Mon({}), 0)
A:jax.interpreters.masking.((mon, linear_coeff),)->poly.copy().copy().items()
A:jax.interpreters.masking.((id, index),)->mon.items()
A:jax.interpreters.masking.(d, r)->divmod(d - const_coeff, linear_coeff)
A:jax.interpreters.masking.specs->tree_unflatten(spec_tree, specs)
A:jax.interpreters.masking.shapes->tree_unflatten(tree, shapes)
jax.interpreters.masking.DimensionHandlerPoly(core.DimensionHandler)
jax.interpreters.masking.DimensionHandlerPoly.is_constant(self,d:DimSize)->bool
jax.interpreters.masking.DimensionHandlerPoly.symbolic_equal(self,d1:core.DimSize,d2:core.DimSize)->bool
jax.interpreters.masking.MaskTrace(Trace)
jax.interpreters.masking.MaskTrace.lift(self,val)
jax.interpreters.masking.MaskTrace.post_process_call(self,call_primitive,out_tracers,params)
jax.interpreters.masking.MaskTrace.process_call(self,call_primitive,f,tracers,params)
jax.interpreters.masking.MaskTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.masking.MaskTrace.pure(self,val)
jax.interpreters.masking.MaskTrace.sublift(self,val)
jax.interpreters.masking.MaskTracer(self,trace,val,polymorphic_shape)
jax.interpreters.masking.MaskTracer.__init__(self,trace,val,polymorphic_shape)
jax.interpreters.masking.MaskTracer.aval(self)
jax.interpreters.masking.MaskTracer.dtype(self)
jax.interpreters.masking.MaskTracer.full_lower(self)
jax.interpreters.masking.MaskTracer.is_pure(self)
jax.interpreters.masking.Mon(dict)
jax.interpreters.masking.Mon.__floordiv__(self,divisor:'Mon')->'Mon'
jax.interpreters.masking.Mon.__hash__(self)
jax.interpreters.masking.Mon.__lt__(self,other:'Mon')
jax.interpreters.masking.Mon.__mul__(self,other:'Mon')->'Mon'
jax.interpreters.masking.Mon.__str__(self)
jax.interpreters.masking.Mon.degree(self)
jax.interpreters.masking.MonomorphicDim(object)
jax.interpreters.masking.MonomorphicDim.__str__(self)
jax.interpreters.masking.Poly(self,coeffs:Dict['Mon',int])
jax.interpreters.masking.Poly.__add__(self,other:'Size')->'Poly'
jax.interpreters.masking.Poly.__divmod__(self,divisor:'Size')->Tuple['Poly', int]
jax.interpreters.masking.Poly.__eq__(self,other)
jax.interpreters.masking.Poly.__floordiv__(self,divisor:'Size')->'Poly'
jax.interpreters.masking.Poly.__ge__(self,other:'Size')
jax.interpreters.masking.Poly.__gt__(self,other:'Size')
jax.interpreters.masking.Poly.__hash__(self)
jax.interpreters.masking.Poly.__init__(self,coeffs:Dict['Mon',int])
jax.interpreters.masking.Poly.__int__(self)
jax.interpreters.masking.Poly.__le__(self,other:'Size')
jax.interpreters.masking.Poly.__lt__(self,other:'Size')
jax.interpreters.masking.Poly.__mod__(self,divisor:'Size')->int
jax.interpreters.masking.Poly.__mul__(self,other:'Size')->'Poly'
jax.interpreters.masking.Poly.__ne__(self,other)
jax.interpreters.masking.Poly.__neg__(self)->'Poly'
jax.interpreters.masking.Poly.__radd__(self,other:'Size')->'Poly'
jax.interpreters.masking.Poly.__rdivmod__(self,dividend:'Size')->Tuple['Poly', int]
jax.interpreters.masking.Poly.__repr__(self)
jax.interpreters.masking.Poly.__rmul__(self,other:'Size')->'Poly'
jax.interpreters.masking.Poly.__rsub__(self,other:'Size')->'Poly'
jax.interpreters.masking.Poly.__str__(self)
jax.interpreters.masking.Poly.__sub__(self,other:'Size')->'Poly'
jax.interpreters.masking.Poly._leading_term(self)->Tuple['Mon', int]
jax.interpreters.masking.Poly.bounds(self)->Tuple[Optional[int], Optional[int]]
jax.interpreters.masking.Poly.evaluate(self,env)
jax.interpreters.masking.Poly.is_constant(self)
jax.interpreters.masking.S_(object)
jax.interpreters.masking.S_.__getitem__(self,idx)
jax.interpreters.masking.ShapeError(Exception)
jax.interpreters.masking.ShapeSpec(tuple)
jax.interpreters.masking.ShapeSpec.__str__(self)
jax.interpreters.masking.ShapeSyntaxError(Exception)
jax.interpreters.masking.UndefinedPoly(core.InconclusiveDimensionOperation)
jax.interpreters.masking.UniqueId(self,name)
jax.interpreters.masking.UniqueId.__init__(self,name)
jax.interpreters.masking.UniqueId.__lt__(self,other)
jax.interpreters.masking.UniqueId.__repr__(self)
jax.interpreters.masking.UniqueIds(dict)
jax.interpreters.masking.UniqueIds.__missing__(self,key)
jax.interpreters.masking._ensure_poly(p:'Size')->'Poly'
jax.interpreters.masking._parse_dim(spec)
jax.interpreters.masking._parse_id(name)
jax.interpreters.masking._parse_lit(val_str)
jax.interpreters.masking._polys_to_ints(shape)
jax.interpreters.masking._shape_spec_consistent(spec,expr)
jax.interpreters.masking.bind_shapes(polymorphic_shapes,padded_shapes)
jax.interpreters.masking.check_shapes(specs,spec_tree,shapes,tree,message_prefix='Output')
jax.interpreters.masking.defnaryop(prim)
jax.interpreters.masking.defvectorized(prim)
jax.interpreters.masking.eval_poly(poly,values_dict)
jax.interpreters.masking.eval_poly_shape(shape,values_dict)
jax.interpreters.masking.extend_shape_envs(logical_env,padded_env)
jax.interpreters.masking.finalize_spec(polymorphic_shape,padded_shape)
jax.interpreters.masking.is_polymorphic(shape:Sequence['Size'])
jax.interpreters.masking.is_tracing()
jax.interpreters.masking.mask_fun(fun,logical_env,padded_env,in_vals,polymorphic_shapes)
jax.interpreters.masking.mask_subtrace(main,shapes,padded_env,*in_vals)
jax.interpreters.masking.mul(coeff,mon)
jax.interpreters.masking.naryop_masking_rule(prim,padded_vals,logical_shapes)
jax.interpreters.masking.padded_shape_as_value(shape)
jax.interpreters.masking.parse_spec(spec='')
jax.interpreters.masking.pow(x,deg)
jax.interpreters.masking.remap_ids(names,shape_spec)
jax.interpreters.masking.shape_as_value(shape)
jax.interpreters.masking.vectorized_masking_rule(prim,padded_vals,logical_shapes,**params)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/partial_eval.py----------------------------------------
A:jax.interpreters.partial_eval.known->self.pval.get_known()
A:jax.interpreters.partial_eval.aval->get_aval(x)
A:jax.interpreters.partial_eval.const->self._new_const(aval, t).pval.get_known()
A:jax.interpreters.partial_eval.tracers->map(self.instantiate_const_abstracted, tracers)
A:jax.interpreters.partial_eval.(out_aval, effects)->primitive.abstract_eval(*avals, **params)
A:jax.interpreters.partial_eval.name_stack->self._current_truncated_name_stack()
A:jax.interpreters.partial_eval.source->jax._src.source_info_util.current().replace(name_stack=name_stack)
A:jax.interpreters.partial_eval.eqn->new_jaxpr_eqn([*constvars, *invars], outvars, prim, dict(call_jaxpr=closed_call_jaxpr, transpose_jaxpr_thunk=transpose_jaxpr_thunk, out_types=out_types, res_tree=res_tree, lin_tree=lin_tree, out_tree=out_tree), closed_call_jaxpr.effects, source_info_util.current())
A:jax.interpreters.partial_eval.out_tracer->JaxprTracer(self, PartialVal.unknown(out_aval), None)
A:jax.interpreters.partial_eval.out_tracer.recipe->new_eqn_recipe(tracers, [out_tracer], primitive, params, effects, source)
A:jax.interpreters.partial_eval.(in_knowns, in_avals, in_consts)->partition_pvals([t.pval for t in tracers])
A:jax.interpreters.partial_eval.f_->trace_to_subjaxpr_nounits(f, self.main, False)
A:jax.interpreters.partial_eval.(f_, aux)->partial_eval_wrapper_nounits(f_, tuple(in_knowns), tuple(in_avals))
A:jax.interpreters.partial_eval.const_params->dict(const_params, in_axes=tuple(const_in_axes), out_axes_thunk=const_out_axes_thunk)
A:jax.interpreters.partial_eval.out->primitive.bind(f, *in_consts, **const_params)
A:jax.interpreters.partial_eval.(out_knowns, out_avals, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.(out_consts, res)->split_list(out, [len(out) - len(jaxpr.constvars)])
A:jax.interpreters.partial_eval.const_tracers->map(trace.new_instantiated_const, consts)
A:jax.interpreters.partial_eval.env_tracers->map(self.full_raise, env)
A:jax.interpreters.partial_eval.staged_params->dict(staged_params, in_axes=staged_in_axes, out_axes=tuple(staged_out_axes), call_jaxpr=call_jaxpr)
A:jax.interpreters.partial_eval.(unk_in_axes, const_in_axes)->partition_list(in_knowns, params['in_axes'])
A:jax.interpreters.partial_eval.f->jax.linear_util.wrap_init(core.jaxpr_as_fun(jaxpr))
A:jax.interpreters.partial_eval.(f, aux)->partial_eval_wrapper(f, tuple(in_avals))
A:jax.interpreters.partial_eval.(out_knowns, _, jaxpr, _)->aux()
A:jax.interpreters.partial_eval.(_, out_axes)->partition_list(out_knowns, out_axes_thunk())
A:jax.interpreters.partial_eval.(out_knowns, out_avals_mapped, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.call_jaxpr->convert_constvars_jaxpr(jaxpr)
A:jax.interpreters.partial_eval.out_axes->params['out_axes_thunk']()
A:jax.interpreters.partial_eval.(staged_out_axes, _)->partition_list(out_knowns, out_axes)
A:jax.interpreters.partial_eval.(jaxpr, res, env)->tracers_to_jaxpr([], unknown_out_tracers)
A:jax.interpreters.partial_eval.(out_knowns, out_avals, out_consts)->partition_pvals(out_pvals)
A:jax.interpreters.partial_eval.trace->main.with_cur_sublevel()
A:jax.interpreters.partial_eval.new_params->dict(params, call_jaxpr=padded_jaxpr)
A:jax.interpreters.partial_eval.(out_knowns, out_avals_mapped, out_consts)->partition_pvals(out_pvals)
A:jax.interpreters.partial_eval.staged_out_axes->tuple(out_axes_unknown)
A:jax.interpreters.partial_eval.(out_axes_unknown, out_axes_known)->partition_list(out_knowns, out_axes)
A:jax.interpreters.partial_eval.(in_avals, in_consts)->unzip2((t.pval for t in tracers))
A:jax.interpreters.partial_eval.(out_consts, consts)->split_list(out_flat, [len(out_flat) - len(jaxpr.constvars)])
A:jax.interpreters.partial_eval.out_pvs->map(PartialVal, zip(out_avals, out_consts))
A:jax.interpreters.partial_eval.fun->inspect.unwrap(fun)
A:jax.interpreters.partial_eval.(fun, aux)->partial_eval_wrapper(fun, tuple(in_avals))
A:jax.interpreters.partial_eval.out_flat->trace_to_subjaxpr(fwd, self.main, True).call_wrapped(*in_consts)
A:jax.interpreters.partial_eval.(out_avals, jaxpr, env)->aux()
A:jax.interpreters.partial_eval.out_pvals->map(PartialVal, zip(out_avals, out_consts))
A:jax.interpreters.partial_eval.closed_jaxpr->jax.core.ClosedJaxpr(jaxpr, ())
A:jax.interpreters.partial_eval.jvp_->trace_to_subjaxpr(jvp, self.main, True)
A:jax.interpreters.partial_eval.(jvp_, aux)->partial_eval_wrapper(jvp_, tuple(in_avals) * 2)
A:jax.interpreters.partial_eval.(_, consts)->split_list(out_flat, [len(out_flat) - len(jaxpr.constvars)])
A:jax.interpreters.partial_eval.converted_jaxpr->Jaxpr(constvars=jaxpr.constvars + env_vars, invars=invars, outvars=jaxpr.outvars, eqns=jaxpr.eqns, effects=jaxpr.effects)
A:jax.interpreters.partial_eval.(res_ts, lin_ts)->split_list(tracers, [params['res_tree'].num_leaves])
A:jax.interpreters.partial_eval.lin_all_known->all((t.is_known() for t in lin_ts))
A:jax.interpreters.partial_eval.in_tracers->map(trace.new_arg, pvals)
A:jax.interpreters.partial_eval.fwd_->trace_to_subjaxpr(fwd, self.main, True)
A:jax.interpreters.partial_eval.(fwd_, aux)->partial_eval_wrapper(fwd_, tuple(in_avals))
A:jax.interpreters.partial_eval.sentinel->object()
A:jax.interpreters.partial_eval.(_, avals_out, _)->trace_to_jaxpr_dynamic(lu.wrap_init(fun, params), avals, debug_info)
A:jax.interpreters.partial_eval.current_name_stack->jax._src.source_info_util.current_name_stack()
A:jax.interpreters.partial_eval.(jaxpr, (out_pvals, consts, env))->inspect.unwrap(fun).call_wrapped(pvals)
A:jax.interpreters.partial_eval.in_args->merge_lists(in_knowns, in_tracers, in_consts)
A:jax.interpreters.partial_eval.out_tracers->map(partial(instantiate_const_at, trace), instantiate, out_tracers)
A:jax.interpreters.partial_eval.(jaxpr, consts, env)->tracers_to_jaxpr(in_tracers, out_tracers)
A:jax.interpreters.partial_eval.FreeVar->namedtuple('FreeVar', ['val'])
A:jax.interpreters.partial_eval.ConstVar->namedtuple('ConstVar', ['val'])
A:jax.interpreters.partial_eval.LambdaBinding->namedtuple('LambdaBinding', [])
A:jax.interpreters.partial_eval.newvar->jax.core.gensym([jaxpr_known, jaxpr_staged])
A:jax.interpreters.partial_eval.var->self.frame.tracer_to_var.get(id(tracer))
A:jax.interpreters.partial_eval.vart_to_var[id(t)]->newvar(aval)
A:jax.interpreters.partial_eval.sorted_tracers->toposort(out_tracers)
A:jax.interpreters.partial_eval.invars->map(self.getvar, tracers)
A:jax.interpreters.partial_eval.varconst_to_var[id(c)]->newvar(get_aval(c))
A:jax.interpreters.partial_eval.processed_eqn_ids->set()
A:jax.interpreters.partial_eval.vt_to_var[id(t)]->getconstvar(recipe.val)
A:jax.interpreters.partial_eval.(env_vars, env_vals)->unzip2(env.items())
A:jax.interpreters.partial_eval.(const_vars, const_vals)->unzip2(consts.items())
A:jax.interpreters.partial_eval.effects->jax.core.join_effects(*(eqn.effects for eqn in eqns))
A:jax.interpreters.partial_eval.jaxpr->Jaxpr(constvars, self.invars, outvars, self.eqns, self.effects)
A:jax.interpreters.partial_eval.lifted_jaxpr->Jaxpr(constvars=(), invars=jaxpr.constvars + jaxpr.invars, outvars=jaxpr.outvars, eqns=jaxpr.eqns, effects=jaxpr.effects)
A:jax.interpreters.partial_eval.(env_vars, invars)->split_list(jaxpr.invars, [num_env_vars])
A:jax.interpreters.partial_eval.(jaxpr_2, out_pvals_2, consts_2)->trace_to_jaxpr(f, pvals, instantiate=instantiate)
A:jax.interpreters.partial_eval.(out_pvs_2, out_consts_2)->unzip2(out_pvals_2)
A:jax.interpreters.partial_eval.(jaxpr_1, out_avals, consts_1)->trace_to_jaxpr_dynamic(lu.wrap_init(fun), in_avals)
A:jax.interpreters.partial_eval.jaxpr_2->convert_constvars_jaxpr(jaxpr_2)
A:jax.interpreters.partial_eval.(in_avals_1, in_avals_2)->unzip2(map(_split_aval, unknowns, jaxpr.in_avals))
A:jax.interpreters.partial_eval.(out_avals_1, out_avals_2)->unzip2(map(_split_aval, uk_out, jaxpr.out_avals))
A:jax.interpreters.partial_eval.instantiated_tracers->map(trace.instantiate_const_abstracted, tracers)
A:jax.interpreters.partial_eval.(jaxpr, eval_out_pvals, consts, env_tracers)->main.with_cur_sublevel().partial_eval(f, in_pvals, partial(remat_call_p.bind, **params), instantiate=False)
A:jax.interpreters.partial_eval.(jaxpr_known, jaxpr_unknown, out_unknowns, out_inst, _)->_partial_eval_jaxpr_custom(jaxpr, in_unknowns, params['policy'])
A:jax.interpreters.partial_eval.(jaxpr_known, in_used_known)->dce_jaxpr(jaxpr_known, [True] * len(jaxpr_known.outvars))
A:jax.interpreters.partial_eval.(_, used_outs_unknown)->partition_list(out_inst, out_unknowns)
A:jax.interpreters.partial_eval.(jaxpr_unknown, in_used_unknown)->dce_jaxpr(jaxpr_unknown, used_outs_unknown)
A:jax.interpreters.partial_eval.(_, in_consts_)->unzip2((t.pval for t in it.chain(env_tracers, tracers) if t.pval.is_known()))
A:jax.interpreters.partial_eval.(_, in_consts)->unzip2((t.pval for t in it.chain(env_tracers, tracers)))
A:jax.interpreters.partial_eval.out_consts->jax.core.eval_jaxpr(jaxpr_known, (), *in_consts)
A:jax.interpreters.partial_eval.out_consts_->iter(out_consts)
A:jax.interpreters.partial_eval.residuals->list(out_consts_)
A:jax.interpreters.partial_eval.res_tracers->map(trace.new_instantiated_const, residuals)
A:jax.interpreters.partial_eval.(_, in_jaxpr_tracers)->partition_list(in_used_unknown, in_jaxpr_tracers)
A:jax.interpreters.partial_eval.recipe->new_eqn_recipe(in_jaxpr_tracers, out_jaxpr_tracers, remat_call_p, new_params, jaxpr_unknown.effects, source_info_util.current())
A:jax.interpreters.partial_eval.(jaxpr_known, jaxpr_unknown, out_unknowns)->partial_eval_jaxpr(closed_jaxpr, in_unknowns, instantiate=False)
A:jax.interpreters.partial_eval.(out_known_pvals, out_unknown_pvals)->_partition_knowns(eval_out_pvals, out_unknowns)
A:jax.interpreters.partial_eval.num_outputs->len(jaxpr_unknown.out_avals)
A:jax.interpreters.partial_eval.jaxpr_known_nores->_dce_jaxpr(jaxpr_known, out_knowns + [False] * num_res, drop_outputs=True)
A:jax.interpreters.partial_eval.jaxpr_known_comp->_dce_jaxpr(jaxpr_known_nores, to_compute)
A:jax.interpreters.partial_eval.reconstructed_consts->jax.core.jaxpr_as_fun(jaxpr_known_comp)(*consts, *in_consts)
A:jax.interpreters.partial_eval.out_known_pvals->map(_reconstruct_pval, out_known_pvals, reconstructed_consts)
A:jax.interpreters.partial_eval.(unks_in, inst_in)->unzip2(map(read, eqn.invars))
A:jax.interpreters.partial_eval.rule->dce_rules.get(eqn.primitive)
A:jax.interpreters.partial_eval.(eqn1, eqn2, unks_out, inst_out, res)->rule(saveable, unks_in, inst_in, eqn)
A:jax.interpreters.partial_eval.inputs->map(ensure_instantiated, inst_in, eqn.invars)
A:jax.interpreters.partial_eval.(out_unknowns, out_inst)->unzip2(map(read, jaxpr.outvars))
A:jax.interpreters.partial_eval.(ins_known, _)->partition_list(unks_in, eqn.invars)
A:jax.interpreters.partial_eval.(outs_known_, _)->partition_list(out_unknowns, jaxpr.outvars)
A:jax.interpreters.partial_eval.known_effects->jax.core.join_effects(*(eqn.effects for eqn in known_eqns))
A:jax.interpreters.partial_eval.jaxpr_known->Jaxpr((), ins_known, [*outs_known, *residuals], known_eqns, known_effects)
A:jax.interpreters.partial_eval.(_, outs_staged)->partition_list(out_inst, jaxpr.outvars)
A:jax.interpreters.partial_eval.staged_effects->jax.core.join_effects(*(eqn.effects for eqn in staged_eqns))
A:jax.interpreters.partial_eval.jaxpr_staged->Jaxpr((), [*residuals, *jaxpr.invars], outs_staged, staged_eqns, staged_effects)
A:jax.interpreters.partial_eval.(jaxpr_known, jaxpr_staged, unks_out, inst_out, num_res)->_partial_eval_jaxpr_custom(jaxpr, unks_in, saveable)
A:jax.interpreters.partial_eval.dropped_outs_known->map(op.or_, unks_out, known_units_out)
A:jax.interpreters.partial_eval.(out_binders_known, _)->partition_list(dropped_outs_known, eqn.outvars)
A:jax.interpreters.partial_eval.(_, out_binders_staged)->partition_list(inst_out, eqn.outvars)
A:jax.interpreters.partial_eval.(params_known, params_staged)->params_updater(unks_in, kept_outs_known, kept_outs_staged, num_res, params_known, params_staged)
A:jax.interpreters.partial_eval.eqn_known->new_jaxpr_eqn(ins_known, [*out_binders_known, *residuals], eqn.primitive, params_known, jaxpr_known.effects, eqn.source_info)
A:jax.interpreters.partial_eval.eqn_staged->new_jaxpr_eqn([*residuals, *eqn.invars], out_binders_staged, eqn.primitive, params_staged, jaxpr_staged.effects, eqn.source_info)
A:jax.interpreters.partial_eval.partial_eval_jaxpr_custom_rules[core.call_p]->partial(call_partial_eval_custom_rule, 'call_jaxpr', lambda _, __, ___, ____, x, y: (x, y))
A:jax.interpreters.partial_eval.partial_eval_jaxpr_custom_rules[core.named_call_p]->partial(call_partial_eval_custom_rule, 'call_jaxpr', lambda _, __, ___, ____, x, y: (x, y))
A:jax.interpreters.partial_eval.partial_eval_jaxpr_custom_rules[remat_call_p]->partial(call_partial_eval_custom_rule, 'call_jaxpr', lambda _, __, ___, ____, p1, p2: (p1, dict(p2, differentiated=True)))
A:jax.interpreters.partial_eval.used_outs->map(read, eqn.outvars)
A:jax.interpreters.partial_eval.(used_ins, new_eqn)->rule(used_outs, eqn)
A:jax.interpreters.partial_eval.used_inputs->map(read, jaxpr.invars)
A:jax.interpreters.partial_eval.new_jaxpr->Jaxpr(new_constvars, new_invars, new_outvars, new_eqns, jaxpr.effects)
A:jax.interpreters.partial_eval.(new_jaxpr, used_inputs)->dce_jaxpr(eqn.params['call_jaxpr'], used_outputs)
A:jax.interpreters.partial_eval.update_params->call_param_updaters.get(map_primitive)
A:jax.interpreters.partial_eval.new_eqn->new_jaxpr_eqn([v for (v, used) in zip(eqn.invars, used_inputs) if used], [v for (v, used) in zip(eqn.outvars, used_outputs) if used], eqn.primitive, new_params, new_jaxpr.effects, eqn.source_info)
A:jax.interpreters.partial_eval.new_invars->_move_to_front(closed_jaxpr.jaxpr.invars, to_move)
A:jax.interpreters.partial_eval.new_closed_jaxpr->jax.core.ClosedJaxpr(new_jaxpr, closed_jaxpr.consts)
A:jax.interpreters.partial_eval.(invar_pos, progenitor_eqns)->self._trace.frame.find_progenitors(self)
A:jax.interpreters.partial_eval.self.gensym->jax.core.gensym()
A:jax.interpreters.partial_eval.self.effects->set()
A:jax.interpreters.partial_eval.(constvars, constvals)->unzip2(self.constvar_to_val.items())
A:jax.interpreters.partial_eval.(jaxpr, constvals)->_inline_literals(jaxpr, constvals)
A:jax.interpreters.partial_eval.(consts_out, new_eqn)->const_fold_rules[eqn.primitive](consts_in, eqn)
A:jax.interpreters.partial_eval.(fwd_vars, new_eqn)->forwarding_rules[eqn.primitive](eqn)
A:jax.interpreters.partial_eval.(new_constvars, new_constvals)->unzip2(consts.items())
A:jax.interpreters.partial_eval.tracer->self._new_const(aval, t)
A:jax.interpreters.partial_eval.self.frame.tracer_to_var[id(tracer)]var->self.frame.newvar(aval)
A:jax.interpreters.partial_eval.varself.frame.tracer_to_var[id(tracer)]->self.frame.newvar(tracer.aval)
A:jax.interpreters.partial_eval.(out_avals, effects)->primitive.abstract_eval(*avals, **params)
A:jax.interpreters.partial_eval.source_info->jax._src.source_info_util.current()
A:jax.interpreters.partial_eval.outvars->map(self.makevar, out_tracers)
A:jax.interpreters.partial_eval.im_tracers->_extract_implicit_args(self, f.in_type, explicit_tracers)
A:jax.interpreters.partial_eval.(in_avals, keep_inputs)->unzip2(f.in_type)
A:jax.interpreters.partial_eval.(jaxpr, out_avals, consts)->trace_to_subjaxpr_dynamic(fun, main, in_avals, keep_inputs=keep_inputs)
A:jax.interpreters.partial_eval.constvars->map(self.getvar, map(self.instantiate_const, call_consts))
A:jax.interpreters.partial_eval.(jaxpr, reduced_out_avals, consts)->trace_to_subjaxpr_dynamic(f, self.main, reduced_in_avals)
A:jax.interpreters.partial_eval.(fun_jaxpr, out_avals, consts)->trace_to_subjaxpr_dynamic(fun, self.main, in_avals)
A:jax.interpreters.partial_eval.closed_fun_jaxpr->jax.core.ClosedJaxpr(convert_constvars_jaxpr(fun_jaxpr), ())
A:jax.interpreters.partial_eval.main_->ref(self.main)
A:jax.interpreters.partial_eval.jvp_jaxpr_thunk->_memoize(lambda : trace_to_subjaxpr_dynamic(jvp, main_(), 2 * in_avals)[::2])
A:jax.interpreters.partial_eval.fwd_jaxpr_thunk->_memoize(lambda : trace_to_subjaxpr_dynamic(fwd, main_(), in_avals)[::2])
A:jax.interpreters.partial_eval.(tracers_res, tracers_lin)->split_list(tracers, [res_tree.num_leaves])
A:jax.interpreters.partial_eval.(call_jaxpr, out_avals, call_consts)->trace_to_subjaxpr_dynamic(call, self.main, in_avals_p)
A:jax.interpreters.partial_eval.closed_call_jaxpr->jax.core.ClosedJaxpr(convert_constvars_jaxpr(call_jaxpr), ())
A:jax.interpreters.partial_eval.(transpose_flat, in_tree2)->flatten_fun_nokwargs(lu.wrap_init(transpose), treedef_tuple((res_tree, out_tree)))
A:jax.interpreters.partial_eval.transpose_jaxpr_thunk->_memoize(lambda : trace_to_subjaxpr_dynamic(transpose_flat, main_(), in_avals_t)[::2])
A:jax.interpreters.partial_eval.saved_state->jax.core.thread_local_state.trace_state.copy()
A:jax.interpreters.partial_eval.func_src_info->fun_sourceinfo(fn)
A:jax.interpreters.partial_eval.arg_info->partial(arg_info_pytree, fn, in_tree, has_kwargs)
A:jax.interpreters.partial_eval.(args, kwargs)->tree_unflatten(in_tree, dummy_args)
A:jax.interpreters.partial_eval.ba->inspect.signature(fn).bind(*args, **kwargs)
A:jax.interpreters.partial_eval.frame->JaxprStackFrame()
A:jax.interpreters.partial_eval.ans->inspect.unwrap(fun).call_wrapped(*in_tracers_)
A:jax.interpreters.partial_eval.(jaxpr, consts)->JaxprStackFrame().to_jaxpr(out_tracers)
A:jax.interpreters.partial_eval.partial_specs->_canonicalize_specs(map(np.ndim, args), axes_specs)
A:jax.interpreters.partial_eval.specs->_complete_specs(args, partial_specs)
A:jax.interpreters.partial_eval.(idxs, implicit_names)->_collect_implicit(args, specs)
A:jax.interpreters.partial_eval.d->sizes.setdefault(name, x.shape[i])
A:jax.interpreters.partial_eval.spec->dict(spec)
A:jax.interpreters.partial_eval.spec[i]->named_tracers.get(id(d), TracerAsName(d))
A:jax.interpreters.partial_eval.idxs[name]->DBIdx(offset + explicit_tracers[id(x.shape[i])])
A:jax.interpreters.partial_eval.offset->len(implicit_names)
A:jax.interpreters.partial_eval.self.tracer->main.with_cur_sublevel().with_cur_sublevel().full_raise(tracer)
A:jax.interpreters.partial_eval.explicit_tracers_->iter(explicit_tracers)
A:jax.interpreters.partial_eval.tracers[d1.val]->main.with_cur_sublevel().instantiate_const(d2)
A:jax.interpreters.partial_eval.a->a.update(shape=tuple(shape)).update(shape=tuple(shape))
A:jax.interpreters.partial_eval.eval_padded->jax.linear_util.wrap_init(partial(_eval_jaxpr_padded, jaxpr, consts))
A:jax.interpreters.partial_eval.(padded_jaxpr, _, padded_consts)->trace_to_jaxpr_dynamic(eval_padded, in_avals)
A:jax.interpreters.partial_eval.outs->rule(in_avals, out_avals, *map(read, eqn.invars), **eqn.params)
A:jax.interpreters.partial_eval.(padded_jaxpr, padded_consts)->pad_jaxpr(call_jaxpr, ())
A:jax.interpreters.partial_eval.(subfuns, bind_params)->prim.get_bind_params(new_params)
A:jax.interpreters.partial_eval.py_args->map(PartialVal, zip(pvs, consts))
A:jax.interpreters.partial_eval.(out_pvs, out_consts)->unzip2(out_pvals)
jax.interpreters.partial_eval.Bound
jax.interpreters.partial_eval.BoundedAxisSize(NamedTuple)
jax.interpreters.partial_eval.DBIdx(NamedTuple)
jax.interpreters.partial_eval.DebugInfo(NamedTuple)
jax.interpreters.partial_eval.DynamicJaxprTrace(core.Trace)
jax.interpreters.partial_eval.DynamicJaxprTrace._lift_tracers_in_aval(self,aval)
jax.interpreters.partial_eval.DynamicJaxprTrace._new_const(self,aval,c)
jax.interpreters.partial_eval.DynamicJaxprTrace.default_process_primitive(self,primitive,tracers,params)
jax.interpreters.partial_eval.DynamicJaxprTrace.frame(self)
jax.interpreters.partial_eval.DynamicJaxprTrace.getvar(self,tracer)
jax.interpreters.partial_eval.DynamicJaxprTrace.instantiate_const(self,val)
jax.interpreters.partial_eval.DynamicJaxprTrace.makevar(self,tracer)
jax.interpreters.partial_eval.DynamicJaxprTrace.new_arg(self,aval)
jax.interpreters.partial_eval.DynamicJaxprTrace.new_const(self,c)
jax.interpreters.partial_eval.DynamicJaxprTrace.post_process_call(self,call_primitive,out_tracers,params)
jax.interpreters.partial_eval.DynamicJaxprTrace.post_process_custom_jvp_call(self,out_tracers,_)
jax.interpreters.partial_eval.DynamicJaxprTrace.post_process_custom_vjp_call(self,out_tracers,_)
jax.interpreters.partial_eval.DynamicJaxprTrace.post_process_map(self,map_primitive,out_tracers,params)
jax.interpreters.partial_eval.DynamicJaxprTrace.process_call(self,call_primitive,f,explicit_tracers,params)
jax.interpreters.partial_eval.DynamicJaxprTrace.process_custom_jvp_call(self,prim,fun,jvp,tracers)
jax.interpreters.partial_eval.DynamicJaxprTrace.process_custom_transpose(self,prim,call,tracers,transpose,out_types,lin_tree,res_tree,out_tree)
jax.interpreters.partial_eval.DynamicJaxprTrace.process_custom_vjp_call(self,prim,fun,fwd,bwd,tracers,out_trees)
jax.interpreters.partial_eval.DynamicJaxprTrace.process_map(self,map_primitive,f,tracers,params)
jax.interpreters.partial_eval.DynamicJaxprTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.partial_eval.DynamicJaxprTrace.sublift(self,t)
jax.interpreters.partial_eval.DynamicJaxprTracer(self,trace,aval,line_info=None)
jax.interpreters.partial_eval.DynamicJaxprTracer.__init__(self,trace,aval,line_info=None)
jax.interpreters.partial_eval.DynamicJaxprTracer._assert_live(self)->None
jax.interpreters.partial_eval.DynamicJaxprTracer._contents(self)
jax.interpreters.partial_eval.DynamicJaxprTracer._origin_msg(self)
jax.interpreters.partial_eval.DynamicJaxprTracer.full_lower(self)
jax.interpreters.partial_eval.JaxprEqnRecipe(NamedTuple)
jax.interpreters.partial_eval.JaxprStackFrame(self)
jax.interpreters.partial_eval.JaxprStackFrame.__init__(self)
jax.interpreters.partial_eval.JaxprStackFrame.add_eqn(self,eqn:core.JaxprEqn)
jax.interpreters.partial_eval.JaxprStackFrame.find_progenitors(self,tracer)
jax.interpreters.partial_eval.JaxprStackFrame.newvar(self,aval)
jax.interpreters.partial_eval.JaxprStackFrame.to_jaxpr(self,out_tracers)
jax.interpreters.partial_eval.JaxprTrace(self,*args,name_stack:source_info_util.NameStack)
jax.interpreters.partial_eval.JaxprTrace.__init__(self,*args,name_stack:source_info_util.NameStack)
jax.interpreters.partial_eval.JaxprTrace._current_truncated_name_stack(self)
jax.interpreters.partial_eval.JaxprTrace.default_process_primitive(self,primitive,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.instantiate_const(self,tracer)->Tracer
jax.interpreters.partial_eval.JaxprTrace.instantiate_const_abstracted(self,tracer)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.lift(self,val)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.new_arg(self,pval:PartialVal)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.new_const(self,val)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.new_instantiated_const(self,val)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.new_instantiated_literal(self,val)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.partial_eval(self,f:lu.WrappedFun,pvals:Sequence[PartialVal],app:Callable[[lu.WrappedFun,Tuple[core.Value,...]],Tuple[core.Value]],instantiate:bool)
jax.interpreters.partial_eval.JaxprTrace.post_process_call(self,primitive,out_tracers,params)
jax.interpreters.partial_eval.JaxprTrace.post_process_custom_jvp_call(self,out_tracers,_)
jax.interpreters.partial_eval.JaxprTrace.post_process_custom_vjp_call(self,out_tracers,_)
jax.interpreters.partial_eval.JaxprTrace.post_process_map(self,primitive,out_tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_call(self,primitive,f,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_custom_jvp_call(self,prim,fun,jvp,tracers)
jax.interpreters.partial_eval.JaxprTrace.process_custom_transpose(self,prim,call,tracers,**params)
jax.interpreters.partial_eval.JaxprTrace.process_custom_vjp_call(self,prim,fun,fwd,bwd,tracers,out_trees)
jax.interpreters.partial_eval.JaxprTrace.process_map(self,primitive,f:lu.WrappedFun,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.process_primitive(self,primitive,tracers,params)
jax.interpreters.partial_eval.JaxprTrace.pure(self,val)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTrace.sublift(self,val)->'JaxprTracer'
jax.interpreters.partial_eval.JaxprTracer(self,trace:JaxprTrace,pval:PartialVal,recipe:Optional[JaxprTracerRecipe])
jax.interpreters.partial_eval.JaxprTracer.__init__(self,trace:JaxprTrace,pval:PartialVal,recipe:Optional[JaxprTracerRecipe])
jax.interpreters.partial_eval.JaxprTracer.__repr__(self)
jax.interpreters.partial_eval.JaxprTracer.aval(self)->AbstractValue
jax.interpreters.partial_eval.JaxprTracer.full_lower(self)
jax.interpreters.partial_eval.JaxprTracer.is_known(self)
jax.interpreters.partial_eval.JaxprTracer.parents(self)->Sequence['JaxprTracer']
jax.interpreters.partial_eval.PartialVal(cls,xs:Tuple[Optional[AbstractValue],core.Value])
jax.interpreters.partial_eval.PartialVal.__new__(cls,xs:Tuple[Optional[AbstractValue],core.Value])
jax.interpreters.partial_eval.PartialVal.get_aval(self)->AbstractValue
jax.interpreters.partial_eval.PartialVal.get_known(self)->Optional[core.Value]
jax.interpreters.partial_eval.PartialVal.is_known(self)->bool
jax.interpreters.partial_eval.PartialVal.known(cls,const:core.Value)->'PartialVal'
jax.interpreters.partial_eval.PartialVal.merge_with_known(self,val:core.Value)->core.Value
jax.interpreters.partial_eval.PartialVal.unknown(cls,aval:AbstractValue)->'PartialVal'
jax.interpreters.partial_eval.TracerAsName(self,tracer)
jax.interpreters.partial_eval.TracerAsName.__eq__(self,other)
jax.interpreters.partial_eval.TracerAsName.__hash__(self)
jax.interpreters.partial_eval.TracerAsName.__init__(self,tracer)
jax.interpreters.partial_eval._arg_type(idxs:Dict[AbstractedAxisName,DBIdx],x:Any,spec:Dict[int,AbstractedAxisName])->AbstractValue
jax.interpreters.partial_eval._canonicalize_specs(ndims:Sequence[int],specs:Optional[Sequence[AbstractedAxesSpec]])->List[Dict[int, AbstractedAxisName]]
jax.interpreters.partial_eval._collect_implicit(args:Sequence[Any],specs:List[Dict[int,AbstractedAxisName]])->Tuple[Dict[AbstractedAxisName, DBIdx], List[AbstractedAxisName]]
jax.interpreters.partial_eval._complete_specs(args:Sequence[Any],partial_specs:List[Dict[int,AbstractedAxisName]])->List[Dict[int, AbstractedAxisName]]
jax.interpreters.partial_eval._const_folding_and_forwarding(jaxpr,constvals)
jax.interpreters.partial_eval._dce_jaxpr(closed_jaxpr:ClosedJaxpr,outputs:Sequence[bool],drop_outputs=False)->ClosedJaxpr
jax.interpreters.partial_eval._dce_open_jaxpr(jaxpr:Jaxpr,outputs:Tuple[bool,...],drop_outputs=False)->Jaxpr
jax.interpreters.partial_eval._drop_vars(jaxpr:Jaxpr,drop_ins:Tuple[bool,...],drop_outs:Tuple[bool,...])
jax.interpreters.partial_eval._eval_jaxpr_padded(jaxpr:Jaxpr,consts:List[Const],*args:DynamicJaxprTracer)->List[Union[Const, DynamicJaxprTracer]]
jax.interpreters.partial_eval._extract_implicit_args(trace:DynamicJaxprTrace,in_type:Sequence[Tuple[AbstractValue,bool]],explicit_tracers:Sequence[DynamicJaxprTracer])->Sequence[DynamicJaxprTracer]
jax.interpreters.partial_eval._implicit_arg_type(name:AbstractedAxisName)->AbstractValue
jax.interpreters.partial_eval._in_avals_from_tracers(tracers:List[DynamicJaxprTracer])->List[AbstractValue]
jax.interpreters.partial_eval._inline_literals(jaxpr,constvals)
jax.interpreters.partial_eval._input_type_to_tracers(trace:DynamicJaxprTrace,in_avals:Sequence[AbstractValue])->Sequence[Tracer]
jax.interpreters.partial_eval._memoize(thunk)
jax.interpreters.partial_eval._move_to_front(lst:Sequence,to_move:Sequence[bool])->Sequence
jax.interpreters.partial_eval._partial_eval_jaxpr(jaxpr,unknowns,instantiate)
jax.interpreters.partial_eval._partial_eval_jaxpr_custom(jaxpr:Jaxpr,in_unknowns:Sequence[bool],saveable:Callable[...,bool])->Tuple[Jaxpr, Jaxpr, Sequence[bool], Sequence[bool], int]
jax.interpreters.partial_eval._partition_knowns(pvals,unknowns:Sequence[bool])
jax.interpreters.partial_eval._reconstruct_pval(pval1:PartialVal,const2:core.Value)
jax.interpreters.partial_eval._remat_partial_eval(trace,_,f,tracers,params)
jax.interpreters.partial_eval._split_aval(unknown:bool,aval:AbstractValue)->Tuple[AbstractValue, AbstractValue]
jax.interpreters.partial_eval._substitute_axis_sizes(env:Dict,aval:AbstractValue)->AbstractValue
jax.interpreters.partial_eval._substitute_tracers_in_type(env:Dict[Var,Tracer],a:AbstractValue)->AbstractValue
jax.interpreters.partial_eval._substitute_vars_in_type(consts:Dict[Var,Literal],env:Dict[Var,Var],a:AbstractValue)->AbstractValue
jax.interpreters.partial_eval._update_annotation(f:lu.WrappedFun,orig_type:Optional[Tuple[Tuple[AbstractValue,bool],...]],in_knowns:List[bool])->lu.WrappedFun
jax.interpreters.partial_eval._zip_knowns(known_list,unknown_list,which_unknown:Sequence[bool])
jax.interpreters.partial_eval.abstract_eval_fun(fun,*avals,debug_info=None,**params)
jax.interpreters.partial_eval.arg_info_flattened(flat_pos:List[int])->str
jax.interpreters.partial_eval.arg_info_pytree(fn:Callable,in_tree:PyTreeDef,has_kwargs:bool,flat_pos:List[int])->str
jax.interpreters.partial_eval.call_padding_rule(prim,in_avals,out_avals,*args,call_jaxpr,**params)
jax.interpreters.partial_eval.call_partial_eval_custom_rule(jaxpr_param_name:str,params_updater:ParamsUpdater,saveable:Callable[...,bool],unks_in:List[bool],inst_in:List[bool],eqn:JaxprEqn)->Tuple[JaxprEqn, JaxprEqn, Sequence[bool], Sequence[bool], List[Var]]
jax.interpreters.partial_eval.convert_constvars_jaxpr(jaxpr:Jaxpr)->Jaxpr
jax.interpreters.partial_eval.convert_envvars_to_constvars(jaxpr:Jaxpr,num_env_vars:int)->Jaxpr
jax.interpreters.partial_eval.dce_jaxpr(jaxpr:Jaxpr,used_outputs:List[bool])->Tuple[Jaxpr, List[bool]]
jax.interpreters.partial_eval.dce_jaxpr_call_rule(used_outputs:List[bool],eqn:JaxprEqn)->Tuple[List[bool], JaxprEqn]
jax.interpreters.partial_eval.debug_info(fn:Callable,in_tree:Optional[PyTreeDef],has_kwargs:bool,traced_for:str)->DebugInfo
jax.interpreters.partial_eval.debug_info_final(fn:lu.WrappedFun,traced_for:str)->DebugInfo
jax.interpreters.partial_eval.extend_jaxpr_stack(main,frame)
jax.interpreters.partial_eval.fun_sourceinfo(fun:Callable)
jax.interpreters.partial_eval.identity(x)
jax.interpreters.partial_eval.infer_lambda_input_type(axes_specs:Optional[Sequence[AbstractedAxesSpec]],args:Sequence[Any])->InputType
jax.interpreters.partial_eval.instantiate_const_at(trace:JaxprTrace,instantiate:bool,tracer)
jax.interpreters.partial_eval.move_binders_to_front(closed_jaxpr:ClosedJaxpr,to_move:Sequence[bool])->ClosedJaxpr
jax.interpreters.partial_eval.new_eqn_recipe(invars:Sequence[JaxprTracer],outvars:Sequence[JaxprTracer],primitive:Primitive,params:Dict[str,Any],effects:core.Effects,source_info:source_info_util.SourceInfo)->JaxprEqnRecipe
jax.interpreters.partial_eval.pad_jaxpr(jaxpr:Jaxpr,consts:Sequence[Const])->Tuple[Jaxpr, List[Const]]
jax.interpreters.partial_eval.partial_eval_jaxpr(jaxpr:ClosedJaxpr,unknowns:Sequence[bool],instantiate:Union[bool,Sequence[bool]])->Tuple[ClosedJaxpr, ClosedJaxpr, Sequence[bool]]
jax.interpreters.partial_eval.partial_eval_jaxpr_custom_rule_not_implemented(name:str,saveable:Callable[...,bool],unks_in:Sequence[bool],inst_in:Sequence[bool],eqn:JaxprEqn)->PartialEvalCustomResult
jax.interpreters.partial_eval.partial_eval_to_jaxpr_dynamic(fun:lu.WrappedFun,in_pvals:Sequence[PartialVal])
jax.interpreters.partial_eval.partial_eval_wrapper(pvs:Sequence[Optional[AbstractValue]],*consts)
jax.interpreters.partial_eval.partial_eval_wrapper_nounits(in_knowns:Sequence[bool],in_avals:Sequence[AbstractValue],*in_consts:Any)
jax.interpreters.partial_eval.partition_pvals(pvals:List[PartialVal])->Tuple[List[bool], List[AbstractValue], List[Any]]
jax.interpreters.partial_eval.recipe_to_eqn(getvar:Callable[[JaxprTracer],Atom],recipe:JaxprEqnRecipe)->core.JaxprEqn
jax.interpreters.partial_eval.trace_to_jaxpr(fun:lu.WrappedFun,pvals:Sequence[PartialVal],instantiate:Union[bool,Sequence[bool]]=False)->Tuple[Jaxpr, List[PartialVal], List[core.Value]]
jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(fun:lu.WrappedFun,in_avals:Sequence[AbstractValue],debug_info:Optional[DebugInfo]=None,*,keep_inputs:Optional[List[bool]]=None)
jax.interpreters.partial_eval.trace_to_jaxpr_final(fun:lu.WrappedFun,in_avals:Sequence[AbstractValue],debug_info:Optional[DebugInfo]=None,keep_inputs:Optional[Sequence[bool]]=None)
jax.interpreters.partial_eval.trace_to_subjaxpr(main:core.MainTrace,instantiate:Union[bool,Sequence[bool]],pvals:Sequence[PartialVal])
jax.interpreters.partial_eval.trace_to_subjaxpr_dynamic(fun:lu.WrappedFun,main:core.MainTrace,in_avals:Sequence[AbstractValue],*,keep_inputs:Optional[Sequence[bool]]=None)
jax.interpreters.partial_eval.trace_to_subjaxpr_nounits(main:core.MainTrace,instantiate:Union[bool,Sequence[bool]],in_pvals:Sequence[PartialVal])
jax.interpreters.partial_eval.tracers_to_jaxpr(in_tracers:Sequence[JaxprTracer],out_tracers:Sequence[JaxprTracer])->Tuple[Jaxpr, Tuple[Any, ...], Tuple[Any, ...]]


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/mlir.py----------------------------------------
A:jax.interpreters.mlir.T->typing.TypeVar('T')
A:jax.interpreters.mlir.a->numpy.array(0 if a.item() == 0 else 255, np.uint8)
A:jax.interpreters.mlir.dtype->numpy.dtype(dtype)
A:jax.interpreters.mlir.types->aval_to_ir_types(aval)
A:jax.interpreters.mlir.handler->_constant_handlers.get(t)
A:jax.interpreters.mlir.out->handler(val, canonicalize_types)
A:jax.interpreters.mlir.values->ir_constants(val)
A:jax.interpreters.mlir.x->numpy.ascontiguousarray(x)
A:jax.interpreters.mlir.ir_type->jax._src.lib.mlir.ir.RankedTensorType.get(x.shape, dtype_to_ir_type(x.dtype))
A:jax.interpreters.mlir.attr->jax._src.lib.mlir.ir.DenseElementsAttr.get(x, type=ir_type.element_type, shape=shape)
A:jax.interpreters.mlir.(zero_stride_axes,)->numpy.where(np.equal(0, val.strides))
A:jax.interpreters.mlir.(other_axes,)->numpy.where(np.not_equal(0, val.strides))
A:jax.interpreters.mlir.collapsed_val->numpy.asarray(collapsed_val, dtypes.canonicalize_dtype(collapsed_val.dtype))
A:jax.interpreters.mlir.frame->jax._src.source_info_util.user_frame(source_info)
A:jax.interpreters.mlir.loc->_source_info_to_location(eqn.primitive, eqn.params, eqn.source_info, name_stack=ctx.name_stack)
A:jax.interpreters.mlir.context->jax._src.lib.mlir.ir.Context()
A:jax.interpreters.mlir._platform_specific_lowerings->collections.defaultdict(dict)
A:jax.interpreters.mlir._module_unique_id->itertools.count()
A:jax.interpreters.mlir._module_name_regex->re.compile('[^\\w.-]')
A:jax.interpreters.mlir.tile_rank->len(sharding.tile_assignment_dimensions)
A:jax.interpreters.mlir.(input_output_aliases, donated_args)->_set_up_aliases(in_avals, out_avals, donated_args)
A:jax.interpreters.mlir.ctx->ModuleContext(platform, axis_context, name_stack)
A:jax.interpreters.mlir.module_name->re.compile('[^\\w.-]').sub('_', module_name)
A:jax.interpreters.mlir.ctx.module.operation.attributes['sym_name']->jax._src.lib.mlir.ir.StringAttr.get(f'{module_name}.{next(_module_unique_id)}')
A:jax.interpreters.mlir.output->io.StringIO()
A:jax.interpreters.mlir.avals_in->map(strip_metadata, avals_in)
A:jax.interpreters.mlir.avals_out->map(strip_metadata, avals_out)
A:jax.interpreters.mlir.donations->collections.defaultdict(collections.deque)
A:jax.interpreters.mlir.out_donated_args->list(donated_args)
A:jax.interpreters.mlir.input_id->donations[aval].popleft()
A:jax.interpreters.mlir.aval->jax.core.ShapedArray((), np.dtype(np.bool_))
A:jax.interpreters.mlir.input_types->map(aval_to_ir_types, ctx.avals_in)
A:jax.interpreters.mlir.output_types->map(aval_to_ir_types, ctx.avals_out)
A:jax.interpreters.mlir.flat_input_types->jax._src.util.flatten(input_types)
A:jax.interpreters.mlir.flat_output_types->jax._src.util.flatten(output_types)
A:jax.interpreters.mlir.ftype->jax._src.lib.mlir.ir.FunctionType.get(flat_input_types, flat_output_types)
A:jax.interpreters.mlir.func_op->FuncOp(ctx.primitive.name, ftype, ip=ctx.module_context.ip)
A:jax.interpreters.mlir.func_op.attributes['sym_visibility']->jax._src.lib.mlir.ir.StringAttr.get('private')
A:jax.interpreters.mlir.ir_arg_shardings->jax._src.util.flatten([[sharding] * len(types) for (sharding, types) in zip(arg_shardings, input_types)])
A:jax.interpreters.mlir.ir_result_shardings->jax._src.util.flatten([[sharding] * len(types) for (sharding, types) in zip(result_shardings, output_types)])
A:jax.interpreters.mlir.attrs['mhlo.is_same_data_across_replicas']->jax._src.lib.mlir.ir.UnitAttr.get()
A:jax.interpreters.mlir.attrs['mhlo.sharding']->jax._src.lib.mlir.ir.StringAttr.get(sharding.SerializeToString())
A:jax.interpreters.mlir.output_ids->jax._src.util.unflatten(list(range(len(flat_output_types))), map(len, output_types))
A:jax.interpreters.mlir.attrs['tf.aliasing_output']->i32_attr(alias)
A:jax.interpreters.mlir.func_op.arg_attrs->jax._src.lib.mlir.ir.ArrayAttr.get([ir.DictAttr.get(attrs) for attrs in arg_attrs])
A:jax.interpreters.mlir.func_op.result_attrs->jax._src.lib.mlir.ir.ArrayAttr.get([ir.DictAttr.get({} if sharding is None else {'mhlo.sharding': ir.StringAttr.get(sharding.SerializeToString())}) for sharding in ir_result_shardings])
A:jax.interpreters.mlir.entry_block->FuncOp(ctx.primitive.name, ftype, ip=ctx.module_context.ip).add_entry_block()
A:jax.interpreters.mlir.flat_args->map(wrap_with_sharding_op, flat_args, ir_arg_shardings)
A:jax.interpreters.mlir.unflattened_args->jax._src.util.unflatten(entry_block.arguments, map(len, input_types))
A:jax.interpreters.mlir.callee_name_stack->jax.interpreters.xla.extend_name_stack(ctx.name_stack, xla.wrap_name(name, 'jit'))
A:jax.interpreters.mlir.out_vals->jaxpr_subcomp(ctx.replace(name_stack=callee_name_stack), jaxpr.jaxpr, map(ir_constants, jaxpr.consts), *args)
A:jax.interpreters.mlir.flat_outputs->map(wrap_with_sharding_op, flat_outputs, ir_result_shardings)
A:jax.interpreters.mlir.outs->lowering_rule(ctx, *_unwrap_singleton_ir_values(unflattened_args))
A:jax.interpreters.mlir.env[v]->tuple(node)
A:jax.interpreters.mlir.in_nodes->map(read, eqn.invars)
A:jax.interpreters.mlir.rule->xla_fallback_lowering(eqn.primitive)
A:jax.interpreters.mlir.rule_ctx->LoweringRuleContext(module_context=ctx, primitive=eqn.primitive, avals_in=map(aval, eqn.invars), avals_out=map(aval, eqn.outvars))
A:jax.interpreters.mlir.ans->rule(rule_ctx, *map(_unwrap_singleton_ir_values, in_nodes), **eqn.params)
A:jax.interpreters.mlir.out_nodes->tuple(map(wrap_singleton_ir_values, ans))
A:jax.interpreters.mlir.wrapped_fun->jax.linear_util.wrap_init(f, params)
A:jax.interpreters.mlir.(jaxpr, _, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_dynamic(wrapped_fun, ctx.avals_in)
A:jax.interpreters.mlir.sub_ctx->ModuleContext(platform, axis_context, name_stack).replace(name_stack=xla.extend_name_stack(ctx.name_stack, stack_name))
A:jax.interpreters.mlir.call->jax._src.lib.mlir.dialects.func.CallOp(flat_output_types, ir.FlatSymbolRefAttr.get(func.name.value), flatten_lowering_ir_args(args))
A:jax.interpreters.mlir.zero->ir_constant(np.array(value, aval.dtype))
A:jax.interpreters.mlir.bool_shape->jax._src.lib.mlir.ir.RankedTensorType.get(dims, ir.IntegerType.get_signless(1))
A:jax.interpreters.mlir.tensor_type->jax._src.lib.mlir.ir.RankedTensorType(x.type)
A:jax.interpreters.mlir.real_eq->compare_mhlo(rx, ry, 'EQ', 'FLOAT')
A:jax.interpreters.mlir.real_cmp->compare_mhlo(rx, ry, cmp, 'FLOAT')
A:jax.interpreters.mlir.imag_cmp->compare_mhlo(mhlo.ImagOp(x).result, mhlo.ImagOp(y).result, cmp, 'FLOAT')
A:jax.interpreters.mlir.min_mhlo->partial(_minmax_mhlo, mhlo.MinOp, 'LT')
A:jax.interpreters.mlir.max_mhlo->partial(_minmax_mhlo, mhlo.MaxOp, 'GT')
A:jax.interpreters.mlir.op->typing.cast(FuncOpType, op)
A:jax.interpreters.mlir.op.attributes['mhlo.sharding']->jax._src.lib.mlir.ir.StringAttr.get(sharding_proto.SerializeToString())
A:jax.interpreters.mlir.wrap_with_full_to_shard_op->partial(_wrap_with_spmd_op, 'SPMDFullToShardShape')
A:jax.interpreters.mlir.wrap_with_shard_to_full_op->partial(_wrap_with_spmd_op, 'SPMDShardToFullShape')
A:jax.interpreters.mlir.func->_emit_lowering_rule_as_fun(partial(f, **params), ctx)
A:jax.interpreters.mlir.xla_computation->jax.interpreters.xla.primitive_subcomputation(module_ctx.platform, module_ctx.axis_env, prim, *ctx.avals_in, **params)
A:jax.interpreters.mlir.submodule_str->jax._src.lib.xla_client._xla.mlir.xla_computation_to_mlir_module(xla_computation)
A:jax.interpreters.mlir.submodule->jax._src.lib.mlir.ir.Module.parse(submodule_str)
A:jax.interpreters.mlir.op.attributes['sym_name']->jax._src.lib.mlir.ir.StringAttr.get(f'xla_fallback_{prim.name}')
A:jax.interpreters.mlir.op.attributes['sym_visibility']->jax._src.lib.mlir.ir.StringAttr.get('private')
jax.interpreters.mlir.ConstantHandler(self,val:Any,canonicalize_types:bool)
jax.interpreters.mlir.ConstantHandler.__call__(self,val:Any,canonicalize_types:bool)
jax.interpreters.mlir.LoweringRuleContext
jax.interpreters.mlir.LoweringRuleContext.replace(self,**kw)
jax.interpreters.mlir.ModuleContext(self,platform:str,axis_context:AxisContext,name_stack:NameStack,context:Optional[ir.Context]=None,module:Optional[ir.Module]=None,ip:Optional[ir.InsertionPoint]=None,symbol_table:Optional[ir.SymbolTable]=None,cached_primitive_lowerings:Optional[Dict[Any,FuncOpType]]=None)
jax.interpreters.mlir.ModuleContext.__init__(self,platform:str,axis_context:AxisContext,name_stack:NameStack,context:Optional[ir.Context]=None,module:Optional[ir.Module]=None,ip:Optional[ir.InsertionPoint]=None,symbol_table:Optional[ir.SymbolTable]=None,cached_primitive_lowerings:Optional[Dict[Any,FuncOpType]]=None)
jax.interpreters.mlir.ModuleContext.axis_env(self)->xla.AxisEnv
jax.interpreters.mlir.ModuleContext.replace(self,**kw)
jax.interpreters.mlir.ReplicaAxisContext
jax.interpreters.mlir.SPMDAxisContext
jax.interpreters.mlir.SPMDAxisContext.axis_env(self)
jax.interpreters.mlir.SPMDAxisContext.extend_manual(self,axes:FrozenSet[MeshAxisName])->'SPMDAxisContext'
jax.interpreters.mlir._array_ir_types(aval:core.ShapedArray)->Sequence[ir.Type]
jax.interpreters.mlir._bint_ir_types(aval:core.AbstractBInt)->Sequence[ir.Type]
jax.interpreters.mlir._call_lowering(fn_name,stack_name,call_jaxpr,backend,ctx,avals_in,avals_out,*args)
jax.interpreters.mlir._device_array_constant_handler(val,canonicalize_types)
jax.interpreters.mlir._dynamic_array_ir_types(aval:core.ShapedArray)->Sequence[ir.Type]
jax.interpreters.mlir._emit_lowering_rule_as_fun(lowering_rule,ctx:LoweringRuleContext)->FuncOpType
jax.interpreters.mlir._ir_consts(consts)
jax.interpreters.mlir._minmax_mhlo(op,cmp,x,y)
jax.interpreters.mlir._named_call_lowering(ctx,*args,name,backend=None,call_jaxpr)
jax.interpreters.mlir._ndarray_constant_handler(val:np.ndarray,canonicalize_types)->Sequence[ir.Value]
jax.interpreters.mlir._numpy_array_constant(x:np.ndarray,canonicalize_types)->Sequence[ir.Value]
jax.interpreters.mlir._python_scalar_handler(dtype,val,canonicalize_dtypes)
jax.interpreters.mlir._set_up_aliases(avals_in,avals_out,donated_args)
jax.interpreters.mlir._source_info_to_location(primitive:core.Primitive,params:Dict,source_info:source_info_util.SourceInfo,name_stack:Union[str,source_info_util.NameStack]='')->ir.Location
jax.interpreters.mlir._unwrap_singleton_ir_values(x)
jax.interpreters.mlir._wrap_with_spmd_op(name:str,result_type:ir.Type,x:ir.Value,sharding_proto:xc.OpSharding,unspecified_dims:Optional[Set[int]]=None)
jax.interpreters.mlir._xla_call_lower(ctx,*args,backend=None,name,call_jaxpr,donated_invars,inline=None,device=None)
jax.interpreters.mlir.add_jaxvals_lowering(ctx,x,y)
jax.interpreters.mlir.aval_to_ir_type(aval:core.AbstractValue)->ir.Type
jax.interpreters.mlir.aval_to_ir_types(aval:core.AbstractValue)->Sequence[ir.Type]
jax.interpreters.mlir.cache_lowering(f)
jax.interpreters.mlir.compare_mhlo(x,y,direction,type)
jax.interpreters.mlir.convert_mhlo(x,aval_in,aval_out)
jax.interpreters.mlir.dense_bool_elements(xs:Sequence[bool])->ir.DenseElementsAttr
jax.interpreters.mlir.dense_int_elements(xs)->ir.DenseIntElementsAttr
jax.interpreters.mlir.dtype_to_ir_type(dtype:Union[np.dtype,np.generic])->ir.Type
jax.interpreters.mlir.flatten_lowering_ir_args(xs:Sequence[Union[ir.Value,Sequence[ir.Value]]])->Sequence[Sequence[ir.Value]]
jax.interpreters.mlir.full_like_aval(value,aval:core.ShapedArray)->ir.Value
jax.interpreters.mlir.i32_attr(i)
jax.interpreters.mlir.i64_attr(i)
jax.interpreters.mlir.ir_constant(val:Any,canonicalize_types:bool=True)->ir.Value
jax.interpreters.mlir.ir_constants(val:Any,canonicalize_types:bool=True)->Sequence[ir.Value]
jax.interpreters.mlir.jaxpr_subcomp(ctx:ModuleContext,jaxpr:core.Jaxpr,consts:Sequence[Sequence[ir.Value]],*args:Sequence[ir.Value])->Sequence[Sequence[ir.Value]]
jax.interpreters.mlir.lower_fun(fun:Callable,multiple_results:bool=True)->Callable
jax.interpreters.mlir.lower_jaxpr_to_fun(ctx:ModuleContext,name:str,jaxpr:core.ClosedJaxpr,*,public:bool=False,replace_units_with_dummy:bool=False,replace_tokens_with_dummy:bool=False,replicated_args:Optional[Sequence[bool]]=None,arg_shardings:Optional[Sequence[Optional[xc.OpSharding]]]=None,result_shardings:Optional[Sequence[Optional[xc.OpSharding]]]=None,use_sharding_annotations:bool=True,input_output_aliases:Optional[Sequence[Optional[int]]]=None)->FuncOpType
jax.interpreters.mlir.lower_jaxpr_to_module(module_name:str,jaxpr:core.ClosedJaxpr,platform:str,axis_context:AxisContext,name_stack:NameStack,donated_args:Sequence[bool],replicated_args:Optional[Sequence[bool]]=None,arg_shardings:Optional[Sequence[Optional[xc.OpSharding]]]=None,result_shardings:Optional[Sequence[Optional[xc.OpSharding]]]=None)->ir.Module
jax.interpreters.mlir.make_ir_context()->ir.Context
jax.interpreters.mlir.module_to_string(module:ir.Module)->str
jax.interpreters.mlir.register_constant_handler(type_:type,handler_fun:ConstantHandler)
jax.interpreters.mlir.register_lowering(prim:core.Primitive,rule:LoweringRule,platform:Optional[str]=None)
jax.interpreters.mlir.set_sharding(op,sharding_proto:xc.OpSharding)
jax.interpreters.mlir.sharded_aval(aval:core.ShapedArray,sharding:Optional[xc.OpSharding])->core.ShapedArray
jax.interpreters.mlir.wrap_singleton_ir_values(x:Union[ir.Value,Sequence[ir.Value]])->Sequence[ir.Value]
jax.interpreters.mlir.wrap_with_sharding_op(x:ir.Value,sharding_proto:xc.OpSharding,unspecified_dims:Optional[Set[int]]=None)
jax.interpreters.mlir.xla_fallback_lowering(prim:core.Primitive)
jax.interpreters.mlir.zeros_like_lowering(ctx,x)


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/interpreters/sharded_jit.py----------------------------------------
A:jax.interpreters.sharded_jit.result_to_populate->ResultToPopulate()
A:jax.interpreters.sharded_jit.spec->jax.interpreters.pxla.partitioned_sharding_spec(npart, parts, aval)
A:jax.interpreters.sharded_jit.indices->jax.interpreters.pxla.spec_to_indices(aval.shape, spec)
A:jax.interpreters.sharded_jit.(jaxpr, global_out_avals, consts)->jax.interpreters.partial_eval.trace_to_jaxpr_final(fun, global_abstract_args)
A:jax.interpreters.sharded_jit.nparts->jax.interpreters.pxla.get_num_partitions(in_parts, out_parts)
A:jax.interpreters.sharded_jit.out_parts->out_parts_thunk()
A:jax.interpreters.sharded_jit.local_out_parts->local_out_parts_thunk()
A:jax.interpreters.sharded_jit.axis_env->jax.interpreters.xla.AxisEnv(nrep, (), ())
A:jax.interpreters.sharded_jit.module->jax.interpreters.mlir.lower_jaxpr_to_module('spjit_{}'.format(fun.__name__), core.ClosedJaxpr(jaxpr, consts), platform=platform, axis_context=mlir.ReplicaAxisContext(axis_env), name_stack=new_name_stack(wrap_name(name, 'sharded_jit')), donated_args=[False] * len(in_parts), arg_shardings=safe_map(xla.sharding_to_proto, in_parts), result_shardings=safe_map(xla.sharding_to_proto, out_parts))
A:jax.interpreters.sharded_jit.built->jax._src.lib.xla_client._xla.mlir.mlir_module_to_xla_computation(mlir.module_to_string(module), use_tuple_args=False, return_tuple=True)
A:jax.interpreters.sharded_jit.devices->jax._src.lib.xla_bridge.devices()
A:jax.interpreters.sharded_jit.device_assignment->numpy.reshape(device_assignment, (-1, nparts))
A:jax.interpreters.sharded_jit.compiled->jax._src.dispatch.backend_compile(xb.get_backend(), built, xb.get_compile_options(nrep, nparts, device_assignment))
A:jax.interpreters.sharded_jit.handle_args->partial(pxla.shard_args, compiled.local_devices(), input_indices)
A:jax.interpreters.sharded_jit.handle_outs->_avals_to_results_handler(nrep, local_nparts, local_out_parts, local_out_avals)
A:jax.interpreters.sharded_jit.subc->subc.build(xops.Tuple(subc, out_nodes)).build(xops.Tuple(subc, out_nodes))
A:jax.interpreters.sharded_jit.arg->jax.interpreters.xla.parameter(subc, i, ctx.builder.GetShape(n))
A:jax.interpreters.sharded_jit.sub_ctx->ctx.module_context.replace(name_stack=new_name_stack(wrap_name(name, 'sharded_jit')))
A:jax.interpreters.sharded_jit.out_nodes->jax._src.util.unflatten(call.results, safe_map(len, output_types))
A:jax.interpreters.sharded_jit.fn->jax.interpreters.mlir.lower_jaxpr_to_fun(sub_ctx, f'sharded_jit_{name}', core.ClosedJaxpr(call_jaxpr, ()))
A:jax.interpreters.sharded_jit.output_types->safe_map(mlir.aval_to_ir_types, ctx.avals_out)
A:jax.interpreters.sharded_jit.flat_output_types->jax._src.util.flatten(output_types)
A:jax.interpreters.sharded_jit.call->jax._src.lib.mlir.dialects.func.CallOp(flat_output_types, ir.FlatSymbolRefAttr.get(fn.name.value), mlir.flatten_lowering_ir_args(args))
A:jax.interpreters.sharded_jit.input_bufs->in_handler(args)
A:jax.interpreters.sharded_jit.out_bufs->jax._src.dispatch.backend_compile(xb.get_backend(), built, xb.get_compile_options(nrep, nparts, device_assignment)).execute_sharded_on_local_devices(input_bufs)
A:jax.interpreters.sharded_jit.param->jax.interpreters.xla.with_sharding(c, sharding, xla.parameter, c, i, *xla.aval_to_xla_shapes(aval))
A:jax.interpreters.sharded_jit.compiled_fun->_sharded_callable(fun, nparts, in_parts, out_parts_thunk, local_in_parts, local_out_parts_thunk, local_nparts, name, *map(xla.abstractify, args))
A:jax.interpreters.sharded_jit.sharded_call_p->jax.core.CallPrimitive('sharded_call')
A:jax.interpreters.sharded_jit.local_nparts->jax.interpreters.pxla.get_num_partitions(local_in_parts, local_out_parts)
A:jax.interpreters.sharded_jit.static_argnums->_ensure_index_tuple(static_argnums)
A:jax.interpreters.sharded_jit.f->jax.linear_util.wrap_init(fun)
A:jax.interpreters.sharded_jit.(f, args)->argnums_partial(f, dyn_argnums, args)
A:jax.interpreters.sharded_jit.(args_flat, in_tree)->tree_flatten((args, kwargs))
A:jax.interpreters.sharded_jit.in_parts_flat->tuple(flatten_axes('sharded_jit in_parts', in_tree.children()[0], in_parts))
A:jax.interpreters.sharded_jit.local_in_parts_flat->tuple(flatten_axes('sharded_jit local_in_parts', in_tree.children()[0], local_in_parts))
A:jax.interpreters.sharded_jit.(flat_fun, out_tree)->flatten_fun(f, in_tree)
A:jax.interpreters.sharded_jit.out_parts_thunk->HashableFunction(lambda : tuple(flatten_axes('sharded_jit out_parts', out_tree(), out_parts)), closure=out_parts)
A:jax.interpreters.sharded_jit.local_out_parts_thunk->HashableFunction(lambda : None, closure=None)
A:jax.interpreters.sharded_jit.out->sharded_call(flat_fun, *args_flat, nparts=nparts, in_parts=in_parts_flat, out_parts_thunk=out_parts_thunk, local_in_parts=local_in_parts_flat, local_out_parts_thunk=local_out_parts_thunk, local_nparts=local_nparts, name=flat_fun.__name__)
A:jax.interpreters.sharded_jit.sharding_constraint_p->jax.core.Primitive('sharding_constraint')
jax.interpreters.sharded_jit.ResultToPopulate
jax.interpreters.sharded_jit._aval_to_result_handler(npart,parts,aval)
jax.interpreters.sharded_jit._avals_to_results_handler(nrep,npart,partitions,out_avals)
jax.interpreters.sharded_jit._execute_spatially_partitioned(compiled,in_handler,out_handler,*args)
jax.interpreters.sharded_jit._map(f,*xs)
jax.interpreters.sharded_jit._sharded_call_impl(fun,*args,nparts,in_parts,out_parts_thunk,local_in_parts,local_out_parts_thunk,local_nparts,name)
jax.interpreters.sharded_jit._sharded_callable(fun:lu.WrappedFun,nparts:Optional[int],in_parts:Tuple[pxla.PartitionsOrReplicated,...],out_parts_thunk:Callable[[],Tuple[pxla.PartitionsOrReplicated,...]],local_in_parts:Optional[Tuple[pxla.PartitionsOrReplicated,...]],local_out_parts_thunk:Callable[[],Optional[Tuple[pxla.PartitionsOrReplicated,...]]],local_nparts:Optional[int],name:str,*abstract_args)
jax.interpreters.sharded_jit._sharded_jit_lowering(ctx,*in_nodes,in_parts,out_parts_thunk,nparts,name,call_jaxpr,local_in_parts,local_out_parts_thunk,local_nparts)
jax.interpreters.sharded_jit._sharded_jit_translation_rule(ctx,avals_in,avals_out,*in_nodes,in_parts,out_parts_thunk,nparts,name,call_jaxpr,local_in_parts,local_out_parts_thunk,local_nparts)
jax.interpreters.sharded_jit._sharding_constraint_impl(x,partitions)
jax.interpreters.sharded_jit._sharding_constraint_lowering(ctx,x_node,partitions)
jax.interpreters.sharded_jit._sharding_constraint_translation_rule(ctx,avals_in,avals_out,x_node,partitions)
jax.interpreters.sharded_jit._xla_sharded_args(c,avals,in_parts)
jax.interpreters.sharded_jit.sharded_jit(fun:Callable,in_parts,out_parts,num_partitions:Optional[int]=None,local_in_parts=None,local_out_parts=None,local_num_partitions=None,static_argnums:Union[int,Iterable[int]]=())
jax.interpreters.sharded_jit.with_sharding_constraint(x,partitions:Optional[pxla.PartitionSpec])


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/lax/__init__.py----------------------------------------


----------------------------------------/dataset/nuaa/anaconda3/envs/jax0.3.6/lib/python3.9/site-packages/jax/lax/linalg.py----------------------------------------

